[
  {
    "instruction": "Write an answer to the following question: How does confidential computing help enable multiple parties to engage in joint analysis using confidential or regulated data inside a TEE while preserving privacy and regulatory compliance?",
    "context": "",
    "output": "Confidential computing enables multiple parties to engage in joint analysis using confidential or regulated data inside a TEE while preserving privacy and regulatory compliance by ensuring that no party's sensitive data or confidential code is exposed to the other parties or system host.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does confidential computing help enable multiple parties to engage in joint analysis using confidential or regulated data inside a TEE while preserving privacy and regulatory compliance?",
      "answer": "Confidential computing enables multiple parties to engage in joint analysis using confidential or regulated data inside a TEE while preserving privacy and regulatory compliance by ensuring that no party's sensitive data or confidential code is exposed to the other parties or system host."
    }
  },
  {
    "instruction": "Write an answer to the following question: What features does Vera's SDK allow developers to add to custom and legacy business applications?",
    "context": "",
    "output": "Vera's SDK allows developers to add encryption, tracking, policy enforcement, and access control to custom and legacy business applications.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What features does Vera's SDK allow developers to add to custom and legacy business applications?",
      "answer": "Vera's SDK allows developers to add encryption, tracking, policy enforcement, and access control to custom and legacy business applications."
    }
  },
  {
    "instruction": "Write an answer to the following question: How do mobile VPNs handle network logins and authentication as the endpoint changes?",
    "context": "",
    "output": "Mobile VPNs maintain a virtual connection to the application at all times as the endpoint changes, handling the necessary network logins and authentication in a manner transparent to the user.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do mobile VPNs handle network logins and authentication as the endpoint changes?",
      "answer": "Mobile VPNs maintain a virtual connection to the application at all times as the endpoint changes, handling the necessary network logins and authentication in a manner transparent to the user."
    }
  },
  {
    "instruction": "Capability-based security\n\n==Introduction==\nCapability-based security is a concept in the design of secure computing systems, one of the existing security models. A capability (known in some systems as a key) is a communicable, unforgeable token of authority. It refers to a value that references an object along with an associated set of access rights. A user program on a capability-based operating system must use a capability to access an object. Capability-based security refers to the principle of designing user programs such that they directly share capabilities with each other according to the principle of least privilege, and to the operating system infrastructure necessary to make such transactions efficient and secure. Capability-based security is to be contrasted with an approach that uses traditional UNIX permissions and Access Control Lists.\nAlthough most operating systems implement a facility which resembles capabilities, they typically do not provide enough support to allow for the exchange of capabilities among possibly mutually untrusting entities to be the primary means of granting and distributing access rights throughout the system. A capability-based system, in contrast, is designed with that goal in mind.\n\n\n\n== Introduction ==\nCapabilities achieve their objective of improving system security by being used in place of forgeable references. A forgeable reference (for example, a path name) identifies an object, but does not specify which access rights are appropriate for that object and the user program which holds that reference. Consequently, any attempt to access the referenced object must be validated by the operating system, based on the ambient authority of the requesting program, typically via the use of an access-control list (ACL). Instead, in a system with capabilities, the mere fact that a user program possesses that capability entitles it to use the referenced object in accordance with the rights that are specified by that capability. In theory, a system with capabilities removes the need for any access control list or similar mechanism by giving all entities all and only the capabilities they will actually need.\nA capability is typically implemented as a privileged data structure that consists of a section that specifies access rights, and a section that uniquely identifies the object to be accessed. The user does not access the data structure or object directly, but instead via a handle. In practice, it is used much like a file descriptor in a traditional operating system (a traditional handle), but to access every object on the system. Capabilities are typically stored by the operating system in a list, with some mechanism in place to prevent the program from directly modifying the contents of the capability (so as to forge access rights or change the object it points to). Some systems have also been based on capability-based addressing (hardware support for capabilities), such as Plessey System 250.\nPrograms possessing capabilities can perform functions on them, such as passing them on to other programs, converting them to a less-privileged version, or deleting them. The operating system must ensure that only specific operations can occur to the capabilities in the system, in order to maintain the integrity of the security policy.\nCapabilities as discussed in this article should not be confused with Portable Operating System Interface (POSIX) 1e/2c \"Capabilities\". The latter are coarse-grained privileges that cannot be transferred between processes.\n\n== Examples ==\nA capability is defined to be a protected object reference which, by virtue of its possession by a user process, grants that process the capability (hence the name) to interact with an object in certain ways. Those ways might include reading data associated with an object, modifying the object, executing the data in the object as a process, and other conceivable access rights. The capability logically consists of a reference that uniquely identifies a particular object and a set of one or more of these rights.\nSuppose that, in a user process's memory space, there exists the following string:\n\n/etc/passwd\n\nAlthough this identifies a unique object on the system, it does not specify access rights and hence is not a capability. Suppose there is instead the following pair of values:\n\n/etc/passwd\nO_RDWR\n\nThis pair identifies an object along with a set of access rights. The pair, however, is still not a capability because the user process's possession of these values says nothing about whether that access would actually be legitimate.\nNow suppose that the user program successfully executes the following statement:\n\nThe variable fd now contains the index of a file descriptor in the process's file descriptor table. This file descriptor is a capability. Its existence in the process's file descriptor table is sufficient to show that the process does indeed have legitimate access to the object. A key feature of this arrangement is that the file descriptor table is in kernel memory and cannot be directly manipulated by the user program.\n\n== Sharing between processes ==\nIn traditional operating systems, programs often communicate with each other and with storage using references like those in the first two examples. Path names are often passed as command-line parameters, sent via sockets, and stored on disk. These references are not capabilities, and must be validated before they can be used. In these systems, a central question is \"on whose authority is a given reference to be evaluated?\" This becomes a critical issue especially for processes which must act on behalf of two different authority-bearing entities. They become susceptible to a programming error known as the confused deputy problem, very frequently resulting in a security hole.\nIn a capability-based system, the capabilities themselves are passed between processes and storage using a mechanism that is known by the operating system to maintain the integrity of those capabilities.\nOne novel approach to solving this problem involves the use of an orthogonally persistent operating system. In such a system, there is no need for entities to be discarded and their capabilities be invalidated, and hence require an ACL-like mechanism to restore those capabilities at a later time. The operating system maintains the integrity and security of the capabilities contained within all storage, both volatile and nonvolatile, at all times; in part by performing all serialization tasks by itself, rather than requiring user programs to do so, as is the case in most operating systems. Because user programs are relieved of this responsibility, there is no need to trust them to reproduce only legal capabilities, nor to validate requests for access using an access control mechanism. An example implementation is the Flex machine from the early 1980s.\n\n== POSIX capabilities ==\nPortable Operating System Interface (POSIX) draft 1003.1e specifies a concept of permissions called \"capabilities\". However, POSIX capabilities differ from capabilities in this article. A POSIX capability is not associated with any object; a process having CAP_NET_BIND_SERVICE capability can listen on any TCP port under 1024. This system is found in Linux.In contrast, Capsicum Unix hybridizes a true capability-system model with a Unix design and POSIX API. Capsicum capabilities are a refined form of file descriptor, a delegable right between processes and additional object types beyond classic POSIX, such as processes, can be referenced via capabilities. In Capsicum capability mode, processes are unable to utilize global namespaces (such as the filesystem namespace) to look up objects, and must instead inherit or be delegated them. This system is found natively in FreeBSD, but patches are available to other systems.\n\n== Implementations ==\nNotable research and commercial systems employing capability-based security include the following:\n\nTahoe-LAFS, an open-source capability-based filesystem\nGNOSIS, an operating system developed at Tymshare\nKeyKOS, successor to GNOSIS\nEROS, The Extremely Reliable Operating System, successor to KeyKOS\nCapROS, a project to further develop the EROS code base for commercial use\nCambridge CAP computer\nHydra (operating system), part of the C.mmp project at Carnegie Mellon University\nStarOS, part of the CM* project at Carnegie Mellon University\nIBM System/38 and AS/400\nIntel iAPX 432\nPlessey System 250\nFlex\nL4 microkernel family:\nOKL4 from Open Kernel Labs\nseL4 from NICTA\nFiasco.OC and NOVA from TU Dresden\nAmoeba distributed operating system\nFreeBSD Capsicum\nGenode\nGoogle Fuchsia\nWebAssembly System Interface (WASI)\nQuestion: What is the relationship between capabilities and objects in a capability-based security system?",
    "context": "",
    "output": "Answer: In a capability-based security system, a capability is associated with an object and grants the process the capability to interact with that object in certain ways.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the relationship between capabilities and objects in a capability-based security system?",
      "answer": "In a capability-based security system, a capability is associated with an object and grants the process the capability to interact with that object in certain ways.",
      "context": "Capability-based security\n\n==Introduction==\nCapability-based security is a concept in the design of secure computing systems, one of the existing security models. A capability (known in some systems as a key) is a communicable, unforgeable token of authority. It refers to a value that references an object along with an associated set of access rights. A user program on a capability-based operating system must use a capability to access an object. Capability-based security refers to the principle of designing user programs such that they directly share capabilities with each other according to the principle of least privilege, and to the operating system infrastructure necessary to make such transactions efficient and secure. Capability-based security is to be contrasted with an approach that uses traditional UNIX permissions and Access Control Lists.\nAlthough most operating systems implement a facility which resembles capabilities, they typically do not provide enough support to allow for the exchange of capabilities among possibly mutually untrusting entities to be the primary means of granting and distributing access rights throughout the system. A capability-based system, in contrast, is designed with that goal in mind.\n\n\n\n== Introduction ==\nCapabilities achieve their objective of improving system security by being used in place of forgeable references. A forgeable reference (for example, a path name) identifies an object, but does not specify which access rights are appropriate for that object and the user program which holds that reference. Consequently, any attempt to access the referenced object must be validated by the operating system, based on the ambient authority of the requesting program, typically via the use of an access-control list (ACL). Instead, in a system with capabilities, the mere fact that a user program possesses that capability entitles it to use the referenced object in accordance with the rights that are specified by that capability. In theory, a system with capabilities removes the need for any access control list or similar mechanism by giving all entities all and only the capabilities they will actually need.\nA capability is typically implemented as a privileged data structure that consists of a section that specifies access rights, and a section that uniquely identifies the object to be accessed. The user does not access the data structure or object directly, but instead via a handle. In practice, it is used much like a file descriptor in a traditional operating system (a traditional handle), but to access every object on the system. Capabilities are typically stored by the operating system in a list, with some mechanism in place to prevent the program from directly modifying the contents of the capability (so as to forge access rights or change the object it points to). Some systems have also been based on capability-based addressing (hardware support for capabilities), such as Plessey System 250.\nPrograms possessing capabilities can perform functions on them, such as passing them on to other programs, converting them to a less-privileged version, or deleting them. The operating system must ensure that only specific operations can occur to the capabilities in the system, in order to maintain the integrity of the security policy.\nCapabilities as discussed in this article should not be confused with Portable Operating System Interface (POSIX) 1e/2c \"Capabilities\". The latter are coarse-grained privileges that cannot be transferred between processes.\n\n== Examples ==\nA capability is defined to be a protected object reference which, by virtue of its possession by a user process, grants that process the capability (hence the name) to interact with an object in certain ways. Those ways might include reading data associated with an object, modifying the object, executing the data in the object as a process, and other conceivable access rights. The capability logically consists of a reference that uniquely identifies a particular object and a set of one or more of these rights.\nSuppose that, in a user process's memory space, there exists the following string:\n\n/etc/passwd\n\nAlthough this identifies a unique object on the system, it does not specify access rights and hence is not a capability. Suppose there is instead the following pair of values:\n\n/etc/passwd\nO_RDWR\n\nThis pair identifies an object along with a set of access rights. The pair, however, is still not a capability because the user process's possession of these values says nothing about whether that access would actually be legitimate.\nNow suppose that the user program successfully executes the following statement:\n\nThe variable fd now contains the index of a file descriptor in the process's file descriptor table. This file descriptor is a capability. Its existence in the process's file descriptor table is sufficient to show that the process does indeed have legitimate access to the object. A key feature of this arrangement is that the file descriptor table is in kernel memory and cannot be directly manipulated by the user program.\n\n== Sharing between processes ==\nIn traditional operating systems, programs often communicate with each other and with storage using references like those in the first two examples. Path names are often passed as command-line parameters, sent via sockets, and stored on disk. These references are not capabilities, and must be validated before they can be used. In these systems, a central question is \"on whose authority is a given reference to be evaluated?\" This becomes a critical issue especially for processes which must act on behalf of two different authority-bearing entities. They become susceptible to a programming error known as the confused deputy problem, very frequently resulting in a security hole.\nIn a capability-based system, the capabilities themselves are passed between processes and storage using a mechanism that is known by the operating system to maintain the integrity of those capabilities.\nOne novel approach to solving this problem involves the use of an orthogonally persistent operating system. In such a system, there is no need for entities to be discarded and their capabilities be invalidated, and hence require an ACL-like mechanism to restore those capabilities at a later time. The operating system maintains the integrity and security of the capabilities contained within all storage, both volatile and nonvolatile, at all times; in part by performing all serialization tasks by itself, rather than requiring user programs to do so, as is the case in most operating systems. Because user programs are relieved of this responsibility, there is no need to trust them to reproduce only legal capabilities, nor to validate requests for access using an access control mechanism. An example implementation is the Flex machine from the early 1980s.\n\n== POSIX capabilities ==\nPortable Operating System Interface (POSIX) draft 1003.1e specifies a concept of permissions called \"capabilities\". However, POSIX capabilities differ from capabilities in this article. A POSIX capability is not associated with any object; a process having CAP_NET_BIND_SERVICE capability can listen on any TCP port under 1024. This system is found in Linux.In contrast, Capsicum Unix hybridizes a true capability-system model with a Unix design and POSIX API. Capsicum capabilities are a refined form of file descriptor, a delegable right between processes and additional object types beyond classic POSIX, such as processes, can be referenced via capabilities. In Capsicum capability mode, processes are unable to utilize global namespaces (such as the filesystem namespace) to look up objects, and must instead inherit or be delegated them. This system is found natively in FreeBSD, but patches are available to other systems.\n\n== Implementations ==\nNotable research and commercial systems employing capability-based security include the following:\n\nTahoe-LAFS, an open-source capability-based filesystem\nGNOSIS, an operating system developed at Tymshare\nKeyKOS, successor to GNOSIS\nEROS, The Extremely Reliable Operating System, successor to KeyKOS\nCapROS, a project to further develop the EROS code base for commercial use\nCambridge CAP computer\nHydra (operating system), part of the C.mmp project at Carnegie Mellon University\nStarOS, part of the CM* project at Carnegie Mellon University\nIBM System/38 and AS/400\nIntel iAPX 432\nPlessey System 250\nFlex\nL4 microkernel family:\nOKL4 from Open Kernel Labs\nseL4 from NICTA\nFiasco.OC and NOVA from TU Dresden\nAmoeba distributed operating system\nFreeBSD Capsicum\nGenode\nGoogle Fuchsia\nWebAssembly System Interface (WASI)"
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the significance of the security properties mentioned in the definition of a cryptographic multilinear map?",
    "context": "",
    "output": "The security properties mentioned in the definition of a cryptographic multilinear map are important for ensuring that the map is secure and cannot be easily reverse-engineered. These properties are essential for ensuring the confidentiality and integrity of data in cryptographic applications.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the significance of the security properties mentioned in the definition of a cryptographic multilinear map?",
      "answer": "The security properties mentioned in the definition of a cryptographic multilinear map are important for ensuring that the map is secure and cannot be easily reverse-engineered. These properties are essential for ensuring the confidentiality and integrity of data in cryptographic applications."
    }
  },
  {
    "instruction": "Shellshock (software bug)\n\n==Introduction==\nShellshock, also known as Bashdoor, is a family of security bugs in the Unix Bash shell, the first of which was disclosed on 24 September 2014. Shellshock could enable an attacker to cause Bash to execute arbitrary commands and gain unauthorized access to many Internet-facing services, such as web servers, that use Bash to process requests.\nOn 12 September 2014, St\u00e9phane Chazelas informed Bash's maintainer Chet Ramey of his discovery of the original bug, which he called \"Bashdoor\". Working with security experts, Mr. Chazelas developed a patch (fix) for the issue, which by then had been assigned the vulnerability identifier CVE-2014-6271. The existence of the bug was announced to the public on 2014-09-24, when Bash updates with the fix were ready for distribution.The bug Chazelas discovered caused Bash to unintentionally execute commands when the commands are concatenated to the end of function definitions stored in the values of environment variables. Within days of its publication, a variety of related vulnerabilities were discovered (CVE-2014-6277, CVE-2014-6278, CVE-2014-7169, CVE-2014-7186 and CVE-2014-7187). Ramey addressed these with a series of further patches.Attackers exploited Shellshock within hours of the initial disclosure by creating botnets of compromised computers to perform distributed denial-of-service attacks and vulnerability scanning. Security companies recorded millions of attacks and probes related to the bug in the days following the disclosure.Because of the potential to compromise millions of unpatched systems, Shellshock was compared to the Heartbleed bug in its severity.\n\n== Background ==\nThe Shellshock bug affects Bash, a program that various Unix-based systems use to execute command lines and command scripts. It is often installed as the system's default command-line interface. Analysis of the source code history of Bash shows the bug was introduced on 5 August 1989, and released in Bash version 1.03 on 1 September 1989.Shellshock is an arbitrary code execution vulnerability that offers a way for users of a system to execute commands that should be unavailable to them. This happens through Bash's \"function export\" feature, whereby one Bash process can share command scripts with other Bash processes that it executes. This feature is implemented by encoding the scripts in a table that is shared between the processes, known as the environment variable list. Each new Bash process scans this table for encoded scripts, assembles each one into a command that defines that script in the new process, and executes that command. The new process assumes that the scripts found in the list come from another Bash process, but it cannot verify this, nor can it verify that the command that it has built is a properly formed script definition. Therefore, an attacker can execute arbitrary commands on the system or exploit other bugs that may exist in Bash's command interpreter, if the attacker has a way to manipulate the environment variable list and then cause Bash to run. At the time the bug was discovered, Bash was installed on macOS and many Linux operating systems as the main command interpreter, so that any program that used the system function to run any other program would use Bash to do so.\nThe presence of the bug was announced to the public on 2014-09-24, when Bash updates with the fix were ready for distribution, though it took some time for computers to be updated to close the potential security issue.\n\n== Reports of attacks ==\nWithin an hour of the announcement of the Bash vulnerability, there were reports of machines being compromised by the bug. By 25 September 2014, botnets based on computers compromised with exploits based on the bug were being used by attackers for distributed denial-of-service (DDoS) attacks and vulnerability scanning. Kaspersky Labs reported that machines compromised in an attack, dubbed \"Thanks-Rob\", were conducting DDoS attacks against three targets, which they did not identify. On 26 September 2014, a Shellshock-related botnet dubbed \"wopbot\" was reported, which was being used for a DDoS attack against Akamai Technologies and to scan the United States Department of Defense.On 26 September, the security firm Incapsula noted 17,400 attacks on more than 1,800 web domains, originating from 400 unique IP addresses, in the previous 24 hours; 55% of the attacks were coming from China and the United States. By 30 September, the website performance firm CloudFlare said it was tracking approximately 1.5 million attacks and probes per day related to the bug.On 6 October, it was widely reported that Yahoo! servers had been compromised in an attack related to the Shellshock issue.\nYet the next day, it was denied that it had been Shellshock that specifically had allowed these attacks.\n\n== Specific exploitation vectors ==\nCGI-based web server\nWhen a web server uses the Common Gateway Interface (CGI) to handle a document request, it copies certain information from the request into the environment variable list and then delegates the request to a handler program. If the handler is a Bash script, or if it executes Bash, then Bash will receive the environment variables passed by the server and will process them as described above. This provides a means for an attacker to trigger the Shellshock vulnerability with a specially crafted document request.\nSecurity documentation for the widely used Apache web server states: \"CGI scripts can ... be extremely dangerous if they are not carefully checked,\" and other methods of handling web server requests are typically used instead. There are a number of online services which attempt to test the vulnerability against web servers exposed to the Internet.\nOpenSSH server\nOpenSSH has a \"ForceCommand\" feature, where a fixed command is executed when the user logs in, instead of just running an unrestricted command shell. The fixed command is executed even if the user specified that another command should be run; in that case the original command is put into the environment variable \"SSH_ORIGINAL_COMMAND\". When the forced command is run in a Bash shell (if the user's shell is set to Bash), the Bash shell will parse the SSH_ORIGINAL_COMMAND environment variable on start-up, and run the commands embedded in it. The user has used their restricted shell access to gain unrestricted shell access, using the Shellshock bug.\nDHCP clients\nSome DHCP clients can also pass commands to Bash; a vulnerable system could be attacked when connecting to an open Wi-Fi network. A DHCP client typically requests and gets an IP address from a DHCP server, but it can also be provided a series of additional options. A malicious DHCP server could provide, in one of these options, a string crafted to execute code on a vulnerable workstation or laptop.\nQmail server\nWhen using Bash to process email messages (e.g. through .forward or qmail-alias piping), the qmail mail server passes external input through in a way that can exploit a vulnerable version of Bash.\nIBM HMC restricted shell\nThe bug can be exploited to gain access to Bash from the restricted shell of the IBM Hardware Management Console, a tiny Linux variant for system administrators. IBM released a patch to resolve this.\n\n== Reported vulnerabilities ==\n\n\n*** Overview ***\nThe maintainer of Bash was warned about the first discovery of the bug on 2014-09-12; a fix followed soon. A few companies and distributors were informed before the matter was publicly disclosed on 2014-09-24 with CVE identifier CVE-2014-6271. However, after the release of the patch there were subsequent reports of different, yet related vulnerabilities.On 26 September 2014, two open-source contributors, David A. Wheeler and Norihiro Tanaka, noted that there were additional issues, even after patching systems using the most recently available patches.  In an email addressed to the oss-sec and bash-bug mailing lists, Wheeler wrote: \"This patch just continues the 'whack-a-mole' job of fixing parsing errors that began with the first patch. Bash's parser is certain [to] have many many many other vulnerabilities\".On 27 September 2014, Micha\u0142 Zalewski from Google Inc. announced his discovery of other Bash vulnerabilities, one based upon the fact that Bash is typically compiled without address space layout randomization. On 1 October, Zalewski released details of the final bugs and confirmed that a patch by Florian Weimer from Red Hat posted on 25 September does indeed prevent them. He has done that using a fuzzing technique with the aid of software utility known as american fuzzy lop.\n\n\n*** Initial report (CVE-2014-6271) ***\nThis original form of the vulnerability (CVE-2014-6271) involves a specially crafted environment variable containing an exported function definition, followed by arbitrary commands. Bash incorrectly executes the trailing commands when it imports the function. The vulnerability can be tested with the following command:\n\nIn systems affected by the vulnerability, the above commands will display the word \"vulnerable\" as a result of Bash executing the command \"echo vulnerable\", which was embedded into the specially crafted environment variable named \"x\".\n\n\n*** CVE-2014-6277 ***\nDiscovered by Micha\u0142 Zalewski, the vulnerability CVE-2014-6277, which relates to the parsing of function definitions in environment variables by Bash, can cause a segfault.\n\n\n*** CVE-2014-6278 ***\nAlso discovered by Micha\u0142 Zalewski, this bug (CVE-2014-6278) relates to the parsing of function definitions in environment variables by Bash.\n\n\n*** CVE-2014-7169 ***\nOn the same day the original vulnerability was published, Tavis Ormandy discovered this related bug (CVE-2014-7169), which is\ndemonstrated in the following code:\n\nOn a vulnerable system, this would execute the command \"date\" unintentionally.Here is an example of a system that has a patch for CVE-2014-6271 but not CVE-2014-7169:\n\nThe system displays syntax errors, notifying the user that CVE-2014-6271 has been prevented, but still writes a file named 'echo', into the working directory, containing the result of the 'date' call.\nA system patched for both CVE-2014-6271 and CVE-2014-7169 will simply echo the word \"date\" and the file \"echo\" will not be created, as shown below:\n\n\n*** CVE-2014-7186 ***\nFlorian Weimer and Todd Sabin found this bug (CVE-2014-7186), which relates to an out-of-bounds memory access error in the Bash parser code.An example of the vulnerability, which leverages the use of multiple \"<<EOF\" declarations (nested \"here documents\"):\n\nA vulnerable system will echo the text \"CVE-2014-7186 vulnerable, redir_stack\".\n\n\n*** CVE-2014-7187 ***\nAlso found by Florian Weimer, CVE-2014-7187 is an off-by-one error in the Bash parser code, allowing out-of-bounds memory access.An example of the vulnerability, which leverages the use of multiple \"done\" declarations:\n\nA vulnerable system will echo the text \"CVE-2014-7187 vulnerable, word_lineno\".  This test requires a shell that supports brace expansion.\n\n== Patches ==\nUntil 24 September 2014, Bash maintainer Chet Ramey provided a patch version bash43-025 of Bash 4.3 addressing CVE-2014-6271, which was already packaged by distribution maintainers. On 24 September, bash43-026 followed, addressing CVE-2014-7169.\nThen CVE-2014-7186 was discovered. Florian Weimer from Red Hat posted some patch code for this \"unofficially\" on 25 September,\nwhich Ramey incorporated into Bash as bash43-027.\u2014These patches provided source code only, helpful only for those who know how to compile (\"rebuild\") a new Bash binary executable file from the patch file and remaining source code files. The patches added a variable name prefix when functions are exported; this prevented arbitrary variables from triggering the vulnerability and enabled other programs to remove Bash functions from the environment.\nThe next day, Red Hat officially presented according updates for Red Hat Enterprise Linux, after another day for Fedora 21.Canonical Ltd. presented updates for its Ubuntu Long Term Support versions on Saturday, 27 September;\non Sunday, there were updates for SUSE Linux Enterprise.\nThe following Monday and Tuesday at the end of the month, Mac OS X updates appeared.On 1 October 2014, Micha\u0142 Zalewski from Google Inc. finally stated that Weimer's code and bash43-027 had fixed not only the first three bugs but even the remaining three that were published after bash43-027, including his own two discoveries. This means that after the earlier distribution updates, no other updates have been required to cover all the six issues.All of them have also been covered for the IBM Hardware Management Console.\n\nHow does the IBM Hardware Management Console (HMC) restricted shell relate to the Shellshock bug and what was the response from IBM?",
    "context": "",
    "output": "The bug can be exploited to gain access to Bash from the restricted shell of the IBM Hardware Management Console, a tiny Linux variant for system administrators. IBM released a patch to resolve this.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the IBM Hardware Management Console (HMC) restricted shell relate to the Shellshock bug and what was the response from IBM?",
      "answer": "The bug can be exploited to gain access to Bash from the restricted shell of the IBM Hardware Management Console, a tiny Linux variant for system administrators. IBM released a patch to resolve this.",
      "context": "Shellshock (software bug)\n\n==Introduction==\nShellshock, also known as Bashdoor, is a family of security bugs in the Unix Bash shell, the first of which was disclosed on 24 September 2014. Shellshock could enable an attacker to cause Bash to execute arbitrary commands and gain unauthorized access to many Internet-facing services, such as web servers, that use Bash to process requests.\nOn 12 September 2014, St\u00e9phane Chazelas informed Bash's maintainer Chet Ramey of his discovery of the original bug, which he called \"Bashdoor\". Working with security experts, Mr. Chazelas developed a patch (fix) for the issue, which by then had been assigned the vulnerability identifier CVE-2014-6271. The existence of the bug was announced to the public on 2014-09-24, when Bash updates with the fix were ready for distribution.The bug Chazelas discovered caused Bash to unintentionally execute commands when the commands are concatenated to the end of function definitions stored in the values of environment variables. Within days of its publication, a variety of related vulnerabilities were discovered (CVE-2014-6277, CVE-2014-6278, CVE-2014-7169, CVE-2014-7186 and CVE-2014-7187). Ramey addressed these with a series of further patches.Attackers exploited Shellshock within hours of the initial disclosure by creating botnets of compromised computers to perform distributed denial-of-service attacks and vulnerability scanning. Security companies recorded millions of attacks and probes related to the bug in the days following the disclosure.Because of the potential to compromise millions of unpatched systems, Shellshock was compared to the Heartbleed bug in its severity.\n\n== Background ==\nThe Shellshock bug affects Bash, a program that various Unix-based systems use to execute command lines and command scripts. It is often installed as the system's default command-line interface. Analysis of the source code history of Bash shows the bug was introduced on 5 August 1989, and released in Bash version 1.03 on 1 September 1989.Shellshock is an arbitrary code execution vulnerability that offers a way for users of a system to execute commands that should be unavailable to them. This happens through Bash's \"function export\" feature, whereby one Bash process can share command scripts with other Bash processes that it executes. This feature is implemented by encoding the scripts in a table that is shared between the processes, known as the environment variable list. Each new Bash process scans this table for encoded scripts, assembles each one into a command that defines that script in the new process, and executes that command. The new process assumes that the scripts found in the list come from another Bash process, but it cannot verify this, nor can it verify that the command that it has built is a properly formed script definition. Therefore, an attacker can execute arbitrary commands on the system or exploit other bugs that may exist in Bash's command interpreter, if the attacker has a way to manipulate the environment variable list and then cause Bash to run. At the time the bug was discovered, Bash was installed on macOS and many Linux operating systems as the main command interpreter, so that any program that used the system function to run any other program would use Bash to do so.\nThe presence of the bug was announced to the public on 2014-09-24, when Bash updates with the fix were ready for distribution, though it took some time for computers to be updated to close the potential security issue.\n\n== Reports of attacks ==\nWithin an hour of the announcement of the Bash vulnerability, there were reports of machines being compromised by the bug. By 25 September 2014, botnets based on computers compromised with exploits based on the bug were being used by attackers for distributed denial-of-service (DDoS) attacks and vulnerability scanning. Kaspersky Labs reported that machines compromised in an attack, dubbed \"Thanks-Rob\", were conducting DDoS attacks against three targets, which they did not identify. On 26 September 2014, a Shellshock-related botnet dubbed \"wopbot\" was reported, which was being used for a DDoS attack against Akamai Technologies and to scan the United States Department of Defense.On 26 September, the security firm Incapsula noted 17,400 attacks on more than 1,800 web domains, originating from 400 unique IP addresses, in the previous 24 hours; 55% of the attacks were coming from China and the United States. By 30 September, the website performance firm CloudFlare said it was tracking approximately 1.5 million attacks and probes per day related to the bug.On 6 October, it was widely reported that Yahoo! servers had been compromised in an attack related to the Shellshock issue.\nYet the next day, it was denied that it had been Shellshock that specifically had allowed these attacks.\n\n== Specific exploitation vectors ==\nCGI-based web server\nWhen a web server uses the Common Gateway Interface (CGI) to handle a document request, it copies certain information from the request into the environment variable list and then delegates the request to a handler program. If the handler is a Bash script, or if it executes Bash, then Bash will receive the environment variables passed by the server and will process them as described above. This provides a means for an attacker to trigger the Shellshock vulnerability with a specially crafted document request.\nSecurity documentation for the widely used Apache web server states: \"CGI scripts can ... be extremely dangerous if they are not carefully checked,\" and other methods of handling web server requests are typically used instead. There are a number of online services which attempt to test the vulnerability against web servers exposed to the Internet.\nOpenSSH server\nOpenSSH has a \"ForceCommand\" feature, where a fixed command is executed when the user logs in, instead of just running an unrestricted command shell. The fixed command is executed even if the user specified that another command should be run; in that case the original command is put into the environment variable \"SSH_ORIGINAL_COMMAND\". When the forced command is run in a Bash shell (if the user's shell is set to Bash), the Bash shell will parse the SSH_ORIGINAL_COMMAND environment variable on start-up, and run the commands embedded in it. The user has used their restricted shell access to gain unrestricted shell access, using the Shellshock bug.\nDHCP clients\nSome DHCP clients can also pass commands to Bash; a vulnerable system could be attacked when connecting to an open Wi-Fi network. A DHCP client typically requests and gets an IP address from a DHCP server, but it can also be provided a series of additional options. A malicious DHCP server could provide, in one of these options, a string crafted to execute code on a vulnerable workstation or laptop.\nQmail server\nWhen using Bash to process email messages (e.g. through .forward or qmail-alias piping), the qmail mail server passes external input through in a way that can exploit a vulnerable version of Bash.\nIBM HMC restricted shell\nThe bug can be exploited to gain access to Bash from the restricted shell of the IBM Hardware Management Console, a tiny Linux variant for system administrators. IBM released a patch to resolve this.\n\n== Reported vulnerabilities ==\n\n\n*** Overview ***\nThe maintainer of Bash was warned about the first discovery of the bug on 2014-09-12; a fix followed soon. A few companies and distributors were informed before the matter was publicly disclosed on 2014-09-24 with CVE identifier CVE-2014-6271. However, after the release of the patch there were subsequent reports of different, yet related vulnerabilities.On 26 September 2014, two open-source contributors, David A. Wheeler and Norihiro Tanaka, noted that there were additional issues, even after patching systems using the most recently available patches.  In an email addressed to the oss-sec and bash-bug mailing lists, Wheeler wrote: \"This patch just continues the 'whack-a-mole' job of fixing parsing errors that began with the first patch. Bash's parser is certain [to] have many many many other vulnerabilities\".On 27 September 2014, Micha\u0142 Zalewski from Google Inc. announced his discovery of other Bash vulnerabilities, one based upon the fact that Bash is typically compiled without address space layout randomization. On 1 October, Zalewski released details of the final bugs and confirmed that a patch by Florian Weimer from Red Hat posted on 25 September does indeed prevent them. He has done that using a fuzzing technique with the aid of software utility known as american fuzzy lop.\n\n\n*** Initial report (CVE-2014-6271) ***\nThis original form of the vulnerability (CVE-2014-6271) involves a specially crafted environment variable containing an exported function definition, followed by arbitrary commands. Bash incorrectly executes the trailing commands when it imports the function. The vulnerability can be tested with the following command:\n\nIn systems affected by the vulnerability, the above commands will display the word \"vulnerable\" as a result of Bash executing the command \"echo vulnerable\", which was embedded into the specially crafted environment variable named \"x\".\n\n\n*** CVE-2014-6277 ***\nDiscovered by Micha\u0142 Zalewski, the vulnerability CVE-2014-6277, which relates to the parsing of function definitions in environment variables by Bash, can cause a segfault.\n\n\n*** CVE-2014-6278 ***\nAlso discovered by Micha\u0142 Zalewski, this bug (CVE-2014-6278) relates to the parsing of function definitions in environment variables by Bash.\n\n\n*** CVE-2014-7169 ***\nOn the same day the original vulnerability was published, Tavis Ormandy discovered this related bug (CVE-2014-7169), which is\ndemonstrated in the following code:\n\nOn a vulnerable system, this would execute the command \"date\" unintentionally.Here is an example of a system that has a patch for CVE-2014-6271 but not CVE-2014-7169:\n\nThe system displays syntax errors, notifying the user that CVE-2014-6271 has been prevented, but still writes a file named 'echo', into the working directory, containing the result of the 'date' call.\nA system patched for both CVE-2014-6271 and CVE-2014-7169 will simply echo the word \"date\" and the file \"echo\" will not be created, as shown below:\n\n\n*** CVE-2014-7186 ***\nFlorian Weimer and Todd Sabin found this bug (CVE-2014-7186), which relates to an out-of-bounds memory access error in the Bash parser code.An example of the vulnerability, which leverages the use of multiple \"<<EOF\" declarations (nested \"here documents\"):\n\nA vulnerable system will echo the text \"CVE-2014-7186 vulnerable, redir_stack\".\n\n\n*** CVE-2014-7187 ***\nAlso found by Florian Weimer, CVE-2014-7187 is an off-by-one error in the Bash parser code, allowing out-of-bounds memory access.An example of the vulnerability, which leverages the use of multiple \"done\" declarations:\n\nA vulnerable system will echo the text \"CVE-2014-7187 vulnerable, word_lineno\".  This test requires a shell that supports brace expansion.\n\n== Patches ==\nUntil 24 September 2014, Bash maintainer Chet Ramey provided a patch version bash43-025 of Bash 4.3 addressing CVE-2014-6271, which was already packaged by distribution maintainers. On 24 September, bash43-026 followed, addressing CVE-2014-7169.\nThen CVE-2014-7186 was discovered. Florian Weimer from Red Hat posted some patch code for this \"unofficially\" on 25 September,\nwhich Ramey incorporated into Bash as bash43-027.\u2014These patches provided source code only, helpful only for those who know how to compile (\"rebuild\") a new Bash binary executable file from the patch file and remaining source code files. The patches added a variable name prefix when functions are exported; this prevented arbitrary variables from triggering the vulnerability and enabled other programs to remove Bash functions from the environment.\nThe next day, Red Hat officially presented according updates for Red Hat Enterprise Linux, after another day for Fedora 21.Canonical Ltd. presented updates for its Ubuntu Long Term Support versions on Saturday, 27 September;\non Sunday, there were updates for SUSE Linux Enterprise.\nThe following Monday and Tuesday at the end of the month, Mac OS X updates appeared.On 1 October 2014, Micha\u0142 Zalewski from Google Inc. finally stated that Weimer's code and bash43-027 had fixed not only the first three bugs but even the remaining three that were published after bash43-027, including his own two discoveries. This means that after the earlier distribution updates, no other updates have been required to cover all the six issues.All of them have also been covered for the IBM Hardware Management Console."
    }
  },
  {
    "instruction": "Write an answer to the following question: How is heap feng shui used in capture the flag events?",
    "context": "",
    "output": "In capture the flag events, heap feng shui is used to describe attacks that exploit characteristics of heap layout, such as the spacing between chunks.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How is heap feng shui used in capture the flag events?",
      "answer": "In capture the flag events, heap feng shui is used to describe attacks that exploit characteristics of heap layout, such as the spacing between chunks."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the purpose of the Practitioner Guide in the Risk IT framework?",
    "context": "",
    "output": "The Practitioner Guide in the Risk IT framework provides guidance on defining a risk universe and scoping risk management, risk appetite and risk tolerance, risk awareness, communication and reporting, expressing and describing risk, risk scenarios, risk response and prioritisation, a risk analysis workflow, and mitigation of IT risk using COBIT and Val IT.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the purpose of the Practitioner Guide in the Risk IT framework?",
      "answer": "The Practitioner Guide in the Risk IT framework provides guidance on defining a risk universe and scoping risk management, risk appetite and risk tolerance, risk awareness, communication and reporting, expressing and describing risk, risk scenarios, risk response and prioritisation, a risk analysis workflow, and mitigation of IT risk using COBIT and Val IT."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the concept of differential equations of addition (DEA) in cryptography?",
    "context": "",
    "output": "DEA in cryptography refers to a type of equation that deals with additions over two different groups, such as addition modulo 2^32 and addition over GF(2), where input and output differences are expressed as XORs.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the concept of differential equations of addition (DEA) in cryptography?",
      "answer": "DEA in cryptography refers to a type of equation that deals with additions over two different groups, such as addition modulo 2^32 and addition over GF(2), where input and output differences are expressed as XORs."
    }
  },
  {
    "instruction": "Write an answer to the following question: Can the range of the GateKeeper device's presence detection be configured?",
    "context": "",
    "output": "Yes, the range at which the computer detects the device's presence can be set through the GateKeeper software dashboard.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Can the range of the GateKeeper device's presence detection be configured?",
      "answer": "Yes, the range at which the computer detects the device's presence can be set through the GateKeeper software dashboard."
    }
  },
  {
    "instruction": "Context: Information technology security assessment\n\n==Introduction==\nInformation Technology Security Assessment (IT Security Assessment) is an explicit study to locate IT security vulnerabilities and risks.\n\n== Background ==\nIn an assessment, the assessor should have the full cooperation of the organization being assessed. The organization grants access to its facilities, provides network access, outlines detailed information about the network, etc. All parties understand that the goal is to study security and identify improvements to secure the systems. An assessment for security is potentially the most useful of all security tests.\n\n== Purpose of security assessment ==\nThe goal of a security assessment (also known as a security audit, security review, or network assessment), is\nto ensure that necessary security controls are integrated into the design and implementation of a project. A properly completed security assessment should provide documentation outlining any security gaps between a project design and approved corporate security policies. Management can address security gaps in three ways:\nManagement can decide to cancel the project, allocate the necessary resources to correct\nthe security gaps, or accept the risk based on an informed risk / reward analysis.\n\n== Methodology ==\nThe following methodology outline is put forward as the effective means in conducting security assessment.\n\nRequirement Study and Situation Analysis\nSecurity policy creation and update\nDocument Review\nRisk Analysis\nVulnerability Scan\nData Analysis\nReport & Briefing\n\n== Sample report ==\nA security assessment report should include the following information:\n\nIntroduction/background information\nExecutive and Management summary\nAssessment scope and objectives\nAssumptions and limitations\nMethods and assessment tools used\nCurrent environment or system description with network diagrams, if any\nSecurity requirements\nSummary of findings and recommendations\nThe general control review result\nThe vulnerability test results\nRisk assessment results including identified assets, threats, vulnerabilities, impact and likelihood assessment, and the risk results analysis\nRecommended safeguards\n\n== Criticisms and shortcomings ==\nIT security risk assessments like many risk assessments in IT, are not actually quantitative and do not represent risk in any actuarially-sound manner.  Measuring risk quantitatively can have a significant impact on prioritizing risks and getting investment approval.Quantitative risk analysis has been applied to IT security in a major US government study in 2000.  The Federal CIO Council commissioned a study of the $100 million IT security investment for the Department of Veterans Affairs with results shown quantitatively.[1] United States Department of Veterans Affairs\n\n== Professional certifications ==\nThere are common vendor-neutral professional certifications for performing security assessment.\n\nCISSP\nCCSP\nCISM\nCISA\nISO/IEC 27001:2013 Auditor/Lead Auditor\nCRISC\nQSA/ISA\n\n== Automated Security Assessment Tools ==\nThere are common tools for automatic security assessment for self/third party usage.\n\nFindings\nPanorays\nRapidFire Tools\nBeyond Security\nVeracode\nRiskWatch\nSolarWinds\nAnswer this question: What is the role of assumptions and limitations in a security assessment report?",
    "context": "",
    "output": "Assumptions and limitations provide context and clarity for the security assessment report, outlining any factors that may have impacted the assessment or the interpretation of the results.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of assumptions and limitations in a security assessment report?",
      "answer": "Assumptions and limitations provide context and clarity for the security assessment report, outlining any factors that may have impacted the assessment or the interpretation of the results.",
      "context": "Information technology security assessment\n\n==Introduction==\nInformation Technology Security Assessment (IT Security Assessment) is an explicit study to locate IT security vulnerabilities and risks.\n\n== Background ==\nIn an assessment, the assessor should have the full cooperation of the organization being assessed. The organization grants access to its facilities, provides network access, outlines detailed information about the network, etc. All parties understand that the goal is to study security and identify improvements to secure the systems. An assessment for security is potentially the most useful of all security tests.\n\n== Purpose of security assessment ==\nThe goal of a security assessment (also known as a security audit, security review, or network assessment), is\nto ensure that necessary security controls are integrated into the design and implementation of a project. A properly completed security assessment should provide documentation outlining any security gaps between a project design and approved corporate security policies. Management can address security gaps in three ways:\nManagement can decide to cancel the project, allocate the necessary resources to correct\nthe security gaps, or accept the risk based on an informed risk / reward analysis.\n\n== Methodology ==\nThe following methodology outline is put forward as the effective means in conducting security assessment.\n\nRequirement Study and Situation Analysis\nSecurity policy creation and update\nDocument Review\nRisk Analysis\nVulnerability Scan\nData Analysis\nReport & Briefing\n\n== Sample report ==\nA security assessment report should include the following information:\n\nIntroduction/background information\nExecutive and Management summary\nAssessment scope and objectives\nAssumptions and limitations\nMethods and assessment tools used\nCurrent environment or system description with network diagrams, if any\nSecurity requirements\nSummary of findings and recommendations\nThe general control review result\nThe vulnerability test results\nRisk assessment results including identified assets, threats, vulnerabilities, impact and likelihood assessment, and the risk results analysis\nRecommended safeguards\n\n== Criticisms and shortcomings ==\nIT security risk assessments like many risk assessments in IT, are not actually quantitative and do not represent risk in any actuarially-sound manner.  Measuring risk quantitatively can have a significant impact on prioritizing risks and getting investment approval.Quantitative risk analysis has been applied to IT security in a major US government study in 2000.  The Federal CIO Council commissioned a study of the $100 million IT security investment for the Department of Veterans Affairs with results shown quantitatively.[1] United States Department of Veterans Affairs\n\n== Professional certifications ==\nThere are common vendor-neutral professional certifications for performing security assessment.\n\nCISSP\nCCSP\nCISM\nCISA\nISO/IEC 27001:2013 Auditor/Lead Auditor\nCRISC\nQSA/ISA\n\n== Automated Security Assessment Tools ==\nThere are common tools for automatic security assessment for self/third party usage.\n\nFindings\nPanorays\nRapidFire Tools\nBeyond Security\nVeracode\nRiskWatch\nSolarWinds"
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the hash function used by AKA?",
    "context": "",
    "output": "AKA uses the SHA-1 hash function.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the hash function used by AKA?",
      "answer": "AKA uses the SHA-1 hash function."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are some of the topics covered in the documentary film series, besides the Nigerian 419 scam?",
    "context": "",
    "output": "The documentary film series covers various topics related to hacking, including malware, site scraping, spear phishing, botnets, and DDOS attacks, as well as online safety education and safe shopping.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are some of the topics covered in the documentary film series, besides the Nigerian 419 scam?",
      "answer": "The documentary film series covers various topics related to hacking, including malware, site scraping, spear phishing, botnets, and DDOS attacks, as well as online safety education and safe shopping."
    }
  },
  {
    "instruction": "Write an answer to the following question: How can fuzzing help in demonstrating the presence of bugs in software programs?",
    "context": "",
    "output": "Fuzzing is used to demonstrate the presence of bugs in software programs by executing a large number of inputs and detecting exceptions such as crashes, memory leaks, or undefined behavior.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can fuzzing help in demonstrating the presence of bugs in software programs?",
      "answer": "Fuzzing is used to demonstrate the presence of bugs in software programs by executing a large number of inputs and detecting exceptions such as crashes, memory leaks, or undefined behavior."
    }
  },
  {
    "instruction": "Arptables\n\n==Introduction==\nThe arptables computer software utility is a network administrator's tool for maintaining the Address Resolution Protocol (ARP) packet filter rules in the Linux kernel firewall modules.\nThe tools may be used to create, update, and view the tables that contain the filtering rules, similarly to the iptables program from which it was developed. A popular application is the creation of filter configurations to prevent ARP spoofing.\nLinux kernel 2.4 only offers two ARP filtering chains, INPUT and OUTPUT, and Linux kernel 2.6 adds the third, FORWARD, applied when bridging packets.\n\n\nQuestion: How many ARP filtering chains are available in Linux kernel 2.4 and what are they used for?",
    "context": "",
    "output": "Answer: Linux kernel 2.4 offers two ARP filtering chains, INPUT and OUTPUT. The INPUT chain is used to filter incoming ARP packets, and the OUTPUT chain is used to filter outgoing ARP packets.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How many ARP filtering chains are available in Linux kernel 2.4 and what are they used for?",
      "answer": "Linux kernel 2.4 offers two ARP filtering chains, INPUT and OUTPUT. The INPUT chain is used to filter incoming ARP packets, and the OUTPUT chain is used to filter outgoing ARP packets.",
      "context": "Arptables\n\n==Introduction==\nThe arptables computer software utility is a network administrator's tool for maintaining the Address Resolution Protocol (ARP) packet filter rules in the Linux kernel firewall modules.\nThe tools may be used to create, update, and view the tables that contain the filtering rules, similarly to the iptables program from which it was developed. A popular application is the creation of filter configurations to prevent ARP spoofing.\nLinux kernel 2.4 only offers two ARP filtering chains, INPUT and OUTPUT, and Linux kernel 2.6 adds the third, FORWARD, applied when bridging packets.\n\n"
    }
  },
  {
    "instruction": "Write an answer to the following question: Can Adaptive Redaction be used to remove sensitive information from documents being copied to removable media?",
    "context": "",
    "output": "Yes, Adaptive Redaction can be used to remove sensitive information from documents being copied to removable media, as well as from emails and web communication.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Can Adaptive Redaction be used to remove sensitive information from documents being copied to removable media?",
      "answer": "Yes, Adaptive Redaction can be used to remove sensitive information from documents being copied to removable media, as well as from emails and web communication."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is obfuscation and how can it be used to protect users online?",
    "context": "",
    "output": "Obfuscation is the automated generation of \"fake\" signals that are indistinguishable from users' actual online activities, providing a noisy \"cover\" under which their real information and communication behavior remains unobservable. It can be used to protect users online by making it more difficult for third parties to distinguish between user-generated and computer-generated queries and other activities.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is obfuscation and how can it be used to protect users online?",
      "answer": "Obfuscation is the automated generation of \"fake\" signals that are indistinguishable from users' actual online activities, providing a noisy \"cover\" under which their real information and communication behavior remains unobservable. It can be used to protect users online by making it more difficult for third parties to distinguish between user-generated and computer-generated queries and other activities."
    }
  },
  {
    "instruction": "Write an answer to the following question: What were the primary large-scale computer crimes of the era in the 1990s?",
    "context": "",
    "output": "The primary large-scale computer crimes of the era in the 1990s were producing and distributing pirated software and movies.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What were the primary large-scale computer crimes of the era in the 1990s?",
      "answer": "The primary large-scale computer crimes of the era in the 1990s were producing and distributing pirated software and movies."
    }
  },
  {
    "instruction": "Tor Mail\n\n==Introduction==\nTor Mail was a Tor hidden service that went offline in August 2013 after an FBI raid on Freedom Hosting. The service allowed users to send and receive email anonymously to email addresses inside and outside the Tor network.\n\n\n\nWhat was the significance of Tor Mail's relationship with Freedom Hosting, and how did this connection impact the service's security and anonymity?",
    "context": "",
    "output": "Tor Mail relied on Freedom Hosting, a popular provider of hidden services on the Tor network, for hosting its platform. When Freedom Hosting was raided by the FBI in August 2013, Tor Mail went offline, impacting the security and anonymity of its users. This incident underscores the vulnerabilities that can arise from dependence on a single hosting provider in the context of maintaining user anonymity and security in a hidden service like Tor Mail.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was the significance of Tor Mail's relationship with Freedom Hosting, and how did this connection impact the service's security and anonymity?",
      "answer": "Tor Mail relied on Freedom Hosting, a popular provider of hidden services on the Tor network, for hosting its platform. When Freedom Hosting was raided by the FBI in August 2013, Tor Mail went offline, impacting the security and anonymity of its users. This incident underscores the vulnerabilities that can arise from dependence on a single hosting provider in the context of maintaining user anonymity and security in a hidden service like Tor Mail.",
      "context": "Tor Mail\n\n==Introduction==\nTor Mail was a Tor hidden service that went offline in August 2013 after an FBI raid on Freedom Hosting. The service allowed users to send and receive email anonymously to email addresses inside and outside the Tor network.\n\n"
    }
  },
  {
    "instruction": "Write an answer to the following question: How do IRC bots contribute to the distribution of warez?",
    "context": "",
    "output": "IRC bots provide file sharing directly by themselves or alongside the FTP service. These bots regulate access to the illicit data by using file queues to limit bandwidth usage or by only running during off-hours overnight when the business owning the compromised hardware is closed for the day.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do IRC bots contribute to the distribution of warez?",
      "answer": "IRC bots provide file sharing directly by themselves or alongside the FTP service. These bots regulate access to the illicit data by using file queues to limit bandwidth usage or by only running during off-hours overnight when the business owning the compromised hardware is closed for the day."
    }
  },
  {
    "instruction": "Write an answer to the following question: How many possible ring settings are there in the Enigma machine?",
    "context": "",
    "output": "There are 26^3 = 17,576 possible ring settings in the Enigma machine, as each of the three rotors can be set to one of 26 possible positions.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How many possible ring settings are there in the Enigma machine?",
      "answer": "There are 26^3 = 17,576 possible ring settings in the Enigma machine, as each of the three rotors can be set to one of 26 possible positions."
    }
  },
  {
    "instruction": "Non-repudiation\n\n==Introduction==\nIn law, non-repudiation is a situation where a statement's author cannot successfully dispute its authorship or the validity of an associated contract. The term is often seen in a legal setting when the authenticity of a signature is being challenged. In such an instance, the authenticity is being \"repudiated\".For example, Mallory buys a cell phone for $100, writes a paper cheque as payment, and signs the cheque with a pen.  Later, she finds that she can't afford it, and claims that the cheque is a forgery.  The signature guarantees that only Mallory could have signed the cheque, and so Mallory's bank must pay the cheque.  This is non-repudiation; Mallory cannot repudiate the cheque. In practice, pen-and-paper signatures aren't hard to forge, but digital signatures can be very hard to break.\n\n\n\n== In security ==\nIn general, non-repudiation involves associating actions or changes with a unique individual. For example, a secure area may use a key card access system where non-repudiation would be violated if key cards were shared or if lost and stolen cards were not immediately reported. Similarly, the owner of a computer account must not allow others to use it, such as by giving away their password, and a policy should be implemented to enforce this.\n\n\n*** In digital security ***\nIn digital security, non-repudiation means:\nA service that provides proof of the integrity and origin of data.\nAn authentication that can be said to be genuine with high confidence.\nAn authentication that the data is available under specific circumstances, or for a period of time: data availability.Proof of data integrity is typically the easiest of these requirements to accomplish. A data hash such as SHA2 usually ensures that the data will not be changed undetectably. Even with this safeguard, it is possible to tamper with data in transit, either through a man-in-the-middle attack or phishing. Because of this, data integrity is best asserted when the recipient already possesses the necessary verification information, such as after being mutually authenticated.The common method to provide non-repudiation in the context of digital communications or storage is Digital Signatures, a more powerful tool that provides non-repudiation in a publicly verifiable manner. Message Authentication Codes (MAC), useful when the communicating parties have arranged to use a shared secret that they both possess, does not give non-repudiation. A misconception is that encrypting, per se, provides authentication \"If the message decrypts properly then it is authentic\" - Wrong! MAC can be subject to several types of attacks, like: message reordering, block substitution, block repetition, .... Thus just providing message integrity and authentication, but not non-repudiation. To achieve non-repudiation one must trust a service (a certificate generated by a trusted third party (TTP) called certificate authority (CA)) which prevents an entity from denying previous commitments or actions (e.g. sending message A to B). The difference between MAC and Digital Signatures, one uses symmetric keys and the other asymmetric keys (provided by the CA). Note that the goal is not to achieve confidentiality: in both cases (MAC or digital signature), one simply appends a tag to the otherwise plaintext, visible message. If confidentiality is also required, then an encryption scheme can be combined with the digital signature, or some form of authenticated encryption could be used.  Verifying the digital origin means that the certified/signed data likely came from someone who possesses the private key corresponding to the signing certificate. If the key used to digitally sign a message is not properly safeguarded by the original owner, digital forgery can occur.\n\n== Trusted third parties (TTPs) ==\nTo mitigate the risk of people repudiating their own signatures, the standard approach is to involve a trusted third party.The two most common TTPs are forensic analysts and notaries. A forensic analyst specializing in handwriting can compare some signature to a known valid signature and assess its legitimacy. A notary is a witness who verifies an individual's identity by checking other credentials and affixing their certification that the person signing is who they claim to be. A notary provides the extra benefit of maintaining independent logs of their transactions, complete with the types of credentials checked, and another signature that can be verified by the forensic analyst. This double security makes notaries the preferred form of verification.For digital information, the most commonly employed TTP is a certificate authority, which issues public key certificates. A public key certificate can be used by anyone to verify digital signatures without a shared secret between the signer and the verifier. The role of the certificate authority is to authoritatively state to whom the certificate belongs, meaning that this person or entity possesses the corresponding private key. However, a digital signature is forensically identical in both legitimate and forged uses. Someone who possesses the private key can create a valid digital signature. Protecting the private key is the idea behind some smart cards such as the United States Department of Defense's Common Access Card (CAC), which never lets the key leave the card. That means that to use the card for encryption and digital signatures, a person needs the personal identification number (PIN) code necessary to unlock it.\nQ: What is the role of a trusted third party (TTP) in mitigating the risk of people repudiating their own signatures?",
    "context": "",
    "output": "The role of a TTP in mitigating the risk of people repudiating their own signatures is to assess the legitimacy of a signature by comparing it to a known valid signature. The two most common TTPs in this context are forensic analysts and notaries. For digital information, the most commonly employed TTP is a certificate authority, which issues public key certificates and authoritatively states to whom the certificate belongs.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of a trusted third party (TTP) in mitigating the risk of people repudiating their own signatures?",
      "answer": "The role of a TTP in mitigating the risk of people repudiating their own signatures is to assess the legitimacy of a signature by comparing it to a known valid signature. The two most common TTPs in this context are forensic analysts and notaries. For digital information, the most commonly employed TTP is a certificate authority, which issues public key certificates and authoritatively states to whom the certificate belongs.",
      "context": "Non-repudiation\n\n==Introduction==\nIn law, non-repudiation is a situation where a statement's author cannot successfully dispute its authorship or the validity of an associated contract. The term is often seen in a legal setting when the authenticity of a signature is being challenged. In such an instance, the authenticity is being \"repudiated\".For example, Mallory buys a cell phone for $100, writes a paper cheque as payment, and signs the cheque with a pen.  Later, she finds that she can't afford it, and claims that the cheque is a forgery.  The signature guarantees that only Mallory could have signed the cheque, and so Mallory's bank must pay the cheque.  This is non-repudiation; Mallory cannot repudiate the cheque. In practice, pen-and-paper signatures aren't hard to forge, but digital signatures can be very hard to break.\n\n\n\n== In security ==\nIn general, non-repudiation involves associating actions or changes with a unique individual. For example, a secure area may use a key card access system where non-repudiation would be violated if key cards were shared or if lost and stolen cards were not immediately reported. Similarly, the owner of a computer account must not allow others to use it, such as by giving away their password, and a policy should be implemented to enforce this.\n\n\n*** In digital security ***\nIn digital security, non-repudiation means:\nA service that provides proof of the integrity and origin of data.\nAn authentication that can be said to be genuine with high confidence.\nAn authentication that the data is available under specific circumstances, or for a period of time: data availability.Proof of data integrity is typically the easiest of these requirements to accomplish. A data hash such as SHA2 usually ensures that the data will not be changed undetectably. Even with this safeguard, it is possible to tamper with data in transit, either through a man-in-the-middle attack or phishing. Because of this, data integrity is best asserted when the recipient already possesses the necessary verification information, such as after being mutually authenticated.The common method to provide non-repudiation in the context of digital communications or storage is Digital Signatures, a more powerful tool that provides non-repudiation in a publicly verifiable manner. Message Authentication Codes (MAC), useful when the communicating parties have arranged to use a shared secret that they both possess, does not give non-repudiation. A misconception is that encrypting, per se, provides authentication \"If the message decrypts properly then it is authentic\" - Wrong! MAC can be subject to several types of attacks, like: message reordering, block substitution, block repetition, .... Thus just providing message integrity and authentication, but not non-repudiation. To achieve non-repudiation one must trust a service (a certificate generated by a trusted third party (TTP) called certificate authority (CA)) which prevents an entity from denying previous commitments or actions (e.g. sending message A to B). The difference between MAC and Digital Signatures, one uses symmetric keys and the other asymmetric keys (provided by the CA). Note that the goal is not to achieve confidentiality: in both cases (MAC or digital signature), one simply appends a tag to the otherwise plaintext, visible message. If confidentiality is also required, then an encryption scheme can be combined with the digital signature, or some form of authenticated encryption could be used.  Verifying the digital origin means that the certified/signed data likely came from someone who possesses the private key corresponding to the signing certificate. If the key used to digitally sign a message is not properly safeguarded by the original owner, digital forgery can occur.\n\n== Trusted third parties (TTPs) ==\nTo mitigate the risk of people repudiating their own signatures, the standard approach is to involve a trusted third party.The two most common TTPs are forensic analysts and notaries. A forensic analyst specializing in handwriting can compare some signature to a known valid signature and assess its legitimacy. A notary is a witness who verifies an individual's identity by checking other credentials and affixing their certification that the person signing is who they claim to be. A notary provides the extra benefit of maintaining independent logs of their transactions, complete with the types of credentials checked, and another signature that can be verified by the forensic analyst. This double security makes notaries the preferred form of verification.For digital information, the most commonly employed TTP is a certificate authority, which issues public key certificates. A public key certificate can be used by anyone to verify digital signatures without a shared secret between the signer and the verifier. The role of the certificate authority is to authoritatively state to whom the certificate belongs, meaning that this person or entity possesses the corresponding private key. However, a digital signature is forensically identical in both legitimate and forged uses. Someone who possesses the private key can create a valid digital signature. Protecting the private key is the idea behind some smart cards such as the United States Department of Defense's Common Access Card (CAC), which never lets the key leave the card. That means that to use the card for encryption and digital signatures, a person needs the personal identification number (PIN) code necessary to unlock it."
    }
  },
  {
    "instruction": "Write an answer to the following question: Can an ISP's mail server solve the reverse DNS problem?",
    "context": "",
    "output": "Yes, using an ISP's mail server as a relay can solve the reverse DNS problem because the forward and reverse lookup for the sending relay have to match, it does not have to be related to the from-field or sending domain of messages it relays.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Can an ISP's mail server solve the reverse DNS problem?",
      "answer": "Yes, using an ISP's mail server as a relay can solve the reverse DNS problem because the forward and reverse lookup for the sending relay have to match, it does not have to be related to the from-field or sending domain of messages it relays."
    }
  },
  {
    "instruction": "Zero-day (computing)\n\n==Introduction==\nA zero-day (also known as a 0-day) is a computer-software vulnerability previously unknown to those who should be interested in its mitigation, like the vendor of the target software. Until the vulnerability is mitigated, hackers can exploit it to adversely affect programs, data, additional computers or a network. An exploit taking advantage of a zero-day is called a zero-day exploit, or zero-day attack.\nThe term \"zero-day\" originally referred to the number of days since a new piece of software was released to the public, so \"zero-day software\" was obtained by hacking into a developer's computer before release. Eventually the term was applied to the vulnerabilities that allowed this hacking, and to the number of days that the vendor has had to fix them. Once the vendors learn of the vulnerability, they will usually create patches or advise workarounds to mitigate it.\nThe more recently that the vendor has become aware of the vulnerability, the more likely it is that no fix or mitigation has been developed. Once a fix is developed, the chance of the exploit succeeding decreases as more users apply the fix over time. For zero-day exploits, unless the vulnerability is inadvertently fixed, such as by an unrelated update that happens to fix the vulnerability, the probability that a user has applied a vendor-supplied patch that fixes the problem is zero, so the exploit would remain available. Zero-day attacks are a severe threat.\n\n\n\n== Attack vectors ==\nPotential attack vectors for a zero-day vulnerability are identical to known vulnerabilities and those that have available patches. For example, when a user visits a rogue website, malicious code on the site can exploit unpatched vulnerabilities in a Web browser. Web browsers are a particular target for criminals because of their widespread distribution and usage. Cybercriminals, as well as international vendors of spyware such as Israel\u2019s NSO Group, can also send malicious e-mail attachments via SMTP, which exploit vulnerabilities in the application opening the attachment. Exploits that take advantage of common file types are numerous and frequent, as evidenced by their increasing appearances in databases such as US-CERT. Criminals can engineer malware to take advantage of these file type exploits to compromise attacked systems or steal confidential data.\n\n== Window of vulnerability ==\nThe time from when a software exploit first becomes active to the time when the number of vulnerable systems shrinks to insignificance is known as the window of vulnerability. The timeline for each software vulnerability is defined by the following main events: \n\nt0: The vulnerability is discovered (by anyone).\nt1a: A security patch is published (e.g., by the software vendor).\nt1b: An exploit becomes active.\nt2: Most vulnerable systems have applied the patch.Thus the formula for the length of the window of vulnerability is: t2 \u2212 t1b.\nIn this formulation, it is always true that t0 \u2264 t1a, and t0 \u2264 t1b. Note that t0 is not the same as day zero. For example, if a hacker is the first to discover (at t0) the vulnerability, the vendor might not learn of it until much later (on day zero).\nFor normal vulnerabilities, t1b > t1a. This implies that the software vendor was aware of the vulnerability and had time to publish a security patch (t1a) before any hacker could craft a workable exploit (t1b). For zero-day exploits, t1b \u2264 t1a, such that the exploit becomes active before a patch is made available.\nBy not disclosing known vulnerabilities, a software vendor hopes to reach t2 before t1b is reached, thus avoiding any exploits. However, the vendor has no guarantees that hackers will not find vulnerabilities on their own. Furthermore, hackers can analyze the security patches themselves, and thereby discover the underlying vulnerabilities and automatically generate working exploits. These exploits can be used effectively up until time t2.\nIn practice, the length of the window of vulnerability varies between systems, vendors, and individual vulnerabilities. It is often measured in days, with one report from 2006 estimating the average as 28 days.\n\n== Protection ==\nZero-day protection is the ability to provide protection against zero-day exploits. Since zero-day attacks are generally unknown to the public, it is often difficult to defend against them. Zero-day attacks are often effective against \"secure\" networks and can remain undetected even after they are launched. Thus, users of so-called secure systems must also exercise common sense and practice safe computing habits.Many techniques exist to limit the effectiveness of zero-day memory corruption vulnerabilities such as buffer overflows. These protection mechanisms exist in contemporary operating systems such as macOS, Windows Vista and beyond (see also: Security and safety features new to Windows Vista), Solaris, Linux, Unix, and Unix-like environments; Windows XP Service Pack 2 includes limited protection against generic memory corruption vulnerabilities and previous versions include even less. Desktop and server protection software also exist to mitigate zero-day buffer overflow vulnerabilities. Typically, these technologies involve heuristic termination analysis in order to stop attacks before they cause any harm.It has been suggested that a solution of this kind may be out of reach because it is algorithmically impossible in the general case to analyze any arbitrary code to determine if it is malicious, as such an analysis reduces to the halting problem over a linear bounded automaton, which is unsolvable. It is, however, unnecessary to address the general case (that is, to sort all programs into the categories of malicious or non-malicious) under most circumstances in order to eliminate a wide range of malicious behaviors. It suffices to recognize the safety of a limited set of programs (e.g., those that can access or modify only a given subset of machine resources) while rejecting both some safe and all unsafe programs. This does require the integrity of those safe programs to be maintained, which may prove difficult in the face of a kernel-level exploit.The Zeroday Emergency Response Team (ZERT) was a group of software engineers who worked to release non-vendor patches for zero-day exploits.\n\n== Worms ==\nZero-day worms take advantage of a surprise attack while they are still unknown to computer security professionals. Recent history shows an increasing rate of worm propagation. Well designed worms can spread very fast with devastating consequences to the Internet and other systems.\n\n== Ethics ==\nDiffering ideologies exist relating to the collection and use of zero-day vulnerability information. Many computer security vendors perform research on zero-day vulnerabilities in order to better understand the nature of vulnerabilities and their exploitation by individuals, computer worms and viruses. Alternatively, some vendors purchase vulnerabilities to augment their research capacity. An example of such a program is TippingPoint's Zero Day Initiative. While selling and buying these vulnerabilities is not technically illegal in most parts of the world, there is a lot of controversy over the method of disclosure. A 2006 German decision to include Article 6 of the Convention on Cybercrime and the EU Framework Decision on Attacks against Information Systems may make selling or even manufacturing vulnerabilities illegal.Most formal programs follow some form of Rain Forest Puppy's disclosure guidelines or the more recent OIS Guidelines for Security Vulnerability Reporting and Response. In general, these rules forbid the public disclosure of vulnerabilities without notification to the vendor and adequate time to produce a patch.\n\n== Viruses ==\nA zero-day virus (also known as zero-day malware or next-generation malware) is a previously unknown computer virus or other malware for which specific antivirus software signatures are not yet available.Traditionally, antivirus software relied upon signatures to identify malware. A virus signature is a unique pattern or code that can be used to detect and identify specific viruses. The antivirus scans file signatures and compares them to a database of known malicious codes. If they match, the file is flagged and treated as a threat. The major limitation of signature-based detection is that it is only capable of flagging already known malware, making it useless against zero-day attacks. Most modern antivirus software still uses signatures but also carries out other types of analysis.\n\n\n*** Code analysis ***\nIn code analysis, the machine code of the file is analysed to see if there is anything that looks suspicious. Typically, malware has characteristic behaviour; code analysis attempts to detect if this is present in the code.\nAlthough useful, code analysis has significant limitations. It is not always easy to determine what a section of code is intended to do, particularly if it is very complex and has been deliberately written with the intention of defeating analysis. Another limitation of code analysis is the time and resources available. In the competitive world of antivirus software, there is always a balance between the effectiveness of analysis and the time delay involved.\nOne approach to overcome the limitations of code analysis is for the antivirus software to run suspect sections of code in a safe sandbox and observe their behavior. This can be orders of magnitude faster than analyzing the same code, but must resist (and detect) attempts by the code to detect the sandbox.\n\n\n*** Generic signatures ***\nGeneric signatures are signatures that are specific to certain behaviour rather than a specific item of malware. Most new malware is not totally novel, but is a variation on earlier malware, or contains code from one or more earlier examples of malware. Thus, the results of previous analysis can be used against new malware.\n\n\n*** Competitiveness in the antivirus software industry ***\nIt is generally accepted in the antivirus industry that most vendors' signature-based protection is identically effective. If a signature is available for an item of malware, then every product (unless dysfunctional) should detect it. However, some vendors are significantly faster than others at becoming aware of new viruses and/or updating their customers' signature databases to detect them.There is a wide range of effectiveness in terms of zero-day virus protection. The German computer magazine c't found that detection rates for zero-day viruses varied from 20% to 68%. It is primarily in the area of zero-day virus performance that manufacturers now compete.\n\n== U.S. government involvement ==\n\n\n*** NSA's use of zero-day exploits (2017) ***\nIn mid-April 2017 the hackers known as The Shadow Brokers (TSB), who are allegedly linked to the Russian government, released files from the NSA (initially just regarded as alleged to be from the NSA, later confirmed through internal details and by American whistleblower Edward Snowden) which include a series of 'zero-day exploits' targeting Microsoft Windows software and a tool to penetrate the Society for Worldwide Interbank Financial Telecommunication (SWIFT)'s service provider. Ars Technica had reported Shadow Brokers' hacking claims in mid-January 2017, and in April the Shadow Brokers posted the exploits as proof.\n\n\n*** Vulnerabilities Equities Process ***\n\nThe Vulnerabilities Equities Process, first revealed publicly in 2016, is a process used by the U.S. federal government to determine on a case-by-case basis how it should treat zero-day computer security vulnerabilities: whether to disclose them to the public to help improve general computer security or to keep them secret for offensive use against the government's adversaries. The process has been criticized for a number of deficiencies, including restriction by non-disclosure agreements, lack of risk ratings, special treatment for the NSA, and a less than full commitment to disclosure as the default option.\nRead the text above and answer this question: How did the term \"zero-day\" come about and what does it originally refer to?",
    "context": "",
    "output": "The term \"zero-day\" originally referred to the number of days since a new piece of software was released to the public. It was used to describe software that was obtained by hacking into a developer's computer before release. Later, the term was applied to the vulnerabilities that allowed this hacking and to the number of days that the vendor has had to fix them.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How did the term \"zero-day\" come about and what does it originally refer to?",
      "answer": "The term \"zero-day\" originally referred to the number of days since a new piece of software was released to the public. It was used to describe software that was obtained by hacking into a developer's computer before release. Later, the term was applied to the vulnerabilities that allowed this hacking and to the number of days that the vendor has had to fix them.",
      "context": "Zero-day (computing)\n\n==Introduction==\nA zero-day (also known as a 0-day) is a computer-software vulnerability previously unknown to those who should be interested in its mitigation, like the vendor of the target software. Until the vulnerability is mitigated, hackers can exploit it to adversely affect programs, data, additional computers or a network. An exploit taking advantage of a zero-day is called a zero-day exploit, or zero-day attack.\nThe term \"zero-day\" originally referred to the number of days since a new piece of software was released to the public, so \"zero-day software\" was obtained by hacking into a developer's computer before release. Eventually the term was applied to the vulnerabilities that allowed this hacking, and to the number of days that the vendor has had to fix them. Once the vendors learn of the vulnerability, they will usually create patches or advise workarounds to mitigate it.\nThe more recently that the vendor has become aware of the vulnerability, the more likely it is that no fix or mitigation has been developed. Once a fix is developed, the chance of the exploit succeeding decreases as more users apply the fix over time. For zero-day exploits, unless the vulnerability is inadvertently fixed, such as by an unrelated update that happens to fix the vulnerability, the probability that a user has applied a vendor-supplied patch that fixes the problem is zero, so the exploit would remain available. Zero-day attacks are a severe threat.\n\n\n\n== Attack vectors ==\nPotential attack vectors for a zero-day vulnerability are identical to known vulnerabilities and those that have available patches. For example, when a user visits a rogue website, malicious code on the site can exploit unpatched vulnerabilities in a Web browser. Web browsers are a particular target for criminals because of their widespread distribution and usage. Cybercriminals, as well as international vendors of spyware such as Israel\u2019s NSO Group, can also send malicious e-mail attachments via SMTP, which exploit vulnerabilities in the application opening the attachment. Exploits that take advantage of common file types are numerous and frequent, as evidenced by their increasing appearances in databases such as US-CERT. Criminals can engineer malware to take advantage of these file type exploits to compromise attacked systems or steal confidential data.\n\n== Window of vulnerability ==\nThe time from when a software exploit first becomes active to the time when the number of vulnerable systems shrinks to insignificance is known as the window of vulnerability. The timeline for each software vulnerability is defined by the following main events: \n\nt0: The vulnerability is discovered (by anyone).\nt1a: A security patch is published (e.g., by the software vendor).\nt1b: An exploit becomes active.\nt2: Most vulnerable systems have applied the patch.Thus the formula for the length of the window of vulnerability is: t2 \u2212 t1b.\nIn this formulation, it is always true that t0 \u2264 t1a, and t0 \u2264 t1b. Note that t0 is not the same as day zero. For example, if a hacker is the first to discover (at t0) the vulnerability, the vendor might not learn of it until much later (on day zero).\nFor normal vulnerabilities, t1b > t1a. This implies that the software vendor was aware of the vulnerability and had time to publish a security patch (t1a) before any hacker could craft a workable exploit (t1b). For zero-day exploits, t1b \u2264 t1a, such that the exploit becomes active before a patch is made available.\nBy not disclosing known vulnerabilities, a software vendor hopes to reach t2 before t1b is reached, thus avoiding any exploits. However, the vendor has no guarantees that hackers will not find vulnerabilities on their own. Furthermore, hackers can analyze the security patches themselves, and thereby discover the underlying vulnerabilities and automatically generate working exploits. These exploits can be used effectively up until time t2.\nIn practice, the length of the window of vulnerability varies between systems, vendors, and individual vulnerabilities. It is often measured in days, with one report from 2006 estimating the average as 28 days.\n\n== Protection ==\nZero-day protection is the ability to provide protection against zero-day exploits. Since zero-day attacks are generally unknown to the public, it is often difficult to defend against them. Zero-day attacks are often effective against \"secure\" networks and can remain undetected even after they are launched. Thus, users of so-called secure systems must also exercise common sense and practice safe computing habits.Many techniques exist to limit the effectiveness of zero-day memory corruption vulnerabilities such as buffer overflows. These protection mechanisms exist in contemporary operating systems such as macOS, Windows Vista and beyond (see also: Security and safety features new to Windows Vista), Solaris, Linux, Unix, and Unix-like environments; Windows XP Service Pack 2 includes limited protection against generic memory corruption vulnerabilities and previous versions include even less. Desktop and server protection software also exist to mitigate zero-day buffer overflow vulnerabilities. Typically, these technologies involve heuristic termination analysis in order to stop attacks before they cause any harm.It has been suggested that a solution of this kind may be out of reach because it is algorithmically impossible in the general case to analyze any arbitrary code to determine if it is malicious, as such an analysis reduces to the halting problem over a linear bounded automaton, which is unsolvable. It is, however, unnecessary to address the general case (that is, to sort all programs into the categories of malicious or non-malicious) under most circumstances in order to eliminate a wide range of malicious behaviors. It suffices to recognize the safety of a limited set of programs (e.g., those that can access or modify only a given subset of machine resources) while rejecting both some safe and all unsafe programs. This does require the integrity of those safe programs to be maintained, which may prove difficult in the face of a kernel-level exploit.The Zeroday Emergency Response Team (ZERT) was a group of software engineers who worked to release non-vendor patches for zero-day exploits.\n\n== Worms ==\nZero-day worms take advantage of a surprise attack while they are still unknown to computer security professionals. Recent history shows an increasing rate of worm propagation. Well designed worms can spread very fast with devastating consequences to the Internet and other systems.\n\n== Ethics ==\nDiffering ideologies exist relating to the collection and use of zero-day vulnerability information. Many computer security vendors perform research on zero-day vulnerabilities in order to better understand the nature of vulnerabilities and their exploitation by individuals, computer worms and viruses. Alternatively, some vendors purchase vulnerabilities to augment their research capacity. An example of such a program is TippingPoint's Zero Day Initiative. While selling and buying these vulnerabilities is not technically illegal in most parts of the world, there is a lot of controversy over the method of disclosure. A 2006 German decision to include Article 6 of the Convention on Cybercrime and the EU Framework Decision on Attacks against Information Systems may make selling or even manufacturing vulnerabilities illegal.Most formal programs follow some form of Rain Forest Puppy's disclosure guidelines or the more recent OIS Guidelines for Security Vulnerability Reporting and Response. In general, these rules forbid the public disclosure of vulnerabilities without notification to the vendor and adequate time to produce a patch.\n\n== Viruses ==\nA zero-day virus (also known as zero-day malware or next-generation malware) is a previously unknown computer virus or other malware for which specific antivirus software signatures are not yet available.Traditionally, antivirus software relied upon signatures to identify malware. A virus signature is a unique pattern or code that can be used to detect and identify specific viruses. The antivirus scans file signatures and compares them to a database of known malicious codes. If they match, the file is flagged and treated as a threat. The major limitation of signature-based detection is that it is only capable of flagging already known malware, making it useless against zero-day attacks. Most modern antivirus software still uses signatures but also carries out other types of analysis.\n\n\n*** Code analysis ***\nIn code analysis, the machine code of the file is analysed to see if there is anything that looks suspicious. Typically, malware has characteristic behaviour; code analysis attempts to detect if this is present in the code.\nAlthough useful, code analysis has significant limitations. It is not always easy to determine what a section of code is intended to do, particularly if it is very complex and has been deliberately written with the intention of defeating analysis. Another limitation of code analysis is the time and resources available. In the competitive world of antivirus software, there is always a balance between the effectiveness of analysis and the time delay involved.\nOne approach to overcome the limitations of code analysis is for the antivirus software to run suspect sections of code in a safe sandbox and observe their behavior. This can be orders of magnitude faster than analyzing the same code, but must resist (and detect) attempts by the code to detect the sandbox.\n\n\n*** Generic signatures ***\nGeneric signatures are signatures that are specific to certain behaviour rather than a specific item of malware. Most new malware is not totally novel, but is a variation on earlier malware, or contains code from one or more earlier examples of malware. Thus, the results of previous analysis can be used against new malware.\n\n\n*** Competitiveness in the antivirus software industry ***\nIt is generally accepted in the antivirus industry that most vendors' signature-based protection is identically effective. If a signature is available for an item of malware, then every product (unless dysfunctional) should detect it. However, some vendors are significantly faster than others at becoming aware of new viruses and/or updating their customers' signature databases to detect them.There is a wide range of effectiveness in terms of zero-day virus protection. The German computer magazine c't found that detection rates for zero-day viruses varied from 20% to 68%. It is primarily in the area of zero-day virus performance that manufacturers now compete.\n\n== U.S. government involvement ==\n\n\n*** NSA's use of zero-day exploits (2017) ***\nIn mid-April 2017 the hackers known as The Shadow Brokers (TSB), who are allegedly linked to the Russian government, released files from the NSA (initially just regarded as alleged to be from the NSA, later confirmed through internal details and by American whistleblower Edward Snowden) which include a series of 'zero-day exploits' targeting Microsoft Windows software and a tool to penetrate the Society for Worldwide Interbank Financial Telecommunication (SWIFT)'s service provider. Ars Technica had reported Shadow Brokers' hacking claims in mid-January 2017, and in April the Shadow Brokers posted the exploits as proof.\n\n\n*** Vulnerabilities Equities Process ***\n\nThe Vulnerabilities Equities Process, first revealed publicly in 2016, is a process used by the U.S. federal government to determine on a case-by-case basis how it should treat zero-day computer security vulnerabilities: whether to disclose them to the public to help improve general computer security or to keep them secret for offensive use against the government's adversaries. The process has been criticized for a number of deficiencies, including restriction by non-disclosure agreements, lack of risk ratings, special treatment for the NSA, and a less than full commitment to disclosure as the default option."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the WG cipher algorithm ensure the security of the encrypted data?",
    "context": "",
    "output": "The WG cipher algorithm ensures the security of the encrypted data by using a secret key and an initialization vector (IV) to generate a unique keystream for each encryption operation. The keystream is combined with the plaintext using the XOR operation to produce the ciphertext. Since the keystream is generated using a pseudorandom process, it is impossible for an attacker to predict it without knowing the secret key and IV. This makes it extremely difficult for an attacker to recover the plaintext from the ciphertext, ensuring the confidentiality and integrity of the encrypted data.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the WG cipher algorithm ensure the security of the encrypted data?",
      "answer": "The WG cipher algorithm ensures the security of the encrypted data by using a secret key and an initialization vector (IV) to generate a unique keystream for each encryption operation. The keystream is combined with the plaintext using the XOR operation to produce the ciphertext. Since the keystream is generated using a pseudorandom process, it is impossible for an attacker to predict it without knowing the secret key and IV. This makes it extremely difficult for an attacker to recover the plaintext from the ciphertext, ensuring the confidentiality and integrity of the encrypted data."
    }
  },
  {
    "instruction": "Write an answer to the following question: Who reversed the magistrate's ruling in the United States District Court for the District of Vermont?",
    "context": "",
    "output": "The ruling of U.S. Magistrate Judge Jerome Niedermeier was reversed by U.S. District Judge William K. Sessions in the United States District Court for the District of Vermont.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Who reversed the magistrate's ruling in the United States District Court for the District of Vermont?",
      "answer": "The ruling of U.S. Magistrate Judge Jerome Niedermeier was reversed by U.S. District Judge William K. Sessions in the United States District Court for the District of Vermont."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the difference between the trust levels provided by the different solutions to the end node problem?",
    "context": "",
    "output": "The trust levels provided by the different solutions to the end node problem depend on the level of control and validation exercised over the end nodes, with the highest level of trust provided by immutable, tamper-resistant clients and the lowest level provided by allowing any hardware to connect with strong user authentication.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the difference between the trust levels provided by the different solutions to the end node problem?",
      "answer": "The trust levels provided by the different solutions to the end node problem depend on the level of control and validation exercised over the end nodes, with the highest level of trust provided by immutable, tamper-resistant clients and the lowest level provided by allowing any hardware to connect with strong user authentication."
    }
  },
  {
    "instruction": "Context: Operation Cyberstorm\n\n==Introduction==\nOperation Cyberstorm was a two-year undercover operation in the United States by the Federal Bureau of Investigation (FBI), against illegal copying of software.  At the time, it was the largest sweep ever conducted by the FBI against illegal copying.\n\n\n\n== Investigations ==\nA number of individuals purchased software at discounts, and resold them at a profit  in violation of their software license.\n\n== Convictions ==\nMirza Ali, 60, of Fremont, California and Sameena Ali, 53, also of Fremont, were sentenced in 2007 to 60 months imprisonment, and forfeiture in the amount of $5,105,977. Keith Griffen, 56, of Oregon City, Oregon, was sentenced to 33 months of imprisonment, restitution to Microsoft Corporation in the amount of $20,000,000, three years of supervised release, and $900 in special assessments. William Glushenko, 66, was sentenced to one year of probation and 100 hours of community service after pleading guilty to misprision of felony.\n\nQuestion: How much restitution did Keith Griffen pay to Microsoft Corporation?\n\nAnswer:",
    "context": "",
    "output": "Keith Griffen paid restitution to Microsoft Corporation in the amount of $20,000,000.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How much restitution did Keith Griffen pay to Microsoft Corporation?",
      "answer": "Keith Griffen paid restitution to Microsoft Corporation in the amount of $20,000,000.",
      "context": "Operation Cyberstorm\n\n==Introduction==\nOperation Cyberstorm was a two-year undercover operation in the United States by the Federal Bureau of Investigation (FBI), against illegal copying of software.  At the time, it was the largest sweep ever conducted by the FBI against illegal copying.\n\n\n\n== Investigations ==\nA number of individuals purchased software at discounts, and resold them at a profit  in violation of their software license.\n\n== Convictions ==\nMirza Ali, 60, of Fremont, California and Sameena Ali, 53, also of Fremont, were sentenced in 2007 to 60 months imprisonment, and forfeiture in the amount of $5,105,977. Keith Griffen, 56, of Oregon City, Oregon, was sentenced to 33 months of imprisonment, restitution to Microsoft Corporation in the amount of $20,000,000, three years of supervised release, and $900 in special assessments. William Glushenko, 66, was sentenced to one year of probation and 100 hours of community service after pleading guilty to misprision of felony."
    }
  },
  {
    "instruction": "Write an answer to the following question: Why have apps for using a phone's camera flash as a flashlight been known to require unnecessary permissions?",
    "context": "",
    "output": "Apps for using a phone's camera flash as a flashlight have been known to require unnecessary permissions, such as access to personal information, to gather personal information and deliver advertising.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Why have apps for using a phone's camera flash as a flashlight been known to require unnecessary permissions?",
      "answer": "Apps for using a phone's camera flash as a flashlight have been known to require unnecessary permissions, such as access to personal information, to gather personal information and deliver advertising."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are some of the issues related to freedom of speech that arise when dealing with cyberbullying?",
    "context": "",
    "output": "Freedom of speech issues often arise when questionable speech is uttered or posted online. Particularly in instances where there are no laws explicitly against cyberbullying, it is not uncommon for defendants to argue that their conduct amounts to an exercise of their freedom of speech.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are some of the issues related to freedom of speech that arise when dealing with cyberbullying?",
      "answer": "Freedom of speech issues often arise when questionable speech is uttered or posted online. Particularly in instances where there are no laws explicitly against cyberbullying, it is not uncommon for defendants to argue that their conduct amounts to an exercise of their freedom of speech."
    }
  },
  {
    "instruction": "Write an answer to the following question: How did botters in AOHell circumvent the limitation of allotted email messages per day?",
    "context": "",
    "output": "Botters in AOHell circumvented the limitation of allotted email messages per day by signing up for white-list accounts subjected to probationary periods where AOL administrators monitored the account.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How did botters in AOHell circumvent the limitation of allotted email messages per day?",
      "answer": "Botters in AOHell circumvented the limitation of allotted email messages per day by signing up for white-list accounts subjected to probationary periods where AOL administrators monitored the account."
    }
  },
  {
    "instruction": "Write an answer to the following question: How did HackingTeam avoid detection and maintain stealth in their operations?",
    "context": "",
    "output": "HackingTeam used advanced techniques to avoid draining cell phone batteries, which could potentially raise suspicions, and other methods to avoid detection.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How did HackingTeam avoid detection and maintain stealth in their operations?",
      "answer": "HackingTeam used advanced techniques to avoid draining cell phone batteries, which could potentially raise suspicions, and other methods to avoid detection."
    }
  },
  {
    "instruction": "Whitelist\n\n==Introduction==\nA whitelist, allowlist, or passlist is a mechanism which explicitly allows some identified entities to access a particular privilege, service, mobility, or recognition i.e. it is a list of things allowed when everything is denied by default. It is the opposite of a blacklist, which is a list of things denied when everything is allowed by default.\n\n\n\n== Email whitelists ==\nSpam filters often include the ability to \"whitelist\" certain sender IP addresses, email addresses or domain names to protect their email from being rejected or sent to a junk mail folder. These can be manually maintained by the user or system administrator - but can also refer to externally maintained whitelist services.\n\n\n*** Non-commercial whitelists ***\nNon-commercial whitelists are operated by various non-profit organisations, ISPs, and others interested in blocking spam. Rather than paying fees, the sender must pass a series of tests; for example, their email server must not be an open relay and have a static IP address. The operator of the whitelist may remove a server from the list if complaints are received.\n\n\n*** Commercial whitelists ***\nCommercial whitelists are a system by which an Internet service provider allows someone to bypass spam filters when sending email messages to its subscribers, in return for a pre-paid fee, either an annual or a per-message fee. A sender can then be more confident that their messages have reached recipients without being blocked, or having links or images stripped out of them, by spam filters. The purpose of commercial whitelists is to allow companies to reliably reach their customers by email.\n\n== Advertising whitelists ==\nMany websites rely on ads as a source of revenue, but the use of ad blockers is increasingly common. Websites that detect an adblocker in use often ask for it to be disabled - or their site to be \"added to the whitelist\" - a standard feature of most adblockers.\n\n== Network whitelists ==\nNetwork Whitelisting can occur at different layers of the OSI model.\n\n\n*** LAN whitelists ***\nLAN whitelists are enforced at layer 2 of the OSI model. Another use for whitelists is in local area network (LAN) security. Many network admins set up MAC address whitelists, or a MAC address filter, to control who is allowed on their networks. This is used when encryption is not a practical solution or in tandem with encryption. However, it's sometimes ineffective because a MAC address can be faked\n\n\n*** Firewall whitelists ***\nSome firewalls can be configured to only allow data-traffic from/ to certain (ranges of) IP-addresses. A firewall generally works at layer 3 and 4 of the OSI model. Layer 3 is the Network Layer where IP works and Layer 4 is the Transport Layer, where TCP and UDP function.\n\n\n*** Application whitelists ***\nThe application layer is layer 7 in the Open Systems Interconnection (OSI) seven-layer model and in the TCP/IP protocol suite. Whitelisting is commonly enforced by applications at this level.\nOne approach in combating viruses and malware is to whitelist software which is considered safe to run, blocking all others. This is particularly attractive in a corporate environment, where there are typically already restrictions on what software is approved.\nLeading providers of application whitelisting technology include Bit9, Velox, McAfee, Lumension, ThreatLocker, Airlock Digital and SMACOn Microsoft Windows, recent versions include AppLocker, which allows administrators to control which executable files are denied or allowed to execute. With AppLocker, administrators are able to create rules based on file names, publishers or file location that will allow certain files to execute. Rules can apply to individuals or groups. Policies are used to group users into different enforcement levels. For example, some users can be added to a report-only policy that will allow administrators to understand the impact before moving that user to a higher enforcement level.\nLinux systems typically have AppArmor and SE Linux features available which can be used to effectively block all applications which are not explicitly whitelisted, and commercial products are also available.On HP-UX introduced a feature called \"HP-UX Whitelisting\" on 11iv3 version.\n\n== Possible racial connotations ==\nIn 2018, a journal commentary on a report on predatory publishing was released making claims that \"white\" and \"black\" are racially charged terms that need to be avoided in instances such as \"whitelist\" and \"blacklist\". The journal became mainstream in Summer 2020 following the George Floyd protests in America wherein a black man was murdered by an officer, sparking protests on police brutality.\nThe premise of the journal is that \"black\" and \"white\" have negative and positive connotations respectively. It states that since \"blacklisting\" was first referred to during \"the time of mass enslavement and forced deportation of Africans to work in European-held colonies in the Americas,\" the word is therefore related to race. There is no mention of \"whitelist\" and its origin or relation to race.\nThis issue is most widely disputed in computing industries where \"whitelist\" and \"blacklist\" are prevalent (e.g. IP whitelisting). Despite the commentary nature of the journal, some companies and individuals in others have taken to replacing \"whitelist\" and \"blacklist\" with new alternatives such as \"allow list\" and \"deny list\".Those that oppose these changes question its attribution to race, citing the same etymology quote that the 2018 journal uses. According to the remark, the term \"blacklist\" evolved from the term \"black book\" about a century ago. The term \"black book\" does not appear to have any etymology or sources that support racial associations, instead originating in the 1400s as a reference to \"a list of people who had committed crimes or fallen out of favor with leaders\", and popularized by King Henry VIII's literal use of a black book. Others also note the prevalence of positive and negative connotations to \"white\" and \"black\" in the Bible, predating attributions to skin tone and slavery. It wasn't until the 1960s Black Power movement that \"Black\" became a widespread word to refer to one's race as a person of color in America (alternate to African-American) lending itself to the argument that the negative connotation behind \"black\" and \"blacklist\" both predate attribution to race.\n\nAnswer this question based on the above context: What is the debate about the racial connotations of the terms \"whitelist\" and \"blacklist\"?",
    "context": "",
    "output": "The debate centers around the origins and connotations of the terms \"whitelist\" and \"blacklist.\" Some argue that \"blacklist\" has negative connotations due to its origins in the time of mass enslavement and forced deportation of Africans, and that \"whitelist\" has positive connotations. Others argue that the terms have no racial connotations and that their origins and connotations predate attributions to race. The debate has led some companies and individuals to replace \"whitelist\" and \"blacklist\" with alternative terms such as \"allow list\" and \"deny list.\"",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the debate about the racial connotations of the terms \"whitelist\" and \"blacklist\"?",
      "answer": "The debate centers around the origins and connotations of the terms \"whitelist\" and \"blacklist.\" Some argue that \"blacklist\" has negative connotations due to its origins in the time of mass enslavement and forced deportation of Africans, and that \"whitelist\" has positive connotations. Others argue that the terms have no racial connotations and that their origins and connotations predate attributions to race. The debate has led some companies and individuals to replace \"whitelist\" and \"blacklist\" with alternative terms such as \"allow list\" and \"deny list.\"",
      "context": "Whitelist\n\n==Introduction==\nA whitelist, allowlist, or passlist is a mechanism which explicitly allows some identified entities to access a particular privilege, service, mobility, or recognition i.e. it is a list of things allowed when everything is denied by default. It is the opposite of a blacklist, which is a list of things denied when everything is allowed by default.\n\n\n\n== Email whitelists ==\nSpam filters often include the ability to \"whitelist\" certain sender IP addresses, email addresses or domain names to protect their email from being rejected or sent to a junk mail folder. These can be manually maintained by the user or system administrator - but can also refer to externally maintained whitelist services.\n\n\n*** Non-commercial whitelists ***\nNon-commercial whitelists are operated by various non-profit organisations, ISPs, and others interested in blocking spam. Rather than paying fees, the sender must pass a series of tests; for example, their email server must not be an open relay and have a static IP address. The operator of the whitelist may remove a server from the list if complaints are received.\n\n\n*** Commercial whitelists ***\nCommercial whitelists are a system by which an Internet service provider allows someone to bypass spam filters when sending email messages to its subscribers, in return for a pre-paid fee, either an annual or a per-message fee. A sender can then be more confident that their messages have reached recipients without being blocked, or having links or images stripped out of them, by spam filters. The purpose of commercial whitelists is to allow companies to reliably reach their customers by email.\n\n== Advertising whitelists ==\nMany websites rely on ads as a source of revenue, but the use of ad blockers is increasingly common. Websites that detect an adblocker in use often ask for it to be disabled - or their site to be \"added to the whitelist\" - a standard feature of most adblockers.\n\n== Network whitelists ==\nNetwork Whitelisting can occur at different layers of the OSI model.\n\n\n*** LAN whitelists ***\nLAN whitelists are enforced at layer 2 of the OSI model. Another use for whitelists is in local area network (LAN) security. Many network admins set up MAC address whitelists, or a MAC address filter, to control who is allowed on their networks. This is used when encryption is not a practical solution or in tandem with encryption. However, it's sometimes ineffective because a MAC address can be faked\n\n\n*** Firewall whitelists ***\nSome firewalls can be configured to only allow data-traffic from/ to certain (ranges of) IP-addresses. A firewall generally works at layer 3 and 4 of the OSI model. Layer 3 is the Network Layer where IP works and Layer 4 is the Transport Layer, where TCP and UDP function.\n\n\n*** Application whitelists ***\nThe application layer is layer 7 in the Open Systems Interconnection (OSI) seven-layer model and in the TCP/IP protocol suite. Whitelisting is commonly enforced by applications at this level.\nOne approach in combating viruses and malware is to whitelist software which is considered safe to run, blocking all others. This is particularly attractive in a corporate environment, where there are typically already restrictions on what software is approved.\nLeading providers of application whitelisting technology include Bit9, Velox, McAfee, Lumension, ThreatLocker, Airlock Digital and SMACOn Microsoft Windows, recent versions include AppLocker, which allows administrators to control which executable files are denied or allowed to execute. With AppLocker, administrators are able to create rules based on file names, publishers or file location that will allow certain files to execute. Rules can apply to individuals or groups. Policies are used to group users into different enforcement levels. For example, some users can be added to a report-only policy that will allow administrators to understand the impact before moving that user to a higher enforcement level.\nLinux systems typically have AppArmor and SE Linux features available which can be used to effectively block all applications which are not explicitly whitelisted, and commercial products are also available.On HP-UX introduced a feature called \"HP-UX Whitelisting\" on 11iv3 version.\n\n== Possible racial connotations ==\nIn 2018, a journal commentary on a report on predatory publishing was released making claims that \"white\" and \"black\" are racially charged terms that need to be avoided in instances such as \"whitelist\" and \"blacklist\". The journal became mainstream in Summer 2020 following the George Floyd protests in America wherein a black man was murdered by an officer, sparking protests on police brutality.\nThe premise of the journal is that \"black\" and \"white\" have negative and positive connotations respectively. It states that since \"blacklisting\" was first referred to during \"the time of mass enslavement and forced deportation of Africans to work in European-held colonies in the Americas,\" the word is therefore related to race. There is no mention of \"whitelist\" and its origin or relation to race.\nThis issue is most widely disputed in computing industries where \"whitelist\" and \"blacklist\" are prevalent (e.g. IP whitelisting). Despite the commentary nature of the journal, some companies and individuals in others have taken to replacing \"whitelist\" and \"blacklist\" with new alternatives such as \"allow list\" and \"deny list\".Those that oppose these changes question its attribution to race, citing the same etymology quote that the 2018 journal uses. According to the remark, the term \"blacklist\" evolved from the term \"black book\" about a century ago. The term \"black book\" does not appear to have any etymology or sources that support racial associations, instead originating in the 1400s as a reference to \"a list of people who had committed crimes or fallen out of favor with leaders\", and popularized by King Henry VIII's literal use of a black book. Others also note the prevalence of positive and negative connotations to \"white\" and \"black\" in the Bible, predating attributions to skin tone and slavery. It wasn't until the 1960s Black Power movement that \"Black\" became a widespread word to refer to one's race as a person of color in America (alternate to African-American) lending itself to the argument that the negative connotation behind \"black\" and \"blacklist\" both predate attribution to race."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the impact of Canada not ratifying the Convention on Cybercrime?",
    "context": "",
    "output": "As Canada has not yet ratified the Convention on Cybercrime, its Criminal Code may not fully address the areas of criminal law set out in the Convention on Cybercrime.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the impact of Canada not ratifying the Convention on Cybercrime?",
      "answer": "As Canada has not yet ratified the Convention on Cybercrime, its Criminal Code may not fully address the areas of criminal law set out in the Convention on Cybercrime."
    }
  },
  {
    "instruction": "The Tor Project\n\n==Introduction==\nThe Tor Project, Inc. is a 501(c)(3) research-education nonprofit organization based in Winchester, New Hampshire. It is founded by computer scientists Roger Dingledine, Nick Mathewson, and five others. The Tor Project is primarily responsible for maintaining software for the Tor anonymity network.\n\n\n\n== Funding ==\nAs of 2012, 80% of the Tor Project's $2 million annual budget came from the United States government, with the U.S. State Department, the Broadcasting Board of Governors, and the National Science Foundation as major contributors, \"to aid democracy advocates in authoritarian states\". The Swedish government and other organizations provided the other 20%, including NGOs and thousands of individual sponsors. Dingledine said that the United States Department of Defense funds are more similar to a research grant than a procurement contract. Tor executive director Andrew Lewman said that even though it accepts funds from the U.S. federal government, the Tor service did not collaborate with the NSA to reveal identities of users.In June 2016, the Tor Project received an award from Mozilla's Open Source Support program (MOSS). The award was \"to significantly enhance the Tor network's metrics infrastructure so that the performance and stability of the network can be monitored and improvements made as appropriate.\"\n\n== Tools ==\nMetrics PortalAnalytics for the Tor network, including graphs of its available bandwidth and estimated userbase. This is a great resource for researchers interested in detailed statistics about Tor.Nyxa terminal (command line) application for monitoring and configuring Tor, intended for command-line enthusiasts and ssh connections. This functions much like top does for system usage, providing real time information on Tor's resource utilization and state.OnionooWeb-based protocol to learn about currently running Tor relays and bridges.OnionShareAn open source tool that allows users to securely and anonymously share a file of any size.OONI (Open Observatory of Network Interference (OONI))a global observation network, monitoring network censorship, which aims to collect high-quality data using open methodologies, using Free and Open Source Software (FL/OSS) to share observations and data about the various types, methods, and amounts of network tampering in the world.OrbotTor for Android and iOS devices, in collaboration with The Guardian ProjectOrliba library for use by any Android application to route Internet traffic through Orbot/Tor.Pluggable Transports (PT)helps circumvent censorship. Transforms the Tor traffic flow between the client and the bridge. This way, censors who monitor traffic between the client and the bridge will see innocent-looking transformed traffic instead of the actual Tor traffic.Relay SearchSite providing an overview of the Tor network.Shadowa discrete-event network simulator that runs the real Tor software as a plug-in. Shadow is open-source software that enables accurate, efficient, controlled, and repeatable Tor experimentation.StemPython Library for writing scripts and applications that interact with Tor.Tails (The Amnesic Incognito Live System)a live CD/USB distribution preconfigured so that everything is safely routed through Tor and leaves no trace on the local system.Torfree software and an open network that helps a user defend against traffic analysis, a form of network surveillance that threatens personal freedom and privacy, confidential business activities and relationships, and state security. The organization has also implemented the software in Rust named Arti.Tor Browsera customization of Mozilla Firefox which uses a Tor circuit for browsing anonymously and with other features consistent with the Tor mission.Tor PhoneA phone that routes its network traffic through tor network. Initially based on a CopperheadOS custom ROM prototype, using Tor with Orbot and Tor Browser are supported by custom Android operating systems CalyxOS and DivestOS. GrapheneOS supports using Orbot VPN but not Tor Browser.TorBirdyTorbutton for Thunderbird and related *bird forks.txtorconPython and Twisted event-based implementation of the Tor control protocol. Unit-tests, state and configuration abstractions, documentation. It is available on PyPI and in Debian.\n\n== Recognition ==\nIn March 2011, the Tor Project received the Free Software Foundation's 2010 Award for Projects of Social Benefit. The citation read, \"Using free software, Tor has enabled roughly 36 million people around the world to experience freedom of access and expression on the Internet while keeping them in control of their privacy and anonymity. Its network has proved pivotal in dissident movements in both Iran and more recently Egypt.\"In September 2012, the Tor Project received the 2012 EFF Pioneer Award, along with J\u00e9r\u00e9mie Zimmermann and Andrew Huang.In November 2012, Foreign Policy magazine named Dingledine, Mathewson, and Syverson among its Top 100 Global Thinkers \"for making the web safe for whistleblowers\".In 2014, Roger Dingledine, Nick Mathewson and Paul Syverson received the USENIX Test of Time Award for their paper titled \"Tor: The Second-Generation Onion Router\", which was published in the Proceedings of the 13th USENIX Security Symposium, August 2004.\n\nAnswer this question based on the above context: Has the Tor service collaborated with the NSA to reveal identities of users?",
    "context": "",
    "output": "No, the Tor service did not collaborate with the NSA to reveal identities of users, despite accepting funds from the U.S. federal government.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Has the Tor service collaborated with the NSA to reveal identities of users?",
      "answer": "No, the Tor service did not collaborate with the NSA to reveal identities of users, despite accepting funds from the U.S. federal government.",
      "context": "The Tor Project\n\n==Introduction==\nThe Tor Project, Inc. is a 501(c)(3) research-education nonprofit organization based in Winchester, New Hampshire. It is founded by computer scientists Roger Dingledine, Nick Mathewson, and five others. The Tor Project is primarily responsible for maintaining software for the Tor anonymity network.\n\n\n\n== Funding ==\nAs of 2012, 80% of the Tor Project's $2 million annual budget came from the United States government, with the U.S. State Department, the Broadcasting Board of Governors, and the National Science Foundation as major contributors, \"to aid democracy advocates in authoritarian states\". The Swedish government and other organizations provided the other 20%, including NGOs and thousands of individual sponsors. Dingledine said that the United States Department of Defense funds are more similar to a research grant than a procurement contract. Tor executive director Andrew Lewman said that even though it accepts funds from the U.S. federal government, the Tor service did not collaborate with the NSA to reveal identities of users.In June 2016, the Tor Project received an award from Mozilla's Open Source Support program (MOSS). The award was \"to significantly enhance the Tor network's metrics infrastructure so that the performance and stability of the network can be monitored and improvements made as appropriate.\"\n\n== Tools ==\nMetrics PortalAnalytics for the Tor network, including graphs of its available bandwidth and estimated userbase. This is a great resource for researchers interested in detailed statistics about Tor.Nyxa terminal (command line) application for monitoring and configuring Tor, intended for command-line enthusiasts and ssh connections. This functions much like top does for system usage, providing real time information on Tor's resource utilization and state.OnionooWeb-based protocol to learn about currently running Tor relays and bridges.OnionShareAn open source tool that allows users to securely and anonymously share a file of any size.OONI (Open Observatory of Network Interference (OONI))a global observation network, monitoring network censorship, which aims to collect high-quality data using open methodologies, using Free and Open Source Software (FL/OSS) to share observations and data about the various types, methods, and amounts of network tampering in the world.OrbotTor for Android and iOS devices, in collaboration with The Guardian ProjectOrliba library for use by any Android application to route Internet traffic through Orbot/Tor.Pluggable Transports (PT)helps circumvent censorship. Transforms the Tor traffic flow between the client and the bridge. This way, censors who monitor traffic between the client and the bridge will see innocent-looking transformed traffic instead of the actual Tor traffic.Relay SearchSite providing an overview of the Tor network.Shadowa discrete-event network simulator that runs the real Tor software as a plug-in. Shadow is open-source software that enables accurate, efficient, controlled, and repeatable Tor experimentation.StemPython Library for writing scripts and applications that interact with Tor.Tails (The Amnesic Incognito Live System)a live CD/USB distribution preconfigured so that everything is safely routed through Tor and leaves no trace on the local system.Torfree software and an open network that helps a user defend against traffic analysis, a form of network surveillance that threatens personal freedom and privacy, confidential business activities and relationships, and state security. The organization has also implemented the software in Rust named Arti.Tor Browsera customization of Mozilla Firefox which uses a Tor circuit for browsing anonymously and with other features consistent with the Tor mission.Tor PhoneA phone that routes its network traffic through tor network. Initially based on a CopperheadOS custom ROM prototype, using Tor with Orbot and Tor Browser are supported by custom Android operating systems CalyxOS and DivestOS. GrapheneOS supports using Orbot VPN but not Tor Browser.TorBirdyTorbutton for Thunderbird and related *bird forks.txtorconPython and Twisted event-based implementation of the Tor control protocol. Unit-tests, state and configuration abstractions, documentation. It is available on PyPI and in Debian.\n\n== Recognition ==\nIn March 2011, the Tor Project received the Free Software Foundation's 2010 Award for Projects of Social Benefit. The citation read, \"Using free software, Tor has enabled roughly 36 million people around the world to experience freedom of access and expression on the Internet while keeping them in control of their privacy and anonymity. Its network has proved pivotal in dissident movements in both Iran and more recently Egypt.\"In September 2012, the Tor Project received the 2012 EFF Pioneer Award, along with J\u00e9r\u00e9mie Zimmermann and Andrew Huang.In November 2012, Foreign Policy magazine named Dingledine, Mathewson, and Syverson among its Top 100 Global Thinkers \"for making the web safe for whistleblowers\".In 2014, Roger Dingledine, Nick Mathewson and Paul Syverson received the USENIX Test of Time Award for their paper titled \"Tor: The Second-Generation Onion Router\", which was published in the Proceedings of the 13th USENIX Security Symposium, August 2004."
    }
  },
  {
    "instruction": "U.S. critical infrastructure protection\n\n==Introduction==\nIn the U.S., critical infrastructure protection (CIP) is a concept that relates to the preparedness and response to serious incidents that involve the critical infrastructure of a region or the nation.\nThe American Presidential directive PDD-63 of May 1998 set up a national program of \"Critical Infrastructure Protection\".  In 2014 the NIST Cybersecurity Framework was published after further presidential directives.\n\n\n\n== Overview ==\nThe systems and networks that make up the infrastructure of society are often taken for granted, yet a disruption to just one of those systems can have dire consequences across other sectors.\nTake, for example, a computer virus that disrupts the distribution of natural gas across a region. This could lead to a consequential reduction in electrical power generation, which in turn leads to the forced shutdown of computerized controls and communications. Road traffic, air traffic, and rail transportation might then become affected. Emergency services might also be hampered.\nAn entire region can become debilitated because some critical elements in the infrastructure become disabled through natural disaster. While potentially in contravention of the Geneva Conventions, military forces have also recognized that it can cripple an enemy's ability to resist by attacking key elements of its civilian and military infrastructure.\nThe federal government has developed a standardized description of critical infrastructure, in order to facilitate monitoring and preparation for disabling events. The government requires private industry in each critical economic sector to:\n\nAssess its vulnerabilities to both physical or cyber attacks\nPlan to eliminate significant vulnerabilities\nDevelop systems to identify and prevent attempted attacks\nAlert, contain and rebuff attacks and then, with the Federal Emergency Management Agency (FEMA), to rebuild essential capabilities in the aftermath\n\n\n*** Infrastructure sectors ***\nCIP defines sectors and organizational responsibilities in a standard way:\n\nBanking and finance: - The Department of the Treasury is responsible for coordinating the protection of not just systems but also maintaining public confidence, through industry initiatives such as the Financial Services Information Sharing and Analysis Center (ISAC)\nTransportation: - The Department of Transportation is responsible for protecting the road, rail, air, and water transportation infrastructure, including computer-controlled just-in-time delivery systems, optimization of distribution through hubs, and traffic and operations centers that are consolidated into key locations, and regulation of the transport of hazardous materials.\nPower: - The Department of Energy oversees energy supplies including electricity, oil, and gas, and works with the Nuclear Regulatory Commission for the protection of nuclear materials and power. Note that CIP in this sector is different from energy security, which is the politics and economics of supply. Additionally, operating under the auspices of the Federal Energy Regulatory Commission is the North American Electric Reliability Corporation (NERC), a non-profit organization that defines and enforces reliability standards for the bulk power system.\nInformation and communications: - Overseen by the Department of Commerce, most areas of life rely on telecommunications and information technology.\nFederal and municipal services: - Overseen jointly by Federal and State agencies.  They guarantee continuity of government at the federal, state, and local levels to meet for provision of essential services.\nEmergency services: - Overseen by the Health and Human Services, this includes emergency health services and public health\nFire departments: - Overseen by the Federal Emergency Management Agency FEMA.\nLaw enforcement agencies: - Overseen jointly by the Department of Justice and the Federal Bureau of Investigation to ensure the orderly running of activities during times of threat or crises.\nPublic works: - Overseen by the United States Environmental Protection Agency.  This includes safe water systems and drainage.In 2003 the remit was expanded to include:\n\nAgriculture and food, with the Department of Agriculture overseeing the safe supply of meat, poultry, and egg products.\nNational monuments and icons, under the Department of the InteriorWith much of the critical infrastructure privately owned, the Department of Defense (DoD) depends on commercial infrastructure to support its normal operations. The Department of State and the Central Intelligence Agency are also involved in intelligence analysis with friendly countries.\nIn May 2007 the DHS completed its sector-specific plans (SSP) for coordinating and dealing with critical events. the Continuity of government (COG) in time of a catastrophic event can be used to preserve the government as seen fit by the president, at which point the welfare of the government can be placed above the welfare of the citizenry of the United States ensuring that the government is preserved to rebuild the economy and country when it is deemed safe to return to the surface of the United States of America.\n\n== Significance ==\nOn March 9, 1999, Deputy Defense Secretary John Hamre warned the United States Congress of a cyber terrorist \"electronic Pearl Harbor\" saying, \"It is not going to be against Navy ships sitting in a Navy shipyard. It is going to be against commercial infrastructure\". Later this fear was qualified by President Clinton after reports of actual cyber terrorist attacks in 2000: \"I think it was an alarm. I don't think it was Pearl Harbor. We lost our Pacific fleet at Pearl Harbor. I don't think the analogous loss was that great.\"\nThere are many examples of computer systems that have been hacked or victims of extortion. One such example occurred in September 1995 where a Russian national allegedly masterminded the break-in of Citicorp's electronic funds transfer system and was ordered to stand trial in the United States. A gang of hackers under his leadership had breached Citicorp's security 40 times during 1994. They were able to transfer $12 million from customer accounts and withdraw an estimated $400,000.\nIn the past, the systems and networks of the infrastructure elements were physically and logically independent and separate. They had little interaction or connection with each other or other sectors of the infrastructure.  With advances in technology, the systems within each sector became automated, and interlinked through computers and communications facilities. As a result, the flow of electricity, oil, gas, and telecommunications throughout the country are linked\u2014albeit sometimes indirectly\u2014but the resulting linkages blur traditional security borders.\nWhile this increased reliance on interlinked capabilities helps make the economy and nation more efficient and perhaps stronger, it also makes the country more vulnerable to disruption and attack. This interdependent and interrelated infrastructure is more vulnerable to physical and cyber disruptions because it has become a complex system with single points of failure.  In the past an incident that would have been an isolated failure can now cause widespread disruption because of cascading effects. As an example, capabilities within the information and communication sector have enabled the United States to reshape its government and business processes, while becoming increasingly software driven. One catastrophic failure in this sector now has the potential to bring down multiple systems including air traffic control, emergency services, banking, trains, electrical power, and dam control.\nThe elements of the infrastructure themselves are also considered possible targets of terrorism. Traditionally, critical infrastructure elements have been lucrative targets for anyone wanting to attack another country. Now, because the infrastructure has become a national lifeline, terrorists can achieve high economic and political value by attacking elements of it. Disrupting or even disabling the infrastructure may reduce the ability to defend the nation, erode public confidence in critical services, and reduce economic strength.  Additionally, well chosen terrorist attacks can become easier and less costly than traditional warfare because of the interdependence of infrastructure elements. These infrastructure elements can become easier targets where there is a low probability of detection.\nThe elements of the infrastructure are also increasingly vulnerable to a dangerous mix of traditional and nontraditional types of threats. Traditional and non-traditional threats include equipment failures, human error, weather and natural causes, physical attacks, and cyber attacks. For each of these threats, the cascading effect caused by single points of failure has the potential to pose dire and far-reaching consequences.\n\n\n*** Challenges ***\nThere are fears that the frequency and severity of critical infrastructure incidents will increase in the future.Although efforts are under way, there is no unified national capability to protect the interrelated aspects of the country's infrastructure. One reason for this is that a good understanding of the inter-relationships does not exist. There is also no consensus on how the elements of the infrastructure mesh together, or how each element functions and affects the others.  Securing national infrastructure depends on understanding the relationships among its elements. Thus when one sector scheduled a three-week drill to mimic the effects of a pandemic flu, even though two-thirds of the participants claimed to have business continuity plans in place, barely half reported that their plan was moderately effective.Critical infrastructure protection requires the development of a national capability to identify and monitor the critical elements and to determine when and if the elements are under attack or are the victim of destructive natural occurrences. CIP is important because it is the link between risk management and infrastructure assurance. It provides the capability needed to eliminate potential vulnerabilities in the critical infrastructure.\nCIP practitioners determine vulnerabilities and analyze alternatives in order to prepare for incidents. They focus on improving the capability to detect and warn of impending attacks on, and system failures within, the critical elements of the national infrastructure.\n\n== Organization and structure ==\nPDD-63 mandated the formation of a national structure for critical infrastructure protection. To accomplish this one of the primary actions was to produce a National Infrastructure Assurance Plan, or NIAP, later renamed National Infrastructure Protection Plan or NIPP.\nThe different entities of the national CIP structure work together as a partnership between the government and the public sectors. Each department and agency of the federal government is responsible for protecting its portion of the government's critical infrastructure. In addition, there are grants made available through the Department of Homeland Security for municipal and private entities to use for CIP and security purposes. These include grants for emergency management, water security training, rail, transit and port security, metropolitan medical response, LEA terrorism prevention programs and the Urban Areas Security Initiative.PDD-63 identified certain functions related to critical infrastructure protection that must be performed chiefly by the federal government. These are national defense, foreign affairs, intelligence, and law enforcement. Each lead agency for these special functions appoints a senior official to serve as a functional coordinator for the federal government. In 2008 a mobile PDA-based Vulnerability Assessment Security Survey Tool (VASST) was introduced to speed physical security assessment of critical infrastructure by law enforcement to meet compliance requirements of PDD-63.\n\n\n*** National Infrastructure Assurance Plan / National Infrastructure Protection Plan ***\n\nFor each of the identified major sectors of the critical infrastructure, the federal government appointed a Sector Liaison Official from a designated Lead Agency.  A private sector counterpart, a Sector Coordinator, was also identified. Together, the two sector representatives, one federal government and one corporate, were responsible for developing a sector NIAP.\nIn addition, each department and agency of the federal government was responsible for developing its own CIP plan for protecting its portion of the federal government's critical infrastructure.  The federal department and agency plans were assimilated with the sector NIAPs to create one comprehensive National Infrastructure Assurance Plan.  Additionally the national structure must ensure there is a national CIP program. This program includes responsibilities such as education and awareness, threat assessment and investigation, and research.\nThe process includes assessments of:\n\nProtection -  Can be defined as the state of being defended, safeguarded, or shielded from injury, loss, or destruction from natural or unnatural forces.\nVulnerability \u2013 The quality of being susceptible to attack or injury, warranted or unwarranted, by accident or by design.\nRisk \u2013 The possibility or likelihood of being attacked or injured.\nMitigation \u2013 The ability to alleviate, reduce, or moderate a vulnerability, thus reducing or eliminating risk.\n\n\n*** Controversy ***\nThere have been public criticisms of the mechanisms and implementation of some security initiatives and grants, with claims they are being led by the same companies who can benefit, and that they are encouraging an unnecessary culture of fear. Commentators note that these initiatives started directly after the collapse of the Cold War, raising the concern that this was simply a diversion of the military-industrial complex away from a funding area which was shrinking and into a richer previously civilian arena.\nGrants have been distributed across the different states even though the perceived risk is not evenly spread, leading to accusations of pork barrel politics that directs money and jobs towards marginal voting areas. The Urban Areas Security Initiative grant program has been particularly controversial, with the 2006 infrastructure list covering 77,000 assets, including a popcorn factory and a hot dog stand.   The 2007 criteria were reduced to 2,100 and now those facilities must make a much stronger case to become eligible for grants. While well-intentioned, some of the results have also been questioned regarding claims of poorly designed and intrusive security theater that distracts attention and money from more pressing issues or creates damaging side effects.\nAn absence of comparative risk analysis and benefits tracking it has made it difficult to counter such allegations with authority. In order to better understand this, and ultimately direct effort more productively, a Risk Management and Analysis Office was recently created in the National Protection and Programs directorate at the Department of Homeland Security.\n\n== Department of Defense and CIP ==\nThe U.S. Department of Defense is responsible for protecting its portion of the government's critical infrastructure.  But as part of the CIP program, DoD has responsibilities that traverse both the national and department-wide critical infrastructure.\nPDD-63 identified the responsibilities DoD had for critical infrastructure protection. First, DoD had to identify its own critical assets and infrastructures and provide assurance through analysis, assessment, and remediation.  DoD was also responsible for identifying and monitoring the national and international infrastructure requirements of industry and other government agencies, all of which needed to be included in the protection planning.  DoD also addressed the assurance and protection of commercial assets and infrastructure services in DoD acquisitions.  Other DoD responsibilities for CIP included assessing the potential impact on military operations that would result from the loss or compromise of infrastructure service.  There were also requirements for monitoring DoD operations, detecting and responding to infrastructure incidents, and providing department indications and warnings as part of the national process.  Ultimately, DoD was responsible for supporting national critical infrastructure protection.\nIn response to the requirements identified in PDD-63, DoD categorized its own critical assets by sector, in a manner similar to the national CIP organization. The DoD identified a slightly different list of infrastructure sectors for those areas that specifically required protection by DoD.  DoD's organizational structure for critical infrastructure protection reflects, complements, and effectively interacts with the national structure for CIP.\n\n\n*** DoD sectors ***\nThere are ten defense critical infrastructure sectors that are protected by the DoD. These include:\n\nFinancial Services - Defense financial services support activities related to officially appropriated funds. These activities include the disbursement of cash, receipt of funds, and acceptance of deposits for credit to officially designated Treasury general accounts. This sector also provides financial services to individuals and on-base organizations, including deposits, account maintenance, and safekeeping. The Defense Finance and Accounting Service is the lead component for the Financial Services sector.\nTransportation - The Defense Transportation System, or DTS, includes resources that support global DoD transportation needs. These include surface, sea, and lift assets; supporting infrastructure; personnel; and related systems. Transportation Command, or USTRANSCOM, is the single manager for DoD transportation.\nPublic Works - Public works includes four distinct physical infrastructure sectors: electric power, oil, and natural gas, water and sewer; and emergency services, such as fire, medical, and hazardous material handling.  This defense infrastructure sector is composed of networks and systems, principally for the distribution of the associated commodities.  The Corps of Engineers is responsible for coordinating the assurance activities of the public works infrastructure sector.\nGlobal Information Grid Command Control, or GIG/C2 - The Global Information Grid Command Control, or GIG/C2, are two combined sectors that support overall asset assurance for CIP.  The GIG is the globally interconnected set of personnel, information, and communication capabilities necessary to achieve information superiority. C2 includes assets, facilities, networks, and systems that support mission accomplishment.  The Defense Information Systems Agency, or DISA, is the lead component responsible for Global Information Grid Command Control.\nIntelligence Surveillance, and Reconnaissance, or ISR - The Defense Intelligence, Surveillance and Reconnaissance infrastructure sector is composed of facilities, networks, and systems that support ISR activities such as intelligence production and fusion centers.  The Defense Intelligence Agency, or DIA, is responsible for coordinating the assurance activities of this infrastructure sector.\nHealth Affairs - The health care infrastructure consists of facilities and sites worldwide. Some are located at DoD installations; however, DoD also manages a larger system of non-DoD care facilities within its health care network. These health care facilities are linked by information systems. The Office of the Assistant Secretary of Defense, Health Affairs is the designated lead component for this sector.\nPersonnel - The defense personnel infrastructure sector includes a large number of assets hosted on component sites, a network of facilities, and information systems linking those sites and facilities. In addition to being responsible for its own assets, the personnel infrastructure sector also coordinates commercial services that support the personnel function. These services include recruitment, record keeping, and training. The Defense Human Resources Activity is the designated lead component for the Defense Personnel infrastructure sector.\nSpace - The defense space infrastructure sector is composed of both space- and ground-based assets including launch, specialized logistics, and control systems. Facilities are located worldwide on both DoD-controlled and private sites. The Defense Space sector is led by the United States Strategic Command, or USSTRATCOM.\nLogistics - The defense logistics sector includes all activities, facilities, networks, and systems that support the provision of supplies and services to U.S. forces worldwide.  Logistics includes the acquisition, storage, movement, distribution, and maintenance of material and supplies. This sector also includes the final disposition of material no longer needed by DoD. The Defense Logistics Agency, or DLA, is the lead component for the DoD Logistics infrastructure.\nDefense Industrial Base - The Defense Industrial Base consists of DoD product and service providers from the private sector. The services and products provided constitute critical assets for DoD.  The lead component for the Defense Industrial Base is the Defense Contract Management Agency.  For those cases when infrastructure protection requirements affect more than one defense sector, DoD has set up special function components that support the implementation of CIP.\n\n\n*** DoD special functions ***\nThe DoD CIP special function components interface with the equivalent national functional coordinators and coordinate all activities related to their function within DoD.\nDoD's special function components currently include seven areas of focus.  They include the following components:\n\nPolicy and Strategy - The Policy and Strategy Special Function Component provides the strategic planning required to prepare our Armed Forces for the 21st century. In part, it satisfies this responsibility through the development of the National Military Strategy.  Within the area of policy development it is responsible for leading the chairman's biennial review of the Unified Command Plan and developing Joint Staff positions on such key issues as the organization, roles and missions, and functions of the Armed Forces and the combatant commands.\nIntelligence Support - The CIP Intelligence Support Special Function Component provides intelligence support to DoD in protection of the Defense portion of the Federal Government Critical Infrastructure. Intelligence Support responsibilities also include supporting the Defense Warning System, Alert and Notification, and interfacing with the national intelligence community.  The responsibilities of the Intelligence Support agencies include such activities as provisioning threat assessments; indications and warnings of potential attacks; advice and support to Sector CIAOs in the development of defense infrastructure sector monitoring and reporting; crisis management support; and counter-intelligence. This special function component is also tasked with the support to the DoD contingent of the NIPC related to intelligence and counter-intelligence.\nIndustrial Policy - The Under Secretary of Defense for Acquisition, Technology & Logistics ensures that an adequate defense industrial base exists and remains viable to meet current, future, and emergent national security requirements.\"\nDefense Security - The Defense Security Service provides to the Department of Defense and other Federal agencies an array of security products and services which are designed to deter and detect espionage\nInformation Assurance - The Assistant Secretary of Defense for Networks and Information Integration, or ASD NII, is the principal OSD staff assistant for the development, oversight, and integration of DoD policies and programs relating to the strategy of information superiority for the Department of Defense. Information Assurance, or IA, is the component of Information Operations that assures DoD's operational readiness by providing for the continuous availability and reliability of information systems and networks. IA protects the DII against exploitation, degradation, and denial of service, while providing the means to efficiently reconstitute and reestablish vital capabilities following an attack.\nResearch and Development - The Research and Development Special Function Component is responsible for information assurance and protection. The Office of Director, Defense Research and Engineering coordinates a CIP DoD research and development agenda. As well as reconciling the DoD agenda with the national R&D agenda.\nEducation and Awareness - Although education and awareness may rightly be considered everyone's responsibility, a comprehensive education and awareness strategy was deemed essential for a successful DoD CIP program. The National Defense University, or NDU, provided advice and assistance in assessing DoD education and awareness requirements. The Education and Awareness Component also developed the CIAO Education Program. This component was tasked to assist in the development of any special education or training required for CIP crisis management personnel.  Education and Awareness also supports both DoD and national CIP policy and strategy formulation and executive leadership development through periodic \"infrastructure games\".\n\n== DoD CIP lifecycle ==\nAs mandated by PDD-63, the DoD must protect its portion of the federal government's critical infrastructure. For DoD, this is the Defense Infrastructure or DI. Protecting the Defense Infrastructure is a complex task involving ten defense sectors.\nIt was deemed that it was nearly impossible to protect every critical asset at every location, therefore the focus was directed on protecting the critical Defense Infrastructure. The critical Defense Infrastructure is the critical assets essential to providing mission assurance.\n\n\n*** Six phases ***\nThe six phases of the DoD CIP life cycle build on one another to create a framework for a comprehensive solution for infrastructure assurance.  The life cycle phases occur before, during, and after an event that may compromise or degrade the infrastructure.  A synopsis of the six phases are:\n\nAnalysis and Assessment (occurs before an event) - The Analysis and Assessment phase is the foundation and most important phase of the CIP life cycle. This phase identifies the assets absolutely critical to mission success and determines the assets\u2019 vulnerabilities, as well as their interdependencies, configurations, and characteristics.  An assessment is then made of the operational impact of infrastructure loss or degradation. In addition, Proactive Cyber Defence may anticipate an attack against computers and networks.  It applies equally well to all critical infrastructure sectors, as it involves interdicting and disrupting an attack or a threat's preparation to attack, either preemptively or in self-defense.\nRemediation (occurs before an event) - The Remediation phase involves precautionary measures and actions taken before an event occurs to fix the known cyber and physical vulnerabilities that could cause an outage or compromise a National Defense Infrastructure, or NDI, or critical asset.  For example, remediation actions may include education and awareness, operational process or procedural changes or system configuration and component changes.\nIndications and Warnings (occurs before and/or during an event) - The Indications and Warnings phase involves daily sector monitoring to assess the mission assurance capabilities of critical infrastructure assets and to determine if there are event indications to report.  Indications are preparatory actions that indicate whether an infrastructure event is likely to occur or is planned.  Indications are based on input at the tactical, operational, theater, and strategic level.  At the tactical level, input comes from asset owners. At the operational level, input comes from the NDI sectors.  At the theater level, input comes from regional assets such as allied intelligence, NATO, command intelligence, allied governments, and coalition forces.  At the strategic level, input comes from intelligence, law-enforcement, and the private sector.  Warning is the process of notifying asset owners of a possible threat or hazard.\nMitigation (occurs both before and during an event) - The Mitigation phase comprises actions taken before or during an event in response to warnings or incidents. DoD Critical Asset owners, NDI sectors, DoD installations, and military operators take these actions to minimize the operational impact of a critical asset's loss or debilitation.\nIncident Response (occurs after an event) - Incident Response comprises the plans and activities taken to eliminate the cause or source of an infrastructure event.\nReconstitution (occurs after an event)  - The last phase of the CIP life cycle, involves actions taken to rebuild or restore a critical asset capability after it has been damaged or destroyed. This phase is the most challenging and least developed process.Effective management of the CIP life cycle ensures that protection activities can be coordinated and reconciled among all DoD sectors. In many ways, DoD CIP, is risk management at its most imperative.  Achieving success means obtaining mission assurance. Missing the mark can mean mission failure as well as human and material losses. For critical infrastructure protection, risk management requires leveraging resources to address the most critical infrastructure assets that are also the most vulnerable and that have the greatest threat exposure.\nThe most important part of the CIP lifecycle is Phase 1.  Because it is crucial to target the right assets for infrastructure protection, determining these assets is the first phase in the CIP life cycle. This phase, Analysis and Assessment, is the key and foundation of the seven lifecycle activities.  Without a solid foundation, the remaining CIP life cycle phases may be flawed, resulting in a CIP plan that fails to protect the critical infrastructure and, therefore, mission assurance.\n\n\n*** Phase 1: Analysis and Assessment ***\nPhase 1 determines what assets are important, and identifies their vulnerabilities, and dependencies so that decision makers have the information they need to make effective risk management choices.\nThe Defense Infrastructure, or DI, is organized into ten sectors. Each sector is composed of assets, such as systems, programs, people, equipment, or facilities. Assets may be simple, such as one facility within one geographic location, or complex, involving geographically dispersed links and nodes.\nThe Analysis and Assessment is made up of five steps that include activities that span and encompass the ten DI sectors and their assets.\n\nI.  The first step in the Analysis and Assessment phase is to identify critical assets.  An asset's criticality is a function of both time and situation based on the asset's operational or business value. For the DI, value depends on several factors:  First, what military operations or services rely on an asset and how those dependencies change across time Next, how sensitive the operation is to the loss or compromise of the asset, in other words what is the maximum allowable down time if the asset is compromised. Finally, what the asset's assurance profile is, in particular whether asset restoration or a switch to a backup can occur within the allowable down time. Through domain expertise and inspection, critical assets are identified and then reported to the CIP Program.\nII.  The second step of the Analysis and Assessment phase is Defense Infrastructure characterization. This step maps and associates critical asset functions and relationships within a DI sector.\nIII.  The third step in the Analysis and Assessment phase is the Operational Impact Analysis. This step is accomplished through the development of operational dependency matrices and the application of operations research methods. Potential operational impacts and service-level requirements are then reflected in the asset's criticality attributes and criticality index in the CIP program.\nIV.  The fourth step is the Vulnerability Assessment.  This step is accomplished through multiple channels.  Through the CIP program, all critical assets have a baseline vulnerability index, which is calculated from inputs associated with the class of asset and geographic region such as the probability of natural disasters, criminal or national security events, and technological failures.  Asset owners, host installations, the sector CIAO, or other DoD entities may provide asset operational readiness and emergency preparedness information.\nV.  The fifth and final step in the Analysis and Assessment phase is Interdependency Analysis. Interdependency analysis seeks to map functions and relationships among DI sectors.  As a result of the Interdependency Analysis, the criticality attributes for previously identified assets may be updated and additional critical assets may be identified to the CIP program.  Multiple groups within the DoD CIP structure perform analysis and assessment activities.  Translating the analysis and assessment process into concrete data requires specific activities, tasks, and tools.\n\n\n**** Phase 1 Example in the \u201cReal World\u201d ****\nOn August 24, 2001, the Director of the Joint Staff requested USPACOM to serve as the lead support Combatant Command for creating a CIP first-ever theater CIP Plan \u2013 known as the \u201cCIP Appendix 16 Plan\u201d. The following is how USPACOM approached the task.\nUSPACOM focused the Analysis and Assessment phase by organizing its activities to answer three major questions:\n\nWhat is critical?\nIs it vulnerable?\nWhat can be done?To answer the question, \u201cWhat is critical?\u201d, USPACOM outlined a three-step procedure:\n\nFirst, identify the project focus.\nSecond, complete an operational analysis.\nThird, complete a Defense Infrastructure analysis.To accomplish these steps, USPACOM adopted a methodology that focuses its CIP efforts on Tier 1 assets. Tier 1 assets are assets that could cause mission failure if they are compromised or damaged.  The methodology UAPACOM adopted and modified is Mission Area Analysis, or MAA.  The MAA links combatant command missions to infrastructure assets that are critical to a given Operations Plan, or OPLAN, Contingency Plan, or CONPLAN, or Crisis Action Plan. Typically, the MAA process determines the assessment site priorities.  USPACOM modified the process and selected the CIP assessment sites and installations prior to conducting the MAA.  The following is an illustration of the USPACOM MAA process:\n\nFirst, it identified the Mission Essential Requirements, or MERs, which are specific combatant commands or joint task force capabilities essential for execution of a warfighting plan. Then, they created an MER matrix for the specific command. For example, one MER may be to provide command, control, communications, and computers, or C4.\nSecond, it identified forces required for each MER. For example, the C4 MER is linked to a specific signal battalion. Third, it linked the forces to the necessary functions and tasks supporting the force. For example, the signal battalion is linked to the Communications and Civil Engineers functions and the task of managing the theater's C4 information systems requirements.\nThird, it links assets to the functions supporting the tasks. The result is a mission area analysis of mission-critical assets.USPACOM uses the MAA data it gathers to scope and focus its efforts on truly mission-critical assets to answer the next question in its process, Is it vulnerable?\nThe first step in answering this question is to complete an installation analysis. The next step is to complete a commercial infrastructure analysis. USPACOM relied upon two different DoD organizations for CIP assessments: Balanced Survivability Assessments, or BSAs, and Mission Assurance Assessments.  The BSA is a two-week mission-focused assessment at a military installation or designated site.  A Mission Assurance Assessment is unique because it uses an area assessment approach to focus on both commercial and military asset vulnerabilities and dependencies.  The final step to determine vulnerabilities is to integrate the two analyses and assessments.  With its critical assets and their vulnerabilities identified, USPACOM is ready to perform risk management activities to decide what can be done to protect the mission-critical assets.\nBooz Allen Hamilton developed this process at PACOM.\n\n\n*** Phase 2: Remediation ***\nThe first phase of the CIP life cycle, Analysis and Assessment, identified the critical assets of DoD sector infrastructures and the vulnerabilities or weaknesses of those critical assets.\nThe second phase is the Remediation phase. In the Remediation phase, the known weaknesses and vulnerabilities are addressed. Remediation actions are deliberate, precautionary measures designed to fix known virtual and physical vulnerabilities before an event occurs. The purpose of remediation is to improve the reliability, availability, and survivability of critical assets and infrastructures.  Remediation actions apply to any type of vulnerability, regardless of its cause. They apply to acts of nature, technology failures, or deliberate malicious actions.\nThe cost of each remediation action depends on the nature of the vulnerability it addresses. The Defense Infrastructure Sector Assurance Plan that each infrastructure sector must develop, establishes the priorities and resources for remediation. Remediation requirements are determined by multiple factors. These are analysis and assessment, input from military planners and other DoD sectors, the National Infrastructure Assurance Plan and other plans, reports, and information on national infrastructure vulnerabilities and remediation, as well as intelligence estimates and assessments of threats.\nRemediation requirements are also gathered through lessons learned from Defense Infrastructure sector monitoring and reporting and infrastructure protection operations and exercises.  The CIP program tracks the status of remediation activities for critical assets. Remediation activities to protect the critical Defense Infrastructure cross multiple Department components.\n\n\n*** Phase 3:  Indications and Warnings ***\nThe need to monitor activities and warn of potential threats to the United States is not new. From conventional assaults to potential nuclear attacks, the military has been at the forefront of monitoring and warning of potential dangers since the founding of the country.  Protecting the security and well-being of the United States, including the critical Defense Infrastructure, has now entered a new era. It has been deemed essential to have a coordinated ability to identify and warn of potential or actual incidents among critical infrastructure domains. The ability to detect and warn of infrastructure events is the third phase of the critical infrastructure protection life cycle, the Indications and Warnings phase.\nIndications and warnings are actions or infrastructure conditions that signal an event is either:\n\nLikely,\nPlanned or\nUnderway.Historically, DoD event indications have focused and relied on intelligence information about foreign developments.  These event indications have been expanded to include all potential infrastructure disruption or degradation, regardless of its cause.  DoD CIP indications are based on four levels of input:\n\nTactical level input from DoD asset owners or installations\nOperational-level input from sector Chief Information Assurance Officers (CIAOs)\nTheater-level input from command and service intelligence and counter-intelligence activities.\nStrategic-level intelligence from the intelligence community, law enforcement, and the private sectorThis fusion of traditional intelligence information with sector-specific information has been determined to be essential for meaningful CIP indications.\nIf an indication is detected, a warning notifying the appropriate asset owners of a possible or occurring event or hazard can be issued.  The sector's assurance plan determines what conditions and actions are monitored and reported for each Defense Infrastructure Sector. Each sector must develop a written Defense Sector Assurance Plan that includes a compendium of sector incidents for monitoring and reporting. The sector incident compendium is made up of three types of incidents:\n\nNationally defined reportable incidents\nDoD defined reportable incidents, and\nSector-defined reportable incidents.DoD critical asset owners, installations, and sector CIAOs determine the DoD and sector-defined incidents.  Each of the reportable incidents or classes of incidents must include the following components:\n\nWho should monitor the incident\nHow soon the incident must be reported\nWhich information elements the incident should contain\nHow the incident reporting should be routed\nWhat follow-up actions are requiredThe National Infrastructure Protection Center (NIPC) is the primary national warning center for significant infrastructure attacks.  Critical asset owners, DoD installations, and Sector CIAOs monitor the infrastructure daily. Indications of an infrastructure incident are reported to the National Military Command Center, or NMCC.  If indications are on a computer network, they are also reported to the Joint Task Force Computer Network Operations (JTF-CNO).  The NMCC and JTF-CNO assess the indications and pass them to the NIPC and appropriate DoD organizations.  When the NIPC determines that an infrastructure event is likely to occur, is planned, or is under way, it issues a national warning. For DoD, the NIPC passes its warnings and alerts to the NMCC and JTF-CNO.  These warnings and alerts are then passed to the DoD components. The warning may include guidance regarding additional protection measures DoD should take.\n\n\n*** Phase 4:  Mitigation ***\nPhase 1 of the CIP life cycle provided a layer of protection by identifying and assessing critical assets and their vulnerabilities. Phase 2 provided another layer of protection by remediating or improving the identified deficiencies and weaknesses of an asset.  Even with these protections and precautions, an infrastructure incident was still possible. When it does the Indications and Warnings phase goes into effect.\nThe Mitigation phase (Phase 4), is made up of preplanned coordinated actions in response to infrastructure warnings or incidents. Mitigation actions are taken before or during an infrastructure event. These actions are designed to minimize the operational impact of the loss of a critical asset, facilitate incident response, and quickly restore the infrastructure service.\nA primary purpose of the Mitigation phase is to minimize the operational impact on other critical Defense Infrastructures and assets when a critical asset is lost or damaged. As an example, if there is a U.S. installation, Site A, located in a host nation. Site A is a tier 1 asset, meaning that if it fails, the Combatant Commands mission fails.  Site A has mutual Global Information Grid Command Control (GIG/C2), information interdependencies with Sites B and C.  In addition, other Defense Infrastructure sectors rely on Site A for mission capabilities.  In this scenario, what could be the impact if the supply line to the commercial power plant that provides the installation's primary power is accidentally severed.  Because of all the interdependencies, losing this asset is more than the loss of just one site. It means the loss of other sector capabilities.\nA possible mitigation action might be for Site A to go on backup power.\nAn alternate action could be to pass complete control of Site A's functionality to another site, where redundancy has been previously arranged.  These actions would limit the impact of this incident on the other sites and related sectors.  In addition to lessening the operational impact of a critical infrastructure event, the Mitigation phase of the CIP life cycle supports and complements two other life cycle phases. Mitigation actions aid in the emergency, investigation, and management activities of Phase 5, Incident Response. They also facilitate the reconstitution activities of Phase 6.\nDuring the Mitigation phase, DoD critical asset owners, DoD installations, and Sector Chief Infrastructure Assurance Officers, or CIAOs, work with the National Military Command Center (NMCC) and the Joint Task Force-Computer Network Operations (JTF-CNO) to develop, train for, and exercise mitigation responses for various scenarios.  When there is a warning, emergency, or infrastructure incident, the critical asset owners, installations, and Sector CIAOs initiate mitigation actions to sustain service to the DoD. They also provide mitigation status information to the NMCC and JTF-CNO. The NMCC monitors for consequences from an event within one Defense Infrastructure sector that are significant enough to affect other sectors. For events that cross two or more sectors, the NMCC advises on the prioritization and coordination of mitigation actions. When event threats or consequences continue to escalate, the NMCC directs mitigation actions by sector to ensure a coordinated response across the DoD. The NMCC and the JTF-CNO keep the National Infrastructure Protection Center, or NIPC, apprised of any significant mitigation activities.\n\n\n*** Phase 5:  Incident response ***\nWhen an event affects the Defense Infrastructure, the Incident Response phase begins. Incident Response is the fifth phase of the CIP life cycle.  The purpose of the Incident Response phase is to eliminate the cause or source of an infrastructure event. For example, during the 9/11 attacks on the World Trade Center and Pentagon, all non-military airplanes were grounded over the United States to prevent further incidents.  Response activities included emergency measures, not from the asset owners or operators, but from dedicated third parties such as law enforcement, medical rescue, fire rescue, hazardous material or explosives handling, and investigative agencies.  Response to Defense Infrastructure incidents can take one of two paths depending on whether or not the event affects a DoD computer network.\nWhen incidents compromise a DoD computer network, the Joint Task Force-Computer Network Operations (JTF-CNO) directs the response activities. These activities are designed to stop the computer network attack, contain and mitigate damage to a DoD information network and then restore minimum required functionality.  JTF-CNO also requests and coordinates any support or assistance from other Federal agencies and civilian organizations during incidents affecting a DoD network.  When incidents impact any other DoD owned assets, installation commanders and critical asset owners follow traditional channels and procedures to coordinate responses. This includes notifying affected Sector Chief Infrastructure Assurance Officers, or CIAOs, in the initial notice and status reporting.  Although third parties play a major role in the response to Defense Infrastructure events, DoD CIP personnel also have responsibilities to fulfill.\n\n\n*** Phase 6:  Reconstitution ***\nAfter the source or cause of an infrastructure event is eliminated or contained, the infrastructure and its capabilities must be restored.  Reconstitution is the last phase of the critical infrastructure protection. Reconstitution is probably the most challenging and least developed process of the life cycle. DoD critical asset owners have the major responsibility for reconstitution.\nQ: What is the role of the Education and Awareness Special Function Component in DoD critical infrastructure protection?",
    "context": "",
    "output": "The Education and Awareness Special Function Component is responsible for developing and implementing a comprehensive education and awareness strategy for a successful DoD CIP program.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of the Education and Awareness Special Function Component in DoD critical infrastructure protection?",
      "answer": "The Education and Awareness Special Function Component is responsible for developing and implementing a comprehensive education and awareness strategy for a successful DoD CIP program.",
      "context": "U.S. critical infrastructure protection\n\n==Introduction==\nIn the U.S., critical infrastructure protection (CIP) is a concept that relates to the preparedness and response to serious incidents that involve the critical infrastructure of a region or the nation.\nThe American Presidential directive PDD-63 of May 1998 set up a national program of \"Critical Infrastructure Protection\".  In 2014 the NIST Cybersecurity Framework was published after further presidential directives.\n\n\n\n== Overview ==\nThe systems and networks that make up the infrastructure of society are often taken for granted, yet a disruption to just one of those systems can have dire consequences across other sectors.\nTake, for example, a computer virus that disrupts the distribution of natural gas across a region. This could lead to a consequential reduction in electrical power generation, which in turn leads to the forced shutdown of computerized controls and communications. Road traffic, air traffic, and rail transportation might then become affected. Emergency services might also be hampered.\nAn entire region can become debilitated because some critical elements in the infrastructure become disabled through natural disaster. While potentially in contravention of the Geneva Conventions, military forces have also recognized that it can cripple an enemy's ability to resist by attacking key elements of its civilian and military infrastructure.\nThe federal government has developed a standardized description of critical infrastructure, in order to facilitate monitoring and preparation for disabling events. The government requires private industry in each critical economic sector to:\n\nAssess its vulnerabilities to both physical or cyber attacks\nPlan to eliminate significant vulnerabilities\nDevelop systems to identify and prevent attempted attacks\nAlert, contain and rebuff attacks and then, with the Federal Emergency Management Agency (FEMA), to rebuild essential capabilities in the aftermath\n\n\n*** Infrastructure sectors ***\nCIP defines sectors and organizational responsibilities in a standard way:\n\nBanking and finance: - The Department of the Treasury is responsible for coordinating the protection of not just systems but also maintaining public confidence, through industry initiatives such as the Financial Services Information Sharing and Analysis Center (ISAC)\nTransportation: - The Department of Transportation is responsible for protecting the road, rail, air, and water transportation infrastructure, including computer-controlled just-in-time delivery systems, optimization of distribution through hubs, and traffic and operations centers that are consolidated into key locations, and regulation of the transport of hazardous materials.\nPower: - The Department of Energy oversees energy supplies including electricity, oil, and gas, and works with the Nuclear Regulatory Commission for the protection of nuclear materials and power. Note that CIP in this sector is different from energy security, which is the politics and economics of supply. Additionally, operating under the auspices of the Federal Energy Regulatory Commission is the North American Electric Reliability Corporation (NERC), a non-profit organization that defines and enforces reliability standards for the bulk power system.\nInformation and communications: - Overseen by the Department of Commerce, most areas of life rely on telecommunications and information technology.\nFederal and municipal services: - Overseen jointly by Federal and State agencies.  They guarantee continuity of government at the federal, state, and local levels to meet for provision of essential services.\nEmergency services: - Overseen by the Health and Human Services, this includes emergency health services and public health\nFire departments: - Overseen by the Federal Emergency Management Agency FEMA.\nLaw enforcement agencies: - Overseen jointly by the Department of Justice and the Federal Bureau of Investigation to ensure the orderly running of activities during times of threat or crises.\nPublic works: - Overseen by the United States Environmental Protection Agency.  This includes safe water systems and drainage.In 2003 the remit was expanded to include:\n\nAgriculture and food, with the Department of Agriculture overseeing the safe supply of meat, poultry, and egg products.\nNational monuments and icons, under the Department of the InteriorWith much of the critical infrastructure privately owned, the Department of Defense (DoD) depends on commercial infrastructure to support its normal operations. The Department of State and the Central Intelligence Agency are also involved in intelligence analysis with friendly countries.\nIn May 2007 the DHS completed its sector-specific plans (SSP) for coordinating and dealing with critical events. the Continuity of government (COG) in time of a catastrophic event can be used to preserve the government as seen fit by the president, at which point the welfare of the government can be placed above the welfare of the citizenry of the United States ensuring that the government is preserved to rebuild the economy and country when it is deemed safe to return to the surface of the United States of America.\n\n== Significance ==\nOn March 9, 1999, Deputy Defense Secretary John Hamre warned the United States Congress of a cyber terrorist \"electronic Pearl Harbor\" saying, \"It is not going to be against Navy ships sitting in a Navy shipyard. It is going to be against commercial infrastructure\". Later this fear was qualified by President Clinton after reports of actual cyber terrorist attacks in 2000: \"I think it was an alarm. I don't think it was Pearl Harbor. We lost our Pacific fleet at Pearl Harbor. I don't think the analogous loss was that great.\"\nThere are many examples of computer systems that have been hacked or victims of extortion. One such example occurred in September 1995 where a Russian national allegedly masterminded the break-in of Citicorp's electronic funds transfer system and was ordered to stand trial in the United States. A gang of hackers under his leadership had breached Citicorp's security 40 times during 1994. They were able to transfer $12 million from customer accounts and withdraw an estimated $400,000.\nIn the past, the systems and networks of the infrastructure elements were physically and logically independent and separate. They had little interaction or connection with each other or other sectors of the infrastructure.  With advances in technology, the systems within each sector became automated, and interlinked through computers and communications facilities. As a result, the flow of electricity, oil, gas, and telecommunications throughout the country are linked\u2014albeit sometimes indirectly\u2014but the resulting linkages blur traditional security borders.\nWhile this increased reliance on interlinked capabilities helps make the economy and nation more efficient and perhaps stronger, it also makes the country more vulnerable to disruption and attack. This interdependent and interrelated infrastructure is more vulnerable to physical and cyber disruptions because it has become a complex system with single points of failure.  In the past an incident that would have been an isolated failure can now cause widespread disruption because of cascading effects. As an example, capabilities within the information and communication sector have enabled the United States to reshape its government and business processes, while becoming increasingly software driven. One catastrophic failure in this sector now has the potential to bring down multiple systems including air traffic control, emergency services, banking, trains, electrical power, and dam control.\nThe elements of the infrastructure themselves are also considered possible targets of terrorism. Traditionally, critical infrastructure elements have been lucrative targets for anyone wanting to attack another country. Now, because the infrastructure has become a national lifeline, terrorists can achieve high economic and political value by attacking elements of it. Disrupting or even disabling the infrastructure may reduce the ability to defend the nation, erode public confidence in critical services, and reduce economic strength.  Additionally, well chosen terrorist attacks can become easier and less costly than traditional warfare because of the interdependence of infrastructure elements. These infrastructure elements can become easier targets where there is a low probability of detection.\nThe elements of the infrastructure are also increasingly vulnerable to a dangerous mix of traditional and nontraditional types of threats. Traditional and non-traditional threats include equipment failures, human error, weather and natural causes, physical attacks, and cyber attacks. For each of these threats, the cascading effect caused by single points of failure has the potential to pose dire and far-reaching consequences.\n\n\n*** Challenges ***\nThere are fears that the frequency and severity of critical infrastructure incidents will increase in the future.Although efforts are under way, there is no unified national capability to protect the interrelated aspects of the country's infrastructure. One reason for this is that a good understanding of the inter-relationships does not exist. There is also no consensus on how the elements of the infrastructure mesh together, or how each element functions and affects the others.  Securing national infrastructure depends on understanding the relationships among its elements. Thus when one sector scheduled a three-week drill to mimic the effects of a pandemic flu, even though two-thirds of the participants claimed to have business continuity plans in place, barely half reported that their plan was moderately effective.Critical infrastructure protection requires the development of a national capability to identify and monitor the critical elements and to determine when and if the elements are under attack or are the victim of destructive natural occurrences. CIP is important because it is the link between risk management and infrastructure assurance. It provides the capability needed to eliminate potential vulnerabilities in the critical infrastructure.\nCIP practitioners determine vulnerabilities and analyze alternatives in order to prepare for incidents. They focus on improving the capability to detect and warn of impending attacks on, and system failures within, the critical elements of the national infrastructure.\n\n== Organization and structure ==\nPDD-63 mandated the formation of a national structure for critical infrastructure protection. To accomplish this one of the primary actions was to produce a National Infrastructure Assurance Plan, or NIAP, later renamed National Infrastructure Protection Plan or NIPP.\nThe different entities of the national CIP structure work together as a partnership between the government and the public sectors. Each department and agency of the federal government is responsible for protecting its portion of the government's critical infrastructure. In addition, there are grants made available through the Department of Homeland Security for municipal and private entities to use for CIP and security purposes. These include grants for emergency management, water security training, rail, transit and port security, metropolitan medical response, LEA terrorism prevention programs and the Urban Areas Security Initiative.PDD-63 identified certain functions related to critical infrastructure protection that must be performed chiefly by the federal government. These are national defense, foreign affairs, intelligence, and law enforcement. Each lead agency for these special functions appoints a senior official to serve as a functional coordinator for the federal government. In 2008 a mobile PDA-based Vulnerability Assessment Security Survey Tool (VASST) was introduced to speed physical security assessment of critical infrastructure by law enforcement to meet compliance requirements of PDD-63.\n\n\n*** National Infrastructure Assurance Plan / National Infrastructure Protection Plan ***\n\nFor each of the identified major sectors of the critical infrastructure, the federal government appointed a Sector Liaison Official from a designated Lead Agency.  A private sector counterpart, a Sector Coordinator, was also identified. Together, the two sector representatives, one federal government and one corporate, were responsible for developing a sector NIAP.\nIn addition, each department and agency of the federal government was responsible for developing its own CIP plan for protecting its portion of the federal government's critical infrastructure.  The federal department and agency plans were assimilated with the sector NIAPs to create one comprehensive National Infrastructure Assurance Plan.  Additionally the national structure must ensure there is a national CIP program. This program includes responsibilities such as education and awareness, threat assessment and investigation, and research.\nThe process includes assessments of:\n\nProtection -  Can be defined as the state of being defended, safeguarded, or shielded from injury, loss, or destruction from natural or unnatural forces.\nVulnerability \u2013 The quality of being susceptible to attack or injury, warranted or unwarranted, by accident or by design.\nRisk \u2013 The possibility or likelihood of being attacked or injured.\nMitigation \u2013 The ability to alleviate, reduce, or moderate a vulnerability, thus reducing or eliminating risk.\n\n\n*** Controversy ***\nThere have been public criticisms of the mechanisms and implementation of some security initiatives and grants, with claims they are being led by the same companies who can benefit, and that they are encouraging an unnecessary culture of fear. Commentators note that these initiatives started directly after the collapse of the Cold War, raising the concern that this was simply a diversion of the military-industrial complex away from a funding area which was shrinking and into a richer previously civilian arena.\nGrants have been distributed across the different states even though the perceived risk is not evenly spread, leading to accusations of pork barrel politics that directs money and jobs towards marginal voting areas. The Urban Areas Security Initiative grant program has been particularly controversial, with the 2006 infrastructure list covering 77,000 assets, including a popcorn factory and a hot dog stand.   The 2007 criteria were reduced to 2,100 and now those facilities must make a much stronger case to become eligible for grants. While well-intentioned, some of the results have also been questioned regarding claims of poorly designed and intrusive security theater that distracts attention and money from more pressing issues or creates damaging side effects.\nAn absence of comparative risk analysis and benefits tracking it has made it difficult to counter such allegations with authority. In order to better understand this, and ultimately direct effort more productively, a Risk Management and Analysis Office was recently created in the National Protection and Programs directorate at the Department of Homeland Security.\n\n== Department of Defense and CIP ==\nThe U.S. Department of Defense is responsible for protecting its portion of the government's critical infrastructure.  But as part of the CIP program, DoD has responsibilities that traverse both the national and department-wide critical infrastructure.\nPDD-63 identified the responsibilities DoD had for critical infrastructure protection. First, DoD had to identify its own critical assets and infrastructures and provide assurance through analysis, assessment, and remediation.  DoD was also responsible for identifying and monitoring the national and international infrastructure requirements of industry and other government agencies, all of which needed to be included in the protection planning.  DoD also addressed the assurance and protection of commercial assets and infrastructure services in DoD acquisitions.  Other DoD responsibilities for CIP included assessing the potential impact on military operations that would result from the loss or compromise of infrastructure service.  There were also requirements for monitoring DoD operations, detecting and responding to infrastructure incidents, and providing department indications and warnings as part of the national process.  Ultimately, DoD was responsible for supporting national critical infrastructure protection.\nIn response to the requirements identified in PDD-63, DoD categorized its own critical assets by sector, in a manner similar to the national CIP organization. The DoD identified a slightly different list of infrastructure sectors for those areas that specifically required protection by DoD.  DoD's organizational structure for critical infrastructure protection reflects, complements, and effectively interacts with the national structure for CIP.\n\n\n*** DoD sectors ***\nThere are ten defense critical infrastructure sectors that are protected by the DoD. These include:\n\nFinancial Services - Defense financial services support activities related to officially appropriated funds. These activities include the disbursement of cash, receipt of funds, and acceptance of deposits for credit to officially designated Treasury general accounts. This sector also provides financial services to individuals and on-base organizations, including deposits, account maintenance, and safekeeping. The Defense Finance and Accounting Service is the lead component for the Financial Services sector.\nTransportation - The Defense Transportation System, or DTS, includes resources that support global DoD transportation needs. These include surface, sea, and lift assets; supporting infrastructure; personnel; and related systems. Transportation Command, or USTRANSCOM, is the single manager for DoD transportation.\nPublic Works - Public works includes four distinct physical infrastructure sectors: electric power, oil, and natural gas, water and sewer; and emergency services, such as fire, medical, and hazardous material handling.  This defense infrastructure sector is composed of networks and systems, principally for the distribution of the associated commodities.  The Corps of Engineers is responsible for coordinating the assurance activities of the public works infrastructure sector.\nGlobal Information Grid Command Control, or GIG/C2 - The Global Information Grid Command Control, or GIG/C2, are two combined sectors that support overall asset assurance for CIP.  The GIG is the globally interconnected set of personnel, information, and communication capabilities necessary to achieve information superiority. C2 includes assets, facilities, networks, and systems that support mission accomplishment.  The Defense Information Systems Agency, or DISA, is the lead component responsible for Global Information Grid Command Control.\nIntelligence Surveillance, and Reconnaissance, or ISR - The Defense Intelligence, Surveillance and Reconnaissance infrastructure sector is composed of facilities, networks, and systems that support ISR activities such as intelligence production and fusion centers.  The Defense Intelligence Agency, or DIA, is responsible for coordinating the assurance activities of this infrastructure sector.\nHealth Affairs - The health care infrastructure consists of facilities and sites worldwide. Some are located at DoD installations; however, DoD also manages a larger system of non-DoD care facilities within its health care network. These health care facilities are linked by information systems. The Office of the Assistant Secretary of Defense, Health Affairs is the designated lead component for this sector.\nPersonnel - The defense personnel infrastructure sector includes a large number of assets hosted on component sites, a network of facilities, and information systems linking those sites and facilities. In addition to being responsible for its own assets, the personnel infrastructure sector also coordinates commercial services that support the personnel function. These services include recruitment, record keeping, and training. The Defense Human Resources Activity is the designated lead component for the Defense Personnel infrastructure sector.\nSpace - The defense space infrastructure sector is composed of both space- and ground-based assets including launch, specialized logistics, and control systems. Facilities are located worldwide on both DoD-controlled and private sites. The Defense Space sector is led by the United States Strategic Command, or USSTRATCOM.\nLogistics - The defense logistics sector includes all activities, facilities, networks, and systems that support the provision of supplies and services to U.S. forces worldwide.  Logistics includes the acquisition, storage, movement, distribution, and maintenance of material and supplies. This sector also includes the final disposition of material no longer needed by DoD. The Defense Logistics Agency, or DLA, is the lead component for the DoD Logistics infrastructure.\nDefense Industrial Base - The Defense Industrial Base consists of DoD product and service providers from the private sector. The services and products provided constitute critical assets for DoD.  The lead component for the Defense Industrial Base is the Defense Contract Management Agency.  For those cases when infrastructure protection requirements affect more than one defense sector, DoD has set up special function components that support the implementation of CIP.\n\n\n*** DoD special functions ***\nThe DoD CIP special function components interface with the equivalent national functional coordinators and coordinate all activities related to their function within DoD.\nDoD's special function components currently include seven areas of focus.  They include the following components:\n\nPolicy and Strategy - The Policy and Strategy Special Function Component provides the strategic planning required to prepare our Armed Forces for the 21st century. In part, it satisfies this responsibility through the development of the National Military Strategy.  Within the area of policy development it is responsible for leading the chairman's biennial review of the Unified Command Plan and developing Joint Staff positions on such key issues as the organization, roles and missions, and functions of the Armed Forces and the combatant commands.\nIntelligence Support - The CIP Intelligence Support Special Function Component provides intelligence support to DoD in protection of the Defense portion of the Federal Government Critical Infrastructure. Intelligence Support responsibilities also include supporting the Defense Warning System, Alert and Notification, and interfacing with the national intelligence community.  The responsibilities of the Intelligence Support agencies include such activities as provisioning threat assessments; indications and warnings of potential attacks; advice and support to Sector CIAOs in the development of defense infrastructure sector monitoring and reporting; crisis management support; and counter-intelligence. This special function component is also tasked with the support to the DoD contingent of the NIPC related to intelligence and counter-intelligence.\nIndustrial Policy - The Under Secretary of Defense for Acquisition, Technology & Logistics ensures that an adequate defense industrial base exists and remains viable to meet current, future, and emergent national security requirements.\"\nDefense Security - The Defense Security Service provides to the Department of Defense and other Federal agencies an array of security products and services which are designed to deter and detect espionage\nInformation Assurance - The Assistant Secretary of Defense for Networks and Information Integration, or ASD NII, is the principal OSD staff assistant for the development, oversight, and integration of DoD policies and programs relating to the strategy of information superiority for the Department of Defense. Information Assurance, or IA, is the component of Information Operations that assures DoD's operational readiness by providing for the continuous availability and reliability of information systems and networks. IA protects the DII against exploitation, degradation, and denial of service, while providing the means to efficiently reconstitute and reestablish vital capabilities following an attack.\nResearch and Development - The Research and Development Special Function Component is responsible for information assurance and protection. The Office of Director, Defense Research and Engineering coordinates a CIP DoD research and development agenda. As well as reconciling the DoD agenda with the national R&D agenda.\nEducation and Awareness - Although education and awareness may rightly be considered everyone's responsibility, a comprehensive education and awareness strategy was deemed essential for a successful DoD CIP program. The National Defense University, or NDU, provided advice and assistance in assessing DoD education and awareness requirements. The Education and Awareness Component also developed the CIAO Education Program. This component was tasked to assist in the development of any special education or training required for CIP crisis management personnel.  Education and Awareness also supports both DoD and national CIP policy and strategy formulation and executive leadership development through periodic \"infrastructure games\".\n\n== DoD CIP lifecycle ==\nAs mandated by PDD-63, the DoD must protect its portion of the federal government's critical infrastructure. For DoD, this is the Defense Infrastructure or DI. Protecting the Defense Infrastructure is a complex task involving ten defense sectors.\nIt was deemed that it was nearly impossible to protect every critical asset at every location, therefore the focus was directed on protecting the critical Defense Infrastructure. The critical Defense Infrastructure is the critical assets essential to providing mission assurance.\n\n\n*** Six phases ***\nThe six phases of the DoD CIP life cycle build on one another to create a framework for a comprehensive solution for infrastructure assurance.  The life cycle phases occur before, during, and after an event that may compromise or degrade the infrastructure.  A synopsis of the six phases are:\n\nAnalysis and Assessment (occurs before an event) - The Analysis and Assessment phase is the foundation and most important phase of the CIP life cycle. This phase identifies the assets absolutely critical to mission success and determines the assets\u2019 vulnerabilities, as well as their interdependencies, configurations, and characteristics.  An assessment is then made of the operational impact of infrastructure loss or degradation. In addition, Proactive Cyber Defence may anticipate an attack against computers and networks.  It applies equally well to all critical infrastructure sectors, as it involves interdicting and disrupting an attack or a threat's preparation to attack, either preemptively or in self-defense.\nRemediation (occurs before an event) - The Remediation phase involves precautionary measures and actions taken before an event occurs to fix the known cyber and physical vulnerabilities that could cause an outage or compromise a National Defense Infrastructure, or NDI, or critical asset.  For example, remediation actions may include education and awareness, operational process or procedural changes or system configuration and component changes.\nIndications and Warnings (occurs before and/or during an event) - The Indications and Warnings phase involves daily sector monitoring to assess the mission assurance capabilities of critical infrastructure assets and to determine if there are event indications to report.  Indications are preparatory actions that indicate whether an infrastructure event is likely to occur or is planned.  Indications are based on input at the tactical, operational, theater, and strategic level.  At the tactical level, input comes from asset owners. At the operational level, input comes from the NDI sectors.  At the theater level, input comes from regional assets such as allied intelligence, NATO, command intelligence, allied governments, and coalition forces.  At the strategic level, input comes from intelligence, law-enforcement, and the private sector.  Warning is the process of notifying asset owners of a possible threat or hazard.\nMitigation (occurs both before and during an event) - The Mitigation phase comprises actions taken before or during an event in response to warnings or incidents. DoD Critical Asset owners, NDI sectors, DoD installations, and military operators take these actions to minimize the operational impact of a critical asset's loss or debilitation.\nIncident Response (occurs after an event) - Incident Response comprises the plans and activities taken to eliminate the cause or source of an infrastructure event.\nReconstitution (occurs after an event)  - The last phase of the CIP life cycle, involves actions taken to rebuild or restore a critical asset capability after it has been damaged or destroyed. This phase is the most challenging and least developed process.Effective management of the CIP life cycle ensures that protection activities can be coordinated and reconciled among all DoD sectors. In many ways, DoD CIP, is risk management at its most imperative.  Achieving success means obtaining mission assurance. Missing the mark can mean mission failure as well as human and material losses. For critical infrastructure protection, risk management requires leveraging resources to address the most critical infrastructure assets that are also the most vulnerable and that have the greatest threat exposure.\nThe most important part of the CIP lifecycle is Phase 1.  Because it is crucial to target the right assets for infrastructure protection, determining these assets is the first phase in the CIP life cycle. This phase, Analysis and Assessment, is the key and foundation of the seven lifecycle activities.  Without a solid foundation, the remaining CIP life cycle phases may be flawed, resulting in a CIP plan that fails to protect the critical infrastructure and, therefore, mission assurance.\n\n\n*** Phase 1: Analysis and Assessment ***\nPhase 1 determines what assets are important, and identifies their vulnerabilities, and dependencies so that decision makers have the information they need to make effective risk management choices.\nThe Defense Infrastructure, or DI, is organized into ten sectors. Each sector is composed of assets, such as systems, programs, people, equipment, or facilities. Assets may be simple, such as one facility within one geographic location, or complex, involving geographically dispersed links and nodes.\nThe Analysis and Assessment is made up of five steps that include activities that span and encompass the ten DI sectors and their assets.\n\nI.  The first step in the Analysis and Assessment phase is to identify critical assets.  An asset's criticality is a function of both time and situation based on the asset's operational or business value. For the DI, value depends on several factors:  First, what military operations or services rely on an asset and how those dependencies change across time Next, how sensitive the operation is to the loss or compromise of the asset, in other words what is the maximum allowable down time if the asset is compromised. Finally, what the asset's assurance profile is, in particular whether asset restoration or a switch to a backup can occur within the allowable down time. Through domain expertise and inspection, critical assets are identified and then reported to the CIP Program.\nII.  The second step of the Analysis and Assessment phase is Defense Infrastructure characterization. This step maps and associates critical asset functions and relationships within a DI sector.\nIII.  The third step in the Analysis and Assessment phase is the Operational Impact Analysis. This step is accomplished through the development of operational dependency matrices and the application of operations research methods. Potential operational impacts and service-level requirements are then reflected in the asset's criticality attributes and criticality index in the CIP program.\nIV.  The fourth step is the Vulnerability Assessment.  This step is accomplished through multiple channels.  Through the CIP program, all critical assets have a baseline vulnerability index, which is calculated from inputs associated with the class of asset and geographic region such as the probability of natural disasters, criminal or national security events, and technological failures.  Asset owners, host installations, the sector CIAO, or other DoD entities may provide asset operational readiness and emergency preparedness information.\nV.  The fifth and final step in the Analysis and Assessment phase is Interdependency Analysis. Interdependency analysis seeks to map functions and relationships among DI sectors.  As a result of the Interdependency Analysis, the criticality attributes for previously identified assets may be updated and additional critical assets may be identified to the CIP program.  Multiple groups within the DoD CIP structure perform analysis and assessment activities.  Translating the analysis and assessment process into concrete data requires specific activities, tasks, and tools.\n\n\n**** Phase 1 Example in the \u201cReal World\u201d ****\nOn August 24, 2001, the Director of the Joint Staff requested USPACOM to serve as the lead support Combatant Command for creating a CIP first-ever theater CIP Plan \u2013 known as the \u201cCIP Appendix 16 Plan\u201d. The following is how USPACOM approached the task.\nUSPACOM focused the Analysis and Assessment phase by organizing its activities to answer three major questions:\n\nWhat is critical?\nIs it vulnerable?\nWhat can be done?To answer the question, \u201cWhat is critical?\u201d, USPACOM outlined a three-step procedure:\n\nFirst, identify the project focus.\nSecond, complete an operational analysis.\nThird, complete a Defense Infrastructure analysis.To accomplish these steps, USPACOM adopted a methodology that focuses its CIP efforts on Tier 1 assets. Tier 1 assets are assets that could cause mission failure if they are compromised or damaged.  The methodology UAPACOM adopted and modified is Mission Area Analysis, or MAA.  The MAA links combatant command missions to infrastructure assets that are critical to a given Operations Plan, or OPLAN, Contingency Plan, or CONPLAN, or Crisis Action Plan. Typically, the MAA process determines the assessment site priorities.  USPACOM modified the process and selected the CIP assessment sites and installations prior to conducting the MAA.  The following is an illustration of the USPACOM MAA process:\n\nFirst, it identified the Mission Essential Requirements, or MERs, which are specific combatant commands or joint task force capabilities essential for execution of a warfighting plan. Then, they created an MER matrix for the specific command. For example, one MER may be to provide command, control, communications, and computers, or C4.\nSecond, it identified forces required for each MER. For example, the C4 MER is linked to a specific signal battalion. Third, it linked the forces to the necessary functions and tasks supporting the force. For example, the signal battalion is linked to the Communications and Civil Engineers functions and the task of managing the theater's C4 information systems requirements.\nThird, it links assets to the functions supporting the tasks. The result is a mission area analysis of mission-critical assets.USPACOM uses the MAA data it gathers to scope and focus its efforts on truly mission-critical assets to answer the next question in its process, Is it vulnerable?\nThe first step in answering this question is to complete an installation analysis. The next step is to complete a commercial infrastructure analysis. USPACOM relied upon two different DoD organizations for CIP assessments: Balanced Survivability Assessments, or BSAs, and Mission Assurance Assessments.  The BSA is a two-week mission-focused assessment at a military installation or designated site.  A Mission Assurance Assessment is unique because it uses an area assessment approach to focus on both commercial and military asset vulnerabilities and dependencies.  The final step to determine vulnerabilities is to integrate the two analyses and assessments.  With its critical assets and their vulnerabilities identified, USPACOM is ready to perform risk management activities to decide what can be done to protect the mission-critical assets.\nBooz Allen Hamilton developed this process at PACOM.\n\n\n*** Phase 2: Remediation ***\nThe first phase of the CIP life cycle, Analysis and Assessment, identified the critical assets of DoD sector infrastructures and the vulnerabilities or weaknesses of those critical assets.\nThe second phase is the Remediation phase. In the Remediation phase, the known weaknesses and vulnerabilities are addressed. Remediation actions are deliberate, precautionary measures designed to fix known virtual and physical vulnerabilities before an event occurs. The purpose of remediation is to improve the reliability, availability, and survivability of critical assets and infrastructures.  Remediation actions apply to any type of vulnerability, regardless of its cause. They apply to acts of nature, technology failures, or deliberate malicious actions.\nThe cost of each remediation action depends on the nature of the vulnerability it addresses. The Defense Infrastructure Sector Assurance Plan that each infrastructure sector must develop, establishes the priorities and resources for remediation. Remediation requirements are determined by multiple factors. These are analysis and assessment, input from military planners and other DoD sectors, the National Infrastructure Assurance Plan and other plans, reports, and information on national infrastructure vulnerabilities and remediation, as well as intelligence estimates and assessments of threats.\nRemediation requirements are also gathered through lessons learned from Defense Infrastructure sector monitoring and reporting and infrastructure protection operations and exercises.  The CIP program tracks the status of remediation activities for critical assets. Remediation activities to protect the critical Defense Infrastructure cross multiple Department components.\n\n\n*** Phase 3:  Indications and Warnings ***\nThe need to monitor activities and warn of potential threats to the United States is not new. From conventional assaults to potential nuclear attacks, the military has been at the forefront of monitoring and warning of potential dangers since the founding of the country.  Protecting the security and well-being of the United States, including the critical Defense Infrastructure, has now entered a new era. It has been deemed essential to have a coordinated ability to identify and warn of potential or actual incidents among critical infrastructure domains. The ability to detect and warn of infrastructure events is the third phase of the critical infrastructure protection life cycle, the Indications and Warnings phase.\nIndications and warnings are actions or infrastructure conditions that signal an event is either:\n\nLikely,\nPlanned or\nUnderway.Historically, DoD event indications have focused and relied on intelligence information about foreign developments.  These event indications have been expanded to include all potential infrastructure disruption or degradation, regardless of its cause.  DoD CIP indications are based on four levels of input:\n\nTactical level input from DoD asset owners or installations\nOperational-level input from sector Chief Information Assurance Officers (CIAOs)\nTheater-level input from command and service intelligence and counter-intelligence activities.\nStrategic-level intelligence from the intelligence community, law enforcement, and the private sectorThis fusion of traditional intelligence information with sector-specific information has been determined to be essential for meaningful CIP indications.\nIf an indication is detected, a warning notifying the appropriate asset owners of a possible or occurring event or hazard can be issued.  The sector's assurance plan determines what conditions and actions are monitored and reported for each Defense Infrastructure Sector. Each sector must develop a written Defense Sector Assurance Plan that includes a compendium of sector incidents for monitoring and reporting. The sector incident compendium is made up of three types of incidents:\n\nNationally defined reportable incidents\nDoD defined reportable incidents, and\nSector-defined reportable incidents.DoD critical asset owners, installations, and sector CIAOs determine the DoD and sector-defined incidents.  Each of the reportable incidents or classes of incidents must include the following components:\n\nWho should monitor the incident\nHow soon the incident must be reported\nWhich information elements the incident should contain\nHow the incident reporting should be routed\nWhat follow-up actions are requiredThe National Infrastructure Protection Center (NIPC) is the primary national warning center for significant infrastructure attacks.  Critical asset owners, DoD installations, and Sector CIAOs monitor the infrastructure daily. Indications of an infrastructure incident are reported to the National Military Command Center, or NMCC.  If indications are on a computer network, they are also reported to the Joint Task Force Computer Network Operations (JTF-CNO).  The NMCC and JTF-CNO assess the indications and pass them to the NIPC and appropriate DoD organizations.  When the NIPC determines that an infrastructure event is likely to occur, is planned, or is under way, it issues a national warning. For DoD, the NIPC passes its warnings and alerts to the NMCC and JTF-CNO.  These warnings and alerts are then passed to the DoD components. The warning may include guidance regarding additional protection measures DoD should take.\n\n\n*** Phase 4:  Mitigation ***\nPhase 1 of the CIP life cycle provided a layer of protection by identifying and assessing critical assets and their vulnerabilities. Phase 2 provided another layer of protection by remediating or improving the identified deficiencies and weaknesses of an asset.  Even with these protections and precautions, an infrastructure incident was still possible. When it does the Indications and Warnings phase goes into effect.\nThe Mitigation phase (Phase 4), is made up of preplanned coordinated actions in response to infrastructure warnings or incidents. Mitigation actions are taken before or during an infrastructure event. These actions are designed to minimize the operational impact of the loss of a critical asset, facilitate incident response, and quickly restore the infrastructure service.\nA primary purpose of the Mitigation phase is to minimize the operational impact on other critical Defense Infrastructures and assets when a critical asset is lost or damaged. As an example, if there is a U.S. installation, Site A, located in a host nation. Site A is a tier 1 asset, meaning that if it fails, the Combatant Commands mission fails.  Site A has mutual Global Information Grid Command Control (GIG/C2), information interdependencies with Sites B and C.  In addition, other Defense Infrastructure sectors rely on Site A for mission capabilities.  In this scenario, what could be the impact if the supply line to the commercial power plant that provides the installation's primary power is accidentally severed.  Because of all the interdependencies, losing this asset is more than the loss of just one site. It means the loss of other sector capabilities.\nA possible mitigation action might be for Site A to go on backup power.\nAn alternate action could be to pass complete control of Site A's functionality to another site, where redundancy has been previously arranged.  These actions would limit the impact of this incident on the other sites and related sectors.  In addition to lessening the operational impact of a critical infrastructure event, the Mitigation phase of the CIP life cycle supports and complements two other life cycle phases. Mitigation actions aid in the emergency, investigation, and management activities of Phase 5, Incident Response. They also facilitate the reconstitution activities of Phase 6.\nDuring the Mitigation phase, DoD critical asset owners, DoD installations, and Sector Chief Infrastructure Assurance Officers, or CIAOs, work with the National Military Command Center (NMCC) and the Joint Task Force-Computer Network Operations (JTF-CNO) to develop, train for, and exercise mitigation responses for various scenarios.  When there is a warning, emergency, or infrastructure incident, the critical asset owners, installations, and Sector CIAOs initiate mitigation actions to sustain service to the DoD. They also provide mitigation status information to the NMCC and JTF-CNO. The NMCC monitors for consequences from an event within one Defense Infrastructure sector that are significant enough to affect other sectors. For events that cross two or more sectors, the NMCC advises on the prioritization and coordination of mitigation actions. When event threats or consequences continue to escalate, the NMCC directs mitigation actions by sector to ensure a coordinated response across the DoD. The NMCC and the JTF-CNO keep the National Infrastructure Protection Center, or NIPC, apprised of any significant mitigation activities.\n\n\n*** Phase 5:  Incident response ***\nWhen an event affects the Defense Infrastructure, the Incident Response phase begins. Incident Response is the fifth phase of the CIP life cycle.  The purpose of the Incident Response phase is to eliminate the cause or source of an infrastructure event. For example, during the 9/11 attacks on the World Trade Center and Pentagon, all non-military airplanes were grounded over the United States to prevent further incidents.  Response activities included emergency measures, not from the asset owners or operators, but from dedicated third parties such as law enforcement, medical rescue, fire rescue, hazardous material or explosives handling, and investigative agencies.  Response to Defense Infrastructure incidents can take one of two paths depending on whether or not the event affects a DoD computer network.\nWhen incidents compromise a DoD computer network, the Joint Task Force-Computer Network Operations (JTF-CNO) directs the response activities. These activities are designed to stop the computer network attack, contain and mitigate damage to a DoD information network and then restore minimum required functionality.  JTF-CNO also requests and coordinates any support or assistance from other Federal agencies and civilian organizations during incidents affecting a DoD network.  When incidents impact any other DoD owned assets, installation commanders and critical asset owners follow traditional channels and procedures to coordinate responses. This includes notifying affected Sector Chief Infrastructure Assurance Officers, or CIAOs, in the initial notice and status reporting.  Although third parties play a major role in the response to Defense Infrastructure events, DoD CIP personnel also have responsibilities to fulfill.\n\n\n*** Phase 6:  Reconstitution ***\nAfter the source or cause of an infrastructure event is eliminated or contained, the infrastructure and its capabilities must be restored.  Reconstitution is the last phase of the critical infrastructure protection. Reconstitution is probably the most challenging and least developed process of the life cycle. DoD critical asset owners have the major responsibility for reconstitution."
    }
  },
  {
    "instruction": "Stack buffer overflow\n\n==Introduction==\nIn software, a stack buffer overflow or stack buffer overrun occurs when a program writes to a memory address on the program's call stack outside of the intended data structure, which is usually a fixed-length buffer.\nStack buffer overflow bugs are caused when a program writes more data to a buffer located on the stack than what is actually allocated for that buffer. This almost always results in corruption of adjacent data on the stack, and in cases where the overflow was triggered by mistake, will often cause the program to crash or operate incorrectly. Stack buffer overflow is a type of the more general programming malfunction known as buffer overflow (or buffer overrun). Overfilling a buffer on the stack is more likely to derail program execution than overfilling a buffer on the heap because the stack contains the return addresses for all active function calls.\nA stack buffer overflow can be caused deliberately as part of an attack known as stack smashing. If the affected program is running with special privileges, or accepts data from untrusted network hosts (e.g. a webserver) then the bug is a potential security vulnerability. If the stack buffer is filled with data supplied from an untrusted user then that user can corrupt the stack in such a way as to inject executable code into the running program and take control of the process. This is one of the oldest and more reliable methods for attackers to gain unauthorized access to a computer.\n\n== Exploiting stack buffer overflows ==\nThe canonical method for exploiting a stack-based buffer overflow is to overwrite the function return address with a pointer to attacker-controlled data (usually on the stack itself). This is illustrated with strcpy() in the following example:\n\nThis code takes an argument from the command line and copies it to a local stack variable c. This works fine for command-line arguments smaller than 12 characters (as can be seen in figure B below). Any arguments larger than 11 characters long will result in corruption of the stack. (The maximum number of characters that is safe is one less than the size of the buffer here because in the C programming language, strings are terminated by a null byte character. A twelve-character input thus requires thirteen bytes to store, the input followed by the sentinel zero byte. The zero byte then ends up overwriting a memory location that's one byte beyond the end of the buffer.)\nThe program stack in foo() with various inputs:\n\nIn figure C above, when an argument larger than 11 bytes is supplied on the command line foo() overwrites local stack data, the saved frame pointer, and most importantly, the return address. When foo() returns it pops the return address off the stack and jumps to that address (i.e. starts executing instructions from that address). Thus, the attacker has overwritten the return address with a pointer to the stack buffer char c[12], which now contains attacker-supplied data. In an actual stack buffer overflow exploit the string of \"A\"'s would instead be shellcode suitable to the platform and desired function. If this program had special privileges (e.g. the SUID bit set to run as the superuser), then the attacker could use this vulnerability to gain superuser privileges on the affected machine.The attacker can also modify internal variable values to exploit some bugs.\nWith this example:\n\n== Platform-related differences ==\nA number of platforms have subtle differences in their implementation of the call stack that can affect the way a stack buffer overflow exploit will work. Some machine architectures store the top-level return address of the call stack in a register. This means that any overwritten return address will not be used until a later unwinding of the call stack. Another example of a machine-specific detail that can affect the choice of exploitation techniques is the fact that most RISC-style machine architectures will not allow unaligned access to memory. Combined with a fixed length for machine opcodes, this machine limitation can make the technique of jumping to the stack almost impossible to implement (with the one exception being when the program actually contains the unlikely code to explicitly jump to the stack register).\n\n\n*** Stacks that grow up ***\nWithin the topic of stack buffer overflows, an often-discussed-but-rarely-seen architecture is one in which the stack grows in the opposite direction. This change in architecture is frequently suggested as a solution to the stack buffer overflow problem because any overflow of a stack buffer that occurs within the same stack frame cannot overwrite the return pointer. However, any overflow that occurs in a buffer from a previous stack frame will still overwrite a return pointer and allow for malicious exploitation of the bug. For instance, in the example above, the return pointer for foo will not be overwritten because the overflow actually occurs within the stack frame for memcpy. However, because the buffer that overflows during the call to memcpy resides in a previous stack frame, the return pointer for memcpy will have a numerically higher memory address than the buffer. This means that instead of the return pointer for foo being overwritten, the return pointer for memcpy will be overwritten. At most, this means that growing the stack in the opposite direction will change some details of how stack buffer overflows are exploitable, but it will not reduce significantly the number of exploitable bugs.\n\n== Protection schemes ==\n\nOver the years, a number of control-flow integrity schemes have been developed to inhibit malicious stack buffer overflow exploitation. These may usually be classified into three categories:\n\nDetect that a stack buffer overflow has occurred and thus prevent redirection of the instruction pointer to malicious code.\nPrevent the execution of malicious code from the stack without directly detecting the stack buffer overflow.\nRandomize the memory space such that finding executable code becomes unreliable.\n\n\n*** Stack canaries ***\n\nStack canaries, named for their analogy to a canary in a coal mine, are used to detect a stack buffer overflow before execution of malicious code can occur. This method works by placing a small integer, the value of which is randomly chosen at program start, in memory just before the stack return pointer. Most buffer overflows overwrite memory from lower to higher memory addresses, so in order to overwrite the return pointer (and thus take control of the process) the canary value must also be overwritten. This value is checked to make sure it has not changed before a routine uses the return pointer on the stack. This technique can greatly increase the difficulty of exploiting a stack buffer overflow because it forces the attacker to gain control of the instruction pointer by some non-traditional means such as corrupting other important variables on the stack.\n\n\n*** Nonexecutable stack ***\n\nAnother approach to preventing stack buffer overflow exploitation is to enforce a memory policy on the stack memory region that disallows execution from the stack (W^X, \"Write XOR Execute\"). This means that in order to execute shellcode from the stack an attacker must either find a way to disable the execution protection from memory, or find a way to put their shellcode payload in a non-protected region of memory. This method is becoming more popular now that hardware support for the no-execute flag is available in most desktop processors.\nWhile this method prevents the canonical stack smashing exploit, stack overflows can be exploited in other ways. First, it is common to find ways to store shellcode in unprotected memory regions like the heap, and so very little need change in the way of exploitation.Another attack is the so-called return to libc method for shellcode creation. In this attack the malicious payload will load the stack not with shellcode, but with a proper call stack so that execution is vectored to a chain of standard library calls, usually with the effect of disabling memory execute protections and allowing shellcode to run as normal. This works because the execution never actually vectors to the stack itself.\nA variant of return-to-libc is return-oriented programming (ROP), which sets up a series of return addresses, each of which executes a small sequence of cherry-picked machine instructions within the existing program code or system libraries, sequence which ends with a return. These so-called gadgets each accomplish some simple register manipulation or similar execution before returning, and stringing them together achieves the attacker's ends. It is even possible to use \"returnless\" return-oriented programming by exploiting instructions or groups of instructions that behave much like a return instruction.\n\n\n*** Randomization ***\nInstead of separating the code from the data, another mitigation technique is to introduce randomization to the memory space of the executing program. Since the attacker needs to determine where executable code that can be used resides, either an executable payload is provided (with an executable stack) or one is constructed using code reuse such as in ret2libc or return-oriented programming (ROP). Randomizing the memory layout will, as a concept, prevent the attacker from knowing where any code is. However, implementations typically will not randomize everything; usually the executable itself is loaded at a fixed address and hence even when ASLR (address space layout randomization) is combined with a nonexecutable stack the attacker can use this fixed region of memory. Therefore, all programs should be compiled with PIE (position-independent executables) such that even this region of memory is randomized. The entropy of the randomization is different from implementation to implementation and a low enough entropy can in itself be a problem in terms of brute forcing the memory space that is randomized.\n\n\n*** Bypass countermeasures ***\nThe previous mitigations make the steps of the exploitation harder. But it is still possible to exploit a stack buffer overflow if some vulnerabilities are presents or if some conditions are met.\n\n\n**** Stack canary bypass ****\n\n\n***** Information leak with format string vulnerability exploitation*****\nAn attacker is able to exploit the format string vulnerability for revealing the memory locations in the vulnerable program.\n\n\n**** Non executable stack bypass ****\nWhen Data Execution Prevention is enabled to forbid any execute access to the stack, the attacker can still use the overwritten return address (the instruction pointer) to point to data in a code segment (.text on Linux) or every other executable section of the program. The goal is to reuse existing code.\n\n\n***** Rop chain*****\nConsists to overwrite the return pointer a bit before a return instruction (ret in x86) of the program. The instructions between the new return pointer and the return instruction will be executed and the return instruction will return to the payload controlled by the exploiter.\n\n\n***** Jop chain*****\nJump Oriented Programming is a technique that uses jump instructions to reuse code instead of ret instruction.\n\n\n**** Randomization bypass ****\nA limitation of ASLR realization on 64-bit systems is that it is vulnerable to memory disclosure and information leakage attacks. The attacker can launch the ROP by revealing a single function address using information leakage attack. The following section describes the similar existing strategy for breaking down the ASLR protection.\n\n== Notable examples ==\nThe Morris worm in 1988 spread in part by exploiting a stack buffer overflow in the Unix finger server.[1]\nThe Slammer worm in 2003 spread by exploiting a stack buffer overflow in Microsoft's SQL server.[2]\nThe Blaster worm in 2003 spread by exploiting a stack buffer overflow in Microsoft DCOM service.\nThe Witty worm in 2004 spread by exploiting a stack buffer overflow in the Internet Security Systems BlackICE Desktop Agent.[3]\nThere are a couple of examples of the Wii allowing arbitrary code to be run on an unmodified system. The \"Twilight hack\" which involves giving a lengthy name to the main character's horse in The Legend of Zelda: Twilight Princess, and \"Smash Stack\" for Super Smash Bros. Brawl which involves using an SD card to load a specially prepared file into the in-game level editor. Though both can be used to execute any arbitrary code, the latter is often used to simply reload Brawl itself with modifications applied.\nRead the text above and answer this question: How does a stack buffer overflow occur and what kind of data can cause it?",
    "context": "",
    "output": "A stack buffer overflow occurs when a program writes more data to a buffer located on the stack than what is actually allocated for that buffer, resulting in corruption of adjacent data on the stack. This can be caused by supplying more data than the buffer can handle, as in the case of command-line arguments larger than 11 characters in the given example.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does a stack buffer overflow occur and what kind of data can cause it?",
      "answer": "A stack buffer overflow occurs when a program writes more data to a buffer located on the stack than what is actually allocated for that buffer, resulting in corruption of adjacent data on the stack. This can be caused by supplying more data than the buffer can handle, as in the case of command-line arguments larger than 11 characters in the given example.",
      "context": "Stack buffer overflow\n\n==Introduction==\nIn software, a stack buffer overflow or stack buffer overrun occurs when a program writes to a memory address on the program's call stack outside of the intended data structure, which is usually a fixed-length buffer.\nStack buffer overflow bugs are caused when a program writes more data to a buffer located on the stack than what is actually allocated for that buffer. This almost always results in corruption of adjacent data on the stack, and in cases where the overflow was triggered by mistake, will often cause the program to crash or operate incorrectly. Stack buffer overflow is a type of the more general programming malfunction known as buffer overflow (or buffer overrun). Overfilling a buffer on the stack is more likely to derail program execution than overfilling a buffer on the heap because the stack contains the return addresses for all active function calls.\nA stack buffer overflow can be caused deliberately as part of an attack known as stack smashing. If the affected program is running with special privileges, or accepts data from untrusted network hosts (e.g. a webserver) then the bug is a potential security vulnerability. If the stack buffer is filled with data supplied from an untrusted user then that user can corrupt the stack in such a way as to inject executable code into the running program and take control of the process. This is one of the oldest and more reliable methods for attackers to gain unauthorized access to a computer.\n\n== Exploiting stack buffer overflows ==\nThe canonical method for exploiting a stack-based buffer overflow is to overwrite the function return address with a pointer to attacker-controlled data (usually on the stack itself). This is illustrated with strcpy() in the following example:\n\nThis code takes an argument from the command line and copies it to a local stack variable c. This works fine for command-line arguments smaller than 12 characters (as can be seen in figure B below). Any arguments larger than 11 characters long will result in corruption of the stack. (The maximum number of characters that is safe is one less than the size of the buffer here because in the C programming language, strings are terminated by a null byte character. A twelve-character input thus requires thirteen bytes to store, the input followed by the sentinel zero byte. The zero byte then ends up overwriting a memory location that's one byte beyond the end of the buffer.)\nThe program stack in foo() with various inputs:\n\nIn figure C above, when an argument larger than 11 bytes is supplied on the command line foo() overwrites local stack data, the saved frame pointer, and most importantly, the return address. When foo() returns it pops the return address off the stack and jumps to that address (i.e. starts executing instructions from that address). Thus, the attacker has overwritten the return address with a pointer to the stack buffer char c[12], which now contains attacker-supplied data. In an actual stack buffer overflow exploit the string of \"A\"'s would instead be shellcode suitable to the platform and desired function. If this program had special privileges (e.g. the SUID bit set to run as the superuser), then the attacker could use this vulnerability to gain superuser privileges on the affected machine.The attacker can also modify internal variable values to exploit some bugs.\nWith this example:\n\n== Platform-related differences ==\nA number of platforms have subtle differences in their implementation of the call stack that can affect the way a stack buffer overflow exploit will work. Some machine architectures store the top-level return address of the call stack in a register. This means that any overwritten return address will not be used until a later unwinding of the call stack. Another example of a machine-specific detail that can affect the choice of exploitation techniques is the fact that most RISC-style machine architectures will not allow unaligned access to memory. Combined with a fixed length for machine opcodes, this machine limitation can make the technique of jumping to the stack almost impossible to implement (with the one exception being when the program actually contains the unlikely code to explicitly jump to the stack register).\n\n\n*** Stacks that grow up ***\nWithin the topic of stack buffer overflows, an often-discussed-but-rarely-seen architecture is one in which the stack grows in the opposite direction. This change in architecture is frequently suggested as a solution to the stack buffer overflow problem because any overflow of a stack buffer that occurs within the same stack frame cannot overwrite the return pointer. However, any overflow that occurs in a buffer from a previous stack frame will still overwrite a return pointer and allow for malicious exploitation of the bug. For instance, in the example above, the return pointer for foo will not be overwritten because the overflow actually occurs within the stack frame for memcpy. However, because the buffer that overflows during the call to memcpy resides in a previous stack frame, the return pointer for memcpy will have a numerically higher memory address than the buffer. This means that instead of the return pointer for foo being overwritten, the return pointer for memcpy will be overwritten. At most, this means that growing the stack in the opposite direction will change some details of how stack buffer overflows are exploitable, but it will not reduce significantly the number of exploitable bugs.\n\n== Protection schemes ==\n\nOver the years, a number of control-flow integrity schemes have been developed to inhibit malicious stack buffer overflow exploitation. These may usually be classified into three categories:\n\nDetect that a stack buffer overflow has occurred and thus prevent redirection of the instruction pointer to malicious code.\nPrevent the execution of malicious code from the stack without directly detecting the stack buffer overflow.\nRandomize the memory space such that finding executable code becomes unreliable.\n\n\n*** Stack canaries ***\n\nStack canaries, named for their analogy to a canary in a coal mine, are used to detect a stack buffer overflow before execution of malicious code can occur. This method works by placing a small integer, the value of which is randomly chosen at program start, in memory just before the stack return pointer. Most buffer overflows overwrite memory from lower to higher memory addresses, so in order to overwrite the return pointer (and thus take control of the process) the canary value must also be overwritten. This value is checked to make sure it has not changed before a routine uses the return pointer on the stack. This technique can greatly increase the difficulty of exploiting a stack buffer overflow because it forces the attacker to gain control of the instruction pointer by some non-traditional means such as corrupting other important variables on the stack.\n\n\n*** Nonexecutable stack ***\n\nAnother approach to preventing stack buffer overflow exploitation is to enforce a memory policy on the stack memory region that disallows execution from the stack (W^X, \"Write XOR Execute\"). This means that in order to execute shellcode from the stack an attacker must either find a way to disable the execution protection from memory, or find a way to put their shellcode payload in a non-protected region of memory. This method is becoming more popular now that hardware support for the no-execute flag is available in most desktop processors.\nWhile this method prevents the canonical stack smashing exploit, stack overflows can be exploited in other ways. First, it is common to find ways to store shellcode in unprotected memory regions like the heap, and so very little need change in the way of exploitation.Another attack is the so-called return to libc method for shellcode creation. In this attack the malicious payload will load the stack not with shellcode, but with a proper call stack so that execution is vectored to a chain of standard library calls, usually with the effect of disabling memory execute protections and allowing shellcode to run as normal. This works because the execution never actually vectors to the stack itself.\nA variant of return-to-libc is return-oriented programming (ROP), which sets up a series of return addresses, each of which executes a small sequence of cherry-picked machine instructions within the existing program code or system libraries, sequence which ends with a return. These so-called gadgets each accomplish some simple register manipulation or similar execution before returning, and stringing them together achieves the attacker's ends. It is even possible to use \"returnless\" return-oriented programming by exploiting instructions or groups of instructions that behave much like a return instruction.\n\n\n*** Randomization ***\nInstead of separating the code from the data, another mitigation technique is to introduce randomization to the memory space of the executing program. Since the attacker needs to determine where executable code that can be used resides, either an executable payload is provided (with an executable stack) or one is constructed using code reuse such as in ret2libc or return-oriented programming (ROP). Randomizing the memory layout will, as a concept, prevent the attacker from knowing where any code is. However, implementations typically will not randomize everything; usually the executable itself is loaded at a fixed address and hence even when ASLR (address space layout randomization) is combined with a nonexecutable stack the attacker can use this fixed region of memory. Therefore, all programs should be compiled with PIE (position-independent executables) such that even this region of memory is randomized. The entropy of the randomization is different from implementation to implementation and a low enough entropy can in itself be a problem in terms of brute forcing the memory space that is randomized.\n\n\n*** Bypass countermeasures ***\nThe previous mitigations make the steps of the exploitation harder. But it is still possible to exploit a stack buffer overflow if some vulnerabilities are presents or if some conditions are met.\n\n\n**** Stack canary bypass ****\n\n\n***** Information leak with format string vulnerability exploitation*****\nAn attacker is able to exploit the format string vulnerability for revealing the memory locations in the vulnerable program.\n\n\n**** Non executable stack bypass ****\nWhen Data Execution Prevention is enabled to forbid any execute access to the stack, the attacker can still use the overwritten return address (the instruction pointer) to point to data in a code segment (.text on Linux) or every other executable section of the program. The goal is to reuse existing code.\n\n\n***** Rop chain*****\nConsists to overwrite the return pointer a bit before a return instruction (ret in x86) of the program. The instructions between the new return pointer and the return instruction will be executed and the return instruction will return to the payload controlled by the exploiter.\n\n\n***** Jop chain*****\nJump Oriented Programming is a technique that uses jump instructions to reuse code instead of ret instruction.\n\n\n**** Randomization bypass ****\nA limitation of ASLR realization on 64-bit systems is that it is vulnerable to memory disclosure and information leakage attacks. The attacker can launch the ROP by revealing a single function address using information leakage attack. The following section describes the similar existing strategy for breaking down the ASLR protection.\n\n== Notable examples ==\nThe Morris worm in 1988 spread in part by exploiting a stack buffer overflow in the Unix finger server.[1]\nThe Slammer worm in 2003 spread by exploiting a stack buffer overflow in Microsoft's SQL server.[2]\nThe Blaster worm in 2003 spread by exploiting a stack buffer overflow in Microsoft DCOM service.\nThe Witty worm in 2004 spread by exploiting a stack buffer overflow in the Internet Security Systems BlackICE Desktop Agent.[3]\nThere are a couple of examples of the Wii allowing arbitrary code to be run on an unmodified system. The \"Twilight hack\" which involves giving a lengthy name to the main character's horse in The Legend of Zelda: Twilight Princess, and \"Smash Stack\" for Super Smash Bros. Brawl which involves using an SD card to load a specially prepared file into the in-game level editor. Though both can be used to execute any arbitrary code, the latter is often used to simply reload Brawl itself with modifications applied."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the role of the \"blender\" in the Crowds anonymity network?",
    "context": "",
    "output": "The blender is a single server responsible for membership management and key distribution in the Crowds anonymity network. It distributes symmetric keys to individual pairs of jondos for encryption and decryption of packets routed along the virtual paths.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of the \"blender\" in the Crowds anonymity network?",
      "answer": "The blender is a single server responsible for membership management and key distribution in the Crowds anonymity network. It distributes symmetric keys to individual pairs of jondos for encryption and decryption of packets routed along the virtual paths."
    }
  },
  {
    "instruction": "Context: Content Threat Removal\n\n==Introduction==\nContent Threat Removal (CTR) is a cybersecurity technology intended to defeat the threat posed by handling digital content in cyberspace. Unlike other defences, including antivirus software and sandboxed execution, it does not rely on being able to detect threats. Similar to Content Disarm and Reconstruction, CTR is designed to remove the threat without knowing whether it has done so and acts without knowing if data contains a threat or not.\nDetection strategies work by detecting unsafe content, and then blocking or removing that content. Content that is deemed safe is delivered to its destination. In contrast, Content Threat Removal assumes all data is hostile and delivers none of it to the destination, regardless of whether it is actually hostile. Although no data is delivered, the business information carried by the data is delivered using new data created for the purpose.\n\n== Threat ==\nAdvanced attacks continuously defeat defences that are based on the detection. These are often referred to as zero-day attacks, because as soon as they are discovered attack detection mechanisms must be updated to identify and neutralise the attack, and until they are, all systems are unprotected. These attacks succeed because attackers are skilled in finding new ways of evading detection. Polymorphic code can be used to evade the detection of known unsafe data and sandbox detection allows attacks to evade dynamic analysis.\n\n== Method ==\nA Content Threat Removal defence works by intercepting data on its way to its destination. The business information carried by the data is extracted and the data is discarded. Then entirely new, clean and safe data is built to carry the information to its destination.\nThe effect of building new data to carry the business information is that any unsafe elements of the original data are left behind and discarded. This includes executable data, macros, scripts and malformed data that trigger vulnerabilities in applications.\nWhile CTR is a form of content transformation, not all transformations provide a complete defence against the content threat.\n\n== Applicability ==\nCTR is applicable to user-to-user traffic, such as email and chat, and machine-to-machine traffic, such as web services. Data transfers can be intercepted by in-line application layer proxies and these can transform the way information content is delivered to remove any threat.CTR works by extracting business information from data and it is not possible to extract information from executable code. This means CTR is not directly applicable to web browsing, since most web pages are code. It can, however, be applied to content that is downloaded from, and uploaded to, websites.\nAlthough most web pages cannot be transformed to render them safe, web browsing can be isolated and the remote access protocols used to reach the isolated environment can be subjected to CTR.\nCTR provides a solution to the problem of Stegware. It naturally removes detectable steganography and eliminates symbiotic and permutation steganography through normalisation.\nAnswer this question: Why is Content Threat Removal (CTR) not directly applicable to web browsing?",
    "context": "",
    "output": "CTR is not directly applicable to web browsing because it is not possible to extract information from executable code, and most web pages are code.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Why is Content Threat Removal (CTR) not directly applicable to web browsing?",
      "answer": "CTR is not directly applicable to web browsing because it is not possible to extract information from executable code, and most web pages are code.",
      "context": "Content Threat Removal\n\n==Introduction==\nContent Threat Removal (CTR) is a cybersecurity technology intended to defeat the threat posed by handling digital content in cyberspace. Unlike other defences, including antivirus software and sandboxed execution, it does not rely on being able to detect threats. Similar to Content Disarm and Reconstruction, CTR is designed to remove the threat without knowing whether it has done so and acts without knowing if data contains a threat or not.\nDetection strategies work by detecting unsafe content, and then blocking or removing that content. Content that is deemed safe is delivered to its destination. In contrast, Content Threat Removal assumes all data is hostile and delivers none of it to the destination, regardless of whether it is actually hostile. Although no data is delivered, the business information carried by the data is delivered using new data created for the purpose.\n\n== Threat ==\nAdvanced attacks continuously defeat defences that are based on the detection. These are often referred to as zero-day attacks, because as soon as they are discovered attack detection mechanisms must be updated to identify and neutralise the attack, and until they are, all systems are unprotected. These attacks succeed because attackers are skilled in finding new ways of evading detection. Polymorphic code can be used to evade the detection of known unsafe data and sandbox detection allows attacks to evade dynamic analysis.\n\n== Method ==\nA Content Threat Removal defence works by intercepting data on its way to its destination. The business information carried by the data is extracted and the data is discarded. Then entirely new, clean and safe data is built to carry the information to its destination.\nThe effect of building new data to carry the business information is that any unsafe elements of the original data are left behind and discarded. This includes executable data, macros, scripts and malformed data that trigger vulnerabilities in applications.\nWhile CTR is a form of content transformation, not all transformations provide a complete defence against the content threat.\n\n== Applicability ==\nCTR is applicable to user-to-user traffic, such as email and chat, and machine-to-machine traffic, such as web services. Data transfers can be intercepted by in-line application layer proxies and these can transform the way information content is delivered to remove any threat.CTR works by extracting business information from data and it is not possible to extract information from executable code. This means CTR is not directly applicable to web browsing, since most web pages are code. It can, however, be applied to content that is downloaded from, and uploaded to, websites.\nAlthough most web pages cannot be transformed to render them safe, web browsing can be isolated and the remote access protocols used to reach the isolated environment can be subjected to CTR.\nCTR provides a solution to the problem of Stegware. It naturally removes detectable steganography and eliminates symbiotic and permutation steganography through normalisation."
    }
  },
  {
    "instruction": "Write an answer to the following question: How did Microsoft's Trustworthy Computing initiative improve the privacy of its products?",
    "context": "",
    "output": "The given text does not provide specific details on how Microsoft's Trustworthy Computing initiative improved the privacy of its products.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How did Microsoft's Trustworthy Computing initiative improve the privacy of its products?",
      "answer": "The given text does not provide specific details on how Microsoft's Trustworthy Computing initiative improved the privacy of its products."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the difference between the Orange Book and the Common Criteria (CC) in the context of the Common Criteria (CC) certification process?",
    "context": "",
    "output": "The Orange Book defined functional protection capabilities and appropriate assurance requirements as single category, and established precisely what security environment was valid for each of the Orange Book categories. On the other hand, the Common Criteria (CC) certification process uses Protection Profiles (PPs) and Security Targets (STs) to state a security problem and specify security requirements for a given collection of systems or products.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the difference between the Orange Book and the Common Criteria (CC) in the context of the Common Criteria (CC) certification process?",
      "answer": "The Orange Book defined functional protection capabilities and appropriate assurance requirements as single category, and established precisely what security environment was valid for each of the Orange Book categories. On the other hand, the Common Criteria (CC) certification process uses Protection Profiles (PPs) and Security Targets (STs) to state a security problem and specify security requirements for a given collection of systems or products."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the IBM 4765 provide a highly secure subsystem for data processing and cryptography, and what components contribute to this security?",
    "context": "",
    "output": "The IBM 4765 provides a highly secure subsystem for data processing and cryptography by housing specialized cryptographic electronics, a microprocessor, memory, and a random number generator within a tamper-responding environment. This configuration ensures that sensitive information is protected and securely processed, reducing the risk of exposure to threats or unauthorized access.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the IBM 4765 provide a highly secure subsystem for data processing and cryptography, and what components contribute to this security?",
      "answer": "The IBM 4765 provides a highly secure subsystem for data processing and cryptography by housing specialized cryptographic electronics, a microprocessor, memory, and a random number generator within a tamper-responding environment. This configuration ensures that sensitive information is protected and securely processed, reducing the risk of exposure to threats or unauthorized access."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the purpose of having two SSDTs in modern Windows kernels?",
    "context": "",
    "output": "Modern Windows kernels use two SSDTs: one for generic routines (KeServiceDescriptorTable) and another (KeServiceDescriptorTableShadow) for graphical routines. This allows for a more efficient mapping of syscalls to kernel function addresses based on the type of routine being called.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the purpose of having two SSDTs in modern Windows kernels?",
      "answer": "Modern Windows kernels use two SSDTs: one for generic routines (KeServiceDescriptorTable) and another (KeServiceDescriptorTableShadow) for graphical routines. This allows for a more efficient mapping of syscalls to kernel function addresses based on the type of routine being called."
    }
  },
  {
    "instruction": "Numbered Panda\n\n==Introduction==\nNumbered Panda (also known as IXESHE, DynCalc, DNSCALC, and APT12) is a cyber espionage group believed to be linked with the Chinese military. The group typically targets organizations in East Asia. These organizations include, but are not limited to, media outlets, high-tech companies, and governments. Numbered Panda is believed to have been operating since 2009. However, the group is also credited with a 2012 data breach at the New York Times. One of the group's typical techniques is to send PDF files loaded with malware via spear phishing campaigns. The decoy documents are typically written in traditional Chinese, which is widely used in Taiwan, and the targets are largely associated with Taiwanese interests. Numbered Panda appears to be actively seeking out cybersecurity research relating to the malware they use. After an Arbor Networks report on the group, FireEye noticed a change in the group's techniques to avoid future detection.\n\n== Discovery and security reports ==\nTrend Micro first reported on Numbered Panda in a 2012 white paper. Researchers discovered that the group launched spear phishing campaigns, using the Ixeshe malware, primarily against East Asian nations since approximately 2009. CrowdStrike further discussed the group in the 2013 blog post Whois Numbered Panda. This post followed the 2012 attack on the New York Times and its subsequent 2013 reporting on the attack. In June 2014, Arbor Networks released a report detailing Numbered Panda's use of Etumbot to target Taiwan and Japan. In September 2014, FireEye released a report highlighting the group's evolution. FireEye linked the release of Arbor Networks report to Numbered Panda's change in tactics.\n\n== Attacks ==\n\n\n*** East Asian Nations (2009-2011) ***\nTrend Micro reported on a campaign against East Asian governments, electronics manufacturers, and a telecommunications company. Numbered Panda engaged in spear phishing email campaigns with malicious attachments. Often, the malicious email attachments would be PDF files that exploited CVE-2009-4324, CVE-2009-09274, CVE-2011-06095, or CVE-CVE-2011-0611 vulnerabilities in Adobe Acrobat, Adobe Reader, and Flash Player. The attackers also used an exploit that affected Microsoft Excel - CVE-2009-3129. The Ixeshe malware used in this campaign allowed Numbered Panda to list all services, processes, and drives; terminate processes and services; download and upload files; start processes and services; get victims\u2019 user names; get a machine's name and domain name; download and execute arbitrary files; cause a system to pause or sleep for a specified number of minutes; spawn a remote shell; and list all current files and directories. After installation, Ixeshe would start communicating with command-and-control servers; oftentimes three servers were hard-coded for redundancy. Numbered Panda often used compromised servers to create these command-and-control servers to increase control of a victim's network infrastructure. Using this technique, the group is believed to have amassed sixty servers by 2012. A majority of the command-and-control servers used from this campaign were located in Taiwan and the United States. Base64 was used for communication between the compromised computer and the server. Trend Micro found that, once decoded, the communication was a standardized structure that detailed the computer's name, local IP address, proxy server IP and port, and the malware ID. Researchers at CrowdStrike found that blogs and WordPress sites were frequently used in the command-and-control infrastructure to make the network traffic look more legitimate.\n\n\n*** Japan and Taiwan (2011-2014) ***\nAn Arbor Security report found that Numbered Panda began a campaign against Japan and Taiwan using the Etumbot malware in 2011. Similar to the previously observed campaign, the attackers would use decoy files, such as PDF, Excel spreadsheets, or Word documents, as email attachments to gain access to victims' computers. Most of the documents observed were written in Traditional Chinese and usually pertained to Taiwanese government interests; several of the files related to upcoming conferences in Taiwan. Once the malicious file was downloaded and extracted by the victim, Etumbot uses a right-to-left override exploit to trick the victim to download the malware installer. According to Arbor Security, the \"technique is a simple way for malware writers to disguise names of malicious files. A hidden Unicode character in the filename will reverse the order of the characters that follow it, so that a .scr binary file appears to be a .xls document, for example.\" Once the malware is installed, it sends a request to a command-and-control server with a RC4 key to encrypt subsequent communication. As was with the Ixeshe malware, Numbered Panda used Base64 encoded characters to communicate from compromised computers to the command-and-control servers.  Etumbot is able to determine if the target computer is using a proxy and will bypass the proxy settings to directly establish a connection. After communication is established, the malware will send an encrypted message from the infected computer to the server with the NetBIOS name of the victim's system, user name, IP address, and if the system is using a proxy.After the May 2014 Arbor Security report detailed Etumbot, FireEye discovered that Numbered Panda changed parts of the malware. FireEye noticed that the protocols and strings previously used were changed in June 2014. The researchers at FireEye believe this change was to help the malware evade further detection. FireEye named this new version of Etumbot HighTide. Numbered Panda continued to target Taiwan with spear phishing email campaigns with malicious attachments. Attached Microsoft Word documents exploited the CVE-2012-0158 vulnerability to help propagate HighTide. FireEye found that compromised Taiwanese government employee email accounts were used in some of the spear phishing. HighTide differs from Etumbot in that its HTTP GET request changed the User Agent, the format and structure of the HTTP Uniform Resource Identifier, the executable file location, and the image base address.\n\n\n*** New York Times (2012) ***\nNumbered Panda is believed to be responsible for the computer network breach at the New York Times in late 2012. The attack occurred after the New York Times published a story about how the relatives of Wen Jiabao, the sixth Premier of the State Council of the People's Republic of China, \"accumulated a fortune worth several billion dollars through business dealings.\" The computers used to launch the attack are believed to be the same university computers used by the Chinese military to attack United States military contractors. Numbered Panda used updated versions of the malware packages Aumlib and Ixeshe. The updated Aumlib allowed Numbered Panda to encode the body of a POST request to gather a victim's BIOS, external IP, and operating system. A new version of Ixeshe altered the previous version's network traffic pattern in an effort to evade existing network traffic signatures designed to detect Ixeshe related infections.\n\nQ: What is the significance of Numbered Panda sending spear phishing email campaigns with malicious attachments?",
    "context": "",
    "output": "A: Numbered Panda sending spear phishing email campaigns with malicious attachments is significant because it shows that they are actively seeking out vulnerabilities in targeted systems to gain access and control.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the significance of Numbered Panda sending spear phishing email campaigns with malicious attachments?",
      "answer": "Numbered Panda sending spear phishing email campaigns with malicious attachments is significant because it shows that they are actively seeking out vulnerabilities in targeted systems to gain access and control.",
      "context": "Numbered Panda\n\n==Introduction==\nNumbered Panda (also known as IXESHE, DynCalc, DNSCALC, and APT12) is a cyber espionage group believed to be linked with the Chinese military. The group typically targets organizations in East Asia. These organizations include, but are not limited to, media outlets, high-tech companies, and governments. Numbered Panda is believed to have been operating since 2009. However, the group is also credited with a 2012 data breach at the New York Times. One of the group's typical techniques is to send PDF files loaded with malware via spear phishing campaigns. The decoy documents are typically written in traditional Chinese, which is widely used in Taiwan, and the targets are largely associated with Taiwanese interests. Numbered Panda appears to be actively seeking out cybersecurity research relating to the malware they use. After an Arbor Networks report on the group, FireEye noticed a change in the group's techniques to avoid future detection.\n\n== Discovery and security reports ==\nTrend Micro first reported on Numbered Panda in a 2012 white paper. Researchers discovered that the group launched spear phishing campaigns, using the Ixeshe malware, primarily against East Asian nations since approximately 2009. CrowdStrike further discussed the group in the 2013 blog post Whois Numbered Panda. This post followed the 2012 attack on the New York Times and its subsequent 2013 reporting on the attack. In June 2014, Arbor Networks released a report detailing Numbered Panda's use of Etumbot to target Taiwan and Japan. In September 2014, FireEye released a report highlighting the group's evolution. FireEye linked the release of Arbor Networks report to Numbered Panda's change in tactics.\n\n== Attacks ==\n\n\n*** East Asian Nations (2009-2011) ***\nTrend Micro reported on a campaign against East Asian governments, electronics manufacturers, and a telecommunications company. Numbered Panda engaged in spear phishing email campaigns with malicious attachments. Often, the malicious email attachments would be PDF files that exploited CVE-2009-4324, CVE-2009-09274, CVE-2011-06095, or CVE-CVE-2011-0611 vulnerabilities in Adobe Acrobat, Adobe Reader, and Flash Player. The attackers also used an exploit that affected Microsoft Excel - CVE-2009-3129. The Ixeshe malware used in this campaign allowed Numbered Panda to list all services, processes, and drives; terminate processes and services; download and upload files; start processes and services; get victims\u2019 user names; get a machine's name and domain name; download and execute arbitrary files; cause a system to pause or sleep for a specified number of minutes; spawn a remote shell; and list all current files and directories. After installation, Ixeshe would start communicating with command-and-control servers; oftentimes three servers were hard-coded for redundancy. Numbered Panda often used compromised servers to create these command-and-control servers to increase control of a victim's network infrastructure. Using this technique, the group is believed to have amassed sixty servers by 2012. A majority of the command-and-control servers used from this campaign were located in Taiwan and the United States. Base64 was used for communication between the compromised computer and the server. Trend Micro found that, once decoded, the communication was a standardized structure that detailed the computer's name, local IP address, proxy server IP and port, and the malware ID. Researchers at CrowdStrike found that blogs and WordPress sites were frequently used in the command-and-control infrastructure to make the network traffic look more legitimate.\n\n\n*** Japan and Taiwan (2011-2014) ***\nAn Arbor Security report found that Numbered Panda began a campaign against Japan and Taiwan using the Etumbot malware in 2011. Similar to the previously observed campaign, the attackers would use decoy files, such as PDF, Excel spreadsheets, or Word documents, as email attachments to gain access to victims' computers. Most of the documents observed were written in Traditional Chinese and usually pertained to Taiwanese government interests; several of the files related to upcoming conferences in Taiwan. Once the malicious file was downloaded and extracted by the victim, Etumbot uses a right-to-left override exploit to trick the victim to download the malware installer. According to Arbor Security, the \"technique is a simple way for malware writers to disguise names of malicious files. A hidden Unicode character in the filename will reverse the order of the characters that follow it, so that a .scr binary file appears to be a .xls document, for example.\" Once the malware is installed, it sends a request to a command-and-control server with a RC4 key to encrypt subsequent communication. As was with the Ixeshe malware, Numbered Panda used Base64 encoded characters to communicate from compromised computers to the command-and-control servers.  Etumbot is able to determine if the target computer is using a proxy and will bypass the proxy settings to directly establish a connection. After communication is established, the malware will send an encrypted message from the infected computer to the server with the NetBIOS name of the victim's system, user name, IP address, and if the system is using a proxy.After the May 2014 Arbor Security report detailed Etumbot, FireEye discovered that Numbered Panda changed parts of the malware. FireEye noticed that the protocols and strings previously used were changed in June 2014. The researchers at FireEye believe this change was to help the malware evade further detection. FireEye named this new version of Etumbot HighTide. Numbered Panda continued to target Taiwan with spear phishing email campaigns with malicious attachments. Attached Microsoft Word documents exploited the CVE-2012-0158 vulnerability to help propagate HighTide. FireEye found that compromised Taiwanese government employee email accounts were used in some of the spear phishing. HighTide differs from Etumbot in that its HTTP GET request changed the User Agent, the format and structure of the HTTP Uniform Resource Identifier, the executable file location, and the image base address.\n\n\n*** New York Times (2012) ***\nNumbered Panda is believed to be responsible for the computer network breach at the New York Times in late 2012. The attack occurred after the New York Times published a story about how the relatives of Wen Jiabao, the sixth Premier of the State Council of the People's Republic of China, \"accumulated a fortune worth several billion dollars through business dealings.\" The computers used to launch the attack are believed to be the same university computers used by the Chinese military to attack United States military contractors. Numbered Panda used updated versions of the malware packages Aumlib and Ixeshe. The updated Aumlib allowed Numbered Panda to encode the body of a POST request to gather a victim's BIOS, external IP, and operating system. A new version of Ixeshe altered the previous version's network traffic pattern in an effort to evade existing network traffic signatures designed to detect Ixeshe related infections."
    }
  },
  {
    "instruction": "Write an answer to the following question: How did the Bazeries cylinder become well known?",
    "context": "",
    "output": "The Bazeries cylinder became well known when Commandant Etienne Bazeries broke the Great Cipher, a century after Jefferson's work.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How did the Bazeries cylinder become well known?",
      "answer": "The Bazeries cylinder became well known when Commandant Etienne Bazeries broke the Great Cipher, a century after Jefferson's work."
    }
  },
  {
    "instruction": "Context: Content Disarm & Reconstruction\n\n==Introduction==\nContent Disarm & Reconstruction (CDR) is a computer security technology for removing potentially malicious code from files. Unlike malware analysis, CDR technology does not determine or detect malware's functionality but removes all file components that are not approved within the system's definitions and policies.It is used to prevent cyber security threats from entering a corporate network perimeter. Channels that CDR can be used to protect include email and website traffic. Advanced solutions can also provide similar protection on computer endpoints, or cloud email and file sharing services.\nThere are three levels of CDR; 1) flattening and converting the original file to a PDF, 2) stripping active content while keeping the original file type, and 3) eliminating all file-borne risk while maintaining file type, integrity and active content. Beyond these three levels, there are also more advanced forms of CDR that is able to perform \"soft conversion\" and \"hard conversion\", based on the user's preference in balancing usability and security. \n\n\n\n== Applications ==\nCDR works by processing all incoming files of an enterprise network, deconstructing them, and removing the elements that do not match the file type's standards or set policies. CDR technology then rebuilds the files into clean versions that can be sent on to end users as intended.Because CDR removes all potentially malicious code, it can be effective against zero-day vulnerabilities that rely on being an unknown threat that other security technologies would need to patch against to maintain protection.\nCDR can be used to prevent cyber threats from variety of sources:\n\nEmail\nData Diodes\nWeb Browsers\nEndpoints\nFile Servers\nFTP\nCloud email or webmail programs\nSMB/CIFS\nRemovable media scanning (CDR Kiosk)CDR can be applied to a variety of file formats including:\n\nImages\nOffice documents\nPDF\nAudio/video file formats\nArchives\nHTML\n\n== Commercial availability ==\nCDR or similar file sanitization technology is commercially available from a number of companies (sorted A-Z): \n\nBodyguard (CDR for desktop), The Netherlands, a cyber security company established in 2021.\nCheck Point (Threat Extraction), Israel, a global company established in 1993.\nClearswift (Structural Sanitization), a UK based Cyber Security provider.\nDeep Secure (Content Threat Removal, CTR), a UK based Cyber Security provider. Acquired by Forcepoint in 2021.\nForcepoint, USA, provides Defense-Grade CDR and Cross Domain Solutions for Large Enterprises, Critical Infrastructure and Governments for 25 years.\nFortinet, USA, founded in 2000 and headquartered in Sunnyvale, California, with offices around the globe.\nGateScanner CDR by Sasa Software, Israel with offices in the US and Singapore.\nGlasswall is a British cybersecurity firm that offers instant protection against file-based threats with CDR technology. Founded in 2005.\nJiransecurity, South Korea, a highly-specialized Security SW company established in 2014.\nReSec Technologies, Israel, Established in 2012.\nOPSWAT, USA, a global cyber-security company founded in 2002 with offices in North America, Europe, and Asia.\nSoftcamp, a South Korean information security company established in 1999 headquartered in South Korea with offices in Japan.\nVotiro (Secure File Gateway, Level 3 CDR), a global cyber-security company established in 2010 with offices in North America, Europe, and Asia.\nYazamTech, CDR Technology, small Israeli startup , established in 2008.\nODIX (ODI) Israel, a malware prevention and deep file inspection solutions company established in 2012.\n\n== Open Source Implementations ==\nDocBleach\nExeFilter\n\nQuestion: How can CDR technology be used to protect FTP?\n\nAnswer:",
    "context": "",
    "output": "CDR technology can be used to protect FTP by processing all incoming files from FTP, deconstructing them, and removing any elements that do not match the file type's standards or set policies. It then rebuilds the files into clean versions that can be sent on to end users as intended.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can CDR technology be used to protect FTP?",
      "answer": "CDR technology can be used to protect FTP by processing all incoming files from FTP, deconstructing them, and removing any elements that do not match the file type's standards or set policies. It then rebuilds the files into clean versions that can be sent on to end users as intended.",
      "context": "Content Disarm & Reconstruction\n\n==Introduction==\nContent Disarm & Reconstruction (CDR) is a computer security technology for removing potentially malicious code from files. Unlike malware analysis, CDR technology does not determine or detect malware's functionality but removes all file components that are not approved within the system's definitions and policies.It is used to prevent cyber security threats from entering a corporate network perimeter. Channels that CDR can be used to protect include email and website traffic. Advanced solutions can also provide similar protection on computer endpoints, or cloud email and file sharing services.\nThere are three levels of CDR; 1) flattening and converting the original file to a PDF, 2) stripping active content while keeping the original file type, and 3) eliminating all file-borne risk while maintaining file type, integrity and active content. Beyond these three levels, there are also more advanced forms of CDR that is able to perform \"soft conversion\" and \"hard conversion\", based on the user's preference in balancing usability and security. \n\n\n\n== Applications ==\nCDR works by processing all incoming files of an enterprise network, deconstructing them, and removing the elements that do not match the file type's standards or set policies. CDR technology then rebuilds the files into clean versions that can be sent on to end users as intended.Because CDR removes all potentially malicious code, it can be effective against zero-day vulnerabilities that rely on being an unknown threat that other security technologies would need to patch against to maintain protection.\nCDR can be used to prevent cyber threats from variety of sources:\n\nEmail\nData Diodes\nWeb Browsers\nEndpoints\nFile Servers\nFTP\nCloud email or webmail programs\nSMB/CIFS\nRemovable media scanning (CDR Kiosk)CDR can be applied to a variety of file formats including:\n\nImages\nOffice documents\nPDF\nAudio/video file formats\nArchives\nHTML\n\n== Commercial availability ==\nCDR or similar file sanitization technology is commercially available from a number of companies (sorted A-Z): \n\nBodyguard (CDR for desktop), The Netherlands, a cyber security company established in 2021.\nCheck Point (Threat Extraction), Israel, a global company established in 1993.\nClearswift (Structural Sanitization), a UK based Cyber Security provider.\nDeep Secure (Content Threat Removal, CTR), a UK based Cyber Security provider. Acquired by Forcepoint in 2021.\nForcepoint, USA, provides Defense-Grade CDR and Cross Domain Solutions for Large Enterprises, Critical Infrastructure and Governments for 25 years.\nFortinet, USA, founded in 2000 and headquartered in Sunnyvale, California, with offices around the globe.\nGateScanner CDR by Sasa Software, Israel with offices in the US and Singapore.\nGlasswall is a British cybersecurity firm that offers instant protection against file-based threats with CDR technology. Founded in 2005.\nJiransecurity, South Korea, a highly-specialized Security SW company established in 2014.\nReSec Technologies, Israel, Established in 2012.\nOPSWAT, USA, a global cyber-security company founded in 2002 with offices in North America, Europe, and Asia.\nSoftcamp, a South Korean information security company established in 1999 headquartered in South Korea with offices in Japan.\nVotiro (Secure File Gateway, Level 3 CDR), a global cyber-security company established in 2010 with offices in North America, Europe, and Asia.\nYazamTech, CDR Technology, small Israeli startup , established in 2008.\nODIX (ODI) Israel, a malware prevention and deep file inspection solutions company established in 2012.\n\n== Open Source Implementations ==\nDocBleach\nExeFilter"
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the language in which the Mbed TLS core SSL library is written?",
    "context": "",
    "output": "The Mbed TLS core SSL library is written in the C programming language.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the language in which the Mbed TLS core SSL library is written?",
      "answer": "The Mbed TLS core SSL library is written in the C programming language."
    }
  },
  {
    "instruction": "Mutual authentication\n\n==Introduction==\nMutual authentication or two-way authentication (not to be confused with two-factor authentication) refers to two parties authenticating each other at the same time in an authentication protocol. It is a default mode of authentication in some protocols (IKE, SSH) and optional in others (TLS).\nMutual authentication is a desired characteristic in verification schemes that transmit sensitive data, in order to ensure data security. Mutual authentication can be accomplished with two types of credentials: usernames and passwords, and public key certificates.\nMutual authentication is often employed in the Internet of Things (IoT). Writing effective security schemes in IoT systems can become challenging, especially when schemes are desired to be lightweight and have low computational costs. Mutual authentication is a crucial security step that can defend against many adversarial attacks, which otherwise can have large consequences if IoT systems (such as e-Healthcare servers) are hacked. In scheme analyses done of past works, a lack of mutual authentication had been considered a weakness in data transmission schemes.\n\n\n\n== Process steps and verification ==\nSchemes that have a mutual authentication step may use different methods of encryption, communication, and verification, but they all share one thing in common: each entity involved in the communication is verified. If Alice wants to communicate with Bob, they will both authenticate the other and verify that it is who they are expecting to communicate with before any data or messages are transmitted. A mutual authentication process that exchanges user IDs may be implemented as follows:\nAlice sends an encrypted message to Bob to show that Alice is a valid user.\nBob verifies message:\nBob checks the format and timestamp. If either is incorrect or invalid, the session is aborted.\nThe message is then decrypted with Bob's secret key, giving Alice's ID.\nBob checks if the message matches a valid user. If not, the session is aborted.\nBob sends Alice a message back to show that Bob is a valid user.\nAlice verifies the message:\nAlice checks the format and timestamp. If either is incorrect or invalid, the session is aborted.\nThen, the message is decrypted with Alice's secret key, giving Bob's ID.\nAlice checks if the message matches a valid user. If not, the session is aborted.\nAt this point, both parties are verified to be who they claim to be and safe for the other to communicate with. Lastly, Alice and Bob will create a shared secret key so that they can continue communicating in a secure manner.To verify that mutual authentication has occurred successfully, Burrows-Abadi-Needham logic (BAN logic) is a well regarded and widely accepted method to use, because it verifies that a message came from a trustworthy entity. BAN logic first assumes an entity is not to be trusted, and then will verify its legality.\n\n== Defenses ==\nMutual authentication supports zero trust networking because it can protect communications against adversarial attacks, notably:\n\nMan-in-the-middle attack\nMan-in-the-middle (MITM) attacks are when a third party wishes to eavesdrop or intercept a message, and sometimes alter the intended message for the recipient. The two parties openly receive messages without verifying the sender, so they do not realize an adversary has inserted themselves into the communication line. Mutual authentication can prevent MITM attacks because both the sender and recipient verify each other before sending them their message keys, so if one of the parties is not verified to be who they claim they are, the session will end.\nReplay attack\nA replay attack is similar to a MITM attack in which older messages are replayed out of context to fool the server. However, this does not work against schemes using mutual authentication because timestamps are a verification factor that are used in the protocols. If the change in time is greater than the maximum allowed time delay, the session will be aborted. Similarly, messages can include a randomly generated number to keep track of when a message was sent.\nSpoofing attack\nSpoofing attacks rely on using false data to pose as another user in order to gain access to a server or be identified as someone else. Mutual authentication can prevent spoofing attacks because the server will authenticate the user as well, and verify that they have the correct session key before allowing any further communication and access.\nImpersonation attacks\nWhen each party authenticates the other, they send each other a certificate that only the other party knows how to unscramble, verifying themselves as a trusted source. In this way, adversaries cannot use impersonation attacks because they do not have the correct certificate to act as if they are the other party.Mutual authentication also ensures information integrity because if the parties are verified to be the correct source, then the information received is reliable as well.\n\n== mTLS ==\nBy default the TLS protocol only proves the identity of the server to the client using X.509 certificates, and the authentication of the client to the server is left to the application layer. TLS also offers client-to-server authentication using client-side X.509 authentication. As it requires provisioning of the certificates to the clients and involves less user-friendly experience, it's rarely used in end-user applications.\nMutual TLS authentication (mTLS) is more often used in business-to-business (B2B) applications, where a limited number of programmatic and homogeneous clients are connecting to specific web services, the operational burden is limited, and security requirements are usually much higher as compared to consumer environments.\nmTLS is also used in microservices-based applications based on runtimes such as Dapr, via systems like SPIFFE.\n\n== Lightweight schemes vs. secured schemes ==\nWhile lightweight schemes and secure schemes are not mutually exclusive, adding a mutual authentication step to data transmissions protocols can often increase performance runtime and computational costs. This can become an issue for network systems that cannot handle large amounts of data or those that constantly have to update for new real-time data (e.g. location tracking, real-time health data).Thus, it becomes a desired characteristic of many mutual authentication schemes to have lightweight properties (e.g. have a low memory footprint) in order to accommodate the system that is storing a lot of data. Many systems implement cloud computing, which allows quick access to large amounts of data, but sometimes large amounts of data can slow down communication. Even with edge-based cloud computing, which is faster than general cloud computing due to a closer proximity between the server and user, lightweight schemes allow for more speed when managing larger amounts of data. One solution to keep schemes lightweight during the mutual authentication process is to limit the number of bits used during communication.Applications that solely rely on device-to-device (D2D) communication, where multiple devices can communicate locally in close proximities, removes the third party network. This in turn can speed up communication time. However, the authentication still occurs through insecure channels, so researchers believe it is still important to ensure mutual authentication occurs in order to keep a secure scheme.Schemes may sacrifice a better runtime or storage cost when ensuring mutual authentication in order to prioritize protecting the sensitive data.\n\n== Password-based schemes ==\nIn mutual authentication schemes that require a user's input password as part of the verification process, there is a higher vulnerability to hackers because the password is human-made rather than a computer-generated certificate. While applications could simply require users to use a computer-generated password, it is inconvenient for people to remember. User-made passwords and the ability to change one's password are important for making an application user-friendly, so many schemes work to accommodate the characteristic. Researchers note that a password based protocol with mutual authentication is important because user identities and passwords are still protected, as the messages are only readable to the two parties involved.However, a negative aspect about password-based authentication is that password tables can take up a lot of memory space. One way around using a lot of memory during a password-based authentication scheme is to implement one-time passwords (OTP), which is a password sent to the user via SMS or email. OTPs are time-sensitive, which means that they will expire after a certain amount of time and that memory does not need to be stored.\n\n\n*** Multi-factor authentication ***\nRecently, more schemes have higher level authentication than password based schemes. While password-based authentication is considered as \"single-factor authentication,\" schemes are beginning to implement smart card (two-factor) or biometric-based (three-factor) authentication schemes. Smart cards are simpler to implement and easy for authentication, but still have risks of being tampered with. Biometrics have grown more popular over password-based schemes because it is more difficult to copy or guess session keys when using biometrics, but it can be difficult to encrypt noisy data. Due to these security risks and limitations, schemes can still employ mutual authentication regardless of how many authentication factors are added.\n\n== Certificate based schemes and system applications ==\nMutual authentication is often found in schemes employed in the Internet of Things (IoT), where physical objects are incorporated into the Internet and can communicate via IP address. Authentication schemes can be applied to many types of systems that involve data transmission. As the Internet's presence in mechanical systems increases, writing effective security schemes for large numbers of users, objects, and servers can become challenging, especially when needing schemes to be lightweight and have low computational costs. Instead of password-based authentication, devices will use certificates to verify each other's identities.\n\n\n*** Radio networks ***\nMutual authentication can be satisfied in radio network schemes, where data transmissions through radio frequencies are secure after verifying the sender and receiver.Radio frequency identification (RFID) tags are commonly used for object detection, which many manufacturers are implementing into their warehouse systems for automation. This allows for a faster way to keep up with inventory and track objects. However, keeping track of items in a system with RFID tags that transmit data to a cloud server increases the chances of security risks, as there are now more digital elements to keep track of. A three way mutual authentication can occur between RFID tags, the tag readers, and the cloud network that stores this data in order to keep RFID tag data secure and unable to be manipulated.Similarly, an alternate RFID tag and reader system that assigns designated readers to tags has been proposed for extra security and low memory cost. Instead of considering all tag readers as one entity, only certain readers can read specific tags. With this method, if a reader is breached, it will not affect the whole system. Individual readers will communicate with specific tags during mutual authentication, which runs in constant time as readers use the same private key for the authentication process.\nMany e-Healthcare systems that remotely monitor patient health data use wireless body area networks (WBAN) that transmit data through radio frequencies. This is beneficial for patients that should not be disturbed while being monitored, and can reduced the workload for medical worker and allow them to focus on the more hands-on jobs. However, a large concern for healthcare providers and patients about using remote health data tracking is that sensitive patient data is being transmitted through unsecured channels, so authentication occurs between the medical body area network user (the patient), the Healthcare Service Provider (HSP) and the trusted third party.\n\n\n*** Cloud based computing ***\ne-Healthcare clouds are another way to store patient data collected remotely. Clouds are useful for storing large amounts of data, such as medical information, that can be accessed by many devices whenever needed. Telecare Medical Information Systems (TMIS), an important way for medical patients to receive healthcare remotely, can ensure secured data with mutual authentication verification schemes. Blockchain is one way that has been proposed to mutually authenticate the user to the database, by authenticating with the main mediBchain node and keeping patient anonymity.Fog-cloud computing is a networking system that can handle large amounts of data, but still has limitations regarding computational and memory cost. Mobile edge computing (MEC) is considered to be an improved, more lightweight fog-cloud computing networking system, and can be used for medical technology that also revolves around location-based data. Due to the large physical range required of locational tracking, 5G networks can send data to the edge of the cloud to store data. An application like smart watches that track patient health data can be used to call the nearest hospital if the patient shows a negative change in vitals.Fog node networks can be implemented in car automation, keeping data about the car and its surrounding states secure. By authenticating the fog nodes and the vehicle, vehicular handoff becomes a safe process and the car\u2019s system is safe from hackers.\n\n\n*** Machine to machine verification ***\nMany systems that do not require a human user as part of the system also have protocols that mutually authenticate between parties. In unmanned aerial vehicle (UAV) systems, a platform authentication occurs rather than user authentication. Mutual authentication during vehicle communication prevents one vehicle's system from being breached, which can then affect the whole system negatively. For example, a system of drones can be employed for agriculture work and cargo delivery, but if one drone were to be breached, the whole system has the potential to collapse.\n\nHow do timestamps prevent replay attacks in mutual authentication?",
    "context": "",
    "output": "Timestamps are used in mutual authentication protocols to prevent replay attacks. If the change in time is greater than the maximum allowed time delay, the session will be aborted.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do timestamps prevent replay attacks in mutual authentication?",
      "answer": "Timestamps are used in mutual authentication protocols to prevent replay attacks. If the change in time is greater than the maximum allowed time delay, the session will be aborted.",
      "context": "Mutual authentication\n\n==Introduction==\nMutual authentication or two-way authentication (not to be confused with two-factor authentication) refers to two parties authenticating each other at the same time in an authentication protocol. It is a default mode of authentication in some protocols (IKE, SSH) and optional in others (TLS).\nMutual authentication is a desired characteristic in verification schemes that transmit sensitive data, in order to ensure data security. Mutual authentication can be accomplished with two types of credentials: usernames and passwords, and public key certificates.\nMutual authentication is often employed in the Internet of Things (IoT). Writing effective security schemes in IoT systems can become challenging, especially when schemes are desired to be lightweight and have low computational costs. Mutual authentication is a crucial security step that can defend against many adversarial attacks, which otherwise can have large consequences if IoT systems (such as e-Healthcare servers) are hacked. In scheme analyses done of past works, a lack of mutual authentication had been considered a weakness in data transmission schemes.\n\n\n\n== Process steps and verification ==\nSchemes that have a mutual authentication step may use different methods of encryption, communication, and verification, but they all share one thing in common: each entity involved in the communication is verified. If Alice wants to communicate with Bob, they will both authenticate the other and verify that it is who they are expecting to communicate with before any data or messages are transmitted. A mutual authentication process that exchanges user IDs may be implemented as follows:\nAlice sends an encrypted message to Bob to show that Alice is a valid user.\nBob verifies message:\nBob checks the format and timestamp. If either is incorrect or invalid, the session is aborted.\nThe message is then decrypted with Bob's secret key, giving Alice's ID.\nBob checks if the message matches a valid user. If not, the session is aborted.\nBob sends Alice a message back to show that Bob is a valid user.\nAlice verifies the message:\nAlice checks the format and timestamp. If either is incorrect or invalid, the session is aborted.\nThen, the message is decrypted with Alice's secret key, giving Bob's ID.\nAlice checks if the message matches a valid user. If not, the session is aborted.\nAt this point, both parties are verified to be who they claim to be and safe for the other to communicate with. Lastly, Alice and Bob will create a shared secret key so that they can continue communicating in a secure manner.To verify that mutual authentication has occurred successfully, Burrows-Abadi-Needham logic (BAN logic) is a well regarded and widely accepted method to use, because it verifies that a message came from a trustworthy entity. BAN logic first assumes an entity is not to be trusted, and then will verify its legality.\n\n== Defenses ==\nMutual authentication supports zero trust networking because it can protect communications against adversarial attacks, notably:\n\nMan-in-the-middle attack\nMan-in-the-middle (MITM) attacks are when a third party wishes to eavesdrop or intercept a message, and sometimes alter the intended message for the recipient. The two parties openly receive messages without verifying the sender, so they do not realize an adversary has inserted themselves into the communication line. Mutual authentication can prevent MITM attacks because both the sender and recipient verify each other before sending them their message keys, so if one of the parties is not verified to be who they claim they are, the session will end.\nReplay attack\nA replay attack is similar to a MITM attack in which older messages are replayed out of context to fool the server. However, this does not work against schemes using mutual authentication because timestamps are a verification factor that are used in the protocols. If the change in time is greater than the maximum allowed time delay, the session will be aborted. Similarly, messages can include a randomly generated number to keep track of when a message was sent.\nSpoofing attack\nSpoofing attacks rely on using false data to pose as another user in order to gain access to a server or be identified as someone else. Mutual authentication can prevent spoofing attacks because the server will authenticate the user as well, and verify that they have the correct session key before allowing any further communication and access.\nImpersonation attacks\nWhen each party authenticates the other, they send each other a certificate that only the other party knows how to unscramble, verifying themselves as a trusted source. In this way, adversaries cannot use impersonation attacks because they do not have the correct certificate to act as if they are the other party.Mutual authentication also ensures information integrity because if the parties are verified to be the correct source, then the information received is reliable as well.\n\n== mTLS ==\nBy default the TLS protocol only proves the identity of the server to the client using X.509 certificates, and the authentication of the client to the server is left to the application layer. TLS also offers client-to-server authentication using client-side X.509 authentication. As it requires provisioning of the certificates to the clients and involves less user-friendly experience, it's rarely used in end-user applications.\nMutual TLS authentication (mTLS) is more often used in business-to-business (B2B) applications, where a limited number of programmatic and homogeneous clients are connecting to specific web services, the operational burden is limited, and security requirements are usually much higher as compared to consumer environments.\nmTLS is also used in microservices-based applications based on runtimes such as Dapr, via systems like SPIFFE.\n\n== Lightweight schemes vs. secured schemes ==\nWhile lightweight schemes and secure schemes are not mutually exclusive, adding a mutual authentication step to data transmissions protocols can often increase performance runtime and computational costs. This can become an issue for network systems that cannot handle large amounts of data or those that constantly have to update for new real-time data (e.g. location tracking, real-time health data).Thus, it becomes a desired characteristic of many mutual authentication schemes to have lightweight properties (e.g. have a low memory footprint) in order to accommodate the system that is storing a lot of data. Many systems implement cloud computing, which allows quick access to large amounts of data, but sometimes large amounts of data can slow down communication. Even with edge-based cloud computing, which is faster than general cloud computing due to a closer proximity between the server and user, lightweight schemes allow for more speed when managing larger amounts of data. One solution to keep schemes lightweight during the mutual authentication process is to limit the number of bits used during communication.Applications that solely rely on device-to-device (D2D) communication, where multiple devices can communicate locally in close proximities, removes the third party network. This in turn can speed up communication time. However, the authentication still occurs through insecure channels, so researchers believe it is still important to ensure mutual authentication occurs in order to keep a secure scheme.Schemes may sacrifice a better runtime or storage cost when ensuring mutual authentication in order to prioritize protecting the sensitive data.\n\n== Password-based schemes ==\nIn mutual authentication schemes that require a user's input password as part of the verification process, there is a higher vulnerability to hackers because the password is human-made rather than a computer-generated certificate. While applications could simply require users to use a computer-generated password, it is inconvenient for people to remember. User-made passwords and the ability to change one's password are important for making an application user-friendly, so many schemes work to accommodate the characteristic. Researchers note that a password based protocol with mutual authentication is important because user identities and passwords are still protected, as the messages are only readable to the two parties involved.However, a negative aspect about password-based authentication is that password tables can take up a lot of memory space. One way around using a lot of memory during a password-based authentication scheme is to implement one-time passwords (OTP), which is a password sent to the user via SMS or email. OTPs are time-sensitive, which means that they will expire after a certain amount of time and that memory does not need to be stored.\n\n\n*** Multi-factor authentication ***\nRecently, more schemes have higher level authentication than password based schemes. While password-based authentication is considered as \"single-factor authentication,\" schemes are beginning to implement smart card (two-factor) or biometric-based (three-factor) authentication schemes. Smart cards are simpler to implement and easy for authentication, but still have risks of being tampered with. Biometrics have grown more popular over password-based schemes because it is more difficult to copy or guess session keys when using biometrics, but it can be difficult to encrypt noisy data. Due to these security risks and limitations, schemes can still employ mutual authentication regardless of how many authentication factors are added.\n\n== Certificate based schemes and system applications ==\nMutual authentication is often found in schemes employed in the Internet of Things (IoT), where physical objects are incorporated into the Internet and can communicate via IP address. Authentication schemes can be applied to many types of systems that involve data transmission. As the Internet's presence in mechanical systems increases, writing effective security schemes for large numbers of users, objects, and servers can become challenging, especially when needing schemes to be lightweight and have low computational costs. Instead of password-based authentication, devices will use certificates to verify each other's identities.\n\n\n*** Radio networks ***\nMutual authentication can be satisfied in radio network schemes, where data transmissions through radio frequencies are secure after verifying the sender and receiver.Radio frequency identification (RFID) tags are commonly used for object detection, which many manufacturers are implementing into their warehouse systems for automation. This allows for a faster way to keep up with inventory and track objects. However, keeping track of items in a system with RFID tags that transmit data to a cloud server increases the chances of security risks, as there are now more digital elements to keep track of. A three way mutual authentication can occur between RFID tags, the tag readers, and the cloud network that stores this data in order to keep RFID tag data secure and unable to be manipulated.Similarly, an alternate RFID tag and reader system that assigns designated readers to tags has been proposed for extra security and low memory cost. Instead of considering all tag readers as one entity, only certain readers can read specific tags. With this method, if a reader is breached, it will not affect the whole system. Individual readers will communicate with specific tags during mutual authentication, which runs in constant time as readers use the same private key for the authentication process.\nMany e-Healthcare systems that remotely monitor patient health data use wireless body area networks (WBAN) that transmit data through radio frequencies. This is beneficial for patients that should not be disturbed while being monitored, and can reduced the workload for medical worker and allow them to focus on the more hands-on jobs. However, a large concern for healthcare providers and patients about using remote health data tracking is that sensitive patient data is being transmitted through unsecured channels, so authentication occurs between the medical body area network user (the patient), the Healthcare Service Provider (HSP) and the trusted third party.\n\n\n*** Cloud based computing ***\ne-Healthcare clouds are another way to store patient data collected remotely. Clouds are useful for storing large amounts of data, such as medical information, that can be accessed by many devices whenever needed. Telecare Medical Information Systems (TMIS), an important way for medical patients to receive healthcare remotely, can ensure secured data with mutual authentication verification schemes. Blockchain is one way that has been proposed to mutually authenticate the user to the database, by authenticating with the main mediBchain node and keeping patient anonymity.Fog-cloud computing is a networking system that can handle large amounts of data, but still has limitations regarding computational and memory cost. Mobile edge computing (MEC) is considered to be an improved, more lightweight fog-cloud computing networking system, and can be used for medical technology that also revolves around location-based data. Due to the large physical range required of locational tracking, 5G networks can send data to the edge of the cloud to store data. An application like smart watches that track patient health data can be used to call the nearest hospital if the patient shows a negative change in vitals.Fog node networks can be implemented in car automation, keeping data about the car and its surrounding states secure. By authenticating the fog nodes and the vehicle, vehicular handoff becomes a safe process and the car\u2019s system is safe from hackers.\n\n\n*** Machine to machine verification ***\nMany systems that do not require a human user as part of the system also have protocols that mutually authenticate between parties. In unmanned aerial vehicle (UAV) systems, a platform authentication occurs rather than user authentication. Mutual authentication during vehicle communication prevents one vehicle's system from being breached, which can then affect the whole system negatively. For example, a system of drones can be employed for agriculture work and cargo delivery, but if one drone were to be breached, the whole system has the potential to collapse."
    }
  },
  {
    "instruction": "Write an answer to the following question: How many processes are identified in the COBIT framework?",
    "context": "",
    "output": "The COBIT framework identifies five main processes: Evaluate, Direct and Monitor (EDM); Align, Plan and Organize (APO); Build, Acquire and Implement (BAI); Deliver, Service and Support (DSS); and Monitor, Evaluate and Assess (MEA).",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How many processes are identified in the COBIT framework?",
      "answer": "The COBIT framework identifies five main processes: Evaluate, Direct and Monitor (EDM); Align, Plan and Organize (APO); Build, Acquire and Implement (BAI); Deliver, Service and Support (DSS); and Monitor, Evaluate and Assess (MEA)."
    }
  },
  {
    "instruction": "2017 Westminster data breach\n\n==Introduction==\nThe 2017 Westminster data breach occurred on 23 June 2017, when an unauthorised attempt was made to gain access to email accounts belonging to a number of politicians at the United Kingdom's Houses of Parliament. Whitehall officials have claimed that Iran was behind the attack. The incident was followed by an attempt to hack accounts belonging to politicians at the Scottish Parliament in August 2017.\n\n\n\n== Events ==\nParliamentarians were told about the cyberattack on the evening of 23 June, and it was made public knowledge the following day by Chris Rennard, a Liberal Democrat member of the House of Lords who posted a request on social media asking people needing to contact him urgently to do so via text message. Remote access to politicians email accounts was disabled.\nHowever, a spokesperson for the House of Commons said that this was a precautionary measure to protect security rather than a consequence of the cyberattack itself. The matter is being investigated by the National Cyber Security Centre with assistance from the National Crime Agency.Westminster authorities described the attack as \"sustained and determined\", and follows media reports that the email passwords of government ministers had been obtained by hackers and were being sold online.On 25 June, a Westminster spokesperson confirmed the cyberattack had been an attempt to hack email accounts with weak passwords, but that an investigation had found less than 1% of the 9,000 email addresses associated with parliament had been compromised\u2014a figure representing around 90 email accounts. However, it was still being treated as a serious security breach: \"The figure is less than many feared, but is still a breach.\" MPs subsequently said that agencies with links to either Russia or North Korea were suspected of being behind the attack.\n\n== Holyrood cyberattack ==\nOn 15 August, officials at Holyrood, home of the Scottish Parliament warned that accounts belonging to Members of the Scottish Parliament (MSPs) were currently the subject of a Brute-force attack which was attempting to crack weak passwords, but that no accounts had been compromised. However, MSPs were warned they may find themselves temporarily locked out of their accounts for security reasons. News outlets, such as The Guardian reported the attack was similar in nature to the one that had occurred at Westminster. The following day officials said that Holyrood was working with the UK's National Cyber Security Centre to increase security measures.\n\nQ: What measures were taken in response to the Westminster data breach?",
    "context": "",
    "output": "A: In response to the Westminster data breach, remote access to politicians' email accounts was disabled as a precautionary measure to protect security. However, a spokesperson for the House of Commons clarified that this was not a consequence of the cyberattack itself but a security measure. An investigation was initiated by the National Cyber Security Centre with assistance from the National Crime Agency.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What measures were taken in response to the Westminster data breach?",
      "answer": "In response to the Westminster data breach, remote access to politicians' email accounts was disabled as a precautionary measure to protect security. However, a spokesperson for the House of Commons clarified that this was not a consequence of the cyberattack itself but a security measure. An investigation was initiated by the National Cyber Security Centre with assistance from the National Crime Agency.",
      "context": "2017 Westminster data breach\n\n==Introduction==\nThe 2017 Westminster data breach occurred on 23 June 2017, when an unauthorised attempt was made to gain access to email accounts belonging to a number of politicians at the United Kingdom's Houses of Parliament. Whitehall officials have claimed that Iran was behind the attack. The incident was followed by an attempt to hack accounts belonging to politicians at the Scottish Parliament in August 2017.\n\n\n\n== Events ==\nParliamentarians were told about the cyberattack on the evening of 23 June, and it was made public knowledge the following day by Chris Rennard, a Liberal Democrat member of the House of Lords who posted a request on social media asking people needing to contact him urgently to do so via text message. Remote access to politicians email accounts was disabled.\nHowever, a spokesperson for the House of Commons said that this was a precautionary measure to protect security rather than a consequence of the cyberattack itself. The matter is being investigated by the National Cyber Security Centre with assistance from the National Crime Agency.Westminster authorities described the attack as \"sustained and determined\", and follows media reports that the email passwords of government ministers had been obtained by hackers and were being sold online.On 25 June, a Westminster spokesperson confirmed the cyberattack had been an attempt to hack email accounts with weak passwords, but that an investigation had found less than 1% of the 9,000 email addresses associated with parliament had been compromised\u2014a figure representing around 90 email accounts. However, it was still being treated as a serious security breach: \"The figure is less than many feared, but is still a breach.\" MPs subsequently said that agencies with links to either Russia or North Korea were suspected of being behind the attack.\n\n== Holyrood cyberattack ==\nOn 15 August, officials at Holyrood, home of the Scottish Parliament warned that accounts belonging to Members of the Scottish Parliament (MSPs) were currently the subject of a Brute-force attack which was attempting to crack weak passwords, but that no accounts had been compromised. However, MSPs were warned they may find themselves temporarily locked out of their accounts for security reasons. News outlets, such as The Guardian reported the attack was similar in nature to the one that had occurred at Westminster. The following day officials said that Holyrood was working with the UK's National Cyber Security Centre to increase security measures."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does Windows Update Agent in Windows 10 differ from its previous versions?",
    "context": "",
    "output": "Windows Update Agent in Windows 10 differs from its previous versions by no longer allowing the manual, selective installation of updates. All updates, regardless of type, are downloaded and installed automatically, and users are only given the option to choose whether their system would reboot automatically to install updates when the system is inactive, or be notified to schedule a reboot.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does Windows Update Agent in Windows 10 differ from its previous versions?",
      "answer": "Windows Update Agent in Windows 10 differs from its previous versions by no longer allowing the manual, selective installation of updates. All updates, regardless of type, are downloaded and installed automatically, and users are only given the option to choose whether their system would reboot automatically to install updates when the system is inactive, or be notified to schedule a reboot."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are some economic factors that influence the level of cyber-security and what are the sources of cyber-security market failure?",
    "context": "",
    "output": "The optimal level of cyber-security depends largely on the incentives facing providers and the incentives facing perpetrators. Potential prisoner\u2019s dilemma, public goods, and negative externalities can become sources of cyber-security market failure when private returns to security are less than the social returns. Therefore, the higher the ratio of public to private benefit, the stronger the case for enacting new public policies to realign incentives for actors to fight cyber-crime with increased investment in cyber-security.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are some economic factors that influence the level of cyber-security and what are the sources of cyber-security market failure?",
      "answer": "The optimal level of cyber-security depends largely on the incentives facing providers and the incentives facing perpetrators. Potential prisoner\u2019s dilemma, public goods, and negative externalities can become sources of cyber-security market failure when private returns to security are less than the social returns. Therefore, the higher the ratio of public to private benefit, the stronger the case for enacting new public policies to realign incentives for actors to fight cyber-crime with increased investment in cyber-security."
    }
  },
  {
    "instruction": "Write an answer to the following question: When was GhostNet discovered and reported?",
    "context": "",
    "output": "GhostNet was discovered in March 2009 and reported by The New York Times on March 29, 2009.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "When was GhostNet discovered and reported?",
      "answer": "GhostNet was discovered in March 2009 and reported by The New York Times on March 29, 2009."
    }
  },
  {
    "instruction": "Write an answer to the following question: Why was it necessary to have a different release with a modified kernel for labeled security environments prior to the Solaris 10 11/06 update?",
    "context": "",
    "output": "Before the Solaris 10 11/06 update, a separate release with a modified kernel was necessary for labeled security environments to enforce mandatory access control policies effectively.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Why was it necessary to have a different release with a modified kernel for labeled security environments prior to the Solaris 10 11/06 update?",
      "answer": "Before the Solaris 10 11/06 update, a separate release with a modified kernel was necessary for labeled security environments to enforce mandatory access control policies effectively."
    }
  },
  {
    "instruction": "Write an answer to the following question: Which architectures does Pentoo support for its Live CD and Live USB distributions?",
    "context": "",
    "output": "Pentoo is available for both 32-bit and 64-bit architectures, ensuring compatibility with a wide variety of hardware platforms.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Which architectures does Pentoo support for its Live CD and Live USB distributions?",
      "answer": "Pentoo is available for both 32-bit and 64-bit architectures, ensuring compatibility with a wide variety of hardware platforms."
    }
  },
  {
    "instruction": "Patch Tuesday\n\n==Introduction==\nPatch Tuesday (also known as Update Tuesday) is an unofficial term used to refer to when Microsoft, Adobe, Oracle and others regularly release software patches for their software products. It is widely referred to in this way by the industry. Microsoft formalized Patch Tuesday in October 2003. Patch Tuesday is known within Microsoft also as the \"B\" release, to distinguish it from the \"C\" and \"D\" releases that occur in the third and fourth weeks of the month, respectively.Patch Tuesday occurs on the second Tuesday of each month in North America. Critical security updates are occasionally released outside of the normal Patch Tuesday cycle; these are known as \"Out-of-band\" releases. As far as the integrated Windows Update (WU) function is concerned, Patch Tuesday begins at 10:00 a.m. PST. Vulnerability information is immediately available in the Security Update Guide. The updates show up in Download Center before they are added to WU, and the KB articles are unlocked later.\nDaily updates consist of malware database refreshes for Microsoft Defender and Microsoft Security Essentials, these updates are not part of the normal Patch Tuesday release cycle.\n\n== Security implications ==\nAn obvious security implication is that security problems that have a solution are withheld from the public for up to a month. This policy is adequate when the vulnerability is not widely known or is extremely obscure, but that is not always the case.\nThere have been cases where vulnerability information became public or actual worms were circulating prior to the next scheduled Patch Tuesday. In critical cases Microsoft issues corresponding patches as they become ready, alleviating the risk if updates are checked for and installed frequently.\nAt the Ignite 2015 event, Microsoft revealed a change in distributing security patches. They release security updates to home PCs, tablets and phones as soon as they are ready, while enterprise customers will stay on the monthly update cycle, which was reworked as Windows Update for Business.\n\n== Exploit Wednesday ==\nMany exploitation events are seen shortly after the release of a patch; analysis of the patch helps exploit developers to immediately take advantage of the previously undisclosed vulnerability, which will remain in unpatched systems. Therefore, the term \"Exploit Wednesday\" was coined.\n\n\n*** Discontinued Windows versions ***\nMicrosoft warned users that it discontinued support for Windows XP starting on April 8, 2014 \u2013  users running Windows XP afterwards would be at the risk of attacks. As security patches of newer Windows versions can reveal similar (or same) vulnerabilities already present in older Windows versions, this can allow attacks on devices with unsupported Windows versions (cf. \"zero-day attacks\"). However Microsoft stopped fixing such (and other) vulnerabilities in unsupported Windows versions, regardless how widely known they became, leaving devices running these Windows versions vulnerable to attacks.  Microsoft made a singular exception during the rapid spread of the WannaCry ransomware and released patches in May 2017 for the by then-unsupported Windows XP, Windows 8, and Windows Server 2003 (in addition to then supported Windows versions).For Windows Vista \"extended support\" was ended April 11, 2017, which will leave vulnerabilities discovered afterwards unfixed, creating the same situation for Vista as for XP before.For Windows 7 (including Service Pack 1), support ended January 14, 2020, and on January 10, 2023 for Windows 8.1; this will cause the same \"unfixed vulnerabilities\" issue for users of these operating systems. Support for Windows 8 already ended January 12, 2016 (with users having to install Windows 8.1 or Windows 10 to continue to get support), and support for Windows 7 without SP1 was ended April 9, 2013 (with the ability to install SP1 to continue to get support until 2020, or having to install Windows 8.1 or Windows 10 to receive support after 2020).\n\n\n*** Windows 10 and 11 ***\n\nStarting with Windows 10, Microsoft began releasing feature updates of Windows twice per year. These releases brought new functionalities, and are governed by Microsoft's modern lifecycle policy, which specifies a support period of 18-36 months. This is in contrast to previous Windows versions, which received only infrequent updates via service packs, and whose support was governed by the fixed lifecycle policy. With the release of Windows 11, both Windows 10 and 11 started receiving annual feature updates in the second half of the year.\nOnce a release's support period ends, devices must be updated to the latest feature update in order to receive updates from Microsoft. As such, for Home and Pro editions of Windows 10 and 11, the latest Windows version is downloaded and installed automatically when the device approaches the end of support date.\n\nIn addition to the commonly used editions like Home and Pro, Microsoft offers specialized Long-Term Servicing Channel (LTSC) versions of Windows 10 with longer support timelines, governed by Microsoft's fixed lifecycle policy. For instance, Windows 10 Enterprise 2016 LTSB will receive extended support until October 13, 2026, and Windows 10 LTSC 2019 will receive extended support until January 9, 2029.\n\n== Adoption by other companies ==\nSAP's \"Security Patch Day\", when the company advises users to install security updates, was chosen to coincide with Patch Tuesdays. Adobe Systems' update schedule for Flash Player since November 2012 also coincides with Patch Tuesday. One of the reasons for this is that Flash Player comes as part of Windows starting with Windows 8 and Flash Player updates for the built-in and the plugin based version both need to be published at the same time in order to prevent reverse-engineering threats. Oracle's quarterly updates coincide with Patch Tuesday.\n\n== Bandwidth impact ==\nWindows Update uses the Background Intelligent Transfer Service (BITS) to download the updates, using idle network bandwidth. However BITS will use the speed as reported by the network interface (NIC) to calculate bandwidth. This can lead to bandwidth calculation errors, for example when a fast network adapter (e.g. 10 Mbit/s) is connected to the network via a slow link (e.g. 56 kbit/s) \u2013  according to Microsoft \"BITS will compete for the full bandwidth [of the NIC] ... BITS has no visibility of the network traffic beyond the client.\"Furthermore, the Windows Update servers of Microsoft do not honor the TCP's slow start congestion control strategy. As a result, other users on the same network may experience significantly slower connections from machines actively retrieving updates. This can be particularly noticeable in environments where many machines individually retrieve updates over a shared, bandwidth-constrained link such as those found in many multi-PC homes and small to medium-sized businesses. Bandwidth demands of patching large numbers of computers can be reduced significantly by deploying Windows Server Update Services (WSUS) to distribute the updates locally.\nIn addition to updates being downloaded from Microsoft servers, Windows 10 devices can \"share\" updates in a peer-to-peer fashion with other Windows 10 devices on the local network, or even with Windows 10 devices on the internet. This can potentially distribute updates faster while reducing usage for networks with a metered connection.\nQuestion: What is the term for exploitation events seen shortly after the release of a patch?",
    "context": "",
    "output": "Answer: The term \"Exploit Wednesday\" was coined to refer to these exploitation events, as analysis of the patch helps exploit developers immediately take advantage of the previously undisclosed vulnerability, which remains in unpatched systems.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the term for exploitation events seen shortly after the release of a patch?",
      "answer": "The term \"Exploit Wednesday\" was coined to refer to these exploitation events, as analysis of the patch helps exploit developers immediately take advantage of the previously undisclosed vulnerability, which remains in unpatched systems.",
      "context": "Patch Tuesday\n\n==Introduction==\nPatch Tuesday (also known as Update Tuesday) is an unofficial term used to refer to when Microsoft, Adobe, Oracle and others regularly release software patches for their software products. It is widely referred to in this way by the industry. Microsoft formalized Patch Tuesday in October 2003. Patch Tuesday is known within Microsoft also as the \"B\" release, to distinguish it from the \"C\" and \"D\" releases that occur in the third and fourth weeks of the month, respectively.Patch Tuesday occurs on the second Tuesday of each month in North America. Critical security updates are occasionally released outside of the normal Patch Tuesday cycle; these are known as \"Out-of-band\" releases. As far as the integrated Windows Update (WU) function is concerned, Patch Tuesday begins at 10:00 a.m. PST. Vulnerability information is immediately available in the Security Update Guide. The updates show up in Download Center before they are added to WU, and the KB articles are unlocked later.\nDaily updates consist of malware database refreshes for Microsoft Defender and Microsoft Security Essentials, these updates are not part of the normal Patch Tuesday release cycle.\n\n== Security implications ==\nAn obvious security implication is that security problems that have a solution are withheld from the public for up to a month. This policy is adequate when the vulnerability is not widely known or is extremely obscure, but that is not always the case.\nThere have been cases where vulnerability information became public or actual worms were circulating prior to the next scheduled Patch Tuesday. In critical cases Microsoft issues corresponding patches as they become ready, alleviating the risk if updates are checked for and installed frequently.\nAt the Ignite 2015 event, Microsoft revealed a change in distributing security patches. They release security updates to home PCs, tablets and phones as soon as they are ready, while enterprise customers will stay on the monthly update cycle, which was reworked as Windows Update for Business.\n\n== Exploit Wednesday ==\nMany exploitation events are seen shortly after the release of a patch; analysis of the patch helps exploit developers to immediately take advantage of the previously undisclosed vulnerability, which will remain in unpatched systems. Therefore, the term \"Exploit Wednesday\" was coined.\n\n\n*** Discontinued Windows versions ***\nMicrosoft warned users that it discontinued support for Windows XP starting on April 8, 2014 \u2013  users running Windows XP afterwards would be at the risk of attacks. As security patches of newer Windows versions can reveal similar (or same) vulnerabilities already present in older Windows versions, this can allow attacks on devices with unsupported Windows versions (cf. \"zero-day attacks\"). However Microsoft stopped fixing such (and other) vulnerabilities in unsupported Windows versions, regardless how widely known they became, leaving devices running these Windows versions vulnerable to attacks.  Microsoft made a singular exception during the rapid spread of the WannaCry ransomware and released patches in May 2017 for the by then-unsupported Windows XP, Windows 8, and Windows Server 2003 (in addition to then supported Windows versions).For Windows Vista \"extended support\" was ended April 11, 2017, which will leave vulnerabilities discovered afterwards unfixed, creating the same situation for Vista as for XP before.For Windows 7 (including Service Pack 1), support ended January 14, 2020, and on January 10, 2023 for Windows 8.1; this will cause the same \"unfixed vulnerabilities\" issue for users of these operating systems. Support for Windows 8 already ended January 12, 2016 (with users having to install Windows 8.1 or Windows 10 to continue to get support), and support for Windows 7 without SP1 was ended April 9, 2013 (with the ability to install SP1 to continue to get support until 2020, or having to install Windows 8.1 or Windows 10 to receive support after 2020).\n\n\n*** Windows 10 and 11 ***\n\nStarting with Windows 10, Microsoft began releasing feature updates of Windows twice per year. These releases brought new functionalities, and are governed by Microsoft's modern lifecycle policy, which specifies a support period of 18-36 months. This is in contrast to previous Windows versions, which received only infrequent updates via service packs, and whose support was governed by the fixed lifecycle policy. With the release of Windows 11, both Windows 10 and 11 started receiving annual feature updates in the second half of the year.\nOnce a release's support period ends, devices must be updated to the latest feature update in order to receive updates from Microsoft. As such, for Home and Pro editions of Windows 10 and 11, the latest Windows version is downloaded and installed automatically when the device approaches the end of support date.\n\nIn addition to the commonly used editions like Home and Pro, Microsoft offers specialized Long-Term Servicing Channel (LTSC) versions of Windows 10 with longer support timelines, governed by Microsoft's fixed lifecycle policy. For instance, Windows 10 Enterprise 2016 LTSB will receive extended support until October 13, 2026, and Windows 10 LTSC 2019 will receive extended support until January 9, 2029.\n\n== Adoption by other companies ==\nSAP's \"Security Patch Day\", when the company advises users to install security updates, was chosen to coincide with Patch Tuesdays. Adobe Systems' update schedule for Flash Player since November 2012 also coincides with Patch Tuesday. One of the reasons for this is that Flash Player comes as part of Windows starting with Windows 8 and Flash Player updates for the built-in and the plugin based version both need to be published at the same time in order to prevent reverse-engineering threats. Oracle's quarterly updates coincide with Patch Tuesday.\n\n== Bandwidth impact ==\nWindows Update uses the Background Intelligent Transfer Service (BITS) to download the updates, using idle network bandwidth. However BITS will use the speed as reported by the network interface (NIC) to calculate bandwidth. This can lead to bandwidth calculation errors, for example when a fast network adapter (e.g. 10 Mbit/s) is connected to the network via a slow link (e.g. 56 kbit/s) \u2013  according to Microsoft \"BITS will compete for the full bandwidth [of the NIC] ... BITS has no visibility of the network traffic beyond the client.\"Furthermore, the Windows Update servers of Microsoft do not honor the TCP's slow start congestion control strategy. As a result, other users on the same network may experience significantly slower connections from machines actively retrieving updates. This can be particularly noticeable in environments where many machines individually retrieve updates over a shared, bandwidth-constrained link such as those found in many multi-PC homes and small to medium-sized businesses. Bandwidth demands of patching large numbers of computers can be reduced significantly by deploying Windows Server Update Services (WSUS) to distribute the updates locally.\nIn addition to updates being downloaded from Microsoft servers, Windows 10 devices can \"share\" updates in a peer-to-peer fashion with other Windows 10 devices on the local network, or even with Windows 10 devices on the internet. This can potentially distribute updates faster while reducing usage for networks with a metered connection."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is a potential way to detect fiber tapping besides noting increased attenuation?",
    "context": "",
    "output": "A potential way to detect fiber tapping besides noting increased attenuation is by noting a change of scattering pattern in the point in line.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is a potential way to detect fiber tapping besides noting increased attenuation?",
      "answer": "A potential way to detect fiber tapping besides noting increased attenuation is by noting a change of scattering pattern in the point in line."
    }
  },
  {
    "instruction": "Write an answer to the following question: How is NordLocker's cloud storage monetized?",
    "context": "",
    "output": "NordLocker monetizes its cloud storage space by charging users for storage beyond the 3 GB provided with the free plan.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How is NordLocker's cloud storage monetized?",
      "answer": "NordLocker monetizes its cloud storage space by charging users for storage beyond the 3 GB provided with the free plan."
    }
  },
  {
    "instruction": "Write an answer to the following question: Does Session store, track, or log the metadata of user messages?",
    "context": "",
    "output": "According to the Oxen Project, the Oxen Service Nodes network is intended to not store, track, or log the metadata of user messages.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Does Session store, track, or log the metadata of user messages?",
      "answer": "According to the Oxen Project, the Oxen Service Nodes network is intended to not store, track, or log the metadata of user messages."
    }
  },
  {
    "instruction": "Write an answer to the following question: What was Ziften's role in the initial formation of the Microsoft Intelligent Security Association?",
    "context": "",
    "output": "Ziften was included as a member in the initial formation of the Microsoft Intelligent Security Association. This indicates that Ziften was recognized as a significant player in the cybersecurity industry and was considered a trusted partner by Microsoft in the field of intelligent security.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was Ziften's role in the initial formation of the Microsoft Intelligent Security Association?",
      "answer": "Ziften was included as a member in the initial formation of the Microsoft Intelligent Security Association. This indicates that Ziften was recognized as a significant player in the cybersecurity industry and was considered a trusted partner by Microsoft in the field of intelligent security."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the WIPO resolution procedure and how does it address Typosquatting?",
    "context": "",
    "output": "The World Intellectual Property Organization (WIPO) offers a Uniform Domain-Name Dispute-Resolution Policy (UDRP) that allows trademark holders to file a case against Typosquatters. To win a case, the complainant must prove that the registered domain name is identical or confusingly similar to their trademark, that the registrant has no legitimate interest in the domain name, and that the domain name is being used in bad faith.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the WIPO resolution procedure and how does it address Typosquatting?",
      "answer": "The World Intellectual Property Organization (WIPO) offers a Uniform Domain-Name Dispute-Resolution Policy (UDRP) that allows trademark holders to file a case against Typosquatters. To win a case, the complainant must prove that the registered domain name is identical or confusingly similar to their trademark, that the registrant has no legitimate interest in the domain name, and that the domain name is being used in bad faith."
    }
  },
  {
    "instruction": "Write an answer to the following question: What legislation has been enacted in Egypt in 2018 related to computer crimes?",
    "context": "",
    "output": "In 2018, Egypt enacted legislation criminalizing fake news and terrorism, setting a flag on accounts which carry more than 5,000 subscribers or followers.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What legislation has been enacted in Egypt in 2018 related to computer crimes?",
      "answer": "In 2018, Egypt enacted legislation criminalizing fake news and terrorism, setting a flag on accounts which carry more than 5,000 subscribers or followers."
    }
  },
  {
    "instruction": "Write an answer to the following question: How can weak passwords contribute to malware infections, and how can using strong passwords and two-factor authentication help mitigate this risk?",
    "context": "",
    "output": "A credential attack occurs when a user account with administrative privileges is cracked and that account is used to provide malware with appropriate privileges. This usually happens because the weakest form of account security is used, which is typically a short password that can be cracked using a dictionary or brute force attack. Using strong passwords and enabling two-factor authentication can reduce this risk.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can weak passwords contribute to malware infections, and how can using strong passwords and two-factor authentication help mitigate this risk?",
      "answer": "A credential attack occurs when a user account with administrative privileges is cracked and that account is used to provide malware with appropriate privileges. This usually happens because the weakest form of account security is used, which is typically a short password that can be cracked using a dictionary or brute force attack. Using strong passwords and enabling two-factor authentication can reduce this risk."
    }
  },
  {
    "instruction": "Write an answer to the following question: What previous attacks has the Lanxiang Vocational School been connected to?",
    "context": "",
    "output": "The Lanxiang Vocational School has been connected to previous attacks, including Google and the Operation Aurora attack.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What previous attacks has the Lanxiang Vocational School been connected to?",
      "answer": "The Lanxiang Vocational School has been connected to previous attacks, including Google and the Operation Aurora attack."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the market size and growth rate of home security systems?",
    "context": "",
    "output": "The market size of home security systems reached $4.8 billion in 2018 and had a compound annual growth rate of 22.4% between 2011 and 2018.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the market size and growth rate of home security systems?",
      "answer": "The market size of home security systems reached $4.8 billion in 2018 and had a compound annual growth rate of 22.4% between 2011 and 2018."
    }
  },
  {
    "instruction": "Context: Slide attack\n\n==Introduction==\nThe slide attack is a form of cryptanalysis designed to deal with the prevailing idea that even weak ciphers can become very strong by increasing the number of rounds, which can ward off a differential attack. The slide attack works in such a way as to make the number of rounds in a cipher irrelevant. Rather than looking at the data-randomizing aspects of the block cipher, the slide attack works by analyzing the key schedule and exploiting weaknesses in it to break the cipher. The most common one is the keys repeating in a cyclic manner.\nThe attack was first described by David Wagner and Alex Biryukov. Bruce Schneier first suggested the term slide attack to them, and they used it in their 1999 paper describing the attack.\nThe only requirements for a slide attack to work on a cipher is that it can be broken down into multiple rounds of an identical F function. This probably means that it has a cyclic key schedule. The F function must be vulnerable to a known-plaintext attack. The slide attack is closely related to the related-key attack.\nThe idea of the slide attack has roots in a paper published by Edna Grossman and Bryant Tuckerman in an IBM Technical Report in 1977. Grossman and Tuckerman demonstrated the attack on a weak block cipher named New Data Seal (NDS). The attack relied on the fact that the cipher has identical subkeys in each round, so the cipher had a cyclic key schedule with a cycle of only one key, which makes it an early version of the slide attack. A summary of the report, including a description of the NDS block cipher and the attack, is given in Cipher Systems (Beker & Piper, 1982).\n\n\n\n== The actual attack ==\nFirst, to introduce some notation. In this section assume the cipher takes n bit blocks and has a key-schedule using \n  \n    \n      \n        \n          K\n          \n            1\n          \n        \n        \u22ef\n        \n          K\n          \n            m\n          \n        \n      \n    \n    {\\displaystyle K_{1}\\cdots K_{m}}\n   as keys of any length.\nThe slide attack works by breaking the cipher up into identical permutation\nfunctions, F. This F function may consist of more than one round\nof the cipher; it is defined by the key-schedule. For example, if a cipher uses an alternating key schedule where it switches between a \n  \n    \n      \n        \n          K\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle K_{1}}\n   and \n  \n    \n      \n        \n          K\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle K_{2}}\n   for each round, the F function would consist of two rounds. Each of the \n  \n    \n      \n        \n          K\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle K_{i}}\n   will\nappear at least once in F.\nThe next step is to collect \n  \n    \n      \n        \n          2\n          \n            n\n            \n              /\n            \n            2\n          \n        \n      \n    \n    {\\displaystyle 2^{n/2}}\n   plaintext-ciphertext pairs. Depending on\nthe characteristics of the cipher fewer may suffice, but by the birthday problem no more than \n  \n    \n      \n        \n          2\n          \n            n\n            \n              /\n            \n            2\n          \n        \n      \n    \n    {\\displaystyle 2^{n/2}}\n   should be needed. These pairs, which denoted as \n  \n    \n      \n        (\n        P\n        ,\n        C\n        )\n      \n    \n    {\\displaystyle (P,C)}\n   are then used to find a slid pair which is denoted \n  \n    \n      \n        (\n        \n          P\n          \n            0\n          \n        \n        ,\n        \n          C\n          \n            0\n          \n        \n        )\n        (\n        \n          P\n          \n            1\n          \n        \n        ,\n        \n          C\n          \n            1\n          \n        \n        )\n      \n    \n    {\\displaystyle (P_{0},C_{0})(P_{1},C_{1})}\n  . A slid pair has the property that \n  \n    \n      \n        \n          P\n          \n            0\n\nQuestion: What is a slid pair, and how is it used in the slide attack?\n\nAnswer:",
    "context": "",
    "output": "A slid pair is a pair of plaintext-ciphertext (P, C) that has the property of being related in a specific way. The slid pair is used to reveal information about the cipher's structure and keys. By finding slid pairs, the slide attack can exploit the cyclic pattern of keys in the key schedule and potentially break the cipher.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is a slid pair, and how is it used in the slide attack?",
      "answer": "A slid pair is a pair of plaintext-ciphertext (P, C) that has the property of being related in a specific way. The slid pair is used to reveal information about the cipher's structure and keys. By finding slid pairs, the slide attack can exploit the cyclic pattern of keys in the key schedule and potentially break the cipher.",
      "context": "Slide attack\n\n==Introduction==\nThe slide attack is a form of cryptanalysis designed to deal with the prevailing idea that even weak ciphers can become very strong by increasing the number of rounds, which can ward off a differential attack. The slide attack works in such a way as to make the number of rounds in a cipher irrelevant. Rather than looking at the data-randomizing aspects of the block cipher, the slide attack works by analyzing the key schedule and exploiting weaknesses in it to break the cipher. The most common one is the keys repeating in a cyclic manner.\nThe attack was first described by David Wagner and Alex Biryukov. Bruce Schneier first suggested the term slide attack to them, and they used it in their 1999 paper describing the attack.\nThe only requirements for a slide attack to work on a cipher is that it can be broken down into multiple rounds of an identical F function. This probably means that it has a cyclic key schedule. The F function must be vulnerable to a known-plaintext attack. The slide attack is closely related to the related-key attack.\nThe idea of the slide attack has roots in a paper published by Edna Grossman and Bryant Tuckerman in an IBM Technical Report in 1977. Grossman and Tuckerman demonstrated the attack on a weak block cipher named New Data Seal (NDS). The attack relied on the fact that the cipher has identical subkeys in each round, so the cipher had a cyclic key schedule with a cycle of only one key, which makes it an early version of the slide attack. A summary of the report, including a description of the NDS block cipher and the attack, is given in Cipher Systems (Beker & Piper, 1982).\n\n\n\n== The actual attack ==\nFirst, to introduce some notation. In this section assume the cipher takes n bit blocks and has a key-schedule using \n  \n    \n      \n        \n          K\n          \n            1\n          \n        \n        \u22ef\n        \n          K\n          \n            m\n          \n        \n      \n    \n    {\\displaystyle K_{1}\\cdots K_{m}}\n   as keys of any length.\nThe slide attack works by breaking the cipher up into identical permutation\nfunctions, F. This F function may consist of more than one round\nof the cipher; it is defined by the key-schedule. For example, if a cipher uses an alternating key schedule where it switches between a \n  \n    \n      \n        \n          K\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle K_{1}}\n   and \n  \n    \n      \n        \n          K\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle K_{2}}\n   for each round, the F function would consist of two rounds. Each of the \n  \n    \n      \n        \n          K\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle K_{i}}\n   will\nappear at least once in F.\nThe next step is to collect \n  \n    \n      \n        \n          2\n          \n            n\n            \n              /\n            \n            2\n          \n        \n      \n    \n    {\\displaystyle 2^{n/2}}\n   plaintext-ciphertext pairs. Depending on\nthe characteristics of the cipher fewer may suffice, but by the birthday problem no more than \n  \n    \n      \n        \n          2\n          \n            n\n            \n              /\n            \n            2\n          \n        \n      \n    \n    {\\displaystyle 2^{n/2}}\n   should be needed. These pairs, which denoted as \n  \n    \n      \n        (\n        P\n        ,\n        C\n        )\n      \n    \n    {\\displaystyle (P,C)}\n   are then used to find a slid pair which is denoted \n  \n    \n      \n        (\n        \n          P\n          \n            0\n          \n        \n        ,\n        \n          C\n          \n            0\n          \n        \n        )\n        (\n        \n          P\n          \n            1\n          \n        \n        ,\n        \n          C\n          \n            1\n          \n        \n        )\n      \n    \n    {\\displaystyle (P_{0},C_{0})(P_{1},C_{1})}\n  . A slid pair has the property that \n  \n    \n      \n        \n          P\n          \n            0"
    }
  },
  {
    "instruction": "Context: Protocol-based intrusion detection system\n\n==Introduction==\nA protocol-based intrusion detection system (PIDS) is an intrusion detection system which is typically installed on a web server, and is used in the monitoring and analysis of the protocol in use by the computing system.  A PIDS will monitor the dynamic behavior and state of the protocol and will typically consist of a system or agent that would typically sit at the front end of a server, monitoring and analyzing the communication between a connected device and the system it is protecting.\nA typical use for a PIDS would be at the front end of a web server monitoring the HTTP (or HTTPS) stream.  Because it understands the HTTP relative to the web server/system it is trying to protect it can offer greater protection than less in-depth techniques such as filtering by IP address or port number alone, however this greater protection comes at the cost of increased computing on the web server.\nWhere HTTPS is in use then this system would need to reside in the \"shim\" or interface between where HTTPS is un-encrypted and immediately prior to it entering the Web presentation layer.\n\n\n\n== Monitoring dynamic behavior ==\nAt a basic level a PIDS would look for, and enforce, the correct use of the protocol. \nAt a more advanced level the PIDS can learn or be taught acceptable constructs of the protocol, and thus better detect anomalous behavior.\n\nQuestion: What is the role of a PIDS in detecting anomalous behavior in a protocol?\n\nAnswer:",
    "context": "",
    "output": "The role of a PIDS in detecting anomalous behavior in a protocol is to monitor the dynamic behavior of the protocol, learn or be taught acceptable constructs, and detect any deviations from the expected behavior that may indicate an intrusion attempt.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of a PIDS in detecting anomalous behavior in a protocol?",
      "answer": "The role of a PIDS in detecting anomalous behavior in a protocol is to monitor the dynamic behavior of the protocol, learn or be taught acceptable constructs, and detect any deviations from the expected behavior that may indicate an intrusion attempt.",
      "context": "Protocol-based intrusion detection system\n\n==Introduction==\nA protocol-based intrusion detection system (PIDS) is an intrusion detection system which is typically installed on a web server, and is used in the monitoring and analysis of the protocol in use by the computing system.  A PIDS will monitor the dynamic behavior and state of the protocol and will typically consist of a system or agent that would typically sit at the front end of a server, monitoring and analyzing the communication between a connected device and the system it is protecting.\nA typical use for a PIDS would be at the front end of a web server monitoring the HTTP (or HTTPS) stream.  Because it understands the HTTP relative to the web server/system it is trying to protect it can offer greater protection than less in-depth techniques such as filtering by IP address or port number alone, however this greater protection comes at the cost of increased computing on the web server.\nWhere HTTPS is in use then this system would need to reside in the \"shim\" or interface between where HTTPS is un-encrypted and immediately prior to it entering the Web presentation layer.\n\n\n\n== Monitoring dynamic behavior ==\nAt a basic level a PIDS would look for, and enforce, the correct use of the protocol. \nAt a more advanced level the PIDS can learn or be taught acceptable constructs of the protocol, and thus better detect anomalous behavior."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the use of internal maps in Rubberhose enhance the security of the system?",
    "context": "",
    "output": "The use of internal maps in Rubberhose ensures that the location of encrypted data remains secure, as each map can only be decrypted via its specific passphrase.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the use of internal maps in Rubberhose enhance the security of the system?",
      "answer": "The use of internal maps in Rubberhose ensures that the location of encrypted data remains secure, as each map can only be decrypted via its specific passphrase."
    }
  },
  {
    "instruction": "Write an answer to the following question: In what scenarios might the use of the md5sum program be most appropriate?",
    "context": "",
    "output": "The md5sum program is most appropriate for identifying known files and verifying their integrity in situations that are not security-related, such as when checking for file transfer errors, disk errors, or non-malicious meddling.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "In what scenarios might the use of the md5sum program be most appropriate?",
      "answer": "The md5sum program is most appropriate for identifying known files and verifying their integrity in situations that are not security-related, such as when checking for file transfer errors, disk errors, or non-malicious meddling."
    }
  },
  {
    "instruction": "Norton Confidential\n\n==Introduction==\nNorton Confidential is a program released in 2006 designed to encrypt passwords online and to detect phishing sites.\n\n\n\n\n\nHow does Norton Confidential address the issue of online security and what are its two main features?",
    "context": "",
    "output": "A: Norton Confidential is a cybersecurity program that focuses on two main aspects of online security: encrypting passwords and detecting phishing sites. Encrypting passwords ensures that even if the data is intercepted, it cannot be read without the decryption key, adding an extra layer of protection. Phishing site detection helps users stay safe from malicious websites that attempt to steal sensitive information by mimicking legitimate ones. Together, these features enhance online security by protecting users' passwords and alerting them to potential threats.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does Norton Confidential address the issue of online security and what are its two main features?",
      "answer": "Norton Confidential is a cybersecurity program that focuses on two main aspects of online security: encrypting passwords and detecting phishing sites. Encrypting passwords ensures that even if the data is intercepted, it cannot be read without the decryption key, adding an extra layer of protection. Phishing site detection helps users stay safe from malicious websites that attempt to steal sensitive information by mimicking legitimate ones. Together, these features enhance online security by protecting users' passwords and alerting them to potential threats.",
      "context": "Norton Confidential\n\n==Introduction==\nNorton Confidential is a program released in 2006 designed to encrypt passwords online and to detect phishing sites.\n\n\n\n"
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the Fiat-Shamir heuristic convert an interactive proof into a non-interactive one?",
    "context": "",
    "output": "The Fiat-Shamir heuristic converts an interactive proof into a non-interactive one by using a hash function to generate the challenge. This eliminates the need for interaction between the prover and the verifier.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the Fiat-Shamir heuristic convert an interactive proof into a non-interactive one?",
      "answer": "The Fiat-Shamir heuristic converts an interactive proof into a non-interactive one by using a hash function to generate the challenge. This eliminates the need for interaction between the prover and the verifier."
    }
  },
  {
    "instruction": "Mutual authentication\n\n==Introduction==\nMutual authentication or two-way authentication (not to be confused with two-factor authentication) refers to two parties authenticating each other at the same time in an authentication protocol. It is a default mode of authentication in some protocols (IKE, SSH) and optional in others (TLS).\nMutual authentication is a desired characteristic in verification schemes that transmit sensitive data, in order to ensure data security. Mutual authentication can be accomplished with two types of credentials: usernames and passwords, and public key certificates.\nMutual authentication is often employed in the Internet of Things (IoT). Writing effective security schemes in IoT systems can become challenging, especially when schemes are desired to be lightweight and have low computational costs. Mutual authentication is a crucial security step that can defend against many adversarial attacks, which otherwise can have large consequences if IoT systems (such as e-Healthcare servers) are hacked. In scheme analyses done of past works, a lack of mutual authentication had been considered a weakness in data transmission schemes.\n\n\n\n== Process steps and verification ==\nSchemes that have a mutual authentication step may use different methods of encryption, communication, and verification, but they all share one thing in common: each entity involved in the communication is verified. If Alice wants to communicate with Bob, they will both authenticate the other and verify that it is who they are expecting to communicate with before any data or messages are transmitted. A mutual authentication process that exchanges user IDs may be implemented as follows:\nAlice sends an encrypted message to Bob to show that Alice is a valid user.\nBob verifies message:\nBob checks the format and timestamp. If either is incorrect or invalid, the session is aborted.\nThe message is then decrypted with Bob's secret key, giving Alice's ID.\nBob checks if the message matches a valid user. If not, the session is aborted.\nBob sends Alice a message back to show that Bob is a valid user.\nAlice verifies the message:\nAlice checks the format and timestamp. If either is incorrect or invalid, the session is aborted.\nThen, the message is decrypted with Alice's secret key, giving Bob's ID.\nAlice checks if the message matches a valid user. If not, the session is aborted.\nAt this point, both parties are verified to be who they claim to be and safe for the other to communicate with. Lastly, Alice and Bob will create a shared secret key so that they can continue communicating in a secure manner.To verify that mutual authentication has occurred successfully, Burrows-Abadi-Needham logic (BAN logic) is a well regarded and widely accepted method to use, because it verifies that a message came from a trustworthy entity. BAN logic first assumes an entity is not to be trusted, and then will verify its legality.\n\n== Defenses ==\nMutual authentication supports zero trust networking because it can protect communications against adversarial attacks, notably:\n\nMan-in-the-middle attack\nMan-in-the-middle (MITM) attacks are when a third party wishes to eavesdrop or intercept a message, and sometimes alter the intended message for the recipient. The two parties openly receive messages without verifying the sender, so they do not realize an adversary has inserted themselves into the communication line. Mutual authentication can prevent MITM attacks because both the sender and recipient verify each other before sending them their message keys, so if one of the parties is not verified to be who they claim they are, the session will end.\nReplay attack\nA replay attack is similar to a MITM attack in which older messages are replayed out of context to fool the server. However, this does not work against schemes using mutual authentication because timestamps are a verification factor that are used in the protocols. If the change in time is greater than the maximum allowed time delay, the session will be aborted. Similarly, messages can include a randomly generated number to keep track of when a message was sent.\nSpoofing attack\nSpoofing attacks rely on using false data to pose as another user in order to gain access to a server or be identified as someone else. Mutual authentication can prevent spoofing attacks because the server will authenticate the user as well, and verify that they have the correct session key before allowing any further communication and access.\nImpersonation attacks\nWhen each party authenticates the other, they send each other a certificate that only the other party knows how to unscramble, verifying themselves as a trusted source. In this way, adversaries cannot use impersonation attacks because they do not have the correct certificate to act as if they are the other party.Mutual authentication also ensures information integrity because if the parties are verified to be the correct source, then the information received is reliable as well.\n\n== mTLS ==\nBy default the TLS protocol only proves the identity of the server to the client using X.509 certificates, and the authentication of the client to the server is left to the application layer. TLS also offers client-to-server authentication using client-side X.509 authentication. As it requires provisioning of the certificates to the clients and involves less user-friendly experience, it's rarely used in end-user applications.\nMutual TLS authentication (mTLS) is more often used in business-to-business (B2B) applications, where a limited number of programmatic and homogeneous clients are connecting to specific web services, the operational burden is limited, and security requirements are usually much higher as compared to consumer environments.\nmTLS is also used in microservices-based applications based on runtimes such as Dapr, via systems like SPIFFE.\n\n== Lightweight schemes vs. secured schemes ==\nWhile lightweight schemes and secure schemes are not mutually exclusive, adding a mutual authentication step to data transmissions protocols can often increase performance runtime and computational costs. This can become an issue for network systems that cannot handle large amounts of data or those that constantly have to update for new real-time data (e.g. location tracking, real-time health data).Thus, it becomes a desired characteristic of many mutual authentication schemes to have lightweight properties (e.g. have a low memory footprint) in order to accommodate the system that is storing a lot of data. Many systems implement cloud computing, which allows quick access to large amounts of data, but sometimes large amounts of data can slow down communication. Even with edge-based cloud computing, which is faster than general cloud computing due to a closer proximity between the server and user, lightweight schemes allow for more speed when managing larger amounts of data. One solution to keep schemes lightweight during the mutual authentication process is to limit the number of bits used during communication.Applications that solely rely on device-to-device (D2D) communication, where multiple devices can communicate locally in close proximities, removes the third party network. This in turn can speed up communication time. However, the authentication still occurs through insecure channels, so researchers believe it is still important to ensure mutual authentication occurs in order to keep a secure scheme.Schemes may sacrifice a better runtime or storage cost when ensuring mutual authentication in order to prioritize protecting the sensitive data.\n\n== Password-based schemes ==\nIn mutual authentication schemes that require a user's input password as part of the verification process, there is a higher vulnerability to hackers because the password is human-made rather than a computer-generated certificate. While applications could simply require users to use a computer-generated password, it is inconvenient for people to remember. User-made passwords and the ability to change one's password are important for making an application user-friendly, so many schemes work to accommodate the characteristic. Researchers note that a password based protocol with mutual authentication is important because user identities and passwords are still protected, as the messages are only readable to the two parties involved.However, a negative aspect about password-based authentication is that password tables can take up a lot of memory space. One way around using a lot of memory during a password-based authentication scheme is to implement one-time passwords (OTP), which is a password sent to the user via SMS or email. OTPs are time-sensitive, which means that they will expire after a certain amount of time and that memory does not need to be stored.\n\n\n*** Multi-factor authentication ***\nRecently, more schemes have higher level authentication than password based schemes. While password-based authentication is considered as \"single-factor authentication,\" schemes are beginning to implement smart card (two-factor) or biometric-based (three-factor) authentication schemes. Smart cards are simpler to implement and easy for authentication, but still have risks of being tampered with. Biometrics have grown more popular over password-based schemes because it is more difficult to copy or guess session keys when using biometrics, but it can be difficult to encrypt noisy data. Due to these security risks and limitations, schemes can still employ mutual authentication regardless of how many authentication factors are added.\n\n== Certificate based schemes and system applications ==\nMutual authentication is often found in schemes employed in the Internet of Things (IoT), where physical objects are incorporated into the Internet and can communicate via IP address. Authentication schemes can be applied to many types of systems that involve data transmission. As the Internet's presence in mechanical systems increases, writing effective security schemes for large numbers of users, objects, and servers can become challenging, especially when needing schemes to be lightweight and have low computational costs. Instead of password-based authentication, devices will use certificates to verify each other's identities.\n\n\n*** Radio networks ***\nMutual authentication can be satisfied in radio network schemes, where data transmissions through radio frequencies are secure after verifying the sender and receiver.Radio frequency identification (RFID) tags are commonly used for object detection, which many manufacturers are implementing into their warehouse systems for automation. This allows for a faster way to keep up with inventory and track objects. However, keeping track of items in a system with RFID tags that transmit data to a cloud server increases the chances of security risks, as there are now more digital elements to keep track of. A three way mutual authentication can occur between RFID tags, the tag readers, and the cloud network that stores this data in order to keep RFID tag data secure and unable to be manipulated.Similarly, an alternate RFID tag and reader system that assigns designated readers to tags has been proposed for extra security and low memory cost. Instead of considering all tag readers as one entity, only certain readers can read specific tags. With this method, if a reader is breached, it will not affect the whole system. Individual readers will communicate with specific tags during mutual authentication, which runs in constant time as readers use the same private key for the authentication process.\nMany e-Healthcare systems that remotely monitor patient health data use wireless body area networks (WBAN) that transmit data through radio frequencies. This is beneficial for patients that should not be disturbed while being monitored, and can reduced the workload for medical worker and allow them to focus on the more hands-on jobs. However, a large concern for healthcare providers and patients about using remote health data tracking is that sensitive patient data is being transmitted through unsecured channels, so authentication occurs between the medical body area network user (the patient), the Healthcare Service Provider (HSP) and the trusted third party.\n\n\n*** Cloud based computing ***\ne-Healthcare clouds are another way to store patient data collected remotely. Clouds are useful for storing large amounts of data, such as medical information, that can be accessed by many devices whenever needed. Telecare Medical Information Systems (TMIS), an important way for medical patients to receive healthcare remotely, can ensure secured data with mutual authentication verification schemes. Blockchain is one way that has been proposed to mutually authenticate the user to the database, by authenticating with the main mediBchain node and keeping patient anonymity.Fog-cloud computing is a networking system that can handle large amounts of data, but still has limitations regarding computational and memory cost. Mobile edge computing (MEC) is considered to be an improved, more lightweight fog-cloud computing networking system, and can be used for medical technology that also revolves around location-based data. Due to the large physical range required of locational tracking, 5G networks can send data to the edge of the cloud to store data. An application like smart watches that track patient health data can be used to call the nearest hospital if the patient shows a negative change in vitals.Fog node networks can be implemented in car automation, keeping data about the car and its surrounding states secure. By authenticating the fog nodes and the vehicle, vehicular handoff becomes a safe process and the car\u2019s system is safe from hackers.\n\n\n*** Machine to machine verification ***\nMany systems that do not require a human user as part of the system also have protocols that mutually authenticate between parties. In unmanned aerial vehicle (UAV) systems, a platform authentication occurs rather than user authentication. Mutual authentication during vehicle communication prevents one vehicle's system from being breached, which can then affect the whole system negatively. For example, a system of drones can be employed for agriculture work and cargo delivery, but if one drone were to be breached, the whole system has the potential to collapse.\n\nBased on the above text, answer a question. What is the role of blockchain in mutual authentication for e-Healthcare clouds?",
    "context": "",
    "output": "Blockchain can be used in mutual authentication for e-Healthcare clouds by authenticating the user to the database, keeping patient anonymity, and ensuring secured data.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of blockchain in mutual authentication for e-Healthcare clouds?",
      "answer": "Blockchain can be used in mutual authentication for e-Healthcare clouds by authenticating the user to the database, keeping patient anonymity, and ensuring secured data.",
      "context": "Mutual authentication\n\n==Introduction==\nMutual authentication or two-way authentication (not to be confused with two-factor authentication) refers to two parties authenticating each other at the same time in an authentication protocol. It is a default mode of authentication in some protocols (IKE, SSH) and optional in others (TLS).\nMutual authentication is a desired characteristic in verification schemes that transmit sensitive data, in order to ensure data security. Mutual authentication can be accomplished with two types of credentials: usernames and passwords, and public key certificates.\nMutual authentication is often employed in the Internet of Things (IoT). Writing effective security schemes in IoT systems can become challenging, especially when schemes are desired to be lightweight and have low computational costs. Mutual authentication is a crucial security step that can defend against many adversarial attacks, which otherwise can have large consequences if IoT systems (such as e-Healthcare servers) are hacked. In scheme analyses done of past works, a lack of mutual authentication had been considered a weakness in data transmission schemes.\n\n\n\n== Process steps and verification ==\nSchemes that have a mutual authentication step may use different methods of encryption, communication, and verification, but they all share one thing in common: each entity involved in the communication is verified. If Alice wants to communicate with Bob, they will both authenticate the other and verify that it is who they are expecting to communicate with before any data or messages are transmitted. A mutual authentication process that exchanges user IDs may be implemented as follows:\nAlice sends an encrypted message to Bob to show that Alice is a valid user.\nBob verifies message:\nBob checks the format and timestamp. If either is incorrect or invalid, the session is aborted.\nThe message is then decrypted with Bob's secret key, giving Alice's ID.\nBob checks if the message matches a valid user. If not, the session is aborted.\nBob sends Alice a message back to show that Bob is a valid user.\nAlice verifies the message:\nAlice checks the format and timestamp. If either is incorrect or invalid, the session is aborted.\nThen, the message is decrypted with Alice's secret key, giving Bob's ID.\nAlice checks if the message matches a valid user. If not, the session is aborted.\nAt this point, both parties are verified to be who they claim to be and safe for the other to communicate with. Lastly, Alice and Bob will create a shared secret key so that they can continue communicating in a secure manner.To verify that mutual authentication has occurred successfully, Burrows-Abadi-Needham logic (BAN logic) is a well regarded and widely accepted method to use, because it verifies that a message came from a trustworthy entity. BAN logic first assumes an entity is not to be trusted, and then will verify its legality.\n\n== Defenses ==\nMutual authentication supports zero trust networking because it can protect communications against adversarial attacks, notably:\n\nMan-in-the-middle attack\nMan-in-the-middle (MITM) attacks are when a third party wishes to eavesdrop or intercept a message, and sometimes alter the intended message for the recipient. The two parties openly receive messages without verifying the sender, so they do not realize an adversary has inserted themselves into the communication line. Mutual authentication can prevent MITM attacks because both the sender and recipient verify each other before sending them their message keys, so if one of the parties is not verified to be who they claim they are, the session will end.\nReplay attack\nA replay attack is similar to a MITM attack in which older messages are replayed out of context to fool the server. However, this does not work against schemes using mutual authentication because timestamps are a verification factor that are used in the protocols. If the change in time is greater than the maximum allowed time delay, the session will be aborted. Similarly, messages can include a randomly generated number to keep track of when a message was sent.\nSpoofing attack\nSpoofing attacks rely on using false data to pose as another user in order to gain access to a server or be identified as someone else. Mutual authentication can prevent spoofing attacks because the server will authenticate the user as well, and verify that they have the correct session key before allowing any further communication and access.\nImpersonation attacks\nWhen each party authenticates the other, they send each other a certificate that only the other party knows how to unscramble, verifying themselves as a trusted source. In this way, adversaries cannot use impersonation attacks because they do not have the correct certificate to act as if they are the other party.Mutual authentication also ensures information integrity because if the parties are verified to be the correct source, then the information received is reliable as well.\n\n== mTLS ==\nBy default the TLS protocol only proves the identity of the server to the client using X.509 certificates, and the authentication of the client to the server is left to the application layer. TLS also offers client-to-server authentication using client-side X.509 authentication. As it requires provisioning of the certificates to the clients and involves less user-friendly experience, it's rarely used in end-user applications.\nMutual TLS authentication (mTLS) is more often used in business-to-business (B2B) applications, where a limited number of programmatic and homogeneous clients are connecting to specific web services, the operational burden is limited, and security requirements are usually much higher as compared to consumer environments.\nmTLS is also used in microservices-based applications based on runtimes such as Dapr, via systems like SPIFFE.\n\n== Lightweight schemes vs. secured schemes ==\nWhile lightweight schemes and secure schemes are not mutually exclusive, adding a mutual authentication step to data transmissions protocols can often increase performance runtime and computational costs. This can become an issue for network systems that cannot handle large amounts of data or those that constantly have to update for new real-time data (e.g. location tracking, real-time health data).Thus, it becomes a desired characteristic of many mutual authentication schemes to have lightweight properties (e.g. have a low memory footprint) in order to accommodate the system that is storing a lot of data. Many systems implement cloud computing, which allows quick access to large amounts of data, but sometimes large amounts of data can slow down communication. Even with edge-based cloud computing, which is faster than general cloud computing due to a closer proximity between the server and user, lightweight schemes allow for more speed when managing larger amounts of data. One solution to keep schemes lightweight during the mutual authentication process is to limit the number of bits used during communication.Applications that solely rely on device-to-device (D2D) communication, where multiple devices can communicate locally in close proximities, removes the third party network. This in turn can speed up communication time. However, the authentication still occurs through insecure channels, so researchers believe it is still important to ensure mutual authentication occurs in order to keep a secure scheme.Schemes may sacrifice a better runtime or storage cost when ensuring mutual authentication in order to prioritize protecting the sensitive data.\n\n== Password-based schemes ==\nIn mutual authentication schemes that require a user's input password as part of the verification process, there is a higher vulnerability to hackers because the password is human-made rather than a computer-generated certificate. While applications could simply require users to use a computer-generated password, it is inconvenient for people to remember. User-made passwords and the ability to change one's password are important for making an application user-friendly, so many schemes work to accommodate the characteristic. Researchers note that a password based protocol with mutual authentication is important because user identities and passwords are still protected, as the messages are only readable to the two parties involved.However, a negative aspect about password-based authentication is that password tables can take up a lot of memory space. One way around using a lot of memory during a password-based authentication scheme is to implement one-time passwords (OTP), which is a password sent to the user via SMS or email. OTPs are time-sensitive, which means that they will expire after a certain amount of time and that memory does not need to be stored.\n\n\n*** Multi-factor authentication ***\nRecently, more schemes have higher level authentication than password based schemes. While password-based authentication is considered as \"single-factor authentication,\" schemes are beginning to implement smart card (two-factor) or biometric-based (three-factor) authentication schemes. Smart cards are simpler to implement and easy for authentication, but still have risks of being tampered with. Biometrics have grown more popular over password-based schemes because it is more difficult to copy or guess session keys when using biometrics, but it can be difficult to encrypt noisy data. Due to these security risks and limitations, schemes can still employ mutual authentication regardless of how many authentication factors are added.\n\n== Certificate based schemes and system applications ==\nMutual authentication is often found in schemes employed in the Internet of Things (IoT), where physical objects are incorporated into the Internet and can communicate via IP address. Authentication schemes can be applied to many types of systems that involve data transmission. As the Internet's presence in mechanical systems increases, writing effective security schemes for large numbers of users, objects, and servers can become challenging, especially when needing schemes to be lightweight and have low computational costs. Instead of password-based authentication, devices will use certificates to verify each other's identities.\n\n\n*** Radio networks ***\nMutual authentication can be satisfied in radio network schemes, where data transmissions through radio frequencies are secure after verifying the sender and receiver.Radio frequency identification (RFID) tags are commonly used for object detection, which many manufacturers are implementing into their warehouse systems for automation. This allows for a faster way to keep up with inventory and track objects. However, keeping track of items in a system with RFID tags that transmit data to a cloud server increases the chances of security risks, as there are now more digital elements to keep track of. A three way mutual authentication can occur between RFID tags, the tag readers, and the cloud network that stores this data in order to keep RFID tag data secure and unable to be manipulated.Similarly, an alternate RFID tag and reader system that assigns designated readers to tags has been proposed for extra security and low memory cost. Instead of considering all tag readers as one entity, only certain readers can read specific tags. With this method, if a reader is breached, it will not affect the whole system. Individual readers will communicate with specific tags during mutual authentication, which runs in constant time as readers use the same private key for the authentication process.\nMany e-Healthcare systems that remotely monitor patient health data use wireless body area networks (WBAN) that transmit data through radio frequencies. This is beneficial for patients that should not be disturbed while being monitored, and can reduced the workload for medical worker and allow them to focus on the more hands-on jobs. However, a large concern for healthcare providers and patients about using remote health data tracking is that sensitive patient data is being transmitted through unsecured channels, so authentication occurs between the medical body area network user (the patient), the Healthcare Service Provider (HSP) and the trusted third party.\n\n\n*** Cloud based computing ***\ne-Healthcare clouds are another way to store patient data collected remotely. Clouds are useful for storing large amounts of data, such as medical information, that can be accessed by many devices whenever needed. Telecare Medical Information Systems (TMIS), an important way for medical patients to receive healthcare remotely, can ensure secured data with mutual authentication verification schemes. Blockchain is one way that has been proposed to mutually authenticate the user to the database, by authenticating with the main mediBchain node and keeping patient anonymity.Fog-cloud computing is a networking system that can handle large amounts of data, but still has limitations regarding computational and memory cost. Mobile edge computing (MEC) is considered to be an improved, more lightweight fog-cloud computing networking system, and can be used for medical technology that also revolves around location-based data. Due to the large physical range required of locational tracking, 5G networks can send data to the edge of the cloud to store data. An application like smart watches that track patient health data can be used to call the nearest hospital if the patient shows a negative change in vitals.Fog node networks can be implemented in car automation, keeping data about the car and its surrounding states secure. By authenticating the fog nodes and the vehicle, vehicular handoff becomes a safe process and the car\u2019s system is safe from hackers.\n\n\n*** Machine to machine verification ***\nMany systems that do not require a human user as part of the system also have protocols that mutually authenticate between parties. In unmanned aerial vehicle (UAV) systems, a platform authentication occurs rather than user authentication. Mutual authentication during vehicle communication prevents one vehicle's system from being breached, which can then affect the whole system negatively. For example, a system of drones can be employed for agriculture work and cargo delivery, but if one drone were to be breached, the whole system has the potential to collapse."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the Microsoft Support Diagnostic Tool (MSDT) and what is its intended use?",
    "context": "",
    "output": "The Microsoft Support Diagnostic Tool (MSDT) is a legacy service in Microsoft Windows used by technical support agents to analyze diagnostic data remotely for troubleshooting purposes. It is activated when a user runs it and enters a unique \"passkey\" and \"incident number\" provided by support. MSDT can also be run offline to generate a .CAB file for later upload from a computer with an internet connection.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the Microsoft Support Diagnostic Tool (MSDT) and what is its intended use?",
      "answer": "The Microsoft Support Diagnostic Tool (MSDT) is a legacy service in Microsoft Windows used by technical support agents to analyze diagnostic data remotely for troubleshooting purposes. It is activated when a user runs it and enters a unique \"passkey\" and \"incident number\" provided by support. MSDT can also be run offline to generate a .CAB file for later upload from a computer with an internet connection."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are the steganography missions on HackThisSite and what is the goal in these missions?",
    "context": "",
    "output": "Steganography missions on HackThisSite involve extracting the hidden message from the media file provided. There are 17 steganography missions available and the goal is to extract the hidden message from the media file.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are the steganography missions on HackThisSite and what is the goal in these missions?",
      "answer": "Steganography missions on HackThisSite involve extracting the hidden message from the media file provided. There are 17 steganography missions available and the goal is to extract the hidden message from the media file."
    }
  },
  {
    "instruction": "Spamming\n\n==Introduction==\nSpamming is the use of messaging systems to send multiple unsolicited messages (spam) to large numbers of recipients for the purpose of commercial advertising, for the purpose of non-commercial proselytizing, for any prohibited purpose (especially the fraudulent purpose of phishing), or simply repeatedly sending the same message to the same user. While the most widely recognized form of spam is email spam, the term is applied to similar abuses in other media: instant messaging spam, Usenet newsgroup spam, Web search engine spam, spam in blogs, wiki spam, online classified ads spam, mobile phone messaging spam, Internet forum spam,  junk fax transmissions, social spam, spam mobile apps, television advertising and file sharing spam. It is named after Spam, a luncheon meat, by way of a Monty Python sketch about a restaurant that has Spam in almost every dish in which Vikings annoyingly sing \"Spam\" repeatedly.Spamming remains economically viable because advertisers have no operating costs beyond the management of their mailing lists, servers, infrastructures, IP ranges, and domain names, and it is difficult to hold senders accountable for their mass mailings. The costs, such as lost productivity and fraud, are borne by the public and by Internet service providers, which have added extra capacity to cope with the volume. Spamming has been the subject of legislation in many jurisdictions.A person who creates spam is called a spammer.\n\n\n\n== Etymology ==\n\nThe term spam is derived from the 1970 \"Spam\" sketch of the BBC sketch comedy television series Monty Python's Flying Circus. The sketch, set in a cafe, has a waitress reading out a menu where every item but one includes the Spam canned luncheon meat. As the waitress recites the Spam-filled menu, a chorus of Viking patrons drown out all conversations with a song, repeating \"Spam, Spam, Spam, Spam\u2026 Lovely Spam! Wonderful Spam!\".In the 1980s the term was adopted to describe certain abusive users who frequented BBSs and MUDs, who would repeat \"Spam\" a huge number of times to scroll other users' text off the screen. In early chat-room services like PeopleLink and the early days of Online America (later known as America Online or AOL), they actually flooded the screen with quotes from the Monty Python sketch. This was used as a tactic by insiders of a group that wanted to drive newcomers out of the room so the usual conversation could continue. It was also used to prevent members of rival groups from chatting\u2014for instance, Star Wars fans often invaded Star Trek chat rooms, filling the space with blocks of text until the Star Trek fans left.It later came to be used on Usenet to mean excessive multiple posting\u2014the repeated posting of the same message. The unwanted message would appear in many, if not all newsgroups, just as Spam appeared in all the menu items in the Monty Python sketch. One of the earliest people to use \"spam\" in this sense was Joel Furr. This use had also become established\u2014to \"spam\" Usenet was to flood newsgroups with junk messages. The word was also attributed to the flood of \"Make Money Fast\" messages that clogged many newsgroups during the 1990s. In 1998, the New Oxford Dictionary of English, which had previously only defined \"spam\" in relation to the trademarked food product, added a second definition to its entry for \"spam\": \"Irrelevant or inappropriate messages sent on the Internet to a large number of newsgroups or users.\"\nThere was also an effort to differentiate between types of newsgroup spam. Messages that were crossposted to too many newsgroups at once, as opposed to those that were posted too frequently, were called \"velveeta\" (after a cheese product), but this term did not persist.\n\n== In different media ==\n\n\n*** Email ***\n\nEmail spam, also known as unsolicited bulk email (UBE), or junk mail, is the practice of sending unwanted email messages, frequently with commercial content, in large quantities. Spam in email started to become a problem when the Internet was opened for commercial use in the mid-1990s. It grew exponentially over the following years, and by 2007 it constituted about 80% to 85% of all e-mail, by a conservative estimate. Pressure to make email spam illegal has resulted in legislation in some jurisdictions, but less so in others. The efforts taken by governing bodies, security systems and email service providers seem to be helping to reduce the volume of email spam. According to \"2014 Internet Security Threat Report, Volume 19\" published by Symantec Corporation, spam volume dropped to 66% of all email traffic.An industry of email address harvesting is dedicated to collecting email addresses and selling compiled databases. Some of these address-harvesting approaches rely on users not reading the fine print of agreements, resulting in their agreeing to send messages indiscriminately to their contacts. This is a common approach in social networking spam such as that generated by the social networking site Quechup.\n\n\n*** Instant messaging ***\n\nInstant messaging spam makes use of instant messaging systems. Although less prevalent than its e-mail counterpart, according to a report from Ferris Research, 500 million spam IMs were sent in 2003, twice the level of 2002.\n\n\n*** Newsgroup and forum ***\n\nNewsgroup spam is a type of spam where the targets are Usenet newsgroups. Spamming of Usenet newsgroups actually pre-dates e-mail spam. Usenet convention defines spamming as excessive multiple posting, that is, the repeated posting of a message (or substantially similar messages). The prevalence of Usenet spam led to the development of the Breidbart Index as an objective measure of a message's \"spamminess\".\nForum spam is the creation of advertising messages on Internet forums. It is generally done by automated spambots. Most forum spam consists of links to external sites, with the dual goals of increasing search engine visibility in highly competitive areas such as weight loss, pharmaceuticals, gambling, pornography, real estate or loans, and generating more traffic for these commercial websites. Some of these links contain code to track the spambot's identity; if a sale goes through, the spammer behind the spambot earns a commission.\n\n\n*** Mobile phone ***\n\nMobile phone spam is directed at the text messaging service of a mobile phone. This can be especially irritating to customers not only for the inconvenience, but also because of the fee they may be charged per text message received in some markets.\nTo comply with CAN-SPAM regulations in the US, SMS messages now must provide options of HELP and STOP, the latter to end communication with the advertiser via SMS altogether.\nDespite the high number of phone users, there has not been so much phone spam, because there is a charge for sending SMS. Recently, there are also observations of mobile phone spam delivered via browser push notifications. These can be a result of allowing websites which are malicious or delivering malicious ads to send a user notifications.\n\n\n*** Social networking spam ***\n\nFacebook and Twitter are not immune to messages containing spam links. Spammers hack into accounts and send false links under the guise of a user's trusted contacts such as friends and family. As for Twitter, spammers gain credibility by following verified accounts such as that of Lady Gaga; when that account owner follows the spammer back, it legitimizes the spammer.\nTwitter has studied what interest structures allow their users to receive interesting tweets and avoid spam, despite the site using the broadcast model, in which all tweets from a user are broadcast to all followers of the user. Spammers, out of malicious intent, post either unwanted (or irrelevant) information or spread misinformation on social media platforms.\n\n\n*** Social spam ***\nSpreading beyond the centrally managed social networking platforms, user-generated content increasingly appears on business, government, and nonprofit websites worldwide. Fake accounts and comments planted by computers programmed to issue social spam can infiltrate these websites.\n\n\n*** Blog, wiki, and guestbook ***\n\nBlog spam is spamming on weblogs. In 2003, this type of spam took advantage of the open nature of comments in the blogging software Movable Type by repeatedly placing comments to various blog posts that provided nothing more than a link to the spammer's commercial web site.\nSimilar attacks are often performed against wikis and guestbooks, both of which accept user contributions.\nAnother possible form of spam in blogs is the spamming of a certain tag on websites such as Tumblr.\n\n\n*** Spam targeting video sharing sites ***\n\nIn actual video spam, the uploaded video is given a name and description with a popular figure or event that is likely to draw attention, or within the video a certain image is timed to come up as the video's thumbnail image to mislead the viewer, such as a still image from a feature film, purporting to be a part-by-part piece of a movie being pirated, e.g. Big Buck Bunny Full Movie Online - Part 1/10 HD, a link to a supposed keygen, trainer, ISO file for a video game, or something similar. The actual content of the video ends up being totally unrelated, a Rickroll, offensive, or simply on-screen text of a link to the site being promoted. In some cases, the link in question may lead to an online survey site, a password-protected archive file with instructions leading to the aforementioned survey (though the survey, and the archive file itself, is worthless and doesn't contain the file in question at all), or in extreme cases, malware. Others may upload videos presented in an infomercial-like format selling their product which feature actors and paid testimonials, though the promoted product or service is of dubious quality and would likely not pass the scrutiny of a standards and practices department at a television station or cable network.\n\n\n*** VoIP Spam ***\n\nVoIP spam is VoIP (Voice over Internet Protocol) spam, usually using SIP (Session Initiation Protocol). This is nearly identical to telemarketing calls over traditional phone lines. When the user chooses to receive the spam call, a pre-recorded spam message or advertisement is usually played back. This is generally easier for the spammer as VoIP services are cheap and easy to anonymize over the Internet, and there are many options for sending mass number of calls from a single location. Accounts or IP addresses being used for VoIP spam can usually be identified by a large number of outgoing calls, low call completion and short call length.\n\n\n*** Academic search ***\nAcademic search engines enable researchers to find academic literature and are used to obtain citation data for calculating author-level metrics. Researchers from the University of California, Berkeley and OvGU demonstrated that most (web-based) academic search engines, especially Google Scholar are not capable of identifying spam attacks. The researchers manipulated the citation counts of articles, and managed to make Google Scholar index complete fake articles, some containing advertising.\n\n\n*** Mobile apps ***\nSpamming in mobile app stores include (i) apps that were automatically generated and as a result do not have any specific functionality or a meaningful description; (ii) multiple instances of the same app being published to obtain increased visibility in the app market; and (iii) apps that make excessive use of unrelated keywords to attract users through unintended searches.\n\n== Noncommercial forms ==\nE-mail and other forms of spamming have been used for purposes other than advertisements. Many early Usenet spams were religious or political. Serdar Argic, for instance, spammed Usenet with historical revisionist screeds. A number of evangelists have spammed Usenet and e-mail media with preaching messages. A growing number of criminals are also using spam to perpetrate various sorts of fraud.\n\n== Geographical origins ==\nIn 2011 the origins of spam were analyzed by Cisco Systems. They provided a report that shows spam volume originating from countries worldwide.\n\n== Trademark issues ==\nHormel Foods Corporation, the maker of SPAM luncheon meat, does not object to the Internet use of the term \"spamming\". However, they did ask that the capitalized word \"Spam\" be reserved to refer to their product and trademark.\n\n== Cost\u2013benefit analyses ==\nThe European Union's Internal Market Commission estimated in 2001 that \"junk email\" cost Internet users \u20ac10 billion per year worldwide. The California legislature found that spam cost United States organizations alone more than $13 billion in 2007, including lost productivity and the additional equipment, software, and manpower needed to combat the problem. Spam's direct effects include the consumption of computer and network resources, and the cost in human time and attention of dismissing unwanted messages. Large companies who are frequent spam targets utilize numerous techniques to detect and prevent spam.The cost to providers of search engines is significant: \"The secondary consequence of spamming is that search engine indexes are inundated with useless pages, increasing the cost of each processed query\". The costs of spam also include the collateral costs of the struggle between spammers and the administrators and users of the media threatened by spamming.Email spam exemplifies a tragedy of the commons: spammers use resources (both physical and human), without bearing the entire cost of those resources. In fact, spammers commonly do not bear the cost at all. This raises the costs for everyone. In some ways spam is even a potential threat to the entire email system, as operated in the past. Since email is so cheap to send, a tiny number of spammers can saturate the Internet with junk mail. Although only a tiny percentage of their targets are motivated to purchase their products (or fall victim to their scams), the low cost may provide a sufficient conversion rate to keep the spamming alive. Furthermore, even though spam appears not to be economically viable as a way for a reputable company to do business, it suffices for professional spammers to convince a tiny proportion of gullible advertisers that it is viable for those spammers to stay in business. Finally, new spammers go into business every day, and the low costs allow a single spammer to do a lot of harm before finally realizing that the business is not profitable.Some companies and groups \"rank\" spammers; spammers who make the news are sometimes referred to by these rankings.\n\n\n*** General costs ***\nIn all cases listed above, including both commercial and non-commercial, \"spam happens\" because of a positive cost-benefit analysis result; if the cost to recipients is excluded as an externality the spammer can avoid paying.Cost is the combination of\n\nOverhead: The costs and overhead of electronic spamming include bandwidth, developing or acquiring an email/wiki/blog spam tool, taking over or acquiring a host/zombie, etc.\nTransaction cost: The incremental cost of contacting each additional recipient once a method of spamming is constructed, multiplied by the number of recipients (see CAPTCHA as a method of increasing transaction costs).\nRisks: Chance and severity of legal and/or public reactions, including damages and punitive damages.\nDamage: Impact on the community and/or communication channels being spammed (see Newsgroup spam).Benefit is the total expected profit from spam, which may include any combination of the commercial and non-commercial reasons listed above. It is normally linear, based on the incremental benefit of reaching each additional spam recipient, combined with the conversion rate. The conversion rate for botnet-generated spam has recently been measured to be around one in 12,000,000 for pharmaceutical spam and one in 200,000 for infection sites as used by the Storm botnet. The authors of the study calculating those conversion rates noted, \"After 26 days, and almost 350 million e-mail messages, only 28 sales resulted.\"\n\n== In crime ==\nSpam can be used to spread computer viruses, trojan horses or other malicious software. The objective may be identity theft, or worse (e.g., advance fee fraud). Some spam attempts to capitalize on human greed, while some attempts to take advantage of the victims' inexperience with computer technology to trick them (e.g., phishing).\nOne of the world's most prolific spammers, Robert Alan Soloway, was arrested by US authorities on May 31, 2007. Described as one of the top ten spammers in the world, Soloway was charged with 35 criminal counts, including mail fraud, wire fraud, e-mail fraud, aggravated identity theft, and money laundering. Prosecutors allege that Soloway used millions of \"zombie\" computers to distribute spam during 2003. This is the first case in which US prosecutors used identity theft laws to prosecute a spammer for taking over someone else's Internet domain name.In an attempt to assess potential legal and technical strategies for stopping illegal spam, a study cataloged three months of online spam data and researched website naming and hosting infrastructures. The study concluded that: 1) half of all spam programs have their domains and servers distributed over just eight percent or fewer of the total available hosting registrars and autonomous systems, with 80 percent of spam programs overall being distributed over just 20 percent of all registrars and autonomous systems; 2) of the 76 purchases for which the researchers received transaction information, there were only 13 distinct banks acting as credit card acquirers and only three banks provided the payment servicing for 95 percent of the spam-advertised goods in the study; and, 3) a \"financial blacklist\" of banking entities that do business with spammers would dramatically reduce monetization of unwanted e-mails. Moreover, this blacklist could be updated far more rapidly than spammers could acquire new banking resources, an asymmetry favoring anti-spam efforts.\n\n== Political issues ==\nAn ongoing concern expressed by parties such as the Electronic Frontier Foundation and the American Civil Liberties Union has to do with so-called \"stealth blocking\", a term for ISPs employing aggressive spam blocking without their users' knowledge. These groups' concern is that ISPs or technicians seeking to reduce spam-related costs may select tools that (either through error or design) also block non-spam e-mail from sites seen as \"spam-friendly\". Few object to the existence of these tools; it is their use in filtering the mail of users who are not informed of their use that draws fire.Even though it is possible in some jurisdictions to treat some spam as unlawful merely by applying existing laws against trespass and conversion, some laws specifically targeting spam have been proposed. In 2004, United States passed the CAN-SPAM Act of 2003 that provided ISPs with tools to combat spam. This act allowed Yahoo! to successfully sue Eric Head who settled the lawsuit for several thousand U.S. dollars in June 2004. But the law is criticized by many for not being effective enough. Indeed, the law was supported by some spammers and organizations that support spamming, and opposed by many in the anti-spam community.\n\n== Court cases ==\n\n\n*** United States ***\nEarthlink won a $25 million judgment against one of the most notorious and active \"spammers\" Khan C. Smith in 2001 for his role in founding the modern spam industry which dealt billions in economic damage and established thousands of spammers into the industry. His email efforts were said to make up more than a third of all Internet email being sent from 1999 until 2002.\nSanford Wallace and Cyber Promotions were the target of a string of lawsuits, many of which were settled out of court, up through a 1998 Earthlink settlement that put Cyber Promotions out of business. Attorney Laurence Canter was disbarred by the Tennessee Supreme Court in 1997 for sending prodigious amounts of spam advertising his immigration law practice. In 2005, Jason Smathers, a former America Online employee, pleaded guilty to charges of violating the CAN-SPAM Act. In 2003, he sold a list of approximately 93 million AOL subscriber e-mail addresses to Sean Dunaway who sold the list to spammers.In 2007, Robert Soloway lost a case in a federal court against the operator of a small Oklahoma-based Internet service provider who accused him of spamming. U.S. Judge Ralph G. Thompson granted a motion by plaintiff Robert Braver for a default judgment and permanent injunction against him. The judgment includes a statutory damages award of about $10 million under Oklahoma law.In June 2007, two men were convicted of eight counts stemming from sending millions of e-mail spam messages that included hardcore pornographic images. Jeffrey A. Kilbride, 41, of Venice, California was sentenced to six years in prison, and James R. Schaffer, 41, of Paradise Valley, Arizona, was sentenced to 63 months. In addition, the two were fined $100,000, ordered to pay $77,500 in restitution to AOL, and ordered to forfeit more than $1.1 million, the amount of illegal proceeds from their spamming operation. The charges included conspiracy, fraud, money laundering, and transportation of obscene materials. The trial, which began on June 5, was the first to include charges under the CAN-SPAM Act of 2003, according to a release from the Department of Justice. The specific law that prosecutors used under the CAN-Spam Act was designed to crack down on the transmission of pornography in spam.In 2005, Scott J. Filary and Donald E. Townsend of Tampa, Florida were sued by Florida Attorney General Charlie Crist for violating the Florida Electronic Mail Communications Act. The two spammers were required to pay $50,000 USD to cover the costs of investigation by the state of Florida, and a $1.1 million penalty if spamming were to continue, the $50,000 was not paid, or the financial statements provided were found to be inaccurate. The spamming operation was successfully shut down.Edna Fiedler, 44, of Olympia, Washington, on June 25, 2008, pleaded guilty in a Tacoma court and was sentenced to 2 years imprisonment and 5 years of supervised release or probation in an Internet $1 million \"Nigerian check scam.\" She conspired to commit bank, wire and mail fraud, against US citizens, specifically using Internet by having had an accomplice who shipped counterfeit checks and money orders to her from Lagos, Nigeria, the previous November. Fiedler shipped out $609,000 fake check and money orders when arrested and prepared to send additional $1.1 million counterfeit materials. Also, the U.S. Postal Service recently intercepted counterfeit checks, lottery tickets and eBay overpayment schemes with a value of $2.1 billion.In a 2009 opinion, Gordon v. Virtumundo, Inc., 575 F.3d 1040, the Ninth Circuit assessed the standing requirements necessary for a private plaintiff to bring a civil cause of action against spam senders under the CAN-SPAM Act of 2003, as well as the scope of the CAN-SPAM Act's federal preemption clause.\n\n\n*** United Kingdom ***\nIn the first successful case of its kind, Nigel Roberts from the Channel Islands won \u00a3270 against Media Logistics UK who sent junk e-mails to his personal account.In January 2007, a Sheriff Court in Scotland awarded Mr. Gordon Dick \u00a3750 (the then maximum sum that could be awarded in a Small Claim action) plus expenses of \u00a3618.66, a total of \u00a31368.66 against Transcom Internet Services Ltd. for breaching anti-spam laws. Transcom had been legally represented at earlier hearings, but were not represented at the proof, so Gordon Dick got his decree by default. It is the largest amount awarded in compensation in the United Kingdom since Roberts v Media Logistics case in 2005.\nDespite the statutory tort that is created by the Regulations implementing the EC Directive, few other people have followed their example. As the Courts engage in active case management, such cases would probably now be expected to be settled by mediation and payment of nominal damages.\n\n\n*** New Zealand ***\nIn October 2008, an international internet spam operation run from New Zealand was cited by American authorities as one of the world's largest, and for a time responsible for up to a third of all unwanted e-mails. In a statement the US Federal Trade Commission (FTC) named Christchurch's Lance Atkinson as one of the principals of the operation. New Zealand's Internal Affairs announced it had lodged a $200,000 claim in the High Court against Atkinson and his brother Shane Atkinson and courier Roland Smits, after raids in Christchurch. This marked the first prosecution since the Unsolicited Electronic Messages Act (UEMA) was passed in September 2007.\nThe FTC said it had received more than three million complaints about spam messages connected to this operation, and estimated that it may be responsible for sending billions of illegal spam messages. The US District Court froze the defendants' assets to preserve them for consumer redress pending trial.\nU.S. co-defendant Jody Smith forfeited more than $800,000 and faces up to five years in prison for charges to which he pleaded guilty.\n\n\n*** Bulgaria ***\nWhile most countries either outlaw or at least ignore spam, Bulgaria is the first and until now only one to legalize it. According to the Bulgarian E-Commerce act (\u0427\u043b.5,6) anyone can send spam to mailboxes published as owned by a company or organization as long as there is a \"clear and straight indication that the message is unsolicited commercial e-mail\" (\"\u0434\u0430 \u043e\u0441\u0438\u0433\u0443\u0440\u0438 \u044f\u0441\u043d\u043e\u0442\u043e \u0438 \u043d\u0435\u0434\u0432\u0443\u0441\u043c\u0438\u0441\u043b\u0435\u043d\u043e \u0440\u0430\u0437\u043f\u043e\u0437\u043d\u0430\u0432\u0430\u043d\u0435 \u043d\u0430 \u0442\u044a\u0440\u0433\u043e\u0432\u0441\u043a\u043e\u0442\u043e \u0441\u044a\u043e\u0431\u0449\u0435\u043d\u0438\u0435 \u043a\u0430\u0442\u043e \u043d\u0435\u043f\u043e\u0438\u0441\u043a\u0430\u043d\u043e\") in the message body.\nThis made lawsuits against Bulgarian ISP's and public e-mail providers with antispam policy possible, as they are obstructing legal commerce activity and thus violate Bulgarian antitrust acts. While there are no such lawsuits until now, several cases of spam obstruction are currently awaiting decision in the Bulgarian Antitrust Commission (\u041a\u043e\u043c\u0438\u0441\u0438\u044f \u0437\u0430 \u0437\u0430\u0449\u0438\u0442\u0430 \u043d\u0430 \u043a\u043e\u043d\u043a\u0443\u0440\u0435\u043d\u0446\u0438\u044f\u0442\u0430) and can end with serious fines for the ISPs in question.The law contains other dubious provisions \u2014 for example, the creation of a nationwide public electronic register of e-mail addresses that do not want to receive spam. It is usually abused as the perfect source for e-mail address harvesting, because publishing invalid or incorrect information in such a register is a criminal offense in Bulgaria.\n\n== Newsgroups ==\nnews.admin.net-abuse.email\n\nWhat was the result of the University of California, Berkeley and OvGU study on academic search engines and spam?",
    "context": "",
    "output": "The study found that most academic search engines, especially Google Scholar, are not capable of identifying spam attacks. Researchers were able to manipulate citation counts and make Google Scholar index complete fake articles, some containing advertising.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was the result of the University of California, Berkeley and OvGU study on academic search engines and spam?",
      "answer": "The study found that most academic search engines, especially Google Scholar, are not capable of identifying spam attacks. Researchers were able to manipulate citation counts and make Google Scholar index complete fake articles, some containing advertising.",
      "context": "Spamming\n\n==Introduction==\nSpamming is the use of messaging systems to send multiple unsolicited messages (spam) to large numbers of recipients for the purpose of commercial advertising, for the purpose of non-commercial proselytizing, for any prohibited purpose (especially the fraudulent purpose of phishing), or simply repeatedly sending the same message to the same user. While the most widely recognized form of spam is email spam, the term is applied to similar abuses in other media: instant messaging spam, Usenet newsgroup spam, Web search engine spam, spam in blogs, wiki spam, online classified ads spam, mobile phone messaging spam, Internet forum spam,  junk fax transmissions, social spam, spam mobile apps, television advertising and file sharing spam. It is named after Spam, a luncheon meat, by way of a Monty Python sketch about a restaurant that has Spam in almost every dish in which Vikings annoyingly sing \"Spam\" repeatedly.Spamming remains economically viable because advertisers have no operating costs beyond the management of their mailing lists, servers, infrastructures, IP ranges, and domain names, and it is difficult to hold senders accountable for their mass mailings. The costs, such as lost productivity and fraud, are borne by the public and by Internet service providers, which have added extra capacity to cope with the volume. Spamming has been the subject of legislation in many jurisdictions.A person who creates spam is called a spammer.\n\n\n\n== Etymology ==\n\nThe term spam is derived from the 1970 \"Spam\" sketch of the BBC sketch comedy television series Monty Python's Flying Circus. The sketch, set in a cafe, has a waitress reading out a menu where every item but one includes the Spam canned luncheon meat. As the waitress recites the Spam-filled menu, a chorus of Viking patrons drown out all conversations with a song, repeating \"Spam, Spam, Spam, Spam\u2026 Lovely Spam! Wonderful Spam!\".In the 1980s the term was adopted to describe certain abusive users who frequented BBSs and MUDs, who would repeat \"Spam\" a huge number of times to scroll other users' text off the screen. In early chat-room services like PeopleLink and the early days of Online America (later known as America Online or AOL), they actually flooded the screen with quotes from the Monty Python sketch. This was used as a tactic by insiders of a group that wanted to drive newcomers out of the room so the usual conversation could continue. It was also used to prevent members of rival groups from chatting\u2014for instance, Star Wars fans often invaded Star Trek chat rooms, filling the space with blocks of text until the Star Trek fans left.It later came to be used on Usenet to mean excessive multiple posting\u2014the repeated posting of the same message. The unwanted message would appear in many, if not all newsgroups, just as Spam appeared in all the menu items in the Monty Python sketch. One of the earliest people to use \"spam\" in this sense was Joel Furr. This use had also become established\u2014to \"spam\" Usenet was to flood newsgroups with junk messages. The word was also attributed to the flood of \"Make Money Fast\" messages that clogged many newsgroups during the 1990s. In 1998, the New Oxford Dictionary of English, which had previously only defined \"spam\" in relation to the trademarked food product, added a second definition to its entry for \"spam\": \"Irrelevant or inappropriate messages sent on the Internet to a large number of newsgroups or users.\"\nThere was also an effort to differentiate between types of newsgroup spam. Messages that were crossposted to too many newsgroups at once, as opposed to those that were posted too frequently, were called \"velveeta\" (after a cheese product), but this term did not persist.\n\n== In different media ==\n\n\n*** Email ***\n\nEmail spam, also known as unsolicited bulk email (UBE), or junk mail, is the practice of sending unwanted email messages, frequently with commercial content, in large quantities. Spam in email started to become a problem when the Internet was opened for commercial use in the mid-1990s. It grew exponentially over the following years, and by 2007 it constituted about 80% to 85% of all e-mail, by a conservative estimate. Pressure to make email spam illegal has resulted in legislation in some jurisdictions, but less so in others. The efforts taken by governing bodies, security systems and email service providers seem to be helping to reduce the volume of email spam. According to \"2014 Internet Security Threat Report, Volume 19\" published by Symantec Corporation, spam volume dropped to 66% of all email traffic.An industry of email address harvesting is dedicated to collecting email addresses and selling compiled databases. Some of these address-harvesting approaches rely on users not reading the fine print of agreements, resulting in their agreeing to send messages indiscriminately to their contacts. This is a common approach in social networking spam such as that generated by the social networking site Quechup.\n\n\n*** Instant messaging ***\n\nInstant messaging spam makes use of instant messaging systems. Although less prevalent than its e-mail counterpart, according to a report from Ferris Research, 500 million spam IMs were sent in 2003, twice the level of 2002.\n\n\n*** Newsgroup and forum ***\n\nNewsgroup spam is a type of spam where the targets are Usenet newsgroups. Spamming of Usenet newsgroups actually pre-dates e-mail spam. Usenet convention defines spamming as excessive multiple posting, that is, the repeated posting of a message (or substantially similar messages). The prevalence of Usenet spam led to the development of the Breidbart Index as an objective measure of a message's \"spamminess\".\nForum spam is the creation of advertising messages on Internet forums. It is generally done by automated spambots. Most forum spam consists of links to external sites, with the dual goals of increasing search engine visibility in highly competitive areas such as weight loss, pharmaceuticals, gambling, pornography, real estate or loans, and generating more traffic for these commercial websites. Some of these links contain code to track the spambot's identity; if a sale goes through, the spammer behind the spambot earns a commission.\n\n\n*** Mobile phone ***\n\nMobile phone spam is directed at the text messaging service of a mobile phone. This can be especially irritating to customers not only for the inconvenience, but also because of the fee they may be charged per text message received in some markets.\nTo comply with CAN-SPAM regulations in the US, SMS messages now must provide options of HELP and STOP, the latter to end communication with the advertiser via SMS altogether.\nDespite the high number of phone users, there has not been so much phone spam, because there is a charge for sending SMS. Recently, there are also observations of mobile phone spam delivered via browser push notifications. These can be a result of allowing websites which are malicious or delivering malicious ads to send a user notifications.\n\n\n*** Social networking spam ***\n\nFacebook and Twitter are not immune to messages containing spam links. Spammers hack into accounts and send false links under the guise of a user's trusted contacts such as friends and family. As for Twitter, spammers gain credibility by following verified accounts such as that of Lady Gaga; when that account owner follows the spammer back, it legitimizes the spammer.\nTwitter has studied what interest structures allow their users to receive interesting tweets and avoid spam, despite the site using the broadcast model, in which all tweets from a user are broadcast to all followers of the user. Spammers, out of malicious intent, post either unwanted (or irrelevant) information or spread misinformation on social media platforms.\n\n\n*** Social spam ***\nSpreading beyond the centrally managed social networking platforms, user-generated content increasingly appears on business, government, and nonprofit websites worldwide. Fake accounts and comments planted by computers programmed to issue social spam can infiltrate these websites.\n\n\n*** Blog, wiki, and guestbook ***\n\nBlog spam is spamming on weblogs. In 2003, this type of spam took advantage of the open nature of comments in the blogging software Movable Type by repeatedly placing comments to various blog posts that provided nothing more than a link to the spammer's commercial web site.\nSimilar attacks are often performed against wikis and guestbooks, both of which accept user contributions.\nAnother possible form of spam in blogs is the spamming of a certain tag on websites such as Tumblr.\n\n\n*** Spam targeting video sharing sites ***\n\nIn actual video spam, the uploaded video is given a name and description with a popular figure or event that is likely to draw attention, or within the video a certain image is timed to come up as the video's thumbnail image to mislead the viewer, such as a still image from a feature film, purporting to be a part-by-part piece of a movie being pirated, e.g. Big Buck Bunny Full Movie Online - Part 1/10 HD, a link to a supposed keygen, trainer, ISO file for a video game, or something similar. The actual content of the video ends up being totally unrelated, a Rickroll, offensive, or simply on-screen text of a link to the site being promoted. In some cases, the link in question may lead to an online survey site, a password-protected archive file with instructions leading to the aforementioned survey (though the survey, and the archive file itself, is worthless and doesn't contain the file in question at all), or in extreme cases, malware. Others may upload videos presented in an infomercial-like format selling their product which feature actors and paid testimonials, though the promoted product or service is of dubious quality and would likely not pass the scrutiny of a standards and practices department at a television station or cable network.\n\n\n*** VoIP Spam ***\n\nVoIP spam is VoIP (Voice over Internet Protocol) spam, usually using SIP (Session Initiation Protocol). This is nearly identical to telemarketing calls over traditional phone lines. When the user chooses to receive the spam call, a pre-recorded spam message or advertisement is usually played back. This is generally easier for the spammer as VoIP services are cheap and easy to anonymize over the Internet, and there are many options for sending mass number of calls from a single location. Accounts or IP addresses being used for VoIP spam can usually be identified by a large number of outgoing calls, low call completion and short call length.\n\n\n*** Academic search ***\nAcademic search engines enable researchers to find academic literature and are used to obtain citation data for calculating author-level metrics. Researchers from the University of California, Berkeley and OvGU demonstrated that most (web-based) academic search engines, especially Google Scholar are not capable of identifying spam attacks. The researchers manipulated the citation counts of articles, and managed to make Google Scholar index complete fake articles, some containing advertising.\n\n\n*** Mobile apps ***\nSpamming in mobile app stores include (i) apps that were automatically generated and as a result do not have any specific functionality or a meaningful description; (ii) multiple instances of the same app being published to obtain increased visibility in the app market; and (iii) apps that make excessive use of unrelated keywords to attract users through unintended searches.\n\n== Noncommercial forms ==\nE-mail and other forms of spamming have been used for purposes other than advertisements. Many early Usenet spams were religious or political. Serdar Argic, for instance, spammed Usenet with historical revisionist screeds. A number of evangelists have spammed Usenet and e-mail media with preaching messages. A growing number of criminals are also using spam to perpetrate various sorts of fraud.\n\n== Geographical origins ==\nIn 2011 the origins of spam were analyzed by Cisco Systems. They provided a report that shows spam volume originating from countries worldwide.\n\n== Trademark issues ==\nHormel Foods Corporation, the maker of SPAM luncheon meat, does not object to the Internet use of the term \"spamming\". However, they did ask that the capitalized word \"Spam\" be reserved to refer to their product and trademark.\n\n== Cost\u2013benefit analyses ==\nThe European Union's Internal Market Commission estimated in 2001 that \"junk email\" cost Internet users \u20ac10 billion per year worldwide. The California legislature found that spam cost United States organizations alone more than $13 billion in 2007, including lost productivity and the additional equipment, software, and manpower needed to combat the problem. Spam's direct effects include the consumption of computer and network resources, and the cost in human time and attention of dismissing unwanted messages. Large companies who are frequent spam targets utilize numerous techniques to detect and prevent spam.The cost to providers of search engines is significant: \"The secondary consequence of spamming is that search engine indexes are inundated with useless pages, increasing the cost of each processed query\". The costs of spam also include the collateral costs of the struggle between spammers and the administrators and users of the media threatened by spamming.Email spam exemplifies a tragedy of the commons: spammers use resources (both physical and human), without bearing the entire cost of those resources. In fact, spammers commonly do not bear the cost at all. This raises the costs for everyone. In some ways spam is even a potential threat to the entire email system, as operated in the past. Since email is so cheap to send, a tiny number of spammers can saturate the Internet with junk mail. Although only a tiny percentage of their targets are motivated to purchase their products (or fall victim to their scams), the low cost may provide a sufficient conversion rate to keep the spamming alive. Furthermore, even though spam appears not to be economically viable as a way for a reputable company to do business, it suffices for professional spammers to convince a tiny proportion of gullible advertisers that it is viable for those spammers to stay in business. Finally, new spammers go into business every day, and the low costs allow a single spammer to do a lot of harm before finally realizing that the business is not profitable.Some companies and groups \"rank\" spammers; spammers who make the news are sometimes referred to by these rankings.\n\n\n*** General costs ***\nIn all cases listed above, including both commercial and non-commercial, \"spam happens\" because of a positive cost-benefit analysis result; if the cost to recipients is excluded as an externality the spammer can avoid paying.Cost is the combination of\n\nOverhead: The costs and overhead of electronic spamming include bandwidth, developing or acquiring an email/wiki/blog spam tool, taking over or acquiring a host/zombie, etc.\nTransaction cost: The incremental cost of contacting each additional recipient once a method of spamming is constructed, multiplied by the number of recipients (see CAPTCHA as a method of increasing transaction costs).\nRisks: Chance and severity of legal and/or public reactions, including damages and punitive damages.\nDamage: Impact on the community and/or communication channels being spammed (see Newsgroup spam).Benefit is the total expected profit from spam, which may include any combination of the commercial and non-commercial reasons listed above. It is normally linear, based on the incremental benefit of reaching each additional spam recipient, combined with the conversion rate. The conversion rate for botnet-generated spam has recently been measured to be around one in 12,000,000 for pharmaceutical spam and one in 200,000 for infection sites as used by the Storm botnet. The authors of the study calculating those conversion rates noted, \"After 26 days, and almost 350 million e-mail messages, only 28 sales resulted.\"\n\n== In crime ==\nSpam can be used to spread computer viruses, trojan horses or other malicious software. The objective may be identity theft, or worse (e.g., advance fee fraud). Some spam attempts to capitalize on human greed, while some attempts to take advantage of the victims' inexperience with computer technology to trick them (e.g., phishing).\nOne of the world's most prolific spammers, Robert Alan Soloway, was arrested by US authorities on May 31, 2007. Described as one of the top ten spammers in the world, Soloway was charged with 35 criminal counts, including mail fraud, wire fraud, e-mail fraud, aggravated identity theft, and money laundering. Prosecutors allege that Soloway used millions of \"zombie\" computers to distribute spam during 2003. This is the first case in which US prosecutors used identity theft laws to prosecute a spammer for taking over someone else's Internet domain name.In an attempt to assess potential legal and technical strategies for stopping illegal spam, a study cataloged three months of online spam data and researched website naming and hosting infrastructures. The study concluded that: 1) half of all spam programs have their domains and servers distributed over just eight percent or fewer of the total available hosting registrars and autonomous systems, with 80 percent of spam programs overall being distributed over just 20 percent of all registrars and autonomous systems; 2) of the 76 purchases for which the researchers received transaction information, there were only 13 distinct banks acting as credit card acquirers and only three banks provided the payment servicing for 95 percent of the spam-advertised goods in the study; and, 3) a \"financial blacklist\" of banking entities that do business with spammers would dramatically reduce monetization of unwanted e-mails. Moreover, this blacklist could be updated far more rapidly than spammers could acquire new banking resources, an asymmetry favoring anti-spam efforts.\n\n== Political issues ==\nAn ongoing concern expressed by parties such as the Electronic Frontier Foundation and the American Civil Liberties Union has to do with so-called \"stealth blocking\", a term for ISPs employing aggressive spam blocking without their users' knowledge. These groups' concern is that ISPs or technicians seeking to reduce spam-related costs may select tools that (either through error or design) also block non-spam e-mail from sites seen as \"spam-friendly\". Few object to the existence of these tools; it is their use in filtering the mail of users who are not informed of their use that draws fire.Even though it is possible in some jurisdictions to treat some spam as unlawful merely by applying existing laws against trespass and conversion, some laws specifically targeting spam have been proposed. In 2004, United States passed the CAN-SPAM Act of 2003 that provided ISPs with tools to combat spam. This act allowed Yahoo! to successfully sue Eric Head who settled the lawsuit for several thousand U.S. dollars in June 2004. But the law is criticized by many for not being effective enough. Indeed, the law was supported by some spammers and organizations that support spamming, and opposed by many in the anti-spam community.\n\n== Court cases ==\n\n\n*** United States ***\nEarthlink won a $25 million judgment against one of the most notorious and active \"spammers\" Khan C. Smith in 2001 for his role in founding the modern spam industry which dealt billions in economic damage and established thousands of spammers into the industry. His email efforts were said to make up more than a third of all Internet email being sent from 1999 until 2002.\nSanford Wallace and Cyber Promotions were the target of a string of lawsuits, many of which were settled out of court, up through a 1998 Earthlink settlement that put Cyber Promotions out of business. Attorney Laurence Canter was disbarred by the Tennessee Supreme Court in 1997 for sending prodigious amounts of spam advertising his immigration law practice. In 2005, Jason Smathers, a former America Online employee, pleaded guilty to charges of violating the CAN-SPAM Act. In 2003, he sold a list of approximately 93 million AOL subscriber e-mail addresses to Sean Dunaway who sold the list to spammers.In 2007, Robert Soloway lost a case in a federal court against the operator of a small Oklahoma-based Internet service provider who accused him of spamming. U.S. Judge Ralph G. Thompson granted a motion by plaintiff Robert Braver for a default judgment and permanent injunction against him. The judgment includes a statutory damages award of about $10 million under Oklahoma law.In June 2007, two men were convicted of eight counts stemming from sending millions of e-mail spam messages that included hardcore pornographic images. Jeffrey A. Kilbride, 41, of Venice, California was sentenced to six years in prison, and James R. Schaffer, 41, of Paradise Valley, Arizona, was sentenced to 63 months. In addition, the two were fined $100,000, ordered to pay $77,500 in restitution to AOL, and ordered to forfeit more than $1.1 million, the amount of illegal proceeds from their spamming operation. The charges included conspiracy, fraud, money laundering, and transportation of obscene materials. The trial, which began on June 5, was the first to include charges under the CAN-SPAM Act of 2003, according to a release from the Department of Justice. The specific law that prosecutors used under the CAN-Spam Act was designed to crack down on the transmission of pornography in spam.In 2005, Scott J. Filary and Donald E. Townsend of Tampa, Florida were sued by Florida Attorney General Charlie Crist for violating the Florida Electronic Mail Communications Act. The two spammers were required to pay $50,000 USD to cover the costs of investigation by the state of Florida, and a $1.1 million penalty if spamming were to continue, the $50,000 was not paid, or the financial statements provided were found to be inaccurate. The spamming operation was successfully shut down.Edna Fiedler, 44, of Olympia, Washington, on June 25, 2008, pleaded guilty in a Tacoma court and was sentenced to 2 years imprisonment and 5 years of supervised release or probation in an Internet $1 million \"Nigerian check scam.\" She conspired to commit bank, wire and mail fraud, against US citizens, specifically using Internet by having had an accomplice who shipped counterfeit checks and money orders to her from Lagos, Nigeria, the previous November. Fiedler shipped out $609,000 fake check and money orders when arrested and prepared to send additional $1.1 million counterfeit materials. Also, the U.S. Postal Service recently intercepted counterfeit checks, lottery tickets and eBay overpayment schemes with a value of $2.1 billion.In a 2009 opinion, Gordon v. Virtumundo, Inc., 575 F.3d 1040, the Ninth Circuit assessed the standing requirements necessary for a private plaintiff to bring a civil cause of action against spam senders under the CAN-SPAM Act of 2003, as well as the scope of the CAN-SPAM Act's federal preemption clause.\n\n\n*** United Kingdom ***\nIn the first successful case of its kind, Nigel Roberts from the Channel Islands won \u00a3270 against Media Logistics UK who sent junk e-mails to his personal account.In January 2007, a Sheriff Court in Scotland awarded Mr. Gordon Dick \u00a3750 (the then maximum sum that could be awarded in a Small Claim action) plus expenses of \u00a3618.66, a total of \u00a31368.66 against Transcom Internet Services Ltd. for breaching anti-spam laws. Transcom had been legally represented at earlier hearings, but were not represented at the proof, so Gordon Dick got his decree by default. It is the largest amount awarded in compensation in the United Kingdom since Roberts v Media Logistics case in 2005.\nDespite the statutory tort that is created by the Regulations implementing the EC Directive, few other people have followed their example. As the Courts engage in active case management, such cases would probably now be expected to be settled by mediation and payment of nominal damages.\n\n\n*** New Zealand ***\nIn October 2008, an international internet spam operation run from New Zealand was cited by American authorities as one of the world's largest, and for a time responsible for up to a third of all unwanted e-mails. In a statement the US Federal Trade Commission (FTC) named Christchurch's Lance Atkinson as one of the principals of the operation. New Zealand's Internal Affairs announced it had lodged a $200,000 claim in the High Court against Atkinson and his brother Shane Atkinson and courier Roland Smits, after raids in Christchurch. This marked the first prosecution since the Unsolicited Electronic Messages Act (UEMA) was passed in September 2007.\nThe FTC said it had received more than three million complaints about spam messages connected to this operation, and estimated that it may be responsible for sending billions of illegal spam messages. The US District Court froze the defendants' assets to preserve them for consumer redress pending trial.\nU.S. co-defendant Jody Smith forfeited more than $800,000 and faces up to five years in prison for charges to which he pleaded guilty.\n\n\n*** Bulgaria ***\nWhile most countries either outlaw or at least ignore spam, Bulgaria is the first and until now only one to legalize it. According to the Bulgarian E-Commerce act (\u0427\u043b.5,6) anyone can send spam to mailboxes published as owned by a company or organization as long as there is a \"clear and straight indication that the message is unsolicited commercial e-mail\" (\"\u0434\u0430 \u043e\u0441\u0438\u0433\u0443\u0440\u0438 \u044f\u0441\u043d\u043e\u0442\u043e \u0438 \u043d\u0435\u0434\u0432\u0443\u0441\u043c\u0438\u0441\u043b\u0435\u043d\u043e \u0440\u0430\u0437\u043f\u043e\u0437\u043d\u0430\u0432\u0430\u043d\u0435 \u043d\u0430 \u0442\u044a\u0440\u0433\u043e\u0432\u0441\u043a\u043e\u0442\u043e \u0441\u044a\u043e\u0431\u0449\u0435\u043d\u0438\u0435 \u043a\u0430\u0442\u043e \u043d\u0435\u043f\u043e\u0438\u0441\u043a\u0430\u043d\u043e\") in the message body.\nThis made lawsuits against Bulgarian ISP's and public e-mail providers with antispam policy possible, as they are obstructing legal commerce activity and thus violate Bulgarian antitrust acts. While there are no such lawsuits until now, several cases of spam obstruction are currently awaiting decision in the Bulgarian Antitrust Commission (\u041a\u043e\u043c\u0438\u0441\u0438\u044f \u0437\u0430 \u0437\u0430\u0449\u0438\u0442\u0430 \u043d\u0430 \u043a\u043e\u043d\u043a\u0443\u0440\u0435\u043d\u0446\u0438\u044f\u0442\u0430) and can end with serious fines for the ISPs in question.The law contains other dubious provisions \u2014 for example, the creation of a nationwide public electronic register of e-mail addresses that do not want to receive spam. It is usually abused as the perfect source for e-mail address harvesting, because publishing invalid or incorrect information in such a register is a criminal offense in Bulgaria.\n\n== Newsgroups ==\nnews.admin.net-abuse.email"
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the purpose of the IMSI\\_S1 in CAVE-based authentication?",
    "context": "",
    "output": "The IMSI\\_S1 (International Mobile Subscriber Identity) is used as an input for the CAVE algorithm in the Unique challenge procedure in CAVE-based authentication.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the purpose of the IMSI\\_S1 in CAVE-based authentication?",
      "answer": "The IMSI\\_S1 (International Mobile Subscriber Identity) is used as an input for the CAVE algorithm in the Unique challenge procedure in CAVE-based authentication."
    }
  },
  {
    "instruction": "Write an answer to the following question: How have dirtboxes been used in the Mexican Drug War and in coordination with Mexico's Naval Infantry Force and flights in Guatemala?",
    "context": "",
    "output": "Dirtboxes have been used by the U.S. Marshals Service in the Mexican Drug War, tracking fugitives in coordination with Mexico's Naval Infantry Force and flights in Guatemala.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How have dirtboxes been used in the Mexican Drug War and in coordination with Mexico's Naval Infantry Force and flights in Guatemala?",
      "answer": "Dirtboxes have been used by the U.S. Marshals Service in the Mexican Drug War, tracking fugitives in coordination with Mexico's Naval Infantry Force and flights in Guatemala."
    }
  },
  {
    "instruction": "KLJN Secure Key Exchange\n\n==Introduction==\nRandom-resistor-random-temperature Kirchhoff-law-Johnson-noise key exchange, also known as RRRT-KLJN or simply KLJN, is an approach for distributing cryptographic keys between two parties that claims to offer unconditional security. This claim, which has been contested, is significant, as the only other key exchange approach claiming to offer unconditional security is Quantum key distribution.\nThe KLJN secure key exchange scheme was proposed in 2005 by Laszlo Kish and Granqvist. It has the advantage over quantum key distribution in that it can be performed over a metallic wire with just four resistors, two noise generators, and four voltage measuring devices---equipment that is low-priced and can be readily manufactured. It has the disadvantage that several attacks against KLJN have been identified which must be defended against.\n\"Given that the amount of effort and funding that goes into Quantum Cryptography is substantial (some even mock it as a distraction from the ultimate prize which is quantum computing), it seems to me that the fact that classic thermodynamic resources allow for similar inherent security should give one pause,\" wrote Henning Dekant, the founder of the Quantum Computing Meetup, in April 2013. The Cybersecurity Curricula 2017, a joint project of the Association for Computing Machinery, the IEEE Computer Society, the Association for Information Systems, and the International Federation for Information Processing Technical Committee on Information Security Education (IFIP WG 11.8) recommends teaching the KLJN Scheme as part of teaching \"Advanced concepts\" in its knowledge unit on cryptography.\n\n\n\n== See Also/Further Reading ==\n\nQ: How does the KLJN key exchange scheme address the challenge of thermodynamic noise in the communication channel?",
    "context": "",
    "output": "A: The KLJN key exchange scheme addresses the challenge of thermodynamic noise in the communication channel by using the principles of random resistors, random temperatures, and Kirchhoff's and Johnson's noise laws. This allows the scheme to generate a secure key even in the presence of thermodynamic noise.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the KLJN key exchange scheme address the challenge of thermodynamic noise in the communication channel?",
      "answer": "The KLJN key exchange scheme addresses the challenge of thermodynamic noise in the communication channel by using the principles of random resistors, random temperatures, and Kirchhoff's and Johnson's noise laws. This allows the scheme to generate a secure key even in the presence of thermodynamic noise.",
      "context": "KLJN Secure Key Exchange\n\n==Introduction==\nRandom-resistor-random-temperature Kirchhoff-law-Johnson-noise key exchange, also known as RRRT-KLJN or simply KLJN, is an approach for distributing cryptographic keys between two parties that claims to offer unconditional security. This claim, which has been contested, is significant, as the only other key exchange approach claiming to offer unconditional security is Quantum key distribution.\nThe KLJN secure key exchange scheme was proposed in 2005 by Laszlo Kish and Granqvist. It has the advantage over quantum key distribution in that it can be performed over a metallic wire with just four resistors, two noise generators, and four voltage measuring devices---equipment that is low-priced and can be readily manufactured. It has the disadvantage that several attacks against KLJN have been identified which must be defended against.\n\"Given that the amount of effort and funding that goes into Quantum Cryptography is substantial (some even mock it as a distraction from the ultimate prize which is quantum computing), it seems to me that the fact that classic thermodynamic resources allow for similar inherent security should give one pause,\" wrote Henning Dekant, the founder of the Quantum Computing Meetup, in April 2013. The Cybersecurity Curricula 2017, a joint project of the Association for Computing Machinery, the IEEE Computer Society, the Association for Information Systems, and the International Federation for Information Processing Technical Committee on Information Security Education (IFIP WG 11.8) recommends teaching the KLJN Scheme as part of teaching \"Advanced concepts\" in its knowledge unit on cryptography.\n\n\n\n== See Also/Further Reading =="
    }
  },
  {
    "instruction": "Write an answer to the following question: What was the impact of the Cloudbleed vulnerability on Cloudflare customers?",
    "context": "",
    "output": "The Cloudbleed vulnerability impacted Cloudflare customers by leaking their data to all other Cloudflare customers that had access to server memory. This occurred more than 18,000,000 times before the problem was corrected. Some of the leaked data was cached by search engines.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was the impact of the Cloudbleed vulnerability on Cloudflare customers?",
      "answer": "The Cloudbleed vulnerability impacted Cloudflare customers by leaking their data to all other Cloudflare customers that had access to server memory. This occurred more than 18,000,000 times before the problem was corrected. Some of the leaked data was cached by search engines."
    }
  },
  {
    "instruction": "Central Monitoring System\n\n==Introduction==\nThe Central Monitoring System, abbreviated to CMS, is a centralized telephone interception provisioning system installed by the Centre for Development of Telematics (C-DOT), an Indian Government owned telecommunications technology development centre, and operated by Telecom Enforcement Resource and Monitoring (TERM) Cells. The CMC system is going to be set up in each major state collocated with the TERM Cells.  Telecom operators in India are required by law to give access to their networks to law enforcement agencies.\n\nThe Indian Government set up the Centralized Monitoring System (CMS) to automate the process of government-approved Lawful Interception & Monitoring of telecommunications. The Cabinet Committee on Security  approved the project of CMS with government funding of INR 400 Crores. Pilot trials have been completed and the system is anticipated to be progressively implemented from the end of the financial year.\n\n== Interception Authorization ==\nIn exercise of the powers conferred by Section 7 of the Indian Telegraph Act, 1885 (13 of 1885), the Government of India made Rule 419A of the Indian Telegraph Rules, 1951. Directions for interception of any message or class of messages under sub-section (2) of Section 5 of the Indian Telegraph Act, 1885 shall not be issued except by an order made by the Secretary to the Government of India in the Ministry of Home Affairs in the case of Government of India and by the Secretary to the State Government in-charge of the Home Department in the case of a State Government. In unavoidable circumstances, such order may be made by an officer, not below the rank of a Joint Secretary to the Government of India, who has been duly authorized by the Union Home Secretary or the State Home Secretary, as the case may be:\nProvided that in emergent cases:\n(i) in remote areas, where obtaining of prior directions for interception of messages or class of messages is not feasible; or\n(ii) for operational reasons, where obtaining of prior directions for interception of message or class of messages is not feasible;\nthe required interception of any message or class of messages shall be carried out with the prior approval of the Head or the second senior most officer of the authorized security i.e. Law Enforcement Agency at the Central Level and the officers authorised in this behalf, not below the rank of Inspector General of Police at the state level but the concerned competent authority shall be informed of such interceptions by the approving authority within three working days and that such interceptions shall be got confirmed by the concerned competent authority within a period of seven working days. If the confirmation from the competent authority is not received within the stipulated seven days, such interception shall cease and the same message or class of messages shall not be intercepted thereafter without the prior approval of the Union Home Secretary or the State Home Secretary, as the case may be.\nThe Hon\u2019ble Supreme Court has upheld the constitutional validity of interceptions and monitoring under Section 5(2) of the Act through its order dated 18.12.1996 in Writ Petition (C) No.256/1991 by People's Union for Civil Liberties (PUCL) Vs. Union of India. It has also observed that the right to hold a telephone conversation in the privacy of one's home or office without interference can certainly be claimed as \"Right to Privacy\", and accordingly, held that telephone tapping would infringe the Right to Life and Right to Freedom of Speech & Expression enshrined in Articles 21 and 19(1)(a) respectively of the Constitution of India, unless it is permitted under the procedure established by law. The Hon\u2019ble Court further observed that Section 5(2) of the Act clearly provides that \u2018occurrence of any public emergency\u2019 or \u2018interest of public safety\u2019 is a sine qua non for the application of these provisions. Neither of these are secretive conditions or situations. Either of the situations would be apparent to a reasonable person.Interception of communication by authorized Law Enforcement Agencies (LEAs) is carried out in accordance with Section 5(2) of the Indian Telegraph Act, 1885 read with Rule 419A of Indian Telegraph (Amendment) Rules, 2007. Following is the list of authorised Law Enforcement Agencies for Lawful Interception:Central Agencies \n\nResearch & Analysis Wing (R&AW)\nIntelligence Bureau\nNational Investigation Agency\nCentral Bureau of Investigation\nNarcotics Control Bureau\nDirectorate of Enforcement\nCentral Board of Direct Taxes\nDirectorate of Revenue Intelligence\nDirectorate of Signal Intelligence, Ministry of Defence - for Jammu & Kashmir, North East & Assam Service Areas onlyState AgenciesDirector General of Police, of concerned state/Commissioner of Police, Delhi for Delhi Metro City Service Area only.\nCall data records (CDRs) can be sought by following the statutory provisions contained in Section 92 of the Code of Criminal Procedure, 1973 or Section 5(2) of the Indian Telegraph Act, 1885 read with Rule 419 A of Indian Telegraph (Amendment) Rules, 2007.\n\n== System details ==\nEarlier the provisioning of Interception of the Telephone was being done by the Telecom operators on the basis of duly authorized order by the competent authority in accordance with 419A telephone rule. Traditionally, the Law Enforcement Agency was approaching the various telecom companies based on the numbering scheme of the target telephone number. In CMS setup there is no change in the Interception authorization order envisaged in 419A telephone rule except that now the Law Enforcement Agency will go to only TERM Cell for any interception order provisioning irrespective of telephone numbering scheme. There is no change in the existing LIS / LIM system in the telecom network. The TERM Cell who are the field unit of DOT and carries the enforcement and regulation of licensing conditions in the field will be sole authority to provision the interception orders but interception orders will be obtained by Law Enforcement Agencies in according to the 419A telephone rule.\n\n== Government objective ==\nGovernment has set up the Centralized Monitoring System (CMS) to automate the process of Lawful Interception & Monitoring of telecommunications technology. Government of India on 2015-12-02 in a reply to parliament question no. 595 on scope, objectives and framework of the CMS has struck a balance between national security, online privacy and free speech informed that to take care of the privacy of citizens, lawful interception and monitoring is governed by the Section 5(2) of Indian Telegraph Act, 1885 read with Rule 419A of Indian Telegraph (Amendment) Rules, 2007 wherein oversight mechanism exists in form of review committee under chairmanship of the Cabinet Secretary at Central Government level and Chief Secretary of the State at the State Government level. The same mechanism is applicable for the interception under the CMS Project also. Additionally, there is an inbuilt mechanism of check and balance as Security Agencies/Law Enforcement Agencies cannot provision the target and the provisioning agency cannot see the content.\n\n== Media reaction ==\nBusiness Standard criticised the fact that a warrant need not be obtained. Firstpost criticised the lack of information from the government about the project and the lack of a legal recourse for a citizen whose personal details were misused or leaked. The Hindu also criticised the lack of information available about the system.The Indian Express criticised the introduction of the system in the absence of accountability and \"any reasonably effective safeguards\" to protect privacy. The Times of India criticised the introduction of CMS without public debate or Parliamentary accountability. The paper also felt that Indian privacy laws were \"lax\", and \"far worse than American law on these matters\".Forbes India pointed out that a consequence of CMS would be that innocent citizens could be wrongly accused of criminal activity. The New York Times argued that India did not need centralised interception facilities to have centralised tracking of interception requests. The paper also expressed supported for a strong privacy law, and advised Indian citizens to \"take greater care of their own privacy and safeguard the security of their communications\".\n\n== Human rights and civil-liberties groups reactions ==\nHuman rights and civil-liberties groups have expressed concerns that the CMS is prone to abuse, and is an infringement of privacy and civil liberties. Critics have described it as \"abuse of privacy rights and security-agency overreach\".Meenakshi Ganguly, the South Asia director of Human Rights Watch, felt that the move toward extensive \"surveillance capabilities enabled by digital communications\" suggests that governments are now \"casting the net wide, enabling intrusions into private lives\". Ganguly also felt that increasing surveillance around the world was an attempt by governments to \"grapple with the power of social media that can enable spontaneous street protests\".Praveen Swami, strategic affairs editor of Network18, felt that \"There is also the argument that the threat of a cyber attack is deliberately overplayed ... it is far-fetched. So there is a need for balance\". Pawan Sinha, a human rights teacher at Delhi University, believes that bypassing courts was \"really very dangerous\" and could be \"easily misused\".Anja Kovacs of the Internet Democracy Project, and a fellow at the New Delhi-based Centre for Internet and Society, felt that there was \"a growing discrepancy and power imbalance between citizens and the state\" and that in the Indian scenario, there were \"no checks and balances in place\".Sunil Abraham, executive director of Bangalore-based non-profit Centre for Internet and Society, advised Indians to \"stop using proprietary software, shift to free/open source software\" and \"encrypt all sensitive Internet traffic and email using software like TOR and GNU Privacy Guard\".Pranesh Prakash, director of policy at the Centre for Internet and Society, warned that the lack of privacy laws and government accountability makes the programme \"very worrisome.\" Cyberlaw specialist Pavan Duggal stated that the \"system is capable of tremendous abuse\" and \"even legitimate conversations could end up being tracked\". Mishi Choudhary, executive director, Software Freedom and Law Center stated that, \"There has been no public consultation on this issue. No one knows what they have proposed or whether it has parliamentary mandate. We don't even have empirical data on phone tapping from the government. It's like a black hole.\"Human rights activist Neingulo Krome described CMS as \"a threat to democracy\" and also felt that the agencies involved could \"soon challenge the authority of the government itself\".\nQuestion: How does the Central Monitoring System (CMS) in India impact the relationship between the government and telecom operators?",
    "context": "",
    "output": "Answer: The Central Monitoring System (CMS) in India has changed the way interception of telecommunications is provisioned. Earlier, the provisioning of Interception of the Telephone was being done by the Telecom operators on the basis of duly authorized order by the competent authority in accordance with 419A telephone rule. However, in CMS setup, the Law Enforcement Agency will approach the TERM Cell for any interception order provisioning, regardless of the telephone numbering scheme. There is no change in the existing LIS / LIM system in the telecom network, but the TERM Cell is now the sole authority to provision the interception orders.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the Central Monitoring System (CMS) in India impact the relationship between the government and telecom operators?",
      "answer": "The Central Monitoring System (CMS) in India has changed the way interception of telecommunications is provisioned. Earlier, the provisioning of Interception of the Telephone was being done by the Telecom operators on the basis of duly authorized order by the competent authority in accordance with 419A telephone rule. However, in CMS setup, the Law Enforcement Agency will approach the TERM Cell for any interception order provisioning, regardless of the telephone numbering scheme. There is no change in the existing LIS / LIM system in the telecom network, but the TERM Cell is now the sole authority to provision the interception orders.",
      "context": "Central Monitoring System\n\n==Introduction==\nThe Central Monitoring System, abbreviated to CMS, is a centralized telephone interception provisioning system installed by the Centre for Development of Telematics (C-DOT), an Indian Government owned telecommunications technology development centre, and operated by Telecom Enforcement Resource and Monitoring (TERM) Cells. The CMC system is going to be set up in each major state collocated with the TERM Cells.  Telecom operators in India are required by law to give access to their networks to law enforcement agencies.\n\nThe Indian Government set up the Centralized Monitoring System (CMS) to automate the process of government-approved Lawful Interception & Monitoring of telecommunications. The Cabinet Committee on Security  approved the project of CMS with government funding of INR 400 Crores. Pilot trials have been completed and the system is anticipated to be progressively implemented from the end of the financial year.\n\n== Interception Authorization ==\nIn exercise of the powers conferred by Section 7 of the Indian Telegraph Act, 1885 (13 of 1885), the Government of India made Rule 419A of the Indian Telegraph Rules, 1951. Directions for interception of any message or class of messages under sub-section (2) of Section 5 of the Indian Telegraph Act, 1885 shall not be issued except by an order made by the Secretary to the Government of India in the Ministry of Home Affairs in the case of Government of India and by the Secretary to the State Government in-charge of the Home Department in the case of a State Government. In unavoidable circumstances, such order may be made by an officer, not below the rank of a Joint Secretary to the Government of India, who has been duly authorized by the Union Home Secretary or the State Home Secretary, as the case may be:\nProvided that in emergent cases:\n(i) in remote areas, where obtaining of prior directions for interception of messages or class of messages is not feasible; or\n(ii) for operational reasons, where obtaining of prior directions for interception of message or class of messages is not feasible;\nthe required interception of any message or class of messages shall be carried out with the prior approval of the Head or the second senior most officer of the authorized security i.e. Law Enforcement Agency at the Central Level and the officers authorised in this behalf, not below the rank of Inspector General of Police at the state level but the concerned competent authority shall be informed of such interceptions by the approving authority within three working days and that such interceptions shall be got confirmed by the concerned competent authority within a period of seven working days. If the confirmation from the competent authority is not received within the stipulated seven days, such interception shall cease and the same message or class of messages shall not be intercepted thereafter without the prior approval of the Union Home Secretary or the State Home Secretary, as the case may be.\nThe Hon\u2019ble Supreme Court has upheld the constitutional validity of interceptions and monitoring under Section 5(2) of the Act through its order dated 18.12.1996 in Writ Petition (C) No.256/1991 by People's Union for Civil Liberties (PUCL) Vs. Union of India. It has also observed that the right to hold a telephone conversation in the privacy of one's home or office without interference can certainly be claimed as \"Right to Privacy\", and accordingly, held that telephone tapping would infringe the Right to Life and Right to Freedom of Speech & Expression enshrined in Articles 21 and 19(1)(a) respectively of the Constitution of India, unless it is permitted under the procedure established by law. The Hon\u2019ble Court further observed that Section 5(2) of the Act clearly provides that \u2018occurrence of any public emergency\u2019 or \u2018interest of public safety\u2019 is a sine qua non for the application of these provisions. Neither of these are secretive conditions or situations. Either of the situations would be apparent to a reasonable person.Interception of communication by authorized Law Enforcement Agencies (LEAs) is carried out in accordance with Section 5(2) of the Indian Telegraph Act, 1885 read with Rule 419A of Indian Telegraph (Amendment) Rules, 2007. Following is the list of authorised Law Enforcement Agencies for Lawful Interception:Central Agencies \n\nResearch & Analysis Wing (R&AW)\nIntelligence Bureau\nNational Investigation Agency\nCentral Bureau of Investigation\nNarcotics Control Bureau\nDirectorate of Enforcement\nCentral Board of Direct Taxes\nDirectorate of Revenue Intelligence\nDirectorate of Signal Intelligence, Ministry of Defence - for Jammu & Kashmir, North East & Assam Service Areas onlyState AgenciesDirector General of Police, of concerned state/Commissioner of Police, Delhi for Delhi Metro City Service Area only.\nCall data records (CDRs) can be sought by following the statutory provisions contained in Section 92 of the Code of Criminal Procedure, 1973 or Section 5(2) of the Indian Telegraph Act, 1885 read with Rule 419 A of Indian Telegraph (Amendment) Rules, 2007.\n\n== System details ==\nEarlier the provisioning of Interception of the Telephone was being done by the Telecom operators on the basis of duly authorized order by the competent authority in accordance with 419A telephone rule. Traditionally, the Law Enforcement Agency was approaching the various telecom companies based on the numbering scheme of the target telephone number. In CMS setup there is no change in the Interception authorization order envisaged in 419A telephone rule except that now the Law Enforcement Agency will go to only TERM Cell for any interception order provisioning irrespective of telephone numbering scheme. There is no change in the existing LIS / LIM system in the telecom network. The TERM Cell who are the field unit of DOT and carries the enforcement and regulation of licensing conditions in the field will be sole authority to provision the interception orders but interception orders will be obtained by Law Enforcement Agencies in according to the 419A telephone rule.\n\n== Government objective ==\nGovernment has set up the Centralized Monitoring System (CMS) to automate the process of Lawful Interception & Monitoring of telecommunications technology. Government of India on 2015-12-02 in a reply to parliament question no. 595 on scope, objectives and framework of the CMS has struck a balance between national security, online privacy and free speech informed that to take care of the privacy of citizens, lawful interception and monitoring is governed by the Section 5(2) of Indian Telegraph Act, 1885 read with Rule 419A of Indian Telegraph (Amendment) Rules, 2007 wherein oversight mechanism exists in form of review committee under chairmanship of the Cabinet Secretary at Central Government level and Chief Secretary of the State at the State Government level. The same mechanism is applicable for the interception under the CMS Project also. Additionally, there is an inbuilt mechanism of check and balance as Security Agencies/Law Enforcement Agencies cannot provision the target and the provisioning agency cannot see the content.\n\n== Media reaction ==\nBusiness Standard criticised the fact that a warrant need not be obtained. Firstpost criticised the lack of information from the government about the project and the lack of a legal recourse for a citizen whose personal details were misused or leaked. The Hindu also criticised the lack of information available about the system.The Indian Express criticised the introduction of the system in the absence of accountability and \"any reasonably effective safeguards\" to protect privacy. The Times of India criticised the introduction of CMS without public debate or Parliamentary accountability. The paper also felt that Indian privacy laws were \"lax\", and \"far worse than American law on these matters\".Forbes India pointed out that a consequence of CMS would be that innocent citizens could be wrongly accused of criminal activity. The New York Times argued that India did not need centralised interception facilities to have centralised tracking of interception requests. The paper also expressed supported for a strong privacy law, and advised Indian citizens to \"take greater care of their own privacy and safeguard the security of their communications\".\n\n== Human rights and civil-liberties groups reactions ==\nHuman rights and civil-liberties groups have expressed concerns that the CMS is prone to abuse, and is an infringement of privacy and civil liberties. Critics have described it as \"abuse of privacy rights and security-agency overreach\".Meenakshi Ganguly, the South Asia director of Human Rights Watch, felt that the move toward extensive \"surveillance capabilities enabled by digital communications\" suggests that governments are now \"casting the net wide, enabling intrusions into private lives\". Ganguly also felt that increasing surveillance around the world was an attempt by governments to \"grapple with the power of social media that can enable spontaneous street protests\".Praveen Swami, strategic affairs editor of Network18, felt that \"There is also the argument that the threat of a cyber attack is deliberately overplayed ... it is far-fetched. So there is a need for balance\". Pawan Sinha, a human rights teacher at Delhi University, believes that bypassing courts was \"really very dangerous\" and could be \"easily misused\".Anja Kovacs of the Internet Democracy Project, and a fellow at the New Delhi-based Centre for Internet and Society, felt that there was \"a growing discrepancy and power imbalance between citizens and the state\" and that in the Indian scenario, there were \"no checks and balances in place\".Sunil Abraham, executive director of Bangalore-based non-profit Centre for Internet and Society, advised Indians to \"stop using proprietary software, shift to free/open source software\" and \"encrypt all sensitive Internet traffic and email using software like TOR and GNU Privacy Guard\".Pranesh Prakash, director of policy at the Centre for Internet and Society, warned that the lack of privacy laws and government accountability makes the programme \"very worrisome.\" Cyberlaw specialist Pavan Duggal stated that the \"system is capable of tremendous abuse\" and \"even legitimate conversations could end up being tracked\". Mishi Choudhary, executive director, Software Freedom and Law Center stated that, \"There has been no public consultation on this issue. No one knows what they have proposed or whether it has parliamentary mandate. We don't even have empirical data on phone tapping from the government. It's like a black hole.\"Human rights activist Neingulo Krome described CMS as \"a threat to democracy\" and also felt that the agencies involved could \"soon challenge the authority of the government itself\"."
    }
  },
  {
    "instruction": "Write an answer to the following question: How can browsing history be used for device fingerprinting?",
    "context": "",
    "output": "The fingerprinter can determine which sites the browser had previously visited within a list it provided by querying the list using JavaScript with the CSS selector :visited.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can browsing history be used for device fingerprinting?",
      "answer": "The fingerprinter can determine which sites the browser had previously visited within a list it provided by querying the list using JavaScript with the CSS selector :visited."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are the two main types of questions used in cognitive password systems?",
    "context": "",
    "output": "The two main types of questions used in cognitive password systems are fact-based questions, which have answers that are independent of an individual's feelings, and opinion-based questions, which have answers based on personal opinions.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are the two main types of questions used in cognitive password systems?",
      "answer": "The two main types of questions used in cognitive password systems are fact-based questions, which have answers that are independent of an individual's feelings, and opinion-based questions, which have answers based on personal opinions."
    }
  },
  {
    "instruction": "Messaging spam\n\n==Introduction==\nMessaging spam, sometimes called SPIM, is a type of spam targeting users of instant messaging (IM) services, SMS, or private messages within websites.\n\n== Instant messaging applications ==\n\nInstant messaging systems, such as Telegram, WhatsApp, Twitter Direct Messaging, Kik, Skype and Snapchat are all targets for spammers. Many IM services are publicly linked to social media platforms, which may include information on the user such as age, sex, location and interests. Advertisers and scammers can gather this information, sign on to the service, and send unsolicited messages which could contain scam links, pornographic material, malware or ransomware. With most services users can report and block spam accounts, or set privacy settings so only contacts can contact them.\n\n== Countermeasures ==\nMany users choose to receive IMs only from people already on their contact list.\nIn corporate settings, spam over IM is blocked by IM spam blockers like those from Actiance, ScanSafe, and Symantec.\nIM providers like Kik have a \"report user\" button, which sends a chatlog to the IM administrators who can then take action.\n\n== Pornographic IM spambots ==\nSpam-bots often sign on to popular messaging services like Kik or Skype to spread pornographic images. Often if the user responds they receive a URL inviting them to a private livestream that will ask them to enter credit card details for \"age verification\".\nThese bots target random usernames; this often results in minors receiving unsolicited pornographic images.\n\n== On Windows NT-based systems ==\n\nIn 2002, a number of spammers began abusing the Windows Messenger service, a function of Windows designed to allow administrators to send alerts to users' workstations (not to be confused with Windows Messenger or Windows Live Messenger, a free instant messaging application) in Microsoft's Windows NT-based operating systems. Messenger Service spam appears as normal dialog boxes containing the spammer's message. These messages are easily blocked by firewalls configured to block packets to the NetBIOS ports 135-139 and 445 as well as unsolicited UDP packets to ports above 1024. Additionally, Windows XP Service Pack 2 disables the Messenger Service by default.\nMessenger Service spammers frequently send messages to vulnerable Windows machines with a URL. The message promises the user to eradicate spam messages sent via the Messenger Service. The URL leads to a website where, for a fee, users are told how to disable the Messenger service. Though the Messenger is easily disabled for free by the user, this works because it creates a perceived need and then offers an immediate solution.\n\n== In opinion-based recommender systems ==\nIn an opinion based recommender system, an important concern is how to evaluate the user-generated reviews on the items. One of the purpose of this evaluation is to identify malicious or spam reviews. Poorly written reviews are considered helpless to the recommender system. However, even if a review is well generated, they can still be harmful to the recommender system by their biased prejudice to form an actual advertisement or slander towards a target item.\nCurrent approach of spam detection methods includes analyzing the spam text and identifying the spam reviewers by their reviews and activities. For the first kind, a machine learning application on review text has been developed. For the second kind, researchers use network motif analysis technique to identify spam reviewers by their recurring reviewing activity.\nQuestion: How do spammers target users on social media platforms linked to instant messaging systems?",
    "context": "",
    "output": "Answer: Spammers target users on social media platforms linked to instant messaging systems by gathering user information such as age, sex, location, and interests. They use this information to sign on to the service and send unsolicited messages to users.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do spammers target users on social media platforms linked to instant messaging systems?",
      "answer": "Spammers target users on social media platforms linked to instant messaging systems by gathering user information such as age, sex, location, and interests. They use this information to sign on to the service and send unsolicited messages to users.",
      "context": "Messaging spam\n\n==Introduction==\nMessaging spam, sometimes called SPIM, is a type of spam targeting users of instant messaging (IM) services, SMS, or private messages within websites.\n\n== Instant messaging applications ==\n\nInstant messaging systems, such as Telegram, WhatsApp, Twitter Direct Messaging, Kik, Skype and Snapchat are all targets for spammers. Many IM services are publicly linked to social media platforms, which may include information on the user such as age, sex, location and interests. Advertisers and scammers can gather this information, sign on to the service, and send unsolicited messages which could contain scam links, pornographic material, malware or ransomware. With most services users can report and block spam accounts, or set privacy settings so only contacts can contact them.\n\n== Countermeasures ==\nMany users choose to receive IMs only from people already on their contact list.\nIn corporate settings, spam over IM is blocked by IM spam blockers like those from Actiance, ScanSafe, and Symantec.\nIM providers like Kik have a \"report user\" button, which sends a chatlog to the IM administrators who can then take action.\n\n== Pornographic IM spambots ==\nSpam-bots often sign on to popular messaging services like Kik or Skype to spread pornographic images. Often if the user responds they receive a URL inviting them to a private livestream that will ask them to enter credit card details for \"age verification\".\nThese bots target random usernames; this often results in minors receiving unsolicited pornographic images.\n\n== On Windows NT-based systems ==\n\nIn 2002, a number of spammers began abusing the Windows Messenger service, a function of Windows designed to allow administrators to send alerts to users' workstations (not to be confused with Windows Messenger or Windows Live Messenger, a free instant messaging application) in Microsoft's Windows NT-based operating systems. Messenger Service spam appears as normal dialog boxes containing the spammer's message. These messages are easily blocked by firewalls configured to block packets to the NetBIOS ports 135-139 and 445 as well as unsolicited UDP packets to ports above 1024. Additionally, Windows XP Service Pack 2 disables the Messenger Service by default.\nMessenger Service spammers frequently send messages to vulnerable Windows machines with a URL. The message promises the user to eradicate spam messages sent via the Messenger Service. The URL leads to a website where, for a fee, users are told how to disable the Messenger service. Though the Messenger is easily disabled for free by the user, this works because it creates a perceived need and then offers an immediate solution.\n\n== In opinion-based recommender systems ==\nIn an opinion based recommender system, an important concern is how to evaluate the user-generated reviews on the items. One of the purpose of this evaluation is to identify malicious or spam reviews. Poorly written reviews are considered helpless to the recommender system. However, even if a review is well generated, they can still be harmful to the recommender system by their biased prejudice to form an actual advertisement or slander towards a target item.\nCurrent approach of spam detection methods includes analyzing the spam text and identifying the spam reviewers by their reviews and activities. For the first kind, a machine learning application on review text has been developed. For the second kind, researchers use network motif analysis technique to identify spam reviewers by their recurring reviewing activity."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are the key server components for each configuration of encryption?",
    "context": "",
    "output": "The key server components include an encryption key server and a key management client.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are the key server components for each configuration of encryption?",
      "answer": "The key server components include an encryption key server and a key management client."
    }
  },
  {
    "instruction": "Write an answer to the following question: How is CSP delivered within the HTML code using a HTML META tag and what are its limitations?",
    "context": "",
    "output": "CSP can be delivered within the HTML code using a HTML META tag. However, its effectiveness will be limited as some features may not be fully supported or may have different syntax.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How is CSP delivered within the HTML code using a HTML META tag and what are its limitations?",
      "answer": "CSP can be delivered within the HTML code using a HTML META tag. However, its effectiveness will be limited as some features may not be fully supported or may have different syntax."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the bridging function in UT-VPN Server and how does it work?",
    "context": "",
    "output": "The bridging function in UT-VPN Server allows for bridging between an arbitrary NIC that the OS has and a virtual HUB.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the bridging function in UT-VPN Server and how does it work?",
      "answer": "The bridging function in UT-VPN Server allows for bridging between an arbitrary NIC that the OS has and a virtual HUB."
    }
  },
  {
    "instruction": "2016 United States election leaks\n\n==Introduction==\nThe 2016 United States election leaks were a series of publications of more than 150,000 stolen emails and other files during the U.S. presidential election campaigns released by Guccifer 2.0, DCLeaks and WikiLeaks. Computer hackers affiliated with the Russian military intelligence service (GRU) infiltrated information systems of the Democratic National Committee (DNC), the Democratic Congressional Campaign Committee (DCCC), and Clinton campaign officials, notably chairman John Podesta, and leaked some of the stolen materials. Emails from Guccifer 2.0 to journalists suggest a link to DCLeaks, and messages WikiLeaks exchanged with Guccifer 2.0 and DCLeaks suggest both submitted emails to WikiLeaks.Guccifer 2.0 released Democrats' files related to their House of Representatives candidates in Florida, Pennsylvania, New Hampshire, Ohio, Illinois, New Mexico and North Carolina, and documents stolen from John Podesta's mailbox and House Minority Leader Nancy Pelosi's hacked personal computer. Guccifer 2.0 also gave reporters a password to access private files on DCLeaks and released information about Republican donors and opposition research about Sarah Palin and Donald Trump. DCLeaks released emails from Republican targets including the 2016 campaign staff of Arizona Senator John McCain, and South Carolina Senator Lindsey Graham. DCLeaks also released information about more than 200 Democratic lawmakers, the emails of the former NATO supreme commander in Europe and files from the George Soros' Open Society Foundation.The emails and documents leaked from the Democratic Party's national committee (DNC) resulted in allegations that the DNC was biased against Bernie Sanders' presidential campaign. The revelations prompted the resignation of DNC chair Debbie Wasserman Schultz before the 2016 Democratic National Convention. These releases caused significant harm to the Clinton campaign, and have been cited as a potential contributing factor to her loss in the general election against Donald Trump. Podesta's emails shed light on the inner workings of the Clinton campaign and suggested that CNN commentator Donna Brazile had shared audience questions with the Clinton campaign in advance of town hall meetings. The emails also contained excerpts from three Clinton speeches to Goldman Sachs and an internal campaign document cataloging potentially problematic portions of over 50 paid speeches.On July 13, 2018, an indictment was made against 12 Russian GRU military officers; it alleged that Guccifer 2.0 and DCLeaks were part of a Russian military operation to interfere in the 2016 U.S. presidential election. The indictment also alleged that the Russian operation provided the emails to WikiLeaks. Wikileaks said its source was not the Russian government or a state party and the Russian government said it had no involvement.\n\n\n\n== Guccifer 2.0 ==\n\n\"Guccifer 2.0\" is a persona which claimed to be the hacker(s) who gained unauthorized access to the Democratic National Committee (DNC) computer network and then leaked its documents to the media, the website WikiLeaks, and a conference event. Some of the documents \"Guccifer 2.0\" released to the media appear to be forgeries cobbled together from public information and previous hacks, which had been mixed with disinformation. The New York Times noted, \"The seats that Guccifer 2.0 targeted in the document dumps were hardly random: They were some of the most competitive House races in the country.\"The U.S. Intelligence Community and research firms concluded that some of the genuine leaks from \"Guccifer 2.0\" were part of a series of cyberattacks on the DNC committed by two Russian military intelligence groups, and that \"Guccifer 2.0\" is actually a persona created by Russian intelligence services to cover for their interference in the 2016 U.S. presidential election. The Russian government denies involvement in the theft, and \"Guccifer 2.0\" denied links to Russia. On June 21, 2016, in an interview with Vice, \"Guccifer 2.0\" said he is Romanian. When pressed to use the Romanian language in an interview with Motherboard via online chat, \"he used such clunky grammar and terminology that experts believed he was using an online translator.\" Linguistic analysis by Shlomo Engelson Argamon showed that Guccifer 2.0 is most likely \"a Russian pretending to be a Romanian\". WikiLeaks founder Julian Assange said Guccifer 2.0's leaks \"look very much like they\u2019re from the Russians. But in some ways, they look very amateur, and almost look too much like the Russians.\"On June 14, 2016, according to The Washington Post, the DNC acknowledged a hack that was attributed to Russia and claimed by Guccifer 2.0 who released several hacked documents, including one from Podesta's mailbox, the next day.In mid-July 13, 2016, Guccifer 2.0 released over 10,000 names from the DNC in two spreadsheets and a list of objectionable quotes from Sarah Palin. A few days later, Guccifer 2.0 gave The Hill exclusive access to numerous documents and files covering political strategies, including correlating the banks that received bailout funds with Republican Party and Democratic Party donations.On July 22, 2016, the DNC emails were published by WikiLeaks and Guccifer 2.0 tweeted that he was the hacker and WikiLeaks' source.On August 15, 2016, a candidate for Congress allegedly contacted Guccifer 2.0 to request information on the candidate's opponent. Guccifer 2.0 responded with the requested stolen information. A week later, Florida GOP campaign advisor Aaron Nevins contacted Guccifer 2.0 and asked for material. Nevins set up a Dropbox account and Guccifer 2.0 transferred 2.5 gigabytes of data to it. Nevins analyzed the data and posted the results on his blog, HelloFLA.com, and sends Guccifer 2.0 a link. Guccifer 2.0 forwarded the link to Roger Stone.On September 13, 2016, during a conference, a confirmed and remote representative of Guccifer 2.0 released almost 700 megabytes (MB) worth of documents from the DNC, which included personal and work email addresses and phone numbers for top Obama White House officials . According to British journalist Duncan Campbell, the Russian intelligence agency, GRU, tried to implicate Seth Rich as the source of the stolen DNC files in order to draw attention away from themselves. Datestamps on the DNC files released on September 13 were altered to show the data had been obtained on July 5, 2016, five days before Rich's death, and the time zone was changed to Eastern Time, within which Washington, D.C., falls. Based partly on their acceptance of the false dates, some experts then concluded that the emails had been copied in the DNC offices, and had not been hacked from outside.On October 4, 2016, Guccifer 2.0 released documents and claimed that they were taken from the Clinton Foundation and showed \"corruption and malfeasance\" there. Security experts quickly determined that the release was a hoax; the release did not contain Clinton Foundation documents, but rather consisted of documents previously released from the DNC and DCCC thefts, data aggregated from public records, and documents that were fabricated altogether as propaganda. Singled out as particularly unrealistic was the idea that Clinton's team would have actually named a file \"Pay for Play\" on their own server, as Guccifer 2.0's screenshots of the alleged \"hack\" show.\n\n== DCLeaks ==\n\nDCLeaks (also known as DC Leaks) was a website that was established in June 2016. It was responsible for publishing leaks of emails belonging to multiple prominent figures in the United States government and military. Cybersecurity research firms determined the site was a front for the Russian cyber-espionage group Fancy Bear. On July 13, 2018, an indictment was made against 12 Russian GRU military officers; it alleged that DCLeaks was part of a Russian military operation to interfere in the 2016 U.S. presidential election.\nAccording to the DCLeaks site's \"About\" page, their aim was \"to find out and tell you the truth about U.S. decision-making process  [sic] as well as about the key elements of American political life.\" They said they were \"the American hacktivists who respect and appreciate freedom of speech, human rights and government of the people.\"In late June 2016, Guccifer 2.0 gave reporters a password to access emails stolen from Democrats on the DCLeaks website.On July 1, 2016, DCLeaks released the emails of four-star General Philip Breedlove, the former NATO supreme commander in Europe. The emails allegedly show that Breedlove sought to overcome President Barack Obama's reluctance to escalate military tensions with Russia over the Russo-Ukrainian War in 2014.On August 12, 2016, DCLeaks released roughly 300 emails from Republican targets, including the 2016 campaign staff of Arizona Senator John McCain, South Carolina Senator Lindsey Graham, and 2012 presidential candidate and former Minnesota Representative Michele Bachmann. The release included 18 emails from the Illinois Republican Party. On the same day, DCLeaks released information about more than 200 Democratic lawmakers, including their personal cellphone numbers. The numerous crank calls that Hillary Clinton received from this disclosure along with the loss of her campaign's email security caused a very severe disruption of her campaign.On August 15, 2016, DCLeaks released 2,576 files predominately related to George Soros' Open Society Foundation. The leak included the Foundation's internal work plans, strategies, priorities and other worldwide activities by Soros and showed the Foundation's support for Palestinian and pro-BDS causes, including Adalah.On September 15, 2016, DCLeaks contacted WikiLeaks about a submission. The Mueller Report concluded the Podesta Emails were probably staged for transfer to WikiLeaks on September 19, 2016.\n\n== DNC Email Leak ==\n\nThe 2016 Democratic National Committee email leak is a collection of Democratic National Committee (DNC) emails stolen by one or more hackers operating under the pseudonym \"Guccifer 2.0\" who are alleged to be Russian intelligence agency hackers, according to indictments carried out by the Mueller investigation. The DNC emails were published by WikiLeaks on July 22, 2016, just before the 2016 Democratic National Convention. Julian Assange said he had originally meant to release the emails on July 18, but WikiLeaks \"had these hiccups that delayed us, and we were given a little more time.\" It wasn't clear who had given him time, and Assange argued that the recording was faulty.The first batch included 19,252 emails and 8,034 attachments from the DNC, the governing body of the United States' Democratic Party. The leak includes emails from seven key DNC staff members, and date from January 2015 to May 2016. On November 6, 2016, WikiLeaks released a second batch of DNC emails, adding 8,263 emails to its collection.The leaks resulted in allegations of bias against Bernie Sanders' presidential campaign, in apparent contradiction with the DNC leadership's publicly stated neutrality, as several DNC operatives openly derided Sanders' campaign and discussed ways to advance Hillary Clinton's nomination. Later revelations included controversial DNC\u2013Clinton agreements dated before the primary, regarding financial arrangements and control over policy and hiring decisions. The revelations prompted the resignation of DNC chair Debbie Wasserman Schultz before the 2016 Democratic National Convention. The DNC issued a formal apology to Bernie Sanders and his supporters \"for the inexcusable remarks made over email\" that did not reflect the DNC's \"steadfast commitment to neutrality during the nominating process.\" After the convention, DNC CEO Amy Dacey, CFO Brad Marshall, and Communications Director Luis Miranda also resigned in the wake of the controversy.\n\n\n*** Guccifer 2.0 submission to WikiLeaks ***\nA week after Guccifer 2.0 appeared online, WikiLeaks sent the persona a message saying to \"send any new material here for us to review and it will have a much higher impact than what you are doing.\" After not receiving a reply, on July 26, 2016 WikiLeaks sent another message that said \"if you have anything hillary related we want it in the next tweo [sic] days prefable [sic] because the DNC is approaching and she will solidify bernie supporters behind her after.\" Guccifer 2.0 responded \"ok ... i see,\" and WikiLeaks added \"we think trump has only a 25% chance of winning against hillary ... so conflict between bernie and hillary is interesting.\" On July 14, 2016 Guccifer 2.0 sent WikiLeaks an email with an encrypted attachment labeled \"wk dnc link1.txt.gpg.\" According to the indictment, the email explained that \"the encrypted file contained instructions on how to access an online archive of stolen DNC documents.\"Four days later, WikiLeaks responded that it had received \"the 1Gb or so archive\" and would release the files that week. The DNC emails were released several days later.\n\n\n*** Contents ***\nThe emails leaked by Wikileaks revealed information about the DNC's interactions with the media, Hillary Clinton's and Bernie Sanders' campaigns, and financial contributions. It also includes personal information about the donors of the Democratic Party, including credit card and Social Security numbers, which could facilitate identity theft.\n\n\n**** Media ****\nThe emails include DNC staff's \"off-the-record\" correspondence with media personalities, including the reporters at CNN, Politico, The Wall Street Journal, and The Washington Post.\n\n\n**** Bernie Sanders' campaign ****\nIn the emails, DNC staffers derided the Sanders campaign. The Washington Post reported: \"Many of the most damaging emails suggest the committee was actively trying to undermine Bernie Sanders's presidential campaign.\"In a May 2016 email chain, the DNC chief financial officer (CFO) Brad Marshall told the DNC chief executive officer, Amy Dacey, that they should have someone from the media ask Sanders if he is an atheist prior to the West Virginia primary.On May 21, 2016, DNC National Press Secretary Mark Paustenbach sent an email to DNC Spokesman Luis Miranda mentioning a controversy that ensued in December 2015, when the National Data Director of the Sanders campaign and three subordinate staffers accessed the Clinton campaign's voter information on the NGP VAN database. (The party accused Sanders' campaign of impropriety and briefly limited its access to the database. The Sanders campaign filed suit for breach of contract against the DNC, but dropped the suit on April 29, 2016.) Paustenbach suggested that the incident could be used to promote a \"narrative for a story, which is that Bernie never had his act together, that his campaign was a mess.\" The DNC rejected this suggestion. The Washington Post wrote: \"Paustenbach's suggestion, in that way, could be read as a defense of the committee rather than pushing negative information about Sanders. But this is still the committee pushing negative information about one of its candidates.\"\n\n\n**** Debbie Wasserman Schultz's emails ****\nFollowing the Nevada Democratic convention, Debbie Wasserman Schultz wrote about Jeff Weaver, manager of Bernie Sanders' campaign: \"Damn liar. Particularly scummy that he barely acknowledges the violent and threatening behavior that occurred\". In another email, Wasserman Schultz said of Bernie Sanders, \"He isn't going to be president.\" Other emails showed her stating that Sanders doesn't understand the Democratic Party.In May 2016, MSNBC's Mika Brzezinski accused the DNC of bias against the Sanders campaign and called on Wasserman Schultz to step down. Wasserman Schultz was upset at the negative media coverage of her actions, and she emailed the political director of NBC News, Chuck Todd, that such coverage of her \"must stop\". Describing the coverage as the \"LAST straw\", she ordered the DNC's communications director to call MSNBC president Phil Griffin to demand an apology from Brzezinski.\n\n\n**** Financial and donor information ****\nAccording to The New York Times, the cache included \"thousands of emails exchanged by Democratic officials and party fund-raisers, revealing in rarely seen detail the elaborate, ingratiating and often bluntly transactional exchanges necessary to harvest hundreds of millions of dollars from the party's wealthy donor class. The emails capture a world where seating charts are arranged with dollar totals in mind, where a White House celebration of gay pride is a thinly disguised occasion for rewarding wealthy donors and where physical proximity to the president is the most precious of currencies.\" As is common in national politics, large party donors \"were the subject of entire dossiers, as fund-raisers tried to gauge their interests, annoyances and passions.\"In a series of email exchanges in April and May 2016, DNC fundraising staff discussed and compiled a list of people (mainly donors) who might be appointed to federal boards and commissions. OpenSecrets senior fellow Bob Biersack noted that this is a longstanding practice in the United States: \"Big donors have always risen to the top of lists for appointment to plum ambassadorships and other boards and commissions around the federal landscape.\" The White House denied that financial support for the party was connected to board appointments, saying: \"Being a donor does not get you a role in this administration, nor does it preclude you from getting one. We've said this for many years now and there's nothing in the emails that have been released that contradicts that.\"\n\n== Podesta Emails ==\n\nIn March 2016, the personal Gmail account of John Podesta, a former White House chief of staff and chair of Hillary Clinton's 2016 U.S. presidential campaign, was compromised via a spear-phishing attack, and some of his emails, many of which were work-related, were hacked. WikiLeaks published the Podesta Emails in October and November 2016. Analysis of the files and communications between WikiLeaks and DCLeaks has resulted in the Mueller Report and Thomas Rid suggesting that the Russian cyber spying group Fancy Bear used DCLeaks to pass the Podesta Emails to WikiLeaks.Podesta's emails shed light on the inner workings of the Clinton campaign, suggested that CNN commentator Donna Brazile had shared audience questions with the Clinton campaign in advance of town hall meeting and contained excerpts from Hillary Clinton's speeches to Wall Street firms. Proponents of the extensively discredited Pizzagate conspiracy theory falsely claimed the emails contained coded messages which supported their conspiracy theory.\n\n\n*** DCLeaks submission to WikiLeaks ***\nOn September 15, 2016 the DCLeaks Twitter account sent WikiLeaks a DM about a possible submission, saying they had gotten no response on the secured chat. The WikiLeaks account responded \"Hi there\" without further elaboration but did not receive a response. The same day, the Guccifer 2.0 Twitter account sent DCLeaks a DM saying that WikiLeaks was trying to contact them and to arrange to speak through encrypted email. Analysis of the metadata on the Podesta emails show a creation date of September 19, 2016. The Mueller Report concluded that this might have been when the emails were transferred to WikiLeaks.\n\n\n*** Publication ***\nOn October 7, 2016, a few hours after the Obama Administration released a statement by the Department of Homeland Security and the director of National Intelligence accusing the Russian government of interfering in the election through hacking, and 30 minutes after The Washington Post reported on the Access Hollywood videotape, WikiLeaks began publishing thousands of emails from Podesta's Gmail account. The hacked documents effectively distracted media and voter attention from both stories. According to WikiLeaks journalist Stefania Maurizi, the release day had been set several days earlier. Throughout October, WikiLeaks released installments of the Podesta emails on a daily basis.On October 17, 2016, the government of Ecuador severed the internet connection of WikiLeaks founder Julian Assange at the Ecuadorian embassy in London. The Ecuadorian government stated that it had temporarily severed Assange's internet connection because of WikiLeaks' release of documents \"impacting on the U.S. election campaign\", although it also stated this was not meant to prevent WikiLeaks from operating. WikiLeaks continued releasing installments of the Podesta emails during this time.\n\n\n*** Contents ***\nSome of the emails provide some insight into the inner workings of the Clinton campaign. For example, the emails show a discussion among campaign manager Robby Mook and top aides about possible campaign themes and slogans. Other emails revealed insights about the internal conflicts of the Clinton Foundation. Some were emails that Barack Obama and Podesta exchanged in 2008.One of the emails released on October 12, 2016, included Podesta's iCloud account password. His iCloud account was hacked, and his Twitter account was then briefly compromised.\n\n\n**** Clinton's Wall Street speeches ****\nWikiLeaks published transcripts of three Clinton speeches to Goldman Sachs and an 80-page internal campaign document cataloging potentially problematic portions of over 50 paid speeches. Earlier in the campaign, WikiLeaks had offered a reward for copies of the speeches. During the Democratic primary campaign, Bernie Sanders had criticized Hillary Clinton for refusing to release transcripts of speeches given to financial firms, portraying her as too close to Wall Street.In the October 2016 presidential debate, Clinton voiced her support for a \"no-fly\" zone in Syria. In a 2013 speech, Clinton had discussed the difficulties involved. In particular, she noted that in order to establish a no-fly zone, Syria's air defenses would need to be destroyed. Because the Assad government had located these anti-aircraft batteries in populated civilian areas, their destruction would cause many collateral civilian deaths. Clinton's staff additionally flagged comments about regulation of Wall Street, as well as her relationship with the industry, as potentially problematic.The excerpts came up in the two subsequent presidential debates between Clinton and Trump. In one of the debates, the moderator Martha Raddatz quoted an excerpt saying that politicians \"need both a public and a private position\" and asked Clinton if it was okay for politicians to be \"two-faced\". Clinton replied, \"As I recall, that was something I said about Abraham Lincoln after having seen the wonderful Steven Spielberg movie called Lincoln. It was a master class watching president Lincoln get the Congress to approve the 13th amendment, it was principled and strategic. I was making the point that it is hard sometimes to get the Congress to do what you want to do.\" In the third presidential debate, the moderator Chris Wallace quoted a speech excerpt where Clinton says, \"My dream is a hemispheric common market with open trade and open borders,\" and asked if she was for open borders. Clinton replied, \"If you went on to read the rest of the sentence, I was talking about energy. We trade more energy with our neighbors than we trade with the rest of the world combined. And I do want us to have an electric grid, an energy system that crosses borders.\"\n\n\n**** Discussions of Catholic religious activities ****\nSandy Newman wrote to Podesta: \"I have not thought at all about how one would 'plant the seeds of the revolution', or who would plant them.\" Podesta agreed that this was necessary to do as Newman suggested and wrote back to note that they had created groups like Catholics in Alliance for the Common Good and Catholics United to push for a more progressive approach to the faith, change would \"have to be bottom up\".Raymond Arroyo responded: \"It makes it seem like you're creating organizations to change the core beliefs of the church,\" he said. \"For someone to come and say, 'I have a political organization to change your church to complete my political agenda or advance my agenda', I don't know how anybody could embrace that.\" Professor Robert P. George added that \"these groups are political operations constructed to masquerade as organizations devoted to the Catholic faith\".The leak revealed an email sent by John Halpin, a senior fellow at the Center for American Progress. The email discussed conservative media mogul Rupert Murdoch's decision to raise his kids in the Catholic Church. He wrote, \"Many of the most powerful elements of the conservative movement are all Catholic (many converts) ... It's an amazing bastardization of the faith. They must be attracted to the systematic thought and severely backwards gender relations and must be totally unaware of Christian democracy.\" Palmieri responded: \"I imagine they think it is the most socially acceptable, politically conservative religion\u2014their rich friends wouldn't understand if they became evangelical.\" Supporters and members of Donald Trump's campaign called the email exchange evidence of anti-Catholic sentiment in the Democratic Party. Halpin confirmed that he had written the email, though he contested claims that it was \"anti-Catholic\" and said that it was taken out of context and that he had sent the email to his Catholic colleagues \"to make a fleeting point about perceived hypocrisy and the flaunting of one's faith by prominent conservative leaders.\"\n\n\n**** Presidential debate questions shared by Donna Brazile ****\nOn October 11, 2016, WikiLeaks released the text of an email sent by Donna Brazile on March 12, 2016, to Clinton communications director Jennifer Palmieri with the subject header \"From time to time I get questions in advance.\" The email included a question about the death penalty. The following day Clinton received a similar question from the Townhall host, Roland Martin. Brazile initially denied coordinating with the Clinton campaign, and a CNN spokesperson said \"CNN did not share any questions with Donna Brazile, or anyone else for that matter, prior to the town hall\" and that \"we have never, ever given a town hall question to anyone beforehand\". According to CNNMoney, the debate moderator Roland Martin did not deny that he shared questions with Brazile. In another leaked email, Brazile wrote: \"One of the questions directed to HRC tomorrow is from a woman with a rash. Her family has lead poison and she will ask what, if anything, will Hillary do as president to help the ppl of Flint.\" At a debate in Flint the following day, a woman whose \"son had developed a rash from the contaminated water\" asked Clinton: \"If elected president, what course will you take to regain my trust in government?\" In a third email, Brazile added: \"I'll send a few more.\"CNN severed ties with Brazile on October 14, 2016. Brazile later said that CNN did not give her \"the ability to defend myself\" after the email release and referred to WikiLeaks as \"WikiLies\". Brazile repeatedly denied that she had received the question on the death penalty in advance and has said that the documents released by WikiLeaks were \"altered\". In an essay for Time written on March 17, 2017, Brazile wrote that the emails revealed that \"among the many things I did in my role as a Democratic operative and D.N.C. Vice Chair [...] was to share potential town hall topics with the Clinton campaign.\" She wrote, \"My job was to make all our Democratic candidates look good, and I worked closely with both campaigns to make that happen. But sending those emails was a mistake I will forever regret.\"\n\n\n**** Saudi Arabia and Qatar ****\nOne leaked email from August 2014, addressed to Podesta, identifies Saudi Arabia and Qatar as providing \"clandestine\", \"financial and logistic\" aid to ISIS and other \"radical Sunni groups\". The email outlines a plan of action against ISIS, urges putting pressure on Saudi Arabia and Qatar to end their alleged support for the group. Its unclear who originally wrote the email.\n\n== Investigations ==\n\n\n*** Cybersecurity analysis ***\nCybersecurity experts and firms, including CrowdStrike, Fidelis Cybersecurity, Mandiant, SecureWorks, and ThreatConnect, and the editor for Ars Technica, stated the leak was part of a series of cyberattacks on the DNC committed by two Russian intelligence groups. U.S. intelligence agencies also stated with \"high confidence\" that the Russian government was behind the theft of emails and documents from the DNC, according to reports in The New York Times and The Washington Post.WikiLeaks founder Julian Assange initially stuck to WikiLeaks policy of neither confirming or denying sources but in January 2017 said that their \"source is not the Russian government and it is not a state party\", and the Russian government said it had no involvement.Researchers from the Atlanta-based cybersecurity firm Dell SecureWorks reported that the emails had been obtained through a data theft carried out by the hacker group Fancy Bear, a group of Russian intelligence-linked hackers that were also responsible for cyberattacks that targeted the Democratic National Committee (DNC) and Democratic Congressional Campaign Committee (DCCC), resulting in WikiLeaks publishing emails from those hacks.SecureWorks concluded Fancy Bear had sent Podesta an email on March 19, 2016, that had the appearance of a Google security alert, but actually contained a misleading link\u2014a strategy known as spear-phishing. The link\u2014which used the URL shortening service Bitly\u2014brought Podesta to a fake log-in page where he entered his Gmail credentials. The email was initially sent to the IT department as it was suspected of being a fake but was described as \"legitimate\" in an e-mail sent by a department employee, who later said he meant to write \"illegitimate\".SecureWorks had tracked the activities of Fancy Bear for more than a year before the cyberattack, and in June 2016, had reported the group made use of malicious Bitly links and fake Google login pages to trick targets into divulging their passwords. However, the hackers left some of their Bitly accounts public, allowing SecureWorks to trace many of their links to e-mail accounts targeted with spear-phishing attacks. Of this list of targeted accounts, more than one hundred were policy advisors to Clinton, or members of her presidential campaign, and by June, twenty staff members had clicked on the phishing links.\n\n\n*** United States intelligence conclusions ***\n\nOn October 7, 2016, the United States Department of Homeland Security and the Office of the Director of National Intelligence stated that the US intelligence community was \"confident\" that the Russian government directed the breaches and the release of the obtained or allegedly obtained material in an attempt to \"... interfere with the US election process.\"The U.S. Intelligence Community tasked resources debating why Putin chose summer 2016 to escalate active measures influencing U.S. politics. Director of National Intelligence James R. Clapper said after the 2011\u201313 Russian protests, Putin's confidence in his viability as a politician was damaged, and Putin responded with the propaganda operation. Former CIA officer Patrick Skinner explained the goal was to spread uncertainty. Former Director of the Defense Intelligence Agency David Shedd said that \"the release of emails just as the Democratic National Convention is getting underway this week has the hallmarks of a Russian active measures campaign.\"On December 9, 2016, the CIA told U.S. legislators the U.S. Intelligence Community concluded Russia conducted operations during the 2016 U.S. election to assist Donald Trump in winning the presidency. Multiple U.S intelligence agencies concluded people with direct ties to the Kremlin gave WikiLeaks hacked emails from the DNC and additional sources such as John Podesta, campaign chairman for Hillary Clinton. The CIA said the foreign intelligence agents were Russian operatives previously known to the U.S. CIA officials told U.S. Senators it was \"quite clear\" Russia's intentions were to help Trump. Trump released a statement December 9, and disregarded the CIA conclusions.During November 2017, the Associated Press revealed that the FBI had deviated from its policy and failed to notify almost all of the persons in the cross hairs of the Kremlin-backed Fancy Bear's attack of 312 prominent government and defense officials who had their emails posted on DCLeaks.Throughout late 2017 into early 2018, numerous individuals gave testimonies to the House Permanent Select Committee on Intelligence (HPSCI) who were charged with carrying out an investigation into the series of cyberattacks. On January 10, 2017, FBI Director James Comey told the Senate Intelligence Committee that Russia succeeded in \"collecting some information from Republican-affiliated targets but did not leak it to the public\". In March 2017, FBI Director James Comey told the House Intelligence Committee that the Russians \u201cdidn't deal with WikiLeaks directly.\u201d He later told the Senate, \u201cThe Russians interfered with our elections in the 2016 cycle,\u201d he said. \u201cThey did it with purpose. They did it with sophistication, with overwhelming technical efforts, and it was an \u2018active measures\u2019 campaign driven from the top of that government.\u201d The Former Director of National Intelligence James Clapper put the conclusion simply to Raffi Khatchadourian: \u201cIt was done by a cutout, which of course afforded Assange plausible deniability.\u201d\n\n\n*** Steele dossier allegations ***\n\nThe Steele dossier, a controversial and unfinished political opposition research report published in January 2017, included several allegations relating to the hacking and leaking of the emails. The individuals named have denied the allegations. Some allegations have been publicly confirmed. However the intelligence community and most experts have treated the dossier with caution due to its unverified allegations.\n\n\n*** Authenticity ***\nA declassified report by the CIA, FBI, and NSA noted that, \"Moscow most likely chose WikiLeaks because of its self-proclaimed reputation for authenticity. Disclosures through WikiLeaks did not contain any evident forgeries.\"Cybersecurity experts interviewed by PolitiFact believe that while most of the emails are probably unaltered, it is possible the hackers inserted some doctored or fabricated material into the collection. Cybersecurity expert Robert Graham described the contents of some of the emails as authentic by using the DomainKeys Identified Mail (DKIM) contained in these emails' signatures. However, not all of the emails have these keys in their signature, and thus could not be verified with this method.\n\n== Reactions ==\nOn July 18, 2016, Dmitry Peskov, press secretary for Russian president Vladimir Putin, stated that the Russian government had no involvement in the DNC hacking incident. Peskov called it \"paranoid\" and \"absurd\", saying: \"We are again seeing these maniacal attempts to exploit the Russian theme in the US election campaign.\" That position was later reiterated by the Russian Embassy in Washington, DC, which called the allegation \"entirely unrealistic\".\n\n\n*** Reactions to DNC Email Leak ***\nThe leak fueled tensions going into the 2016 Democratic National Convention: although DNC operatives denied accusations of bias, Sanders operatives and multiple media commentators cited the leaks as clear evidence that the DNC had been favoring Clinton and undermining Sanders. Several media commentators have disputed the significance of the emails, arguing that the DNC's internal preference for Clinton was not historically unusual and was unlikely to have swayed the final outcome of the primary; whereas many of Sanders' supporters viewed the revelations as symptomatic of an entrenched, unethical political establishment.On July 24, 2016, Sanders urged Wasserman Schultz to resign following the leak and stated that he was \"disappointed\" by the leak, but that he was \"not shocked.\" Jeff Weaver, Bernie Sanders' campaign manager, called for greater accountability in the DNC, calling Wasserman Schultz \"a figure of disunity\" within the Democratic Party. Later the same day, Wasserman Schultz resigned from her position as DNC Chairman, effective as of the end of the nominating convention. On July 24, 2016, in an interview with NPR, former DNC Chair and current Governor of Virginia Terry McAuliffe said \"... that the chair's job should be \"to remain neutral.\" \"I sat in that chair in 2004 trying to navigate all the different candidates we had. But if you had people in there who were trashing one of the candidates, I can tell you this, if I were still chairman they wouldn't be working there. I mean, that is just totally unacceptable behavior.\"On July 25, 2016, Anthony Zurcher, North America reporter for the BBC, commented that \"the revelation that those in the heart of the Democratic establishment sought to undermine the anti-establishment Sanders is roughly on a par with [Casablanca character] police Capt Renault's professed shock that gambling was taking place in the Casablanca club he was raiding, as a waiter hands him his winnings.\"On July 27, 2016, The New York Times reported that Julian Assange, in an interview on British ITV on June 12, 2016, had \"made it clear that he hoped to harm Hillary Clinton's chances of winning the presidency.\"\n\n\n*** Reactions to Podesta Emails ***\nSociology professor Zeynep Tufekci criticized how WikiLeaks handled the release of these emails, writing, \"Taking one campaign manager's email account and releasing it with zero curation in the last month of an election needs to be treated as what it is: political sabotage, not whistle-blowing.\" In an op-ed for The Intercept, James Risen criticized the media for its reporting on emails, arguing that the hacking of the emails was a more significant story than the content of the emails themselves. Thomas Frank, writing in an editorial column for The Guardian, argued that the emails gave an \"unprecedented view into the workings of the elite, and how it looks after itself\".Glen Caplin, a spokesman for the Clinton campaign, said, \"By dribbling these out every day WikiLeaks is proving they are nothing but a propaganda arm of the Kremlin with a political agenda doing [Vladimir] Putin's dirty work to help elect Donald Trump.\"\n\n\n*** Other reactions ***\nFollowing the publication of the stolen emails, NSA whistleblower Edward Snowden criticized WikiLeaks for its wholesale leakage of data, writing that \"their hostility to even modest curation is a mistake.\" The Washington Post contrasted the difference between WikiLeaks' practices and Snowden's disclosure of information about NSA: while Snowden worked with journalists to vet documents (withholding some where it would endanger national security), WikiLeaks' \"more radical\" approach involves the dumping of \"massive, searchable caches online with few\u2014if any\u2014apparent efforts to remove sensitive personal information.\"\nOn July 25, 2016, Anne Applebaum, columnist for The Washington Post, wrote that:... with the exception of a few people on Twitter and a handful of print journalists, most of those covering this story, especially on television, are not interested in the nature of the hackers, and they are not asking why the Russians apparently chose to pass the emails on to WikiLeaks at this particular moment, on the eve of the Democratic National Convention. They are focusing instead on the content of what were meant to be private emails ...She went on to describe in detail other Russian destabilization campaigns in Eastern European countries.On July 25, 2016, Thomas Rid, Professor in Security Studies at King's College, London, and non-resident fellow at the School for Advanced International Studies, Johns Hopkins University, in Washington, DC, summed up the evidence pointing to Russia being behind the hacking of the DNC files and the \"Guccifer-branded leaking operation\". He concludes that these actions successfully blunted the \"DNC's ability to use its opposition research in surprise against Trump ...\" He further writes that data exfiltration from political organizations is done by many countries and is considered to be a legitimate form of intelligence work. \"But digitally exfiltrating and then publishing possibly manipulated documents disguised as freewheeling hacktivism is crossing a big red line and setting a dangerous precedent: an authoritarian country directly yet covertly trying to sabotage an American election.\"Russian security expert and investigative journalist Andrei Soldatov said \"It is almost impossible to know for sure whether or not Russia is behind a hack of the DNC's servers\". According to him, one of the reasons Russia would try to sway the US presidential election is that the Russian government considers Clinton \"a hater of Russia\": \"There is this mentality in Russia of being besieged; that it is always under attack from the United States ... They are trying to interfere in our internal affairs so why not try to do the same thing to them?\"The American public's interest in WikiLeaks in October roughly coincided with a tightening presidential race between Trump and Clinton. According to an analysis of opinion polling by Harry Enten of FiveThirtyEight, the release of the emails roughly matched Clinton's decline in the polls, though public perceptions of her trustworthiness remained stable in the polls. Enten concluded that WikiLeaks' activities were \"among the factors that might have contributed to [Clinton's] loss.\"\n\n== Civil DNC lawsuit ==\n\nOn April 20, 2018, the Democratic National Committee filed a civil lawsuit in federal court in New York, accusing the Russian government, the Trump campaign, Wikileaks, and others of conspiracy to alter the course of the 2016 presidential election and asking for monetary damages and a declaration admitting guilt. A hearing on the defendants' motions to dismiss was scheduled for May 17, 2018. In July 2019, the suit was dismissed with prejudice. In his judgement, federal judge John Koeltl said that although he believed the Russian government was involved in the hacking, US federal law generally prohibited suits against foreign governments. The judge said the other defendants, \"did not participate in any wrongdoing in obtaining the materials in the first place\" and were therefore within the law in publishing the information. He also said that the DNC's argument was \"entirely divorced from the facts\" and even if the Russians had directly provided the hacked documents to the Trump team, it would not be criminal for the campaign to publish those documents, as long as they did not contribute to the hacking itself. Koeltl denied the defendants motion for sanctions, but dismissed the suit with prejudice, meaning it had a substantive legal defect and could not be refiled.\n\nWhat was the role of WikiLeaks in the DNC email leak?",
    "context": "",
    "output": "A: WikiLeaks published the DNC emails on July 22, 2016, just before the 2016 Democratic National Convention.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was the role of WikiLeaks in the DNC email leak?",
      "answer": "WikiLeaks published the DNC emails on July 22, 2016, just before the 2016 Democratic National Convention.",
      "context": "2016 United States election leaks\n\n==Introduction==\nThe 2016 United States election leaks were a series of publications of more than 150,000 stolen emails and other files during the U.S. presidential election campaigns released by Guccifer 2.0, DCLeaks and WikiLeaks. Computer hackers affiliated with the Russian military intelligence service (GRU) infiltrated information systems of the Democratic National Committee (DNC), the Democratic Congressional Campaign Committee (DCCC), and Clinton campaign officials, notably chairman John Podesta, and leaked some of the stolen materials. Emails from Guccifer 2.0 to journalists suggest a link to DCLeaks, and messages WikiLeaks exchanged with Guccifer 2.0 and DCLeaks suggest both submitted emails to WikiLeaks.Guccifer 2.0 released Democrats' files related to their House of Representatives candidates in Florida, Pennsylvania, New Hampshire, Ohio, Illinois, New Mexico and North Carolina, and documents stolen from John Podesta's mailbox and House Minority Leader Nancy Pelosi's hacked personal computer. Guccifer 2.0 also gave reporters a password to access private files on DCLeaks and released information about Republican donors and opposition research about Sarah Palin and Donald Trump. DCLeaks released emails from Republican targets including the 2016 campaign staff of Arizona Senator John McCain, and South Carolina Senator Lindsey Graham. DCLeaks also released information about more than 200 Democratic lawmakers, the emails of the former NATO supreme commander in Europe and files from the George Soros' Open Society Foundation.The emails and documents leaked from the Democratic Party's national committee (DNC) resulted in allegations that the DNC was biased against Bernie Sanders' presidential campaign. The revelations prompted the resignation of DNC chair Debbie Wasserman Schultz before the 2016 Democratic National Convention. These releases caused significant harm to the Clinton campaign, and have been cited as a potential contributing factor to her loss in the general election against Donald Trump. Podesta's emails shed light on the inner workings of the Clinton campaign and suggested that CNN commentator Donna Brazile had shared audience questions with the Clinton campaign in advance of town hall meetings. The emails also contained excerpts from three Clinton speeches to Goldman Sachs and an internal campaign document cataloging potentially problematic portions of over 50 paid speeches.On July 13, 2018, an indictment was made against 12 Russian GRU military officers; it alleged that Guccifer 2.0 and DCLeaks were part of a Russian military operation to interfere in the 2016 U.S. presidential election. The indictment also alleged that the Russian operation provided the emails to WikiLeaks. Wikileaks said its source was not the Russian government or a state party and the Russian government said it had no involvement.\n\n\n\n== Guccifer 2.0 ==\n\n\"Guccifer 2.0\" is a persona which claimed to be the hacker(s) who gained unauthorized access to the Democratic National Committee (DNC) computer network and then leaked its documents to the media, the website WikiLeaks, and a conference event. Some of the documents \"Guccifer 2.0\" released to the media appear to be forgeries cobbled together from public information and previous hacks, which had been mixed with disinformation. The New York Times noted, \"The seats that Guccifer 2.0 targeted in the document dumps were hardly random: They were some of the most competitive House races in the country.\"The U.S. Intelligence Community and research firms concluded that some of the genuine leaks from \"Guccifer 2.0\" were part of a series of cyberattacks on the DNC committed by two Russian military intelligence groups, and that \"Guccifer 2.0\" is actually a persona created by Russian intelligence services to cover for their interference in the 2016 U.S. presidential election. The Russian government denies involvement in the theft, and \"Guccifer 2.0\" denied links to Russia. On June 21, 2016, in an interview with Vice, \"Guccifer 2.0\" said he is Romanian. When pressed to use the Romanian language in an interview with Motherboard via online chat, \"he used such clunky grammar and terminology that experts believed he was using an online translator.\" Linguistic analysis by Shlomo Engelson Argamon showed that Guccifer 2.0 is most likely \"a Russian pretending to be a Romanian\". WikiLeaks founder Julian Assange said Guccifer 2.0's leaks \"look very much like they\u2019re from the Russians. But in some ways, they look very amateur, and almost look too much like the Russians.\"On June 14, 2016, according to The Washington Post, the DNC acknowledged a hack that was attributed to Russia and claimed by Guccifer 2.0 who released several hacked documents, including one from Podesta's mailbox, the next day.In mid-July 13, 2016, Guccifer 2.0 released over 10,000 names from the DNC in two spreadsheets and a list of objectionable quotes from Sarah Palin. A few days later, Guccifer 2.0 gave The Hill exclusive access to numerous documents and files covering political strategies, including correlating the banks that received bailout funds with Republican Party and Democratic Party donations.On July 22, 2016, the DNC emails were published by WikiLeaks and Guccifer 2.0 tweeted that he was the hacker and WikiLeaks' source.On August 15, 2016, a candidate for Congress allegedly contacted Guccifer 2.0 to request information on the candidate's opponent. Guccifer 2.0 responded with the requested stolen information. A week later, Florida GOP campaign advisor Aaron Nevins contacted Guccifer 2.0 and asked for material. Nevins set up a Dropbox account and Guccifer 2.0 transferred 2.5 gigabytes of data to it. Nevins analyzed the data and posted the results on his blog, HelloFLA.com, and sends Guccifer 2.0 a link. Guccifer 2.0 forwarded the link to Roger Stone.On September 13, 2016, during a conference, a confirmed and remote representative of Guccifer 2.0 released almost 700 megabytes (MB) worth of documents from the DNC, which included personal and work email addresses and phone numbers for top Obama White House officials . According to British journalist Duncan Campbell, the Russian intelligence agency, GRU, tried to implicate Seth Rich as the source of the stolen DNC files in order to draw attention away from themselves. Datestamps on the DNC files released on September 13 were altered to show the data had been obtained on July 5, 2016, five days before Rich's death, and the time zone was changed to Eastern Time, within which Washington, D.C., falls. Based partly on their acceptance of the false dates, some experts then concluded that the emails had been copied in the DNC offices, and had not been hacked from outside.On October 4, 2016, Guccifer 2.0 released documents and claimed that they were taken from the Clinton Foundation and showed \"corruption and malfeasance\" there. Security experts quickly determined that the release was a hoax; the release did not contain Clinton Foundation documents, but rather consisted of documents previously released from the DNC and DCCC thefts, data aggregated from public records, and documents that were fabricated altogether as propaganda. Singled out as particularly unrealistic was the idea that Clinton's team would have actually named a file \"Pay for Play\" on their own server, as Guccifer 2.0's screenshots of the alleged \"hack\" show.\n\n== DCLeaks ==\n\nDCLeaks (also known as DC Leaks) was a website that was established in June 2016. It was responsible for publishing leaks of emails belonging to multiple prominent figures in the United States government and military. Cybersecurity research firms determined the site was a front for the Russian cyber-espionage group Fancy Bear. On July 13, 2018, an indictment was made against 12 Russian GRU military officers; it alleged that DCLeaks was part of a Russian military operation to interfere in the 2016 U.S. presidential election.\nAccording to the DCLeaks site's \"About\" page, their aim was \"to find out and tell you the truth about U.S. decision-making process  [sic] as well as about the key elements of American political life.\" They said they were \"the American hacktivists who respect and appreciate freedom of speech, human rights and government of the people.\"In late June 2016, Guccifer 2.0 gave reporters a password to access emails stolen from Democrats on the DCLeaks website.On July 1, 2016, DCLeaks released the emails of four-star General Philip Breedlove, the former NATO supreme commander in Europe. The emails allegedly show that Breedlove sought to overcome President Barack Obama's reluctance to escalate military tensions with Russia over the Russo-Ukrainian War in 2014.On August 12, 2016, DCLeaks released roughly 300 emails from Republican targets, including the 2016 campaign staff of Arizona Senator John McCain, South Carolina Senator Lindsey Graham, and 2012 presidential candidate and former Minnesota Representative Michele Bachmann. The release included 18 emails from the Illinois Republican Party. On the same day, DCLeaks released information about more than 200 Democratic lawmakers, including their personal cellphone numbers. The numerous crank calls that Hillary Clinton received from this disclosure along with the loss of her campaign's email security caused a very severe disruption of her campaign.On August 15, 2016, DCLeaks released 2,576 files predominately related to George Soros' Open Society Foundation. The leak included the Foundation's internal work plans, strategies, priorities and other worldwide activities by Soros and showed the Foundation's support for Palestinian and pro-BDS causes, including Adalah.On September 15, 2016, DCLeaks contacted WikiLeaks about a submission. The Mueller Report concluded the Podesta Emails were probably staged for transfer to WikiLeaks on September 19, 2016.\n\n== DNC Email Leak ==\n\nThe 2016 Democratic National Committee email leak is a collection of Democratic National Committee (DNC) emails stolen by one or more hackers operating under the pseudonym \"Guccifer 2.0\" who are alleged to be Russian intelligence agency hackers, according to indictments carried out by the Mueller investigation. The DNC emails were published by WikiLeaks on July 22, 2016, just before the 2016 Democratic National Convention. Julian Assange said he had originally meant to release the emails on July 18, but WikiLeaks \"had these hiccups that delayed us, and we were given a little more time.\" It wasn't clear who had given him time, and Assange argued that the recording was faulty.The first batch included 19,252 emails and 8,034 attachments from the DNC, the governing body of the United States' Democratic Party. The leak includes emails from seven key DNC staff members, and date from January 2015 to May 2016. On November 6, 2016, WikiLeaks released a second batch of DNC emails, adding 8,263 emails to its collection.The leaks resulted in allegations of bias against Bernie Sanders' presidential campaign, in apparent contradiction with the DNC leadership's publicly stated neutrality, as several DNC operatives openly derided Sanders' campaign and discussed ways to advance Hillary Clinton's nomination. Later revelations included controversial DNC\u2013Clinton agreements dated before the primary, regarding financial arrangements and control over policy and hiring decisions. The revelations prompted the resignation of DNC chair Debbie Wasserman Schultz before the 2016 Democratic National Convention. The DNC issued a formal apology to Bernie Sanders and his supporters \"for the inexcusable remarks made over email\" that did not reflect the DNC's \"steadfast commitment to neutrality during the nominating process.\" After the convention, DNC CEO Amy Dacey, CFO Brad Marshall, and Communications Director Luis Miranda also resigned in the wake of the controversy.\n\n\n*** Guccifer 2.0 submission to WikiLeaks ***\nA week after Guccifer 2.0 appeared online, WikiLeaks sent the persona a message saying to \"send any new material here for us to review and it will have a much higher impact than what you are doing.\" After not receiving a reply, on July 26, 2016 WikiLeaks sent another message that said \"if you have anything hillary related we want it in the next tweo [sic] days prefable [sic] because the DNC is approaching and she will solidify bernie supporters behind her after.\" Guccifer 2.0 responded \"ok ... i see,\" and WikiLeaks added \"we think trump has only a 25% chance of winning against hillary ... so conflict between bernie and hillary is interesting.\" On July 14, 2016 Guccifer 2.0 sent WikiLeaks an email with an encrypted attachment labeled \"wk dnc link1.txt.gpg.\" According to the indictment, the email explained that \"the encrypted file contained instructions on how to access an online archive of stolen DNC documents.\"Four days later, WikiLeaks responded that it had received \"the 1Gb or so archive\" and would release the files that week. The DNC emails were released several days later.\n\n\n*** Contents ***\nThe emails leaked by Wikileaks revealed information about the DNC's interactions with the media, Hillary Clinton's and Bernie Sanders' campaigns, and financial contributions. It also includes personal information about the donors of the Democratic Party, including credit card and Social Security numbers, which could facilitate identity theft.\n\n\n**** Media ****\nThe emails include DNC staff's \"off-the-record\" correspondence with media personalities, including the reporters at CNN, Politico, The Wall Street Journal, and The Washington Post.\n\n\n**** Bernie Sanders' campaign ****\nIn the emails, DNC staffers derided the Sanders campaign. The Washington Post reported: \"Many of the most damaging emails suggest the committee was actively trying to undermine Bernie Sanders's presidential campaign.\"In a May 2016 email chain, the DNC chief financial officer (CFO) Brad Marshall told the DNC chief executive officer, Amy Dacey, that they should have someone from the media ask Sanders if he is an atheist prior to the West Virginia primary.On May 21, 2016, DNC National Press Secretary Mark Paustenbach sent an email to DNC Spokesman Luis Miranda mentioning a controversy that ensued in December 2015, when the National Data Director of the Sanders campaign and three subordinate staffers accessed the Clinton campaign's voter information on the NGP VAN database. (The party accused Sanders' campaign of impropriety and briefly limited its access to the database. The Sanders campaign filed suit for breach of contract against the DNC, but dropped the suit on April 29, 2016.) Paustenbach suggested that the incident could be used to promote a \"narrative for a story, which is that Bernie never had his act together, that his campaign was a mess.\" The DNC rejected this suggestion. The Washington Post wrote: \"Paustenbach's suggestion, in that way, could be read as a defense of the committee rather than pushing negative information about Sanders. But this is still the committee pushing negative information about one of its candidates.\"\n\n\n**** Debbie Wasserman Schultz's emails ****\nFollowing the Nevada Democratic convention, Debbie Wasserman Schultz wrote about Jeff Weaver, manager of Bernie Sanders' campaign: \"Damn liar. Particularly scummy that he barely acknowledges the violent and threatening behavior that occurred\". In another email, Wasserman Schultz said of Bernie Sanders, \"He isn't going to be president.\" Other emails showed her stating that Sanders doesn't understand the Democratic Party.In May 2016, MSNBC's Mika Brzezinski accused the DNC of bias against the Sanders campaign and called on Wasserman Schultz to step down. Wasserman Schultz was upset at the negative media coverage of her actions, and she emailed the political director of NBC News, Chuck Todd, that such coverage of her \"must stop\". Describing the coverage as the \"LAST straw\", she ordered the DNC's communications director to call MSNBC president Phil Griffin to demand an apology from Brzezinski.\n\n\n**** Financial and donor information ****\nAccording to The New York Times, the cache included \"thousands of emails exchanged by Democratic officials and party fund-raisers, revealing in rarely seen detail the elaborate, ingratiating and often bluntly transactional exchanges necessary to harvest hundreds of millions of dollars from the party's wealthy donor class. The emails capture a world where seating charts are arranged with dollar totals in mind, where a White House celebration of gay pride is a thinly disguised occasion for rewarding wealthy donors and where physical proximity to the president is the most precious of currencies.\" As is common in national politics, large party donors \"were the subject of entire dossiers, as fund-raisers tried to gauge their interests, annoyances and passions.\"In a series of email exchanges in April and May 2016, DNC fundraising staff discussed and compiled a list of people (mainly donors) who might be appointed to federal boards and commissions. OpenSecrets senior fellow Bob Biersack noted that this is a longstanding practice in the United States: \"Big donors have always risen to the top of lists for appointment to plum ambassadorships and other boards and commissions around the federal landscape.\" The White House denied that financial support for the party was connected to board appointments, saying: \"Being a donor does not get you a role in this administration, nor does it preclude you from getting one. We've said this for many years now and there's nothing in the emails that have been released that contradicts that.\"\n\n== Podesta Emails ==\n\nIn March 2016, the personal Gmail account of John Podesta, a former White House chief of staff and chair of Hillary Clinton's 2016 U.S. presidential campaign, was compromised via a spear-phishing attack, and some of his emails, many of which were work-related, were hacked. WikiLeaks published the Podesta Emails in October and November 2016. Analysis of the files and communications between WikiLeaks and DCLeaks has resulted in the Mueller Report and Thomas Rid suggesting that the Russian cyber spying group Fancy Bear used DCLeaks to pass the Podesta Emails to WikiLeaks.Podesta's emails shed light on the inner workings of the Clinton campaign, suggested that CNN commentator Donna Brazile had shared audience questions with the Clinton campaign in advance of town hall meeting and contained excerpts from Hillary Clinton's speeches to Wall Street firms. Proponents of the extensively discredited Pizzagate conspiracy theory falsely claimed the emails contained coded messages which supported their conspiracy theory.\n\n\n*** DCLeaks submission to WikiLeaks ***\nOn September 15, 2016 the DCLeaks Twitter account sent WikiLeaks a DM about a possible submission, saying they had gotten no response on the secured chat. The WikiLeaks account responded \"Hi there\" without further elaboration but did not receive a response. The same day, the Guccifer 2.0 Twitter account sent DCLeaks a DM saying that WikiLeaks was trying to contact them and to arrange to speak through encrypted email. Analysis of the metadata on the Podesta emails show a creation date of September 19, 2016. The Mueller Report concluded that this might have been when the emails were transferred to WikiLeaks.\n\n\n*** Publication ***\nOn October 7, 2016, a few hours after the Obama Administration released a statement by the Department of Homeland Security and the director of National Intelligence accusing the Russian government of interfering in the election through hacking, and 30 minutes after The Washington Post reported on the Access Hollywood videotape, WikiLeaks began publishing thousands of emails from Podesta's Gmail account. The hacked documents effectively distracted media and voter attention from both stories. According to WikiLeaks journalist Stefania Maurizi, the release day had been set several days earlier. Throughout October, WikiLeaks released installments of the Podesta emails on a daily basis.On October 17, 2016, the government of Ecuador severed the internet connection of WikiLeaks founder Julian Assange at the Ecuadorian embassy in London. The Ecuadorian government stated that it had temporarily severed Assange's internet connection because of WikiLeaks' release of documents \"impacting on the U.S. election campaign\", although it also stated this was not meant to prevent WikiLeaks from operating. WikiLeaks continued releasing installments of the Podesta emails during this time.\n\n\n*** Contents ***\nSome of the emails provide some insight into the inner workings of the Clinton campaign. For example, the emails show a discussion among campaign manager Robby Mook and top aides about possible campaign themes and slogans. Other emails revealed insights about the internal conflicts of the Clinton Foundation. Some were emails that Barack Obama and Podesta exchanged in 2008.One of the emails released on October 12, 2016, included Podesta's iCloud account password. His iCloud account was hacked, and his Twitter account was then briefly compromised.\n\n\n**** Clinton's Wall Street speeches ****\nWikiLeaks published transcripts of three Clinton speeches to Goldman Sachs and an 80-page internal campaign document cataloging potentially problematic portions of over 50 paid speeches. Earlier in the campaign, WikiLeaks had offered a reward for copies of the speeches. During the Democratic primary campaign, Bernie Sanders had criticized Hillary Clinton for refusing to release transcripts of speeches given to financial firms, portraying her as too close to Wall Street.In the October 2016 presidential debate, Clinton voiced her support for a \"no-fly\" zone in Syria. In a 2013 speech, Clinton had discussed the difficulties involved. In particular, she noted that in order to establish a no-fly zone, Syria's air defenses would need to be destroyed. Because the Assad government had located these anti-aircraft batteries in populated civilian areas, their destruction would cause many collateral civilian deaths. Clinton's staff additionally flagged comments about regulation of Wall Street, as well as her relationship with the industry, as potentially problematic.The excerpts came up in the two subsequent presidential debates between Clinton and Trump. In one of the debates, the moderator Martha Raddatz quoted an excerpt saying that politicians \"need both a public and a private position\" and asked Clinton if it was okay for politicians to be \"two-faced\". Clinton replied, \"As I recall, that was something I said about Abraham Lincoln after having seen the wonderful Steven Spielberg movie called Lincoln. It was a master class watching president Lincoln get the Congress to approve the 13th amendment, it was principled and strategic. I was making the point that it is hard sometimes to get the Congress to do what you want to do.\" In the third presidential debate, the moderator Chris Wallace quoted a speech excerpt where Clinton says, \"My dream is a hemispheric common market with open trade and open borders,\" and asked if she was for open borders. Clinton replied, \"If you went on to read the rest of the sentence, I was talking about energy. We trade more energy with our neighbors than we trade with the rest of the world combined. And I do want us to have an electric grid, an energy system that crosses borders.\"\n\n\n**** Discussions of Catholic religious activities ****\nSandy Newman wrote to Podesta: \"I have not thought at all about how one would 'plant the seeds of the revolution', or who would plant them.\" Podesta agreed that this was necessary to do as Newman suggested and wrote back to note that they had created groups like Catholics in Alliance for the Common Good and Catholics United to push for a more progressive approach to the faith, change would \"have to be bottom up\".Raymond Arroyo responded: \"It makes it seem like you're creating organizations to change the core beliefs of the church,\" he said. \"For someone to come and say, 'I have a political organization to change your church to complete my political agenda or advance my agenda', I don't know how anybody could embrace that.\" Professor Robert P. George added that \"these groups are political operations constructed to masquerade as organizations devoted to the Catholic faith\".The leak revealed an email sent by John Halpin, a senior fellow at the Center for American Progress. The email discussed conservative media mogul Rupert Murdoch's decision to raise his kids in the Catholic Church. He wrote, \"Many of the most powerful elements of the conservative movement are all Catholic (many converts) ... It's an amazing bastardization of the faith. They must be attracted to the systematic thought and severely backwards gender relations and must be totally unaware of Christian democracy.\" Palmieri responded: \"I imagine they think it is the most socially acceptable, politically conservative religion\u2014their rich friends wouldn't understand if they became evangelical.\" Supporters and members of Donald Trump's campaign called the email exchange evidence of anti-Catholic sentiment in the Democratic Party. Halpin confirmed that he had written the email, though he contested claims that it was \"anti-Catholic\" and said that it was taken out of context and that he had sent the email to his Catholic colleagues \"to make a fleeting point about perceived hypocrisy and the flaunting of one's faith by prominent conservative leaders.\"\n\n\n**** Presidential debate questions shared by Donna Brazile ****\nOn October 11, 2016, WikiLeaks released the text of an email sent by Donna Brazile on March 12, 2016, to Clinton communications director Jennifer Palmieri with the subject header \"From time to time I get questions in advance.\" The email included a question about the death penalty. The following day Clinton received a similar question from the Townhall host, Roland Martin. Brazile initially denied coordinating with the Clinton campaign, and a CNN spokesperson said \"CNN did not share any questions with Donna Brazile, or anyone else for that matter, prior to the town hall\" and that \"we have never, ever given a town hall question to anyone beforehand\". According to CNNMoney, the debate moderator Roland Martin did not deny that he shared questions with Brazile. In another leaked email, Brazile wrote: \"One of the questions directed to HRC tomorrow is from a woman with a rash. Her family has lead poison and she will ask what, if anything, will Hillary do as president to help the ppl of Flint.\" At a debate in Flint the following day, a woman whose \"son had developed a rash from the contaminated water\" asked Clinton: \"If elected president, what course will you take to regain my trust in government?\" In a third email, Brazile added: \"I'll send a few more.\"CNN severed ties with Brazile on October 14, 2016. Brazile later said that CNN did not give her \"the ability to defend myself\" after the email release and referred to WikiLeaks as \"WikiLies\". Brazile repeatedly denied that she had received the question on the death penalty in advance and has said that the documents released by WikiLeaks were \"altered\". In an essay for Time written on March 17, 2017, Brazile wrote that the emails revealed that \"among the many things I did in my role as a Democratic operative and D.N.C. Vice Chair [...] was to share potential town hall topics with the Clinton campaign.\" She wrote, \"My job was to make all our Democratic candidates look good, and I worked closely with both campaigns to make that happen. But sending those emails was a mistake I will forever regret.\"\n\n\n**** Saudi Arabia and Qatar ****\nOne leaked email from August 2014, addressed to Podesta, identifies Saudi Arabia and Qatar as providing \"clandestine\", \"financial and logistic\" aid to ISIS and other \"radical Sunni groups\". The email outlines a plan of action against ISIS, urges putting pressure on Saudi Arabia and Qatar to end their alleged support for the group. Its unclear who originally wrote the email.\n\n== Investigations ==\n\n\n*** Cybersecurity analysis ***\nCybersecurity experts and firms, including CrowdStrike, Fidelis Cybersecurity, Mandiant, SecureWorks, and ThreatConnect, and the editor for Ars Technica, stated the leak was part of a series of cyberattacks on the DNC committed by two Russian intelligence groups. U.S. intelligence agencies also stated with \"high confidence\" that the Russian government was behind the theft of emails and documents from the DNC, according to reports in The New York Times and The Washington Post.WikiLeaks founder Julian Assange initially stuck to WikiLeaks policy of neither confirming or denying sources but in January 2017 said that their \"source is not the Russian government and it is not a state party\", and the Russian government said it had no involvement.Researchers from the Atlanta-based cybersecurity firm Dell SecureWorks reported that the emails had been obtained through a data theft carried out by the hacker group Fancy Bear, a group of Russian intelligence-linked hackers that were also responsible for cyberattacks that targeted the Democratic National Committee (DNC) and Democratic Congressional Campaign Committee (DCCC), resulting in WikiLeaks publishing emails from those hacks.SecureWorks concluded Fancy Bear had sent Podesta an email on March 19, 2016, that had the appearance of a Google security alert, but actually contained a misleading link\u2014a strategy known as spear-phishing. The link\u2014which used the URL shortening service Bitly\u2014brought Podesta to a fake log-in page where he entered his Gmail credentials. The email was initially sent to the IT department as it was suspected of being a fake but was described as \"legitimate\" in an e-mail sent by a department employee, who later said he meant to write \"illegitimate\".SecureWorks had tracked the activities of Fancy Bear for more than a year before the cyberattack, and in June 2016, had reported the group made use of malicious Bitly links and fake Google login pages to trick targets into divulging their passwords. However, the hackers left some of their Bitly accounts public, allowing SecureWorks to trace many of their links to e-mail accounts targeted with spear-phishing attacks. Of this list of targeted accounts, more than one hundred were policy advisors to Clinton, or members of her presidential campaign, and by June, twenty staff members had clicked on the phishing links.\n\n\n*** United States intelligence conclusions ***\n\nOn October 7, 2016, the United States Department of Homeland Security and the Office of the Director of National Intelligence stated that the US intelligence community was \"confident\" that the Russian government directed the breaches and the release of the obtained or allegedly obtained material in an attempt to \"... interfere with the US election process.\"The U.S. Intelligence Community tasked resources debating why Putin chose summer 2016 to escalate active measures influencing U.S. politics. Director of National Intelligence James R. Clapper said after the 2011\u201313 Russian protests, Putin's confidence in his viability as a politician was damaged, and Putin responded with the propaganda operation. Former CIA officer Patrick Skinner explained the goal was to spread uncertainty. Former Director of the Defense Intelligence Agency David Shedd said that \"the release of emails just as the Democratic National Convention is getting underway this week has the hallmarks of a Russian active measures campaign.\"On December 9, 2016, the CIA told U.S. legislators the U.S. Intelligence Community concluded Russia conducted operations during the 2016 U.S. election to assist Donald Trump in winning the presidency. Multiple U.S intelligence agencies concluded people with direct ties to the Kremlin gave WikiLeaks hacked emails from the DNC and additional sources such as John Podesta, campaign chairman for Hillary Clinton. The CIA said the foreign intelligence agents were Russian operatives previously known to the U.S. CIA officials told U.S. Senators it was \"quite clear\" Russia's intentions were to help Trump. Trump released a statement December 9, and disregarded the CIA conclusions.During November 2017, the Associated Press revealed that the FBI had deviated from its policy and failed to notify almost all of the persons in the cross hairs of the Kremlin-backed Fancy Bear's attack of 312 prominent government and defense officials who had their emails posted on DCLeaks.Throughout late 2017 into early 2018, numerous individuals gave testimonies to the House Permanent Select Committee on Intelligence (HPSCI) who were charged with carrying out an investigation into the series of cyberattacks. On January 10, 2017, FBI Director James Comey told the Senate Intelligence Committee that Russia succeeded in \"collecting some information from Republican-affiliated targets but did not leak it to the public\". In March 2017, FBI Director James Comey told the House Intelligence Committee that the Russians \u201cdidn't deal with WikiLeaks directly.\u201d He later told the Senate, \u201cThe Russians interfered with our elections in the 2016 cycle,\u201d he said. \u201cThey did it with purpose. They did it with sophistication, with overwhelming technical efforts, and it was an \u2018active measures\u2019 campaign driven from the top of that government.\u201d The Former Director of National Intelligence James Clapper put the conclusion simply to Raffi Khatchadourian: \u201cIt was done by a cutout, which of course afforded Assange plausible deniability.\u201d\n\n\n*** Steele dossier allegations ***\n\nThe Steele dossier, a controversial and unfinished political opposition research report published in January 2017, included several allegations relating to the hacking and leaking of the emails. The individuals named have denied the allegations. Some allegations have been publicly confirmed. However the intelligence community and most experts have treated the dossier with caution due to its unverified allegations.\n\n\n*** Authenticity ***\nA declassified report by the CIA, FBI, and NSA noted that, \"Moscow most likely chose WikiLeaks because of its self-proclaimed reputation for authenticity. Disclosures through WikiLeaks did not contain any evident forgeries.\"Cybersecurity experts interviewed by PolitiFact believe that while most of the emails are probably unaltered, it is possible the hackers inserted some doctored or fabricated material into the collection. Cybersecurity expert Robert Graham described the contents of some of the emails as authentic by using the DomainKeys Identified Mail (DKIM) contained in these emails' signatures. However, not all of the emails have these keys in their signature, and thus could not be verified with this method.\n\n== Reactions ==\nOn July 18, 2016, Dmitry Peskov, press secretary for Russian president Vladimir Putin, stated that the Russian government had no involvement in the DNC hacking incident. Peskov called it \"paranoid\" and \"absurd\", saying: \"We are again seeing these maniacal attempts to exploit the Russian theme in the US election campaign.\" That position was later reiterated by the Russian Embassy in Washington, DC, which called the allegation \"entirely unrealistic\".\n\n\n*** Reactions to DNC Email Leak ***\nThe leak fueled tensions going into the 2016 Democratic National Convention: although DNC operatives denied accusations of bias, Sanders operatives and multiple media commentators cited the leaks as clear evidence that the DNC had been favoring Clinton and undermining Sanders. Several media commentators have disputed the significance of the emails, arguing that the DNC's internal preference for Clinton was not historically unusual and was unlikely to have swayed the final outcome of the primary; whereas many of Sanders' supporters viewed the revelations as symptomatic of an entrenched, unethical political establishment.On July 24, 2016, Sanders urged Wasserman Schultz to resign following the leak and stated that he was \"disappointed\" by the leak, but that he was \"not shocked.\" Jeff Weaver, Bernie Sanders' campaign manager, called for greater accountability in the DNC, calling Wasserman Schultz \"a figure of disunity\" within the Democratic Party. Later the same day, Wasserman Schultz resigned from her position as DNC Chairman, effective as of the end of the nominating convention. On July 24, 2016, in an interview with NPR, former DNC Chair and current Governor of Virginia Terry McAuliffe said \"... that the chair's job should be \"to remain neutral.\" \"I sat in that chair in 2004 trying to navigate all the different candidates we had. But if you had people in there who were trashing one of the candidates, I can tell you this, if I were still chairman they wouldn't be working there. I mean, that is just totally unacceptable behavior.\"On July 25, 2016, Anthony Zurcher, North America reporter for the BBC, commented that \"the revelation that those in the heart of the Democratic establishment sought to undermine the anti-establishment Sanders is roughly on a par with [Casablanca character] police Capt Renault's professed shock that gambling was taking place in the Casablanca club he was raiding, as a waiter hands him his winnings.\"On July 27, 2016, The New York Times reported that Julian Assange, in an interview on British ITV on June 12, 2016, had \"made it clear that he hoped to harm Hillary Clinton's chances of winning the presidency.\"\n\n\n*** Reactions to Podesta Emails ***\nSociology professor Zeynep Tufekci criticized how WikiLeaks handled the release of these emails, writing, \"Taking one campaign manager's email account and releasing it with zero curation in the last month of an election needs to be treated as what it is: political sabotage, not whistle-blowing.\" In an op-ed for The Intercept, James Risen criticized the media for its reporting on emails, arguing that the hacking of the emails was a more significant story than the content of the emails themselves. Thomas Frank, writing in an editorial column for The Guardian, argued that the emails gave an \"unprecedented view into the workings of the elite, and how it looks after itself\".Glen Caplin, a spokesman for the Clinton campaign, said, \"By dribbling these out every day WikiLeaks is proving they are nothing but a propaganda arm of the Kremlin with a political agenda doing [Vladimir] Putin's dirty work to help elect Donald Trump.\"\n\n\n*** Other reactions ***\nFollowing the publication of the stolen emails, NSA whistleblower Edward Snowden criticized WikiLeaks for its wholesale leakage of data, writing that \"their hostility to even modest curation is a mistake.\" The Washington Post contrasted the difference between WikiLeaks' practices and Snowden's disclosure of information about NSA: while Snowden worked with journalists to vet documents (withholding some where it would endanger national security), WikiLeaks' \"more radical\" approach involves the dumping of \"massive, searchable caches online with few\u2014if any\u2014apparent efforts to remove sensitive personal information.\"\nOn July 25, 2016, Anne Applebaum, columnist for The Washington Post, wrote that:... with the exception of a few people on Twitter and a handful of print journalists, most of those covering this story, especially on television, are not interested in the nature of the hackers, and they are not asking why the Russians apparently chose to pass the emails on to WikiLeaks at this particular moment, on the eve of the Democratic National Convention. They are focusing instead on the content of what were meant to be private emails ...She went on to describe in detail other Russian destabilization campaigns in Eastern European countries.On July 25, 2016, Thomas Rid, Professor in Security Studies at King's College, London, and non-resident fellow at the School for Advanced International Studies, Johns Hopkins University, in Washington, DC, summed up the evidence pointing to Russia being behind the hacking of the DNC files and the \"Guccifer-branded leaking operation\". He concludes that these actions successfully blunted the \"DNC's ability to use its opposition research in surprise against Trump ...\" He further writes that data exfiltration from political organizations is done by many countries and is considered to be a legitimate form of intelligence work. \"But digitally exfiltrating and then publishing possibly manipulated documents disguised as freewheeling hacktivism is crossing a big red line and setting a dangerous precedent: an authoritarian country directly yet covertly trying to sabotage an American election.\"Russian security expert and investigative journalist Andrei Soldatov said \"It is almost impossible to know for sure whether or not Russia is behind a hack of the DNC's servers\". According to him, one of the reasons Russia would try to sway the US presidential election is that the Russian government considers Clinton \"a hater of Russia\": \"There is this mentality in Russia of being besieged; that it is always under attack from the United States ... They are trying to interfere in our internal affairs so why not try to do the same thing to them?\"The American public's interest in WikiLeaks in October roughly coincided with a tightening presidential race between Trump and Clinton. According to an analysis of opinion polling by Harry Enten of FiveThirtyEight, the release of the emails roughly matched Clinton's decline in the polls, though public perceptions of her trustworthiness remained stable in the polls. Enten concluded that WikiLeaks' activities were \"among the factors that might have contributed to [Clinton's] loss.\"\n\n== Civil DNC lawsuit ==\n\nOn April 20, 2018, the Democratic National Committee filed a civil lawsuit in federal court in New York, accusing the Russian government, the Trump campaign, Wikileaks, and others of conspiracy to alter the course of the 2016 presidential election and asking for monetary damages and a declaration admitting guilt. A hearing on the defendants' motions to dismiss was scheduled for May 17, 2018. In July 2019, the suit was dismissed with prejudice. In his judgement, federal judge John Koeltl said that although he believed the Russian government was involved in the hacking, US federal law generally prohibited suits against foreign governments. The judge said the other defendants, \"did not participate in any wrongdoing in obtaining the materials in the first place\" and were therefore within the law in publishing the information. He also said that the DNC's argument was \"entirely divorced from the facts\" and even if the Russians had directly provided the hacked documents to the Trump team, it would not be criminal for the campaign to publish those documents, as long as they did not contribute to the hacking itself. Koeltl denied the defendants motion for sanctions, but dismissed the suit with prejudice, meaning it had a substantive legal defect and could not be refiled."
    }
  },
  {
    "instruction": "Write an answer to the following question: What type of keys are established using private and public ephemeral keys?",
    "context": "",
    "output": "Private and public ephemeral keys are used to establish key wrapping keys, data encryption keys, or MAC keys, and optionally other keying material.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What type of keys are established using private and public ephemeral keys?",
      "answer": "Private and public ephemeral keys are used to establish key wrapping keys, data encryption keys, or MAC keys, and optionally other keying material."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the criticism of the Simon cipher for having too small a security margin?",
    "context": "",
    "output": "The criticism of the Simon cipher for having too small a security margin is that it has too few rounds between the best attacks and the full cipher, making it more likely to be broken by future advances in cryptanalysis.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the criticism of the Simon cipher for having too small a security margin?",
      "answer": "The criticism of the Simon cipher for having too small a security margin is that it has too few rounds between the best attacks and the full cipher, making it more likely to be broken by future advances in cryptanalysis."
    }
  },
  {
    "instruction": "Write an answer to the following question: What was the punishment for MostHateD, a prominent member of globalHell?",
    "context": "",
    "output": "MostHateD was sentenced to 26 months' imprisonment and three years' supervised release.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was the punishment for MostHateD, a prominent member of globalHell?",
      "answer": "MostHateD was sentenced to 26 months' imprisonment and three years' supervised release."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the role of software licensing in enforcing the usage and distribution of computer software?",
    "context": "",
    "output": "Software licensing is a legal instrument used to govern the usage and distribution of computer software, often enforced by implementing a product activation or digital rights management (DRM) mechanism.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of software licensing in enforcing the usage and distribution of computer software?",
      "answer": "Software licensing is a legal instrument used to govern the usage and distribution of computer software, often enforced by implementing a product activation or digital rights management (DRM) mechanism."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does EnCase support incident response in a user-friendly way?",
    "context": "",
    "output": "EnCase Endpoint Investigator, released in 2016, is a more user-friendly web interface for incident response, allowing for a faster response time from an attack or event.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does EnCase support incident response in a user-friendly way?",
      "answer": "EnCase Endpoint Investigator, released in 2016, is a more user-friendly web interface for incident response, allowing for a faster response time from an attack or event."
    }
  },
  {
    "instruction": "Forensic disk controller\n\n==Introduction==\nA forensic disk controller or hardware write-block device is a specialized type of computer hard disk controller made for the purpose of gaining read-only access to computer hard drives without the risk of damaging the drive's contents.  The device is named forensic because its most common application is for use in investigations where a computer hard drive may contain evidence. Such a controller historically has been made in the form of a dongle that fits between a computer and an IDE or SCSI hard drive, but with the advent of USB and SATA, forensic disk controllers supporting these newer technologies have become widespread. Steve Bress and Mark Menz invented hard drive write blocking (US Patent 6,813,682). A device which is installed between a storage media under investigation and an investigator's computer is called a \"bridge kit\".  The bridge kit has one connector for the storage media and another connector the investigator's computer.  It allows the investigator to read, but not alter the device under investigation.The United States National Institute of Justice operates a Computer Forensics Tool Testing (CFTT) program which formally identifies the following top-level tool requirements:\n\nA hardware write block (HWB) device shall not transmit a command to a protected storage device that modifies the data on the storage device.\nAn HWB device shall return the data requested by a read operation.\nAn HWB device shall return without modification any access-significant information requested from the drive.\n\nAny error condition reported by the storage device to the HWB device shall be reported to the host.\n\n== Description ==\nForensic disk controllers intercept write commands from the host operating system, preventing them from reaching the drive. Whenever the host bus architecture supports it the controller reports that the drive is read-only. The disk controller can either deny all writes to the disk and report them as failures, or use on-board memory to cache the writes for the duration of the session.\nA disk controller that caches writes in memory presents the appearance to the operating system that the drive is writable, and uses the memory to ensure that the operating system sees changes to the individual disk sectors it attempted to overwrite.  It does this by retrieving sectors from the disk if the operating system hasn't attempted to change them, and retrieving the changed version from memory for sectors that have been changed.\n\n== Uses ==\nForensic disk controllers are most commonly associated with the process of creating a disk image, or acquisition, during forensic analysis. Their use is to prevent inadvertent modification of evidence.\nUsing hardware to protect the hard drive from writes is very important for several reasons.  First, many operating systems, including Windows, may write to any hard disk that is connected to the system.  At the very least, Windows will update the access time for any file accessed, and may write things to the disk unexpectedly - such as creating hidden folders for the recycle bin or saved hardware configuration.  Virus infections or malware on the system used for analysis may attempt to infect the disk being inspected.  Additionally, the NTFS file system may attempt to commit or rollback unfinished transactions, and/or change flags on the volume to mark it as \"in use\".  At the worst, undesired files may allocate and overwrite deleted space on the hard disk which may potentially destroy evidence in the form of previously deleted files.\nProtecting an evidence drive from writes during investigation is also important to counter potential allegations that the contents of the drive were altered during the investigation. Of course, this can be alleged anyway, but in the absence of technology to protect a drive from writes, there is no way for such an allegation to be refuted.\nQuestion: How can hidden folders be created on a hard disk?",
    "context": "",
    "output": "Answer: Hidden folders can be created on a hard disk by the operating system, such as when the recycle bin or saved hardware configuration is stored.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can hidden folders be created on a hard disk?",
      "answer": "Hidden folders can be created on a hard disk by the operating system, such as when the recycle bin or saved hardware configuration is stored.",
      "context": "Forensic disk controller\n\n==Introduction==\nA forensic disk controller or hardware write-block device is a specialized type of computer hard disk controller made for the purpose of gaining read-only access to computer hard drives without the risk of damaging the drive's contents.  The device is named forensic because its most common application is for use in investigations where a computer hard drive may contain evidence. Such a controller historically has been made in the form of a dongle that fits between a computer and an IDE or SCSI hard drive, but with the advent of USB and SATA, forensic disk controllers supporting these newer technologies have become widespread. Steve Bress and Mark Menz invented hard drive write blocking (US Patent 6,813,682). A device which is installed between a storage media under investigation and an investigator's computer is called a \"bridge kit\".  The bridge kit has one connector for the storage media and another connector the investigator's computer.  It allows the investigator to read, but not alter the device under investigation.The United States National Institute of Justice operates a Computer Forensics Tool Testing (CFTT) program which formally identifies the following top-level tool requirements:\n\nA hardware write block (HWB) device shall not transmit a command to a protected storage device that modifies the data on the storage device.\nAn HWB device shall return the data requested by a read operation.\nAn HWB device shall return without modification any access-significant information requested from the drive.\n\nAny error condition reported by the storage device to the HWB device shall be reported to the host.\n\n== Description ==\nForensic disk controllers intercept write commands from the host operating system, preventing them from reaching the drive. Whenever the host bus architecture supports it the controller reports that the drive is read-only. The disk controller can either deny all writes to the disk and report them as failures, or use on-board memory to cache the writes for the duration of the session.\nA disk controller that caches writes in memory presents the appearance to the operating system that the drive is writable, and uses the memory to ensure that the operating system sees changes to the individual disk sectors it attempted to overwrite.  It does this by retrieving sectors from the disk if the operating system hasn't attempted to change them, and retrieving the changed version from memory for sectors that have been changed.\n\n== Uses ==\nForensic disk controllers are most commonly associated with the process of creating a disk image, or acquisition, during forensic analysis. Their use is to prevent inadvertent modification of evidence.\nUsing hardware to protect the hard drive from writes is very important for several reasons.  First, many operating systems, including Windows, may write to any hard disk that is connected to the system.  At the very least, Windows will update the access time for any file accessed, and may write things to the disk unexpectedly - such as creating hidden folders for the recycle bin or saved hardware configuration.  Virus infections or malware on the system used for analysis may attempt to infect the disk being inspected.  Additionally, the NTFS file system may attempt to commit or rollback unfinished transactions, and/or change flags on the volume to mark it as \"in use\".  At the worst, undesired files may allocate and overwrite deleted space on the hard disk which may potentially destroy evidence in the form of previously deleted files.\nProtecting an evidence drive from writes during investigation is also important to counter potential allegations that the contents of the drive were altered during the investigation. Of course, this can be alleged anyway, but in the absence of technology to protect a drive from writes, there is no way for such an allegation to be refuted."
    }
  },
  {
    "instruction": "Context: Bogofilter\n\n==Introduction==\nBogofilter is a mail filter that classifies e-mail as spam or ham (non-spam) by a statistical analysis of the message's header and content (body). The program is able to learn from the user's classifications and corrections. It was originally written by Eric S. Raymond after he read Paul Graham's article \"A Plan for Spam\" and is now maintained together with a group of contributors by David Relson, Matthias Andree and Greg Louis.\nThe statistical technique used is known as Bayesian filtering. Bogofilter's primary algorithm uses the f(w) parameter and the Fisher inverse chi-square technique that he describes.\nBogofilter may be run by a MDA or mail client to classify messages as they are delivered to recipient mailboxes, or be used by a MTA to classify messages as they are received from the sending SMTP server.  Bogofilter examines tokens in the message body and header, and refers to wordlists stored by BerkeleyDB, SQLite or QDBM to calculate a probability score that a new message is spam. Bogofilter provides processing for plain text and HTML and supports reading multi-part MIME message including base64, quoted-printable, and uuencoded text or HTML.  Bogofilter ignores non-text attachments, such as images.\nIt is possible to tune Bogofilter's statistical algorithms by modifying various coefficients and other settings in its configuration file, or by using the automated bogotune utility included with the software, which attempts to optimise various coefficients to maximise filtering efficiency for a particular corpus of spam and non-spam.\nStandard tests at TREC 2005 show that Bogofilter compares well to its competitors spambayes, CRM114 and DSPAM. Other competitors include, but are not limited to Spamprobe  and QSF. \nBogofilter is written in C, and runs on Linux, FreeBSD, NetBSD, OpenBSD, Solaris, Mac OS X, HP-UX, AIX and other platforms. It is released under the GNU GPL.\n\n\n\n== Email clients that can use Bogofilter ==\nThe following email clients are known to support Bogofilter as a spam filtering backend:\n\nGNOME Evolution\nClaws Mail\nKMail\nMutt (email client)\nAlpine (email client)\n\nQuestion: Where did the idea of Bogofilter come from?\n\nAnswer:",
    "context": "",
    "output": "The idea of Bogofilter came from Eric S. Raymond reading Paul Graham's article \"A Plan for Spam\".",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Where did the idea of Bogofilter come from?",
      "answer": "The idea of Bogofilter came from Eric S. Raymond reading Paul Graham's article \"A Plan for Spam\".",
      "context": "Bogofilter\n\n==Introduction==\nBogofilter is a mail filter that classifies e-mail as spam or ham (non-spam) by a statistical analysis of the message's header and content (body). The program is able to learn from the user's classifications and corrections. It was originally written by Eric S. Raymond after he read Paul Graham's article \"A Plan for Spam\" and is now maintained together with a group of contributors by David Relson, Matthias Andree and Greg Louis.\nThe statistical technique used is known as Bayesian filtering. Bogofilter's primary algorithm uses the f(w) parameter and the Fisher inverse chi-square technique that he describes.\nBogofilter may be run by a MDA or mail client to classify messages as they are delivered to recipient mailboxes, or be used by a MTA to classify messages as they are received from the sending SMTP server.  Bogofilter examines tokens in the message body and header, and refers to wordlists stored by BerkeleyDB, SQLite or QDBM to calculate a probability score that a new message is spam. Bogofilter provides processing for plain text and HTML and supports reading multi-part MIME message including base64, quoted-printable, and uuencoded text or HTML.  Bogofilter ignores non-text attachments, such as images.\nIt is possible to tune Bogofilter's statistical algorithms by modifying various coefficients and other settings in its configuration file, or by using the automated bogotune utility included with the software, which attempts to optimise various coefficients to maximise filtering efficiency for a particular corpus of spam and non-spam.\nStandard tests at TREC 2005 show that Bogofilter compares well to its competitors spambayes, CRM114 and DSPAM. Other competitors include, but are not limited to Spamprobe  and QSF. \nBogofilter is written in C, and runs on Linux, FreeBSD, NetBSD, OpenBSD, Solaris, Mac OS X, HP-UX, AIX and other platforms. It is released under the GNU GPL.\n\n\n\n== Email clients that can use Bogofilter ==\nThe following email clients are known to support Bogofilter as a spam filtering backend:\n\nGNOME Evolution\nClaws Mail\nKMail\nMutt (email client)\nAlpine (email client)"
    }
  },
  {
    "instruction": "Write an answer to the following question: What patents does Keeper hold through the United States Patent & Trademark Office?",
    "context": "",
    "output": "Keeper holds multiple patents through the United States Patent & Trademark Office, including methods for securely sharing information.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What patents does Keeper hold through the United States Patent & Trademark Office?",
      "answer": "Keeper holds multiple patents through the United States Patent & Trademark Office, including methods for securely sharing information."
    }
  },
  {
    "instruction": "Write an answer to the following question: What was the impact of the 2008 Agent.BTZ worm attack on the US military?",
    "context": "",
    "output": "The 2008 Agent.BTZ worm attack on the US military resulted in the infection of 300,000 computers.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was the impact of the 2008 Agent.BTZ worm attack on the US military?",
      "answer": "The 2008 Agent.BTZ worm attack on the US military resulted in the infection of 300,000 computers."
    }
  },
  {
    "instruction": "Write an answer to the following question: How did Johannes Trithemius contribute to the field of cryptography and steganography?",
    "context": "",
    "output": "Johannes Trithemius is considered the founder of modern cryptography and steganography. He wrote extensively on these subjects, including his most famous work, Steganographia, which was placed on the Index Librorum Prohibitorum in 1609 and removed in 1900.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How did Johannes Trithemius contribute to the field of cryptography and steganography?",
      "answer": "Johannes Trithemius is considered the founder of modern cryptography and steganography. He wrote extensively on these subjects, including his most famous work, Steganographia, which was placed on the Index Librorum Prohibitorum in 1609 and removed in 1900."
    }
  },
  {
    "instruction": "Rubber-hose cryptanalysis\n\n==Introduction==\nIn cryptography, rubber-hose cryptanalysis is a euphemism for the extraction of cryptographic secrets (e.g. the password to an encrypted file) from a person by coercion or torture\u2014such as beating that person with a rubber hose, hence the name\u2014in contrast to a mathematical or technical cryptanalytic attack.\n\n\n\n== Details ==\nAccording to Amnesty International and the UN, many countries in the world routinely torture people. It is therefore logical to assume that at least some of those countries use (or would be willing to use) some form of rubber-hose cryptanalysis.  In practice, psychological coercion can prove as effective as physical torture. Not physically violent but highly intimidating methods include such tactics as the threat of harsh legal penalties. The incentive to cooperate may be some form of plea bargain, such as an offer to drop or reduce criminal charges against a suspect in return for full co-operation with investigators. Alternatively, in some countries threats may be made to prosecute as co-conspirators (or inflict violence upon) close relatives (e.g. spouse, children, or parents) of the person being questioned unless they co-operate.In some contexts, rubber-hose cryptanalysis may not be a viable attack because of a need to decrypt data covertly; information such as a password may lose its value if it is known to have been compromised.  It has been argued that one of the purposes of strong cryptography is to force adversaries to resort to less covert attacks.The earliest known use of the term was on the sci.crypt newsgroup, in a message posted 16 October 1990 by Marcus J. Ranum, alluding to corporal punishment:\n\n...the rubber-hose technique of cryptanalysis. (in which a rubber hose is applied forcefully and frequently to the soles of the feet until the key to the cryptosystem is discovered, a process that can take a surprisingly short time and is quite computationally inexpensive).\nAlthough the term is used tongue-in-cheek, its implications are serious: in modern cryptosystems, the weakest link is often the human user. A direct attack on a cipher algorithm, or the cryptographic protocols used, is likely to be much more expensive and difficult than targeting the people who use or manage the system. Thus, many cryptosystems and security systems are designed with special emphasis on keeping human vulnerability to a minimum. For example, in public-key cryptography, the defender may hold the key to encrypt the message, but not the decryption key needed to decipher it. The problem here is that the defender may be unable to convince the attacker to stop coercion. In plausibly deniable encryption, a second key is created which unlocks a second convincing but relatively harmless message (for example, apparently personal writings expressing \"deviant\" thoughts or desires of some type that are lawful but taboo), so the defender can prove to have handed over the keys whilst the attacker remains unaware of the primary hidden message. In this case, the designer's expectation is that the attacker will not realize this, and forego threats or actual torture. The risk, however, is that the attacker may be aware of deniable encryption and will assume the defender knows more than one key, meaning the attacker may refuse to stop coercing the defender even if one or more keys are revealed: on the assumption the defender is still withholding additional keys which hold additional information.\n\n== In law ==\nIn some jurisdictions, statutes assume the opposite\u2014that human operators know (or have access to) such things as session keys, an assumption which parallels that made by rubber-hose practitioners. An example is the United Kingdom's Regulation of Investigatory Powers Act, which makes it a crime not to surrender encryption keys on demand from a government official authorized by the act.\nAccording to the Home Office, the burden of proof that an accused person is in possession of a key rests on the prosecution; moreover, the act contains a defense for operators who have lost or forgotten a key, and they are not liable if they are judged to have done what they can to recover a key.\n\n== Possible case ==\nIn the lead-up to the 2017 Kenyan general election, the head of information, communication, and technology at the Independent Electoral and Boundaries Commission, Christopher Msando, was murdered. He had played a major role in developing the new voting system for the election. His body showed apparent marks of torture, and there were concerns that the murderers had tried to get password information out of him.\n\n== In popular culture ==\nA well-known xkcd comic (xkcd 538: Security) describes the issue.  In the first panel a crypto nerd imagines that due to his advanced encryption (4096-bit RSA), the crackers will be ultimately defeated, despite having access to million-dollar hardware. In the second panel, the people with the desire to access this information use a five-dollar wrench and torture to coerce the nerd to give them the password.\n\nWhy might rubber-hose cryptanalysis not be a viable attack in certain contexts?",
    "context": "",
    "output": "Rubber-hose cryptanalysis may not be a viable attack in certain contexts because the value of the information being sought, such as a password, may be lost if it is known to have been compromised. Additionally, there may be a need to decrypt data covertly, which would not be possible with this type of attack.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Why might rubber-hose cryptanalysis not be a viable attack in certain contexts?",
      "answer": "Rubber-hose cryptanalysis may not be a viable attack in certain contexts because the value of the information being sought, such as a password, may be lost if it is known to have been compromised. Additionally, there may be a need to decrypt data covertly, which would not be possible with this type of attack.",
      "context": "Rubber-hose cryptanalysis\n\n==Introduction==\nIn cryptography, rubber-hose cryptanalysis is a euphemism for the extraction of cryptographic secrets (e.g. the password to an encrypted file) from a person by coercion or torture\u2014such as beating that person with a rubber hose, hence the name\u2014in contrast to a mathematical or technical cryptanalytic attack.\n\n\n\n== Details ==\nAccording to Amnesty International and the UN, many countries in the world routinely torture people. It is therefore logical to assume that at least some of those countries use (or would be willing to use) some form of rubber-hose cryptanalysis.  In practice, psychological coercion can prove as effective as physical torture. Not physically violent but highly intimidating methods include such tactics as the threat of harsh legal penalties. The incentive to cooperate may be some form of plea bargain, such as an offer to drop or reduce criminal charges against a suspect in return for full co-operation with investigators. Alternatively, in some countries threats may be made to prosecute as co-conspirators (or inflict violence upon) close relatives (e.g. spouse, children, or parents) of the person being questioned unless they co-operate.In some contexts, rubber-hose cryptanalysis may not be a viable attack because of a need to decrypt data covertly; information such as a password may lose its value if it is known to have been compromised.  It has been argued that one of the purposes of strong cryptography is to force adversaries to resort to less covert attacks.The earliest known use of the term was on the sci.crypt newsgroup, in a message posted 16 October 1990 by Marcus J. Ranum, alluding to corporal punishment:\n\n...the rubber-hose technique of cryptanalysis. (in which a rubber hose is applied forcefully and frequently to the soles of the feet until the key to the cryptosystem is discovered, a process that can take a surprisingly short time and is quite computationally inexpensive).\nAlthough the term is used tongue-in-cheek, its implications are serious: in modern cryptosystems, the weakest link is often the human user. A direct attack on a cipher algorithm, or the cryptographic protocols used, is likely to be much more expensive and difficult than targeting the people who use or manage the system. Thus, many cryptosystems and security systems are designed with special emphasis on keeping human vulnerability to a minimum. For example, in public-key cryptography, the defender may hold the key to encrypt the message, but not the decryption key needed to decipher it. The problem here is that the defender may be unable to convince the attacker to stop coercion. In plausibly deniable encryption, a second key is created which unlocks a second convincing but relatively harmless message (for example, apparently personal writings expressing \"deviant\" thoughts or desires of some type that are lawful but taboo), so the defender can prove to have handed over the keys whilst the attacker remains unaware of the primary hidden message. In this case, the designer's expectation is that the attacker will not realize this, and forego threats or actual torture. The risk, however, is that the attacker may be aware of deniable encryption and will assume the defender knows more than one key, meaning the attacker may refuse to stop coercing the defender even if one or more keys are revealed: on the assumption the defender is still withholding additional keys which hold additional information.\n\n== In law ==\nIn some jurisdictions, statutes assume the opposite\u2014that human operators know (or have access to) such things as session keys, an assumption which parallels that made by rubber-hose practitioners. An example is the United Kingdom's Regulation of Investigatory Powers Act, which makes it a crime not to surrender encryption keys on demand from a government official authorized by the act.\nAccording to the Home Office, the burden of proof that an accused person is in possession of a key rests on the prosecution; moreover, the act contains a defense for operators who have lost or forgotten a key, and they are not liable if they are judged to have done what they can to recover a key.\n\n== Possible case ==\nIn the lead-up to the 2017 Kenyan general election, the head of information, communication, and technology at the Independent Electoral and Boundaries Commission, Christopher Msando, was murdered. He had played a major role in developing the new voting system for the election. His body showed apparent marks of torture, and there were concerns that the murderers had tried to get password information out of him.\n\n== In popular culture ==\nA well-known xkcd comic (xkcd 538: Security) describes the issue.  In the first panel a crypto nerd imagines that due to his advanced encryption (4096-bit RSA), the crackers will be ultimately defeated, despite having access to million-dollar hardware. In the second panel, the people with the desire to access this information use a five-dollar wrench and torture to coerce the nerd to give them the password."
    }
  },
  {
    "instruction": "Schmitt Analysis\n\n==Introduction==\nSchmitt analysis is a legal framework developed in 1999 by Michael N. Schmitt, leading author of the Tallinn Manual, for deciding if a state's involvement in a cyber-attack constitutes a use of force. Such a framework is important as part of international law's adaptation process to the growing threat of cyber-warfare. The characteristics of a cyber-attack can determine which legal regime will govern state behavior, and the Schmitt analysis is one of the most commonly used ways of analyzing those characteristics. It can also be used as a basis for training professionals in the legal field to deal with cyberwarfare.\n\n\n\n== Motivations ==\nAs society becomes more dependent on computers for critical infrastructure, countries have become increasingly concerned with threats in cyberspace. The prevalence of computers and the pace of technological innovation has advanced civilization significantly but has left many vulnerabilities that can be exploited. Countries must be prepared to defend themselves and know how to respond accordingly to computer network attacks (CNAs). These unique attacks are different in many ways to the physical uses of force that happen in traditional warfare. Attackers can now remotely disable their targets simply through the transmission of data. CNAs also have a broad definition, and not every CNA enacted by one State upon another is sufficient reason for States to escalate into armed engagement.\nDepending on if the CNA is treated as a use of force or not, the offending party would be judged based on either IHL or IHRL. And the jus ad bellum is the body of law that defines when it is reasonable for sovereign states to resort to use of force to defend their resources, people and interests. Article 51 of the UN Charter defines a situation where a sovereign state might employ use of force, and it states that:\n\n\"Nothing in the present Charter shall impair the inherent right of individual or collective self-defense if an armed attack occurs against a Member of the United Nations, until the Security Council has taken measures necessary to maintain international peace and security. Measures taken by Members in the exercise of this right of self-defense shall be immediately reported to the Security Council and shall not in any way affect the authority and responsibility of the Security Council under the present Charter to take at any time such action as it deems necessary in order to maintain or restore international peace and security.\"\n\nA State has the autonomy to act in self-defense, but it needs proof that there is an imminent threat. It also needs to act according to the criteria of proportionality and necessity. The Schmitt analysis is a framework for evaluating a CNA, according to seven parameters, to determine if it constitutes a wrongful use of force, and for governments to decide on a valid course of action after being attacked.\n\n\n*** Historical background ***\nThe Estonian Cyber-attacks of 2007, targeting Estonia's Internet resources, appear to be the first cyber attacks to be used as a weapon in a political conflict. In Estonia there was tension between the citizens that wanted their country to be more independent and the Russian-Estonians. Because the attacks came from Russian addresses, the Russian government was accused of endorsing the attacks. The UN Security Council did not react to the Estonian cyber-attacks. Afterwards, the threat of cyber-war between States seemed much more real and imminent. This event also highlighted the importance of international cooperation for the protection of cyberspace. It also brings to light the necessity for international legislation regarding what qualifies as appropriate government response to CNAs.During the 2008 conflict between Georgian nationalists and South Ossetian separatists, many Georgian websites were subject to defacement and DDoS attacks. During this conflict a website named StopGeorgia.ru was put up and in it were links to potential targets for attacks, along with malicious software. Russian civilians could participate in the cyber-attacks, and there is the question of if this direct participation implies that they should not be considered civilians anymore.\nIn 2010 the Stuxnet worm that infected Natanz uranium enrichment facilities in Iran and is suspected to have destroyed up to a 1000 centrifuges was discovered, setting back Iran's nuclear program by several years. The Russian company Kaspersky said the virus could only have been deployed with nation-state support, and that it would lead to the creation of a new kind of arms race in the world. Considering the damage caused, along with the invasiveness, lack of clear legitimacy and the speculation that the worm was developed and deployed with help of U.S. government with possible Israeli or German assistance means Stuxnet could seen as a use of force. Though it might not be seen as an unlawful use of force since the Iran nuclear activities targeted were illegal. For this reason the virus has been called a cyber-weapon, although the Iranian government did not claim it had been victim of a cyber-attack. The Iranian government's inaction might have implications for the development of legal norms regarding cyberspace, and a state's inaction is not addressed by the Schmitt framework.\n\n== CNA as a use of force ==\nSchmitt's analysis is strongly tied to Article 2(4) of the UN Charter, which states that:\n\n\"All Members shall refrain in their international relations from the threat or use of force against the territorial integrity or political independence of any state, or in any other manner inconsistent with the Purposes of the United Nations.\"\n\nNot every use of force falls within the scope of Article 2(4), only those that may threaten international peace. And the article does not specify armed force, and there is the question of if it can be read as any kind of force, even economic force such as through violative economic coercion. The idea is that any use of force not authorized within the Charter is wrongful. In practice though, it is necessary to have a degree of flexibility. There are situations, such as those of decolonization and humanitarian intervention, that a strict following of this rule might not aligned with community interests. And the law regarding use of force needs to adapt and evolve to new situations and circumstances, such as those of cyber-warfare. It would be difficult to classify every CNA as a use of force, considering for example that some might not even cause any direct physical damage. To make use of the established law that has dealt with armed forces, Schmitt proposed comparing the characteristics and consequences of CNAs. This goal of this case-by-case approach is to properly classify with CNAs fall into the category of use of force and which do not.\n\n\n*** The nuclear warfare analogy ***\nComputer network attacks are, like weapons of mass destructions, asymmetric in nature. Since infrastructure such as power grids, transportation, and telecommunications are interlinked, an attack on one site might have a catastrophic domino effect. The destructive capabilities of cyber-attacks have been compared to the effects of nuclear radiation and the EMP effect of nuclear blasts. Small countries wanting to have an impact can take advantage of how cheap it is to launch a CNA. Nuclear weapons have also not been outlawed, but along other weapons of warfare, there is a need to be very careful about using or threatening to use these weapons and follow rules of proportionality, necessity, and humanity. Both nuclear weapons and information weapons do not distinguish between civilians and non-civilians.\n\n== Analysis criteria ==\nSeven criteria are used to evaluate the computer network attack. The analysis focuses predominantly on criteria that are dependent on the consequences of the CNA (and as such a cyber attack is considered a cyber attack only when there is injury, death and to objects and their functionality), and so it is more useful for analyzing events after they have happened and not as they are being planned. This utilitarian focus is also predominant in the jus in bello, which strives for humanity while still allowing for in some cases a trade-off between military gains and civilian casualties, for example. The Schmitt analysis is also subjective, and depends heavily on context. It does not try to set measurements for where the boundaries where CNAs become uses of force, but instead tries to compare the characteristics of a particular CNA and characteristics of traditional uses of force.\nSeverity: This is the level of destruction caused by the attack. The scope, duration and intensity of the attack are taken into consideration. Defacing a public figure's website might be considered not a use of force, while disabling an online banking system or shutting off a nuclear plant's safety mechanisms might be.\nImmediacy: The speed of which the harm is done, where a more immediate attack leaves less room for dialogue and negotiation between the attacker and the target. For a State to act in self-defense, it should have irrefutable proof that the threat to the nation is immediate.\nDirectness: A CNA might have unexpected consequences, and it can be difficult to predict the complete impact of a cyber-attack. This is how clear it is that the consequences are in fact consequences of the CNA and not of other events.\nInvasiveness: CNAs are normally less invasive than a movement of troops into a State's territory. If a cyber-attack affects the sovereignty of a state, then it is more likely to be considered a use of force.\nMeasurability: This is how clear the exact consequences of the CNA are in terms of how much damage has been done. In armed coercion, the consequences tend to be very clear.\nPresumptive legitimacy: A State might employ a CNA as a method of defensive counter-attack. Self-defense is one of the exceptions to the prohibition of the application of violence. A state might also employ CNAs in a way that does not resemble armed coercion.\nResponsibility: The USDOD argues that if an attack from State A to State B is not sponsored by State A, then State B does not have the right to invade State A's nation, and should instead ask for it to intervene and stop the attack. But since attackers can route their data through remote locations, it may be difficult to attribute with certainty a CNA to the accused State, such as happened in Estonia in 2007.A relevant factor when performing a Schmitt Analysis is to ask if the perpetrators of the attack attempted to act in accordance to the Law of Armed Conflict (LOAC). This might be the case of Stuxnet, which was designed to minimize collateral damage, and only spread beyond its intended target accidentally. This attempted can imply state involvement in the attack, since private individuals might not be so concerned with international law. And it also means that the attack is more likely to be characterized as a use of force, even if they do not cause actual damage.\n\n== Potential shortcomings ==\nThe main issue with using the Schmitt framework is that it requires attribution, the attacking nation must be held responsible for the attack. This does not seem to happen in most cases, as states carry their actions within cyberspace in a secretive fashion and do not claim responsibility. There is also the possibility that the state that has been attacked will not take action against the offenders, and will not accuse another state of unlawful action. Some also criticize the framework's adherence to Article 2(4)'s instrument-based paradigm and restrictive definition of unlawful use of force, and favor a more consequence-based framework.\nQ: How can the characteristics and consequences of computer network attacks (CNAs) be compared to those of armed forces?",
    "context": "",
    "output": "Schmitt proposed comparing the characteristics and consequences of CNAs to those of armed forces as a case-by-case approach to properly classify which CNAs fall into the category of use of force and which do not.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can the characteristics and consequences of computer network attacks (CNAs) be compared to those of armed forces?",
      "answer": "Schmitt proposed comparing the characteristics and consequences of CNAs to those of armed forces as a case-by-case approach to properly classify which CNAs fall into the category of use of force and which do not.",
      "context": "Schmitt Analysis\n\n==Introduction==\nSchmitt analysis is a legal framework developed in 1999 by Michael N. Schmitt, leading author of the Tallinn Manual, for deciding if a state's involvement in a cyber-attack constitutes a use of force. Such a framework is important as part of international law's adaptation process to the growing threat of cyber-warfare. The characteristics of a cyber-attack can determine which legal regime will govern state behavior, and the Schmitt analysis is one of the most commonly used ways of analyzing those characteristics. It can also be used as a basis for training professionals in the legal field to deal with cyberwarfare.\n\n\n\n== Motivations ==\nAs society becomes more dependent on computers for critical infrastructure, countries have become increasingly concerned with threats in cyberspace. The prevalence of computers and the pace of technological innovation has advanced civilization significantly but has left many vulnerabilities that can be exploited. Countries must be prepared to defend themselves and know how to respond accordingly to computer network attacks (CNAs). These unique attacks are different in many ways to the physical uses of force that happen in traditional warfare. Attackers can now remotely disable their targets simply through the transmission of data. CNAs also have a broad definition, and not every CNA enacted by one State upon another is sufficient reason for States to escalate into armed engagement.\nDepending on if the CNA is treated as a use of force or not, the offending party would be judged based on either IHL or IHRL. And the jus ad bellum is the body of law that defines when it is reasonable for sovereign states to resort to use of force to defend their resources, people and interests. Article 51 of the UN Charter defines a situation where a sovereign state might employ use of force, and it states that:\n\n\"Nothing in the present Charter shall impair the inherent right of individual or collective self-defense if an armed attack occurs against a Member of the United Nations, until the Security Council has taken measures necessary to maintain international peace and security. Measures taken by Members in the exercise of this right of self-defense shall be immediately reported to the Security Council and shall not in any way affect the authority and responsibility of the Security Council under the present Charter to take at any time such action as it deems necessary in order to maintain or restore international peace and security.\"\n\nA State has the autonomy to act in self-defense, but it needs proof that there is an imminent threat. It also needs to act according to the criteria of proportionality and necessity. The Schmitt analysis is a framework for evaluating a CNA, according to seven parameters, to determine if it constitutes a wrongful use of force, and for governments to decide on a valid course of action after being attacked.\n\n\n*** Historical background ***\nThe Estonian Cyber-attacks of 2007, targeting Estonia's Internet resources, appear to be the first cyber attacks to be used as a weapon in a political conflict. In Estonia there was tension between the citizens that wanted their country to be more independent and the Russian-Estonians. Because the attacks came from Russian addresses, the Russian government was accused of endorsing the attacks. The UN Security Council did not react to the Estonian cyber-attacks. Afterwards, the threat of cyber-war between States seemed much more real and imminent. This event also highlighted the importance of international cooperation for the protection of cyberspace. It also brings to light the necessity for international legislation regarding what qualifies as appropriate government response to CNAs.During the 2008 conflict between Georgian nationalists and South Ossetian separatists, many Georgian websites were subject to defacement and DDoS attacks. During this conflict a website named StopGeorgia.ru was put up and in it were links to potential targets for attacks, along with malicious software. Russian civilians could participate in the cyber-attacks, and there is the question of if this direct participation implies that they should not be considered civilians anymore.\nIn 2010 the Stuxnet worm that infected Natanz uranium enrichment facilities in Iran and is suspected to have destroyed up to a 1000 centrifuges was discovered, setting back Iran's nuclear program by several years. The Russian company Kaspersky said the virus could only have been deployed with nation-state support, and that it would lead to the creation of a new kind of arms race in the world. Considering the damage caused, along with the invasiveness, lack of clear legitimacy and the speculation that the worm was developed and deployed with help of U.S. government with possible Israeli or German assistance means Stuxnet could seen as a use of force. Though it might not be seen as an unlawful use of force since the Iran nuclear activities targeted were illegal. For this reason the virus has been called a cyber-weapon, although the Iranian government did not claim it had been victim of a cyber-attack. The Iranian government's inaction might have implications for the development of legal norms regarding cyberspace, and a state's inaction is not addressed by the Schmitt framework.\n\n== CNA as a use of force ==\nSchmitt's analysis is strongly tied to Article 2(4) of the UN Charter, which states that:\n\n\"All Members shall refrain in their international relations from the threat or use of force against the territorial integrity or political independence of any state, or in any other manner inconsistent with the Purposes of the United Nations.\"\n\nNot every use of force falls within the scope of Article 2(4), only those that may threaten international peace. And the article does not specify armed force, and there is the question of if it can be read as any kind of force, even economic force such as through violative economic coercion. The idea is that any use of force not authorized within the Charter is wrongful. In practice though, it is necessary to have a degree of flexibility. There are situations, such as those of decolonization and humanitarian intervention, that a strict following of this rule might not aligned with community interests. And the law regarding use of force needs to adapt and evolve to new situations and circumstances, such as those of cyber-warfare. It would be difficult to classify every CNA as a use of force, considering for example that some might not even cause any direct physical damage. To make use of the established law that has dealt with armed forces, Schmitt proposed comparing the characteristics and consequences of CNAs. This goal of this case-by-case approach is to properly classify with CNAs fall into the category of use of force and which do not.\n\n\n*** The nuclear warfare analogy ***\nComputer network attacks are, like weapons of mass destructions, asymmetric in nature. Since infrastructure such as power grids, transportation, and telecommunications are interlinked, an attack on one site might have a catastrophic domino effect. The destructive capabilities of cyber-attacks have been compared to the effects of nuclear radiation and the EMP effect of nuclear blasts. Small countries wanting to have an impact can take advantage of how cheap it is to launch a CNA. Nuclear weapons have also not been outlawed, but along other weapons of warfare, there is a need to be very careful about using or threatening to use these weapons and follow rules of proportionality, necessity, and humanity. Both nuclear weapons and information weapons do not distinguish between civilians and non-civilians.\n\n== Analysis criteria ==\nSeven criteria are used to evaluate the computer network attack. The analysis focuses predominantly on criteria that are dependent on the consequences of the CNA (and as such a cyber attack is considered a cyber attack only when there is injury, death and to objects and their functionality), and so it is more useful for analyzing events after they have happened and not as they are being planned. This utilitarian focus is also predominant in the jus in bello, which strives for humanity while still allowing for in some cases a trade-off between military gains and civilian casualties, for example. The Schmitt analysis is also subjective, and depends heavily on context. It does not try to set measurements for where the boundaries where CNAs become uses of force, but instead tries to compare the characteristics of a particular CNA and characteristics of traditional uses of force.\nSeverity: This is the level of destruction caused by the attack. The scope, duration and intensity of the attack are taken into consideration. Defacing a public figure's website might be considered not a use of force, while disabling an online banking system or shutting off a nuclear plant's safety mechanisms might be.\nImmediacy: The speed of which the harm is done, where a more immediate attack leaves less room for dialogue and negotiation between the attacker and the target. For a State to act in self-defense, it should have irrefutable proof that the threat to the nation is immediate.\nDirectness: A CNA might have unexpected consequences, and it can be difficult to predict the complete impact of a cyber-attack. This is how clear it is that the consequences are in fact consequences of the CNA and not of other events.\nInvasiveness: CNAs are normally less invasive than a movement of troops into a State's territory. If a cyber-attack affects the sovereignty of a state, then it is more likely to be considered a use of force.\nMeasurability: This is how clear the exact consequences of the CNA are in terms of how much damage has been done. In armed coercion, the consequences tend to be very clear.\nPresumptive legitimacy: A State might employ a CNA as a method of defensive counter-attack. Self-defense is one of the exceptions to the prohibition of the application of violence. A state might also employ CNAs in a way that does not resemble armed coercion.\nResponsibility: The USDOD argues that if an attack from State A to State B is not sponsored by State A, then State B does not have the right to invade State A's nation, and should instead ask for it to intervene and stop the attack. But since attackers can route their data through remote locations, it may be difficult to attribute with certainty a CNA to the accused State, such as happened in Estonia in 2007.A relevant factor when performing a Schmitt Analysis is to ask if the perpetrators of the attack attempted to act in accordance to the Law of Armed Conflict (LOAC). This might be the case of Stuxnet, which was designed to minimize collateral damage, and only spread beyond its intended target accidentally. This attempted can imply state involvement in the attack, since private individuals might not be so concerned with international law. And it also means that the attack is more likely to be characterized as a use of force, even if they do not cause actual damage.\n\n== Potential shortcomings ==\nThe main issue with using the Schmitt framework is that it requires attribution, the attacking nation must be held responsible for the attack. This does not seem to happen in most cases, as states carry their actions within cyberspace in a secretive fashion and do not claim responsibility. There is also the possibility that the state that has been attacked will not take action against the offenders, and will not accuse another state of unlawful action. Some also criticize the framework's adherence to Article 2(4)'s instrument-based paradigm and restrictive definition of unlawful use of force, and favor a more consequence-based framework."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the javax.security.auth.Refreshable interface impact the handling of credentials in JAAS?",
    "context": "",
    "output": "The javax.security.auth.Refreshable interface is useful for handling credentials in JAAS when a credential has a limited timespan in which it is valid.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the javax.security.auth.Refreshable interface impact the handling of credentials in JAAS?",
      "answer": "The javax.security.auth.Refreshable interface is useful for handling credentials in JAAS when a credential has a limited timespan in which it is valid."
    }
  },
  {
    "instruction": "John the Ripper\n\n==Introduction==\nJohn the Ripper is a free password cracking software tool. Originally developed for the Unix operating system, it can run on fifteen different platforms (eleven of which are architecture-specific versions of Unix, DOS, Win32, BeOS, and OpenVMS). It is among the most frequently used password testing and breaking programs as it combines a number of password crackers into one package, autodetects password hash types, and includes a customizable cracker. It can be run against various encrypted password formats including several crypt password hash types most commonly found on various Unix versions (based on DES, MD5, or Blowfish), Kerberos AFS, and Windows NT/2000/XP/2003 LM hash. Additional modules have extended its ability to include MD4-based password hashes and passwords stored in LDAP, MySQL, and others.\n\n== Sample output ==\nHere is a sample output in a Debian environment.\n\nThe first line is a command to expand the data stored in the file \"pass.txt\". The next line is the contents of the file, i.e. the user (AZl) and the hash associated with that user (zWwxIh15Q). The third line is the command for running John the Ripper utilizing the \"-w\" flag. \"password.lst\" is the name of a text file full of words the program will use against the hash, pass.txt makes another appearance as the file we want John to work on.\nThen we see output from John working. Loaded 1 password hash \u2014 the one we saw with the \"cat\" command \u2014 and the type of hash John thinks it is (Traditional DES). We also see that the attempt required one guess at a time of 0 with a 100% guess rate.\n\n== Attack types ==\nOne of the modes John can use is the dictionary attack. It takes text string samples (usually from a file, called a wordlist, containing words found in a dictionary or real passwords cracked before), encrypting it in the same format as the password being examined (including both the encryption algorithm and key), and comparing the output to the encrypted string. It can also perform a variety of alterations to the dictionary words and try these. Many of these alterations are also used in John's single attack mode, which modifies an associated plaintext (such as a username with an encrypted password) and checks the variations against the hashes.\nJohn also offers a brute force mode. In this type of attack, the program goes through all the possible plaintexts, hashing each one and then comparing it to the input hash. John uses character frequency tables to try plaintexts containing more frequently used characters first. This method is useful for cracking passwords that do not appear in dictionary wordlists, but it takes a long time to run.\n\nBased on the above text, answer a question. How does John the Ripper's single attack mode work?",
    "context": "",
    "output": "John the Ripper's single attack mode modifies an associated plaintext, such as a username with an encrypted password, and checks the variations against the hashes.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does John the Ripper's single attack mode work?",
      "answer": "John the Ripper's single attack mode modifies an associated plaintext, such as a username with an encrypted password, and checks the variations against the hashes.",
      "context": "John the Ripper\n\n==Introduction==\nJohn the Ripper is a free password cracking software tool. Originally developed for the Unix operating system, it can run on fifteen different platforms (eleven of which are architecture-specific versions of Unix, DOS, Win32, BeOS, and OpenVMS). It is among the most frequently used password testing and breaking programs as it combines a number of password crackers into one package, autodetects password hash types, and includes a customizable cracker. It can be run against various encrypted password formats including several crypt password hash types most commonly found on various Unix versions (based on DES, MD5, or Blowfish), Kerberos AFS, and Windows NT/2000/XP/2003 LM hash. Additional modules have extended its ability to include MD4-based password hashes and passwords stored in LDAP, MySQL, and others.\n\n== Sample output ==\nHere is a sample output in a Debian environment.\n\nThe first line is a command to expand the data stored in the file \"pass.txt\". The next line is the contents of the file, i.e. the user (AZl) and the hash associated with that user (zWwxIh15Q). The third line is the command for running John the Ripper utilizing the \"-w\" flag. \"password.lst\" is the name of a text file full of words the program will use against the hash, pass.txt makes another appearance as the file we want John to work on.\nThen we see output from John working. Loaded 1 password hash \u2014 the one we saw with the \"cat\" command \u2014 and the type of hash John thinks it is (Traditional DES). We also see that the attempt required one guess at a time of 0 with a 100% guess rate.\n\n== Attack types ==\nOne of the modes John can use is the dictionary attack. It takes text string samples (usually from a file, called a wordlist, containing words found in a dictionary or real passwords cracked before), encrypting it in the same format as the password being examined (including both the encryption algorithm and key), and comparing the output to the encrypted string. It can also perform a variety of alterations to the dictionary words and try these. Many of these alterations are also used in John's single attack mode, which modifies an associated plaintext (such as a username with an encrypted password) and checks the variations against the hashes.\nJohn also offers a brute force mode. In this type of attack, the program goes through all the possible plaintexts, hashing each one and then comparing it to the input hash. John uses character frequency tables to try plaintexts containing more frequently used characters first. This method is useful for cracking passwords that do not appear in dictionary wordlists, but it takes a long time to run."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the role of LKRG in the Whonix operating system?",
    "context": "",
    "output": "LKRG is a Linux security module that thwarts classes of kernel exploitation techniques, hardening the guest OS and making it more difficult for adversaries to break out of the hypervisor and deanonymize the user.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of LKRG in the Whonix operating system?",
      "answer": "LKRG is a Linux security module that thwarts classes of kernel exploitation techniques, hardening the guest OS and making it more difficult for adversaries to break out of the hypervisor and deanonymize the user."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are some common forms of Twitterbots?",
    "context": "",
    "output": "Twitterbots can take various forms, such as producing automated posts on the Twitter microblogging service, automatically following Twitter users, serving as spam, enticing clicks on promotional links, posting @replies, or automatically retweeting based on specific words or phrases.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are some common forms of Twitterbots?",
      "answer": "Twitterbots can take various forms, such as producing automated posts on the Twitter microblogging service, automatically following Twitter users, serving as spam, enticing clicks on promotional links, posting @replies, or automatically retweeting based on specific words or phrases."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the purpose of the check performed in the reassembly process of IP fragments?",
    "context": "",
    "output": "The purpose of the check performed in the reassembly process of IP fragments is to ensure that the sum of the \"Fragment Offset\" and \"Total length\" fields in the IP header of each IP fragment is smaller or equal to 65,535. If the sum is greater, the packet is invalid and the IP fragment is ignored. This check is performed by some firewalls to protect hosts that do not have the bug fixed.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the purpose of the check performed in the reassembly process of IP fragments?",
      "answer": "The purpose of the check performed in the reassembly process of IP fragments is to ensure that the sum of the \"Fragment Offset\" and \"Total length\" fields in the IP header of each IP fragment is smaller or equal to 65,535. If the sum is greater, the packet is invalid and the IP fragment is ignored. This check is performed by some firewalls to protect hosts that do not have the bug fixed."
    }
  },
  {
    "instruction": "Write an answer to the following question: Is CounterSpy still available for purchase?",
    "context": "",
    "output": "No, CounterSpy is no longer available for purchase as it was discontinued in 2011.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Is CounterSpy still available for purchase?",
      "answer": "No, CounterSpy is no longer available for purchase as it was discontinued in 2011."
    }
  },
  {
    "instruction": "DroidKungFu\n\n==Introduction==\nDroidKungFu is a malware that affects Android OS. It primarily targets users in China. The first evidence of this malware was found in the Android Market in March 2011.\n\n\n\n== Process of DroidKungFu malware ==\nDroidkungFu encrypts two different root exploits: a udev exploit and a \"RageAgainsTheCage\" exploit, to break android security.  Once executed, it decrypts the exploits and communicates with a remote server without user knowledge.\n\n\n*** Function ***\nSilent mobile device rooting\nUnlocks all system files and functions\nInstalls itself without any user interaction\n\n\n*** Data collected ***\nIMEI number\nPhone model\nAndroid OS version\nNetwork operator\nNetwork type\nInformation stored in the Phone & SD Card memory\n\nHow does DroidKungFu malware break Android security?",
    "context": "",
    "output": "DroidKungFu malware breaks Android security by encrypting two different root exploits and decrypting them once executed, allowing it to communicate with a remote server without user knowledge.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does DroidKungFu malware break Android security?",
      "answer": "DroidKungFu malware breaks Android security by encrypting two different root exploits and decrypting them once executed, allowing it to communicate with a remote server without user knowledge.",
      "context": "DroidKungFu\n\n==Introduction==\nDroidKungFu is a malware that affects Android OS. It primarily targets users in China. The first evidence of this malware was found in the Android Market in March 2011.\n\n\n\n== Process of DroidKungFu malware ==\nDroidkungFu encrypts two different root exploits: a udev exploit and a \"RageAgainsTheCage\" exploit, to break android security.  Once executed, it decrypts the exploits and communicates with a remote server without user knowledge.\n\n\n*** Function ***\nSilent mobile device rooting\nUnlocks all system files and functions\nInstalls itself without any user interaction\n\n\n*** Data collected ***\nIMEI number\nPhone model\nAndroid OS version\nNetwork operator\nNetwork type\nInformation stored in the Phone & SD Card memory"
    }
  },
  {
    "instruction": "Write an answer to the following question: How does ISO/IEC JTC 1/SC 27 ensure that its standards and technical reports are relevant and applicable in various areas of information and ICT security?",
    "context": "",
    "output": "ISO/IEC JTC 1/SC 27 ensures that its standards and technical reports are relevant and applicable in various areas of information and ICT security by collaborating with a wide range of internal and external organizations. These collaborations help the subcommittee stay up-to-date with emerging trends and technologies, and ensure that their standards and technical reports are relevant and applicable in the ever-evolving landscape of information and ICT security.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does ISO/IEC JTC 1/SC 27 ensure that its standards and technical reports are relevant and applicable in various areas of information and ICT security?",
      "answer": "ISO/IEC JTC 1/SC 27 ensures that its standards and technical reports are relevant and applicable in various areas of information and ICT security by collaborating with a wide range of internal and external organizations. These collaborations help the subcommittee stay up-to-date with emerging trends and technologies, and ensure that their standards and technical reports are relevant and applicable in the ever-evolving landscape of information and ICT security."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does SAE use the MAC addresses of both peers to solve the authentication problem in the Diffie-Hellman key exchange?",
    "context": "",
    "output": "SAE uses the MAC addresses of both peers to create a pre-shared key, which is then used to influence the resulting key in the Diffie-Hellman key exchange. This ensures that both parties possess the correct mesh password, thereby solving the authentication problem.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does SAE use the MAC addresses of both peers to solve the authentication problem in the Diffie-Hellman key exchange?",
      "answer": "SAE uses the MAC addresses of both peers to create a pre-shared key, which is then used to influence the resulting key in the Diffie-Hellman key exchange. This ensures that both parties possess the correct mesh password, thereby solving the authentication problem."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the current status of the Frogbit cipher algorithm within the eCRYPT network's eSTREAM Project?",
    "context": "",
    "output": "The Frogbit cipher algorithm has been 'archived' within the eSTREAM Project of the eCRYPT network. This status indicates that the algorithm is no longer being actively developed or considered for further implementation in the project. The reasons for its archival may include its lack of selection for Phase 2, lower performance compared to other algorithms, or issues with the message authentication code feature. Regardless, the algorithm remains a part of the eSTREAM Project's archive, showcasing its historical relevance in the field of stream cipher research.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the current status of the Frogbit cipher algorithm within the eCRYPT network's eSTREAM Project?",
      "answer": "The Frogbit cipher algorithm has been 'archived' within the eSTREAM Project of the eCRYPT network. This status indicates that the algorithm is no longer being actively developed or considered for further implementation in the project. The reasons for its archival may include its lack of selection for Phase 2, lower performance compared to other algorithms, or issues with the message authentication code feature. Regardless, the algorithm remains a part of the eSTREAM Project's archive, showcasing its historical relevance in the field of stream cipher research."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the significance of the fact that Oleksandr Tkachuk of Security Service of Ukraine stated that they managed to authenticate a number of documents in the release but could not confirm the authenticity of the entire batch of documents?",
    "context": "",
    "output": "The fact that Oleksandr Tkachuk of Security Service of Ukraine stated that they managed to authenticate a number of documents in the release but could not confirm the authenticity of the entire batch of documents is significant because it raises questions about the authenticity of the emails and the extent of Russian involvement in the conflict in eastern Ukraine.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the significance of the fact that Oleksandr Tkachuk of Security Service of Ukraine stated that they managed to authenticate a number of documents in the release but could not confirm the authenticity of the entire batch of documents?",
      "answer": "The fact that Oleksandr Tkachuk of Security Service of Ukraine stated that they managed to authenticate a number of documents in the release but could not confirm the authenticity of the entire batch of documents is significant because it raises questions about the authenticity of the emails and the extent of Russian involvement in the conflict in eastern Ukraine."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are some of the functions provided by m0n0wall?",
    "context": "",
    "output": "Some of the functions provided by m0n0wall include Stateful packet filter firewall, IPsec and PPTP VPNs, Inbound and Outbound Network Address Translation, Captive portal, Traffic shaper, Inbound and Outbound port filtering, Support for 802.1q compatible VLANs, Multiple IP addresses on LAN and WAN ports, and IPS.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are some of the functions provided by m0n0wall?",
      "answer": "Some of the functions provided by m0n0wall include Stateful packet filter firewall, IPsec and PPTP VPNs, Inbound and Outbound Network Address Translation, Captive portal, Traffic shaper, Inbound and Outbound port filtering, Support for 802.1q compatible VLANs, Multiple IP addresses on LAN and WAN ports, and IPS."
    }
  },
  {
    "instruction": "Write an answer to the following question: What intranet does Intelink-S operate on?",
    "context": "",
    "output": "Intelink-S operates on SIPRNet.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What intranet does Intelink-S operate on?",
      "answer": "Intelink-S operates on SIPRNet."
    }
  },
  {
    "instruction": "Write an answer to the following question: How did the hacker access the NRA servers?",
    "context": "",
    "output": "The hacker accessed the NRA servers through a rarely used VAT refund service for deals abroad.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How did the hacker access the NRA servers?",
      "answer": "The hacker accessed the NRA servers through a rarely used VAT refund service for deals abroad."
    }
  },
  {
    "instruction": "Context: Foreshadow\n\n==Introduction==\nForeshadow, known as L1 Terminal Fault (L1TF) by Intel, is a vulnerability that affects modern microprocessors that was first discovered by two independent teams of researchers in January 2018, but was first disclosed to the public on 14 August 2018. The vulnerability is a speculative execution attack on Intel processors that may result in the disclosure of sensitive information stored in personal computers and third-party clouds. There are two versions: the first version (original/Foreshadow) (CVE-2018-3615) targets data from SGX enclaves; and the second version (next-generation/Foreshadow-NG) (CVE-2018-3620 and CVE-2018-3646) targets virtual machines (VMs), hypervisors (VMM), operating systems (OS) kernel memory, and System Management Mode (SMM) memory. A listing of affected Intel hardware has been posted.Foreshadow is similar to the Spectre security vulnerabilities discovered earlier to affect Intel and AMD chips, and the Meltdown vulnerability that also affected Intel. AMD products are not affected by the Foreshadow security flaws. According to one expert, \"[Foreshadow] lets malicious software break into secure areas that even the Spectre and Meltdown flaws couldn't crack\". Nonetheless, one of the variants of Foreshadow goes beyond Intel chips with SGX technology, and affects \"all [Intel] Core processors built over the last seven years\".Foreshadow may be very difficult to exploit. As of 15 August 2018, there seems to be no evidence of any serious hacking involving the Foreshadow vulnerabilities. Nevertheless, applying software patches may help alleviate some concern, although the balance between security and performance may be a worthy consideration. Companies performing cloud computing may see a significant decrease in their overall computing power; people should not likely see any performance impact, according to researchers. The real fix, according to Intel, is by replacing today's processors. Intel further states, \"These changes begin with our next-generation Intel Xeon Scalable processors (code-named Cascade Lake), as well as new client processors expected to launch later this year [2018].\"On 16 August 2018, researchers presented technical details of the Foreshadow security vulnerabilities in a seminar, and publication, entitled \"Foreshadow: Extracting the Keys to the Intel SGX Kingdom with Transient Out-of-Order Execution\" at a USENIX security conference.\n\n== Mechanism ==\nThe Foreshadow vulnerability is a speculative execution attack on Intel processors that may result in the disclosure of sensitive information stored in personal computers and third-party clouds. There are two versions: the first version (original/Foreshadow) (CVE-2018-3615 [attacks SGX]) targets data from SGX enclaves; and the second version (next-generation/Foreshadow-NG) (CVE-2018-3620 [attacks the OS Kernel and SMM mode] and CVE-2018-3646 [attacks virtual machines]) targets virtual machines (VMs), hypervisors (VMM), operating systems (OS) kernel memory, and System Management Mode (SMM) memory. Intel considers the entire class of speculative execution side channel vulnerabilities as \"L1 Terminal Fault\" (L1TF).For Foreshadow, the sensitive data of interest is the encrypted data in an SGX enclave. Usually, an attempt to read enclave memory from outside the enclave is made, speculative execution is permitted to modify the cache based on the data that was read, and then the processor is allowed to block the speculation when it detects that the protected-enclave memory is involved and reading is not permitted. Speculative execution can use sensitive data in a level 1 cache before the processor notices a lack of permission. The Foreshadow attacks are stealthy, and leave few traces of the attack event afterwards in a computer's logs.On 16 August 2018, researchers presented technical details of the Foreshadow security vulnerabilities in a seminar, and publication, at a USENIX security conference.\n\n== Impact ==\nForeshadow is similar to the Spectre security vulnerabilities discovered earlier to affect Intel and AMD chips, and the Meltdown vulnerability that affected Intel. AMD products, according to AMD, are not affected by the Foreshadow security flaws. According to one expert, \"[Foreshadow] lets malicious software break into secure areas that even the Spectre and Meltdown flaws couldn't crack\". Nonetheless, one of the variants of Foreshadow goes beyond Intel chips with SGX technology, and affects \"all [Intel] Core processors built over the last seven years\".Intel notes that the Foreshadow flaws could produce the following:\nMalicious applications, which may be able to infer data in the operating system memory, or data from other applications.\nA malicious guest virtual machine (VM) may infer data in the VM's memory, or data in the memory of other guest VMs.\nMalicious software running outside of SMM may infer data in SMM memory.\nMalicious software running outside of an Intel SGX enclave or within an enclave may infer data from within another Intel SGX enclave.According to one of the discoverers of the computer flaws: \"... the SGX security hole can lead to a \"Complete collapse of the SGX ecosystem.\"A partial listing of affected Intel hardware has been posted, and is described below. (Note: a more detailed - and updated - listing of affected products is on the official Intel website.)\n\nIntel Core i3/i5/i7/M processor (45 nm and 32 nm)\n2nd/3rd/4th/5th/6th/7th/8th generation Intel Core processors\nIntel Core X-series processor family for Intel X99 and X299 platforms\nIntel Xeon processor 3400/3600/5500/5600/6500/7500 series\nIntel Xeon Processor E3 v1/v2/v3/v4/v5/v6 family\nIntel Xeon Processor E5 v1/v2/v3/v4 family\nIntel Xeon Processor E7 v1/v2/v3/v4 family\nIntel Xeon Processor Scalable family\nIntel Xeon Processor D (1500, 2100)Foreshadow may be very difficult to exploit, and there seems to be no evidence to date (15 August 2018) of any serious hacking involving the Foreshadow vulnerabilities.\n\n== Mitigation ==\nApplying software patches may help alleviate some concern(s), although the balance between security and performance may be a worthy consideration. Companies performing cloud computing may see a significant decrease in their overall computing power; people should not likely see any performance impact, according to researchers.The real fix, according to Intel, is by replacing today's processors. Intel further states, \"These changes begin with our next-generation Intel Xeon Scalable processors (code-named Cascade Lake), as well as new client processors expected to launch later this year [2018].\"\nAnswer this question: What is Foreshadow and how does it affect Intel processors?",
    "context": "",
    "output": "Foreshadow, also known as L1 Terminal Fault (L1TF), is a speculative execution attack on Intel processors that may result in the disclosure of sensitive information from SGX enclaves, virtual machines, hypervisors, operating systems kernel memory, and System Management Mode (SMM) memory. It is similar to Spectre and Meltdown vulnerabilities and affects Intel Core processors built over the last seven years.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is Foreshadow and how does it affect Intel processors?",
      "answer": "Foreshadow, also known as L1 Terminal Fault (L1TF), is a speculative execution attack on Intel processors that may result in the disclosure of sensitive information from SGX enclaves, virtual machines, hypervisors, operating systems kernel memory, and System Management Mode (SMM) memory. It is similar to Spectre and Meltdown vulnerabilities and affects Intel Core processors built over the last seven years.",
      "context": "Foreshadow\n\n==Introduction==\nForeshadow, known as L1 Terminal Fault (L1TF) by Intel, is a vulnerability that affects modern microprocessors that was first discovered by two independent teams of researchers in January 2018, but was first disclosed to the public on 14 August 2018. The vulnerability is a speculative execution attack on Intel processors that may result in the disclosure of sensitive information stored in personal computers and third-party clouds. There are two versions: the first version (original/Foreshadow) (CVE-2018-3615) targets data from SGX enclaves; and the second version (next-generation/Foreshadow-NG) (CVE-2018-3620 and CVE-2018-3646) targets virtual machines (VMs), hypervisors (VMM), operating systems (OS) kernel memory, and System Management Mode (SMM) memory. A listing of affected Intel hardware has been posted.Foreshadow is similar to the Spectre security vulnerabilities discovered earlier to affect Intel and AMD chips, and the Meltdown vulnerability that also affected Intel. AMD products are not affected by the Foreshadow security flaws. According to one expert, \"[Foreshadow] lets malicious software break into secure areas that even the Spectre and Meltdown flaws couldn't crack\". Nonetheless, one of the variants of Foreshadow goes beyond Intel chips with SGX technology, and affects \"all [Intel] Core processors built over the last seven years\".Foreshadow may be very difficult to exploit. As of 15 August 2018, there seems to be no evidence of any serious hacking involving the Foreshadow vulnerabilities. Nevertheless, applying software patches may help alleviate some concern, although the balance between security and performance may be a worthy consideration. Companies performing cloud computing may see a significant decrease in their overall computing power; people should not likely see any performance impact, according to researchers. The real fix, according to Intel, is by replacing today's processors. Intel further states, \"These changes begin with our next-generation Intel Xeon Scalable processors (code-named Cascade Lake), as well as new client processors expected to launch later this year [2018].\"On 16 August 2018, researchers presented technical details of the Foreshadow security vulnerabilities in a seminar, and publication, entitled \"Foreshadow: Extracting the Keys to the Intel SGX Kingdom with Transient Out-of-Order Execution\" at a USENIX security conference.\n\n== Mechanism ==\nThe Foreshadow vulnerability is a speculative execution attack on Intel processors that may result in the disclosure of sensitive information stored in personal computers and third-party clouds. There are two versions: the first version (original/Foreshadow) (CVE-2018-3615 [attacks SGX]) targets data from SGX enclaves; and the second version (next-generation/Foreshadow-NG) (CVE-2018-3620 [attacks the OS Kernel and SMM mode] and CVE-2018-3646 [attacks virtual machines]) targets virtual machines (VMs), hypervisors (VMM), operating systems (OS) kernel memory, and System Management Mode (SMM) memory. Intel considers the entire class of speculative execution side channel vulnerabilities as \"L1 Terminal Fault\" (L1TF).For Foreshadow, the sensitive data of interest is the encrypted data in an SGX enclave. Usually, an attempt to read enclave memory from outside the enclave is made, speculative execution is permitted to modify the cache based on the data that was read, and then the processor is allowed to block the speculation when it detects that the protected-enclave memory is involved and reading is not permitted. Speculative execution can use sensitive data in a level 1 cache before the processor notices a lack of permission. The Foreshadow attacks are stealthy, and leave few traces of the attack event afterwards in a computer's logs.On 16 August 2018, researchers presented technical details of the Foreshadow security vulnerabilities in a seminar, and publication, at a USENIX security conference.\n\n== Impact ==\nForeshadow is similar to the Spectre security vulnerabilities discovered earlier to affect Intel and AMD chips, and the Meltdown vulnerability that affected Intel. AMD products, according to AMD, are not affected by the Foreshadow security flaws. According to one expert, \"[Foreshadow] lets malicious software break into secure areas that even the Spectre and Meltdown flaws couldn't crack\". Nonetheless, one of the variants of Foreshadow goes beyond Intel chips with SGX technology, and affects \"all [Intel] Core processors built over the last seven years\".Intel notes that the Foreshadow flaws could produce the following:\nMalicious applications, which may be able to infer data in the operating system memory, or data from other applications.\nA malicious guest virtual machine (VM) may infer data in the VM's memory, or data in the memory of other guest VMs.\nMalicious software running outside of SMM may infer data in SMM memory.\nMalicious software running outside of an Intel SGX enclave or within an enclave may infer data from within another Intel SGX enclave.According to one of the discoverers of the computer flaws: \"... the SGX security hole can lead to a \"Complete collapse of the SGX ecosystem.\"A partial listing of affected Intel hardware has been posted, and is described below. (Note: a more detailed - and updated - listing of affected products is on the official Intel website.)\n\nIntel Core i3/i5/i7/M processor (45 nm and 32 nm)\n2nd/3rd/4th/5th/6th/7th/8th generation Intel Core processors\nIntel Core X-series processor family for Intel X99 and X299 platforms\nIntel Xeon processor 3400/3600/5500/5600/6500/7500 series\nIntel Xeon Processor E3 v1/v2/v3/v4/v5/v6 family\nIntel Xeon Processor E5 v1/v2/v3/v4 family\nIntel Xeon Processor E7 v1/v2/v3/v4 family\nIntel Xeon Processor Scalable family\nIntel Xeon Processor D (1500, 2100)Foreshadow may be very difficult to exploit, and there seems to be no evidence to date (15 August 2018) of any serious hacking involving the Foreshadow vulnerabilities.\n\n== Mitigation ==\nApplying software patches may help alleviate some concern(s), although the balance between security and performance may be a worthy consideration. Companies performing cloud computing may see a significant decrease in their overall computing power; people should not likely see any performance impact, according to researchers.The real fix, according to Intel, is by replacing today's processors. Intel further states, \"These changes begin with our next-generation Intel Xeon Scalable processors (code-named Cascade Lake), as well as new client processors expected to launch later this year [2018].\""
    }
  },
  {
    "instruction": "Write an answer to the following question: What did Brian Murphy assert in a whistleblower complaint in September 2020?",
    "context": "",
    "output": "Brian Murphy, a former DHS undersecretary for intelligence and analysis, asserted in a whistleblower complaint that Wolf told him to cease providing intelligence assessments on the threat of Russian interference in the US, and instead start reporting on interference activities by China and Iran.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What did Brian Murphy assert in a whistleblower complaint in September 2020?",
      "answer": "Brian Murphy, a former DHS undersecretary for intelligence and analysis, asserted in a whistleblower complaint that Wolf told him to cease providing intelligence assessments on the threat of Russian interference in the US, and instead start reporting on interference activities by China and Iran."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the purpose of the Windows Data Protection API (DPAPI) in Microsoft SQL Server TDE?",
    "context": "",
    "output": "The Windows Data Protection API (DPAPI) protects a single instance-wide Service Master Key (SMK) in Microsoft SQL Server TDE.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the purpose of the Windows Data Protection API (DPAPI) in Microsoft SQL Server TDE?",
      "answer": "The Windows Data Protection API (DPAPI) protects a single instance-wide Service Master Key (SMK) in Microsoft SQL Server TDE."
    }
  },
  {
    "instruction": "Context: File integrity monitoring\n\n==Introduction==\nFile integrity monitoring (FIM) is an internal control or process that performs the act of validating the integrity of operating system and application software files using a verification method between the current file state and a known, good baseline.  This comparison method often involves calculating a known cryptographic checksum of the file's original baseline and comparing with the calculated checksum of the current state of the file. Other file attributes can also be used to monitor integrity.Generally, the act of performing file integrity monitoring is automated using internal controls such as an application or process. Such monitoring can be performed randomly, at a defined polling interval, or in real-time.\n\n== Security objectives ==\nChanges to configurations, files and file attributes across the IT infrastructure are common, but hidden within a large volume of daily changes can be the few that impact file or configuration integrity. These changes can also reduce security posture and in some cases may be leading indicators of a breach in progress. Values monitored for unexpected changes to files or configuration items include: \n\nCredentials\nPrivileges and Security Settings\nContent\nCore attributes and size\nHash values\nConfiguration values\n\n== Compliance objectives ==\nMultiple compliance objectives indicate file integrity monitoring as a requirement.  Several examples of compliance objectives with the requirement for file integrity monitoring include: \n\nPCI DSS - Payment Card Industry Data Security Standard (Requirement 11.5)\nSOX - Sarbanes-Oxley Act (Section 404)\nNERC CIP - NERC CIP Standard (CIP-010-2)\nFISMA - Federal Information Security Management Act (NIST SP800-53 Rev3)\nHIPAA - Health Insurance Portability and Accountability Act of 1996 (NIST Publication 800-66)\nSANS Critical Security Controls (Control 3)\n\nQuestion: What are some compliance objectives that require file integrity monitoring?\n\nAnswer:",
    "context": "",
    "output": "Some compliance objectives that require file integrity monitoring include PCI DSS (Requirement 11.5), SOX (Section 404), NERC CIP (CIP-010-2), FISMA (NIST SP800-53 Rev3), HIPAA (NIST Publication 800-66), and SANS Critical Security Controls (Control 3).",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are some compliance objectives that require file integrity monitoring?",
      "answer": "Some compliance objectives that require file integrity monitoring include PCI DSS (Requirement 11.5), SOX (Section 404), NERC CIP (CIP-010-2), FISMA (NIST SP800-53 Rev3), HIPAA (NIST Publication 800-66), and SANS Critical Security Controls (Control 3).",
      "context": "File integrity monitoring\n\n==Introduction==\nFile integrity monitoring (FIM) is an internal control or process that performs the act of validating the integrity of operating system and application software files using a verification method between the current file state and a known, good baseline.  This comparison method often involves calculating a known cryptographic checksum of the file's original baseline and comparing with the calculated checksum of the current state of the file. Other file attributes can also be used to monitor integrity.Generally, the act of performing file integrity monitoring is automated using internal controls such as an application or process. Such monitoring can be performed randomly, at a defined polling interval, or in real-time.\n\n== Security objectives ==\nChanges to configurations, files and file attributes across the IT infrastructure are common, but hidden within a large volume of daily changes can be the few that impact file or configuration integrity. These changes can also reduce security posture and in some cases may be leading indicators of a breach in progress. Values monitored for unexpected changes to files or configuration items include: \n\nCredentials\nPrivileges and Security Settings\nContent\nCore attributes and size\nHash values\nConfiguration values\n\n== Compliance objectives ==\nMultiple compliance objectives indicate file integrity monitoring as a requirement.  Several examples of compliance objectives with the requirement for file integrity monitoring include: \n\nPCI DSS - Payment Card Industry Data Security Standard (Requirement 11.5)\nSOX - Sarbanes-Oxley Act (Section 404)\nNERC CIP - NERC CIP Standard (CIP-010-2)\nFISMA - Federal Information Security Management Act (NIST SP800-53 Rev3)\nHIPAA - Health Insurance Portability and Accountability Act of 1996 (NIST Publication 800-66)\nSANS Critical Security Controls (Control 3)"
    }
  },
  {
    "instruction": "Service scan\n\n==Introduction==\nOn computer networks, a service scan identifies the available network services by attempting to initiate many sessions to different applications with each device in a target group of devices. This is done by sending session initiation packets for many different applications to open ports on all of the devices specified in the target group of devices. This scan is done across a wide range of  TCP,  UDP (and other transport layer protocols if desired such as  SCTP). A service scanner will identify each device it finds along with the services that it finds on the ports that it scans.Most user-based network services are intended to be found by users. As an example, a web service may be made available on TCP port 80 on a device. TCP/80 is the standard port for HTTP and users would be able to access the content of that web server, the website, by directing their web browsers to that device where the user would be able to view the home page of the website. However, a web service may be opened on a different port, where different content may be shared. This may be in an attempt to hide some content from ordinary users and only to provide it to users who know how to access the web service on the nonstandard port. A port scan will be able to identify that a port is open on the device, but may not be able to determine what service is being offered on that port. A service scan of that device will be able to determine that the port is open and that it is a web service.\nService scanners can be set to target a single device, but they are more often set to target a large number of devices. For example, a service scanner may be configured to scan a subnet. A service scanner may also be configured to scan standardized, well-known, and otherwise unused  ports and will attempt to initiate sessions to many known services for each port. This is different from a port sweep that will only identify open ports, which are assumed to be associated with the default service for that port. The difference is that a port scan and a port sweep will detect that a device has a port open and would assume that the port is associated with the service normally associated with that port. However, a service scanner would verify that the service is actually associated with that port, or would attempt to find and report the application actually associated with that port on the device.\nInformation security personnel may perform service scans to reduce risk. For example, a service scanner may be configured to only search for Microsoft SQL Servers on TCP ports from 1 to 50,000 on all of the devices in an  enterprise private network. If the service scanner only finds the MSSQL service running on known and authorized servers at TCP/1433 (the assigned port) then they can be reasonably sure that there are no unauthorized SQL servers in their network. Tools such as nmap and nessus may be used for this purpose.\nOn the other hand, a network attacker may use a special type of service scanner, known as a vulnerability scanner, to find devices that have not been patched to find a known vulnerability.  An attacker may also use a service scanner to find open administrative ports such as Telnet on TCP/21 and SSH on TCP/22. Once an attacker finds those ports they may then attempt to gain access to those devices by guessing usernames and passwords.\n\n\n\n\nRead the text above and answer this question: What is the risk associated with open administrative ports detected by a service scanner, and how can an attacker exploit this vulnerability?",
    "context": "",
    "output": "Open administrative ports, such as Telnet on TCP/21 and SSH on TCP/22, can pose a significant security risk if discovered by an attacker. These ports provide access to device administration interfaces, which, if compromised, can lead to unauthorized access and control of the device. Attackers can use service scanners to detect these open ports and then attempt to gain access to the device by guessing usernames and passwords. This can result in a security breach, data theft, or further network compromise. To mitigate this risk, it is essential to implement strong access control policies, regularly monitor and patch administrative interfaces, and limit exposure of these ports to only trusted and authorized users or systems.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the risk associated with open administrative ports detected by a service scanner, and how can an attacker exploit this vulnerability?",
      "answer": "Open administrative ports, such as Telnet on TCP/21 and SSH on TCP/22, can pose a significant security risk if discovered by an attacker. These ports provide access to device administration interfaces, which, if compromised, can lead to unauthorized access and control of the device. Attackers can use service scanners to detect these open ports and then attempt to gain access to the device by guessing usernames and passwords. This can result in a security breach, data theft, or further network compromise. To mitigate this risk, it is essential to implement strong access control policies, regularly monitor and patch administrative interfaces, and limit exposure of these ports to only trusted and authorized users or systems.",
      "context": "Service scan\n\n==Introduction==\nOn computer networks, a service scan identifies the available network services by attempting to initiate many sessions to different applications with each device in a target group of devices. This is done by sending session initiation packets for many different applications to open ports on all of the devices specified in the target group of devices. This scan is done across a wide range of  TCP,  UDP (and other transport layer protocols if desired such as  SCTP). A service scanner will identify each device it finds along with the services that it finds on the ports that it scans.Most user-based network services are intended to be found by users. As an example, a web service may be made available on TCP port 80 on a device. TCP/80 is the standard port for HTTP and users would be able to access the content of that web server, the website, by directing their web browsers to that device where the user would be able to view the home page of the website. However, a web service may be opened on a different port, where different content may be shared. This may be in an attempt to hide some content from ordinary users and only to provide it to users who know how to access the web service on the nonstandard port. A port scan will be able to identify that a port is open on the device, but may not be able to determine what service is being offered on that port. A service scan of that device will be able to determine that the port is open and that it is a web service.\nService scanners can be set to target a single device, but they are more often set to target a large number of devices. For example, a service scanner may be configured to scan a subnet. A service scanner may also be configured to scan standardized, well-known, and otherwise unused  ports and will attempt to initiate sessions to many known services for each port. This is different from a port sweep that will only identify open ports, which are assumed to be associated with the default service for that port. The difference is that a port scan and a port sweep will detect that a device has a port open and would assume that the port is associated with the service normally associated with that port. However, a service scanner would verify that the service is actually associated with that port, or would attempt to find and report the application actually associated with that port on the device.\nInformation security personnel may perform service scans to reduce risk. For example, a service scanner may be configured to only search for Microsoft SQL Servers on TCP ports from 1 to 50,000 on all of the devices in an  enterprise private network. If the service scanner only finds the MSSQL service running on known and authorized servers at TCP/1433 (the assigned port) then they can be reasonably sure that there are no unauthorized SQL servers in their network. Tools such as nmap and nessus may be used for this purpose.\nOn the other hand, a network attacker may use a special type of service scanner, known as a vulnerability scanner, to find devices that have not been patched to find a known vulnerability.  An attacker may also use a service scanner to find open administrative ports such as Telnet on TCP/21 and SSH on TCP/22. Once an attacker finds those ports they may then attempt to gain access to those devices by guessing usernames and passwords.\n\n\n\n"
    }
  },
  {
    "instruction": "Write an answer to the following question: How are security mechanisms related to security services in the OSI Reference Model?",
    "context": "",
    "output": "Security mechanisms like Encipherment, Digital Signature, Access Control, Data Integrity, Authentication Exchange, Traffic Padding, Routing Control, and Notarization can be used to provide security services in the OSI Reference Model.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How are security mechanisms related to security services in the OSI Reference Model?",
      "answer": "Security mechanisms like Encipherment, Digital Signature, Access Control, Data Integrity, Authentication Exchange, Traffic Padding, Routing Control, and Notarization can be used to provide security services in the OSI Reference Model."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the primary purpose of implementing database auditing?",
    "context": "",
    "output": "The primary purpose of implementing database auditing is to serve as a security measure for databases. This involves monitoring the database and keeping an eye on the actions of database users to ensure that only authorized individuals are accessing the information they are permitted to.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the primary purpose of implementing database auditing?",
      "answer": "The primary purpose of implementing database auditing is to serve as a security measure for databases. This involves monitoring the database and keeping an eye on the actions of database users to ensure that only authorized individuals are accessing the information they are permitted to."
    }
  },
  {
    "instruction": "Write an answer to the following question: Why is code signing not used on Linux for software authentication on first run?",
    "context": "",
    "output": "Code signing is not used on Linux for software authentication on first run because of that platform's decentralized nature, the package manager being the predominant mode of distribution for all forms of software, and the open-source model allowing direct inspection of the source code if desired.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Why is code signing not used on Linux for software authentication on first run?",
      "answer": "Code signing is not used on Linux for software authentication on first run because of that platform's decentralized nature, the package manager being the predominant mode of distribution for all forms of software, and the open-source model allowing direct inspection of the source code if desired."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the intended audience for the results of PRODIGAL's analysis?",
    "context": "",
    "output": "The results of PRODIGAL's analysis, which include the five most serious threats per day, are intended for agents, analysts, and operators working in counterintelligence.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the intended audience for the results of PRODIGAL's analysis?",
      "answer": "The results of PRODIGAL's analysis, which include the five most serious threats per day, are intended for agents, analysts, and operators working in counterintelligence."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is an encryption gateway appliance and how does it help email encryption?",
    "context": "",
    "output": "An encryption gateway appliance is a device that has been configured to ensure compliance with regulatory and security policies, and routes emails through it to automatically encrypt emails that require it.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is an encryption gateway appliance and how does it help email encryption?",
      "answer": "An encryption gateway appliance is a device that has been configured to ensure compliance with regulatory and security policies, and routes emails through it to automatically encrypt emails that require it."
    }
  },
  {
    "instruction": "TZSP\n\n==Introduction==\nTaZmen Sniffer Protocol (TZSP) is an encapsulation protocol used to wrap other protocols. It is commonly used to wrap 802.11 wireless packets to support Intrusion Detection Systems (IDS), wireless tracking, or other wireless applications.\n\n\n\n== Protocol Summary ==\nA number of 802.11 sensors and Access Points use the TZSP protocol for packet capture. It is an open protocol that was designed to encapsulate other protocols over UDP. The primary use for this protocol has been the capture of wireless traffic and transmission of them over a wired network.\n\n\n*** Protocol Header ***\nThe protocol specified three parts to each TZSP packet: A 4-byte header followed by one or more tagged fields, the last of which has to be the TAG_END(0x01), and finally the encapsulated data.\nThe header and tagged fields use big-endian ordering where appropriate.\n\n\n*** Version ***\nThe TZSP version should always be set to 1 (0x01).\n\n\n*** Type ***\n0 (0x00) Received tag list\n1 (0x01) Packet for transmit\n2 (0x02) Reserved\n3 (0x03) Configuration\n4 (0x04) Keepalive\n5 (0x05) Port opener\n\n\n*** Encapsulated Protocol ***\n  1 (0x01) Ethernet\n 18 (0x12) IEEE 802.11\n119 (0x77) Prism Header\n127 (0x7F) WLAN AVS\n\n\n*** Tagged Fields ***\nThe tagged fields consist of a one-byte tag type, followed by a one-byte tag length, followed by a variable amount of data. The tag length does not include the tag type or tag length.  All TZSP compatible decoders should skip unknown tagged fields.\n\n<1 unsigned byte > Tag Type\n<1 unsigned byte > Tag Length\n<variable length > Dependent on Tag Length\n\nThere are two exceptions to this format. First, when a TAG_END (0x01) is received it is the end of all of the tagged fields. It DOES NOT have a Tag length nor any associated data. The second is the TAG_PADDING (0x00). This can be inserted at any point and should be ignored. It DOES NOT have a tag length nor any tag data.\nThe following are the valid TZSP tag types:\nTAG_PADDING\n\n== Open Source Support ==\nSnort\nWireshark\nQuestion: Which open-source tools support the TZSP protocol?",
    "context": "",
    "output": "Answer: Snort and Wireshark are the open-source tools that support the TZSP protocol.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Which open-source tools support the TZSP protocol?",
      "answer": "Snort and Wireshark are the open-source tools that support the TZSP protocol.",
      "context": "TZSP\n\n==Introduction==\nTaZmen Sniffer Protocol (TZSP) is an encapsulation protocol used to wrap other protocols. It is commonly used to wrap 802.11 wireless packets to support Intrusion Detection Systems (IDS), wireless tracking, or other wireless applications.\n\n\n\n== Protocol Summary ==\nA number of 802.11 sensors and Access Points use the TZSP protocol for packet capture. It is an open protocol that was designed to encapsulate other protocols over UDP. The primary use for this protocol has been the capture of wireless traffic and transmission of them over a wired network.\n\n\n*** Protocol Header ***\nThe protocol specified three parts to each TZSP packet: A 4-byte header followed by one or more tagged fields, the last of which has to be the TAG_END(0x01), and finally the encapsulated data.\nThe header and tagged fields use big-endian ordering where appropriate.\n\n\n*** Version ***\nThe TZSP version should always be set to 1 (0x01).\n\n\n*** Type ***\n0 (0x00) Received tag list\n1 (0x01) Packet for transmit\n2 (0x02) Reserved\n3 (0x03) Configuration\n4 (0x04) Keepalive\n5 (0x05) Port opener\n\n\n*** Encapsulated Protocol ***\n  1 (0x01) Ethernet\n 18 (0x12) IEEE 802.11\n119 (0x77) Prism Header\n127 (0x7F) WLAN AVS\n\n\n*** Tagged Fields ***\nThe tagged fields consist of a one-byte tag type, followed by a one-byte tag length, followed by a variable amount of data. The tag length does not include the tag type or tag length.  All TZSP compatible decoders should skip unknown tagged fields.\n\n<1 unsigned byte > Tag Type\n<1 unsigned byte > Tag Length\n<variable length > Dependent on Tag Length\n\nThere are two exceptions to this format. First, when a TAG_END (0x01) is received it is the end of all of the tagged fields. It DOES NOT have a Tag length nor any associated data. The second is the TAG_PADDING (0x00). This can be inserted at any point and should be ignored. It DOES NOT have a tag length nor any tag data.\nThe following are the valid TZSP tag types:\nTAG_PADDING\n\n== Open Source Support ==\nSnort\nWireshark"
    }
  },
  {
    "instruction": "Write an answer to the following question: How do some alternative 3rd-party firmware make DVD+Rs readable by older DVD players?",
    "context": "",
    "output": "Some alternative 3rd-party firmware make DVD+Rs readable by older DVD players by enabling the Bitsetting/Booktyping feature, which makes the burned DVDs appear as DVD-ROMs and are playable by older DVD players.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do some alternative 3rd-party firmware make DVD+Rs readable by older DVD players?",
      "answer": "Some alternative 3rd-party firmware make DVD+Rs readable by older DVD players by enabling the Bitsetting/Booktyping feature, which makes the burned DVDs appear as DVD-ROMs and are playable by older DVD players."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the attack command work in network encryption cracking?",
    "context": "",
    "output": "The attack command in network encryption cracking is used to perform cracking on gathered packets. The command is typically simple and only requires a few inputs to initiate the cracking process.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the attack command work in network encryption cracking?",
      "answer": "The attack command in network encryption cracking is used to perform cracking on gathered packets. The command is typically simple and only requires a few inputs to initiate the cracking process."
    }
  },
  {
    "instruction": "Privoxy\n\n==Introduction==\nPrivoxy is a free non-caching web proxy with filtering capabilities for enhancing privacy, manipulating cookies and modifying web page data and HTTP headers before the page is rendered by the browser. Privoxy is a \"privacy enhancing proxy\", filtering web pages and removing advertisements. Privoxy can be customized by users, for both stand-alone systems and multi-user networks. Privoxy can be chained to other proxies and is frequently used in combination with Squid among others and can be used to bypass Internet censorship.\n\n\n\n\n\nHow does Privoxy manipulate cookies and HTTP headers?",
    "context": "",
    "output": "A: Privoxy can modify cookies and HTTP headers before a web page is rendered by the browser, allowing users to control the information that is sent to and received from web servers. For example, users can configure Privoxy to block certain types of cookies, modify HTTP headers to obscure their IP address or other identifying information, or even add custom headers to requests. This level of control can help users protect their privacy and enhance their security online.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does Privoxy manipulate cookies and HTTP headers?",
      "answer": "Privoxy can modify cookies and HTTP headers before a web page is rendered by the browser, allowing users to control the information that is sent to and received from web servers. For example, users can configure Privoxy to block certain types of cookies, modify HTTP headers to obscure their IP address or other identifying information, or even add custom headers to requests. This level of control can help users protect their privacy and enhance their security online.",
      "context": "Privoxy\n\n==Introduction==\nPrivoxy is a free non-caching web proxy with filtering capabilities for enhancing privacy, manipulating cookies and modifying web page data and HTTP headers before the page is rendered by the browser. Privoxy is a \"privacy enhancing proxy\", filtering web pages and removing advertisements. Privoxy can be customized by users, for both stand-alone systems and multi-user networks. Privoxy can be chained to other proxies and is frequently used in combination with Squid among others and can be used to bypass Internet censorship.\n\n\n\n"
    }
  },
  {
    "instruction": "Write an answer to the following question: How does Sculpt handle device detection and configuration?",
    "context": "",
    "output": "Sculpt has automatic device detection and configuration.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does Sculpt handle device detection and configuration?",
      "answer": "Sculpt has automatic device detection and configuration."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does CryptoGraf ensure that messages are not intercepted during transmission?",
    "context": "",
    "output": "CryptoGraf ensures the confidentiality of messages by encrypting them using AES-256 bit, which makes it difficult for unauthorized parties to intercept and read the message.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does CryptoGraf ensure that messages are not intercepted during transmission?",
      "answer": "CryptoGraf ensures the confidentiality of messages by encrypting them using AES-256 bit, which makes it difficult for unauthorized parties to intercept and read the message."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the default size limit for sites in ZeroNet?",
    "context": "",
    "output": "By default, sites have a size limit of 10 megabytes in ZeroNet.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the default size limit for sites in ZeroNet?",
      "answer": "By default, sites have a size limit of 10 megabytes in ZeroNet."
    }
  },
  {
    "instruction": "Write an answer to the following question: How is a scytale used for encryption in cryptography?",
    "context": "",
    "output": "A scytale is a cryptographic tool used to perform a transposition cipher, where a strip of parchment is wrapped around a cylinder, and the message is written on it. The recipient, who has a rod of the same diameter, can then wrap the strip around it and read the message.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How is a scytale used for encryption in cryptography?",
      "answer": "A scytale is a cryptographic tool used to perform a transposition cipher, where a strip of parchment is wrapped around a cylinder, and the message is written on it. The recipient, who has a rod of the same diameter, can then wrap the strip around it and read the message."
    }
  },
  {
    "instruction": "Macaroons (computer science)\n\n==Introduction==\nIn computer security, macaroons are authorization credentials that support decentralized delegation between principals.Macaroons are used in a variety of systems, including the Ubuntu Snappy package manager, the HyperDex data store, the Matrix communication protocol, and the Python Package Index.\n\n\n\n== Claims ==\nA macaroon is composed of series of \"caveats\", for example:\n\nmay upload files to /user/A/ (issued by server)\nonly to /user/A/album/123 (derived by A)\nonly GIFs, up to 1MB (derived by B)\nuntil noon today (derived by C)The macaroon model doesn't specify the language for these caveats; The original paper proposes a model of subjects and rights, but the details are left to individual implementations.\n\n== Related technologies ==\nMacaroons are similar to some other technologies.\nCompared to JSON Web Token (JWT):\n\nHolder of macaroon can issue a sub-macaroon with smaller power, while JWT is fixed\nMacaroon is notably longer than JWT\nMacaroon is equivalent to signed JWT, but does not offer equivalent to encrypted JWTCompared to Certificates\n\nMacaroons are based on a symmetric model, while certificates on asymmetric\nMacaroons are computationally cheaper and require simpler cryptographic primitives\nUsing a macaroon (sent to a server) can disclose some private information held by the macaroon holder, meaning that server must be trusted; Using a certificate means signing a payload using a private key, which is not sent to the server, thus communication with untrusted servers is less risky.\n\n== Invalidation ==\nImplementations need to decide whether the entire macaroon tree is invalidated at once from its root, the server secret key; or if intermediate macaroons are to be blacklisted, comparable to time-bound JWT's.\n\nAnswer this question based on the above context: How are authorization credentials represented in computer security?",
    "context": "",
    "output": "In computer security, authorization credentials are represented by macaroons, which support decentralized delegation between principals.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How are authorization credentials represented in computer security?",
      "answer": "In computer security, authorization credentials are represented by macaroons, which support decentralized delegation between principals.",
      "context": "Macaroons (computer science)\n\n==Introduction==\nIn computer security, macaroons are authorization credentials that support decentralized delegation between principals.Macaroons are used in a variety of systems, including the Ubuntu Snappy package manager, the HyperDex data store, the Matrix communication protocol, and the Python Package Index.\n\n\n\n== Claims ==\nA macaroon is composed of series of \"caveats\", for example:\n\nmay upload files to /user/A/ (issued by server)\nonly to /user/A/album/123 (derived by A)\nonly GIFs, up to 1MB (derived by B)\nuntil noon today (derived by C)The macaroon model doesn't specify the language for these caveats; The original paper proposes a model of subjects and rights, but the details are left to individual implementations.\n\n== Related technologies ==\nMacaroons are similar to some other technologies.\nCompared to JSON Web Token (JWT):\n\nHolder of macaroon can issue a sub-macaroon with smaller power, while JWT is fixed\nMacaroon is notably longer than JWT\nMacaroon is equivalent to signed JWT, but does not offer equivalent to encrypted JWTCompared to Certificates\n\nMacaroons are based on a symmetric model, while certificates on asymmetric\nMacaroons are computationally cheaper and require simpler cryptographic primitives\nUsing a macaroon (sent to a server) can disclose some private information held by the macaroon holder, meaning that server must be trusted; Using a certificate means signing a payload using a private key, which is not sent to the server, thus communication with untrusted servers is less risky.\n\n== Invalidation ==\nImplementations need to decide whether the entire macaroon tree is invalidated at once from its root, the server secret key; or if intermediate macaroons are to be blacklisted, comparable to time-bound JWT's."
    }
  },
  {
    "instruction": "Write an answer to the following question: How is the order of the group calculated in Trace Zero Cryptography?",
    "context": "",
    "output": "In Trace Zero Cryptography, the order of the group can be calculated using the characteristic polynomial of the Frobenius endomorphism for groups of cryptographically relevant size. This is not the case in Elliptic Curve Cryptography when the group of points of an elliptic curve over a prime field is used for cryptographic purposes.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How is the order of the group calculated in Trace Zero Cryptography?",
      "answer": "In Trace Zero Cryptography, the order of the group can be calculated using the characteristic polynomial of the Frobenius endomorphism for groups of cryptographically relevant size. This is not the case in Elliptic Curve Cryptography when the group of points of an elliptic curve over a prime field is used for cryptographic purposes."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does Dr.Web's ATM Shield help protect against ATM threats?",
    "context": "",
    "output": "Dr.Web's ATM Shield is designed to identify and study ATM threats, providing protection against encroachments of cybercriminals. This tool is essential in the face of increasing ATM-related cyber threats.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does Dr.Web's ATM Shield help protect against ATM threats?",
      "answer": "Dr.Web's ATM Shield is designed to identify and study ATM threats, providing protection against encroachments of cybercriminals. This tool is essential in the face of increasing ATM-related cyber threats."
    }
  },
  {
    "instruction": "Write an answer to the following question: How can software development through runtime environments be used to protect against malicious programs in mobile devices?",
    "context": "",
    "output": "Software development through runtime environments can be used to prevent malicious actions by continuously monitoring the actions of the execution threads they manage. This can help to prevent buffer overflows and other malicious actions.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can software development through runtime environments be used to protect against malicious programs in mobile devices?",
      "answer": "Software development through runtime environments can be used to prevent malicious actions by continuously monitoring the actions of the execution threads they manage. This can help to prevent buffer overflows and other malicious actions."
    }
  },
  {
    "instruction": "Fork bomb\n\n==Introduction==\nIn computing, a fork bomb (also called rabbit virus or wabbit) is a denial-of-service attack wherein a process continually replicates itself to deplete available system resources, slowing down or crashing the system due to resource starvation.\n\n== Implementation ==\nFork bombs operate both by consuming CPU time in the process of forking, and by saturating the operating system's process table. A basic implementation of a fork bomb is an infinite loop that repeatedly launches new copies of itself.\nIn Unix-like operating systems, fork bombs are generally written to use the fork system call. As forked processes are also copies of the first program, once they resume execution from the next address at the frame pointer, they continue forking endlessly within their own copy of the same infinite loop; this has the effect of causing an exponential growth in processes. As modern Unix systems generally use a copy-on-write resource management technique when forking new processes, a fork bomb generally will not saturate such a system's memory.\nMicrosoft Windows operating systems do not have an equivalent functionality to the Unix fork system call; a fork bomb on such an operating system must therefore create a new process instead of forking from an existing one.\nHowever, in Microsft Windows, a fork bomb can be created in a batch file with content %0|%0. If this batch file is executed, it starts creating unlimited copies of itself.\nA classic example of a fork bomb is one written in Unix shell :(){ :|:& };:, possibly dating back to 1999, which can be more easily understood as\n\nIn it, a function is defined (fork()) as calling itself (fork), then piping (|) its result to a background job of itself (&).\nThe code using a colon : as the function name is not valid in a shell as defined by POSIX, which only permits alphanumeric characters and underscores in function names. However, its usage is allowed in GNU Bash as an extension.The first formulation of the Unix shell fork bomb has been proposed as an anonymous work of art.\n\n== Prevention ==\nAs a fork bomb's mode of operation is entirely encapsulated by creating new processes, one way of preventing a fork bomb from severely affecting the entire system is to limit the maximum number of processes that a single user may own. On Linux, this can be achieved by using the ulimit utility; for example, the command ulimit -u 30 would limit the affected user to a maximum of thirty owned processes.\nOn PAM-enabled systems, this limit can also be set in /etc/security/limits.conf,\nand on FreeBSD, the system administrator can put limits in /etc/login.conf.\nModern Linux systems also allow finer-grained fork bomb prevention through cgroups and process number (PID) controllers.\n\nAnswer this question based on the above context: How does a fork bomb cause a denial-of-service attack?",
    "context": "",
    "output": "A fork bomb is a type of denial-of-service attack that consumes available system resources, such as CPU time and process table entries, by repeatedly forking new copies of itself. This leads to resource depletion, slowing down or crashing the system due to resource starvation.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does a fork bomb cause a denial-of-service attack?",
      "answer": "A fork bomb is a type of denial-of-service attack that consumes available system resources, such as CPU time and process table entries, by repeatedly forking new copies of itself. This leads to resource depletion, slowing down or crashing the system due to resource starvation.",
      "context": "Fork bomb\n\n==Introduction==\nIn computing, a fork bomb (also called rabbit virus or wabbit) is a denial-of-service attack wherein a process continually replicates itself to deplete available system resources, slowing down or crashing the system due to resource starvation.\n\n== Implementation ==\nFork bombs operate both by consuming CPU time in the process of forking, and by saturating the operating system's process table. A basic implementation of a fork bomb is an infinite loop that repeatedly launches new copies of itself.\nIn Unix-like operating systems, fork bombs are generally written to use the fork system call. As forked processes are also copies of the first program, once they resume execution from the next address at the frame pointer, they continue forking endlessly within their own copy of the same infinite loop; this has the effect of causing an exponential growth in processes. As modern Unix systems generally use a copy-on-write resource management technique when forking new processes, a fork bomb generally will not saturate such a system's memory.\nMicrosoft Windows operating systems do not have an equivalent functionality to the Unix fork system call; a fork bomb on such an operating system must therefore create a new process instead of forking from an existing one.\nHowever, in Microsft Windows, a fork bomb can be created in a batch file with content %0|%0. If this batch file is executed, it starts creating unlimited copies of itself.\nA classic example of a fork bomb is one written in Unix shell :(){ :|:& };:, possibly dating back to 1999, which can be more easily understood as\n\nIn it, a function is defined (fork()) as calling itself (fork), then piping (|) its result to a background job of itself (&).\nThe code using a colon : as the function name is not valid in a shell as defined by POSIX, which only permits alphanumeric characters and underscores in function names. However, its usage is allowed in GNU Bash as an extension.The first formulation of the Unix shell fork bomb has been proposed as an anonymous work of art.\n\n== Prevention ==\nAs a fork bomb's mode of operation is entirely encapsulated by creating new processes, one way of preventing a fork bomb from severely affecting the entire system is to limit the maximum number of processes that a single user may own. On Linux, this can be achieved by using the ulimit utility; for example, the command ulimit -u 30 would limit the affected user to a maximum of thirty owned processes.\nOn PAM-enabled systems, this limit can also be set in /etc/security/limits.conf,\nand on FreeBSD, the system administrator can put limits in /etc/login.conf.\nModern Linux systems also allow finer-grained fork bomb prevention through cgroups and process number (PID) controllers."
    }
  },
  {
    "instruction": "Fortify Software\n\n==Introduction==\nFortify Software, later known as Fortify Inc., is a California-based software security vendor, founded in 2003 and acquired by Hewlett-Packard in 2010, Micro Focus in 2017, and OpenText in 2022.\nFortify offerings included Static application security testing (SAST) and Dynamic Application Security Testing products, as well as products and services that support Software Security Assurance. In 2011, Fortify introduced Fortify OnDemand, a static and dynamic application testing service.\n\n== Technical advisory board ==\nFortify's technical advisory board was composed of Avi Rubin, Bill Joy, David Wagner, Fred Schneider, Gary McGraw, Greg Morrisett, Li Gong, Marcus Ranum, Matt Bishop, William Pugh, and John Viega.\n\n== Security research ==\nFortify created a security research group that maintained the Java Open Review project and the Vulncat taxonomy of security vulnerabilities in addition to the security rules for Fortify's analysis software. Members of the group wrote the book Secure Coding with Static Analysis, and published research, including JavaScript Hijacking, Attacking the build: Cross build Injection, Watch what you write: Preventing Cross-site scripting by observing program output, and Dynamic taint propagation: Finding vulnerabilities without attacking.\n\nWhat was the name of Fortify's technical advisory board?",
    "context": "",
    "output": "Fortify's technical advisory board was composed of well-known experts in the field of computer security.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was the name of Fortify's technical advisory board?",
      "answer": "Fortify's technical advisory board was composed of well-known experts in the field of computer security.",
      "context": "Fortify Software\n\n==Introduction==\nFortify Software, later known as Fortify Inc., is a California-based software security vendor, founded in 2003 and acquired by Hewlett-Packard in 2010, Micro Focus in 2017, and OpenText in 2022.\nFortify offerings included Static application security testing (SAST) and Dynamic Application Security Testing products, as well as products and services that support Software Security Assurance. In 2011, Fortify introduced Fortify OnDemand, a static and dynamic application testing service.\n\n== Technical advisory board ==\nFortify's technical advisory board was composed of Avi Rubin, Bill Joy, David Wagner, Fred Schneider, Gary McGraw, Greg Morrisett, Li Gong, Marcus Ranum, Matt Bishop, William Pugh, and John Viega.\n\n== Security research ==\nFortify created a security research group that maintained the Java Open Review project and the Vulncat taxonomy of security vulnerabilities in addition to the security rules for Fortify's analysis software. Members of the group wrote the book Secure Coding with Static Analysis, and published research, including JavaScript Hijacking, Attacking the build: Cross build Injection, Watch what you write: Preventing Cross-site scripting by observing program output, and Dynamic taint propagation: Finding vulnerabilities without attacking."
    }
  },
  {
    "instruction": "Pseudorandom permutation\n\n==Introduction==\nIn cryptography, a pseudorandom permutation (PRP) is a function that cannot be distinguished from a random permutation (that is, a permutation selected at random with uniform probability, from the family of all permutations on the function's domain) with practical effort.\n\n== Definition ==\nLet F be a mapping \n  \n    \n      \n        \n          \n            {\n            \n              0\n              ,\n              1\n            \n            }\n          \n          \n            n\n          \n        \n        \u00d7\n        \n          \n            {\n            \n              0\n              ,\n              1\n            \n            }\n          \n          \n            s\n          \n        \n        \u2192\n        \n          \n            {\n            \n              0\n              ,\n              1\n            \n            }\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\left\\{0,1\\right\\}^{n}\\times \\left\\{0,1\\right\\}^{s}\\rightarrow \\left\\{0,1\\right\\}^{n}}\n  . F is a PRP if and only if\n\nFor any \n  \n    \n      \n        K\n        \u2208\n        \n          \n            {\n            \n              0\n              ,\n              1\n            \n            }\n          \n          \n            s\n          \n        \n      \n    \n    {\\displaystyle K\\in \\left\\{0,1\\right\\}^{s}}\n  , \n  \n    \n      \n        \n          F\n          \n            K\n          \n        \n      \n    \n    {\\displaystyle F_{K}}\n   is a bijection from \n  \n    \n      \n        \n          \n            {\n            \n              0\n              ,\n              1\n            \n            }\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\left\\{0,1\\right\\}^{n}}\n   to \n  \n    \n      \n        \n          \n            {\n            \n              0\n              ,\n              1\n            \n            }\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\left\\{0,1\\right\\}^{n}}\n  , where \n  \n    \n      \n        \n          F\n          \n            K\n          \n        \n        (\n        x\n        )\n\n== The model of block ciphers ==\nThe idealized abstraction of a (keyed) block cipher is a truly random permutation on the mappings between plaintext and ciphertext.  If a distinguishing algorithm exists that achieves significant advantage with less effort than specified by the block cipher's security parameter (this usually means the effort required should be about the same as a brute force search through the cipher's key space), then the cipher is considered broken at least in a certificational sense, even if such a break doesn't immediately lead to a practical security failure.Modern ciphers are expected to have super pseudorandomness.\nThat is, the cipher should be indistinguishable from a randomly chosen permutation on the same message space, even if the adversary has black-box access to the forward and inverse directions of the cipher.\n\n== Connections with pseudorandom function ==\nMichael Luby and Charles Rackoff showed that a \"strong\" pseudorandom permutation can be built from a pseudorandom function using a Luby\u2013Rackoff construction which is built using a Feistel cipher.\n\n== Related concepts ==\n\n\n*** Unpredictable permutation ***\nAn unpredictable permutation (UP) Fk is a permutation whose values cannot be predicted by a fast randomized algorithm. Unpredictable permutations may be used as a cryptographic primitive, a building block for cryptographic systems with more complex properties.\nAn adversary for an unpredictable permutation is defined to be an algorithm that is given access to an oracle for both forward and inverse permutation operations. The adversary is given a challenge input k and is asked to predict the value of Fk. It is allowed to make a series of queries to the oracle to help it make this prediction, but is not allowed to query the value of k itself.A randomized algorithm for generating permutations generates an unpredictable permutation if its outputs are permutations on a set of items (described by length-n binary strings)  that cannot be predicted with accuracy significantly better than random by an adversary that makes a polynomial (in n) number of queries to the oracle prior to the challenge round, whose running time is polynomial in n, and whose error probability is less than 1/2 for all instances. That is, it cannot be predicted in the complexity class PP, relativized by the oracle for the permutation.\n\n\n**** Properties of unpredictable permutations ****\nIt can be shown that a function Fk is not a secure message authentication code (MAC) if it satisfies only the unpredictability requirement. It can also be shown that one cannot build an efficient variable input length MAC from a block cipher which is modelled as a UP of n bits. It has been shown that the output of a k\n\n== Applications ==\nDESK x X \u2192 X \u2200  X\n\nBased on the above text, answer a question. What is the definition of a randomized algorithm for generating permutations that generates an unpredictable permutation?",
    "context": "",
    "output": "A randomized algorithm for generating permutations generates an unpredictable permutation if its outputs are permutations on a set of items (described by length-n binary strings) that cannot be predicted with accuracy significantly better than random by an adversary that makes a polynomial (in n) number of queries to the oracle prior to the challenge round, whose running time is polynomial in n, and whose error probability is less than 1/2 for all instances.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the definition of a randomized algorithm for generating permutations that generates an unpredictable permutation?",
      "answer": "A randomized algorithm for generating permutations generates an unpredictable permutation if its outputs are permutations on a set of items (described by length-n binary strings) that cannot be predicted with accuracy significantly better than random by an adversary that makes a polynomial (in n) number of queries to the oracle prior to the challenge round, whose running time is polynomial in n, and whose error probability is less than 1/2 for all instances.",
      "context": "Pseudorandom permutation\n\n==Introduction==\nIn cryptography, a pseudorandom permutation (PRP) is a function that cannot be distinguished from a random permutation (that is, a permutation selected at random with uniform probability, from the family of all permutations on the function's domain) with practical effort.\n\n== Definition ==\nLet F be a mapping \n  \n    \n      \n        \n          \n            {\n            \n              0\n              ,\n              1\n            \n            }\n          \n          \n            n\n          \n        \n        \u00d7\n        \n          \n            {\n            \n              0\n              ,\n              1\n            \n            }\n          \n          \n            s\n          \n        \n        \u2192\n        \n          \n            {\n            \n              0\n              ,\n              1\n            \n            }\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\left\\{0,1\\right\\}^{n}\\times \\left\\{0,1\\right\\}^{s}\\rightarrow \\left\\{0,1\\right\\}^{n}}\n  . F is a PRP if and only if\n\nFor any \n  \n    \n      \n        K\n        \u2208\n        \n          \n            {\n            \n              0\n              ,\n              1\n            \n            }\n          \n          \n            s\n          \n        \n      \n    \n    {\\displaystyle K\\in \\left\\{0,1\\right\\}^{s}}\n  , \n  \n    \n      \n        \n          F\n          \n            K\n          \n        \n      \n    \n    {\\displaystyle F_{K}}\n   is a bijection from \n  \n    \n      \n        \n          \n            {\n            \n              0\n              ,\n              1\n            \n            }\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\left\\{0,1\\right\\}^{n}}\n   to \n  \n    \n      \n        \n          \n            {\n            \n              0\n              ,\n              1\n            \n            }\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\left\\{0,1\\right\\}^{n}}\n  , where \n  \n    \n      \n        \n          F\n          \n            K\n          \n        \n        (\n        x\n        )\n\n== The model of block ciphers ==\nThe idealized abstraction of a (keyed) block cipher is a truly random permutation on the mappings between plaintext and ciphertext.  If a distinguishing algorithm exists that achieves significant advantage with less effort than specified by the block cipher's security parameter (this usually means the effort required should be about the same as a brute force search through the cipher's key space), then the cipher is considered broken at least in a certificational sense, even if such a break doesn't immediately lead to a practical security failure.Modern ciphers are expected to have super pseudorandomness.\nThat is, the cipher should be indistinguishable from a randomly chosen permutation on the same message space, even if the adversary has black-box access to the forward and inverse directions of the cipher.\n\n== Connections with pseudorandom function ==\nMichael Luby and Charles Rackoff showed that a \"strong\" pseudorandom permutation can be built from a pseudorandom function using a Luby\u2013Rackoff construction which is built using a Feistel cipher.\n\n== Related concepts ==\n\n\n*** Unpredictable permutation ***\nAn unpredictable permutation (UP) Fk is a permutation whose values cannot be predicted by a fast randomized algorithm. Unpredictable permutations may be used as a cryptographic primitive, a building block for cryptographic systems with more complex properties.\nAn adversary for an unpredictable permutation is defined to be an algorithm that is given access to an oracle for both forward and inverse permutation operations. The adversary is given a challenge input k and is asked to predict the value of Fk. It is allowed to make a series of queries to the oracle to help it make this prediction, but is not allowed to query the value of k itself.A randomized algorithm for generating permutations generates an unpredictable permutation if its outputs are permutations on a set of items (described by length-n binary strings)  that cannot be predicted with accuracy significantly better than random by an adversary that makes a polynomial (in n) number of queries to the oracle prior to the challenge round, whose running time is polynomial in n, and whose error probability is less than 1/2 for all instances. That is, it cannot be predicted in the complexity class PP, relativized by the oracle for the permutation.\n\n\n**** Properties of unpredictable permutations ****\nIt can be shown that a function Fk is not a secure message authentication code (MAC) if it satisfies only the unpredictability requirement. It can also be shown that one cannot build an efficient variable input length MAC from a block cipher which is modelled as a UP of n bits. It has been shown that the output of a k\n\n== Applications ==\nDESK x X \u2192 X \u2200  X"
    }
  },
  {
    "instruction": "Sguil\n\n==Introduction==\nSguil (pronounced sgweel or squeal) is a collection of free software components for Network Security Monitoring (NSM) and event driven analysis of IDS alerts. The sguil client is written in Tcl/Tk and can be run on any operating system that supports these.  Sguil integrates alert data from Snort, session data from SANCP, and full content data from a second instance of Snort running in packet logger mode.\nSguil is an implementation of a Network Security Monitoring system. NSM is defined as \"collection, analysis, and escalation of indications and warnings to detect and respond  to intrusions.\"\nSguil is released under the GPL 3.0.\n\n== Tools that make up Sguil ==\n\nBased on the above text, answer a question. What are the primary data sources integrated by Sguil for NSM?",
    "context": "",
    "output": "Sguil integrates alert data from Snort, session data from SANCP, and full content data from a second instance of Snort running in packet logger mode.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are the primary data sources integrated by Sguil for NSM?",
      "answer": "Sguil integrates alert data from Snort, session data from SANCP, and full content data from a second instance of Snort running in packet logger mode.",
      "context": "Sguil\n\n==Introduction==\nSguil (pronounced sgweel or squeal) is a collection of free software components for Network Security Monitoring (NSM) and event driven analysis of IDS alerts. The sguil client is written in Tcl/Tk and can be run on any operating system that supports these.  Sguil integrates alert data from Snort, session data from SANCP, and full content data from a second instance of Snort running in packet logger mode.\nSguil is an implementation of a Network Security Monitoring system. NSM is defined as \"collection, analysis, and escalation of indications and warnings to detect and respond  to intrusions.\"\nSguil is released under the GPL 3.0.\n\n== Tools that make up Sguil =="
    }
  },
  {
    "instruction": "Write an answer to the following question: How do on-access or real-time scanners in anti-malware software function, and what are their advantages and disadvantages?",
    "context": "",
    "output": "On-access or real-time scanners in anti-malware software hook deep into the operating system's core or kernel and check files for malware every time the operating system accesses a file. This type of malware protection works similarly to how certain malware itself would attempt to operate, though with the user's informed permission for protecting the system. However, this can have a considerable performance impact on the operating system.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do on-access or real-time scanners in anti-malware software function, and what are their advantages and disadvantages?",
      "answer": "On-access or real-time scanners in anti-malware software hook deep into the operating system's core or kernel and check files for malware every time the operating system accesses a file. This type of malware protection works similarly to how certain malware itself would attempt to operate, though with the user's informed permission for protecting the system. However, this can have a considerable performance impact on the operating system."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does SLM contribute to IT governance?",
    "context": "",
    "output": "SLM allows CSOs, CIOs, and CISOs to prove that they are adequately protecting electronic data relevant to processes, contributing to IT governance by ensuring that IT supports corporate strategy and objectives through suitable organization structures and processes.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does SLM contribute to IT governance?",
      "answer": "SLM allows CSOs, CIOs, and CISOs to prove that they are adequately protecting electronic data relevant to processes, contributing to IT governance by ensuring that IT supports corporate strategy and objectives through suitable organization structures and processes."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the difference between a simple authentication protocol and a more complicated one?",
    "context": "",
    "output": "A simple authentication protocol, like the one between Alice and Bob in the example, is vulnerable to various attacks such as eavesdropping, replay attacks, and man-in-the-middle attacks. More complicated authentication protocols are designed to be resilient against these attacks.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the difference between a simple authentication protocol and a more complicated one?",
      "answer": "A simple authentication protocol, like the one between Alice and Bob in the example, is vulnerable to various attacks such as eavesdropping, replay attacks, and man-in-the-middle attacks. More complicated authentication protocols are designed to be resilient against these attacks."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does Julian Assange view the role of cryptography in protecting against state surveillance, and why does he consider it a \"vital tool\" in fighting state oppression?",
    "context": "",
    "output": "Julian Assange sees cryptography as an essential building block for the independence of organizations on the Internet, akin to how armies serve as essential building blocks for the independence of states. He believes that without strong cryptography, intellectual life cannot gain proper independence from those who control physical reality, often the security guards of the world. Assange emphasizes the significance of cryptography as a powerful tool in resisting state oppression, as he argues in his book, Cypherpunks.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does Julian Assange view the role of cryptography in protecting against state surveillance, and why does he consider it a \"vital tool\" in fighting state oppression?",
      "answer": "Julian Assange sees cryptography as an essential building block for the independence of organizations on the Internet, akin to how armies serve as essential building blocks for the independence of states. He believes that without strong cryptography, intellectual life cannot gain proper independence from those who control physical reality, often the security guards of the world. Assange emphasizes the significance of cryptography as a powerful tool in resisting state oppression, as he argues in his book, Cypherpunks."
    }
  },
  {
    "instruction": "Berserk Bear\n\n==Introduction==\nBerserk Bear (aka Crouching Yeti, Dragonfly, Dragonfly 2.0, DYMALLOY, Energetic Bear, Havex, IRON LIBERTY, Koala, or TeamSpy) is a Russian cyber espionage group, sometimes known as an advanced persistent threat. According to the United States, the group is composed of \"FSB hackers,\" either those directly employed by the FSB or Russian civilian, criminal hackers coerced into contracting as FSB hackers while still freelancing or moonlighting as criminal hackers. Four accused Berserk Bear participants, three FSB staff and one civilian, have been indicted in the United States and are regarded by the United States Department of Justice as fugitives.\n\n== Activities ==\nBerserk Bear specializes in compromising utilities infrastructure, especially that belonging to companies responsible for water or energy distribution. It has performed these activities in at least Germany and the U.S. These operations are targeted towards surveillance and technical reconnaissance.Berserk Bear has also targeted many state, local, and tribal government and aviation networks in the U.S., and as of October 1, 2020, had exfiltrated data from at least two victim servers. In particular, Berserk Bear is believed to have infiltrated the computer network of the city of Austin, Texas, during 2020.The group is capable of producing its own advanced malware, although it sometimes seeks to mimic other hacking groups and conceal its activities.\n\n== Indictments unsealed 2022 ==\nIn 2021 federal grand juries in the United States indicted three personnel of the Russian Federal Security Service (FSB) and a civilian from the Central Research Institute of Chemistry and Mechanics (CNIIHM). These indictments were kept under seal until March 2022 when the United States publicly named the defendants and treated them as fugitives.\n\n\n*** Evgeny Gladkikh ***\nEvgeny Gladkikh (Russian: \u0415\u0432\u0433\u0435\u043d\u0438\u0439 \u0413\u043b\u0430\u0434\u043a\u0438\u0445): is accused of targeting network-connected safety equipment with the intent to gain the capability to sabotage them. He was indicted in the U.S. District Court for the District of Columbia\n\n\n*** \"Center 16\" defendants ***\nThe indictment in the case United States v. Akulov, et al. is focused on members of a team within \"Center 16\" (Russian: 16-\u0439 \u0426\u0435\u043d\u0442\u0440) an FSB component also known as Military Unit 71330 (Russian: B\u043e\u0439\u0441\u043a\u043e\u0432\u0430\u044f \u0447\u0430\u0441\u0442\u044c B/\u0427 71330).\nThe British Foreign Office states that the full name of Center 16 is \"Radio-Electronic Intelligence by Means of Communication\" (TsRRSS); Russian: \u0426\u0435\u043d\u0442\u0440 \u0440\u0430\u0434\u0438\u043e\u044d\u043b\u0435\u043a\u0442\u0440\u043e\u043d\u043d\u043e\u0439 \u0440\u0430\u0437\u0432\u0435\u0434\u043a\u0438 \u043d\u0430 \u0441\u0440\u0435\u0434\u0441\u0442\u0432\u0430\u0445 \u0441\u0432\u044f\u0437\u0438 (\u0426PPCC)The U.S. v. Akulov case was filed within the United States District Court for the District of Kansas. The named defendants are:\n\nPavel Aleksandrovich Akulov (Russian: \u041f\u0430\u0432\u0435\u043b \u0410\u043b\u0435\u043a\u0441\u0430\u043d\u0434\u0440\u043e\u0432\u0438\u0447 \u0410\u043a\u0443\u043b\u043e\u0432, b. 2 July 1985) is described as a military officer assigned to Military Unit 71330, who held the rank of lieutenant as of 2013. Akulov is described as conducting surveillance and reconnaissance supporting the targeting of the Wolf Creek Generating Station computer network.\nMikhail Mikhailovich Gavrilov (Russian: \u041c\u0438\u0445\u0430\u0438\u043b \u041c\u0438\u0445\u0430\u0439\u043b\u043e\u0432\u0438\u0447 \u0413\u0430\u0432\u0440\u0438\u043b\u043e\u0432, b. 7 November 1979) is described as Russian military intelligence officer assigned to Military Unit 71330. He has held the rank of captain and major. He is described as conducting computer intrusions into the computer networks of Wolf Creek and another unnamed entity (\"Company 7\") used to access energy, utility and critical infrastructure webmail login webpages.\nMarat Valeryevich Tyukov (Russian: \u041c\u0430\u0440\u0430\u0442 \u0412\u0430\u043b\u0435\u0440\u044c\u0435\u0432\u0438\u0447 \u0422\u044e\u043a\u043e\u0432, b. 17 November 1982) is described as a Russian military intelligence officer assigned to Military Unit 71330. He is alleged to have gained unauthorized access to a server owned by an unnamed entity (\"Company One\") that was used for command and control infrastructure. He is also accused of tampering with updates to industrial control software which affected power and energy companies globally.\n\n\n*** FBI and Department of State designation ***\nThe U.S. State Department Rewards for Justice Program is offering $10 million for tips leading that lead to the apprehension of the four named \"Berserk Bear\" suspects.\n\nQ: Who are the accused participants of Berserk Bear and what are their current statuses according to the United States Department of Justice?",
    "context": "",
    "output": "A: Four accused Berserk Bear participants, three FSB staff and one civilian, have been indicted in the United States and are regarded by the United States Department of Justice as fugitives.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Who are the accused participants of Berserk Bear and what are their current statuses according to the United States Department of Justice?",
      "answer": "Four accused Berserk Bear participants, three FSB staff and one civilian, have been indicted in the United States and are regarded by the United States Department of Justice as fugitives.",
      "context": "Berserk Bear\n\n==Introduction==\nBerserk Bear (aka Crouching Yeti, Dragonfly, Dragonfly 2.0, DYMALLOY, Energetic Bear, Havex, IRON LIBERTY, Koala, or TeamSpy) is a Russian cyber espionage group, sometimes known as an advanced persistent threat. According to the United States, the group is composed of \"FSB hackers,\" either those directly employed by the FSB or Russian civilian, criminal hackers coerced into contracting as FSB hackers while still freelancing or moonlighting as criminal hackers. Four accused Berserk Bear participants, three FSB staff and one civilian, have been indicted in the United States and are regarded by the United States Department of Justice as fugitives.\n\n== Activities ==\nBerserk Bear specializes in compromising utilities infrastructure, especially that belonging to companies responsible for water or energy distribution. It has performed these activities in at least Germany and the U.S. These operations are targeted towards surveillance and technical reconnaissance.Berserk Bear has also targeted many state, local, and tribal government and aviation networks in the U.S., and as of October 1, 2020, had exfiltrated data from at least two victim servers. In particular, Berserk Bear is believed to have infiltrated the computer network of the city of Austin, Texas, during 2020.The group is capable of producing its own advanced malware, although it sometimes seeks to mimic other hacking groups and conceal its activities.\n\n== Indictments unsealed 2022 ==\nIn 2021 federal grand juries in the United States indicted three personnel of the Russian Federal Security Service (FSB) and a civilian from the Central Research Institute of Chemistry and Mechanics (CNIIHM). These indictments were kept under seal until March 2022 when the United States publicly named the defendants and treated them as fugitives.\n\n\n*** Evgeny Gladkikh ***\nEvgeny Gladkikh (Russian: \u0415\u0432\u0433\u0435\u043d\u0438\u0439 \u0413\u043b\u0430\u0434\u043a\u0438\u0445): is accused of targeting network-connected safety equipment with the intent to gain the capability to sabotage them. He was indicted in the U.S. District Court for the District of Columbia\n\n\n*** \"Center 16\" defendants ***\nThe indictment in the case United States v. Akulov, et al. is focused on members of a team within \"Center 16\" (Russian: 16-\u0439 \u0426\u0435\u043d\u0442\u0440) an FSB component also known as Military Unit 71330 (Russian: B\u043e\u0439\u0441\u043a\u043e\u0432\u0430\u044f \u0447\u0430\u0441\u0442\u044c B/\u0427 71330).\nThe British Foreign Office states that the full name of Center 16 is \"Radio-Electronic Intelligence by Means of Communication\" (TsRRSS); Russian: \u0426\u0435\u043d\u0442\u0440 \u0440\u0430\u0434\u0438\u043e\u044d\u043b\u0435\u043a\u0442\u0440\u043e\u043d\u043d\u043e\u0439 \u0440\u0430\u0437\u0432\u0435\u0434\u043a\u0438 \u043d\u0430 \u0441\u0440\u0435\u0434\u0441\u0442\u0432\u0430\u0445 \u0441\u0432\u044f\u0437\u0438 (\u0426PPCC)The U.S. v. Akulov case was filed within the United States District Court for the District of Kansas. The named defendants are:\n\nPavel Aleksandrovich Akulov (Russian: \u041f\u0430\u0432\u0435\u043b \u0410\u043b\u0435\u043a\u0441\u0430\u043d\u0434\u0440\u043e\u0432\u0438\u0447 \u0410\u043a\u0443\u043b\u043e\u0432, b. 2 July 1985) is described as a military officer assigned to Military Unit 71330, who held the rank of lieutenant as of 2013. Akulov is described as conducting surveillance and reconnaissance supporting the targeting of the Wolf Creek Generating Station computer network.\nMikhail Mikhailovich Gavrilov (Russian: \u041c\u0438\u0445\u0430\u0438\u043b \u041c\u0438\u0445\u0430\u0439\u043b\u043e\u0432\u0438\u0447 \u0413\u0430\u0432\u0440\u0438\u043b\u043e\u0432, b. 7 November 1979) is described as Russian military intelligence officer assigned to Military Unit 71330. He has held the rank of captain and major. He is described as conducting computer intrusions into the computer networks of Wolf Creek and another unnamed entity (\"Company 7\") used to access energy, utility and critical infrastructure webmail login webpages.\nMarat Valeryevich Tyukov (Russian: \u041c\u0430\u0440\u0430\u0442 \u0412\u0430\u043b\u0435\u0440\u044c\u0435\u0432\u0438\u0447 \u0422\u044e\u043a\u043e\u0432, b. 17 November 1982) is described as a Russian military intelligence officer assigned to Military Unit 71330. He is alleged to have gained unauthorized access to a server owned by an unnamed entity (\"Company One\") that was used for command and control infrastructure. He is also accused of tampering with updates to industrial control software which affected power and energy companies globally.\n\n\n*** FBI and Department of State designation ***\nThe U.S. State Department Rewards for Justice Program is offering $10 million for tips leading that lead to the apprehension of the four named \"Berserk Bear\" suspects."
    }
  },
  {
    "instruction": "2011 PlayStation Network outage\n\n==Introduction==\nThe 2011 PlayStation Network outage (sometimes referred to as the PSN Hack) was the result of an \"external intrusion\" on Sony's PlayStation Network and Qriocity services, in which personal details from approximately 77 million accounts were compromised and prevented users of PlayStation 3 and PlayStation Portable consoles from accessing the service. The attack occurred between April 17 and April 19, 2011, forcing Sony to deactivate the PlayStation Network servers on April 20. On May 4, Sony confirmed that personally identifiable information from each of the 77 million accounts had been exposed. The outage lasted 23 days.At the time of the outage, with a count of 77 million registered PlayStation Network accounts, it was not only one of the largest data security breaches, but also the longest PS Network outage in history. It surpassed the 2007 TJX hack which affected 45 million customers. Government officials in various countries voiced concern over the theft and Sony's one-week delay before warning its users.\nSony stated on April 26 that it was attempting to get online services running \"within a week.\" On May 14, Sony released PlayStation 3 firmware version 3.61 as a security patch. The firmware required users to change their account's password upon signing in. At the time the firmware was released, the network was still offline. Regional restoration was announced by Kazuo Hirai in a video from Sony. A map of regional restoration and the network within the United States was shared as the service was coming back online.\n\n== Prelude ==\nIn March 2010, Sony had released a firmware update for the PlayStation 3, which had patched functionality to use 3rd Party Operating Systems, such as Linux, on the System. This had caused outrage in the System's modding community, as the 3rd Party Operating Systems were used frequently in modification.\nOn January 2, 2011, George Hotz had successfully jailbroke the PlayStation 3 firmware. A day later, he had started distributing the jailbreak through his website.\nOn January 11, 2011, Sony had filed a lawsuit against Hotz, for distributing software to jailbreak their systems on his website.On April 2, 2011, a group of hackers claiming to be Anonymous, had declared \"Operation Sony\". Later the same week, On April 11, Sony had dropped the lawsuit with Hotz.On April 13, the group had released a video in text to speech, calling for \"A day of Sony Protest\".\n\n== Timeline of the outage ==\nOn April 20, 2011, Sony acknowledged on the official PlayStation Blog that it was \"aware certain functions of the PlayStation Network\" were down. Upon attempting to sign in via the PlayStation 3, users received a message indicating that the network was \"undergoing maintenance\". The following day, Sony asked its customers for patience while the cause of outage was investigated and stated that it may take \"a full day or two\" to get the service fully functional again.The company later announced an \"external intrusion\" had affected the PlayStation Network and Qriocity services. This intrusion occurred between April 17 and April 19. On April 20, Sony suspended all PlayStation Network and Qriocity services worldwide. Sony expressed their regrets for the downtime and called the task of repairing the system \"time-consuming\" but would lead to a stronger network infrastructure and additional security. On April 25, Sony spokesman Patrick Seybold reiterated on the PlayStation Blog that fixing and enhancing the network was a \"time intensive\" process with no estimated time of completion. However, the next day Sony stated that there was a \"clear path to have PlayStation Network and Qriocity systems back online\", with some services expected to be restored within a week. Furthermore, Sony acknowledged the \"compromise of personal information as a result of an illegal intrusion on our systems.\"On May 1 Sony announced a \"Welcome Back\" program for customers affected by the outage. The company also confirmed that some PSN and Qriocity services would be available during the first week of May. The list of services expected to become available included:\n\nRestoration of Online game-play across the PlayStation 3 (PS3) and PSP (PlayStation Portable) systems\nThis includes titles requiring online verification and downloaded games\nAccess to Music Unlimited powered by Qriocity for PS3/PSP for existing subscribers\nAccess to account management and password reset\nAccess to download un-expired Movie Rentals on PS3, PSP and MediaGo\nPlayStation Home\nFriends List\nChat Functionality\nOn May 2 Sony issued a press release, according to which the Sony Online Entertainment (SOE) services had been taken offline for maintenance due to potentially related activities during the initial criminal hack. Over 12,000 credit card numbers, albeit in encrypted form, from non-U.S. cardholders and additional information from 24.7 million SOE accounts may have been accessed.During the week, Sony sent a letter to the US House of Representatives, answering questions and concerns about the event. In the letter Sony announced that they would be providing Identity Theft insurance policies in the amount of US$1 million per user of the PlayStation Network and Qriocity services, despite no reports of credit card fraud being indicated. This was later confirmed on the PlayStation Blog, where it was announced that the service, AllClear ID Plus powered by Debix, would be available to users in the United States free for 12 months, and would include Internet surveillance, complete identity repair in the event of theft and a $1 million identity theft insurance policy for each user.On May 6 Sony stated they had begun \"final stages of internal testing\" for the PlayStation Network, which had been rebuilt. However, the following day Sony reported that they would not be able to bring services back online within the one-week timeframe given on May 1, because \"the extent of the attack on Sony Online Entertainment servers\" had not been known at the time. SOE confirmed on their Twitter account that their games would not be available until some time after the weekend.Reuters began reporting the event as \"the biggest Internet security break-in ever\". A Sony spokesperson said:\nSony had removed the personal details of 2,500 people stolen by hackers and posted on a website\nThe data included names and some addresses, which were in a database created in 2001\nNo date had been fixed for the restartOn May 14 various services began coming back online on a country-by-country basis, starting with North America. These services included: sign-in for PSN and Qriocity services (including password resetting), online game-play on PS3 and PSP, playback of rental video content, Music Unlimited service (PS3 and PC), access to third party services (such as Netflix, Hulu, Vudu and MLB.tv), friends list, chat functionality and PlayStation Home. The actions came with a firmware update for the PS3, version 3.61. As of May 15 service in Japan and East Asia had not yet been approved.On May 18 SOE shut down the password reset page on their site following the discovery of another exploit that allowed users to reset other users' passwords, using the other user's email address and date of birth. Sign-in using PSN details to various other Sony websites was also disabled, but console sign-ins were not affected.On May 23 Sony stated that the outage costs were $171 million.\n\n== Sony response ==\n\n\n*** US House of Representatives ***\nSony reported on May 4 to the PlayStation Blog that:\n\nKazuo Hirai, Chairman of the Board of Directors of Sony Computer Entertainment America, submitted written answers to questions posed by the United States House subcommittee about the large-scale, criminal cyber-attack we have experienced.\nSony relayed via the letter that:\n\nIn summary, we told the subcommittee that in dealing with this cyber attack we followed four key principles:\nAct with care and caution.\nProvide relevant information to the public when it has been verified.\nTake responsibility for our obligations to our customers.\nWork with law enforcement authorities.\nWe also informed the subcommittee of the following:\n\nSony has been the victim of a very carefully planned, very professional, highly sophisticated criminal cyber attack.\nWe discovered that the intruders had planted a file on one of our Sony Online Entertainment servers named \u201cAnonymous\u201d with the words \u201cWe are Legion.\u201d\nBy April 25, forensic teams were able to confirm the scope of the personal data they believed had been taken, and could not rule out whether credit card information had been accessed. On April 26, we notified customers of those facts.\nAs of today, the major credit card companies have not reported any fraudulent transactions that they believe are the direct result of this cyber attack.\nProtecting individuals\u2019 personal data is the highest priority and ensuring that the Internet can be made secure for commerce is also essential. Worldwide, countries and businesses will have to come together to ensure the safety of commerce over the Internet and find ways to combat cybercrime and cyber terrorism.\nWe are taking a number of steps to prevent future breaches, including enhanced levels of data protection and encryption; enhanced ability to detect software intrusions, unauthorized access and unusual activity patterns; additional firewalls; establishment of a new data center in an undisclosed location with increased security; and the naming of a new Chief Information Security Officer.\n\n\n*** Explanation of delays ***\nOn April 26, 2011 Sony explained on the PlayStation Blog why it took so long to inform PSN users of the data theft:\nThere\u2019s a difference in timing between when we identified there was an intrusion and when we learned of consumers\u2019 data being compromised. We learned there was an intrusion April 19th and subsequently shut the services down. We then brought in outside experts to help us learn how the intrusion occurred and to conduct an investigation to determine the nature and scope of the incident. It was necessary to conduct several days of forensic analysis, and it took our experts until yesterday to understand the scope of the breach. We then shared that information with our consumers and announced it publicly this afternoon.\n\n\n*** Sony investigation ***\nPossible data theft led Sony to provide an update in regards to a criminal investigation in a blog posted on April 27: \"We are currently working with law enforcement on this matter as well as a recognized technology security firm to conduct a complete investigation. This malicious attack against our system and against our customers is a criminal act and we are proceeding aggressively to find those responsible.\"On May 3 Sony Computer Entertainment CEO Kazuo Hirai reiterated this and said the \"external intrusion\" which had caused them to shut down the PlayStation Network constituted a \"criminal cyber attack\". Hirai expanded further, claiming that Sony systems had been under attack prior to the outage \"for the past month and half\", suggesting a concerted attempt to target Sony.On May 4 Sony announced that it was adding Data Forte to the investigation team of Guidance Software and Protiviti in analysing the attacks. Legal aspects of the case were handled by Baker & McKenzie. Sony stated their belief that Anonymous, a decentralized unorganized loosely affiliated group of hackers and activists may have performed the attack. No Anons claimed any involvement.Upon learning that a breach had occurred, Sony launched an internal investigation. Sony reported, in its letter to the United States Congress:\n\nOne of our first calls was to the FBI, and this is an active, on-going investigation.\nHave you identified how the breach occurred?\n\nYes, we believe so. Sony Network Entertainment America is continuing its investigation into this criminal intrusion, and more detailed information could be discovered during this process. We are reluctant to make full details publicly available because the information is the subject of an on-going criminal investigation and also the information could be used to exploit vulnerabilities in systems other than Sony's that have similar architecture to the PlayStation Network.\n\n\n*** Inability to use PlayStation 3 content ***\nWhile most games remained playable in their offline modes, the PlayStation 3 was unable to play certain Capcom titles in any form. Streaming video providers throughout different regions such as Hulu, Vudu, Netflix and LoveFilm displayed the same maintenance message. Some users claimed to be able to use Netflix's streaming service  but others were unable.\n\n== Criticism of Sony ==\n\n\n*** Delayed warning of possible data theft ***\n\nOn April 26, nearly a week after the outage, Sony confirmed that it \"cannot rule out the possibility\" that personally identifiable information such as PlayStation Network account username, password, home address, and email address had been compromised. Sony also mentioned the possibility that credit card data was taken\u2014after claiming that encryption had been placed on the databases, which would partially satisfy PCI Compliance for storing credit card information on a server.\nSubsequent to the announcement on both the official blog and by e-mail, users were asked to safeguard credit card transactions by checking bank statements. This warning came nearly a week after the initial \"external intrusion\" and while the Network was turned off.Some disputed this explanation and queried that if Sony deemed the situation so severe that they had to turn off the network, Sony should have warned users of possible data theft sooner than on April 26. Concerns have been raised over violations of PCI Compliance and the failure to immediately notify users. US Senator Richard Blumenthal wrote to Sony Computer Entertainment America CEO Jack Tretton questioning the delay.Sony replied in a letter to the subcommittee:\n\nYour statement indicated you have no evidence at this time that credit card information was obtained, yet you cannot rule out this possibility. Please explain why you do not believe credit card information was obtained and why you cannot determine if the data was in fact taken.\nAs stated above, Sony Network Entertainment America has not been able to conclude with certainty through the forensic analysis done to date that credit card information was not transferred from the PlayStation Network system. We know that for other personal information contained in the account database, the hacker made queries to the database, and the external forensics teams have seen large amounts of data transferred in response to those queries. Our forensics teams have not seen the queries and corresponding data transfers of the credit card information.\n\n\n*** Unencrypted personal details ***\nCredit card data was encrypted, but Sony admitted that other user information was not encrypted at the time of the intrusion. The Daily Telegraph reported that \"If the provider stores passwords unencrypted, then it's very easy for somebody else \u2013 not just an external attacker, but members of staff or contractors working on Sony's site \u2013 to get access and discover those passwords, potentially using them for nefarious means.\"\nOn May 2, Sony clarified the \"unencrypted\" status of users' passwords, stating that:\nWhile the passwords that were stored were not \u201cencrypted,\u201d they were transformed using a cryptographic hash function. There is a difference between these two types of security measures which is why we said the passwords had not been encrypted. But I want to be very clear that the passwords were not stored in our database in cleartext form.\n\n\n*** British Information Commissioner's Office ***\nFollowing a formal investigation of Sony for breaches of the UK's Data Protection Act 1998, the Information Commissioner's Office issued a statement highly critical of the security Sony had in place:\n\nIf you are responsible for so many payment card details and log-in details then keeping that personal data secure has to be your priority. In this case that just didn't happen, and when the database was targeted \u2013 albeit in a determined criminal attack \u2013 the security measures in place were simply not good enough.\nThere's no disguising that this is a business that should have known better. It is a company that trades on its technical expertise, and there's no doubt in my mind that they had access to both the technical knowledge and the resources to keep this information safe.\nSony was fined \u00a3250,000 ($395k) for security measures so poor they did not comply with the British law.\n\n== Sony Online Entertainment outage ==\nOn May 3 Sony stated in a press release that there may be a correlation between the attack that had occurred on April 16 towards the PlayStation Network and one that compromised Sony Online Entertainment on May 2. This portion of the attack resulted in the theft of information on 24.6 million Sony Online Entertainment account holders. The database contained 12,700 credit card numbers, particularly those of non-U.S. residents, and had not been in use since 2007 as much of the data applied to expired cards and deleted accounts. Sony updated this information the following day by stating that only 900 cards on the database were still valid. The attack resulted in the suspension of SOE servers and Facebook games. SOE granted 30 days of free time, plus one day for each day the server was down, to users of Clone Wars Adventures, DC Universe Online, EverQuest, EverQuest II, EverQuest Online Adventures, Free Realms, Pirates of the Burning Sea, PlanetSide, Poxnora, Star Wars Galaxies and Vanguard: Saga of Heroes, as well as other forms of compensation for all other Sony Online games.\nSecurity experts Eugene Lapidous of AnchorFree, Chester Wisniewski of Sophos Canada and Avner Levin of Ryerson University (now Toronto Metropolitan University) criticized Sony, questioning its methods of securing user data. Lapidous called the breach \"difficult to excuse\" and Wisniewski called it \"an act of hubris or simply gross incompetence\".\n\n== Reaction ==\n\n\n*** Compensation to users ***\nSony hosted special events after the PlayStation Network returned to service. Sony stated that they had plans for PS3 versions of DC Universe Online and Free Realms to help alleviate some of their losses. In a press conference in Tokyo on May 1, Sony announced a \"Welcome Back\" program. As well as \"selected PlayStation entertainment content\" the program promised to include 30 days free membership of PlayStation Plus for all PSN members, while existing PlayStation Plus members received an additional 30 days on their subscription. Qriocity subscribers received 30 days. Sony promised other content and services over the coming weeks. Sony offered one year free identity theft protection to all users with details forthcoming.\nHulu compensated PlayStation 3 users for the inability to use their service during the outage by offering one week of free service to Hulu Plus members.On May 16, 2011, Sony announced that two PlayStation 3 games and two PSP games would be offered for free from lists of five and four,\u2020 respectively. The games available varied by region and were only available in countries which had access to the PlayStation Store prior to the outage. On May 27, 2011, Sony announced the \"welcome back\" package for Japan and the Asia region (Hong Kong, Singapore, Malaysia, Thailand and Indonesia). In the Asia region, a theme - Dokodemo Issyo Spring Theme - was offered for free in addition to the games available in the \"welcome back\" package.^\u2020  5 PSP games are offered in the Japanese market.\n\n^\u2021  Version of Killzone Liberation offered does not offer online gameplay functionality.\n\n\n*** Government reaction ***\nThe data theft concerned authorities around the world. Graham Cluley, senior technology consultant at Sophos, said the breach \"certainly ranks as one of the biggest data losses ever to affect individuals\".The British Information Commissioner's Office stated that Sony would be questioned, and that an investigation would take place to discover whether Sony had taken adequate precautions to protect customer details. Under the UK's Data Protection Act, Sony was fined \u00a3250,000 for the breach.Privacy Commissioner of Canada Jennifer Stoddart confirmed that the Canadian authorities would investigate. The Commissioner's office conveyed their concern as to why the authorities in Canada weren't informed of a security breach earlier.US Senator Richard Blumenthal of Connecticut demanded answers from Sony about the data breach by emailing SCEA CEO Jack Tretton arguing about the delay in informing its customers and insisting that Sony do more for its customers than just offer free credit reporting services. Blumenthal later called for an investigation by the US Department of Justice to find the person or persons responsible and to determine if Sony was liable for the way that it handled the situation.Congresswoman Mary Bono Mack and Congressman G. K. Butterfield sent a letter to Sony, demanding information on when the breach was discovered and how the crisis would be handled.Sony had been asked to testify before a congressional hearing on security and to answer questions about the breach of security on May 2, but sent a written response instead.\n\n\n*** Legal action against Sony ***\nA lawsuit was posted on April 27 by Kristopher Johns from Birmingham, Alabama on behalf of all PlayStation users alleging Sony \"failed to encrypt data and establish adequate firewalls to handle a server intrusion contingency, failed to provide prompt and adequate warnings of security breaches, and unreasonably delayed in bringing the PSN service back online.\" According to the complaint filed in the lawsuit, Sony failed to notify members of a possible security breach and storing members' credit card information, a violation of PCI Compliance\u2014the digital security standard for the Payment Card Industry.\nA Canadian lawsuit against Sony USA, Sony Canada and Sony Japan claimed damages up to C$1 billion including free credit monitoring and identity theft insurance. The plaintiff was quoted as saying, \"If you can't trust a huge multi-national corporation like Sony to protect your private information, who can you trust? It appears to me that Sony focuses more on protecting its games than its PlayStation users\".In October 2012 a California judge dismissed a lawsuit against Sony over the PSN security breach, ruling that Sony had not violated California's consumer-protection laws, citing \"there is no such thing as perfect security\".In 2013 United Kingdom Information Commissioner's Office charged Sony with a \u00a3250,000 penalty for putting a large amount of personal and financial data of PSN clients  at risk.\n\n\n*** Credit card fraud ***\nAs of May 2011, there were no verifiable reports of credit card fraud related to the outage. There were reports on the Internet that some PlayStation users experienced credit card fraud; however, they were yet to be linked to the incident. Users who registered a credit card for use only with Sony also reported credit card fraud. Sony said that the CSC codes requested by their services were not stored, but hackers may have been able to decrypt or record credit card details while inside Sony's network.Sony stated in their letter to the subcommittee:\n\nHow many PlayStation Network account holders provided credit card information to Sony Computer Entertainment?\nGlobally, approximately 12.3 million account holders had credit card information on file on the PlayStation Network system. In the United States, approximately 5.6 million account holders had credit card information on file on the system. These numbers include active and expired credit cards.\n\nAs of today, the major credit card companies have not reported that they have seen any increase in the number of fraudulent credit card transactions as a result of the attack, and they have not reported to us any fraudulent transactions that they believe are a direct result of the intrusions described above.\nOn May 5, a letter from Sony Corporation of America CEO and President Sir Howard Stringer emphasized that there had been no evidence of credit card fraud and that a $1 million identity theft insurance policy would be available to PSN and Qriocity users:\nTo date, there is no confirmed evidence any credit card or personal information has been misused, and we continue to monitor the situation closely. We are also moving ahead with plans to help protect our customers from identity theft around the world. A program for U.S. PlayStation Network and Qriocity customers that includes a $1 million identity theft insurance policy per user was launched earlier today and announcements for other regions will be coming soon.\n\n== Change to terms and conditions ==\nIt has been suggested that a change to the PSN terms and conditions announced on September 15, 2011, was motivated by the large damages being claimed by class action suits against Sony, in an effort to minimise the company's losses. The new agreement required users to agree to give up their right (to join together as a group in a class action) to sue Sony over any future security breach, without first trying to resolve legal issues with an arbitrator. This included any ongoing class action suits initiated prior to August 20, 2011.\nAnother clause, which removed a user's right to trial by jury should the user opt out of the clause (by sending a letter to Sony), says:\n\nIf the Class Action Waiver clause is found to be illegal or unenforceable, this entire Section 15 will be unenforceable, and the dispute will be decided by a court and you and the Sony Entity you have a dispute with each agree to waive in that instance, to the fullest extent allowed by law, any trial by jury.\nSony guaranteed that a court of law in the respective country, in this case the US, would hold jurisdiction in regards to any rules or changes in the Sony PSN ToS:\nThese Terms of Service and all questions relating to the performance, interpretation, breach or enforcement of these Terms of Service, or the rights, obligations and liabilities of you and us under them are governed by the laws of the State of California.  You agree that all disputes, claims or litigation arising from or related in any way to these Terms of Service and our relationship with you will be litigated only in a court of competent jurisdiction located in San Mateo County, State of California.  You agree to be subject to personal jurisdiction and venue in that location.\nRead the text above and answer this question: What was the impact of the 2011 PlayStation Network outage on the availability of certain Capcom titles and streaming video providers on the PlayStation 3?",
    "context": "",
    "output": "The outage made it impossible for PlayStation 3 users to play certain Capcom titles in any form. Streaming video providers such as Hulu, Vudu, Netflix, and LoveFilm also displayed maintenance messages, with some users unable to access their services.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was the impact of the 2011 PlayStation Network outage on the availability of certain Capcom titles and streaming video providers on the PlayStation 3?",
      "answer": "The outage made it impossible for PlayStation 3 users to play certain Capcom titles in any form. Streaming video providers such as Hulu, Vudu, Netflix, and LoveFilm also displayed maintenance messages, with some users unable to access their services.",
      "context": "2011 PlayStation Network outage\n\n==Introduction==\nThe 2011 PlayStation Network outage (sometimes referred to as the PSN Hack) was the result of an \"external intrusion\" on Sony's PlayStation Network and Qriocity services, in which personal details from approximately 77 million accounts were compromised and prevented users of PlayStation 3 and PlayStation Portable consoles from accessing the service. The attack occurred between April 17 and April 19, 2011, forcing Sony to deactivate the PlayStation Network servers on April 20. On May 4, Sony confirmed that personally identifiable information from each of the 77 million accounts had been exposed. The outage lasted 23 days.At the time of the outage, with a count of 77 million registered PlayStation Network accounts, it was not only one of the largest data security breaches, but also the longest PS Network outage in history. It surpassed the 2007 TJX hack which affected 45 million customers. Government officials in various countries voiced concern over the theft and Sony's one-week delay before warning its users.\nSony stated on April 26 that it was attempting to get online services running \"within a week.\" On May 14, Sony released PlayStation 3 firmware version 3.61 as a security patch. The firmware required users to change their account's password upon signing in. At the time the firmware was released, the network was still offline. Regional restoration was announced by Kazuo Hirai in a video from Sony. A map of regional restoration and the network within the United States was shared as the service was coming back online.\n\n== Prelude ==\nIn March 2010, Sony had released a firmware update for the PlayStation 3, which had patched functionality to use 3rd Party Operating Systems, such as Linux, on the System. This had caused outrage in the System's modding community, as the 3rd Party Operating Systems were used frequently in modification.\nOn January 2, 2011, George Hotz had successfully jailbroke the PlayStation 3 firmware. A day later, he had started distributing the jailbreak through his website.\nOn January 11, 2011, Sony had filed a lawsuit against Hotz, for distributing software to jailbreak their systems on his website.On April 2, 2011, a group of hackers claiming to be Anonymous, had declared \"Operation Sony\". Later the same week, On April 11, Sony had dropped the lawsuit with Hotz.On April 13, the group had released a video in text to speech, calling for \"A day of Sony Protest\".\n\n== Timeline of the outage ==\nOn April 20, 2011, Sony acknowledged on the official PlayStation Blog that it was \"aware certain functions of the PlayStation Network\" were down. Upon attempting to sign in via the PlayStation 3, users received a message indicating that the network was \"undergoing maintenance\". The following day, Sony asked its customers for patience while the cause of outage was investigated and stated that it may take \"a full day or two\" to get the service fully functional again.The company later announced an \"external intrusion\" had affected the PlayStation Network and Qriocity services. This intrusion occurred between April 17 and April 19. On April 20, Sony suspended all PlayStation Network and Qriocity services worldwide. Sony expressed their regrets for the downtime and called the task of repairing the system \"time-consuming\" but would lead to a stronger network infrastructure and additional security. On April 25, Sony spokesman Patrick Seybold reiterated on the PlayStation Blog that fixing and enhancing the network was a \"time intensive\" process with no estimated time of completion. However, the next day Sony stated that there was a \"clear path to have PlayStation Network and Qriocity systems back online\", with some services expected to be restored within a week. Furthermore, Sony acknowledged the \"compromise of personal information as a result of an illegal intrusion on our systems.\"On May 1 Sony announced a \"Welcome Back\" program for customers affected by the outage. The company also confirmed that some PSN and Qriocity services would be available during the first week of May. The list of services expected to become available included:\n\nRestoration of Online game-play across the PlayStation 3 (PS3) and PSP (PlayStation Portable) systems\nThis includes titles requiring online verification and downloaded games\nAccess to Music Unlimited powered by Qriocity for PS3/PSP for existing subscribers\nAccess to account management and password reset\nAccess to download un-expired Movie Rentals on PS3, PSP and MediaGo\nPlayStation Home\nFriends List\nChat Functionality\nOn May 2 Sony issued a press release, according to which the Sony Online Entertainment (SOE) services had been taken offline for maintenance due to potentially related activities during the initial criminal hack. Over 12,000 credit card numbers, albeit in encrypted form, from non-U.S. cardholders and additional information from 24.7 million SOE accounts may have been accessed.During the week, Sony sent a letter to the US House of Representatives, answering questions and concerns about the event. In the letter Sony announced that they would be providing Identity Theft insurance policies in the amount of US$1 million per user of the PlayStation Network and Qriocity services, despite no reports of credit card fraud being indicated. This was later confirmed on the PlayStation Blog, where it was announced that the service, AllClear ID Plus powered by Debix, would be available to users in the United States free for 12 months, and would include Internet surveillance, complete identity repair in the event of theft and a $1 million identity theft insurance policy for each user.On May 6 Sony stated they had begun \"final stages of internal testing\" for the PlayStation Network, which had been rebuilt. However, the following day Sony reported that they would not be able to bring services back online within the one-week timeframe given on May 1, because \"the extent of the attack on Sony Online Entertainment servers\" had not been known at the time. SOE confirmed on their Twitter account that their games would not be available until some time after the weekend.Reuters began reporting the event as \"the biggest Internet security break-in ever\". A Sony spokesperson said:\nSony had removed the personal details of 2,500 people stolen by hackers and posted on a website\nThe data included names and some addresses, which were in a database created in 2001\nNo date had been fixed for the restartOn May 14 various services began coming back online on a country-by-country basis, starting with North America. These services included: sign-in for PSN and Qriocity services (including password resetting), online game-play on PS3 and PSP, playback of rental video content, Music Unlimited service (PS3 and PC), access to third party services (such as Netflix, Hulu, Vudu and MLB.tv), friends list, chat functionality and PlayStation Home. The actions came with a firmware update for the PS3, version 3.61. As of May 15 service in Japan and East Asia had not yet been approved.On May 18 SOE shut down the password reset page on their site following the discovery of another exploit that allowed users to reset other users' passwords, using the other user's email address and date of birth. Sign-in using PSN details to various other Sony websites was also disabled, but console sign-ins were not affected.On May 23 Sony stated that the outage costs were $171 million.\n\n== Sony response ==\n\n\n*** US House of Representatives ***\nSony reported on May 4 to the PlayStation Blog that:\n\nKazuo Hirai, Chairman of the Board of Directors of Sony Computer Entertainment America, submitted written answers to questions posed by the United States House subcommittee about the large-scale, criminal cyber-attack we have experienced.\nSony relayed via the letter that:\n\nIn summary, we told the subcommittee that in dealing with this cyber attack we followed four key principles:\nAct with care and caution.\nProvide relevant information to the public when it has been verified.\nTake responsibility for our obligations to our customers.\nWork with law enforcement authorities.\nWe also informed the subcommittee of the following:\n\nSony has been the victim of a very carefully planned, very professional, highly sophisticated criminal cyber attack.\nWe discovered that the intruders had planted a file on one of our Sony Online Entertainment servers named \u201cAnonymous\u201d with the words \u201cWe are Legion.\u201d\nBy April 25, forensic teams were able to confirm the scope of the personal data they believed had been taken, and could not rule out whether credit card information had been accessed. On April 26, we notified customers of those facts.\nAs of today, the major credit card companies have not reported any fraudulent transactions that they believe are the direct result of this cyber attack.\nProtecting individuals\u2019 personal data is the highest priority and ensuring that the Internet can be made secure for commerce is also essential. Worldwide, countries and businesses will have to come together to ensure the safety of commerce over the Internet and find ways to combat cybercrime and cyber terrorism.\nWe are taking a number of steps to prevent future breaches, including enhanced levels of data protection and encryption; enhanced ability to detect software intrusions, unauthorized access and unusual activity patterns; additional firewalls; establishment of a new data center in an undisclosed location with increased security; and the naming of a new Chief Information Security Officer.\n\n\n*** Explanation of delays ***\nOn April 26, 2011 Sony explained on the PlayStation Blog why it took so long to inform PSN users of the data theft:\nThere\u2019s a difference in timing between when we identified there was an intrusion and when we learned of consumers\u2019 data being compromised. We learned there was an intrusion April 19th and subsequently shut the services down. We then brought in outside experts to help us learn how the intrusion occurred and to conduct an investigation to determine the nature and scope of the incident. It was necessary to conduct several days of forensic analysis, and it took our experts until yesterday to understand the scope of the breach. We then shared that information with our consumers and announced it publicly this afternoon.\n\n\n*** Sony investigation ***\nPossible data theft led Sony to provide an update in regards to a criminal investigation in a blog posted on April 27: \"We are currently working with law enforcement on this matter as well as a recognized technology security firm to conduct a complete investigation. This malicious attack against our system and against our customers is a criminal act and we are proceeding aggressively to find those responsible.\"On May 3 Sony Computer Entertainment CEO Kazuo Hirai reiterated this and said the \"external intrusion\" which had caused them to shut down the PlayStation Network constituted a \"criminal cyber attack\". Hirai expanded further, claiming that Sony systems had been under attack prior to the outage \"for the past month and half\", suggesting a concerted attempt to target Sony.On May 4 Sony announced that it was adding Data Forte to the investigation team of Guidance Software and Protiviti in analysing the attacks. Legal aspects of the case were handled by Baker & McKenzie. Sony stated their belief that Anonymous, a decentralized unorganized loosely affiliated group of hackers and activists may have performed the attack. No Anons claimed any involvement.Upon learning that a breach had occurred, Sony launched an internal investigation. Sony reported, in its letter to the United States Congress:\n\nOne of our first calls was to the FBI, and this is an active, on-going investigation.\nHave you identified how the breach occurred?\n\nYes, we believe so. Sony Network Entertainment America is continuing its investigation into this criminal intrusion, and more detailed information could be discovered during this process. We are reluctant to make full details publicly available because the information is the subject of an on-going criminal investigation and also the information could be used to exploit vulnerabilities in systems other than Sony's that have similar architecture to the PlayStation Network.\n\n\n*** Inability to use PlayStation 3 content ***\nWhile most games remained playable in their offline modes, the PlayStation 3 was unable to play certain Capcom titles in any form. Streaming video providers throughout different regions such as Hulu, Vudu, Netflix and LoveFilm displayed the same maintenance message. Some users claimed to be able to use Netflix's streaming service  but others were unable.\n\n== Criticism of Sony ==\n\n\n*** Delayed warning of possible data theft ***\n\nOn April 26, nearly a week after the outage, Sony confirmed that it \"cannot rule out the possibility\" that personally identifiable information such as PlayStation Network account username, password, home address, and email address had been compromised. Sony also mentioned the possibility that credit card data was taken\u2014after claiming that encryption had been placed on the databases, which would partially satisfy PCI Compliance for storing credit card information on a server.\nSubsequent to the announcement on both the official blog and by e-mail, users were asked to safeguard credit card transactions by checking bank statements. This warning came nearly a week after the initial \"external intrusion\" and while the Network was turned off.Some disputed this explanation and queried that if Sony deemed the situation so severe that they had to turn off the network, Sony should have warned users of possible data theft sooner than on April 26. Concerns have been raised over violations of PCI Compliance and the failure to immediately notify users. US Senator Richard Blumenthal wrote to Sony Computer Entertainment America CEO Jack Tretton questioning the delay.Sony replied in a letter to the subcommittee:\n\nYour statement indicated you have no evidence at this time that credit card information was obtained, yet you cannot rule out this possibility. Please explain why you do not believe credit card information was obtained and why you cannot determine if the data was in fact taken.\nAs stated above, Sony Network Entertainment America has not been able to conclude with certainty through the forensic analysis done to date that credit card information was not transferred from the PlayStation Network system. We know that for other personal information contained in the account database, the hacker made queries to the database, and the external forensics teams have seen large amounts of data transferred in response to those queries. Our forensics teams have not seen the queries and corresponding data transfers of the credit card information.\n\n\n*** Unencrypted personal details ***\nCredit card data was encrypted, but Sony admitted that other user information was not encrypted at the time of the intrusion. The Daily Telegraph reported that \"If the provider stores passwords unencrypted, then it's very easy for somebody else \u2013 not just an external attacker, but members of staff or contractors working on Sony's site \u2013 to get access and discover those passwords, potentially using them for nefarious means.\"\nOn May 2, Sony clarified the \"unencrypted\" status of users' passwords, stating that:\nWhile the passwords that were stored were not \u201cencrypted,\u201d they were transformed using a cryptographic hash function. There is a difference between these two types of security measures which is why we said the passwords had not been encrypted. But I want to be very clear that the passwords were not stored in our database in cleartext form.\n\n\n*** British Information Commissioner's Office ***\nFollowing a formal investigation of Sony for breaches of the UK's Data Protection Act 1998, the Information Commissioner's Office issued a statement highly critical of the security Sony had in place:\n\nIf you are responsible for so many payment card details and log-in details then keeping that personal data secure has to be your priority. In this case that just didn't happen, and when the database was targeted \u2013 albeit in a determined criminal attack \u2013 the security measures in place were simply not good enough.\nThere's no disguising that this is a business that should have known better. It is a company that trades on its technical expertise, and there's no doubt in my mind that they had access to both the technical knowledge and the resources to keep this information safe.\nSony was fined \u00a3250,000 ($395k) for security measures so poor they did not comply with the British law.\n\n== Sony Online Entertainment outage ==\nOn May 3 Sony stated in a press release that there may be a correlation between the attack that had occurred on April 16 towards the PlayStation Network and one that compromised Sony Online Entertainment on May 2. This portion of the attack resulted in the theft of information on 24.6 million Sony Online Entertainment account holders. The database contained 12,700 credit card numbers, particularly those of non-U.S. residents, and had not been in use since 2007 as much of the data applied to expired cards and deleted accounts. Sony updated this information the following day by stating that only 900 cards on the database were still valid. The attack resulted in the suspension of SOE servers and Facebook games. SOE granted 30 days of free time, plus one day for each day the server was down, to users of Clone Wars Adventures, DC Universe Online, EverQuest, EverQuest II, EverQuest Online Adventures, Free Realms, Pirates of the Burning Sea, PlanetSide, Poxnora, Star Wars Galaxies and Vanguard: Saga of Heroes, as well as other forms of compensation for all other Sony Online games.\nSecurity experts Eugene Lapidous of AnchorFree, Chester Wisniewski of Sophos Canada and Avner Levin of Ryerson University (now Toronto Metropolitan University) criticized Sony, questioning its methods of securing user data. Lapidous called the breach \"difficult to excuse\" and Wisniewski called it \"an act of hubris or simply gross incompetence\".\n\n== Reaction ==\n\n\n*** Compensation to users ***\nSony hosted special events after the PlayStation Network returned to service. Sony stated that they had plans for PS3 versions of DC Universe Online and Free Realms to help alleviate some of their losses. In a press conference in Tokyo on May 1, Sony announced a \"Welcome Back\" program. As well as \"selected PlayStation entertainment content\" the program promised to include 30 days free membership of PlayStation Plus for all PSN members, while existing PlayStation Plus members received an additional 30 days on their subscription. Qriocity subscribers received 30 days. Sony promised other content and services over the coming weeks. Sony offered one year free identity theft protection to all users with details forthcoming.\nHulu compensated PlayStation 3 users for the inability to use their service during the outage by offering one week of free service to Hulu Plus members.On May 16, 2011, Sony announced that two PlayStation 3 games and two PSP games would be offered for free from lists of five and four,\u2020 respectively. The games available varied by region and were only available in countries which had access to the PlayStation Store prior to the outage. On May 27, 2011, Sony announced the \"welcome back\" package for Japan and the Asia region (Hong Kong, Singapore, Malaysia, Thailand and Indonesia). In the Asia region, a theme - Dokodemo Issyo Spring Theme - was offered for free in addition to the games available in the \"welcome back\" package.^\u2020  5 PSP games are offered in the Japanese market.\n\n^\u2021  Version of Killzone Liberation offered does not offer online gameplay functionality.\n\n\n*** Government reaction ***\nThe data theft concerned authorities around the world. Graham Cluley, senior technology consultant at Sophos, said the breach \"certainly ranks as one of the biggest data losses ever to affect individuals\".The British Information Commissioner's Office stated that Sony would be questioned, and that an investigation would take place to discover whether Sony had taken adequate precautions to protect customer details. Under the UK's Data Protection Act, Sony was fined \u00a3250,000 for the breach.Privacy Commissioner of Canada Jennifer Stoddart confirmed that the Canadian authorities would investigate. The Commissioner's office conveyed their concern as to why the authorities in Canada weren't informed of a security breach earlier.US Senator Richard Blumenthal of Connecticut demanded answers from Sony about the data breach by emailing SCEA CEO Jack Tretton arguing about the delay in informing its customers and insisting that Sony do more for its customers than just offer free credit reporting services. Blumenthal later called for an investigation by the US Department of Justice to find the person or persons responsible and to determine if Sony was liable for the way that it handled the situation.Congresswoman Mary Bono Mack and Congressman G. K. Butterfield sent a letter to Sony, demanding information on when the breach was discovered and how the crisis would be handled.Sony had been asked to testify before a congressional hearing on security and to answer questions about the breach of security on May 2, but sent a written response instead.\n\n\n*** Legal action against Sony ***\nA lawsuit was posted on April 27 by Kristopher Johns from Birmingham, Alabama on behalf of all PlayStation users alleging Sony \"failed to encrypt data and establish adequate firewalls to handle a server intrusion contingency, failed to provide prompt and adequate warnings of security breaches, and unreasonably delayed in bringing the PSN service back online.\" According to the complaint filed in the lawsuit, Sony failed to notify members of a possible security breach and storing members' credit card information, a violation of PCI Compliance\u2014the digital security standard for the Payment Card Industry.\nA Canadian lawsuit against Sony USA, Sony Canada and Sony Japan claimed damages up to C$1 billion including free credit monitoring and identity theft insurance. The plaintiff was quoted as saying, \"If you can't trust a huge multi-national corporation like Sony to protect your private information, who can you trust? It appears to me that Sony focuses more on protecting its games than its PlayStation users\".In October 2012 a California judge dismissed a lawsuit against Sony over the PSN security breach, ruling that Sony had not violated California's consumer-protection laws, citing \"there is no such thing as perfect security\".In 2013 United Kingdom Information Commissioner's Office charged Sony with a \u00a3250,000 penalty for putting a large amount of personal and financial data of PSN clients  at risk.\n\n\n*** Credit card fraud ***\nAs of May 2011, there were no verifiable reports of credit card fraud related to the outage. There were reports on the Internet that some PlayStation users experienced credit card fraud; however, they were yet to be linked to the incident. Users who registered a credit card for use only with Sony also reported credit card fraud. Sony said that the CSC codes requested by their services were not stored, but hackers may have been able to decrypt or record credit card details while inside Sony's network.Sony stated in their letter to the subcommittee:\n\nHow many PlayStation Network account holders provided credit card information to Sony Computer Entertainment?\nGlobally, approximately 12.3 million account holders had credit card information on file on the PlayStation Network system. In the United States, approximately 5.6 million account holders had credit card information on file on the system. These numbers include active and expired credit cards.\n\nAs of today, the major credit card companies have not reported that they have seen any increase in the number of fraudulent credit card transactions as a result of the attack, and they have not reported to us any fraudulent transactions that they believe are a direct result of the intrusions described above.\nOn May 5, a letter from Sony Corporation of America CEO and President Sir Howard Stringer emphasized that there had been no evidence of credit card fraud and that a $1 million identity theft insurance policy would be available to PSN and Qriocity users:\nTo date, there is no confirmed evidence any credit card or personal information has been misused, and we continue to monitor the situation closely. We are also moving ahead with plans to help protect our customers from identity theft around the world. A program for U.S. PlayStation Network and Qriocity customers that includes a $1 million identity theft insurance policy per user was launched earlier today and announcements for other regions will be coming soon.\n\n== Change to terms and conditions ==\nIt has been suggested that a change to the PSN terms and conditions announced on September 15, 2011, was motivated by the large damages being claimed by class action suits against Sony, in an effort to minimise the company's losses. The new agreement required users to agree to give up their right (to join together as a group in a class action) to sue Sony over any future security breach, without first trying to resolve legal issues with an arbitrator. This included any ongoing class action suits initiated prior to August 20, 2011.\nAnother clause, which removed a user's right to trial by jury should the user opt out of the clause (by sending a letter to Sony), says:\n\nIf the Class Action Waiver clause is found to be illegal or unenforceable, this entire Section 15 will be unenforceable, and the dispute will be decided by a court and you and the Sony Entity you have a dispute with each agree to waive in that instance, to the fullest extent allowed by law, any trial by jury.\nSony guaranteed that a court of law in the respective country, in this case the US, would hold jurisdiction in regards to any rules or changes in the Sony PSN ToS:\nThese Terms of Service and all questions relating to the performance, interpretation, breach or enforcement of these Terms of Service, or the rights, obligations and liabilities of you and us under them are governed by the laws of the State of California.  You agree that all disputes, claims or litigation arising from or related in any way to these Terms of Service and our relationship with you will be litigated only in a court of competent jurisdiction located in San Mateo County, State of California.  You agree to be subject to personal jurisdiction and venue in that location."
    }
  },
  {
    "instruction": "Context: SpamBayes\n\n==Introduction==\nSpamBayes is a Bayesian spam filter written in Python which uses techniques laid out by Paul Graham in his essay \"A Plan for Spam\". It has subsequently been improved by Gary Robinson and Tim Peters, among others.\nThe most notable difference between a conventional Bayesian filter and the filter used by SpamBayes is that there are three classifications rather than two: spam, non-spam (called ham in SpamBayes), and unsure. The user trains a message as being either ham or spam; when filtering a message, the spam filters generate one score for ham and another for spam.\nIf the spam score is high and the ham score is low, the message will be classified as spam.\nIf the spam score is low and the ham score is high, the message will be classified as ham.\nIf the scores are both high or both low, the message will be classified as unsure.\nThis approach leads to a low number of false positives and false negatives, but it may result in a number of unsures which need a human decision.\n\n== Web filtering ==\nSome work has gone into applying SpamBayes to filter internet content via a proxy web server.\nAnswer this question: What is the role of the user in SpamBayes classification process?",
    "context": "",
    "output": "The user plays an important role in SpamBayes classification process by training messages as ham or spam, and making a decision for messages classified as unsure.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of the user in SpamBayes classification process?",
      "answer": "The user plays an important role in SpamBayes classification process by training messages as ham or spam, and making a decision for messages classified as unsure.",
      "context": "SpamBayes\n\n==Introduction==\nSpamBayes is a Bayesian spam filter written in Python which uses techniques laid out by Paul Graham in his essay \"A Plan for Spam\". It has subsequently been improved by Gary Robinson and Tim Peters, among others.\nThe most notable difference between a conventional Bayesian filter and the filter used by SpamBayes is that there are three classifications rather than two: spam, non-spam (called ham in SpamBayes), and unsure. The user trains a message as being either ham or spam; when filtering a message, the spam filters generate one score for ham and another for spam.\nIf the spam score is high and the ham score is low, the message will be classified as spam.\nIf the spam score is low and the ham score is high, the message will be classified as ham.\nIf the scores are both high or both low, the message will be classified as unsure.\nThis approach leads to a low number of false positives and false negatives, but it may result in a number of unsures which need a human decision.\n\n== Web filtering ==\nSome work has gone into applying SpamBayes to filter internet content via a proxy web server."
    }
  },
  {
    "instruction": "Forensic search\n\n==Introduction==\nForensic search is an emerging field of computer forensics. Forensic search focuses on user created data such as email files, cell phone records, office documents, PDFs and other files that are easily interpreted by a person.\nForensic search differs from computer forensic analysis in that it does not seek to review or analyze the lower level system files such as the registry, link files or disk level issues more commonly associated with traditional computer forensic analysis.\n\n\n\n== Purpose ==\nForensic search has emerged due to a number of factors including:\n\nImprovements in technologies to enable lesser qualified users to undertake search and analysis of data that would have previously been undertaken only by a computer forensic expert. (This trend can be seen in many industries).\nA need to reduce the high cost of undertaking a full computer forensic analysis of a user's computer, when in most cases the evidence found in the user created data is most useful and all that is required.\nThe rise of Cloud computing which has seen a move away from data storage on local computer hardware to data storage in any number of remote locations.\nA lack of qualified computer forensic experts\nThe need to address the backlog of cases in most policing agencies where computer-based information requires review.\nThe need to involve other types of expertise for proper assessment of evidence, e.g. knowledge of accounting regulations, legal knowledge, etc.\n\n== Objectives ==\nThe objective of forensic search software is to allow a person with only a general knowledge of computers, but skilled in document review or investigation techniques, to undertake and search user created electronically stored information (ESI). Data that is typically considered to be user created ESI is made up of emails, documents, pictures and other file types created by a user, as opposed to data created by the computer's operating system (i.e. registry files, link files, unallocated space.  These are controlled or created by the computer and not the user). The objective of reviewing the user created data is to find information that may be used to base decisions on as part of an investigation.\n\n== Forensic search software ==\nForensic search software differs from using the native applications (e.g. Outlook) or desktop search software (e.g. Google Desktop) to search the data in that no changes are made to the data during processing or searching that may impact the results or skew the findings. Forensic search software will also allow access to the base metadata of items not available via the native application. A good example of this would be the metadata in MS Word documents.  A number of forensic search software products will be able to perform data recovery on a range of email file types.\nSome examples of how using the native application or non-forensic application can affect the data:\n\nOpening a Microsoft Word document in Microsoft Word may change the created, modified or last accessed dates in the document. This could lead to the incorrect dates being supplied in evidence.\nReviewing data in some native applications will trigger the systems antivirus software, again changing data or altering evidence.\nFailure to freeze the evidence prior to opening the files, coupled with the fact that merely opening the files changes them, can and has invalidated critical evidence.Forensic search software has become popular as a method of reducing the time and cost of search and analysis of larger data sets by focusing on the user data that most often yields evidence or results.E-mail tends to be personal, plentiful and candid. For most adults, e-mail is their primary means of written communication and is often sought after for evidence. A new generation of tools is being developed in order to address the challenges being faced by digital forensic and ediscovery practitioners.\n\n== Other types of review ==\nForensic search software has been likened to eDiscovery review software, however this is not strictly the case. eDiscovery review software, while dealing with many of the same type of computer records and search options, offer extra functionality to that of forensic search software. Features such as redaction and legal hold are standard in eDiscovery review software. It is also the case that Forensic Search software does not meet with the higher end tasks outlined in the widely accepted electronic discovery reference model (EDRM). Tasks such as identification, collection, reservation or presentation are generally not covered by forensic search software.However, true eDiscovery review is generally the domain of qualified legal practitioners or companies.The use of the term eDiscovery has become a catchall in some circles for the processing and searching of electronically stored information (ESI). However, this is not a true representation of the term of eDiscovery. For a more detailed understanding of eDiscovery, the Electronic Discovery Reference Model (EDRM) is a good guideline.\nIt could be said that forensic search is more closely related to early case assessment (ECA) than eDiscovery as ECA does not require the rigor of a full eDiscovery review.\n\n== Evidence value of user created data versus other types of data ==\nWhen presenting data as part of a report that may be used to form a decision or as evidence, it is important that the data be correctly represented so the reader can understand it. In the case of generating reports on system created data such as registry files, link files and other system created data this can be a costly exercise. It can also be the case that there is no straightforward answer or explanation.An example of this would be attempting to explain to a lay person the method and techniques of decoding the UserAssist Key in the Windows system registry. The UserAssist key can hold a great deal of information about the actions of the user of the computer. However to explain this key, the reviewer has to be able to identify the key and correctly interpret the key setting. The keys are often encoded by ROT 13.Once these keys are decoded to human readable formats, the reviewer then has to show how a setting relates to the case.  It is often time-consuming to review hundreds, even thousands, of settings that at times only deliver very circumstantial and sometimes contentious findings. When reviewing user created data such as e-mail or contracts, reporting and understanding the findings is often much more straight forward. The semi skilled user will usually have a good grasp of how email works as they use it in their day-to-day work. A person trained in law will understand a contract and does not need specialist forensic knowledge to do so. This can lead to much lower costs of review and less contentious or circumstantial findings.\n\n== High-level functionality of forensic search software ==\nThe features of forensic search software are focused on allowing the user to search and view a range of data and users\u2019 files at one time.\nSpecific features of forensic search software include:\nThe ability to process varying types of data enabling it to be searched by the reviewer with little or no computer forensic knowledge\nKeyword searching across all data and data types processed\nThe ability to create complex searches such as including or excluding data\nUsing MD5 and other algorithms to search and identify files and data\nThe ability to filter based on metadata such as dates, email addresses and file types\nThe ability to review different data typed in the same search results\nThe ability to view all results in the same user interface\nThe ability to export items to various formats i.e. email, Word, HTML\nThe ability to create shareable reports\n\n== Changes in computer forensics ==\nThere are many newer and emerging fields of computer forensics such as Cloud forensics, mobile phone forensics, network forensics, memory analysis, browser forensics, forensic triage and internet forensics. In the not so distant past a computer forensic expert's most common role was to attend a person's house, place of work or data center to forensically \"image\" all computers or devices that may be involved in a case. This was categorized as the collection phase.Once collection phase was complete these images were reviewed and the ESI that was relevant was supplied to the interested parties. This required the computer forensic investigator to have a good deal of experience and training in:\n\nIdentifying which computer, applications or devices may be involved\nHow to disassemble a computer and extract the hard drives of the computer without causing damage.\nHow to correctly take a forensic image to keep chain of custody\nHow to use the forensic analysis software to correctly interpret and supply the resultsThis process was time-consuming and costly.  The computer forensic expert's primary role is to investigate the computer evidence (ESI).  They may not have been as familiar with the entire case or objectives as that of the case agent, detective, forensic accountant or crime analyst. This often led to non-perfect or time-consuming identification of the correct evidence items between the differing parties. What would immediately flag the interest of a detective with a deep knowledge of the case and parties involved may go unnoticed by a computer forensic expert. An example would be an email from a suspect in another case to a suspect in this case, or contact / phone calls to a witness from a suspect.To compound the issue, there has been a massive increase in the size of the data that the computer forensic expert needs to collect. It is now often the case that the computer hard drive is not able to be imaged, for example if the computer that contains the evidence is too big, or the system cannot be shut down to take an image as it is a mission critical server such as an email server or company file server. The rise of Cloud computing has also added challenges to the collection of evidence. The data that requires collection and review may reside in the Cloud. In this case there is no computer available to image.  The forensic expert then needs to collect the information using forensic software designed to work with certain Cloud providers.In short the collection of evidence has changed significantly in the past few years. Recognizing these challenges, the concept of Hybrid Forensics has been discussed and the creation of tools that adopt a different approach to collecting data. The concept of Hybrid Forensics is the selective collection of data from 'live' systems in such a way that is may be considered as being reliable evidence in court.\n\n== Barriers to the adoption of forensic search in law enforcement ==\nLaw enforcement organizations like many other organizations are divided into skill specific units. In the computer forensic / cybercrime area these units take responsibility for all aspects of the ESI. These units are usually time poor and under resourced.Albeit that time and resources are low the main knowledge in the unit comes from officers or consultants with 7+ years of experience (this predates most computer forensic degrees available). These officers have become familiar over time with the methodology of using a forensic analysis software package as this is all that was on offer when they started in the field. Hence when new officers or resources become available it is forensic analysis software that is prioritized over newer more specific software and newer forensic field types.\n\nBased on the above text, answer a question. What are some barriers to the adoption of forensic search in law enforcement?",
    "context": "",
    "output": "Some barriers to the adoption of forensic search in law enforcement include the division of organizations into skill-specific units, time poverty, under-resourcing, the prioritization of forensic analysis software over newer more specific software, and the lack of familiarity with newer forensic field types.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are some barriers to the adoption of forensic search in law enforcement?",
      "answer": "Some barriers to the adoption of forensic search in law enforcement include the division of organizations into skill-specific units, time poverty, under-resourcing, the prioritization of forensic analysis software over newer more specific software, and the lack of familiarity with newer forensic field types.",
      "context": "Forensic search\n\n==Introduction==\nForensic search is an emerging field of computer forensics. Forensic search focuses on user created data such as email files, cell phone records, office documents, PDFs and other files that are easily interpreted by a person.\nForensic search differs from computer forensic analysis in that it does not seek to review or analyze the lower level system files such as the registry, link files or disk level issues more commonly associated with traditional computer forensic analysis.\n\n\n\n== Purpose ==\nForensic search has emerged due to a number of factors including:\n\nImprovements in technologies to enable lesser qualified users to undertake search and analysis of data that would have previously been undertaken only by a computer forensic expert. (This trend can be seen in many industries).\nA need to reduce the high cost of undertaking a full computer forensic analysis of a user's computer, when in most cases the evidence found in the user created data is most useful and all that is required.\nThe rise of Cloud computing which has seen a move away from data storage on local computer hardware to data storage in any number of remote locations.\nA lack of qualified computer forensic experts\nThe need to address the backlog of cases in most policing agencies where computer-based information requires review.\nThe need to involve other types of expertise for proper assessment of evidence, e.g. knowledge of accounting regulations, legal knowledge, etc.\n\n== Objectives ==\nThe objective of forensic search software is to allow a person with only a general knowledge of computers, but skilled in document review or investigation techniques, to undertake and search user created electronically stored information (ESI). Data that is typically considered to be user created ESI is made up of emails, documents, pictures and other file types created by a user, as opposed to data created by the computer's operating system (i.e. registry files, link files, unallocated space.  These are controlled or created by the computer and not the user). The objective of reviewing the user created data is to find information that may be used to base decisions on as part of an investigation.\n\n== Forensic search software ==\nForensic search software differs from using the native applications (e.g. Outlook) or desktop search software (e.g. Google Desktop) to search the data in that no changes are made to the data during processing or searching that may impact the results or skew the findings. Forensic search software will also allow access to the base metadata of items not available via the native application. A good example of this would be the metadata in MS Word documents.  A number of forensic search software products will be able to perform data recovery on a range of email file types.\nSome examples of how using the native application or non-forensic application can affect the data:\n\nOpening a Microsoft Word document in Microsoft Word may change the created, modified or last accessed dates in the document. This could lead to the incorrect dates being supplied in evidence.\nReviewing data in some native applications will trigger the systems antivirus software, again changing data or altering evidence.\nFailure to freeze the evidence prior to opening the files, coupled with the fact that merely opening the files changes them, can and has invalidated critical evidence.Forensic search software has become popular as a method of reducing the time and cost of search and analysis of larger data sets by focusing on the user data that most often yields evidence or results.E-mail tends to be personal, plentiful and candid. For most adults, e-mail is their primary means of written communication and is often sought after for evidence. A new generation of tools is being developed in order to address the challenges being faced by digital forensic and ediscovery practitioners.\n\n== Other types of review ==\nForensic search software has been likened to eDiscovery review software, however this is not strictly the case. eDiscovery review software, while dealing with many of the same type of computer records and search options, offer extra functionality to that of forensic search software. Features such as redaction and legal hold are standard in eDiscovery review software. It is also the case that Forensic Search software does not meet with the higher end tasks outlined in the widely accepted electronic discovery reference model (EDRM). Tasks such as identification, collection, reservation or presentation are generally not covered by forensic search software.However, true eDiscovery review is generally the domain of qualified legal practitioners or companies.The use of the term eDiscovery has become a catchall in some circles for the processing and searching of electronically stored information (ESI). However, this is not a true representation of the term of eDiscovery. For a more detailed understanding of eDiscovery, the Electronic Discovery Reference Model (EDRM) is a good guideline.\nIt could be said that forensic search is more closely related to early case assessment (ECA) than eDiscovery as ECA does not require the rigor of a full eDiscovery review.\n\n== Evidence value of user created data versus other types of data ==\nWhen presenting data as part of a report that may be used to form a decision or as evidence, it is important that the data be correctly represented so the reader can understand it. In the case of generating reports on system created data such as registry files, link files and other system created data this can be a costly exercise. It can also be the case that there is no straightforward answer or explanation.An example of this would be attempting to explain to a lay person the method and techniques of decoding the UserAssist Key in the Windows system registry. The UserAssist key can hold a great deal of information about the actions of the user of the computer. However to explain this key, the reviewer has to be able to identify the key and correctly interpret the key setting. The keys are often encoded by ROT 13.Once these keys are decoded to human readable formats, the reviewer then has to show how a setting relates to the case.  It is often time-consuming to review hundreds, even thousands, of settings that at times only deliver very circumstantial and sometimes contentious findings. When reviewing user created data such as e-mail or contracts, reporting and understanding the findings is often much more straight forward. The semi skilled user will usually have a good grasp of how email works as they use it in their day-to-day work. A person trained in law will understand a contract and does not need specialist forensic knowledge to do so. This can lead to much lower costs of review and less contentious or circumstantial findings.\n\n== High-level functionality of forensic search software ==\nThe features of forensic search software are focused on allowing the user to search and view a range of data and users\u2019 files at one time.\nSpecific features of forensic search software include:\nThe ability to process varying types of data enabling it to be searched by the reviewer with little or no computer forensic knowledge\nKeyword searching across all data and data types processed\nThe ability to create complex searches such as including or excluding data\nUsing MD5 and other algorithms to search and identify files and data\nThe ability to filter based on metadata such as dates, email addresses and file types\nThe ability to review different data typed in the same search results\nThe ability to view all results in the same user interface\nThe ability to export items to various formats i.e. email, Word, HTML\nThe ability to create shareable reports\n\n== Changes in computer forensics ==\nThere are many newer and emerging fields of computer forensics such as Cloud forensics, mobile phone forensics, network forensics, memory analysis, browser forensics, forensic triage and internet forensics. In the not so distant past a computer forensic expert's most common role was to attend a person's house, place of work or data center to forensically \"image\" all computers or devices that may be involved in a case. This was categorized as the collection phase.Once collection phase was complete these images were reviewed and the ESI that was relevant was supplied to the interested parties. This required the computer forensic investigator to have a good deal of experience and training in:\n\nIdentifying which computer, applications or devices may be involved\nHow to disassemble a computer and extract the hard drives of the computer without causing damage.\nHow to correctly take a forensic image to keep chain of custody\nHow to use the forensic analysis software to correctly interpret and supply the resultsThis process was time-consuming and costly.  The computer forensic expert's primary role is to investigate the computer evidence (ESI).  They may not have been as familiar with the entire case or objectives as that of the case agent, detective, forensic accountant or crime analyst. This often led to non-perfect or time-consuming identification of the correct evidence items between the differing parties. What would immediately flag the interest of a detective with a deep knowledge of the case and parties involved may go unnoticed by a computer forensic expert. An example would be an email from a suspect in another case to a suspect in this case, or contact / phone calls to a witness from a suspect.To compound the issue, there has been a massive increase in the size of the data that the computer forensic expert needs to collect. It is now often the case that the computer hard drive is not able to be imaged, for example if the computer that contains the evidence is too big, or the system cannot be shut down to take an image as it is a mission critical server such as an email server or company file server. The rise of Cloud computing has also added challenges to the collection of evidence. The data that requires collection and review may reside in the Cloud. In this case there is no computer available to image.  The forensic expert then needs to collect the information using forensic software designed to work with certain Cloud providers.In short the collection of evidence has changed significantly in the past few years. Recognizing these challenges, the concept of Hybrid Forensics has been discussed and the creation of tools that adopt a different approach to collecting data. The concept of Hybrid Forensics is the selective collection of data from 'live' systems in such a way that is may be considered as being reliable evidence in court.\n\n== Barriers to the adoption of forensic search in law enforcement ==\nLaw enforcement organizations like many other organizations are divided into skill specific units. In the computer forensic / cybercrime area these units take responsibility for all aspects of the ESI. These units are usually time poor and under resourced.Albeit that time and resources are low the main knowledge in the unit comes from officers or consultants with 7+ years of experience (this predates most computer forensic degrees available). These officers have become familiar over time with the methodology of using a forensic analysis software package as this is all that was on offer when they started in the field. Hence when new officers or resources become available it is forensic analysis software that is prioritized over newer more specific software and newer forensic field types."
    }
  },
  {
    "instruction": "Woo\u2013Lam\n\n==Introduction==\nIn cryptography, Woo\u2013Lam refers to various computer network authentication protocols designed by Simon S. Lam and Thomas Woo. The protocols enable two communicating parties to authenticate each other's identity and to exchange session keys, and involve the use of a trusted key distribution center (KDC) to negotiate between the parties. Both symmetric-key and public-key variants have been described. However, the protocols suffer from various security flaws, and in part have been described as being inefficient compared to alternative authentication protocols.\n\n== Public-key protocol ==\n\n\n*** Notation ***\nThe following notation is used to describe the algorithm:\n\n  \n    \n      \n        A\n        ,\n        B\n      \n    \n    {\\displaystyle A,B}\n   - network nodes.\n\n  \n    \n      \n        K\n        \n          U\n          \n            x\n          \n        \n      \n    \n    {\\displaystyle KU_{x}}\n   - public key of node \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  .\n\n  \n    \n      \n        K\n        \n          R\n          \n            x\n          \n        \n      \n    \n    {\\displaystyle KR_{x}}\n   - private key of \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  .\n\n  \n    \n      \n        \n          N\n          \n            x\n          \n        \n      \n    \n    {\\displaystyle N_{x}}\n   - nonce chosen by \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  .\n\n  \n    \n      \n        I\n        \n          D\n          \n            x\n          \n        \n      \n    \n    {\\displaystyle ID_{x}}\n   - unique identifier of \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  .\n\n  \n    \n      \n        \n          E\n          \n            k\n          \n        \n      \n    \n    {\\displaystyle E_{k}}\n   - public-key encryption using key \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  .\n\n  \n    \n      \n        \n          S\n          \n            k\n          \n        \n      \n    \n    {\\displaystyle S_{k}}\n   - digital signature using key \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  .\n\n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n   - random session key chosen by the KDC.\n\n  \n    \n      \n        \n          |\n        \n        \n          |\n        \n      \n    \n    {\\displaystyle ||}\n   - concatenation.It is assumed that all parties know the KDC's public key.\n\n\n*** Message exchange ***\n\n  \n    \n      \n        1\n        )\n        A\n        \u2192\n        K\n        D\n        C\n        :\n        I\n        \n          D\n          \n            A\n          \n        \n        \n          |\n        \n        \n          |\n        \n        I\n        \n          D\n          \n            B\n          \n        \n      \n    \n    {\\displaystyle 1)A\\rightarrow KDC:ID_{A}||ID_{B}}\n  \n  \n    \n      \n        2\n        )\n        K\n        D\n        C\n        \u2192\n        A\n        :\n        \n          S\n          \n            K\n            \n              R\n              \n                K\n                D\n                C\n              \n            \n          \n        \n        [\n        I\n        \n          D\n          \n            B\n          \n        \n        \n          |\n        \n        \n          |\n        \n        K\n        \n          U\n          \n            B\n          \n        \n        ]\n      \n    \n    {\\displaystyle 2)KDC\\rightarrow A:S_{KR_{KDC}}[ID_{B}||KU_{B}]}\n  \n  \n    \n      \n        3\n        )\n        A\n        \u2192\n        B\n        :\n        \n          E\n          \n            K\n            \n              U\n              \n                B\n              \n            \n          \n        \n        [\n        \n          N\n          \n            A\n          \n        \n        \n          |\n        \n        \n          |\n        \n        I\n        \n          D\n          \n            A\n          \n        \n        ]\n      \n    \n    {\\displaystyle 3)A\\rightarrow B:E_{KU_{B}}[N_{A}||ID_{A}]}\n  \n  \n    \n      \n        4\n        )\n        B\n        \u2192\n        K\n        D\n        C\n        :\n        I\n        \n          D\n          \n            B\n          \n        \n        \n          |\n        \n        \n          |\n        \n        I\n        \n          D\n          \n            A\n          \n        \n        \n          |\n        \n        \n          |\n        \n        \n          E\n          \n            K\n            \n              U\n              \n                K\n                D\n                C\n              \n            \n          \n        \n        [\n        \n          N\n          \n            A\n          \n        \n        ]\n      \n    \n    {\\displaystyle 4)B\\rightarrow KDC:ID_{B}||ID_{A}||E_{KU_{KDC}}[N_{A}]}\n  \n  \n    \n      \n        5\n        )\n        K\n        D\n        C\n        \u2192\n        B\n        :\n        \n          S\n          \n            K\n            \n              R\n              \n                K\n                D\n                C\n              \n            \n          \n        \n        [\n        I\n        \n          D\n          \n            A\n          \n        \n        \n          |\n        \n        \n          |\n        \n        K\n        \n          U\n          \n            A\n          \n        \n        ]\n        \n          |\n        \n        \n          |\n        \n        \n          E\n          \n            K\n            \n              U\n              \n                B\n              \n            \n          \n        \n        [\n        \n          S\n          \n            K\n            \n              R\n              \n                K\n                D\n                C\n              \n            \n          \n        \n        [\n        \n          N\n          \n            A\n          \n        \n        \n          |\n        \n        \n          |\n        \n        K\n        \n          |\n        \n        \n          |\n        \n        I\n        \n          D\n          \n            B\n          \n        \n        \n          |\n        \n        \n          |\n        \n        I\n        \n          D\n          \n            A\n          \n        \n        ]\n        ]\n      \n    \n    {\\displaystyle 5)KDC\\rightarrow B:S_{KR_{KDC}}[ID_{A}||KU_{A}]||E_{KU_{B}}[S_{KR_{KDC}}[N_{A}||K||ID_{B}||ID_{A}]]}\n  \n  \n    \n      \n        6\n        )\n        B\n        \u2192\n        A\n        :\n        \n          E\n          \n            K\n            \n              U\n              \n                A\n              \n            \n          \n        \n        [\n        \n          S\n          \n            K\n            \n              R\n              \n                K\n                D\n                C\n              \n            \n          \n        \n        [\n        \n          N\n          \n            A\n          \n        \n        \n          |\n        \n        \n          |\n        \n        K\n        ]\n        \n          |\n        \n        \n          |\n        \n        \n          N\n          \n            B\n          \n        \n        ]\n      \n    \n    {\\displaystyle 6)B\\rightarrow A:E_{KU_{A}}[S_{KR_{KDC}}[N_{A}||K]||N_{B}]}\n  \n  \n    \n      \n        7\n        )\n        A\n        \u2192\n        B\n        :\n        \n          E\n          \n            K\n          \n        \n        [\n        \n          N\n          \n            B\n          \n        \n        ]\n      \n    \n    {\\displaystyle 7)A\\rightarrow B:E_{K}[N_{B}]}\n  The original version of the protocol had the identifier \n  \n    \n      \n        I\n        \n          D\n          \n            A\n          \n        \n      \n    \n    {\\displaystyle ID_{A}}\n   omitted from lines 5 and 6, which did not account for the fact that \n  \n    \n      \n        \n          N\n          \n            A\n          \n        \n      \n    \n    {\\displaystyle N_{A}}\n   is unique only among nonces generated by A and not by other parties. The protocol was revised after the authors themselves spotted a flaw in the algorithm.\nQuestion: What is the flaw in the original version of the Woo-Lam public-key protocol?",
    "context": "",
    "output": "Answer: The original version of the Woo-Lam public-key protocol did not account for the fact that the nonce NA is unique only among nonces generated by A and not by other parties, which could lead to security vulnerabilities.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the flaw in the original version of the Woo-Lam public-key protocol?",
      "answer": "The original version of the Woo-Lam public-key protocol did not account for the fact that the nonce NA is unique only among nonces generated by A and not by other parties, which could lead to security vulnerabilities.",
      "context": "Woo\u2013Lam\n\n==Introduction==\nIn cryptography, Woo\u2013Lam refers to various computer network authentication protocols designed by Simon S. Lam and Thomas Woo. The protocols enable two communicating parties to authenticate each other's identity and to exchange session keys, and involve the use of a trusted key distribution center (KDC) to negotiate between the parties. Both symmetric-key and public-key variants have been described. However, the protocols suffer from various security flaws, and in part have been described as being inefficient compared to alternative authentication protocols.\n\n== Public-key protocol ==\n\n\n*** Notation ***\nThe following notation is used to describe the algorithm:\n\n  \n    \n      \n        A\n        ,\n        B\n      \n    \n    {\\displaystyle A,B}\n   - network nodes.\n\n  \n    \n      \n        K\n        \n          U\n          \n            x\n          \n        \n      \n    \n    {\\displaystyle KU_{x}}\n   - public key of node \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  .\n\n  \n    \n      \n        K\n        \n          R\n          \n            x\n          \n        \n      \n    \n    {\\displaystyle KR_{x}}\n   - private key of \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  .\n\n  \n    \n      \n        \n          N\n          \n            x\n          \n        \n      \n    \n    {\\displaystyle N_{x}}\n   - nonce chosen by \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  .\n\n  \n    \n      \n        I\n        \n          D\n          \n            x\n          \n        \n      \n    \n    {\\displaystyle ID_{x}}\n   - unique identifier of \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  .\n\n  \n    \n      \n        \n          E\n          \n            k\n          \n        \n      \n    \n    {\\displaystyle E_{k}}\n   - public-key encryption using key \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  .\n\n  \n    \n      \n        \n          S\n          \n            k\n          \n        \n      \n    \n    {\\displaystyle S_{k}}\n   - digital signature using key \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  .\n\n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n   - random session key chosen by the KDC.\n\n  \n    \n      \n        \n          |\n        \n        \n          |\n        \n      \n    \n    {\\displaystyle ||}\n   - concatenation.It is assumed that all parties know the KDC's public key.\n\n\n*** Message exchange ***\n\n  \n    \n      \n        1\n        )\n        A\n        \u2192\n        K\n        D\n        C\n        :\n        I\n        \n          D\n          \n            A\n          \n        \n        \n          |\n        \n        \n          |\n        \n        I\n        \n          D\n          \n            B\n          \n        \n      \n    \n    {\\displaystyle 1)A\\rightarrow KDC:ID_{A}||ID_{B}}\n  \n  \n    \n      \n        2\n        )\n        K\n        D\n        C\n        \u2192\n        A\n        :\n        \n          S\n          \n            K\n            \n              R\n              \n                K\n                D\n                C\n              \n            \n          \n        \n        [\n        I\n        \n          D\n          \n            B\n          \n        \n        \n          |\n        \n        \n          |\n        \n        K\n        \n          U\n          \n            B\n          \n        \n        ]\n      \n    \n    {\\displaystyle 2)KDC\\rightarrow A:S_{KR_{KDC}}[ID_{B}||KU_{B}]}\n  \n  \n    \n      \n        3\n        )\n        A\n        \u2192\n        B\n        :\n        \n          E\n          \n            K\n            \n              U\n              \n                B\n              \n            \n          \n        \n        [\n        \n          N\n          \n            A\n          \n        \n        \n          |\n        \n        \n          |\n        \n        I\n        \n          D\n          \n            A\n          \n        \n        ]\n      \n    \n    {\\displaystyle 3)A\\rightarrow B:E_{KU_{B}}[N_{A}||ID_{A}]}\n  \n  \n    \n      \n        4\n        )\n        B\n        \u2192\n        K\n        D\n        C\n        :\n        I\n        \n          D\n          \n            B\n          \n        \n        \n          |\n        \n        \n          |\n        \n        I\n        \n          D\n          \n            A\n          \n        \n        \n          |\n        \n        \n          |\n        \n        \n          E\n          \n            K\n            \n              U\n              \n                K\n                D\n                C\n              \n            \n          \n        \n        [\n        \n          N\n          \n            A\n          \n        \n        ]\n      \n    \n    {\\displaystyle 4)B\\rightarrow KDC:ID_{B}||ID_{A}||E_{KU_{KDC}}[N_{A}]}\n  \n  \n    \n      \n        5\n        )\n        K\n        D\n        C\n        \u2192\n        B\n        :\n        \n          S\n          \n            K\n            \n              R\n              \n                K\n                D\n                C\n              \n            \n          \n        \n        [\n        I\n        \n          D\n          \n            A\n          \n        \n        \n          |\n        \n        \n          |\n        \n        K\n        \n          U\n          \n            A\n          \n        \n        ]\n        \n          |\n        \n        \n          |\n        \n        \n          E\n          \n            K\n            \n              U\n              \n                B\n              \n            \n          \n        \n        [\n        \n          S\n          \n            K\n            \n              R\n              \n                K\n                D\n                C\n              \n            \n          \n        \n        [\n        \n          N\n          \n            A\n          \n        \n        \n          |\n        \n        \n          |\n        \n        K\n        \n          |\n        \n        \n          |\n        \n        I\n        \n          D\n          \n            B\n          \n        \n        \n          |\n        \n        \n          |\n        \n        I\n        \n          D\n          \n            A\n          \n        \n        ]\n        ]\n      \n    \n    {\\displaystyle 5)KDC\\rightarrow B:S_{KR_{KDC}}[ID_{A}||KU_{A}]||E_{KU_{B}}[S_{KR_{KDC}}[N_{A}||K||ID_{B}||ID_{A}]]}\n  \n  \n    \n      \n        6\n        )\n        B\n        \u2192\n        A\n        :\n        \n          E\n          \n            K\n            \n              U\n              \n                A\n              \n            \n          \n        \n        [\n        \n          S\n          \n            K\n            \n              R\n              \n                K\n                D\n                C\n              \n            \n          \n        \n        [\n        \n          N\n          \n            A\n          \n        \n        \n          |\n        \n        \n          |\n        \n        K\n        ]\n        \n          |\n        \n        \n          |\n        \n        \n          N\n          \n            B\n          \n        \n        ]\n      \n    \n    {\\displaystyle 6)B\\rightarrow A:E_{KU_{A}}[S_{KR_{KDC}}[N_{A}||K]||N_{B}]}\n  \n  \n    \n      \n        7\n        )\n        A\n        \u2192\n        B\n        :\n        \n          E\n          \n            K\n          \n        \n        [\n        \n          N\n          \n            B\n          \n        \n        ]\n      \n    \n    {\\displaystyle 7)A\\rightarrow B:E_{K}[N_{B}]}\n  The original version of the protocol had the identifier \n  \n    \n      \n        I\n        \n          D\n          \n            A\n          \n        \n      \n    \n    {\\displaystyle ID_{A}}\n   omitted from lines 5 and 6, which did not account for the fact that \n  \n    \n      \n        \n          N\n          \n            A\n          \n        \n      \n    \n    {\\displaystyle N_{A}}\n   is unique only among nonces generated by A and not by other parties. The protocol was revised after the authors themselves spotted a flaw in the algorithm."
    }
  },
  {
    "instruction": "Context: Keycloak\n\n==Introduction==\nKeycloak is an open source software product to allow single sign-on with identity and access management aimed at modern applications and services.  As of March 2018 this WildFly community project is under the stewardship of Red Hat who use it as the upstream project for their RH-SSO product.\n\n\n\n== Features ==\nThe features of Keycloak include:\n\nUser registration\nSocial login\nSingle sign-on/sign-off across all applications belonging to the same realm\nTwo-factor authentication\nLDAP integration\nKerberos broker\nMultitenancy with per-realm customizable skin\nCustom extensions to extend the core functionality\n\n== Components ==\nThere are two main components of Keycloak:\n\nKeycloak server, including the API and graphical interface.\nKeycloak application adapter: a set of libraries to call the server.\nAnswer this question: How does Keycloak's LDAP integration benefit organizations?",
    "context": "",
    "output": "Keycloak's LDAP integration can benefit organizations by allowing them to leverage their existing LDAP infrastructure for user and group management. This can simplify the management of users and groups, and can also improve security by allowing for centralized control of user access.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does Keycloak's LDAP integration benefit organizations?",
      "answer": "Keycloak's LDAP integration can benefit organizations by allowing them to leverage their existing LDAP infrastructure for user and group management. This can simplify the management of users and groups, and can also improve security by allowing for centralized control of user access.",
      "context": "Keycloak\n\n==Introduction==\nKeycloak is an open source software product to allow single sign-on with identity and access management aimed at modern applications and services.  As of March 2018 this WildFly community project is under the stewardship of Red Hat who use it as the upstream project for their RH-SSO product.\n\n\n\n== Features ==\nThe features of Keycloak include:\n\nUser registration\nSocial login\nSingle sign-on/sign-off across all applications belonging to the same realm\nTwo-factor authentication\nLDAP integration\nKerberos broker\nMultitenancy with per-realm customizable skin\nCustom extensions to extend the core functionality\n\n== Components ==\nThere are two main components of Keycloak:\n\nKeycloak server, including the API and graphical interface.\nKeycloak application adapter: a set of libraries to call the server."
    }
  },
  {
    "instruction": "Write an answer to the following question: How can piggybackers take advantage of an authorized person's disregard for the law or rules?",
    "context": "",
    "output": "Piggybackers can take advantage of an authorized person's disregard for the law or rules by finding an authorized person who disregards the law or the rules of the facility and agreeably allows the piggybacker to tag along.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can piggybackers take advantage of an authorized person's disregard for the law or rules?",
      "answer": "Piggybackers can take advantage of an authorized person's disregard for the law or rules by finding an authorized person who disregards the law or the rules of the facility and agreeably allows the piggybacker to tag along."
    }
  },
  {
    "instruction": "Write an answer to the following question: What version of IObit's software was updated to address Malwarebytes' accusations?",
    "context": "",
    "output": "As of version 1.3, IObit's database was updated to address the accusations of intellectual property theft made earlier by Malwarebytes.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What version of IObit's software was updated to address Malwarebytes' accusations?",
      "answer": "As of version 1.3, IObit's database was updated to address the accusations of intellectual property theft made earlier by Malwarebytes."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does RPKI help in enforcing aggregation and preventing hijacking through the announcement of a more specific prefix?",
    "context": "",
    "output": "RPKI allows the members of regional Internet registries, known as local Internet registries (LIRs), to obtain a resource certificate listing the Internet number resources they hold. Using the resource certificate, LIRs can create cryptographic attestations about the route announcements they authorise to be made with the prefixes they hold. If the maximum length is not defined in the ROA, any more specific announcement of the prefix will be considered invalid, which enforces aggregation and prevents hijacking through the announcement of a more specific prefix.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does RPKI help in enforcing aggregation and preventing hijacking through the announcement of a more specific prefix?",
      "answer": "RPKI allows the members of regional Internet registries, known as local Internet registries (LIRs), to obtain a resource certificate listing the Internet number resources they hold. Using the resource certificate, LIRs can create cryptographic attestations about the route announcements they authorise to be made with the prefixes they hold. If the maximum length is not defined in the ROA, any more specific announcement of the prefix will be considered invalid, which enforces aggregation and prevents hijacking through the announcement of a more specific prefix."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the AHTCC combat international cybercrime?",
    "context": "",
    "output": "The AHTCC combats international cybercrime by working alongside large nations to develop plans of combat and being capable of managing domestic and international cybercrime. They have been successful in this field, as seen in cases such as 'Operation Carpo' and the arrest of an online Russian crime syndicate.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the AHTCC combat international cybercrime?",
      "answer": "The AHTCC combats international cybercrime by working alongside large nations to develop plans of combat and being capable of managing domestic and international cybercrime. They have been successful in this field, as seen in cases such as 'Operation Carpo' and the arrest of an online Russian crime syndicate."
    }
  },
  {
    "instruction": "USBKill\n\n==Introduction==\nUSBKill is anti-forensic software distributed via GitHub, written in Python for the BSD, Linux, and OS X operating systems. It is designed to serve as a kill switch if the computer on which it is installed should fall under the control of individuals or entities against the desires of the owner. It is free software, available under the GNU General Public License.The program's developer, who goes by the online name Hephaest0s, created it in response to the circumstances of the arrest of Silk Road founder Ross Ulbricht, during which U.S. federal agents were able to get access to incriminating evidence on his laptop without needing his cooperation by copying data from its flash drive after distracting him. It maintains a whitelist of devices allowed to connect to the computer's USB ports; if a device not on that whitelist connects, it can take actions ranging from merely returning to the lock screen to encrypting the hard drive, or wiping all data on the computer. However, it can also be used as part of a computer security regimen to prevent the surreptitious installation of malware or spyware or the clandestine duplication of files, according to its creator.\n\n== Background ==\nWhen law enforcement agencies began making computer crime arrests in the 1990s, they would often ask judges for no knock search warrants, to deny their targets time to delete incriminating evidence from computers or storage media. In more extreme circumstances where it was likely that the targets could get advance notice of arriving police, judges would grant \"power-off\" warrants, allowing utilities to turn off the electricity to the location of the raid shortly beforehand, further forestalling any efforts to destroy evidence before it could be seized. These methods were effective against criminals who produced and distributed pirated software and movies, which was the primary large-scale computer crime of the era.By the 2010s, the circumstances of computer crime had changed along with legitimate computer use. Criminals were more likely to use the Internet to facilitate their crimes, so they needed to remain online most of the time. To do so, and still keep their activities discreet, they used computer security features like lock screens and password protection.For those reasons, law enforcement now attempts to apprehend suspected cybercriminals with their computers on and in use, all accounts both on the computer and online open and logged in, and thus easily searchable. If they fail to seize the computer in that condition, there are some methods available to bypass password protection, but these may take more time than police have available. It might be legally impossible to compel the suspect to relinquish their password; in the United States, where many computer-crime investigations take place, courts have distinguished between forcing a suspect to use material means of protecting data such as a thumbprint, retinal scan, or key, as opposed to a password or passcode, which is purely the product of the suspect's mental processes and is thus protected from compelled disclosure by the Fifth Amendment.The usual technique for authorities\u2014either public entities such as law enforcement or private organizations like companies\u2014seizing a computer (usually a laptop) that they believe is being used improperly is first to physically separate the suspect user from the computer enough that they cannot touch it, to prevent them from closing its lid, unplugging it, or typing a command. Once they have done so, they often install a device in the USB port that spoofs minor actions of a mouse, touchpad, or keyboard, preventing the computer from going into sleep mode, from which it would usually return to a lock screen which would require a password.Agents with the U.S. Federal Bureau of Investigation (FBI) investigating Ross Ulbricht, founder of the online black market Silk Road, learned that he often ran the site from his laptop, using the wireless networks available at branches of the San Francisco Public Library. When they had enough evidence to arrest him, they planned to catch him in the act of running Silk Road, with his computer on and logged in. They needed to ensure he was unable to trigger encryption or delete evidence when they did.In October 2013, a male and female agent pretended to have a lovers' quarrel near where Ulbricht was working at the Glen Park branch. According to Business Insider, Ulbricht was distracted and got up to see what the problem was, whereupon the female agent grabbed his laptop while the male agent restrained Ulbricht. The female agent was then able to insert a flash drive into one of the laptop's USB ports, with software that copied key files. According to Joshuah Bearman of Wired, a third agent grabbed the laptop while Ulbricht was distracted by the apparent lovers' fight and handed it to agent Tom Kiernan.\n\n== Use ==\nIn response to the circumstances of Ulbricht's arrest, a programmer known as Hephaest0s developed the USBKill code in Python and uploaded it to GitHub in 2014. It is available as free software under the GNU General Public License and currently runs under both Linux and OS X.\nThe program, when installed, prompts the user to create a whitelist of devices that are allowed to connect to the computer via its USB ports, which it checks at an adjustable sample rate. The user may also choose what actions the computer will take if it detects a USB device not on the whitelist (by default, it shuts down and erases data from the RAM and swap file). Users need to be logged in as root. Hephaest0s cautions users that they must be using at least partial disk encryption along with USBKill to fully prevent attackers from gaining access; Gizmodo suggests using a virtual machine that will not be present when the computer reboots.It can also be used in reverse, with a whitelisted flash drive in the USB port attached to the user's wrist via a lanyard serving as a key. In this instance, if the flash drive is forcibly removed, the program will initiate the desired routines. \"[It] is designed to do one thing,\" wrote Aaron Grothe in a short article on USBKill in 2600, \"and it does it pretty well.\" As a further precaution, he suggests users rename it to something innocuous once they have loaded it on their computers, in case someone might be looking for it on a seized computer to disable it.In addition to its designed purpose, Hephaest0s suggests other uses unconnected to a user's desire to frustrate police and prosecutors. As part of a general security regimen, it could be used to prevent the surreptitious installation of malware or spyware on, or copying of files from, a protected computer. It is also recommended for general use as part of a robust security practice, even when there are no threats to be feared.\n\n== Variations and modifications ==\nWith his 2600 article, Grothe shared a patch that included a feature that allowed the program to shut down a network when a non-whitelisted USB is inserted into any terminal. Nate Brune, another programmer, created Silk Guardian, a version of USBKill that takes the form of a loadable kernel module, since he \"[felt] that it could be implemented better than it already is.\" In the issue of 2600 following Grothe's article, another writer, going by the name Jack D. Ripper, explained how Ninja OS, an operating system designed for live flash drives, handles the issue. It uses a bash script resident in memory based watchdog timer that cycles a loop through the boot device (i.e., the flash drive) three times a second to see if it is still mounted and reboots the computer if it is not.\n\nBased on the above text, answer a question. How does Ninja OS handle unauthorized access to a computer?",
    "context": "",
    "output": "Ninja OS, an operating system designed for live flash drives, uses a bash script resident in memory based watchdog timer that cycles a loop through the boot device to see if it is still mounted and reboots the computer if it is not.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does Ninja OS handle unauthorized access to a computer?",
      "answer": "Ninja OS, an operating system designed for live flash drives, uses a bash script resident in memory based watchdog timer that cycles a loop through the boot device to see if it is still mounted and reboots the computer if it is not.",
      "context": "USBKill\n\n==Introduction==\nUSBKill is anti-forensic software distributed via GitHub, written in Python for the BSD, Linux, and OS X operating systems. It is designed to serve as a kill switch if the computer on which it is installed should fall under the control of individuals or entities against the desires of the owner. It is free software, available under the GNU General Public License.The program's developer, who goes by the online name Hephaest0s, created it in response to the circumstances of the arrest of Silk Road founder Ross Ulbricht, during which U.S. federal agents were able to get access to incriminating evidence on his laptop without needing his cooperation by copying data from its flash drive after distracting him. It maintains a whitelist of devices allowed to connect to the computer's USB ports; if a device not on that whitelist connects, it can take actions ranging from merely returning to the lock screen to encrypting the hard drive, or wiping all data on the computer. However, it can also be used as part of a computer security regimen to prevent the surreptitious installation of malware or spyware or the clandestine duplication of files, according to its creator.\n\n== Background ==\nWhen law enforcement agencies began making computer crime arrests in the 1990s, they would often ask judges for no knock search warrants, to deny their targets time to delete incriminating evidence from computers or storage media. In more extreme circumstances where it was likely that the targets could get advance notice of arriving police, judges would grant \"power-off\" warrants, allowing utilities to turn off the electricity to the location of the raid shortly beforehand, further forestalling any efforts to destroy evidence before it could be seized. These methods were effective against criminals who produced and distributed pirated software and movies, which was the primary large-scale computer crime of the era.By the 2010s, the circumstances of computer crime had changed along with legitimate computer use. Criminals were more likely to use the Internet to facilitate their crimes, so they needed to remain online most of the time. To do so, and still keep their activities discreet, they used computer security features like lock screens and password protection.For those reasons, law enforcement now attempts to apprehend suspected cybercriminals with their computers on and in use, all accounts both on the computer and online open and logged in, and thus easily searchable. If they fail to seize the computer in that condition, there are some methods available to bypass password protection, but these may take more time than police have available. It might be legally impossible to compel the suspect to relinquish their password; in the United States, where many computer-crime investigations take place, courts have distinguished between forcing a suspect to use material means of protecting data such as a thumbprint, retinal scan, or key, as opposed to a password or passcode, which is purely the product of the suspect's mental processes and is thus protected from compelled disclosure by the Fifth Amendment.The usual technique for authorities\u2014either public entities such as law enforcement or private organizations like companies\u2014seizing a computer (usually a laptop) that they believe is being used improperly is first to physically separate the suspect user from the computer enough that they cannot touch it, to prevent them from closing its lid, unplugging it, or typing a command. Once they have done so, they often install a device in the USB port that spoofs minor actions of a mouse, touchpad, or keyboard, preventing the computer from going into sleep mode, from which it would usually return to a lock screen which would require a password.Agents with the U.S. Federal Bureau of Investigation (FBI) investigating Ross Ulbricht, founder of the online black market Silk Road, learned that he often ran the site from his laptop, using the wireless networks available at branches of the San Francisco Public Library. When they had enough evidence to arrest him, they planned to catch him in the act of running Silk Road, with his computer on and logged in. They needed to ensure he was unable to trigger encryption or delete evidence when they did.In October 2013, a male and female agent pretended to have a lovers' quarrel near where Ulbricht was working at the Glen Park branch. According to Business Insider, Ulbricht was distracted and got up to see what the problem was, whereupon the female agent grabbed his laptop while the male agent restrained Ulbricht. The female agent was then able to insert a flash drive into one of the laptop's USB ports, with software that copied key files. According to Joshuah Bearman of Wired, a third agent grabbed the laptop while Ulbricht was distracted by the apparent lovers' fight and handed it to agent Tom Kiernan.\n\n== Use ==\nIn response to the circumstances of Ulbricht's arrest, a programmer known as Hephaest0s developed the USBKill code in Python and uploaded it to GitHub in 2014. It is available as free software under the GNU General Public License and currently runs under both Linux and OS X.\nThe program, when installed, prompts the user to create a whitelist of devices that are allowed to connect to the computer via its USB ports, which it checks at an adjustable sample rate. The user may also choose what actions the computer will take if it detects a USB device not on the whitelist (by default, it shuts down and erases data from the RAM and swap file). Users need to be logged in as root. Hephaest0s cautions users that they must be using at least partial disk encryption along with USBKill to fully prevent attackers from gaining access; Gizmodo suggests using a virtual machine that will not be present when the computer reboots.It can also be used in reverse, with a whitelisted flash drive in the USB port attached to the user's wrist via a lanyard serving as a key. In this instance, if the flash drive is forcibly removed, the program will initiate the desired routines. \"[It] is designed to do one thing,\" wrote Aaron Grothe in a short article on USBKill in 2600, \"and it does it pretty well.\" As a further precaution, he suggests users rename it to something innocuous once they have loaded it on their computers, in case someone might be looking for it on a seized computer to disable it.In addition to its designed purpose, Hephaest0s suggests other uses unconnected to a user's desire to frustrate police and prosecutors. As part of a general security regimen, it could be used to prevent the surreptitious installation of malware or spyware on, or copying of files from, a protected computer. It is also recommended for general use as part of a robust security practice, even when there are no threats to be feared.\n\n== Variations and modifications ==\nWith his 2600 article, Grothe shared a patch that included a feature that allowed the program to shut down a network when a non-whitelisted USB is inserted into any terminal. Nate Brune, another programmer, created Silk Guardian, a version of USBKill that takes the form of a loadable kernel module, since he \"[felt] that it could be implemented better than it already is.\" In the issue of 2600 following Grothe's article, another writer, going by the name Jack D. Ripper, explained how Ninja OS, an operating system designed for live flash drives, handles the issue. It uses a bash script resident in memory based watchdog timer that cycles a loop through the boot device (i.e., the flash drive) three times a second to see if it is still mounted and reboots the computer if it is not."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does IS5 define the secure disposal of paper media?",
    "context": "",
    "output": "The text does not provide specific details on how IS5 defines the secure disposal of paper media.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does IS5 define the secure disposal of paper media?",
      "answer": "The text does not provide specific details on how IS5 defines the secure disposal of paper media."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the primary purpose of the NIPRNet?",
    "context": "",
    "output": "The NIPRNet is primarily used to exchange unclassified information among its users, including information subject to controls on distribution. It also provides its users with access to the Internet.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the primary purpose of the NIPRNet?",
      "answer": "The NIPRNet is primarily used to exchange unclassified information among its users, including information subject to controls on distribution. It also provides its users with access to the Internet."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does HoneyMonkey's recording of every read or write of the file system and registry help in detecting exploits and malware?",
    "context": "",
    "output": "HoneyMonkey's recording of every read or write of the file system and registry allows it to keep a log of what data was collected by the web-site and what software was installed by it. This log can then be analyzed to determine if any malware has been loaded and to detect any exploits that may have been used.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does HoneyMonkey's recording of every read or write of the file system and registry help in detecting exploits and malware?",
      "answer": "HoneyMonkey's recording of every read or write of the file system and registry allows it to keep a log of what data was collected by the web-site and what software was installed by it. This log can then be analyzed to determine if any malware has been loaded and to detect any exploits that may have been used."
    }
  },
  {
    "instruction": "Email spoofing\n\n==Introduction==\nEmail spoofing is the creation of email messages with a forged sender address. The term applies to email purporting to be from an address which is not actually the sender's; mail sent in reply to that address may bounce or be delivered to an unrelated party whose identity has been faked. Disposable email address or \"masked\" email is a different topic, providing a masked email address that is not the user's normal address, which is not disclosed (for example, so that it cannot be harvested), but forwards mail sent to it to the user's real address.The original transmission protocols used for email do not have built-in authentication methods: this deficiency allows spam and phishing emails to use spoofing in order to mislead the recipient. More recent countermeasures have made such spoofing from internet sources more difficult but not eliminated it; few internal networks have defenses against a spoof email from a colleague's compromised computer on that network. Individuals and businesses deceived by spoof emails may suffer significant financial losses; in particular, spoofed emails are often used to infect computers with ransomware.\n\n== Technical details ==\nWhen a Simple Mail Transfer Protocol (SMTP) email is sent, the initial connection provides two pieces of address information:\n\nMAIL FROM: - generally presented to the recipient as the Return-path: header but not normally visible to the end user, and by default no checks are done that the sending system is authorized to send on behalf of that address.\nRCPT TO: - specifies which email address the email is delivered to, is not normally visible to the end user but may be present in the headers as part of the \"Received:\" header.Together, these are sometimes referred to as the \"envelope\" addressing \u2013 an analogy to a traditional paper envelope. Unless the receiving mail server signals that it has problems with either of these items, the sending system sends the \"DATA\" command, and typically sends several header items, including:\n\nFrom: Joe Q Doe <joeqdoe@example.com>  - the address visible to the recipient; but again, by default no checks are done that the sending system is authorized to send on behalf of that address.\nReply-to: Jane Roe <Jane.Roe@example.mil> - similarly not checkedand sometimes:\n\nSender: Jin Jo <jin.jo@example.jp> - also not checkedThe result is that the email recipient sees the email as having come from the address in the From: header. They may sometimes be able to find the MAIL FROM address, and if they reply to the email, it will go to either the address presented in the From: or Reply-to: header, but none of these addresses are typically reliable, so automated bounce messages may generate backscatter.\nAlthough email spoofing is effective in forging the email address, the IP address of the computer sending the mail can generally be identified from the \"Received:\" lines in the email header. In malicious cases, however, this is likely to be the computer of an innocent third party infected by malware that is sending the email without the owner's knowledge.\n\n== Malicious use of spoofing ==\nPhishing and business email compromise (see below) scams generally involve an element of email spoofing.\nEmail spoofing has been responsible for public incidents with serious business and financial consequences. This was the case in an October 2013 email to a news agency which was spoofed to look as if it was from the Swedish company Fingerprint Cards. The email stated that Samsung offered to purchase the company. The news spread and the stock exchange rate surged by 50%.Malware such as Klez and Sober among many more modern examples often search for email addresses within the computer they have infected, and they use those addresses both as targets for email, and also to create credible forged From fields in the emails that they send. This is to ensure that the emails are more likely to be opened. For example:\n\nAlice is sent an infected email which she opens, running the worm code.\nThe worm code searches Alice's email address book and finds the addresses of Bob and Charlie.\nFrom Alice's computer, the worm sends an infected email to Bob, but is forged to appear as if it was sent by Charlie.In this case, even if Bob's system detects the incoming mail as containing malware, he sees the source as being Charlie, even though it really came from Alice's computer. Meanwhile, Alice may remain unaware that her computer has been infected, and Charlie does not know anything about it at all, unless he receives an error message from Bob.\nHow does email spoofing differ from spam and email phishing?\nThe main difference between spam and a spoofed message is that spammers don't edit email headers to pretend the email was sent from someone else. Both phishing and spoofing emails aim to trick someone to believe the message was sent from a legitimate sender. However, the main phishers' intent is to compromise user personal and financial information, while spoofing emails is just one of the ways they use to do so.\n\n== The effect on mail servers ==\nTraditionally, mail servers could accept a mail item, then later send a Non-Delivery Report or \"bounce\" message if it couldn't be delivered or had been quarantined for any reason. These would be sent to the \"MAIL FROM:\" aka \"Return Path\" address. With the massive rise in forged addresses, best practice is now to not generate NDRs for detected spam, viruses etc. but to reject the email during the SMTP transaction. When mail administrators fail to take this approach, their systems are guilty of sending \"backscatter\" emails to innocent parties - in itself a form of spam - or being used to perform \"Joe job\" attacks.\n\n== Countermeasures ==\nThe SSL/TLS system used to encrypt server-to-server email traffic can also be used to enforce authentication, but in practice it is seldom used, and a range of other potential solutions have also failed to gain traction.\nA number of defensive systems have come into wide use, including:\n\nSender Policy Framework (SPF) \u2013  an email authentication method designed to detect forging sender addresses during the delivery of the email.\nDomainKeys Identified Mail (DKIM) \u2013  an email authentication method designed to detect forged sender addresses in email (email spoofing), a technique often used in phishing and email spam.\nDomain-based Message Authentication, Reporting and Conformance (DMARC)  \u2013  an email authentication protocol. It is designed to give email domain owners the ability to protect their domain from unauthorized use, commonly known as email spoofing. The purpose and primary outcome of implementing DMARC is to protect a domain from being used in business email compromise attacks, phishing emails, email scams and other cyber threat activities.To effectively stop forged email being delivered, the sending domains, their mail servers, and the receiving system all need to be configured correctly for these higher standards of authentication. Although their use is increasing, estimates vary widely as to what percentage of emails have no form of domain authentication: from 8.6% to \"almost half\". For this reason, receiving mail systems typically have a range of settings to configure how they treat poorly-configured domains or email.\n\n== Business email ==\nBusiness email compromise attacks are a class of cyber crime that use email fraud to attack commercial, government and non-profit organizations to achieve a specific outcome which negatively impacts the target organization. Examples include invoice scams and spear phishing spoof attacks which are designed to gather data for other criminal activities. A business deceived by an email spoof can suffer additional financial, business continuity and reputational damage: fake emails are a favored route for ransomware that can stop operations unless a ransom is paid; consumer privacy breaches can also be enabled.\nTypically, an attack targets specific employee roles within an organization by sending a spoof email (or series of spoof emails) which fraudulently represent a senior colleague (CEO or similar) or a trusted customer. (This type of attack is known as spear phishing). The email will issue instructions, such as approving payments or releasing client data. The emails often use social engineering to trick the victim into making money transfers to the bank account of the fraudster.The worldwide financial impact is large. The United States' Federal Bureau of Investigation recorded $26 billion of US and international losses associated with BEC attacks between June 2016 and July 2019.\n\n\n*** Incidents ***\nDublin Zoo lost \u20ac130,000 in such a scam in 2017 - a total of \u20ac500,000 was taken, though most was recovered.\nThe Austrian aerospace firm FACC AG was defrauded of 42 million euros ($47 million) through an attack in February 2016 - and subsequently fired both the CFO and CEO.\nTe Wananga o Aotearoa in New Zealand was defrauded of $120,000 (NZD).\nThe New Zealand Fire Service was scammed out of $52,000 in 2015.\nUbiquiti Networks lost $46.7 million through such a scam in 2015.\nSave the Children USA was the victim of a $1 million cyberscam in 2017.\nAustralian organisations that reported business email compromise attacks on the Australian Competition and Consumer Commission suffered approximately $2,800,000 (AUD) in financial losses for the 2018 year.\nIn 2013, Evaldas Rimasauskas and his employees sent thousands of fraud emails to get access to companies email systems.\n\nBased on the above text, answer a question. How does email spoofing affect the trust in email communication?",
    "context": "",
    "output": "Email spoofing affects the trust in email communication as it allows attackers to forge sender addresses, making it difficult for recipients to identify the true sender of an email. This can lead to recipients being tricked into providing personal and financial information, transferring money, or opening infected email attachments.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does email spoofing affect the trust in email communication?",
      "answer": "Email spoofing affects the trust in email communication as it allows attackers to forge sender addresses, making it difficult for recipients to identify the true sender of an email. This can lead to recipients being tricked into providing personal and financial information, transferring money, or opening infected email attachments.",
      "context": "Email spoofing\n\n==Introduction==\nEmail spoofing is the creation of email messages with a forged sender address. The term applies to email purporting to be from an address which is not actually the sender's; mail sent in reply to that address may bounce or be delivered to an unrelated party whose identity has been faked. Disposable email address or \"masked\" email is a different topic, providing a masked email address that is not the user's normal address, which is not disclosed (for example, so that it cannot be harvested), but forwards mail sent to it to the user's real address.The original transmission protocols used for email do not have built-in authentication methods: this deficiency allows spam and phishing emails to use spoofing in order to mislead the recipient. More recent countermeasures have made such spoofing from internet sources more difficult but not eliminated it; few internal networks have defenses against a spoof email from a colleague's compromised computer on that network. Individuals and businesses deceived by spoof emails may suffer significant financial losses; in particular, spoofed emails are often used to infect computers with ransomware.\n\n== Technical details ==\nWhen a Simple Mail Transfer Protocol (SMTP) email is sent, the initial connection provides two pieces of address information:\n\nMAIL FROM: - generally presented to the recipient as the Return-path: header but not normally visible to the end user, and by default no checks are done that the sending system is authorized to send on behalf of that address.\nRCPT TO: - specifies which email address the email is delivered to, is not normally visible to the end user but may be present in the headers as part of the \"Received:\" header.Together, these are sometimes referred to as the \"envelope\" addressing \u2013 an analogy to a traditional paper envelope. Unless the receiving mail server signals that it has problems with either of these items, the sending system sends the \"DATA\" command, and typically sends several header items, including:\n\nFrom: Joe Q Doe <joeqdoe@example.com>  - the address visible to the recipient; but again, by default no checks are done that the sending system is authorized to send on behalf of that address.\nReply-to: Jane Roe <Jane.Roe@example.mil> - similarly not checkedand sometimes:\n\nSender: Jin Jo <jin.jo@example.jp> - also not checkedThe result is that the email recipient sees the email as having come from the address in the From: header. They may sometimes be able to find the MAIL FROM address, and if they reply to the email, it will go to either the address presented in the From: or Reply-to: header, but none of these addresses are typically reliable, so automated bounce messages may generate backscatter.\nAlthough email spoofing is effective in forging the email address, the IP address of the computer sending the mail can generally be identified from the \"Received:\" lines in the email header. In malicious cases, however, this is likely to be the computer of an innocent third party infected by malware that is sending the email without the owner's knowledge.\n\n== Malicious use of spoofing ==\nPhishing and business email compromise (see below) scams generally involve an element of email spoofing.\nEmail spoofing has been responsible for public incidents with serious business and financial consequences. This was the case in an October 2013 email to a news agency which was spoofed to look as if it was from the Swedish company Fingerprint Cards. The email stated that Samsung offered to purchase the company. The news spread and the stock exchange rate surged by 50%.Malware such as Klez and Sober among many more modern examples often search for email addresses within the computer they have infected, and they use those addresses both as targets for email, and also to create credible forged From fields in the emails that they send. This is to ensure that the emails are more likely to be opened. For example:\n\nAlice is sent an infected email which she opens, running the worm code.\nThe worm code searches Alice's email address book and finds the addresses of Bob and Charlie.\nFrom Alice's computer, the worm sends an infected email to Bob, but is forged to appear as if it was sent by Charlie.In this case, even if Bob's system detects the incoming mail as containing malware, he sees the source as being Charlie, even though it really came from Alice's computer. Meanwhile, Alice may remain unaware that her computer has been infected, and Charlie does not know anything about it at all, unless he receives an error message from Bob.\nHow does email spoofing differ from spam and email phishing?\nThe main difference between spam and a spoofed message is that spammers don't edit email headers to pretend the email was sent from someone else. Both phishing and spoofing emails aim to trick someone to believe the message was sent from a legitimate sender. However, the main phishers' intent is to compromise user personal and financial information, while spoofing emails is just one of the ways they use to do so.\n\n== The effect on mail servers ==\nTraditionally, mail servers could accept a mail item, then later send a Non-Delivery Report or \"bounce\" message if it couldn't be delivered or had been quarantined for any reason. These would be sent to the \"MAIL FROM:\" aka \"Return Path\" address. With the massive rise in forged addresses, best practice is now to not generate NDRs for detected spam, viruses etc. but to reject the email during the SMTP transaction. When mail administrators fail to take this approach, their systems are guilty of sending \"backscatter\" emails to innocent parties - in itself a form of spam - or being used to perform \"Joe job\" attacks.\n\n== Countermeasures ==\nThe SSL/TLS system used to encrypt server-to-server email traffic can also be used to enforce authentication, but in practice it is seldom used, and a range of other potential solutions have also failed to gain traction.\nA number of defensive systems have come into wide use, including:\n\nSender Policy Framework (SPF) \u2013  an email authentication method designed to detect forging sender addresses during the delivery of the email.\nDomainKeys Identified Mail (DKIM) \u2013  an email authentication method designed to detect forged sender addresses in email (email spoofing), a technique often used in phishing and email spam.\nDomain-based Message Authentication, Reporting and Conformance (DMARC)  \u2013  an email authentication protocol. It is designed to give email domain owners the ability to protect their domain from unauthorized use, commonly known as email spoofing. The purpose and primary outcome of implementing DMARC is to protect a domain from being used in business email compromise attacks, phishing emails, email scams and other cyber threat activities.To effectively stop forged email being delivered, the sending domains, their mail servers, and the receiving system all need to be configured correctly for these higher standards of authentication. Although their use is increasing, estimates vary widely as to what percentage of emails have no form of domain authentication: from 8.6% to \"almost half\". For this reason, receiving mail systems typically have a range of settings to configure how they treat poorly-configured domains or email.\n\n== Business email ==\nBusiness email compromise attacks are a class of cyber crime that use email fraud to attack commercial, government and non-profit organizations to achieve a specific outcome which negatively impacts the target organization. Examples include invoice scams and spear phishing spoof attacks which are designed to gather data for other criminal activities. A business deceived by an email spoof can suffer additional financial, business continuity and reputational damage: fake emails are a favored route for ransomware that can stop operations unless a ransom is paid; consumer privacy breaches can also be enabled.\nTypically, an attack targets specific employee roles within an organization by sending a spoof email (or series of spoof emails) which fraudulently represent a senior colleague (CEO or similar) or a trusted customer. (This type of attack is known as spear phishing). The email will issue instructions, such as approving payments or releasing client data. The emails often use social engineering to trick the victim into making money transfers to the bank account of the fraudster.The worldwide financial impact is large. The United States' Federal Bureau of Investigation recorded $26 billion of US and international losses associated with BEC attacks between June 2016 and July 2019.\n\n\n*** Incidents ***\nDublin Zoo lost \u20ac130,000 in such a scam in 2017 - a total of \u20ac500,000 was taken, though most was recovered.\nThe Austrian aerospace firm FACC AG was defrauded of 42 million euros ($47 million) through an attack in February 2016 - and subsequently fired both the CFO and CEO.\nTe Wananga o Aotearoa in New Zealand was defrauded of $120,000 (NZD).\nThe New Zealand Fire Service was scammed out of $52,000 in 2015.\nUbiquiti Networks lost $46.7 million through such a scam in 2015.\nSave the Children USA was the victim of a $1 million cyberscam in 2017.\nAustralian organisations that reported business email compromise attacks on the Australian Competition and Consumer Commission suffered approximately $2,800,000 (AUD) in financial losses for the 2018 year.\nIn 2013, Evaldas Rimasauskas and his employees sent thousands of fraud emails to get access to companies email systems."
    }
  },
  {
    "instruction": "Write an answer to the following question: Why can IBS systems not be used for non-repudiation?",
    "context": "",
    "output": "IBS systems cannot be used for non-repudiation because the Private Key Generator (PKG) generates private keys for users, and may decrypt and/or sign any message without authorization.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Why can IBS systems not be used for non-repudiation?",
      "answer": "IBS systems cannot be used for non-repudiation because the Private Key Generator (PKG) generates private keys for users, and may decrypt and/or sign any message without authorization."
    }
  },
  {
    "instruction": "Bulletproof hosting\n\n==Introduction==\nBulletproof hosting (BPH) is technical infrastructure service provided by an Internet hosting service that is resilient to complaints of illicit activities, which serves criminal actors as a basic building block for streamlining various cyberattacks. BPH providers allow online gambling, illegal pornography, botnet command and control servers, spam, copyrighted materials, hate speech and misinformation, despite takedown court orders and law enforcement subpoenas, allowing such material in their acceptable use policies.BPH providers usually operate in jurisdictions which have lenient laws against such conduct. Most non-BPH service providers prohibit transferring materials over their network that would be in violation of their terms of service and the local laws of the incorporated jurisdiction, and oftentimes any abuse reports would result in takedowns to avoid their autonomous system's IP address block being blacklisted by other providers and by Spamhaus.\n\n== Difficulties ==\nSince any abuse reports to the BPH will be disregarded, in most cases, the whole IP block (\"netblock\") assigned to the BPH's autonomous system will be blacklisted by other providers and third party spam filters. Additionally, BPH also have difficulty in finding network peering points for establishing Border Gateway Protocol sessions, since routing a BPH provider's network can affect the reputation of upstream autonomous systems and transit provider. This makes it difficult for BPH services to provide stable network connectivity, and in extreme cases, they can be completely de-peered; therefore BPH providers evade AS's reputation based fortification such as BGP Ranking and ASwatch through unconventional methodologies.\n\n\n*** Web hosting reseller ***\nAccording to a report, due to their mounting difficulties, BPH providers engage in establishing reseller relationships with lower-end hosting providers; although these providers are not complicit in supporting the illegitimate activities, they tend to be lenient on abuse reports and do not actively engage in fraud detection. Therefore, BPH conceals itself behind lower-end hosting providers, leveraging their better reputation and simultaneously operating both bulletproof and legitimate resells through the sub-allocated network blocks. However, if the BPH services are caught, providers of BPH migrate their clients to a newer internet infrastructure\u2014newer lower-end AS, or IP space\u2014effectively making the blacklisted IP addresses of the previous AS ephemeral; thus continuing to engage in criminal conduct by modifying the DNS server's resource records of the listening services and making it point to the newer IP addresses belonging to the current AS's IP space. Due to privacy concerns, the customary modes of contact for BPH providers include ICQ, Skype, and XMPP (or Jabber).\n\n== Admissible abuses ==\nMost BPH providers promise immunity against copyright infringement and court order takedown notices, notably Digital Millennium Copyright Act (DMCA), Electronic Commerce Directive (ECD) and law enforcement subpoenas. They also allow users to operate phishing, scams (such as high-yield investment program), botnet masters and unlicensed online pharmacy websites. In these cases, the BPH providers (known as \"offshore providers\") operate in jurisdictions which do not have any extradition treaty or mutual legal assistance treaty (MLAT) signed with the five eye countries, particularly the United States. However, most BPH providers have a zero-tolerance policy towards child pornography and terrorism, although a few allow cold storage of such material given forbidden open-accessibility via the public internet.Prevalent jurisdictions for incorporation and location of the data centers for BPH providers include Russia (being more permissive), Ukraine, China, Moldova, Romania, Bulgaria, Belize, Panama and the Seychelles.\n\n== Impacts ==\nBPH services act as vital network infrastructure providers for activities such as cybercrime and online illicit economies, and the well-established working model of the cybercrime economies surrounds upon tool development and skill-sharing among peers. The development of exploits, such as zero-day vulnerabilities, are done by a very small community of highly-skilled actors, who encase them in convenient tools which are usually bought by low-skilled actors (known as script kiddies), who make use of BPH providers for carry out cyberattacks, usually targeting low-profile unpretentious network services and individuals. According to a report produced by Carnegie Mellon University for the United States Department of Defense, low-profile amateur actors are also potent in causing harmful consequences, especially to small businesses, inexperienced internet users, and miniature servers.Criminal actors also run specialized computer programs on BPH providers knowns as port scanners which scan the entire IPv4 address space for open ports, services run on those open ports, and the version of their service daemons, searching for vulnerable versions for exploitation. One such notable vulnerability scanned by the port scanners is Heartbleed, which affected millions of internet servers. Furthermore, BPH clients also host click fraud, adware (such as DollarRevenue), and money laundering recruitment sites, which lure untried internet users into honey trapping and causing financial losses to the individuals while unrestrictedly keeping their illicit sites online, despite court orders and takedown attempts by law enforcement.\n\n\n*** Counterinitiatives against BPH ***\nThe Spamhaus Project is an international nonprofit organization that monitors cyber threats and provides realtime blacklist reports (known as the \"Badness Index\") on malicious ASs, netblocks, and registrars that are involved in spam, phishing, or cybercrime activities. The Spamhaus team works closely with law enforcement agencies such as National Cyber-Forensics and Training Alliance (NCFTA) and Federal Bureau of Investigation (FBI), and the data compiled by Spamhaus is used by the majority of the ISPs, email service providers, corporations, educational institutes, governments and uplink gateways of military networks. Spamhaus publishes various data feeds that list netblocks of the criminal actors, and is designed for use by gateways, firewalls and routing equipments to filter out (or \"nullroute\") traffic originating from these netblocks:\nSpamhaus Don't Route Or Peer List (DROP) lists netblocks allocated by an established Regional Internet Registry (RIR) or National Internet Registry (NIR) that are used by criminal actors, and doesn't include abused IP address spaces sub-allocated netblocks of a reputable AS.\nSpamhaus Domain Block List (DBL) lists domain names with poor reputation in DNSBL format.\nSpamhaus Botnet Controller List (BCL) lists single IPv4 addresses of botnet masters.\n\n== Notable closed services ==\nThe following are some of the notable defunct BPH providers:\n\nCyberBunker, taken down in September 2019.\nMcColo, taken down in November 2008.\nRussian Business Network (RBN), taken down in November 2007.\nAtrivo, taken down in September 2008.\n3FN, taken down by FTC in June 2009.\nProxiez, taken down in May 2010.\n\n== Bibliography ==\nMcCoy, Damon; Mi, Xianghang; Wang, Xiofeng (26 June 2017). \"Under the Shadow of Sunshine: Understanding and Detecting Bulletproof Hosting on Legitimate Service Provider Networks\". IEEE Security & Privacy. New York University: 805\u2013823. doi:10.1109/SP.2017.32. ISBN 978-1-5090-5533-3. S2CID 1593958.\nHan, Catherine; Kumar, Deepak; Durumic, Zakir (2021). \"On the Infrastructure Providers that Support Misinformation\" (PDF). Stanford University. Archived (PDF) from the original on 25 August 2021. Retrieved 4 December 2021.\nKonte, Maria; Feamster, Nick; Perdisci, Roberto (17 August 2015). \"ASwatch: An AS Reputation System to Expose Bulletproof Hosting ASes\". SIGCOMM Association for Computing Machinery. New York, United States. 45 (4). doi:10.1145/2829988.2787494. ISSN 0146-4833.\nLeporini, Dino (2015). Architectures and protocols powering illegal content streaming over the Internet. University of Pisa. Amsterdam, Netherlands: International Broadcasting Convention. p. 7. doi:10.1049/ibc.2015.0013. ISBN 978-1-78561-185-8.\nClayton, Richard; Moore, Tyler (22 December 2008). \"The Impact of Incentives on Notice and Take-down\". Managing Information Risk and the Economics of Security. Boston: Springer Publishing: 199\u2013223. doi:10.1007/978-0-387-09762-6_10. ISBN 978-0-387-09761-9.\nKopp, Daniel; Strehle, Eric; Hohlfeld, Oliver (November 2021). \"CyberBunker 2.0 - A Domain and Traffic Perspective on a Bulletproof Hoster\". Proceedings of the 2021 ACM SIGSAC Conference on Computer and Communications Security. Association for Computing Machinery, Brandenburg University of Technology. pp. 2432\u20132434. arXiv:2109.06858. doi:10.1145/3460120.3485352. ISBN 9781450384544. S2CID 237503582.\nCollier, Benjamin; Hutchings, Alice (15 April 2021). \"Cybercrime is (often) boring: maintaining the infrastructure of cybercrime economies\". The British Journal of Criminology. Oxford University Press. 61 (5). doi:10.1093/bjc/azab026.\nBradbury, Danny (15 October 2010). \"Digging up the hacking underground\". Infosecurity. ScienceDirect. 7 (5): 14\u201317. doi:10.1016/S1754-4548(10)70084-X. ISSN 1754-4548.\nKonte, M.; Feamster, N.; Jung, J. (January 2008). \"SAC 025: SSAC Advisory on Fast Flux Hosting and DNS\" (PDF). Security and Stability Advisory Committee (SSAC). Internet Corporation for Assigned Names and Numbers (1). Archived (PDF) from the original on 22 November 2021. Retrieved 12 December 2021.\nQ: What are exploits and how are they used in cyberattacks?",
    "context": "",
    "output": "Exploits are usually bought by low-skilled actors (known as script kiddies) who make use of BPH providers for carry out cyberattacks, usually targeting low-profile unpretentious network services and individuals. Exploits are developed by a very small community of highly-skilled actors who encase them in convenient tools.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are exploits and how are they used in cyberattacks?",
      "answer": "Exploits are usually bought by low-skilled actors (known as script kiddies) who make use of BPH providers for carry out cyberattacks, usually targeting low-profile unpretentious network services and individuals. Exploits are developed by a very small community of highly-skilled actors who encase them in convenient tools.",
      "context": "Bulletproof hosting\n\n==Introduction==\nBulletproof hosting (BPH) is technical infrastructure service provided by an Internet hosting service that is resilient to complaints of illicit activities, which serves criminal actors as a basic building block for streamlining various cyberattacks. BPH providers allow online gambling, illegal pornography, botnet command and control servers, spam, copyrighted materials, hate speech and misinformation, despite takedown court orders and law enforcement subpoenas, allowing such material in their acceptable use policies.BPH providers usually operate in jurisdictions which have lenient laws against such conduct. Most non-BPH service providers prohibit transferring materials over their network that would be in violation of their terms of service and the local laws of the incorporated jurisdiction, and oftentimes any abuse reports would result in takedowns to avoid their autonomous system's IP address block being blacklisted by other providers and by Spamhaus.\n\n== Difficulties ==\nSince any abuse reports to the BPH will be disregarded, in most cases, the whole IP block (\"netblock\") assigned to the BPH's autonomous system will be blacklisted by other providers and third party spam filters. Additionally, BPH also have difficulty in finding network peering points for establishing Border Gateway Protocol sessions, since routing a BPH provider's network can affect the reputation of upstream autonomous systems and transit provider. This makes it difficult for BPH services to provide stable network connectivity, and in extreme cases, they can be completely de-peered; therefore BPH providers evade AS's reputation based fortification such as BGP Ranking and ASwatch through unconventional methodologies.\n\n\n*** Web hosting reseller ***\nAccording to a report, due to their mounting difficulties, BPH providers engage in establishing reseller relationships with lower-end hosting providers; although these providers are not complicit in supporting the illegitimate activities, they tend to be lenient on abuse reports and do not actively engage in fraud detection. Therefore, BPH conceals itself behind lower-end hosting providers, leveraging their better reputation and simultaneously operating both bulletproof and legitimate resells through the sub-allocated network blocks. However, if the BPH services are caught, providers of BPH migrate their clients to a newer internet infrastructure\u2014newer lower-end AS, or IP space\u2014effectively making the blacklisted IP addresses of the previous AS ephemeral; thus continuing to engage in criminal conduct by modifying the DNS server's resource records of the listening services and making it point to the newer IP addresses belonging to the current AS's IP space. Due to privacy concerns, the customary modes of contact for BPH providers include ICQ, Skype, and XMPP (or Jabber).\n\n== Admissible abuses ==\nMost BPH providers promise immunity against copyright infringement and court order takedown notices, notably Digital Millennium Copyright Act (DMCA), Electronic Commerce Directive (ECD) and law enforcement subpoenas. They also allow users to operate phishing, scams (such as high-yield investment program), botnet masters and unlicensed online pharmacy websites. In these cases, the BPH providers (known as \"offshore providers\") operate in jurisdictions which do not have any extradition treaty or mutual legal assistance treaty (MLAT) signed with the five eye countries, particularly the United States. However, most BPH providers have a zero-tolerance policy towards child pornography and terrorism, although a few allow cold storage of such material given forbidden open-accessibility via the public internet.Prevalent jurisdictions for incorporation and location of the data centers for BPH providers include Russia (being more permissive), Ukraine, China, Moldova, Romania, Bulgaria, Belize, Panama and the Seychelles.\n\n== Impacts ==\nBPH services act as vital network infrastructure providers for activities such as cybercrime and online illicit economies, and the well-established working model of the cybercrime economies surrounds upon tool development and skill-sharing among peers. The development of exploits, such as zero-day vulnerabilities, are done by a very small community of highly-skilled actors, who encase them in convenient tools which are usually bought by low-skilled actors (known as script kiddies), who make use of BPH providers for carry out cyberattacks, usually targeting low-profile unpretentious network services and individuals. According to a report produced by Carnegie Mellon University for the United States Department of Defense, low-profile amateur actors are also potent in causing harmful consequences, especially to small businesses, inexperienced internet users, and miniature servers.Criminal actors also run specialized computer programs on BPH providers knowns as port scanners which scan the entire IPv4 address space for open ports, services run on those open ports, and the version of their service daemons, searching for vulnerable versions for exploitation. One such notable vulnerability scanned by the port scanners is Heartbleed, which affected millions of internet servers. Furthermore, BPH clients also host click fraud, adware (such as DollarRevenue), and money laundering recruitment sites, which lure untried internet users into honey trapping and causing financial losses to the individuals while unrestrictedly keeping their illicit sites online, despite court orders and takedown attempts by law enforcement.\n\n\n*** Counterinitiatives against BPH ***\nThe Spamhaus Project is an international nonprofit organization that monitors cyber threats and provides realtime blacklist reports (known as the \"Badness Index\") on malicious ASs, netblocks, and registrars that are involved in spam, phishing, or cybercrime activities. The Spamhaus team works closely with law enforcement agencies such as National Cyber-Forensics and Training Alliance (NCFTA) and Federal Bureau of Investigation (FBI), and the data compiled by Spamhaus is used by the majority of the ISPs, email service providers, corporations, educational institutes, governments and uplink gateways of military networks. Spamhaus publishes various data feeds that list netblocks of the criminal actors, and is designed for use by gateways, firewalls and routing equipments to filter out (or \"nullroute\") traffic originating from these netblocks:\nSpamhaus Don't Route Or Peer List (DROP) lists netblocks allocated by an established Regional Internet Registry (RIR) or National Internet Registry (NIR) that are used by criminal actors, and doesn't include abused IP address spaces sub-allocated netblocks of a reputable AS.\nSpamhaus Domain Block List (DBL) lists domain names with poor reputation in DNSBL format.\nSpamhaus Botnet Controller List (BCL) lists single IPv4 addresses of botnet masters.\n\n== Notable closed services ==\nThe following are some of the notable defunct BPH providers:\n\nCyberBunker, taken down in September 2019.\nMcColo, taken down in November 2008.\nRussian Business Network (RBN), taken down in November 2007.\nAtrivo, taken down in September 2008.\n3FN, taken down by FTC in June 2009.\nProxiez, taken down in May 2010.\n\n== Bibliography ==\nMcCoy, Damon; Mi, Xianghang; Wang, Xiofeng (26 June 2017). \"Under the Shadow of Sunshine: Understanding and Detecting Bulletproof Hosting on Legitimate Service Provider Networks\". IEEE Security & Privacy. New York University: 805\u2013823. doi:10.1109/SP.2017.32. ISBN 978-1-5090-5533-3. S2CID 1593958.\nHan, Catherine; Kumar, Deepak; Durumic, Zakir (2021). \"On the Infrastructure Providers that Support Misinformation\" (PDF). Stanford University. Archived (PDF) from the original on 25 August 2021. Retrieved 4 December 2021.\nKonte, Maria; Feamster, Nick; Perdisci, Roberto (17 August 2015). \"ASwatch: An AS Reputation System to Expose Bulletproof Hosting ASes\". SIGCOMM Association for Computing Machinery. New York, United States. 45 (4). doi:10.1145/2829988.2787494. ISSN 0146-4833.\nLeporini, Dino (2015). Architectures and protocols powering illegal content streaming over the Internet. University of Pisa. Amsterdam, Netherlands: International Broadcasting Convention. p. 7. doi:10.1049/ibc.2015.0013. ISBN 978-1-78561-185-8.\nClayton, Richard; Moore, Tyler (22 December 2008). \"The Impact of Incentives on Notice and Take-down\". Managing Information Risk and the Economics of Security. Boston: Springer Publishing: 199\u2013223. doi:10.1007/978-0-387-09762-6_10. ISBN 978-0-387-09761-9.\nKopp, Daniel; Strehle, Eric; Hohlfeld, Oliver (November 2021). \"CyberBunker 2.0 - A Domain and Traffic Perspective on a Bulletproof Hoster\". Proceedings of the 2021 ACM SIGSAC Conference on Computer and Communications Security. Association for Computing Machinery, Brandenburg University of Technology. pp. 2432\u20132434. arXiv:2109.06858. doi:10.1145/3460120.3485352. ISBN 9781450384544. S2CID 237503582.\nCollier, Benjamin; Hutchings, Alice (15 April 2021). \"Cybercrime is (often) boring: maintaining the infrastructure of cybercrime economies\". The British Journal of Criminology. Oxford University Press. 61 (5). doi:10.1093/bjc/azab026.\nBradbury, Danny (15 October 2010). \"Digging up the hacking underground\". Infosecurity. ScienceDirect. 7 (5): 14\u201317. doi:10.1016/S1754-4548(10)70084-X. ISSN 1754-4548.\nKonte, M.; Feamster, N.; Jung, J. (January 2008). \"SAC 025: SSAC Advisory on Fast Flux Hosting and DNS\" (PDF). Security and Stability Advisory Committee (SSAC). Internet Corporation for Assigned Names and Numbers (1). Archived (PDF) from the original on 22 November 2021. Retrieved 12 December 2021."
    }
  },
  {
    "instruction": "WS-SecurityPolicy\n\n==Introduction==\nWS-SecurityPolicy is a web services specification, created by IBM and 12 co-authors, that has become an OASIS standard as of version 1.2. It extends the fundamental security protocols specified by the WS-Security, WS-Trust and WS-SecureConversation by offering mechanisms to represent the capabilities and requirements of web services as policies. Security policy assertions are based on the WS-Policy framework. \nPolicy assertions can be used to require more generic security attributes like transport layer security <TransportBinding>, message level security <AsymmetricBinding> or timestamps, and specific attributes like token types. \nMost policy assertion can be found in following categories:\n\nProtection assertions identify the elements of a message that are required to be signed, encrypted or existent.\nToken assertions specify allowed token formats (SAML, X509, Username etc.).\nSecurity binding assertions control basic security safeguards like transport and message level security, cryptographic algorithm suite and required timestamps.\nSupporting token assertions add functions like user sign-on using a username token.Policies can be used to drive development tools to generate code with certain capabilities, or may be used at runtime to negotiate the security aspects of web service communication. Policies may be attached to WSDL elements such as service, port, operation and message, as defined in WS Policy Attachment.\n\n\n\n== Sample Policies ==\nNamespaces used by the following XML-snippets:\n\n<p:Policy \n   xmlns:p\n\n== Other WS policy languages ==\nThe term Web Services Security Policy Language is used for two different XML-based languages:\n\nAs described above, based on the WS-Policy framework, as defined in, published as version 1.3 in Feb. 2009\nWSPL, based on XACML profile for Web-services, but that was not finalized.\nQuestion: What are supporting token assertions in WS-SecurityPolicy?",
    "context": "",
    "output": "Answer: Supporting token assertions in WS-SecurityPolicy add functions such as user sign-on using a username token. These assertions help enhance the security and functionality of web services.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are supporting token assertions in WS-SecurityPolicy?",
      "answer": "Supporting token assertions in WS-SecurityPolicy add functions such as user sign-on using a username token. These assertions help enhance the security and functionality of web services.",
      "context": "WS-SecurityPolicy\n\n==Introduction==\nWS-SecurityPolicy is a web services specification, created by IBM and 12 co-authors, that has become an OASIS standard as of version 1.2. It extends the fundamental security protocols specified by the WS-Security, WS-Trust and WS-SecureConversation by offering mechanisms to represent the capabilities and requirements of web services as policies. Security policy assertions are based on the WS-Policy framework. \nPolicy assertions can be used to require more generic security attributes like transport layer security <TransportBinding>, message level security <AsymmetricBinding> or timestamps, and specific attributes like token types. \nMost policy assertion can be found in following categories:\n\nProtection assertions identify the elements of a message that are required to be signed, encrypted or existent.\nToken assertions specify allowed token formats (SAML, X509, Username etc.).\nSecurity binding assertions control basic security safeguards like transport and message level security, cryptographic algorithm suite and required timestamps.\nSupporting token assertions add functions like user sign-on using a username token.Policies can be used to drive development tools to generate code with certain capabilities, or may be used at runtime to negotiate the security aspects of web service communication. Policies may be attached to WSDL elements such as service, port, operation and message, as defined in WS Policy Attachment.\n\n\n\n== Sample Policies ==\nNamespaces used by the following XML-snippets:\n\n<p:Policy \n   xmlns:p\n\n== Other WS policy languages ==\nThe term Web Services Security Policy Language is used for two different XML-based languages:\n\nAs described above, based on the WS-Policy framework, as defined in, published as version 1.3 in Feb. 2009\nWSPL, based on XACML profile for Web-services, but that was not finalized."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is The Tor Project, and who developed it?",
    "context": "",
    "output": "The Tor Project is a project that developed Tor, an onion routing-based anonymity network. It was developed by Nick Mathewson and his two colleagues under a contract from the United States Naval Research Laboratory.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is The Tor Project, and who developed it?",
      "answer": "The Tor Project is a project that developed Tor, an onion routing-based anonymity network. It was developed by Nick Mathewson and his two colleagues under a contract from the United States Naval Research Laboratory."
    }
  },
  {
    "instruction": "Common Weakness Enumeration\n\n==Introduction==\nThe Common Weakness Enumeration (CWE) is a category system for hardware and software weaknesses and vulnerabilities. It is sustained by a community project with the goals of understanding flaws in software and hardware and creating automated tools that can be used to identify, fix, and prevent those flaws.  The project is sponsored by the National Cybersecurity FFRDC, which is operated by The MITRE Corporation, with support from US-CERT and the National Cyber Security Division of the U.S. Department of Homeland Security.Version 4.10 of the CWE standard was released in July 2021.CWE has over 600 categories, including classes for buffer overflows, path/directory tree traversal errors, race conditions, cross-site scripting, hard-coded passwords, and insecure random numbers.\n\n== Examples ==\nCWE category 121 is for stack-based buffer overflows.\n\n== CWE compatibility ==\nCommon Weakness Enumeration (CWE) Compatibility program allows a service or a product to be reviewed and registered as officially \"CWE-Compatible\" and \"CWE-Effective\". The program assists organizations in selecting the right software tools and learning about possible weaknesses and their possible impact.\nIn order to obtain CWE Compatible status a product or a service must meet 4 out of 6 requirements, shown below:\n\nThere are 56 organizations as of September 2019 that develop and maintain products and services that achieved CWE Compatible status.\n\n== Research, critiques, and new developments ==\nSome researchers think that ambiguities in CWE can be avoided or reduced.\nQuestion: What is the significance of CWE category 121?",
    "context": "",
    "output": "Answer: CWE category 121 is dedicated to stack-based buffer overflows, which is a specific type of vulnerability in software.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the significance of CWE category 121?",
      "answer": "CWE category 121 is dedicated to stack-based buffer overflows, which is a specific type of vulnerability in software.",
      "context": "Common Weakness Enumeration\n\n==Introduction==\nThe Common Weakness Enumeration (CWE) is a category system for hardware and software weaknesses and vulnerabilities. It is sustained by a community project with the goals of understanding flaws in software and hardware and creating automated tools that can be used to identify, fix, and prevent those flaws.  The project is sponsored by the National Cybersecurity FFRDC, which is operated by The MITRE Corporation, with support from US-CERT and the National Cyber Security Division of the U.S. Department of Homeland Security.Version 4.10 of the CWE standard was released in July 2021.CWE has over 600 categories, including classes for buffer overflows, path/directory tree traversal errors, race conditions, cross-site scripting, hard-coded passwords, and insecure random numbers.\n\n== Examples ==\nCWE category 121 is for stack-based buffer overflows.\n\n== CWE compatibility ==\nCommon Weakness Enumeration (CWE) Compatibility program allows a service or a product to be reviewed and registered as officially \"CWE-Compatible\" and \"CWE-Effective\". The program assists organizations in selecting the right software tools and learning about possible weaknesses and their possible impact.\nIn order to obtain CWE Compatible status a product or a service must meet 4 out of 6 requirements, shown below:\n\nThere are 56 organizations as of September 2019 that develop and maintain products and services that achieved CWE Compatible status.\n\n== Research, critiques, and new developments ==\nSome researchers think that ambiguities in CWE can be avoided or reduced."
    }
  },
  {
    "instruction": "Write an answer to the following question: How can extreme weather events and natural disasters lead to internet outages?",
    "context": "",
    "output": "Extreme weather events and natural disasters can cause internet outages by directly destroying local ICT infrastructure or indirectly damaging the local electricity grid.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can extreme weather events and natural disasters lead to internet outages?",
      "answer": "Extreme weather events and natural disasters can cause internet outages by directly destroying local ICT infrastructure or indirectly damaging the local electricity grid."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the use of a block cipher in HAS-V contribute to its security?",
    "context": "",
    "output": "The use of a block cipher in HAS-V provides a strong foundation for the hash function, making it resistant to various attacks. The block cipher's symmetric-key algorithm helps to ensure the confidentiality and integrity of the hash value.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the use of a block cipher in HAS-V contribute to its security?",
      "answer": "The use of a block cipher in HAS-V provides a strong foundation for the hash function, making it resistant to various attacks. The block cipher's symmetric-key algorithm helps to ensure the confidentiality and integrity of the hash value."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does NSS enable cross-platform development for security-enabled applications?",
    "context": "",
    "output": "NSS provides a collection of cryptographic libraries and a framework that supports cross-platform development for security-enabled client and server applications. It also offers optional support for hardware TLS/SSL acceleration on the server side and hardware smart cards on the client side. Additionally, NSS uses Netscape Portable Runtime (NSPR), a platform-neutral open-source API for system functions, which facilitates cross-platform development.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does NSS enable cross-platform development for security-enabled applications?",
      "answer": "NSS provides a collection of cryptographic libraries and a framework that supports cross-platform development for security-enabled client and server applications. It also offers optional support for hardware TLS/SSL acceleration on the server side and hardware smart cards on the client side. Additionally, NSS uses Netscape Portable Runtime (NSPR), a platform-neutral open-source API for system functions, which facilitates cross-platform development."
    }
  },
  {
    "instruction": "Write an answer to the following question: What was EnGarde Secure Linux's role in the adoption of SELinux for complete server implementations?",
    "context": "",
    "output": "EnGarde Secure Linux was one of the earliest distributions to include SELinux for complete server implementations, and was one of the first Linux server platforms designed solely for security.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was EnGarde Secure Linux's role in the adoption of SELinux for complete server implementations?",
      "answer": "EnGarde Secure Linux was one of the earliest distributions to include SELinux for complete server implementations, and was one of the first Linux server platforms designed solely for security."
    }
  },
  {
    "instruction": "Write an answer to the following question: How did the attackers access SolarWinds's software publishing infrastructure?",
    "context": "",
    "output": "The attackers accessed SolarWinds's software publishing infrastructure no later than September 2019, possibly via SolarWinds's Microsoft Office 365 account, which had also been compromised at some point.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How did the attackers access SolarWinds's software publishing infrastructure?",
      "answer": "The attackers accessed SolarWinds's software publishing infrastructure no later than September 2019, possibly via SolarWinds's Microsoft Office 365 account, which had also been compromised at some point."
    }
  },
  {
    "instruction": "FragAttacks\n\n==Introduction==\nFragAttacks, or fragmentation and aggregation attacks, are a group of Wi-Fi vulnerabilities discovered by security research Mathy Vanhoef. Since the vulnerabilities are design flaws in the Wi-Fi standard, any device released after 1997 could be vulnerable. The attack can be executed without special privileges. The attack was detailed on August 5, 2021 at Black Hat Briefings USA and at later at the USENIX 30th Security Symposium, where recordings are shared publicly. The attack does not leave any trace in the network logs.\n\n== Patches ==\nVanhoef worked with the Wi-Fi Alliance to help vendors issue patches.Microsoft started issuing patches for Windows 7 through Windows 10 on May 11, 2021.\nQ: How did Mathy Vanhoef share his findings on FragAttacks with the public?",
    "context": "",
    "output": "Mathy Vanhoef shared his findings on FragAttacks at Black Hat Briefings USA and at the USENIX 30th Security Symposium, where recordings of his presentations are publicly available.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How did Mathy Vanhoef share his findings on FragAttacks with the public?",
      "answer": "Mathy Vanhoef shared his findings on FragAttacks at Black Hat Briefings USA and at the USENIX 30th Security Symposium, where recordings of his presentations are publicly available.",
      "context": "FragAttacks\n\n==Introduction==\nFragAttacks, or fragmentation and aggregation attacks, are a group of Wi-Fi vulnerabilities discovered by security research Mathy Vanhoef. Since the vulnerabilities are design flaws in the Wi-Fi standard, any device released after 1997 could be vulnerable. The attack can be executed without special privileges. The attack was detailed on August 5, 2021 at Black Hat Briefings USA and at later at the USENIX 30th Security Symposium, where recordings are shared publicly. The attack does not leave any trace in the network logs.\n\n== Patches ==\nVanhoef worked with the Wi-Fi Alliance to help vendors issue patches.Microsoft started issuing patches for Windows 7 through Windows 10 on May 11, 2021."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the purpose of the BPF filter syntax in ngrep?",
    "context": "",
    "output": "The BPF filter syntax in ngrep is used to select network sources or destinations or protocols for analysis.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the purpose of the BPF filter syntax in ngrep?",
      "answer": "The BPF filter syntax in ngrep is used to select network sources or destinations or protocols for analysis."
    }
  },
  {
    "instruction": "Malleability (cryptography)\n\n==Introduction==\nMalleability is a property of some cryptographic algorithms. An encryption algorithm is \"malleable\" if it is possible to transform a ciphertext into another ciphertext which decrypts to a related plaintext. That is, given an encryption of a plaintext \n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n  , it is possible to generate another ciphertext which decrypts to \n  \n    \n      \n        f\n        (\n        m\n        )\n      \n    \n    {\\displaystyle f(m)}\n  , for a known function \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n  , without necessarily knowing or learning \n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n  .\nMalleability is often an undesirable property in a general-purpose cryptosystem, since it allows an attacker to modify the contents of a message.  For example, suppose that a bank uses a stream cipher to hide its financial information, and a user sends an encrypted message containing, say, \"TRANSFER $0000100.00 TO ACCOUNT #199.\"  If an attacker can modify the message on the wire, and can guess the format of the unencrypted message, the attacker could change the amount of the transaction, or the recipient of the funds, e.g.  \"TRANSFER $0100000.00 TO ACCOUNT #227\". Malleability does not refer to the attacker's ability to read the encrypted message. Both before and after tampering, the attacker cannot read the encrypted message.\nOn the other hand, some cryptosystems are malleable by design. In other words, in some circumstances it may be viewed as a feature that anyone can transform an encryption of \n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n   into a valid encryption of \n  \n    \n      \n        f\n        (\n        m\n        )\n      \n    \n    {\\displaystyle f(m)}\n    (for some restricted class of functions \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n  ) without necessarily learning \n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n  . Such schemes are known as homomorphic encryption schemes.\nA cryptosystem may be semantically secure against chosen plaintext attacks or even non-adaptive chosen ciphertext attacks (CCA1) while still being malleable. However, security against adaptive chosen ciphertext attacks (CCA2) is equivalent to non-malleability.\n\n\n\n== Example malleable cryptosystems ==\nIn a stream cipher, the ciphertext is produced by taking the exclusive or of the plaintext and a pseudorandom stream based on a secret key \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  , as \n  \n    \n      \n        E\n        (\n        m\n        )\n\n== Complete non-malleability ==\nFischlin, in 2005, defined the notion of complete non-malleability as the ability of the system to remain non-malleable while giving the adversary additional power to choose a new public key which could be a function of the original public key. In other words, the adversary shouldn't be able to come up with a ciphertext whose underlying plaintext is related to the original message through a relation that also takes public keys into account.\n\nCan malleability be exploited in stream ciphers?",
    "context": "",
    "output": "A: Yes, malleability can be exploited in stream ciphers by an attacker who can modify the ciphertext, potentially altering the plaintext in a predictable manner.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Can malleability be exploited in stream ciphers?",
      "answer": "Yes, malleability can be exploited in stream ciphers by an attacker who can modify the ciphertext, potentially altering the plaintext in a predictable manner.",
      "context": "Malleability (cryptography)\n\n==Introduction==\nMalleability is a property of some cryptographic algorithms. An encryption algorithm is \"malleable\" if it is possible to transform a ciphertext into another ciphertext which decrypts to a related plaintext. That is, given an encryption of a plaintext \n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n  , it is possible to generate another ciphertext which decrypts to \n  \n    \n      \n        f\n        (\n        m\n        )\n      \n    \n    {\\displaystyle f(m)}\n  , for a known function \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n  , without necessarily knowing or learning \n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n  .\nMalleability is often an undesirable property in a general-purpose cryptosystem, since it allows an attacker to modify the contents of a message.  For example, suppose that a bank uses a stream cipher to hide its financial information, and a user sends an encrypted message containing, say, \"TRANSFER $0000100.00 TO ACCOUNT #199.\"  If an attacker can modify the message on the wire, and can guess the format of the unencrypted message, the attacker could change the amount of the transaction, or the recipient of the funds, e.g.  \"TRANSFER $0100000.00 TO ACCOUNT #227\". Malleability does not refer to the attacker's ability to read the encrypted message. Both before and after tampering, the attacker cannot read the encrypted message.\nOn the other hand, some cryptosystems are malleable by design. In other words, in some circumstances it may be viewed as a feature that anyone can transform an encryption of \n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n   into a valid encryption of \n  \n    \n      \n        f\n        (\n        m\n        )\n      \n    \n    {\\displaystyle f(m)}\n    (for some restricted class of functions \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n  ) without necessarily learning \n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n  . Such schemes are known as homomorphic encryption schemes.\nA cryptosystem may be semantically secure against chosen plaintext attacks or even non-adaptive chosen ciphertext attacks (CCA1) while still being malleable. However, security against adaptive chosen ciphertext attacks (CCA2) is equivalent to non-malleability.\n\n\n\n== Example malleable cryptosystems ==\nIn a stream cipher, the ciphertext is produced by taking the exclusive or of the plaintext and a pseudorandom stream based on a secret key \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  , as \n  \n    \n      \n        E\n        (\n        m\n        )\n\n== Complete non-malleability ==\nFischlin, in 2005, defined the notion of complete non-malleability as the ability of the system to remain non-malleable while giving the adversary additional power to choose a new public key which could be a function of the original public key. In other words, the adversary shouldn't be able to come up with a ciphertext whose underlying plaintext is related to the original message through a relation that also takes public keys into account."
    }
  },
  {
    "instruction": "Firewalld\n\n==Introduction==\nfirewalld is a firewall management tool for Linux operating systems. It provides firewall features by acting as a front-end for the Linux kernel's netfilter framework. firewalld's current default backend is nftables. Prior to v0.6.0, iptables was the default backend. Through its abstractions, firewalld acts as an alternative to nft and iptables command line programs. The name firewalld adheres to the Unix convention of naming system daemons by appending the letter \"d\".firewalld is written in Python. It was intended to be ported to C++, but the porting project was abandoned in January 2015.\n\n== Features ==\nfirewalld supports both IPv4 and IPv6 networks and can administer separate firewall zones with varying degrees of trust as defined in zone profiles. Administrators can configure Network Manager to automatically switch zone profiles based on known Wi-Fi (wireless) and Ethernet (wired) networks, but firewalld cannot do this on its own.Services and applications can use the D-Bus interface to query and configure the firewall. firewalld supports timed rules, meaning the number of connections (or \"hits\") to a service can be limited globally. There is no support for hit-counting and subsequent connection rejection per source IP; a common technique deployed to limit the impact of  brute-force  hacking and distributed denial-of-service attacks.firewalld's command syntax is similar to but more verbose than other iptables front-ends like Ubuntu's Uncomplicated Firewall (ufw). The command-line interface allows managing firewall rulesets for protocol, ports, source and destination; or predefined services by name.\nServices are defined as XML files containing port- and protocol-mappings, and optionally extra information like specifying subnets and listing required Kernel helper modules.\nThe syntax resembles that of systemd's service files. A simple service file for a web server listening on TCP port 443 might look like this:\n\n== Forward and output filtering ==\nfirewalld v0.9.0 added native support for forward and output forwarding via policy objects. This allows filtering traffic flowing between zones. Policies support most firewalld primitives available to zones: services, ports, forward-ports, masquerade, rich rules, etc.\n\n== Limitations ==\nBy default firewalld does not block outbound traffic as required by standards such as NIST 800-171 and 800-53. However, an outbound block can be added with a policy.\n\n== Graphical front-ends (GUIs) ==\nfirewall-config is a graphical front-end that is optionally included with firewalld, with support for most of its features.\nfirewall-applet is a small status indicator utility that is optionally included with firewalld. It can provide firewall event log notifications as well as a quick way to open firewall-config. firewall-applet was ported from the GTK+ to the Qt framework in the summer of 2015 following the GNOME Desktop\u2019s deprecation of system tray icons.\n\n== Adoption ==\nfirewalld ships by default on the following Linux distributions:\nCentOS 7 and newer\nFedora 18 and newer\nOpenSUSE Leap 15 and newer\nRed Hat Enterprise Linux 7 and newer\nSUSE Linux Enterprise 15 and newer\nEndeavourOS Apollo and newerfirewalld is enabled by default in all of these distributions. firewalld is also available as one of many firewall options in the package repository of many other popular distributions such as Debian or Ubuntu.\nQuestion: What does firewalld use as its default backend for providing firewall features on Linux operating systems?",
    "context": "",
    "output": "Answer: firewalld's current default backend is nftables.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What does firewalld use as its default backend for providing firewall features on Linux operating systems?",
      "answer": "firewalld's current default backend is nftables.",
      "context": "Firewalld\n\n==Introduction==\nfirewalld is a firewall management tool for Linux operating systems. It provides firewall features by acting as a front-end for the Linux kernel's netfilter framework. firewalld's current default backend is nftables. Prior to v0.6.0, iptables was the default backend. Through its abstractions, firewalld acts as an alternative to nft and iptables command line programs. The name firewalld adheres to the Unix convention of naming system daemons by appending the letter \"d\".firewalld is written in Python. It was intended to be ported to C++, but the porting project was abandoned in January 2015.\n\n== Features ==\nfirewalld supports both IPv4 and IPv6 networks and can administer separate firewall zones with varying degrees of trust as defined in zone profiles. Administrators can configure Network Manager to automatically switch zone profiles based on known Wi-Fi (wireless) and Ethernet (wired) networks, but firewalld cannot do this on its own.Services and applications can use the D-Bus interface to query and configure the firewall. firewalld supports timed rules, meaning the number of connections (or \"hits\") to a service can be limited globally. There is no support for hit-counting and subsequent connection rejection per source IP; a common technique deployed to limit the impact of  brute-force  hacking and distributed denial-of-service attacks.firewalld's command syntax is similar to but more verbose than other iptables front-ends like Ubuntu's Uncomplicated Firewall (ufw). The command-line interface allows managing firewall rulesets for protocol, ports, source and destination; or predefined services by name.\nServices are defined as XML files containing port- and protocol-mappings, and optionally extra information like specifying subnets and listing required Kernel helper modules.\nThe syntax resembles that of systemd's service files. A simple service file for a web server listening on TCP port 443 might look like this:\n\n== Forward and output filtering ==\nfirewalld v0.9.0 added native support for forward and output forwarding via policy objects. This allows filtering traffic flowing between zones. Policies support most firewalld primitives available to zones: services, ports, forward-ports, masquerade, rich rules, etc.\n\n== Limitations ==\nBy default firewalld does not block outbound traffic as required by standards such as NIST 800-171 and 800-53. However, an outbound block can be added with a policy.\n\n== Graphical front-ends (GUIs) ==\nfirewall-config is a graphical front-end that is optionally included with firewalld, with support for most of its features.\nfirewall-applet is a small status indicator utility that is optionally included with firewalld. It can provide firewall event log notifications as well as a quick way to open firewall-config. firewall-applet was ported from the GTK+ to the Qt framework in the summer of 2015 following the GNOME Desktop\u2019s deprecation of system tray icons.\n\n== Adoption ==\nfirewalld ships by default on the following Linux distributions:\nCentOS 7 and newer\nFedora 18 and newer\nOpenSUSE Leap 15 and newer\nRed Hat Enterprise Linux 7 and newer\nSUSE Linux Enterprise 15 and newer\nEndeavourOS Apollo and newerfirewalld is enabled by default in all of these distributions. firewalld is also available as one of many firewall options in the package repository of many other popular distributions such as Debian or Ubuntu."
    }
  },
  {
    "instruction": "Write an answer to the following question: Where was the searchable website, called wehaveyourdata, found to be hosted?",
    "context": "",
    "output": "The searchable website, called wehaveyourdata, was found to be hosted in Russia.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Where was the searchable website, called wehaveyourdata, found to be hosted?",
      "answer": "The searchable website, called wehaveyourdata, was found to be hosted in Russia."
    }
  },
  {
    "instruction": "Evasion (network security)\n\n==Introduction==\nIn network security, evasion is bypassing an information security defense in order to deliver an exploit, attack, or other form of malware to a target network or system, without detection. Evasions are typically used to counter network-based intrusion detection and prevention systems (IPS, IDS) but can also be used to by-pass firewalls and defeat malware analysis. A further target of evasions can be to crash a network security defense, rendering it in-effective to subsequent targeted attacks.\n\n\n\n== Description ==\nEvasions can be particularly nasty because a well-planned and implemented evasion can enable full sessions to be carried forth in packets that evade an IDS. Attacks carried in such sessions will happen right under the nose of the network and service administrators.\nThe security systems are rendered ineffective against well-designed evasion techniques, in the same way a stealth fighter can attack without detection by radar and other defensive systems.\nA good analogy to evasions is a system designed to recognize keywords in speech patterns on a phone system, such as \u201cbreak into system X\u201d. A simple evasion would be to use a language other than English, but which both parties can still understand, and wishfully a language that as few people as possible can talk.\n\n== Evasion attacks ==\nVarious advanced and targeted evasion attacks have been known since the mid-1990s:\n\nA seminal text describing the attacks against IDS systems appeared in 1997.\nOne of the first comprehensive description of attacks was reported by Ptacek and Newsham in a technical report in 1998.\nIn 1998, also an article in the Phrack Magazine describes ways to by-pass network intrusion detection.\n\n== Reports ==\nThe 1997 article mostly discusses various shell-scripting and character-based tricks to fool an IDS. The Phrack Magazine article and the technical report from Ptacek et al. discusses TCP/IP protocol exploits, evasions and others. More recent discussions on evasions include the report by Kevin Timm.\n\n== Protecting against evasions ==\nThe challenge in protecting servers from evasions is to model the end-host operation at the network security device, i.e., the device should be able to know how the target host would interpret the traffic, and if it would be harmful, or not. A key solution in protecting against evasions is traffic normalization at the IDS/IPS device. The other way separation internet access can be implemented based on how endpoint user can be safe accessing the internet segment.Lately there has been discussions on putting more effort on research in evasion techniques. A presentation at Hack.lu discussed some potentially new evasion techniques and how to apply multiple evasion techniques to by-pass network security devices.\nRead the text above and answer this question: How do evasions compare to stealth fighters in terms of their ability to bypass detection?",
    "context": "",
    "output": "Just as stealth fighters can attack without detection by radar and other defensive systems, evasions can carry out attacks without being detected by security systems.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do evasions compare to stealth fighters in terms of their ability to bypass detection?",
      "answer": "Just as stealth fighters can attack without detection by radar and other defensive systems, evasions can carry out attacks without being detected by security systems.",
      "context": "Evasion (network security)\n\n==Introduction==\nIn network security, evasion is bypassing an information security defense in order to deliver an exploit, attack, or other form of malware to a target network or system, without detection. Evasions are typically used to counter network-based intrusion detection and prevention systems (IPS, IDS) but can also be used to by-pass firewalls and defeat malware analysis. A further target of evasions can be to crash a network security defense, rendering it in-effective to subsequent targeted attacks.\n\n\n\n== Description ==\nEvasions can be particularly nasty because a well-planned and implemented evasion can enable full sessions to be carried forth in packets that evade an IDS. Attacks carried in such sessions will happen right under the nose of the network and service administrators.\nThe security systems are rendered ineffective against well-designed evasion techniques, in the same way a stealth fighter can attack without detection by radar and other defensive systems.\nA good analogy to evasions is a system designed to recognize keywords in speech patterns on a phone system, such as \u201cbreak into system X\u201d. A simple evasion would be to use a language other than English, but which both parties can still understand, and wishfully a language that as few people as possible can talk.\n\n== Evasion attacks ==\nVarious advanced and targeted evasion attacks have been known since the mid-1990s:\n\nA seminal text describing the attacks against IDS systems appeared in 1997.\nOne of the first comprehensive description of attacks was reported by Ptacek and Newsham in a technical report in 1998.\nIn 1998, also an article in the Phrack Magazine describes ways to by-pass network intrusion detection.\n\n== Reports ==\nThe 1997 article mostly discusses various shell-scripting and character-based tricks to fool an IDS. The Phrack Magazine article and the technical report from Ptacek et al. discusses TCP/IP protocol exploits, evasions and others. More recent discussions on evasions include the report by Kevin Timm.\n\n== Protecting against evasions ==\nThe challenge in protecting servers from evasions is to model the end-host operation at the network security device, i.e., the device should be able to know how the target host would interpret the traffic, and if it would be harmful, or not. A key solution in protecting against evasions is traffic normalization at the IDS/IPS device. The other way separation internet access can be implemented based on how endpoint user can be safe accessing the internet segment.Lately there has been discussions on putting more effort on research in evasion techniques. A presentation at Hack.lu discussed some potentially new evasion techniques and how to apply multiple evasion techniques to by-pass network security devices."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the purpose of the review phase in the eDiscovery process?",
    "context": "",
    "output": "During the review phase, documents are reviewed for responsiveness to discovery requests and for privilege.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the purpose of the review phase in the eDiscovery process?",
      "answer": "During the review phase, documents are reviewed for responsiveness to discovery requests and for privilege."
    }
  },
  {
    "instruction": "Write an answer to the following question: When did the Viasat hack occur and what was the impact?",
    "context": "",
    "output": "The Viasat hack occurred on 24 February 2022, resulting in thousands of modems getting bricked and thousands of customers in Europe being without internet for a month. Additionally, remote control of 5,800 wind turbines belonging to Enercon in Central Europe was affected.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "When did the Viasat hack occur and what was the impact?",
      "answer": "The Viasat hack occurred on 24 February 2022, resulting in thousands of modems getting bricked and thousands of customers in Europe being without internet for a month. Additionally, remote control of 5,800 wind turbines belonging to Enercon in Central Europe was affected."
    }
  },
  {
    "instruction": "Write an answer to the following question: Which instruction set does Kali Linux support?",
    "context": "",
    "output": "Kali Linux is distributed in 32-bit and 64-bit images for use on hosts based on the x86 instruction set, as well as an image for the ARM architecture for use on the Beagle Board computer and Samsung's ARM Chromebook.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Which instruction set does Kali Linux support?",
      "answer": "Kali Linux is distributed in 32-bit and 64-bit images for use on hosts based on the x86 instruction set, as well as an image for the ARM architecture for use on the Beagle Board computer and Samsung's ARM Chromebook."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the difference between a 40-bit key and a derived key, and why is a 40-bit key considered insecure?",
    "context": "",
    "output": "A 40-bit key is a key with a length of 40 bits, which was once the upper limit of what could be exported from the U.S. and other countries without a license. A derived key, on the other hand, is a key computed by applying a predetermined hash algorithm or key derivation function to a password or passphrase. A 40-bit key is considered insecure due to its short key length, which makes it relatively easy for attackers to perform brute-force attacks. In contrast, derived keys can be more secure as they are based on a password or passphrase, which can be longer and more complex.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the difference between a 40-bit key and a derived key, and why is a 40-bit key considered insecure?",
      "answer": "A 40-bit key is a key with a length of 40 bits, which was once the upper limit of what could be exported from the U.S. and other countries without a license. A derived key, on the other hand, is a key computed by applying a predetermined hash algorithm or key derivation function to a password or passphrase. A 40-bit key is considered insecure due to its short key length, which makes it relatively easy for attackers to perform brute-force attacks. In contrast, derived keys can be more secure as they are based on a password or passphrase, which can be longer and more complex."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the timeline of the Aurora vulnerability and its recognition in the industry?",
    "context": "",
    "output": "The Aurora vulnerability was first demonstrated on March 4, 2007, and was then notified to the industry by NERC on June 21, 2007. It gained public attention when CNN released a previously classified demonstration video on September 27, 2007. NERC released a recommendation to industry on the Aurora vulnerability on October 13, 2010, and the US Department of Homeland Security released 840 pages of documents related to Aurora on July 3, 2014.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the timeline of the Aurora vulnerability and its recognition in the industry?",
      "answer": "The Aurora vulnerability was first demonstrated on March 4, 2007, and was then notified to the industry by NERC on June 21, 2007. It gained public attention when CNN released a previously classified demonstration video on September 27, 2007. NERC released a recommendation to industry on the Aurora vulnerability on October 13, 2010, and the US Department of Homeland Security released 840 pages of documents related to Aurora on July 3, 2014."
    }
  },
  {
    "instruction": "Write an answer to the following question: How has the PRISM program been received by the international community?",
    "context": "",
    "output": "The PRISM program has been met with general displeasure by the international community. National leaders have spoken against the NSA, while some have spoken against their own national surveillance. Some question if the costs of hunting terrorists now overshadow the loss of citizen privacy.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How has the PRISM program been received by the international community?",
      "answer": "The PRISM program has been met with general displeasure by the international community. National leaders have spoken against the NSA, while some have spoken against their own national surveillance. Some question if the costs of hunting terrorists now overshadow the loss of citizen privacy."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does MILS architecture ensure that security monitors are always invoked?",
    "context": "",
    "output": "MILS architecture ensures that security monitors are always invoked by checking each and every access/message, preventing unauthorized changes to security monitor code, configuration, and data.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does MILS architecture ensure that security monitors are always invoked?",
      "answer": "MILS architecture ensures that security monitors are always invoked by checking each and every access/message, preventing unauthorized changes to security monitor code, configuration, and data."
    }
  },
  {
    "instruction": "Dynamic linker\n\n==Introduction==\nIn computing, a dynamic linker is the part of an operating system that loads and links the shared libraries needed by an executable when it is executed (at \"run time\"), by copying the content of libraries from persistent storage to RAM, filling jump tables and relocating pointers. The specific operating system and executable format determine how the dynamic linker functions and how it is implemented.\nLinking is often referred to as a process that is performed when the executable is compiled, while a dynamic linker is a special part of an operating system that loads external shared libraries into a running process and then binds those shared libraries dynamically to the running process. This approach is also called dynamic linking or late linking.\n\n== Implementations ==\n\n\n*** Microsoft Windows ***\n\nDynamic-link library, or DLL, is Microsoft's implementation of the shared library concept in the Microsoft Windows and OS/2 operating systems. These libraries usually have the file extension DLL, OCX (for libraries containing ActiveX controls), or DRV (for legacy system drivers).  The file formats for DLLs are the same as for Windows EXE files \u2013  that is, Portable Executable (PE) for 32-bit and 64-bit Windows, and New Executable (NE) for 16-bit Windows. As with EXEs, DLLs can contain code, data, and resources, in any combination.\nData files with the same file format as a DLL, but with different file extensions and possibly containing only resource sections, can be called resource DLLs. Examples of such DLLs include multi-language user interface libraries with extension MUI, icon libraries, sometimes having the extension ICL, and font files, having the extensions FON and FOT.\n\n\n*** Unix-like systems using ELF, and Darwin-based systems ***\nIn most Unix-like systems, most of the machine code that makes up the dynamic linker is actually an external executable that the operating system kernel loads and executes first in a process address space newly constructed as a result of calling exec or posix_spawn functions. At link time, the path of the dynamic linker that should be used is embedded into the executable image.\nWhen an executable file is loaded, the operating system kernel reads the path of the dynamic linker from it and then attempts to load and execute this other executable binary; if that attempt fails because, for example, there is no file with that path, the attempt to execute the original executable fails. The dynamic linker then loads the initial executable image and all the dynamically-linked libraries on which it depends and starts the executable. As a result, the pathname of the dynamic linker is part of the operating system's application binary interface.\n\n\n**** Systems using ELF ****\nIn Unix-like systems that use ELF for executable images and dynamic libraries, such as Solaris, 64-bit versions of HP-UX, Linux, FreeBSD, NetBSD, OpenBSD, and DragonFly BSD, the path of the dynamic linker that should be used is embedded at link time into the .interp section of the executable's PT_INTERP segment.  In those systems, dynamically loaded shared libraries can be identified by the filename suffix .so (shared object).\nThe dynamic linker can be influenced into modifying its behavior during either the program's execution or the program's linking, and the examples of this can be seen in the run-time linker manual pages for various Unix-like systems. A typical modification of this behavior is the use of LD_LIBRARY_PATH and LD_PRELOAD environment variables, which adjust the runtime linking process by searching for shared libraries at alternate locations and by forcibly loading and linking libraries that would otherwise not be, respectively.  An example is zlibc, also known as uncompress.so, which facilitates transparent decompression when used through the LD_PRELOAD hack; consequently, it is possible to read pre-compressed (gzipped) file data on BSD and Linux systems as if the files were not compressed, essentially allowing a user to add transparent compression to the underlying filesystem, although with some caveats. The mechanism is flexible, allowing trivial adaptation of the same code to perform additional or alternate processing of data during the file read, prior to the provision of said data to the user process that has requested it.\n\n\n**** macOS and iOS ****\nIn the Apple Darwin operating system, and in the macOS and iOS operating systems built on top of it, the path of the dynamic linker that should be used is embedded at link time into one of the Mach-O load commands in the executable image.  In those systems, dynamically loaded shared libraries can be identified either by the filename suffix .dylib or by their placement inside the bundle for a framework.\nThe dynamic linker not only links the target executable to the shared libraries but also places machine code functions at specific address points in memory that the target executable knows about at link time. When an executable wishes to interact with the dynamic linker, it simply executes the machine-specific call or jump instruction to one of those well-known address points. The executables on the macOS and iOS platforms often interact with the dynamic linker during the execution of the process; it is even known that an executable might interact with the dynamic linker, causing it to load more libraries and resolve more symbols, hours after it initially launches. The reason that a macOS or iOS program interacts with the dynamic linker so often is due both to Apple's Cocoa and Cocoa Touch APIs and Objective-C, the language in which they are implemented (see their main articles for more information).\nThe dynamic linker can be coerced into modifying some of its behavior; however, unlike other Unix-like operating systems, these modifications are hints that can be (and sometimes are) ignored by the dynamic linker. Examples of this can be seen in dyld's manual page. A typical modification of this behavior is the use of the DYLD_FRAMEWORK_PATH and DYLD_PRINT_LIBRARIES environment variables. The former of the previously-mentioned variables adjusts the executables' search path for the shared libraries, while the latter displays the names of the libraries as they are loaded and linked.\nApple's macOS dynamic linker is an open-source project released as part of Darwin and can be found in the Apple's open-source dyld project.\n\n\n*** XCOFF-based Unix-like systems ***\nIn Unix-like operating systems using XCOFF, such as AIX, dynamically-loaded shared libraries use the filename suffix .a.\nThe dynamic linker can be influenced into modifying its behavior during either the program's execution or the program's linking.\nA typical modification of this behavior is the use of the LIBPATH environment variable.\nThis variable adjusts the runtime linking process by searching for shared libraries at alternate locations and by forcibly loading and linking libraries that would otherwise not be, respectively.\n\n\n*** OS/360 and successors ***\nDynamic linking from Assembler language programs in IBM OS/360 and its successors is done typically using a LINK macro instruction containing a Supervisor Call instruction that activates the operating system routines that makes  the library module to be linked available to the program. Library modules may reside in a \"STEPLIB\" or \"JOBLIB\" specified in control cards and only available to a specific execution of the program, in a library included in the LINKLIST in the PARMLIB (specified at system startup time), or in the \"link pack area\" where specific reentrant modules are loaded at system startup time.\n\n\n*** Multics ***\nIn the Multics operating system all files, including executables, are segments. A call to a routine not part of the current segment will cause the system to find the referenced segment, in memory or on disk, and add it to the address space of the running process. Dynamic linking is the normal method of operation, and static linking (using the binder) is the exception.\n\n== Efficiency ==\nDynamic linking is generally slower (requires more CPU cycles) than linking during compilation time, as is the case for most processes executed at runtime. However, dynamic linking is often more space-efficient (on disk and in memory at runtime). When a library is linked statically, every process being run is linked with its own copy of the library functions being called upon. Therefore, if a library is called upon many times by different programs, the same functions in that library are duplicated in several places in the system's memory. Using shared, dynamic libraries means that, instead of linking each file to its own copy of a library at compilation time and potentially wasting memory space, only one copy of the library is ever stored in memory at a time, freeing up memory space to be used elsewhere. Additionally, in dynamic linking, a library is only loaded if it is actually being used.\n\nHow does the dynamic linker function in different operating systems?",
    "context": "",
    "output": "The dynamic linker functions differently in different operating systems, such as Microsoft Windows, Unix-like systems using ELF and Darwin-based systems, XCOFF-based Unix-like systems, IBM OS/360 and its successors, and Multics. The specific implementation depends on the operating system and executable format.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the dynamic linker function in different operating systems?",
      "answer": "The dynamic linker functions differently in different operating systems, such as Microsoft Windows, Unix-like systems using ELF and Darwin-based systems, XCOFF-based Unix-like systems, IBM OS/360 and its successors, and Multics. The specific implementation depends on the operating system and executable format.",
      "context": "Dynamic linker\n\n==Introduction==\nIn computing, a dynamic linker is the part of an operating system that loads and links the shared libraries needed by an executable when it is executed (at \"run time\"), by copying the content of libraries from persistent storage to RAM, filling jump tables and relocating pointers. The specific operating system and executable format determine how the dynamic linker functions and how it is implemented.\nLinking is often referred to as a process that is performed when the executable is compiled, while a dynamic linker is a special part of an operating system that loads external shared libraries into a running process and then binds those shared libraries dynamically to the running process. This approach is also called dynamic linking or late linking.\n\n== Implementations ==\n\n\n*** Microsoft Windows ***\n\nDynamic-link library, or DLL, is Microsoft's implementation of the shared library concept in the Microsoft Windows and OS/2 operating systems. These libraries usually have the file extension DLL, OCX (for libraries containing ActiveX controls), or DRV (for legacy system drivers).  The file formats for DLLs are the same as for Windows EXE files \u2013  that is, Portable Executable (PE) for 32-bit and 64-bit Windows, and New Executable (NE) for 16-bit Windows. As with EXEs, DLLs can contain code, data, and resources, in any combination.\nData files with the same file format as a DLL, but with different file extensions and possibly containing only resource sections, can be called resource DLLs. Examples of such DLLs include multi-language user interface libraries with extension MUI, icon libraries, sometimes having the extension ICL, and font files, having the extensions FON and FOT.\n\n\n*** Unix-like systems using ELF, and Darwin-based systems ***\nIn most Unix-like systems, most of the machine code that makes up the dynamic linker is actually an external executable that the operating system kernel loads and executes first in a process address space newly constructed as a result of calling exec or posix_spawn functions. At link time, the path of the dynamic linker that should be used is embedded into the executable image.\nWhen an executable file is loaded, the operating system kernel reads the path of the dynamic linker from it and then attempts to load and execute this other executable binary; if that attempt fails because, for example, there is no file with that path, the attempt to execute the original executable fails. The dynamic linker then loads the initial executable image and all the dynamically-linked libraries on which it depends and starts the executable. As a result, the pathname of the dynamic linker is part of the operating system's application binary interface.\n\n\n**** Systems using ELF ****\nIn Unix-like systems that use ELF for executable images and dynamic libraries, such as Solaris, 64-bit versions of HP-UX, Linux, FreeBSD, NetBSD, OpenBSD, and DragonFly BSD, the path of the dynamic linker that should be used is embedded at link time into the .interp section of the executable's PT_INTERP segment.  In those systems, dynamically loaded shared libraries can be identified by the filename suffix .so (shared object).\nThe dynamic linker can be influenced into modifying its behavior during either the program's execution or the program's linking, and the examples of this can be seen in the run-time linker manual pages for various Unix-like systems. A typical modification of this behavior is the use of LD_LIBRARY_PATH and LD_PRELOAD environment variables, which adjust the runtime linking process by searching for shared libraries at alternate locations and by forcibly loading and linking libraries that would otherwise not be, respectively.  An example is zlibc, also known as uncompress.so, which facilitates transparent decompression when used through the LD_PRELOAD hack; consequently, it is possible to read pre-compressed (gzipped) file data on BSD and Linux systems as if the files were not compressed, essentially allowing a user to add transparent compression to the underlying filesystem, although with some caveats. The mechanism is flexible, allowing trivial adaptation of the same code to perform additional or alternate processing of data during the file read, prior to the provision of said data to the user process that has requested it.\n\n\n**** macOS and iOS ****\nIn the Apple Darwin operating system, and in the macOS and iOS operating systems built on top of it, the path of the dynamic linker that should be used is embedded at link time into one of the Mach-O load commands in the executable image.  In those systems, dynamically loaded shared libraries can be identified either by the filename suffix .dylib or by their placement inside the bundle for a framework.\nThe dynamic linker not only links the target executable to the shared libraries but also places machine code functions at specific address points in memory that the target executable knows about at link time. When an executable wishes to interact with the dynamic linker, it simply executes the machine-specific call or jump instruction to one of those well-known address points. The executables on the macOS and iOS platforms often interact with the dynamic linker during the execution of the process; it is even known that an executable might interact with the dynamic linker, causing it to load more libraries and resolve more symbols, hours after it initially launches. The reason that a macOS or iOS program interacts with the dynamic linker so often is due both to Apple's Cocoa and Cocoa Touch APIs and Objective-C, the language in which they are implemented (see their main articles for more information).\nThe dynamic linker can be coerced into modifying some of its behavior; however, unlike other Unix-like operating systems, these modifications are hints that can be (and sometimes are) ignored by the dynamic linker. Examples of this can be seen in dyld's manual page. A typical modification of this behavior is the use of the DYLD_FRAMEWORK_PATH and DYLD_PRINT_LIBRARIES environment variables. The former of the previously-mentioned variables adjusts the executables' search path for the shared libraries, while the latter displays the names of the libraries as they are loaded and linked.\nApple's macOS dynamic linker is an open-source project released as part of Darwin and can be found in the Apple's open-source dyld project.\n\n\n*** XCOFF-based Unix-like systems ***\nIn Unix-like operating systems using XCOFF, such as AIX, dynamically-loaded shared libraries use the filename suffix .a.\nThe dynamic linker can be influenced into modifying its behavior during either the program's execution or the program's linking.\nA typical modification of this behavior is the use of the LIBPATH environment variable.\nThis variable adjusts the runtime linking process by searching for shared libraries at alternate locations and by forcibly loading and linking libraries that would otherwise not be, respectively.\n\n\n*** OS/360 and successors ***\nDynamic linking from Assembler language programs in IBM OS/360 and its successors is done typically using a LINK macro instruction containing a Supervisor Call instruction that activates the operating system routines that makes  the library module to be linked available to the program. Library modules may reside in a \"STEPLIB\" or \"JOBLIB\" specified in control cards and only available to a specific execution of the program, in a library included in the LINKLIST in the PARMLIB (specified at system startup time), or in the \"link pack area\" where specific reentrant modules are loaded at system startup time.\n\n\n*** Multics ***\nIn the Multics operating system all files, including executables, are segments. A call to a routine not part of the current segment will cause the system to find the referenced segment, in memory or on disk, and add it to the address space of the running process. Dynamic linking is the normal method of operation, and static linking (using the binder) is the exception.\n\n== Efficiency ==\nDynamic linking is generally slower (requires more CPU cycles) than linking during compilation time, as is the case for most processes executed at runtime. However, dynamic linking is often more space-efficient (on disk and in memory at runtime). When a library is linked statically, every process being run is linked with its own copy of the library functions being called upon. Therefore, if a library is called upon many times by different programs, the same functions in that library are duplicated in several places in the system's memory. Using shared, dynamic libraries means that, instead of linking each file to its own copy of a library at compilation time and potentially wasting memory space, only one copy of the library is ever stored in memory at a time, freeing up memory space to be used elsewhere. Additionally, in dynamic linking, a library is only loaded if it is actually being used."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is Continuous Data Protection (CDP) and how does it differ from Near-CDP?",
    "context": "",
    "output": "Continuous Data Protection (CDP) instantly saves a copy of every change made to the data, allowing restoration of data to any point in time. Near-CDP backup applications automatically take incremental backups at a specific interval, allowing restores to an interval boundary. True CDP must be run in conjunction with a virtual machine, while Near-CDP is more practicable for ordinary personal backup applications.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is Continuous Data Protection (CDP) and how does it differ from Near-CDP?",
      "answer": "Continuous Data Protection (CDP) instantly saves a copy of every change made to the data, allowing restoration of data to any point in time. Near-CDP backup applications automatically take incremental backups at a specific interval, allowing restores to an interval boundary. True CDP must be run in conjunction with a virtual machine, while Near-CDP is more practicable for ordinary personal backup applications."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the NATO Cyber Operations Centre contribute to the alliance's cyber defense?",
    "context": "",
    "output": "The NATO Cyber Operations Centre is responsible for the defense of the alliance's communication and information systems, as well as for conducting cyber intelligence and cyber warfare operations in support of NATO's missions and operations. It also provides cyber security education and awareness programs to the NATO personnel and collaborates with other national and international organizations to enhance the cyber defense capabilities of the alliance.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the NATO Cyber Operations Centre contribute to the alliance's cyber defense?",
      "answer": "The NATO Cyber Operations Centre is responsible for the defense of the alliance's communication and information systems, as well as for conducting cyber intelligence and cyber warfare operations in support of NATO's missions and operations. It also provides cyber security education and awareness programs to the NATO personnel and collaborates with other national and international organizations to enhance the cyber defense capabilities of the alliance."
    }
  },
  {
    "instruction": "Write an answer to the following question: How do challenge-response (C/R) systems differentiate between legitimate senders and spammers?",
    "context": "",
    "output": "C/R systems exploit the differences in characteristics between legitimate senders and spammers. Legitimate senders typically have a valid return address, while spammers usually forge a return address. Additionally, spammers send emails in large quantities, while legitimate senders generally send emails individually. C/R systems use these differences to create challenges that are easy for legitimate senders to fulfill and difficult for spammers to complete in large numbers.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do challenge-response (C/R) systems differentiate between legitimate senders and spammers?",
      "answer": "C/R systems exploit the differences in characteristics between legitimate senders and spammers. Legitimate senders typically have a valid return address, while spammers usually forge a return address. Additionally, spammers send emails in large quantities, while legitimate senders generally send emails individually. C/R systems use these differences to create challenges that are easy for legitimate senders to fulfill and difficult for spammers to complete in large numbers."
    }
  },
  {
    "instruction": "OTPW\n\n==Introduction==\nOTPW is a one-time password system developed for authentication in Unix-like operating systems by Markus Kuhn. A user's real password is not directly transmitted across the network. Rather, a series of one-time passwords is created from a short set of characters (constant secret) and a set of one-time tokens. As each single-use password can only be used once, passwords intercepted by a password sniffer or key logger are not useful to an attacker.\nOTPW is supported in Unix and Linux (via pluggable authentication modules), OpenBSD, NetBSD, and FreeBSD, and a generic open source implementation can be used to enable its use on other systems.\nOTPW, like the other one-time password systems, is sensitive to a man in the middle attack if used by itself. This could for example be solved by putting SSL, SPKM or similar security protocol \"under it\" which authenticates the server and gives point-to-point security between the client and server.\n\n\n\n== Design and differences from other implementations ==\nUnlike S/KEY, OTPW is not based on the Lamport's scheme in which every one-time password is the one-way hash value of its successor. Password lists based on the Lamport's scheme have the problem that if the attacker can see one of the last passwords on the list, then all previous passwords can be calculated from it. It also does not store the encrypted passwords as suggested by Aviel D. Rubin in Independent One-Time Passwords, in order to keep the host free of files with secrets.\nIn OTPW a one-way hash value of every single password is stored in a potentially widely readable file in the user\u2019s home directory. For instance, hash values of 300 passwords (a typical A4 page) require only a four kilobyte long .otpw file, a typically negligible amount of storage space.\nThe passwords are carefully generated random numbers. The random number generator is based on the RIPEMD-160 secure hash function, and it is seeded by hashing together the output of various shell commands. These provide unpredictability in the form of a system random number seed, access times of important system files, usage history of the host, and more. The random state is the 160-bit output of the hash function. The random state is iterated after each use by concatenating the old state with the current high-resolution timer output and hashing the result again. The first 72 bits of the hash output are encoded with a modified base64 scheme to produce readable passwords, while the remaining 88 bits represent the undisclosed internal state of the random number generator.\nIn many fonts, the characters 0 and O or 1 and l and I are difficult to distinguish, therefore the modified base64 encoding replaces the three characters 01l by corresponding :,\n\n== Usage ==\nOne-time password authentication with the OTPW package is accomplished via a file .otpw located in the user\u2019s home directory. No state is kept in any system-wide files, therefore OTPW does not introduce any new setuid root programs. As long as a user does not have .otpw in his home directory, the one-time-password facility has not been activated for him.\nA user who wants to set up the one-time-password capability just executes the otpw-gen program. The program will ask for a prefix password and it will then write a password list to standard output. The chosen prefix password should be memorized and the password list can be formatted and printed.\nWhere one-time-password authentication is used, the password prompt will be followed by a 3-digit password number. Enter first the prefix password that was given to otpw-gen, followed directly (without hitting return between) by the password with the requested number from the printed password list:\n\n  login: kuhn\n  Password 019: geHeimOdAkH62c\n\nIn this example, geHeim was the prefix password.\nA clever attacker might observe the password being entered and might try to use the fact that computers can send data much faster than users can finish entering passwords. In the several hundred milliseconds that the user needs to press the return key after the last character, an attacker could on a parallel connection to the same machine send the code of the return key faster than the user.\nTo prevent such a race-for-the-last-key attack, any login attempt that is taking place concurrently with another attempt will require three one-time passwords to be entered, neither of which will ever be the password which is locked by the concurrent authentication attempt.\n\n  login: kuhn\n  Password 022/000/004: geHeimQ\n\nAnswer this question based on the above context: What is the purpose of the prefix password in OTPW?",
    "context": "",
    "output": "The prefix password in OTPW is a memorized password given to the user during the setup of the one-time-password capability. It is entered first, followed directly by the requested password from the printed password list.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the purpose of the prefix password in OTPW?",
      "answer": "The prefix password in OTPW is a memorized password given to the user during the setup of the one-time-password capability. It is entered first, followed directly by the requested password from the printed password list.",
      "context": "OTPW\n\n==Introduction==\nOTPW is a one-time password system developed for authentication in Unix-like operating systems by Markus Kuhn. A user's real password is not directly transmitted across the network. Rather, a series of one-time passwords is created from a short set of characters (constant secret) and a set of one-time tokens. As each single-use password can only be used once, passwords intercepted by a password sniffer or key logger are not useful to an attacker.\nOTPW is supported in Unix and Linux (via pluggable authentication modules), OpenBSD, NetBSD, and FreeBSD, and a generic open source implementation can be used to enable its use on other systems.\nOTPW, like the other one-time password systems, is sensitive to a man in the middle attack if used by itself. This could for example be solved by putting SSL, SPKM or similar security protocol \"under it\" which authenticates the server and gives point-to-point security between the client and server.\n\n\n\n== Design and differences from other implementations ==\nUnlike S/KEY, OTPW is not based on the Lamport's scheme in which every one-time password is the one-way hash value of its successor. Password lists based on the Lamport's scheme have the problem that if the attacker can see one of the last passwords on the list, then all previous passwords can be calculated from it. It also does not store the encrypted passwords as suggested by Aviel D. Rubin in Independent One-Time Passwords, in order to keep the host free of files with secrets.\nIn OTPW a one-way hash value of every single password is stored in a potentially widely readable file in the user\u2019s home directory. For instance, hash values of 300 passwords (a typical A4 page) require only a four kilobyte long .otpw file, a typically negligible amount of storage space.\nThe passwords are carefully generated random numbers. The random number generator is based on the RIPEMD-160 secure hash function, and it is seeded by hashing together the output of various shell commands. These provide unpredictability in the form of a system random number seed, access times of important system files, usage history of the host, and more. The random state is the 160-bit output of the hash function. The random state is iterated after each use by concatenating the old state with the current high-resolution timer output and hashing the result again. The first 72 bits of the hash output are encoded with a modified base64 scheme to produce readable passwords, while the remaining 88 bits represent the undisclosed internal state of the random number generator.\nIn many fonts, the characters 0 and O or 1 and l and I are difficult to distinguish, therefore the modified base64 encoding replaces the three characters 01l by corresponding :,\n\n== Usage ==\nOne-time password authentication with the OTPW package is accomplished via a file .otpw located in the user\u2019s home directory. No state is kept in any system-wide files, therefore OTPW does not introduce any new setuid root programs. As long as a user does not have .otpw in his home directory, the one-time-password facility has not been activated for him.\nA user who wants to set up the one-time-password capability just executes the otpw-gen program. The program will ask for a prefix password and it will then write a password list to standard output. The chosen prefix password should be memorized and the password list can be formatted and printed.\nWhere one-time-password authentication is used, the password prompt will be followed by a 3-digit password number. Enter first the prefix password that was given to otpw-gen, followed directly (without hitting return between) by the password with the requested number from the printed password list:\n\n  login: kuhn\n  Password 019: geHeimOdAkH62c\n\nIn this example, geHeim was the prefix password.\nA clever attacker might observe the password being entered and might try to use the fact that computers can send data much faster than users can finish entering passwords. In the several hundred milliseconds that the user needs to press the return key after the last character, an attacker could on a parallel connection to the same machine send the code of the return key faster than the user.\nTo prevent such a race-for-the-last-key attack, any login attempt that is taking place concurrently with another attempt will require three one-time passwords to be entered, neither of which will ever be the password which is locked by the concurrent authentication attempt.\n\n  login: kuhn\n  Password 022/000/004: geHeimQ"
    }
  },
  {
    "instruction": "AVG AntiVirus\n\n==Introduction==\nAVG AntiVirus (previously known as AVG, an abbreviation of Anti-Virus Guard) is a line of antivirus software developed by AVG Technologies, a subsidiary of Avast, a part of Gen Digital. It is available for Windows, macOS and Android.\n\n\n\n== Platform support ==\nAVG provides AVG AntiVirus Free for Windows, AVG AntiVirus for Mac for macOS and AVG AntiVirus for Android for Android devices. All are freemium products: They are free to download, install, update and use, but for technical support a premium plan must be purchased.\nAVG stopped providing new features for Windows XP and Windows Vista in January 2019. New versions require Windows 7 or later; virus definitions are still provided for previous versions.\n\n== Features ==\nAVG features most of the common functions available in modern antivirus and Internet security programs, including periodic scans, scans of sent and received emails (including adding footers to the emails indicating this), the ability to repair some virus-infected files, and a quarantine area (virus vault) in which infected files are held.\n\n\n*** LinkScanner ***\nThe patent pending LinkScanner technology acquired from Exploit Prevention Labs and built into most AVG products, provides real-time updated protection against exploits and drive-by downloads. LinkScanner includes: Search-Shield \u2013 a safe search component that places safety ratings next to each link in Google, Yahoo! and MSN search results; plus Active Surf-Shield \u2013 a safe surf component that scans the contents of a web site in real-time to ensure it's safe being opened. Concerns regarding web analytics have made LinkScanner a controversial component (see \"LinkScanner concerns\" below).\n\n\n**** LinkScanner concerns ****\nWhen AVG 8.0 was first released, its LinkScanner safe search feature was shown to cause an increase in traffic on websites that appear high in search engine results pages. Since LinkScanner disguises the scans as coming from an Internet Explorer 6 browser when it prescans each site listed in the search results, website usage logs showed incorrect and overinflated site visitor statistics. The prescanning of every link in search results also caused websites to transfer more data than usual, resulting in higher bandwidth usage for web site operators and slow performance for users. AVG initially said that site administrators would be able to filter the LinkScanner traffic out of their site statistics, leaving the problem of excess bandwidth usage still to be solved. Pay-per-click advertising was not affected by the increase in traffic.\n\n\n*** AVG Online Shield ***\nAVG Online Shield is a feature designed to check files and ensure that they are safe. AVG Online Shield also ensures the safety of exchanging files via instant messengers and VoIP clients.In response to complaints, AVG announced that as of 9 July 2008 \"Search-Shield will no longer scan each search result online for new exploits, which was causing the spikes that webmasters addressed with us\", releasing a new build on that date that applies a local blacklist, then prefetches and scans only those links clicked on by the user.\n\n== Controversy ==\nAs of 2014, there are numerous reports dating back to 2012 that the AVG SafeGuard Toolbar installs itself without the consent of the user, as a side effect of installing other applications. The toolbar program appears to cause significant RAM issues and can be considered an intrusive potentially unwanted program (PUP). Once installed, the AVG toolbar is virtually impossible to remove. The toolbar uninstaller does not function, instead re-installing the add-on if manually removed. Consequently, many discussions and blog posts have described complex procedures for removal of the AVG toolbar, each with very mixed results.In September 2015, AVG announced that it would start tracking users for profit, analyzing their data for sale to the advertising industry. This measure received criticism from consumers, the press and security industry, as many users intended to use the software in order to protect themselves from spyware and would not expect the functions of spyware to be \"hidden\" in security software.In December 2015, the AVG Web TuneUp Google Chrome extension (automatically installed with AVG AntiVirus) was revealed to contain multiple critical security vulnerabilities. Most notably, Chrome users' browsing history could be exposed to any website, cookies from any site the user has visited could be read by an attacker, and trivial cross-site scripting (XSS) issues could allow any website to execute arbitrary code (as another domain).\nThe XSS vulnerability allowed a user's mail from \"mail.google.com\" to be read by any website, or financial information to be read from the user's online banking site. The AVG team fixed this by only allowing \"mysearch.avg.com\" and \"webtuneup.avg.com\" to execute these scripts. Despite this remediation, attackers could leverage any of these attacks if an XSS vulnerability was found on the AVG sites. As of April 2016, Web TuneUp was still not available for download from the AVG website.\nRead the text above and answer this question: What versions of Windows does AVG AntiVirus support?",
    "context": "",
    "output": "AVG AntiVirus requires Windows 7 or later, and new versions no longer provide new features for Windows XP and Windows Vista.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What versions of Windows does AVG AntiVirus support?",
      "answer": "AVG AntiVirus requires Windows 7 or later, and new versions no longer provide new features for Windows XP and Windows Vista.",
      "context": "AVG AntiVirus\n\n==Introduction==\nAVG AntiVirus (previously known as AVG, an abbreviation of Anti-Virus Guard) is a line of antivirus software developed by AVG Technologies, a subsidiary of Avast, a part of Gen Digital. It is available for Windows, macOS and Android.\n\n\n\n== Platform support ==\nAVG provides AVG AntiVirus Free for Windows, AVG AntiVirus for Mac for macOS and AVG AntiVirus for Android for Android devices. All are freemium products: They are free to download, install, update and use, but for technical support a premium plan must be purchased.\nAVG stopped providing new features for Windows XP and Windows Vista in January 2019. New versions require Windows 7 or later; virus definitions are still provided for previous versions.\n\n== Features ==\nAVG features most of the common functions available in modern antivirus and Internet security programs, including periodic scans, scans of sent and received emails (including adding footers to the emails indicating this), the ability to repair some virus-infected files, and a quarantine area (virus vault) in which infected files are held.\n\n\n*** LinkScanner ***\nThe patent pending LinkScanner technology acquired from Exploit Prevention Labs and built into most AVG products, provides real-time updated protection against exploits and drive-by downloads. LinkScanner includes: Search-Shield \u2013 a safe search component that places safety ratings next to each link in Google, Yahoo! and MSN search results; plus Active Surf-Shield \u2013 a safe surf component that scans the contents of a web site in real-time to ensure it's safe being opened. Concerns regarding web analytics have made LinkScanner a controversial component (see \"LinkScanner concerns\" below).\n\n\n**** LinkScanner concerns ****\nWhen AVG 8.0 was first released, its LinkScanner safe search feature was shown to cause an increase in traffic on websites that appear high in search engine results pages. Since LinkScanner disguises the scans as coming from an Internet Explorer 6 browser when it prescans each site listed in the search results, website usage logs showed incorrect and overinflated site visitor statistics. The prescanning of every link in search results also caused websites to transfer more data than usual, resulting in higher bandwidth usage for web site operators and slow performance for users. AVG initially said that site administrators would be able to filter the LinkScanner traffic out of their site statistics, leaving the problem of excess bandwidth usage still to be solved. Pay-per-click advertising was not affected by the increase in traffic.\n\n\n*** AVG Online Shield ***\nAVG Online Shield is a feature designed to check files and ensure that they are safe. AVG Online Shield also ensures the safety of exchanging files via instant messengers and VoIP clients.In response to complaints, AVG announced that as of 9 July 2008 \"Search-Shield will no longer scan each search result online for new exploits, which was causing the spikes that webmasters addressed with us\", releasing a new build on that date that applies a local blacklist, then prefetches and scans only those links clicked on by the user.\n\n== Controversy ==\nAs of 2014, there are numerous reports dating back to 2012 that the AVG SafeGuard Toolbar installs itself without the consent of the user, as a side effect of installing other applications. The toolbar program appears to cause significant RAM issues and can be considered an intrusive potentially unwanted program (PUP). Once installed, the AVG toolbar is virtually impossible to remove. The toolbar uninstaller does not function, instead re-installing the add-on if manually removed. Consequently, many discussions and blog posts have described complex procedures for removal of the AVG toolbar, each with very mixed results.In September 2015, AVG announced that it would start tracking users for profit, analyzing their data for sale to the advertising industry. This measure received criticism from consumers, the press and security industry, as many users intended to use the software in order to protect themselves from spyware and would not expect the functions of spyware to be \"hidden\" in security software.In December 2015, the AVG Web TuneUp Google Chrome extension (automatically installed with AVG AntiVirus) was revealed to contain multiple critical security vulnerabilities. Most notably, Chrome users' browsing history could be exposed to any website, cookies from any site the user has visited could be read by an attacker, and trivial cross-site scripting (XSS) issues could allow any website to execute arbitrary code (as another domain).\nThe XSS vulnerability allowed a user's mail from \"mail.google.com\" to be read by any website, or financial information to be read from the user's online banking site. The AVG team fixed this by only allowing \"mysearch.avg.com\" and \"webtuneup.avg.com\" to execute these scripts. Despite this remediation, attackers could leverage any of these attacks if an XSS vulnerability was found on the AVG sites. As of April 2016, Web TuneUp was still not available for download from the AVG website."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the computational security parameter affect the hardness of a cryptographic scheme in the context of the hardness of a PRF?",
    "context": "",
    "output": "In the context of a PRF, the computational security parameter is used to set the size of the key space such that a brute-force search requires O(2^\u03ba) computational power, making the PRF key harder to guess for an adversary.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the computational security parameter affect the hardness of a cryptographic scheme in the context of the hardness of a PRF?",
      "answer": "In the context of a PRF, the computational security parameter is used to set the size of the key space such that a brute-force search requires O(2^\u03ba) computational power, making the PRF key harder to guess for an adversary."
    }
  },
  {
    "instruction": "Write an answer to the following question: Are there any indications in network logs that a FragAttacks attack has occurred?",
    "context": "",
    "output": "No, FragAttacks do not leave any trace in network logs, making it challenging to determine if an attack has occurred.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Are there any indications in network logs that a FragAttacks attack has occurred?",
      "answer": "No, FragAttacks do not leave any trace in network logs, making it challenging to determine if an attack has occurred."
    }
  },
  {
    "instruction": "Answer based on context:\n\nLeftover hash lemma\n\n==Introduction==\nThe leftover hash lemma is a lemma in cryptography first stated by Russell Impagliazzo, Leonid Levin, and Michael Luby.Imagine that you have a secret key X that has n uniform random bits, and you would like to use this secret key to encrypt a message. Unfortunately, you were a bit careless with the key, and know that an adversary was able to learn the values of some t < n bits of that key, but you do not know which t bits. Can you still use your key, or do you have to throw it away and choose a new key? The leftover hash lemma tells us that we can produce a key of about n \u2212 t bits, over which the adversary has almost no knowledge. Since the adversary knows all but n \u2212 t bits, this is almost optimal.\nMore precisely, the leftover hash lemma tells us that we can extract a length asymptotic to \n  \n    \n      \n        \n          H\n          \n            \u221e\n          \n        \n        (\n        X\n        )\n      \n    \n    {\\displaystyle H_{\\infty }(X)}\n   (the min-entropy of X) bits from a random variable X that are almost uniformly distributed. In other words, an adversary who has some partial knowledge about X, will have almost no knowledge about the extracted value. That is why this is also called privacy amplification (see privacy amplification section in the article Quantum key distribution).\nRandomness extractors achieve the same result, but use (normally) less randomness.\nLet X be a random variable over \n  \n    \n      \n        \n          \n            X\n          \n        \n      \n    \n    {\\displaystyle {\\mathcal {X}}}\n   and let \n  \n    \n      \n        m\n        >\n        0\n      \n    \n    {\\displaystyle m>0}\n  . Let \n  \n    \n      \n        h\n        :\n        \n          \n            S\n          \n        \n        \u00d7\n        \n          \n            X\n          \n        \n        \u2192\n        {\n        0\n        ,\n        \n        1\n        \n          }\n          \n            m\n          \n        \n      \n    \n    {\\textstyle h\\colon {\\mathcal {S}}\\times {\\mathcal {X}}\\rightarrow \\{0,\\,1\\}^{m}}\n   be a 2-universal hash function. If \n\n  \n    \n      \n        m\n        \u2264\n        \n          H\n          \n            \u221e\n          \n        \n        (\n        X\n        )\n        \u2212\n        2\n        log\n        \u2061\n        \n          (\n          \n            \n              1\n              \u03b5\n            \n          \n          )\n        \n      \n    \n    {\\textstyle m\\leq H_{\\infty }(X)-2\\log \\left({\\frac {1}{\\varepsilon }}\\right)}\n  then for S uniform over \n  \n    \n      \n        \n          \n            S\n          \n        \n      \n    \n    {\\displaystyle {\\mathcal {S}}}\n   and independent of X, we have: \n\n  \n    \n      \n        \u03b4\n        \n          [\n          \n            (\n            h\n            (\n            S\n            ,\n            X\n            )\n            ,\n            S\n            )\n            ,\n            (\n            U\n            ,\n            S\n            )\n          \n          ]\n        \n        \u2264\n        \u03b5\n        .\n      \n    \n    {\\textstyle \\delta \\left[(h(S,X),S),(U,S)\\right]\\leq \\varepsilon .}\n  where U is uniform over \n  \n    \n      \n        {\n        0\n        ,\n        1\n        \n          }\n          \n            m\n          \n        \n      \n    \n    {\\displaystyle \\{0,1\\}^{m}}\n   and independent of S.\n  \n    \n      \n        \n          H\n          \n            \u221e\n          \n        \n        (\n        X\n        )\n        =\n        \u2212\n        log\n        \u2061\n        \n          max\n          \n            x\n          \n        \n        Pr\n        [\n        X\n        =\n        x\n        ]\n      \n    \n    {\\textstyle H_{\\infty }(X)=-\\log \\max _{x}\\Pr[X=x]}\n   is the min-entropy of X, which measures the amount of randomness X has. The min-entropy is always less than or equal to the Shannon entropy. Note that \n  \n    \n      \n        \n          max\n          \n            x\n          \n        \n        Pr\n        [\n        X\n        =\n        x\n        ]\n      \n    \n    {\\textstyle \\max _{x}\\Pr[X=x]}\n   is the probability of correctly guessing X. (The best guess is to guess the most probable value.) Therefore, the min-entropy measures how difficult it is to guess X.\n\n  \n    \n      \n        0\n        \u2264\n        \u03b4\n        (\n        X\n        ,\n        Y\n        )\n        =\n        \n          \n            1\n            2\n          \n        \n        \n          \u2211\n          \n            v\n          \n        \n        \n          |\n          \n            Pr\n            [\n            X\n            =\n            v\n            ]\n            \u2212\n            Pr\n            [\n            Y\n            =\n            v\n            ]\n          \n          |\n        \n        \u2264\n        1\n      \n    \n    {\\textstyle 0\\leq \\delta (X,Y)={\\frac {1}{2}}\\sum _{v}\\left|\\Pr[X=v]-\\Pr[Y=v]\\right|\\leq 1}\n   is a statistical distance between X and Y.\n\n\n\n\n\nHow does the leftover hash lemma relate to the privacy amplification in quantum key distribution?",
    "context": "",
    "output": "The leftover hash lemma is used to extract a length asymptotic to the min-entropy of a random variable in a process known as privacy amplification. This process is used in quantum key distribution to distill a secret key from a raw key that may have been partially compromised by an eavesdropper. The leftover hash lemma ensures that the extractor can produce a secret key that is almost uniformly distributed and independent of the eavesdropper's partial knowledge, making it a crucial component of quantum key distribution.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the leftover hash lemma relate to the privacy amplification in quantum key distribution?",
      "answer": "The leftover hash lemma is used to extract a length asymptotic to the min-entropy of a random variable in a process known as privacy amplification. This process is used in quantum key distribution to distill a secret key from a raw key that may have been partially compromised by an eavesdropper. The leftover hash lemma ensures that the extractor can produce a secret key that is almost uniformly distributed and independent of the eavesdropper's partial knowledge, making it a crucial component of quantum key distribution.",
      "context": "Leftover hash lemma\n\n==Introduction==\nThe leftover hash lemma is a lemma in cryptography first stated by Russell Impagliazzo, Leonid Levin, and Michael Luby.Imagine that you have a secret key X that has n uniform random bits, and you would like to use this secret key to encrypt a message. Unfortunately, you were a bit careless with the key, and know that an adversary was able to learn the values of some t < n bits of that key, but you do not know which t bits. Can you still use your key, or do you have to throw it away and choose a new key? The leftover hash lemma tells us that we can produce a key of about n \u2212 t bits, over which the adversary has almost no knowledge. Since the adversary knows all but n \u2212 t bits, this is almost optimal.\nMore precisely, the leftover hash lemma tells us that we can extract a length asymptotic to \n  \n    \n      \n        \n          H\n          \n            \u221e\n          \n        \n        (\n        X\n        )\n      \n    \n    {\\displaystyle H_{\\infty }(X)}\n   (the min-entropy of X) bits from a random variable X that are almost uniformly distributed. In other words, an adversary who has some partial knowledge about X, will have almost no knowledge about the extracted value. That is why this is also called privacy amplification (see privacy amplification section in the article Quantum key distribution).\nRandomness extractors achieve the same result, but use (normally) less randomness.\nLet X be a random variable over \n  \n    \n      \n        \n          \n            X\n          \n        \n      \n    \n    {\\displaystyle {\\mathcal {X}}}\n   and let \n  \n    \n      \n        m\n        >\n        0\n      \n    \n    {\\displaystyle m>0}\n  . Let \n  \n    \n      \n        h\n        :\n        \n          \n            S\n          \n        \n        \u00d7\n        \n          \n            X\n          \n        \n        \u2192\n        {\n        0\n        ,\n        \n        1\n        \n          }\n          \n            m\n          \n        \n      \n    \n    {\\textstyle h\\colon {\\mathcal {S}}\\times {\\mathcal {X}}\\rightarrow \\{0,\\,1\\}^{m}}\n   be a 2-universal hash function. If \n\n  \n    \n      \n        m\n        \u2264\n        \n          H\n          \n            \u221e\n          \n        \n        (\n        X\n        )\n        \u2212\n        2\n        log\n        \u2061\n        \n          (\n          \n            \n              1\n              \u03b5\n            \n          \n          )\n        \n      \n    \n    {\\textstyle m\\leq H_{\\infty }(X)-2\\log \\left({\\frac {1}{\\varepsilon }}\\right)}\n  then for S uniform over \n  \n    \n      \n        \n          \n            S\n          \n        \n      \n    \n    {\\displaystyle {\\mathcal {S}}}\n   and independent of X, we have: \n\n  \n    \n      \n        \u03b4\n        \n          [\n          \n            (\n            h\n            (\n            S\n            ,\n            X\n            )\n            ,\n            S\n            )\n            ,\n            (\n            U\n            ,\n            S\n            )\n          \n          ]\n        \n        \u2264\n        \u03b5\n        .\n      \n    \n    {\\textstyle \\delta \\left[(h(S,X),S),(U,S)\\right]\\leq \\varepsilon .}\n  where U is uniform over \n  \n    \n      \n        {\n        0\n        ,\n        1\n        \n          }\n          \n            m\n          \n        \n      \n    \n    {\\displaystyle \\{0,1\\}^{m}}\n   and independent of S.\n  \n    \n      \n        \n          H\n          \n            \u221e\n          \n        \n        (\n        X\n        )\n        =\n        \u2212\n        log\n        \u2061\n        \n          max\n          \n            x\n          \n        \n        Pr\n        [\n        X\n        =\n        x\n        ]\n      \n    \n    {\\textstyle H_{\\infty }(X)=-\\log \\max _{x}\\Pr[X=x]}\n   is the min-entropy of X, which measures the amount of randomness X has. The min-entropy is always less than or equal to the Shannon entropy. Note that \n  \n    \n      \n        \n          max\n          \n            x\n          \n        \n        Pr\n        [\n        X\n        =\n        x\n        ]\n      \n    \n    {\\textstyle \\max _{x}\\Pr[X=x]}\n   is the probability of correctly guessing X. (The best guess is to guess the most probable value.) Therefore, the min-entropy measures how difficult it is to guess X.\n\n  \n    \n      \n        0\n        \u2264\n        \u03b4\n        (\n        X\n        ,\n        Y\n        )\n        =\n        \n          \n            1\n            2\n          \n        \n        \n          \u2211\n          \n            v\n          \n        \n        \n          |\n          \n            Pr\n            [\n            X\n            =\n            v\n            ]\n            \u2212\n            Pr\n            [\n            Y\n            =\n            v\n            ]\n          \n          |\n        \n        \u2264\n        1\n      \n    \n    {\\textstyle 0\\leq \\delta (X,Y)={\\frac {1}{2}}\\sum _{v}\\left|\\Pr[X=v]-\\Pr[Y=v]\\right|\\leq 1}\n   is a statistical distance between X and Y.\n\n\n\n"
    }
  },
  {
    "instruction": "Answer based on context:\n\nCore FTP\n\n==Introduction==\nCore FTP is a freeware secure FTP client for Windows, developed by CoreFTP.com. Features include FTP, SSL/TLS, SFTP via SSH, and HTTP/HTTPS support. Secure FTP clients encrypt account information and data transferred across the internet, protecting data from being seen, or sniffed across networks. Core FTP is a traditional FTP client with local files displayed on the left, remote files on the right.\nCore FTP Server is a secure FTP server for Windows, developed by CoreFTP.com, starting in 2010.\n\n\n\n== Licensing ==\nCoreFTP LE is free for personal, educational, non-profit, and business use.\n\n== Reviews and references ==\nPC Magazine \u2013 59 Ways to Supercharge Windows \u2013  Odds & Ends \u2013 Core FTP LE\nSoftpedia.com \u2013 Reviews \u2013 \"Today, try Core FTP Lite!\" \u2013 By: Codrut Nistor, Editor, Software Reviews\n\nWho is the target audience for CoreFTP LE?",
    "context": "",
    "output": "CoreFTP LE is free for personal, educational, non-profit, and business use.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Who is the target audience for CoreFTP LE?",
      "answer": "CoreFTP LE is free for personal, educational, non-profit, and business use.",
      "context": "Core FTP\n\n==Introduction==\nCore FTP is a freeware secure FTP client for Windows, developed by CoreFTP.com. Features include FTP, SSL/TLS, SFTP via SSH, and HTTP/HTTPS support. Secure FTP clients encrypt account information and data transferred across the internet, protecting data from being seen, or sniffed across networks. Core FTP is a traditional FTP client with local files displayed on the left, remote files on the right.\nCore FTP Server is a secure FTP server for Windows, developed by CoreFTP.com, starting in 2010.\n\n\n\n== Licensing ==\nCoreFTP LE is free for personal, educational, non-profit, and business use.\n\n== Reviews and references ==\nPC Magazine \u2013 59 Ways to Supercharge Windows \u2013  Odds & Ends \u2013 Core FTP LE\nSoftpedia.com \u2013 Reviews \u2013 \"Today, try Core FTP Lite!\" \u2013 By: Codrut Nistor, Editor, Software Reviews"
    }
  },
  {
    "instruction": "CESG Claims Tested Mark\n\n==Introduction==\nThe CESG Claims Tested Mark (abbreviated as CCT Mark or CCTM), formerly CSIA Claims Tested Mark,  is a UK Government Standard for computer security. \nThe CCT Mark is based upon framework where vendors can make claims about the security attributes of their products and/or services, and independent testing laboratories can evaluate the products/services to determine if they actually meet the claims. In other words, the CCT Mark provides quality assurance approach to validate whether the implementation of a computer security product or services has been performed in an appropriate manner.\n\n== Operation ==\nAll Testing Laboratories must comply with ISO 17025, with the United Kingdom Accreditation Service (UKAS) carrying out the accreditation.\n\n== Comparisons ==\nThe CCT Mark is often compared to the international Common Criteria (CC), which is simultaneously both correct and incorrect:\n\nBoth provide methods for achieving a measure of assurance of computer security products and systems\nNeither can provide a guarantee that approval means that no exploitable flaws exist, but rather reduce the likelihood of such flaw being present\nThe Common Criteria is constructed in a layered manner, with multiple Evaluation Assurance Level (EAL) specifications being available with increasing complexity, timescale and costs as the EAL number rises\nCommon Criteria is supported by a Mutual Recognition Agreement (MRA), which, at the lower EAL numbers at least, means that products tested in one country will normally be accepted in other markets\nThe CCT Mark is aimed at the same market as the lower CC EAL numbers (currently EAL1/2), and has been specifically designed for timescale and cost efficiency\n\n== Future ==\nAs of September 2010, CESG have announced that the product assurance element of CCT Mark will be overtaken by the new Commercial Product Assurance (CPA) approach.  It is unclear as yet whether CCT Mark will remain in existence for assurance of Information Security services.\n\nAnswer this question based on the above context: What is the role of vendors in the CCT Mark framework?",
    "context": "",
    "output": "Vendors play a crucial role in the CCT Mark framework by making claims about the security attributes of their products and/or services. Independent testing laboratories then evaluate these claims to determine if they actually meet the claims, providing a quality assurance approach to validate the implementation of computer security products and services.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of vendors in the CCT Mark framework?",
      "answer": "Vendors play a crucial role in the CCT Mark framework by making claims about the security attributes of their products and/or services. Independent testing laboratories then evaluate these claims to determine if they actually meet the claims, providing a quality assurance approach to validate the implementation of computer security products and services.",
      "context": "CESG Claims Tested Mark\n\n==Introduction==\nThe CESG Claims Tested Mark (abbreviated as CCT Mark or CCTM), formerly CSIA Claims Tested Mark,  is a UK Government Standard for computer security. \nThe CCT Mark is based upon framework where vendors can make claims about the security attributes of their products and/or services, and independent testing laboratories can evaluate the products/services to determine if they actually meet the claims. In other words, the CCT Mark provides quality assurance approach to validate whether the implementation of a computer security product or services has been performed in an appropriate manner.\n\n== Operation ==\nAll Testing Laboratories must comply with ISO 17025, with the United Kingdom Accreditation Service (UKAS) carrying out the accreditation.\n\n== Comparisons ==\nThe CCT Mark is often compared to the international Common Criteria (CC), which is simultaneously both correct and incorrect:\n\nBoth provide methods for achieving a measure of assurance of computer security products and systems\nNeither can provide a guarantee that approval means that no exploitable flaws exist, but rather reduce the likelihood of such flaw being present\nThe Common Criteria is constructed in a layered manner, with multiple Evaluation Assurance Level (EAL) specifications being available with increasing complexity, timescale and costs as the EAL number rises\nCommon Criteria is supported by a Mutual Recognition Agreement (MRA), which, at the lower EAL numbers at least, means that products tested in one country will normally be accepted in other markets\nThe CCT Mark is aimed at the same market as the lower CC EAL numbers (currently EAL1/2), and has been specifically designed for timescale and cost efficiency\n\n== Future ==\nAs of September 2010, CESG have announced that the product assurance element of CCT Mark will be overtaken by the new Commercial Product Assurance (CPA) approach.  It is unclear as yet whether CCT Mark will remain in existence for assurance of Information Security services."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the United States Department of Defense define signals intelligence?",
    "context": "",
    "output": "The United States Department of Defense defines signals intelligence as a category of intelligence comprising communications intelligence, electronic intelligence, and foreign instrumentation signals intelligence, however transmitted.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the United States Department of Defense define signals intelligence?",
      "answer": "The United States Department of Defense defines signals intelligence as a category of intelligence comprising communications intelligence, electronic intelligence, and foreign instrumentation signals intelligence, however transmitted."
    }
  },
  {
    "instruction": "Hash-based cryptography\n\n==Introduction==\nHash-based cryptography is the generic term for constructions of cryptographic primitives based on the security of hash functions. It is of interest as a type of post-quantum cryptography.\nSo far, hash-based cryptography is used to construct digital signatures schemes such as the Merkle signature scheme, zero knowledge and computationally integrity proofs, such as the zk-STARK proof system and range proofs over issued credentials via the HashWires  protocol. Hash-based signature schemes combine a one-time signature scheme, such as a Lamport signature, with a Merkle tree structure. Since a one-time signature scheme key can only sign a single message securely, it is practical to combine many such keys within a single, larger structure. A Merkle tree structure is used to this end. In this hierarchical data structure, a hash function and concatenation are used repeatedly to compute tree nodes.\nOne consideration with hash-based signature schemes is that they can only sign a limited number of messages securely, because of their use of one-time signature schemes. The US National Institute of Standards and Technology (NIST), specified that algorithms in its post-quantum cryptography competition support a minimum of 264 signatures safely.In 2022, NIST announced SPHINCS+ as one of three algorithms to be standardized for digital signatures. NIST standardized stateful hash-based cryptography based on the eXtended Merkle Signature Scheme (XMSS) and Leighton-Micali Signatures (LMS), which are applicable in different circumstances, in 2020, but noted that the requirement to maintain state when using them makes them more difficult to implement in a way that avoids misuse.\n\n== One-time signature schemes ==\nHash-based signature schemes use one-time signature schemes as their building block. A given one-time signing key can only be used to sign a single message securely. Indeed, signatures reveal part of the signing key. The security of (hash-based) one-time signature schemes relies exclusively on the security of an underlying hash function.\nCommonly used one-time signature schemes include the Lamport-Diffie scheme, the Winternitz scheme and its improvements, such as the W-OTS+ scheme. Unlike the seminal Lamport-Diffie scheme, the Winternitz scheme and variants can sign many bits at once. The number of bits to be signed at once is determined by a value: the Winternitz parameter. The existence of this parameter provides a trade-off between size and speed. Large values of the Winternitz parameter yield short signatures and keys, at the price of slower signing and verifying. In practice, a typical value for this parameter is 16.\nIn the case of stateless hash-based signatures, few-time signature schemes are used. Such schemes allow security to decrease gradually in case a few-time key is used more than once. HORST is an example of a few-time signature scheme.\n\n== Combining many one-time key pairs into a hash-based signature scheme ==\nThe central idea of hash-based signature schemes is to combine a larger number of one-time key pairs into a single structure to obtain a practical way of signing more than once (yet a limited number of times). This is done using a Merkle tree structure, with possible variations. One public and one private key are constructed from the numerous public and private keys of the underlying one-time scheme. The global public key is the single node at the very top of the Merkle tree. Its value is an output of the selected hash function, so a typical public key size is 32 bytes. The validity of this global public key is related to the validity of a given one-time public key using a sequence of tree nodes. This sequence is called the authentication path. It is stored as part of the signature, and allows a verifier to reconstruct the node path between those two public keys.\nThe global private key is generally handled using a pseudo-random number generator. It is then sufficient to store a seed value. One-time secret keys are derived successively from the seed value using the generator. With this approach, the global private key is also very small, e.g. typically 32 bytes.\nThe problem of tree traversal is critical to signing performance. Increasingly efficient approaches have been introduced, dramatically speeding up signing time.\nSome hash-based signature schemes use multiple layers of tree, offering faster signing at the price of larger signatures. In such schemes, only the lowest layer of trees is used to sign messages, while all other trees sign root values of lower trees.\nThe Naor-Yung work shows the pattern by which to transfer a limited time signature of the Merkle type family into an unlimited (regular) signature scheme.\n\n== Properties of hash-based signature schemes ==\nHash-based signature schemes rely on security assumptions about the underlying hash function, but any hash function fulfilling these assumptions can be used. As a consequence, each adequate hash function yields a different corresponding hash-based signature scheme. Even if a given hash function becomes insecure, it is sufficient to replace it by a different, secure one to obtain a secure instantiation of the hash-based signature scheme under consideration. Some hash-based signature schemes (such as XMSS with pseudorandom key generation) are forward secure, meaning that previous signatures remain valid if a secret key is compromised.\nThe minimality of security assumptions is another characteristic of hash-based signature schemes. Generally, these schemes only require a secure (for instance in the sense of second preimage resistance) cryptographic hash function to guarantee the overall security of the scheme. This kind of assumption is necessary for any digital signature scheme; however, other signature schemes require additional security assumptions, which is not the case here.\nBecause of their reliance on an underlying one-time signature scheme, hash-based signature schemes can only sign a fixed number of messages securely. In the case of the Merkle and XMSS schemes, a maximum of \n  \n    \n      \n        \n          2\n          \n            h\n          \n        \n      \n    \n    {\\displaystyle 2^{h}}\n   messages can be signed securely, with \n  \n    \n      \n        h\n      \n    \n    {\\displaystyle h}\n   the total Merkle tree height.\n\n== Examples of hash-based signature schemes ==\nSince Merkle's initial scheme, numerous hash-based signature schemes with performance improvements have been introduced. Recent ones include the XMSS, the Leighton-Micali (LMS), the SPHINCS and the BPQS schemes. Most hash-based signature schemes are stateful, meaning that signing requires updating the secret key, unlike conventional digital signature schemes. For stateful hash-based signature schemes, signing requires keeping state of the used one-time keys and making sure they are never reused. The XMSS, LMS and BPQS  schemes are stateful, while the SPHINCS scheme is stateless. SPHINCS signatures are larger than XMSS and LMS signatures. BPQS has been designed specifically for blockchain systems. Additionally to the WOTS+ one-time signature scheme, SPHINCS also uses a few-time (hash-based) signature scheme called HORST. HORST is an improvement of an older few-time signature scheme, HORS (Hash to Obtain Random Subset).The stateful hash-based schemes XMSS and XMSSMT are specified in RFC 8391 (XMSS: eXtended Merkle Signature Scheme)\n.\nLeighton-Micali Hash-Based Signatures are specified in RFC 8554. Practical improvements have been proposed in the literature that alleviate the concerns introduced by stateful schemes. Hash functions appropriate for these schemes include SHA-2, SHA-3 and BLAKE.\n\n== Implementations ==\nThe XMSS, GMSS and SPHINCS schemes are available in the Java Bouncy Castle cryptographic APIs. SPHINCS is implemented in the SUPERCOP benchmarking toolkit. Optimised and unoptimised reference implementations of the XMSS RFC exist. The LMS scheme has been implemented in Python and in C following its Internet-Draft.\n\nAnswer this question based on the above context: What are some examples of hash functions appropriate for hash-based signature schemes?",
    "context": "",
    "output": "Some examples of hash functions appropriate for hash-based signature schemes include SHA-2, SHA-3, and BLAKE.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are some examples of hash functions appropriate for hash-based signature schemes?",
      "answer": "Some examples of hash functions appropriate for hash-based signature schemes include SHA-2, SHA-3, and BLAKE.",
      "context": "Hash-based cryptography\n\n==Introduction==\nHash-based cryptography is the generic term for constructions of cryptographic primitives based on the security of hash functions. It is of interest as a type of post-quantum cryptography.\nSo far, hash-based cryptography is used to construct digital signatures schemes such as the Merkle signature scheme, zero knowledge and computationally integrity proofs, such as the zk-STARK proof system and range proofs over issued credentials via the HashWires  protocol. Hash-based signature schemes combine a one-time signature scheme, such as a Lamport signature, with a Merkle tree structure. Since a one-time signature scheme key can only sign a single message securely, it is practical to combine many such keys within a single, larger structure. A Merkle tree structure is used to this end. In this hierarchical data structure, a hash function and concatenation are used repeatedly to compute tree nodes.\nOne consideration with hash-based signature schemes is that they can only sign a limited number of messages securely, because of their use of one-time signature schemes. The US National Institute of Standards and Technology (NIST), specified that algorithms in its post-quantum cryptography competition support a minimum of 264 signatures safely.In 2022, NIST announced SPHINCS+ as one of three algorithms to be standardized for digital signatures. NIST standardized stateful hash-based cryptography based on the eXtended Merkle Signature Scheme (XMSS) and Leighton-Micali Signatures (LMS), which are applicable in different circumstances, in 2020, but noted that the requirement to maintain state when using them makes them more difficult to implement in a way that avoids misuse.\n\n== One-time signature schemes ==\nHash-based signature schemes use one-time signature schemes as their building block. A given one-time signing key can only be used to sign a single message securely. Indeed, signatures reveal part of the signing key. The security of (hash-based) one-time signature schemes relies exclusively on the security of an underlying hash function.\nCommonly used one-time signature schemes include the Lamport-Diffie scheme, the Winternitz scheme and its improvements, such as the W-OTS+ scheme. Unlike the seminal Lamport-Diffie scheme, the Winternitz scheme and variants can sign many bits at once. The number of bits to be signed at once is determined by a value: the Winternitz parameter. The existence of this parameter provides a trade-off between size and speed. Large values of the Winternitz parameter yield short signatures and keys, at the price of slower signing and verifying. In practice, a typical value for this parameter is 16.\nIn the case of stateless hash-based signatures, few-time signature schemes are used. Such schemes allow security to decrease gradually in case a few-time key is used more than once. HORST is an example of a few-time signature scheme.\n\n== Combining many one-time key pairs into a hash-based signature scheme ==\nThe central idea of hash-based signature schemes is to combine a larger number of one-time key pairs into a single structure to obtain a practical way of signing more than once (yet a limited number of times). This is done using a Merkle tree structure, with possible variations. One public and one private key are constructed from the numerous public and private keys of the underlying one-time scheme. The global public key is the single node at the very top of the Merkle tree. Its value is an output of the selected hash function, so a typical public key size is 32 bytes. The validity of this global public key is related to the validity of a given one-time public key using a sequence of tree nodes. This sequence is called the authentication path. It is stored as part of the signature, and allows a verifier to reconstruct the node path between those two public keys.\nThe global private key is generally handled using a pseudo-random number generator. It is then sufficient to store a seed value. One-time secret keys are derived successively from the seed value using the generator. With this approach, the global private key is also very small, e.g. typically 32 bytes.\nThe problem of tree traversal is critical to signing performance. Increasingly efficient approaches have been introduced, dramatically speeding up signing time.\nSome hash-based signature schemes use multiple layers of tree, offering faster signing at the price of larger signatures. In such schemes, only the lowest layer of trees is used to sign messages, while all other trees sign root values of lower trees.\nThe Naor-Yung work shows the pattern by which to transfer a limited time signature of the Merkle type family into an unlimited (regular) signature scheme.\n\n== Properties of hash-based signature schemes ==\nHash-based signature schemes rely on security assumptions about the underlying hash function, but any hash function fulfilling these assumptions can be used. As a consequence, each adequate hash function yields a different corresponding hash-based signature scheme. Even if a given hash function becomes insecure, it is sufficient to replace it by a different, secure one to obtain a secure instantiation of the hash-based signature scheme under consideration. Some hash-based signature schemes (such as XMSS with pseudorandom key generation) are forward secure, meaning that previous signatures remain valid if a secret key is compromised.\nThe minimality of security assumptions is another characteristic of hash-based signature schemes. Generally, these schemes only require a secure (for instance in the sense of second preimage resistance) cryptographic hash function to guarantee the overall security of the scheme. This kind of assumption is necessary for any digital signature scheme; however, other signature schemes require additional security assumptions, which is not the case here.\nBecause of their reliance on an underlying one-time signature scheme, hash-based signature schemes can only sign a fixed number of messages securely. In the case of the Merkle and XMSS schemes, a maximum of \n  \n    \n      \n        \n          2\n          \n            h\n          \n        \n      \n    \n    {\\displaystyle 2^{h}}\n   messages can be signed securely, with \n  \n    \n      \n        h\n      \n    \n    {\\displaystyle h}\n   the total Merkle tree height.\n\n== Examples of hash-based signature schemes ==\nSince Merkle's initial scheme, numerous hash-based signature schemes with performance improvements have been introduced. Recent ones include the XMSS, the Leighton-Micali (LMS), the SPHINCS and the BPQS schemes. Most hash-based signature schemes are stateful, meaning that signing requires updating the secret key, unlike conventional digital signature schemes. For stateful hash-based signature schemes, signing requires keeping state of the used one-time keys and making sure they are never reused. The XMSS, LMS and BPQS  schemes are stateful, while the SPHINCS scheme is stateless. SPHINCS signatures are larger than XMSS and LMS signatures. BPQS has been designed specifically for blockchain systems. Additionally to the WOTS+ one-time signature scheme, SPHINCS also uses a few-time (hash-based) signature scheme called HORST. HORST is an improvement of an older few-time signature scheme, HORS (Hash to Obtain Random Subset).The stateful hash-based schemes XMSS and XMSSMT are specified in RFC 8391 (XMSS: eXtended Merkle Signature Scheme)\n.\nLeighton-Micali Hash-Based Signatures are specified in RFC 8554. Practical improvements have been proposed in the literature that alleviate the concerns introduced by stateful schemes. Hash functions appropriate for these schemes include SHA-2, SHA-3 and BLAKE.\n\n== Implementations ==\nThe XMSS, GMSS and SPHINCS schemes are available in the Java Bouncy Castle cryptographic APIs. SPHINCS is implemented in the SUPERCOP benchmarking toolkit. Optimised and unoptimised reference implementations of the XMSS RFC exist. The LMS scheme has been implemented in Python and in C following its Internet-Draft."
    }
  },
  {
    "instruction": "Write an answer to the following question: How do attackers spread links to infected pages in an exploit kit?",
    "context": "",
    "output": "Attackers spread links to infected pages in an exploit kit via spam, malvertising, or by compromising legitimate sites.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do attackers spread links to infected pages in an exploit kit?",
      "answer": "Attackers spread links to infected pages in an exploit kit via spam, malvertising, or by compromising legitimate sites."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is cloaking and how does it manipulate search engines?",
    "context": "",
    "output": "Cloaking is a technique where a website presents different content to search engine crawlers than what is shown to human users. It manipulates search engine rankings by misleading crawlers about the website's actual content.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is cloaking and how does it manipulate search engines?",
      "answer": "Cloaking is a technique where a website presents different content to search engine crawlers than what is shown to human users. It manipulates search engine rankings by misleading crawlers about the website's actual content."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the role of a War Room in computer security incident management, and how is it used during an incident response?",
    "context": "",
    "output": "A War Room is a secure environment for reviewing confidential material and investigating a security incident. It is used to facilitate communication and collaboration among the incident response team, and may be used to document the attendees, current nature of the incident, and recommended actions.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of a War Room in computer security incident management, and how is it used during an incident response?",
      "answer": "A War Room is a secure environment for reviewing confidential material and investigating a security incident. It is used to facilitate communication and collaboration among the incident response team, and may be used to document the attendees, current nature of the incident, and recommended actions."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is web content filtering, and why is it important in adversarial information retrieval?",
    "context": "",
    "output": "Web content filtering is the process of blocking or restricting access to specific web content based on predefined criteria. It is important in adversarial information retrieval to prevent the spread of malicious or inappropriate content.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is web content filtering, and why is it important in adversarial information retrieval?",
      "answer": "Web content filtering is the process of blocking or restricting access to specific web content based on predefined criteria. It is important in adversarial information retrieval to prevent the spread of malicious or inappropriate content."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the simplest form of voice inversion scrambling and how does it work?",
    "context": "",
    "output": "The simplest form of voice inversion scrambling involves replacing the frequency of each component with the difference between the frequency of a carrier wave and the original frequency. This is achieved by amplitude modulating the speech signal with the carrier and then applying a low-pass filter to select the lower sideband.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the simplest form of voice inversion scrambling and how does it work?",
      "answer": "The simplest form of voice inversion scrambling involves replacing the frequency of each component with the difference between the frequency of a carrier wave and the original frequency. This is achieved by amplitude modulating the speech signal with the carrier and then applying a low-pass filter to select the lower sideband."
    }
  },
  {
    "instruction": "Write an answer to the following question: How can attackers exploit digital assistants using audio injection?",
    "context": "",
    "output": "Attackers can exploit digital assistants by using unwanted instructions spoken in natural language, which can trigger the execution of desired actions. These devices lack authentication when reacting to user commands, making it possible for attackers to issue activation words and commands.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can attackers exploit digital assistants using audio injection?",
      "answer": "Attackers can exploit digital assistants by using unwanted instructions spoken in natural language, which can trigger the execution of desired actions. These devices lack authentication when reacting to user commands, making it possible for attackers to issue activation words and commands."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is used for Elliptic Curve Diffie-Hellman (ECDH) Key Exchange in the Commercial National Security Algorithm Suite?",
    "context": "",
    "output": "Curve P-384 is used for Elliptic Curve Diffie-Hellman (ECDH) Key Exchange in the Commercial National Security Algorithm Suite.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is used for Elliptic Curve Diffie-Hellman (ECDH) Key Exchange in the Commercial National Security Algorithm Suite?",
      "answer": "Curve P-384 is used for Elliptic Curve Diffie-Hellman (ECDH) Key Exchange in the Commercial National Security Algorithm Suite."
    }
  },
  {
    "instruction": "Shnakule\n\n==Introduction==\nShnakule is the biggest malware network in existence. It averages over 2000 hosts and has had as many as 4357. It targets users while visiting trusted sites and routes them to malware by using relays, exploits, and payload servers. These are continually shifted to new domains.\n\n\n\nAnswer this question based on the above context: How does Shnakule, the largest malware network, compromise user security while visiting trusted sites?",
    "context": "",
    "output": "Shnakule targets users through trusted sites by using relays, exploits, and payload servers. These servers route users to malware domains, which are continually shifted to new domains to evade detection and enhance the network's persistence.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does Shnakule, the largest malware network, compromise user security while visiting trusted sites?",
      "answer": "Shnakule targets users through trusted sites by using relays, exploits, and payload servers. These servers route users to malware domains, which are continually shifted to new domains to evade detection and enhance the network's persistence.",
      "context": "Shnakule\n\n==Introduction==\nShnakule is the biggest malware network in existence. It averages over 2000 hosts and has had as many as 4357. It targets users while visiting trusted sites and routes them to malware by using relays, exploits, and payload servers. These are continually shifted to new domains.\n\n"
    }
  },
  {
    "instruction": "Write an answer to the following question: How does Snort function as a Network Intrusion Detection System (NIDS)?",
    "context": "",
    "output": "As a NIDS, Snort monitors network traffic and analyzes it against a user-defined rule set. Based on the analysis, it performs a specific action, such as triggering an alert or blocking the traffic, helping to detect and prevent intrusions.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does Snort function as a Network Intrusion Detection System (NIDS)?",
      "answer": "As a NIDS, Snort monitors network traffic and analyzes it against a user-defined rule set. Based on the analysis, it performs a specific action, such as triggering an alert or blocking the traffic, helping to detect and prevent intrusions."
    }
  },
  {
    "instruction": "Privilege (computing)\n\n==Introduction==\nIn computing, privilege is defined as the delegation of authority to perform security-relevant functions on a computer system. A privilege allows a user to perform an action with security consequences. Examples of various privileges include the ability to create a new user, install software, or change  kernel functions.\nUsers who have been delegated extra levels of control are called privileged.  Users who lack most privileges are defined as unprivileged, regular, or normal users.\n\n== Theory ==\nPrivileges can either be automatic, granted, or applied for.  \nAn automatic privilege exists when there is no requirement to have permission to perform an action.  For example, on systems where people are required to log into a system to use it, logging out will not require a privilege.  Systems that do not implement file protection - such as MS-DOS - essentially give unlimited privilege to perform any action on a file.\nA granted privilege exists as a result of presenting some credential to the privilege granting authority.  This is usually accomplished by logging on to a system with a username and password, and if the username and password supplied are correct, the user is granted additional privileges.\nA privilege is applied for by either an executed program issuing a request for advanced privileges, or by running some program to apply for the additional privileges.  An example of a user applying for additional privileges is provided by the sudo command to run a command as superuser (root) user, or by the Kerberos authentication system.\nModern processor architectures have multiple CPU modes that allows the OS to run at different privilege levels. Some processors have two levels (such as user and supervisor); i386+ processors have four levels (#0 with the most, #3 with the least privileges). Tasks are tagged with a privilege level. Resources (segments, pages, ports, etc.) and the privileged instructions are tagged with a demanded privilege level. When a task tries to use a resource, or execute a privileged instruction, the processor determines whether it has the permission (if not, a \"protection fault\" interrupt is generated). This prevents user tasks from damaging the OS or each other.\nIn computer programming, exceptions related to privileged instruction violations may be caused when an array has been accessed out of bounds or an invalid pointer has been dereferenced when the invalid memory location referenced is a privileged location, such as one controlling device input/output. This is particularly more likely to occur in programming languages such as C, which use pointer arithmetic or do not check array bounds automatically.\n\n\n*** Criticism ***\nMark Miller has critiqued the framing of privilege as being poorly defined and hard to measure, and suggested that authority can be defined as the set of things a program can do, which is more helpful.\n\n== Unix ==\nOn Unix-like systems, the superuser (commonly known as 'root') owns all the privileges.  Ordinary users are granted only enough permissions to accomplish their most common tasks. UNIX systems have built-in security features. Most users cannot set up a new user account nor do other administrative procedures. The user \u201croot\u201d is a special user, something called super-user, which can do anything at all on the system. This high degree power is necessary to fully administer a UNIX system, but it also allows its user to make a mistake and cause system problems. \nUnprivileged users usually cannot:\n\nAdjust kernel options;\nmodify system files, or files of other users.\nchange the ownership of any files;\nchange the runlevel (on systems with System V-style initialization);\nchange the file mode of any files;\nadjust ulimits or disk quotas;\nstart, stop and remove  daemons;\nsignal processes of other users;\ncreate device nodes;\ncreate or remove users or groups;\nmount or unmount volumes (although it is becoming common to allow regular users to mount and unmount removable media, such as compact discs - this is typically accomplished via FUSE);\nexecute the contents of any sbin/ directory (although it is becoming common to simply restrict the behavior of such programs when executed by regular users);\nbind ports below 1024.\n\n== Windows NT ==\nOn Windows NT-based systems, privileges are delegated in varying degrees.  These delegations can be defined using the local security policy manager (secpol.msc).  The following is an abbreviated list of the default assignments:\n\n'NT AUTHORITY\\System' is the closest equivalent to the Superuser on Unix-like systems. It has many of the privileges of a classic Unix superuser (such as being a trustee on every file created);\n'Administrator' is one of the closest equivalents to the superuser (root) on Unix-like systems. However, this user cannot override as many of the operating system's protections as the superuser can;\nmembers of the 'Administrators' group have privileges almost equal to 'Administrator';\nmembers of the 'Power Users' group have the ability to install programs and backup the system.\nmembers of the 'Users' group are the equivalent to unprivileged users on Unix-like systems.Windows defines a number of administrative privileges  that can be assigned individually to users and/or groups. An account (user) holds only the privileges granted to it, either directly or indirectly through group memberships. Upon installation a number of groups and accounts are created and privileges are granted to them. However, these grants can be changed at a later time or though a group policy. Unlike Linux, no privileges are implicitly or permanently granted to a specific account.\nSome administrative privileges (e.g. taking ownership of or restoring arbitrary files) are so powerful that if used with malicious intent they could allow the entire system to be compromised. With user account control (on by default since Windows Vista) Windows will strip the user token of these privileges at login. Thus, if a user logs in with an account with broad system privileges, he/she will still not be running with these system privileges. Whenever the user wants to perform administrative actions requiring any of the system privileges he/she will have to do this from an elevated process. When launching an elevated process, the user is made aware that his/her administrative privileges are being asserted through a prompt requiring his/her consent. Not holding privileges until actually required is in keeping with the principle of least privilege.\nElevated processes will run with the full privileges of the user, not the full privileges of the system. Even so, the privileges of the user may still be more than what is required for that particular process, thus not completely least privilege.\nThe DOS-based Windows ME, Windows 98, Windows 95 and previous versions of non-NT Windows only operated on the FAT filesystem, did not support filesystem permissions and therefore privileges are effectively defeated on Windows NT-based systems that do not use the NTFS file system.\n\n\n*** Nomenclature ***\nThe names used in the Windows source code end in either \"privilege\" or \"logonright\". This has led to some confusion about what the full set of all these \"rights\" and \"privileges\" should be called.\nMicrosoft currently uses the term \"user rights\".\nIn the past some other terms have also been used by Microsoft, such as \"privilege rights\"\n, \"logon user rights\"\nand \"nt-rights\".\n\nAnswer this question based on the above context: What are some actions that unprivileged users usually cannot perform on Unix-like systems?",
    "context": "",
    "output": "Unprivileged users usually cannot adjust kernel options, modify system files or files of other users, change the ownership of any files, change the runlevel, change the file mode of any files, adjust ulimits or disk quotas, start, stop and remove daemons, signal processes of other users, create device nodes, create or remove users or groups, mount or unmount volumes, execute the contents of any sbin/ directory, or bind ports below 1024.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are some actions that unprivileged users usually cannot perform on Unix-like systems?",
      "answer": "Unprivileged users usually cannot adjust kernel options, modify system files or files of other users, change the ownership of any files, change the runlevel, change the file mode of any files, adjust ulimits or disk quotas, start, stop and remove daemons, signal processes of other users, create device nodes, create or remove users or groups, mount or unmount volumes, execute the contents of any sbin/ directory, or bind ports below 1024.",
      "context": "Privilege (computing)\n\n==Introduction==\nIn computing, privilege is defined as the delegation of authority to perform security-relevant functions on a computer system. A privilege allows a user to perform an action with security consequences. Examples of various privileges include the ability to create a new user, install software, or change  kernel functions.\nUsers who have been delegated extra levels of control are called privileged.  Users who lack most privileges are defined as unprivileged, regular, or normal users.\n\n== Theory ==\nPrivileges can either be automatic, granted, or applied for.  \nAn automatic privilege exists when there is no requirement to have permission to perform an action.  For example, on systems where people are required to log into a system to use it, logging out will not require a privilege.  Systems that do not implement file protection - such as MS-DOS - essentially give unlimited privilege to perform any action on a file.\nA granted privilege exists as a result of presenting some credential to the privilege granting authority.  This is usually accomplished by logging on to a system with a username and password, and if the username and password supplied are correct, the user is granted additional privileges.\nA privilege is applied for by either an executed program issuing a request for advanced privileges, or by running some program to apply for the additional privileges.  An example of a user applying for additional privileges is provided by the sudo command to run a command as superuser (root) user, or by the Kerberos authentication system.\nModern processor architectures have multiple CPU modes that allows the OS to run at different privilege levels. Some processors have two levels (such as user and supervisor); i386+ processors have four levels (#0 with the most, #3 with the least privileges). Tasks are tagged with a privilege level. Resources (segments, pages, ports, etc.) and the privileged instructions are tagged with a demanded privilege level. When a task tries to use a resource, or execute a privileged instruction, the processor determines whether it has the permission (if not, a \"protection fault\" interrupt is generated). This prevents user tasks from damaging the OS or each other.\nIn computer programming, exceptions related to privileged instruction violations may be caused when an array has been accessed out of bounds or an invalid pointer has been dereferenced when the invalid memory location referenced is a privileged location, such as one controlling device input/output. This is particularly more likely to occur in programming languages such as C, which use pointer arithmetic or do not check array bounds automatically.\n\n\n*** Criticism ***\nMark Miller has critiqued the framing of privilege as being poorly defined and hard to measure, and suggested that authority can be defined as the set of things a program can do, which is more helpful.\n\n== Unix ==\nOn Unix-like systems, the superuser (commonly known as 'root') owns all the privileges.  Ordinary users are granted only enough permissions to accomplish their most common tasks. UNIX systems have built-in security features. Most users cannot set up a new user account nor do other administrative procedures. The user \u201croot\u201d is a special user, something called super-user, which can do anything at all on the system. This high degree power is necessary to fully administer a UNIX system, but it also allows its user to make a mistake and cause system problems. \nUnprivileged users usually cannot:\n\nAdjust kernel options;\nmodify system files, or files of other users.\nchange the ownership of any files;\nchange the runlevel (on systems with System V-style initialization);\nchange the file mode of any files;\nadjust ulimits or disk quotas;\nstart, stop and remove  daemons;\nsignal processes of other users;\ncreate device nodes;\ncreate or remove users or groups;\nmount or unmount volumes (although it is becoming common to allow regular users to mount and unmount removable media, such as compact discs - this is typically accomplished via FUSE);\nexecute the contents of any sbin/ directory (although it is becoming common to simply restrict the behavior of such programs when executed by regular users);\nbind ports below 1024.\n\n== Windows NT ==\nOn Windows NT-based systems, privileges are delegated in varying degrees.  These delegations can be defined using the local security policy manager (secpol.msc).  The following is an abbreviated list of the default assignments:\n\n'NT AUTHORITY\\System' is the closest equivalent to the Superuser on Unix-like systems. It has many of the privileges of a classic Unix superuser (such as being a trustee on every file created);\n'Administrator' is one of the closest equivalents to the superuser (root) on Unix-like systems. However, this user cannot override as many of the operating system's protections as the superuser can;\nmembers of the 'Administrators' group have privileges almost equal to 'Administrator';\nmembers of the 'Power Users' group have the ability to install programs and backup the system.\nmembers of the 'Users' group are the equivalent to unprivileged users on Unix-like systems.Windows defines a number of administrative privileges  that can be assigned individually to users and/or groups. An account (user) holds only the privileges granted to it, either directly or indirectly through group memberships. Upon installation a number of groups and accounts are created and privileges are granted to them. However, these grants can be changed at a later time or though a group policy. Unlike Linux, no privileges are implicitly or permanently granted to a specific account.\nSome administrative privileges (e.g. taking ownership of or restoring arbitrary files) are so powerful that if used with malicious intent they could allow the entire system to be compromised. With user account control (on by default since Windows Vista) Windows will strip the user token of these privileges at login. Thus, if a user logs in with an account with broad system privileges, he/she will still not be running with these system privileges. Whenever the user wants to perform administrative actions requiring any of the system privileges he/she will have to do this from an elevated process. When launching an elevated process, the user is made aware that his/her administrative privileges are being asserted through a prompt requiring his/her consent. Not holding privileges until actually required is in keeping with the principle of least privilege.\nElevated processes will run with the full privileges of the user, not the full privileges of the system. Even so, the privileges of the user may still be more than what is required for that particular process, thus not completely least privilege.\nThe DOS-based Windows ME, Windows 98, Windows 95 and previous versions of non-NT Windows only operated on the FAT filesystem, did not support filesystem permissions and therefore privileges are effectively defeated on Windows NT-based systems that do not use the NTFS file system.\n\n\n*** Nomenclature ***\nThe names used in the Windows source code end in either \"privilege\" or \"logonright\". This has led to some confusion about what the full set of all these \"rights\" and \"privileges\" should be called.\nMicrosoft currently uses the term \"user rights\".\nIn the past some other terms have also been used by Microsoft, such as \"privilege rights\"\n, \"logon user rights\"\nand \"nt-rights\"."
    }
  },
  {
    "instruction": "Write an answer to the following question: What were the differences between the basic version and the mobile versions of the DUDEK encryption system?",
    "context": "",
    "output": "The basic version of the DUDEK encryption system was the TgS-1, while the mobile versions were the TgS-1M and TgS-1MS. The mobile versions were likely more compact and portable than the basic version, making them suitable for use in field operations or by mobile units.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What were the differences between the basic version and the mobile versions of the DUDEK encryption system?",
      "answer": "The basic version of the DUDEK encryption system was the TgS-1, while the mobile versions were the TgS-1M and TgS-1MS. The mobile versions were likely more compact and portable than the basic version, making them suitable for use in field operations or by mobile units."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does DNSSEC impact DNS server performance?",
    "context": "",
    "output": "DNSSEC implementation can add significant load to some DNS servers. Common DNSSEC-signed responses are far larger than the default UDP size of 512 bytes, which can lead to the use of multiple IP fragments and TCP. Many current TCP implementations store a great deal of data for each TCP connection, and heavily loaded servers can run out of resources simply trying to respond to a larger number of (possibly bogus) DNSSEC requests. Protocol extensions, such as TCP Cookie Transactions, have been developed to reduce this loading.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does DNSSEC impact DNS server performance?",
      "answer": "DNSSEC implementation can add significant load to some DNS servers. Common DNSSEC-signed responses are far larger than the default UDP size of 512 bytes, which can lead to the use of multiple IP fragments and TCP. Many current TCP implementations store a great deal of data for each TCP connection, and heavily loaded servers can run out of resources simply trying to respond to a larger number of (possibly bogus) DNSSEC requests. Protocol extensions, such as TCP Cookie Transactions, have been developed to reduce this loading."
    }
  },
  {
    "instruction": "Write an answer to the following question: How did the fail0verflow group recover the ECDSA private key used by Sony to sign software for the PlayStation 3 game console?",
    "context": "",
    "output": "The fail0verflow group recovered the ECDSA private key used by Sony because Sony did not properly implement the algorithm, using a static value for k instead of a random one. This made it possible to solve for the private key, rendering the entire algorithm useless.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How did the fail0verflow group recover the ECDSA private key used by Sony to sign software for the PlayStation 3 game console?",
      "answer": "The fail0verflow group recovered the ECDSA private key used by Sony because Sony did not properly implement the algorithm, using a static value for k instead of a random one. This made it possible to solve for the private key, rendering the entire algorithm useless."
    }
  },
  {
    "instruction": "Context: Homomorphic encryption\n\n==Introduction==\nHomomorphic encryption is a form of encryption that allows computations to be performed on encrypted data without first having to decrypt it. The resulting computations are left in an encrypted form which, when decrypted, result in an output that is identical to that produced had the operations been performed on the unencrypted data.  Homomorphic encryption can be used for privacy-preserving outsourced storage and computation. This allows data to be encrypted and out-sourced to commercial cloud environments for processing, all while encrypted.\nFor sensitive data, such as health care information, homomorphic encryption can be used to enable new services by removing privacy barriers inhibiting data sharing or increase security to existing services.  For example, predictive analytics in health care can be hard to apply via a third party service provider due to medical data privacy concerns, but if the predictive analytics service provider can operate on encrypted data instead, these privacy concerns are diminished. Moreover, even if the service provider's system is compromised, the data would remain secure.\n\n\n\n== Description ==\nHomomorphic encryption is a form of encryption with an additional evaluation capability for computing over encrypted data without access to the secret key. The result of such a computation remains encrypted. Homomorphic encryption can be viewed as an extension of public-key cryptography. Homomorphic refers to homomorphism in algebra: the encryption and decryption functions can be thought of as homomorphisms between plaintext and ciphertext spaces.\nHomomorphic encryption includes multiple types of encryption schemes that can perform different classes of computations over encrypted data. The computations are represented as either Boolean or arithmetic circuits.  Some common types of homomorphic encryption are partially homomorphic, somewhat homomorphic, leveled fully homomorphic, and fully homomorphic encryption:\n\nPartially homomorphic encryption encompasses schemes that support the evaluation of circuits consisting of only one type of gate, e.g., addition or multiplication.\nSomewhat homomorphic encryption schemes can evaluate two types of gates, but only for a subset of circuits.\nLeveled fully homomorphic encryption supports the evaluation of arbitrary circuits composed of multiple types of gates of bounded (pre-determined) depth.\nFully homomorphic encryption (FHE) allows the evaluation of arbitrary circuits composed of multiple types of gates of unbounded depth and is the strongest notion of homomorphic encryption.For the majority of homomorphic encryption schemes, the multiplicative depth of circuits is the main practical limitation in performing computations over encrypted data.  Homomorphic encryption schemes are inherently malleable. In terms of malleability, homomorphic encryption schemes have weaker security properties than non-homomorphic schemes.\n\n== Partially homomorphic cryptosystems ==\nIn the following examples, the notation \n  \n    \n      \n        \n          \n            E\n          \n        \n        (\n        x\n        )\n      \n    \n    {\\displaystyle {\\mathcal {E}}(x)}\n   is used to denote the encryption of the message \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  .\nUnpadded RSA\nIf the RSA public key has modulus \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n   and encryption exponent \n  \n    \n      \n        e\n      \n    \n    {\\displaystyle e}\n  , then the encryption of a message \n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n   is given by \n  \n    \n      \n        \n          \n            E\n          \n        \n        (\n        m\n        )\n\n== Fully homomorphic encryption ==\nA cryptosystem that supports arbitrary computation on ciphertexts is known as fully homomorphic encryption (FHE). Such a scheme enables the construction of programs for any desirable functionality, which can be run on encrypted inputs to produce an encryption of the result. Since such a program need never decrypt its inputs, it can be run by an untrusted party without revealing its inputs and internal state. Fully homomorphic cryptosystems have great practical implications in the outsourcing of private computations, for instance, in the context of cloud computing.\n\n\n*** Implementations ***\nA list of open-source FHE libraries implementing second-generation (BGV/BFV), third-generation (FHEW/TFHE), and/or fourth-generation (CKKS) FHE schemes is provided below. \nThere are several open-source implementations of fully homomorphic encryption schemes. Second-generation and fourth-generation FHE scheme implementations typically operate in the leveled FHE mode (though bootstrapping is still available in some libraries) and support efficient SIMD-like packing of data; they are typically used to compute on encrypted integers or real/complex numbers. Third-generation FHE scheme implementations often bootstrap after each operation but have limited support for packing; they were initially used to compute Boolean circuits over encrypted bits, but have been extended to support integer arithmetics and univariate function evaluation. The choice of using a second-generation vs. third-generation vs fourth-generation scheme depends on the input data types and the desired computation.\n\n\n*** Standardization ***\nIn 2017, researchers from IBM, Microsoft, Intel, the NIST, and others formed an open consortium, the Homomorphic Encryption Standardization Consortium (Homomorphicencryption.org), that maintains a community security Homomorphic Encryption Standard (The Standard).\n\nQuestion: What is the main practical limitation in performing computations over encrypted data for most homomorphic encryption schemes?\n\nAnswer:",
    "context": "",
    "output": "The main practical limitation in performing computations over encrypted data for most homomorphic encryption schemes is the multiplicative depth of circuits.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the main practical limitation in performing computations over encrypted data for most homomorphic encryption schemes?",
      "answer": "The main practical limitation in performing computations over encrypted data for most homomorphic encryption schemes is the multiplicative depth of circuits.",
      "context": "Homomorphic encryption\n\n==Introduction==\nHomomorphic encryption is a form of encryption that allows computations to be performed on encrypted data without first having to decrypt it. The resulting computations are left in an encrypted form which, when decrypted, result in an output that is identical to that produced had the operations been performed on the unencrypted data.  Homomorphic encryption can be used for privacy-preserving outsourced storage and computation. This allows data to be encrypted and out-sourced to commercial cloud environments for processing, all while encrypted.\nFor sensitive data, such as health care information, homomorphic encryption can be used to enable new services by removing privacy barriers inhibiting data sharing or increase security to existing services.  For example, predictive analytics in health care can be hard to apply via a third party service provider due to medical data privacy concerns, but if the predictive analytics service provider can operate on encrypted data instead, these privacy concerns are diminished. Moreover, even if the service provider's system is compromised, the data would remain secure.\n\n\n\n== Description ==\nHomomorphic encryption is a form of encryption with an additional evaluation capability for computing over encrypted data without access to the secret key. The result of such a computation remains encrypted. Homomorphic encryption can be viewed as an extension of public-key cryptography. Homomorphic refers to homomorphism in algebra: the encryption and decryption functions can be thought of as homomorphisms between plaintext and ciphertext spaces.\nHomomorphic encryption includes multiple types of encryption schemes that can perform different classes of computations over encrypted data. The computations are represented as either Boolean or arithmetic circuits.  Some common types of homomorphic encryption are partially homomorphic, somewhat homomorphic, leveled fully homomorphic, and fully homomorphic encryption:\n\nPartially homomorphic encryption encompasses schemes that support the evaluation of circuits consisting of only one type of gate, e.g., addition or multiplication.\nSomewhat homomorphic encryption schemes can evaluate two types of gates, but only for a subset of circuits.\nLeveled fully homomorphic encryption supports the evaluation of arbitrary circuits composed of multiple types of gates of bounded (pre-determined) depth.\nFully homomorphic encryption (FHE) allows the evaluation of arbitrary circuits composed of multiple types of gates of unbounded depth and is the strongest notion of homomorphic encryption.For the majority of homomorphic encryption schemes, the multiplicative depth of circuits is the main practical limitation in performing computations over encrypted data.  Homomorphic encryption schemes are inherently malleable. In terms of malleability, homomorphic encryption schemes have weaker security properties than non-homomorphic schemes.\n\n== Partially homomorphic cryptosystems ==\nIn the following examples, the notation \n  \n    \n      \n        \n          \n            E\n          \n        \n        (\n        x\n        )\n      \n    \n    {\\displaystyle {\\mathcal {E}}(x)}\n   is used to denote the encryption of the message \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  .\nUnpadded RSA\nIf the RSA public key has modulus \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n   and encryption exponent \n  \n    \n      \n        e\n      \n    \n    {\\displaystyle e}\n  , then the encryption of a message \n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n   is given by \n  \n    \n      \n        \n          \n            E\n          \n        \n        (\n        m\n        )\n\n== Fully homomorphic encryption ==\nA cryptosystem that supports arbitrary computation on ciphertexts is known as fully homomorphic encryption (FHE). Such a scheme enables the construction of programs for any desirable functionality, which can be run on encrypted inputs to produce an encryption of the result. Since such a program need never decrypt its inputs, it can be run by an untrusted party without revealing its inputs and internal state. Fully homomorphic cryptosystems have great practical implications in the outsourcing of private computations, for instance, in the context of cloud computing.\n\n\n*** Implementations ***\nA list of open-source FHE libraries implementing second-generation (BGV/BFV), third-generation (FHEW/TFHE), and/or fourth-generation (CKKS) FHE schemes is provided below. \nThere are several open-source implementations of fully homomorphic encryption schemes. Second-generation and fourth-generation FHE scheme implementations typically operate in the leveled FHE mode (though bootstrapping is still available in some libraries) and support efficient SIMD-like packing of data; they are typically used to compute on encrypted integers or real/complex numbers. Third-generation FHE scheme implementations often bootstrap after each operation but have limited support for packing; they were initially used to compute Boolean circuits over encrypted bits, but have been extended to support integer arithmetics and univariate function evaluation. The choice of using a second-generation vs. third-generation vs fourth-generation scheme depends on the input data types and the desired computation.\n\n\n*** Standardization ***\nIn 2017, researchers from IBM, Microsoft, Intel, the NIST, and others formed an open consortium, the Homomorphic Encryption Standardization Consortium (Homomorphicencryption.org), that maintains a community security Homomorphic Encryption Standard (The Standard)."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does TCP/IP stack fingerprinting enable identification of a remote machine's operating system?",
    "context": "",
    "output": "TCP/IP stack fingerprinting is the process of detecting the characteristics of a TCP/IP stack implementation on a remote machine. Different operating systems and their versions set unique defaults for certain parameters within the TCP protocol definition, such as initial packet size, TTL, window size, and others. By collecting and analyzing these values, one can distinguish among various operating systems and implementations of TCP/IP, forming a 67-bit signature or fingerprint for the target machine.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does TCP/IP stack fingerprinting enable identification of a remote machine's operating system?",
      "answer": "TCP/IP stack fingerprinting is the process of detecting the characteristics of a TCP/IP stack implementation on a remote machine. Different operating systems and their versions set unique defaults for certain parameters within the TCP protocol definition, such as initial packet size, TTL, window size, and others. By collecting and analyzing these values, one can distinguish among various operating systems and implementations of TCP/IP, forming a 67-bit signature or fingerprint for the target machine."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are the benefits of using tokenization over traditional encryption methods?",
    "context": "",
    "output": "The benefits of using tokenization over traditional encryption methods include lower processing and storage requirements, and the ability to keep specific data fully or partially visible for processing and analytics.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are the benefits of using tokenization over traditional encryption methods?",
      "answer": "The benefits of using tokenization over traditional encryption methods include lower processing and storage requirements, and the ability to keep specific data fully or partially visible for processing and analytics."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are some solutions for storing the external key used to encrypt the data with full disk encryption?",
    "context": "",
    "output": "Some solutions for storing the external key used to encrypt the data with full disk encryption include using a username and password, using a smartcard in combination with a PIN, using a biometric authentication method, using a dongle to store the key, using a boot-time driver that can ask for a password from the user, using a network interchange to recover the key, using a TPM to store the decryption key, and using a combination of these methods.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are some solutions for storing the external key used to encrypt the data with full disk encryption?",
      "answer": "Some solutions for storing the external key used to encrypt the data with full disk encryption include using a username and password, using a smartcard in combination with a PIN, using a biometric authentication method, using a dongle to store the key, using a boot-time driver that can ask for a password from the user, using a network interchange to recover the key, using a TPM to store the decryption key, and using a combination of these methods."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the use of a DMZ within an enclave provide additional security for publicly accessible systems?",
    "context": "",
    "output": "The use of a DMZ within an enclave provides additional security for publicly accessible systems by building it on a separate network interface of the enclave perimeter firewall, routing all DMZ traffic through the firewall for processing and keeping it separate from the rest of the protected network. This helps ensure that publicly accessible systems are isolated from sensitive systems and resources within the enclave.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the use of a DMZ within an enclave provide additional security for publicly accessible systems?",
      "answer": "The use of a DMZ within an enclave provides additional security for publicly accessible systems by building it on a separate network interface of the enclave perimeter firewall, routing all DMZ traffic through the firewall for processing and keeping it separate from the rest of the protected network. This helps ensure that publicly accessible systems are isolated from sensitive systems and resources within the enclave."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the goal of the ISO/IEC 7064 standard in terms of error detection capabilities?",
    "context": "",
    "output": "The goal of the ISO/IEC 7064 standard is to detect all single substitution errors, all or nearly all single local transposition errors, all or nearly all circular shift errors, a high proportion of double substitution errors, and a high proportion of all other errors in alphanumeric strings.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the goal of the ISO/IEC 7064 standard in terms of error detection capabilities?",
      "answer": "The goal of the ISO/IEC 7064 standard is to detect all single substitution errors, all or nearly all single local transposition errors, all or nearly all circular shift errors, a high proportion of double substitution errors, and a high proportion of all other errors in alphanumeric strings."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the purpose of Alina POS RAM Scraper checking for updates upon execution?",
    "context": "",
    "output": "Alina POS RAM Scraper checks for updates to ensure it has the latest version and to remove existing code if an update is found.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the purpose of Alina POS RAM Scraper checking for updates upon execution?",
      "answer": "Alina POS RAM Scraper checks for updates to ensure it has the latest version and to remove existing code if an update is found."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does SURBL help in identifying cracked sites?",
    "context": "",
    "output": "SURBL helps in identifying cracked sites by listing them under the CR list, which can be queried using the SURBL DNS servers.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does SURBL help in identifying cracked sites?",
      "answer": "SURBL helps in identifying cracked sites by listing them under the CR list, which can be queried using the SURBL DNS servers."
    }
  },
  {
    "instruction": "Differential cryptanalysis\n\n==Introduction==\nDifferential cryptanalysis is a general form of cryptanalysis applicable primarily to block ciphers, but also to stream ciphers and cryptographic hash functions. In the broadest sense, it is the study of how differences in information input can affect the resultant difference at the output. In the case of a block cipher, it refers to a set of techniques for tracing differences through the network of transformation, discovering where the cipher exhibits non-random behavior, and exploiting such properties to recover the secret key (cryptography key).\n\n\n\n== Attack mechanics ==\nDifferential cryptanalysis is usually a chosen plaintext attack, meaning that the attacker must be able to obtain ciphertexts for some set of plaintexts of their choosing. There are, however, extensions that would allow a known plaintext or even a ciphertext-only attack. The basic method uses pairs of plaintext related by a constant difference. Difference can be defined in several ways, but the eXclusive OR (XOR) operation is usual. The attacker then computes the differences of the corresponding ciphertexts, hoping to detect statistical patterns in their distribution. The resulting pair of differences is called a differential. Their statistical properties depend upon the nature of the S-boxes used for encryption, so the attacker analyses differentials \n  \n    \n      \n        (\n        \n          \u0394\n          \n            x\n          \n        \n        ,\n        \n          \u0394\n          \n            y\n          \n        \n        )\n      \n    \n    {\\displaystyle (\\Delta _{x},\\Delta _{y})}\n   where\n\n(and \u2295 denotes exclusive or) for each such S-box S. In the basic attack, one particular ciphertext difference is expected to be especially frequent. In this way, the cipher can be distinguished from random. More sophisticated variations allow the key to be recovered faster than exhaustive search.\nIn the most basic form of key recovery through differential cryptanalysis, an attacker requests the ciphertexts for a large number of plaintext pairs, then assumes that the differential holds for at least r \u2212 1 rounds, where r is the total number of rounds. The attacker then deduces which round keys (for the final round) are possible, assuming the difference between the blocks before the final round is fixed. When round keys are short, this can be achieved by simply exhaustively decrypting the ciphertext pairs one round with each possible round key. When one round key has been deemed a potential round key considerably more often than any other key, it is assumed to be the correct round key.\nFor any particular cipher, the input difference must be carefully selected for the attack to be successful. An analysis of the algorithm's internals is undertaken; the standard method is to trace a path of highly probable differences through the various stages of encryption, termed a differential characteristic.\nSince differential cryptanalysis became public knowledge, it has become a basic concern of cipher designers. New designs are expected to be accompanied by evidence that the algorithm is resistant to this attack and many including the Advanced Encryption Standard, have been proven secure against the attack.\n\n== Attack in detail ==\nThe attack relies primarily on the fact that a given input/output difference pattern only occurs for certain values of inputs.  Usually the attack is applied in essence to the non-linear components as if they were a solid component (usually they are in fact look-up tables or S-boxes).  Observing the desired output difference (between two chosen or known plaintext inputs) suggests possible key values.\nFor example, if a differential of 1\n\n== Specialized types ==\nHigher-order differential cryptanalysis\nTruncated differential cryptanalysis\nImpossible differential cryptanalysis\nBoomerang attack\n\nQ: What type of attack is differential cryptanalysis?",
    "context": "",
    "output": "A: Differential cryptanalysis is usually a chosen plaintext attack, but there are extensions that allow for known plaintext or even ciphertext-only attacks.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What type of attack is differential cryptanalysis?",
      "answer": "Differential cryptanalysis is usually a chosen plaintext attack, but there are extensions that allow for known plaintext or even ciphertext-only attacks.",
      "context": "Differential cryptanalysis\n\n==Introduction==\nDifferential cryptanalysis is a general form of cryptanalysis applicable primarily to block ciphers, but also to stream ciphers and cryptographic hash functions. In the broadest sense, it is the study of how differences in information input can affect the resultant difference at the output. In the case of a block cipher, it refers to a set of techniques for tracing differences through the network of transformation, discovering where the cipher exhibits non-random behavior, and exploiting such properties to recover the secret key (cryptography key).\n\n\n\n== Attack mechanics ==\nDifferential cryptanalysis is usually a chosen plaintext attack, meaning that the attacker must be able to obtain ciphertexts for some set of plaintexts of their choosing. There are, however, extensions that would allow a known plaintext or even a ciphertext-only attack. The basic method uses pairs of plaintext related by a constant difference. Difference can be defined in several ways, but the eXclusive OR (XOR) operation is usual. The attacker then computes the differences of the corresponding ciphertexts, hoping to detect statistical patterns in their distribution. The resulting pair of differences is called a differential. Their statistical properties depend upon the nature of the S-boxes used for encryption, so the attacker analyses differentials \n  \n    \n      \n        (\n        \n          \u0394\n          \n            x\n          \n        \n        ,\n        \n          \u0394\n          \n            y\n          \n        \n        )\n      \n    \n    {\\displaystyle (\\Delta _{x},\\Delta _{y})}\n   where\n\n(and \u2295 denotes exclusive or) for each such S-box S. In the basic attack, one particular ciphertext difference is expected to be especially frequent. In this way, the cipher can be distinguished from random. More sophisticated variations allow the key to be recovered faster than exhaustive search.\nIn the most basic form of key recovery through differential cryptanalysis, an attacker requests the ciphertexts for a large number of plaintext pairs, then assumes that the differential holds for at least r \u2212 1 rounds, where r is the total number of rounds. The attacker then deduces which round keys (for the final round) are possible, assuming the difference between the blocks before the final round is fixed. When round keys are short, this can be achieved by simply exhaustively decrypting the ciphertext pairs one round with each possible round key. When one round key has been deemed a potential round key considerably more often than any other key, it is assumed to be the correct round key.\nFor any particular cipher, the input difference must be carefully selected for the attack to be successful. An analysis of the algorithm's internals is undertaken; the standard method is to trace a path of highly probable differences through the various stages of encryption, termed a differential characteristic.\nSince differential cryptanalysis became public knowledge, it has become a basic concern of cipher designers. New designs are expected to be accompanied by evidence that the algorithm is resistant to this attack and many including the Advanced Encryption Standard, have been proven secure against the attack.\n\n== Attack in detail ==\nThe attack relies primarily on the fact that a given input/output difference pattern only occurs for certain values of inputs.  Usually the attack is applied in essence to the non-linear components as if they were a solid component (usually they are in fact look-up tables or S-boxes).  Observing the desired output difference (between two chosen or known plaintext inputs) suggests possible key values.\nFor example, if a differential of 1\n\n== Specialized types ==\nHigher-order differential cryptanalysis\nTruncated differential cryptanalysis\nImpossible differential cryptanalysis\nBoomerang attack"
    }
  },
  {
    "instruction": "Write an answer to the following question: How can the behavior of the dynamic linker be influenced in Unix-like systems using ELF?",
    "context": "",
    "output": "The behavior of the dynamic linker can be influenced during the program's execution or linking in Unix-like systems using ELF by using environment variables such as LD_LIBRARY_PATH and LD_PRELOAD. These variables adjust the runtime linking process by searching for shared libraries at alternate locations and forcibly loading and linking libraries, respectively.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can the behavior of the dynamic linker be influenced in Unix-like systems using ELF?",
      "answer": "The behavior of the dynamic linker can be influenced during the program's execution or linking in Unix-like systems using ELF by using environment variables such as LD_LIBRARY_PATH and LD_PRELOAD. These variables adjust the runtime linking process by searching for shared libraries at alternate locations and forcibly loading and linking libraries, respectively."
    }
  },
  {
    "instruction": "Write an answer to the following question: How many parts of Military Cryptanalytics were completed and published?",
    "context": "",
    "output": "Only parts I and II of Military Cryptanalytics were completed and published. Parts III and IV were never completed.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How many parts of Military Cryptanalytics were completed and published?",
      "answer": "Only parts I and II of Military Cryptanalytics were completed and published. Parts III and IV were never completed."
    }
  },
  {
    "instruction": "Write an answer to the following question: What was the motivation behind the creation of Evercookie?",
    "context": "",
    "output": "Evercookie was created by Samy Kamkar in 2010 to demonstrate the possible infiltration from websites that use respawning and to show how users' privacy can be compromised by contemporary tracking tools.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was the motivation behind the creation of Evercookie?",
      "answer": "Evercookie was created by Samy Kamkar in 2010 to demonstrate the possible infiltration from websites that use respawning and to show how users' privacy can be compromised by contemporary tracking tools."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is a man-in-the-middle attack and how does it work?",
    "context": "",
    "output": "A man-in-the-middle attack is a type of cyberattack in which an attacker intercepts and alters communication between two parties. It can be used to steal sensitive information or inject malware into a system.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is a man-in-the-middle attack and how does it work?",
      "answer": "A man-in-the-middle attack is a type of cyberattack in which an attacker intercepts and alters communication between two parties. It can be used to steal sensitive information or inject malware into a system."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the role of the community behind BackBox?",
    "context": "",
    "output": "The community behind BackBox provides support and helps in customizing and improving the system.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of the community behind BackBox?",
      "answer": "The community behind BackBox provides support and helps in customizing and improving the system."
    }
  },
  {
    "instruction": "Write an answer to the following question: How do TLS accelerators improve the performance of TLS and SSL encryption?",
    "context": "",
    "output": "TLS accelerators improve the performance of TLS and SSL encryption by offloading processor-intensive public-key encryption to a hardware accelerator, freeing up resources on the server and improving the efficiency of the encryption process.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do TLS accelerators improve the performance of TLS and SSL encryption?",
      "answer": "TLS accelerators improve the performance of TLS and SSL encryption by offloading processor-intensive public-key encryption to a hardware accelerator, freeing up resources on the server and improving the efficiency of the encryption process."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does iOS 8 and later versions differ from earlier versions in terms of encryption and data security?",
    "context": "",
    "output": "iOS 8 and later versions include encryption mechanisms that make it difficult for the government to access data on the device without the user's consent. In contrast, earlier versions of iOS did not have the same level of encryption and were more vulnerable to government surveillance. This difference is a key point of contention in the FBI-Apple encryption dispute.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does iOS 8 and later versions differ from earlier versions in terms of encryption and data security?",
      "answer": "iOS 8 and later versions include encryption mechanisms that make it difficult for the government to access data on the device without the user's consent. In contrast, earlier versions of iOS did not have the same level of encryption and were more vulnerable to government surveillance. This difference is a key point of contention in the FBI-Apple encryption dispute."
    }
  },
  {
    "instruction": "Data Security Law of the People's Republic of China\n\n==Introduction==\nThe Data Security Law of the People's Republic of China (Chinese: \u4e2d\u534e\u4eba\u6c11\u5171\u548c\u56fd\u6570\u636e\u5b89\u5168\u6cd5; pinyin: Zh\u014dnghu\u00e1 r\u00e9nm\u00edn g\u00f2ngh\u00e9gu\u00f3 sh\u00f9j\u00f9 \u0101nqu\u00e1n f\u01ce; referred to as the Data Security Law or DSL) governs the creation, use, storage, transfer, and exploitation of data within China. The law is seen to be primarily targeted at technology companies which have grown increasingly powerful in China over the years. The law is part of a series of interlocking but related national security legislation including the National Security Law of the People's Republic of China, Cybersecurity Law and National Intelligence Law, passed during Xi Jinping's administration as part of efforts to strengthen national security .\n\n== Provisions ==\nThe law controversially requires data localisation of data collected by foreign and domestic entities on Chinese citizens. The law prohibits the export of data by technology companies without first the completion of a \"cybersecurity review\", the process of which is vague and still being developed. In addition, foreign judicial authorities are prohibited from requesting data on Chinese citizens without first seeking permission from Chinese authorities.\nArticle 36: The competent authorities of the PRC are to handle foreign justice or law enforcement institution requests for the provision of data, according to relevant laws and treaties or agreements concluded or participated in by the PRC, or in accordance with the principle of equality and reciprocity. Domestic organizations and individuals must not provide data stored within the mainland territory of the PRC to the justice or law enforcement institutions of foreign countries without the approval of the competent authorities of the PRC.\n\n== Reactions ==\nCarolyn Bigg of law firms DLA Piper Hong Kong stated that the law represents: \u201canother important piece in the overall data protection regulatory jigsaw in China\u201d, making it: \u201ccomplex\" and \"increasingly onerous\" for international businesses to navigate through. Chinese technology company stocks fell in reaction to the passing of the law while tech companies such as Meituan, Alibaba and Ant Financial were all placed under regulatory scrutiny prior to its passing. The law is seen to have wide-ranging implications and is seen as another step in the increasing lawfare between China and the United States in areas of trade, intellectual property and national security since the beginning of the US-China trade war which began in 2016.\nQuestion: What is the role of the competent authorities of the PRC under the Data Security Law?",
    "context": "",
    "output": "Answer: The competent authorities of the PRC are responsible for handling foreign justice or law enforcement institution requests for the provision of data under the Data Security Law. This includes ensuring that requests are handled in accordance with relevant laws and treaties or agreements, or in accordance with the principle of equality and reciprocity.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of the competent authorities of the PRC under the Data Security Law?",
      "answer": "The competent authorities of the PRC are responsible for handling foreign justice or law enforcement institution requests for the provision of data under the Data Security Law. This includes ensuring that requests are handled in accordance with relevant laws and treaties or agreements, or in accordance with the principle of equality and reciprocity.",
      "context": "Data Security Law of the People's Republic of China\n\n==Introduction==\nThe Data Security Law of the People's Republic of China (Chinese: \u4e2d\u534e\u4eba\u6c11\u5171\u548c\u56fd\u6570\u636e\u5b89\u5168\u6cd5; pinyin: Zh\u014dnghu\u00e1 r\u00e9nm\u00edn g\u00f2ngh\u00e9gu\u00f3 sh\u00f9j\u00f9 \u0101nqu\u00e1n f\u01ce; referred to as the Data Security Law or DSL) governs the creation, use, storage, transfer, and exploitation of data within China. The law is seen to be primarily targeted at technology companies which have grown increasingly powerful in China over the years. The law is part of a series of interlocking but related national security legislation including the National Security Law of the People's Republic of China, Cybersecurity Law and National Intelligence Law, passed during Xi Jinping's administration as part of efforts to strengthen national security .\n\n== Provisions ==\nThe law controversially requires data localisation of data collected by foreign and domestic entities on Chinese citizens. The law prohibits the export of data by technology companies without first the completion of a \"cybersecurity review\", the process of which is vague and still being developed. In addition, foreign judicial authorities are prohibited from requesting data on Chinese citizens without first seeking permission from Chinese authorities.\nArticle 36: The competent authorities of the PRC are to handle foreign justice or law enforcement institution requests for the provision of data, according to relevant laws and treaties or agreements concluded or participated in by the PRC, or in accordance with the principle of equality and reciprocity. Domestic organizations and individuals must not provide data stored within the mainland territory of the PRC to the justice or law enforcement institutions of foreign countries without the approval of the competent authorities of the PRC.\n\n== Reactions ==\nCarolyn Bigg of law firms DLA Piper Hong Kong stated that the law represents: \u201canother important piece in the overall data protection regulatory jigsaw in China\u201d, making it: \u201ccomplex\" and \"increasingly onerous\" for international businesses to navigate through. Chinese technology company stocks fell in reaction to the passing of the law while tech companies such as Meituan, Alibaba and Ant Financial were all placed under regulatory scrutiny prior to its passing. The law is seen to have wide-ranging implications and is seen as another step in the increasing lawfare between China and the United States in areas of trade, intellectual property and national security since the beginning of the US-China trade war which began in 2016."
    }
  },
  {
    "instruction": "Sherwood Applied Business Security Architecture\n\n==Introduction==\nSABSA (Sherwood Applied Business Security Architecture) is a model and methodology for developing a risk-driven enterprise information security architecture and service management, to support critical business processes. It was developed independently from the Zachman Framework, but has a similar structure. The primary characteristic of the SABSA model is that everything must be derived from an analysis of the business requirements for security, especially those in which security has an enabling function through which new business opportunities can be developed and exploited.\nThe process analyzes the business requirements at the outset, and creates a chain of traceability through the strategy and concept, design, implementation, and ongoing \u2018manage and measure\u2019 phases of the lifecycle to ensure that the business mandate is preserved.  Framework tools created from practical experience further support the whole methodology.  \nThe model is layered, with the top layer being the business requirements definition stage.  At each lower layer a new level of abstraction and detail is developed, going through the definition of the conceptual architecture, logical services architecture, physical infrastructure architecture and finally at the lowest layer, the selection of technologies and products (component architecture). \nThe SABSA model itself is generic and can be the starting point for any organization, but by going through the process of analysis and decision-making implied by its structure, it becomes specific to the enterprise, and is finally highly customized to a unique business model.  It becomes in reality the enterprise security architecture, and it is central to the success of a strategic program of information security management within the organization. \nSABSA is a particular example of a methodology that can be used both for IT (information technology) and OT (operational technology) environments.\n\n\n\n== SABSA matrix ==\nNote: The above is the original SABSA Matrix, which is still valid today, but it has been expanded by a comprehensive service management matrix and updated in some detail and terminology areas. In the words of David Lynas, SABSA author, \"The SABSA Matrix and the SABSA Service Management Matrix have not been updated since the late 90s. We have redesigned them to deliver the improvements your feedback has requested over the years. We have not fundamentally changed the structure or principles of the matrices (very few elements have changed position) but have focussed on terminology update and consistency.\" The new versions can be downloaded (along with the 2009 revision of the SABSA White Paper and other important documents like the SABSA Certification Roadmap) at the SABSA Members' Web Site.\n\nAnswer this question based on the above context: How does the SABSA model support the design phase of the security architecture lifecycle?",
    "context": "",
    "output": "The SABSA model supports the design phase of the security architecture lifecycle by providing a framework for defining the logical services architecture. This includes the identification of logical services, the development of service definitions, and the creation of service models.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the SABSA model support the design phase of the security architecture lifecycle?",
      "answer": "The SABSA model supports the design phase of the security architecture lifecycle by providing a framework for defining the logical services architecture. This includes the identification of logical services, the development of service definitions, and the creation of service models.",
      "context": "Sherwood Applied Business Security Architecture\n\n==Introduction==\nSABSA (Sherwood Applied Business Security Architecture) is a model and methodology for developing a risk-driven enterprise information security architecture and service management, to support critical business processes. It was developed independently from the Zachman Framework, but has a similar structure. The primary characteristic of the SABSA model is that everything must be derived from an analysis of the business requirements for security, especially those in which security has an enabling function through which new business opportunities can be developed and exploited.\nThe process analyzes the business requirements at the outset, and creates a chain of traceability through the strategy and concept, design, implementation, and ongoing \u2018manage and measure\u2019 phases of the lifecycle to ensure that the business mandate is preserved.  Framework tools created from practical experience further support the whole methodology.  \nThe model is layered, with the top layer being the business requirements definition stage.  At each lower layer a new level of abstraction and detail is developed, going through the definition of the conceptual architecture, logical services architecture, physical infrastructure architecture and finally at the lowest layer, the selection of technologies and products (component architecture). \nThe SABSA model itself is generic and can be the starting point for any organization, but by going through the process of analysis and decision-making implied by its structure, it becomes specific to the enterprise, and is finally highly customized to a unique business model.  It becomes in reality the enterprise security architecture, and it is central to the success of a strategic program of information security management within the organization. \nSABSA is a particular example of a methodology that can be used both for IT (information technology) and OT (operational technology) environments.\n\n\n\n== SABSA matrix ==\nNote: The above is the original SABSA Matrix, which is still valid today, but it has been expanded by a comprehensive service management matrix and updated in some detail and terminology areas. In the words of David Lynas, SABSA author, \"The SABSA Matrix and the SABSA Service Management Matrix have not been updated since the late 90s. We have redesigned them to deliver the improvements your feedback has requested over the years. We have not fundamentally changed the structure or principles of the matrices (very few elements have changed position) but have focussed on terminology update and consistency.\" The new versions can be downloaded (along with the 2009 revision of the SABSA White Paper and other important documents like the SABSA Certification Roadmap) at the SABSA Members' Web Site."
    }
  },
  {
    "instruction": "Write an answer to the following question: When was the Cisco PIX VPN product hacked by the Equation Group?",
    "context": "",
    "output": "The Cisco PIX VPN product was hacked by the Equation Group somewhere before 2016.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "When was the Cisco PIX VPN product hacked by the Equation Group?",
      "answer": "The Cisco PIX VPN product was hacked by the Equation Group somewhere before 2016."
    }
  },
  {
    "instruction": "Write an answer to the following question: How can a server determine that a given mail message is spam?",
    "context": "",
    "output": "A server can determine that a given mail message is spam by checking for spam traps or after trusted users' reports. Cross-checking against available DNSBLs can also help to avoid including innocent forwarders in the tarpit database.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can a server determine that a given mail message is spam?",
      "answer": "A server can determine that a given mail message is spam by checking for spam traps or after trusted users' reports. Cross-checking against available DNSBLs can also help to avoid including innocent forwarders in the tarpit database."
    }
  },
  {
    "instruction": "OpenSSL\n\n==Introduction==\nOpenSSL is a software library for applications that provide secure communications over computer networks against eavesdropping, and identify the party at the other end. It is widely used by Internet servers, including the majority of HTTPS websites.\nOpenSSL contains an open-source implementation of the SSL and TLS protocols.  The core library, written in the C programming language, implements basic cryptographic functions and provides various utility functions. Wrappers allowing the use of the OpenSSL library in a variety of computer languages are available.\nThe OpenSSL Software Foundation (OSF) represents the OpenSSL project in most legal capacities including contributor license agreements, managing donations, and so on. OpenSSL Software Services (OSS) also represents the OpenSSL project for support contracts.\nOpenSSL is available for most Unix-like operating systems (including Linux, macOS, and BSD), Microsoft Windows and OpenVMS.\n\n\n\n== Project history ==\nThe OpenSSL project was founded in 1998 to provide a free set of encryption tools for the code used on the Internet. It is based on a fork of SSLeay by Eric Andrew Young and Tim Hudson, which unofficially ended development on December 17, 1998, when Young and Hudson both went to work for RSA Security.  The initial founding members were Mark Cox, Ralf Engelschall, Stephen Henson, Ben Laurie, and Paul Sutton.As of May 2019, the OpenSSL management committee consisted of seven people and there are seventeen developers with commit access (many of whom are also part of the OpenSSL management committee). There are only two full-time employees (fellows) and the remainder are volunteers.\nThe project has a budget of less than $1 million USD per year and relies primarily on donations. Development of TLS 1.3 was sponsored by Akamai.\n\n== Major version releases ==\n\n== Algorithms ==\nOpenSSL supports a number of different cryptographic algorithms:\n\nCiphers\n\nAES, Blowfish, Camellia, Chacha20, Poly1305,  SEED, CAST-128, DES, IDEA, RC2, RC4, RC5, Triple DES, GOST 28147-89, SM4\nCryptographic hash functions\n\nMD5, MD4, MD2, SHA-1, SHA-2, SHA-3, RIPEMD-160, MDC-2, GOST R 34.11-94, BLAKE2, Whirlpool, SM3\nPublic-key cryptography\n\nRSA, DSA, Diffie\u2013Hellman key exchange,  Elliptic curve, X25519, Ed25519, X448, Ed448, GOST R 34.10-2001, SM2(Perfect forward secrecy is supported using elliptic curve Diffie\u2013Hellman since version 1.0.)\n\n== FIPS 140 validation ==\nFIPS 140 is a U.S. Federal program for the testing and certification of cryptographic modules. An early FIPS 140-1 certificate for OpenSSL's FOM 1.0 was revoked in July 2006 \"when questions were raised about the validated module's interaction with outside software.\" The module was re-certified in February 2007 before giving way to FIPS 140-2. OpenSSL 1.0.2 supported the use of the OpenSSL FIPS Object Module (FOM), which was built to deliver FIPS approved algorithms in a FIPS 140-2 validated environment. OpenSSL controversially decided to categorize the 1.0.2 architecture as 'end of life' or 'EOL', effective December 31, 2019, despite objections that it was the only version of OpenSSL that was currently available with support for FIPS mode. As a result of the EOL, many users were unable to properly deploy the FOM 2.0 and fell out of compliance because they did not secure extended support for the 1.0.2 architecture, although the FOM itself remained validated for eight months further.\nThe FIPS Object Module 2.0 remained FIPS 140-2 validated in several formats until September 1, 2020, when NIST deprecated the usage of FIPS 186-2 for Digital Signature Standard and designated all non-compliant modules as 'Historical'. This designation includes a caution to federal agencies that they should not include the module in any new procurements. All three of the OpenSSL validations were included in the deprecation \u2013 the OpenSSL FIPS Object Module (certificate #1747), OpenSSL FIPS Object Module SE (certificate #2398), and OpenSSL FIPS Object Module RE (certificate #2473). Many 'private label' OpenSSL-based validations and clones created by consultants were also moved to the Historical List, although some FIPS validated modules with replacement compatibility avoided the deprecation, such as BoringCrypto from Google and CryptoComply from SafeLogic.The OpenSSL Management Committee announced a change in the versioning scheme.\nDue to this change, the major number of the next major version would have been doubled, since the OpenSSL FIPS module already occupied this number. Therefore the decision was made to skip the OpenSSL 2.0 version number and continue with OpenSSL 3.0 .\nOpenSSL 3.0 restored FIPS mode and underwent FIPS 140-2 testing, but with significant delays: The effort was first kicked off in 2016 with support from SafeLogic and further support from Oracle in 2017, but the process has been challenging.\nOn October 20, 2020, the OpenSSL FIPS Provider 3.0 was added to the CMVP Implementation Under Test List, which reflected an official engagement with a testing lab to proceed with a FIPS 140-2 validation. This resulted in a slew of certifications in the following months.\n\n== Licensing ==\nOpenSSL was dual-licensed under the OpenSSL License and the SSLeay License, which means that the terms of either licenses can be used. The OpenSSL License is Apache License 1.0 and SSLeay License bears some similarity to a 4-clause BSD License.\nAs the OpenSSL License was Apache License 1.0, but not Apache License 2.0, it requires the phrase \"this product includes software developed by the OpenSSL Project for use in the OpenSSL Toolkit\" to appear in advertising material and any redistributions (Sections 3 and 6 of the OpenSSL License). Due to this restriction, the OpenSSL License and the Apache License 1.0 are incompatible with the GNU GPL.\nSome GPL developers have added an OpenSSL exception to their licenses that specifically permits using OpenSSL with their system. GNU Wget and climm both use such exceptions. Some packages (like Deluge) explicitly modify the GPL license by adding an extra section at the beginning of the license documenting the exception. Other packages use the LGPL-licensed GnuTLS, BSD-licensed Botan, or MPL-licensed NSS, which perform the same task.\nOpenSSL announced in August 2015 that it would require most contributors to sign a Contributor License Agreement (CLA), and that OpenSSL would eventually be relicensed under the terms of Apache License 2.0. This process commenced in March 2017, and was complete in 2018.On 7 September 2021, OpenSSL 3.0.0 was released under the Apache License 2.0.\n\n== Notable vulnerabilities ==\n\n\n*** Denial of service: ASN.1 parsing ***\nOpenSSL 0.9.6k has a bug where certain ASN.1 sequences triggered a large number of recursions on Windows machines, discovered on November 4, 2003. Windows could not handle large recursions correctly, so OpenSSL would crash as a result. Being able to send arbitrary large numbers of ASN.1 sequences would cause OpenSSL to crash as a result.\n\n\n*** OCSP stapling vulnerability ***\nWhen creating a handshake, the client could send an incorrectly formatted ClientHello message, leading to OpenSSL parsing more than the end of the message. Assigned the identifier CVE-2011-0014 by the CVE project, this affected all OpenSSL versions 0.9.8h to 0.9.8q and OpenSSL 1.0.0 to 1.0.0c. Since the parsing could lead to a read on an incorrect memory address, it was possible for the attacker to cause a DoS. It was also possible that some applications expose the contents of parsed OCSP extensions, leading to an attacker being able to read the contents of memory that came after the ClientHello.\n\n\n*** ASN.1 BIO vulnerability ***\nWhen using Basic Input/Output (BIO) or FILE based functions to read untrusted DER format data, OpenSSL is vulnerable. This vulnerability was discovered on April 19, 2012, and was assigned the CVE identifier CVE-2012-2110. While not directly affecting the SSL/TLS code of OpenSSL, any application that was using ASN.1 functions (particularly d2i_X509 and d2i_PKCS12) were also not affected.\n\n\n*** SSL, TLS and DTLS plaintext recovery attack ***\nIn handling CBC cipher-suites in SSL, TLS, and DTLS, OpenSSL was found vulnerable to a timing attack during the MAC processing. Nadhem Alfardan and Kenny Paterson discovered the problem, and published their findings on February 5, 2013. The vulnerability was assigned the CVE identifier CVE-2013-0169.\n\n\n*** Predictable private keys (Debian-specific) ***\nOpenSSL's pseudo-random number generator acquires entropy using complex programming methods. To keep the Valgrind analysis tool from issuing associated warnings, a maintainer of the Debian distribution applied a patch to Debian's variant of the OpenSSL suite, which inadvertently broke its random number generator by limiting the overall number of private keys it could generate to 32,768. The broken version was included in the Debian release of September 17, 2006 (version 0.9.8c-1), also compromising other Debian-based distributions, for example Ubuntu. Ready-to-use exploits are easily available.The error was reported by Debian on May 13, 2008. On the Debian 4.0 distribution (etch), these problems were fixed in version 0.9.8c-4etch3, while fixes for the Debian 5.0 distribution (lenny) were provided in version 0.9.8g-9.\n\n\n*** Heartbleed ***\n\nOpenSSL versions 1.0.1 through 1.0.1f have a severe memory handling bug in their implementation of the TLS Heartbeat Extension that could be used to reveal up to 64 KB of the application's memory with every heartbeat (CVE-2014-0160). By reading the memory of the web server, attackers could access sensitive data, including the server's private key. This could allow attackers to decode earlier eavesdropped communications if the encryption protocol used does not ensure perfect forward secrecy. Knowledge of the private key could also allow an attacker to mount a man-in-the-middle attack against any future communications. The vulnerability might also reveal unencrypted parts of other users' sensitive requests and responses, including session cookies and passwords, which might allow attackers to hijack the identity of another user of the service.At its disclosure on April 7, 2014, around 17% or half a million of the Internet's secure web servers certified by trusted authorities were believed to have been vulnerable to the attack. However, Heartbleed can affect both the server and client.\n\n\n*** CCS injection vulnerability ***\nThe CCS Injection Vulnerability (CVE-2014-0224) is a security bypass vulnerability that results from a weakness in OpenSSL methods used for keying material.This vulnerability can be exploited through the use of a man-in-the-middle attack, where an attacker may be able to decrypt and modify traffic in transit. A remote unauthenticated attacker could exploit this vulnerability by using a specially crafted handshake to force the use of weak keying material. Successful exploitation could lead to a security bypass condition where an attacker could gain access to potentially sensitive information. The attack can only be performed between a vulnerable client and server.\nOpenSSL clients are vulnerable in all versions of OpenSSL before the versions 0.9.8za, 1.0.0m and 1.0.1h. Servers are only known to be vulnerable in OpenSSL 1.0.1 and 1.0.2-beta1. Users of OpenSSL servers earlier than 1.0.1 are advised to upgrade as a precaution.\n\n\n*** ClientHello sigalgs DoS ***\nThis vulnerability (CVE-2015-0291) allows anyone to take a certificate, read its contents and modify it accurately to abuse the vulnerability causing a certificate to crash a client or server. If a client connects to an OpenSSL 1.0.2 server and renegotiates with an invalid signature algorithms extension, a null-pointer dereference occurs. This can cause a DoS attack against the server.\nA Stanford Security researcher, David Ramos, had a private exploit and presented it to the OpenSSL team, which then patched the issue.\nOpenSSL classified the bug as a high-severity issue, noting version 1.0.2 was found vulnerable.\n\n\n*** Key recovery attack on Diffie\u2013Hellman small subgroups ***\nThis vulnerability (CVE-2016-0701) allows, when some particular circumstances are met, to recover the OpenSSL server's private Diffie\u2013Hellman key. An Adobe System Security researcher, Antonio Sanso, privately reported the vulnerability.\nOpenSSL classified the bug as a high-severity issue, noting only version 1.0.2 was found vulnerable.\n\n== Forks ==\n\n\n*** Agglomerated SSL ***\nIn 2009, after frustrations with the original OpenSSL API, Marco Peereboom, an OpenBSD developer at the time, forked the original API by creating Agglomerated SSL (assl), which reuses OpenSSL API under the hood, but provides a much simpler external interface.  It has since been deprecated in light of the LibreSSL fork circa 2016.\n\n\n*** LibreSSL ***\n\nIn April 2014 in the wake of Heartbleed, members of the OpenBSD project forked OpenSSL starting with the 1.0.1g branch, to create a project named LibreSSL. In the first week of pruning the OpenSSL's codebase, more than 90,000 lines of C code had been removed from the fork.\n\n\n*** BoringSSL ***\nIn June 2014, Google announced its own fork of OpenSSL dubbed BoringSSL. Google plans to co-operate with OpenSSL and LibreSSL developers. Google has since developed a new library, Tink, based on BoringSSL.\n\n== Criticisms ==\n\n\n*** Backwards compatibility ***\nAmong developers communities, OpenSSL is often cited for coming with a bit of API compatibility breakage with each new major version, which requires software adaptations that tend to delay new version adoptions. This, combined with the fact that previous releases are generally maintained for no more than two years after a new major one is emitted tends to force some vendors to anticipate software migrations very early while still having little time left to update to a new release, sometimes at the risk of losing some compatibility with existing software or risking regressions.\n\n\n*** Delay between releases ***\nWhile LTS (long term supported) releases are maintained for 5 years, accumulated delays in release time frames tend to force operating system vendors to stay on the last supported release longer, leaving less margin when the new version is available. For example OpenSSL 3.0 was initially expected for Q4 2019 and was finally issued 21 months later without extending the expected end of support for previously supported version 1.1.1, and this despite the significant changes that required adaptations to existing software.\n\n\n*** Significant performance regressions ***\nThe reduced support delay of version 1.1.1 mentioned above causes further concerns to users whose workloads are sensitive to performance. Some time after general availability of 3.0, some users started to report serious performance regressions affecting this version in multi-threaded environments, many citing the inefficient use of locks in frequent low-level operations, citing slowdowns from 80 to 400 times. The OpenSSL team has created a meta-issue to try to centralize reports of such massive performance regressions. About half of these reporters indicate the impossibility for them to upgrade to 3.0 from earlier versions, adding to the trouble caused by the limited support time left on previous version 1.1.1.\n\n\n*** Consideration for users' requirements ***\nWhile the QUIC transport layer was being worked on to support the third version of the HTTP protocol, it was proposed to use TLS to provide security, and identified that some adaptations to TLS libraries would be needed. Such modifications were brought to BoringSSL which was the library being primarily used by QUIC developers by then, and later ported to other libraries. A port of this work was quickly proposed to OpenSSL. While some discussion started the same day, it quickly stalled and was first blocked on license considerations, then kept on hold once these concerns were cleared. Finally 10 months later the OpenSSL Management Committee announced on a blog post that this patch set would not be adopted for 3.0 on the fear that the API would change over time. Finally more than one year after planned release of 3.0 which was still not coming, a team of volunteers from Akamai and Microsoft decided to fork the project as QuicTLS and support these patches on top of the OpenSSL code in order to unblock QUIC development. This action was generally welcome by the community. Finally after OpenSSL 3.0 was finally released, the QUIC patch set was reconsidered and decided against, causing tens to hundreds of reactions of disappointment among the community. The pull request was closed, while users felt the need to publicly express their disappointment, or beg operating system vendors to support the alternative QuicTLS fork, or seek for alternative solutions. Finally Rich Salz, co-founder of the QuicTLS fork, announced his interest in seeing an Apache project forked from QuicTLS. As of 25 February 2023 there is still no QUIC-compatible long-term supported TLS library available by default in operating systems without requiring end-users to rebuild it themselves from sources.\n\nAnswer this question based on the above context: Who reported the Key recovery attack on Diffie\u2013Hellman small subgroups vulnerability (CVE-2016-0701) in OpenSSL?",
    "context": "",
    "output": "The Key recovery attack on Diffie\u2013Hellman small subgroups vulnerability (CVE-2016-0701) in OpenSSL was reported by an Adobe System Security researcher, Antonio Sanso.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Who reported the Key recovery attack on Diffie\u2013Hellman small subgroups vulnerability (CVE-2016-0701) in OpenSSL?",
      "answer": "The Key recovery attack on Diffie\u2013Hellman small subgroups vulnerability (CVE-2016-0701) in OpenSSL was reported by an Adobe System Security researcher, Antonio Sanso.",
      "context": "OpenSSL\n\n==Introduction==\nOpenSSL is a software library for applications that provide secure communications over computer networks against eavesdropping, and identify the party at the other end. It is widely used by Internet servers, including the majority of HTTPS websites.\nOpenSSL contains an open-source implementation of the SSL and TLS protocols.  The core library, written in the C programming language, implements basic cryptographic functions and provides various utility functions. Wrappers allowing the use of the OpenSSL library in a variety of computer languages are available.\nThe OpenSSL Software Foundation (OSF) represents the OpenSSL project in most legal capacities including contributor license agreements, managing donations, and so on. OpenSSL Software Services (OSS) also represents the OpenSSL project for support contracts.\nOpenSSL is available for most Unix-like operating systems (including Linux, macOS, and BSD), Microsoft Windows and OpenVMS.\n\n\n\n== Project history ==\nThe OpenSSL project was founded in 1998 to provide a free set of encryption tools for the code used on the Internet. It is based on a fork of SSLeay by Eric Andrew Young and Tim Hudson, which unofficially ended development on December 17, 1998, when Young and Hudson both went to work for RSA Security.  The initial founding members were Mark Cox, Ralf Engelschall, Stephen Henson, Ben Laurie, and Paul Sutton.As of May 2019, the OpenSSL management committee consisted of seven people and there are seventeen developers with commit access (many of whom are also part of the OpenSSL management committee). There are only two full-time employees (fellows) and the remainder are volunteers.\nThe project has a budget of less than $1 million USD per year and relies primarily on donations. Development of TLS 1.3 was sponsored by Akamai.\n\n== Major version releases ==\n\n== Algorithms ==\nOpenSSL supports a number of different cryptographic algorithms:\n\nCiphers\n\nAES, Blowfish, Camellia, Chacha20, Poly1305,  SEED, CAST-128, DES, IDEA, RC2, RC4, RC5, Triple DES, GOST 28147-89, SM4\nCryptographic hash functions\n\nMD5, MD4, MD2, SHA-1, SHA-2, SHA-3, RIPEMD-160, MDC-2, GOST R 34.11-94, BLAKE2, Whirlpool, SM3\nPublic-key cryptography\n\nRSA, DSA, Diffie\u2013Hellman key exchange,  Elliptic curve, X25519, Ed25519, X448, Ed448, GOST R 34.10-2001, SM2(Perfect forward secrecy is supported using elliptic curve Diffie\u2013Hellman since version 1.0.)\n\n== FIPS 140 validation ==\nFIPS 140 is a U.S. Federal program for the testing and certification of cryptographic modules. An early FIPS 140-1 certificate for OpenSSL's FOM 1.0 was revoked in July 2006 \"when questions were raised about the validated module's interaction with outside software.\" The module was re-certified in February 2007 before giving way to FIPS 140-2. OpenSSL 1.0.2 supported the use of the OpenSSL FIPS Object Module (FOM), which was built to deliver FIPS approved algorithms in a FIPS 140-2 validated environment. OpenSSL controversially decided to categorize the 1.0.2 architecture as 'end of life' or 'EOL', effective December 31, 2019, despite objections that it was the only version of OpenSSL that was currently available with support for FIPS mode. As a result of the EOL, many users were unable to properly deploy the FOM 2.0 and fell out of compliance because they did not secure extended support for the 1.0.2 architecture, although the FOM itself remained validated for eight months further.\nThe FIPS Object Module 2.0 remained FIPS 140-2 validated in several formats until September 1, 2020, when NIST deprecated the usage of FIPS 186-2 for Digital Signature Standard and designated all non-compliant modules as 'Historical'. This designation includes a caution to federal agencies that they should not include the module in any new procurements. All three of the OpenSSL validations were included in the deprecation \u2013 the OpenSSL FIPS Object Module (certificate #1747), OpenSSL FIPS Object Module SE (certificate #2398), and OpenSSL FIPS Object Module RE (certificate #2473). Many 'private label' OpenSSL-based validations and clones created by consultants were also moved to the Historical List, although some FIPS validated modules with replacement compatibility avoided the deprecation, such as BoringCrypto from Google and CryptoComply from SafeLogic.The OpenSSL Management Committee announced a change in the versioning scheme.\nDue to this change, the major number of the next major version would have been doubled, since the OpenSSL FIPS module already occupied this number. Therefore the decision was made to skip the OpenSSL 2.0 version number and continue with OpenSSL 3.0 .\nOpenSSL 3.0 restored FIPS mode and underwent FIPS 140-2 testing, but with significant delays: The effort was first kicked off in 2016 with support from SafeLogic and further support from Oracle in 2017, but the process has been challenging.\nOn October 20, 2020, the OpenSSL FIPS Provider 3.0 was added to the CMVP Implementation Under Test List, which reflected an official engagement with a testing lab to proceed with a FIPS 140-2 validation. This resulted in a slew of certifications in the following months.\n\n== Licensing ==\nOpenSSL was dual-licensed under the OpenSSL License and the SSLeay License, which means that the terms of either licenses can be used. The OpenSSL License is Apache License 1.0 and SSLeay License bears some similarity to a 4-clause BSD License.\nAs the OpenSSL License was Apache License 1.0, but not Apache License 2.0, it requires the phrase \"this product includes software developed by the OpenSSL Project for use in the OpenSSL Toolkit\" to appear in advertising material and any redistributions (Sections 3 and 6 of the OpenSSL License). Due to this restriction, the OpenSSL License and the Apache License 1.0 are incompatible with the GNU GPL.\nSome GPL developers have added an OpenSSL exception to their licenses that specifically permits using OpenSSL with their system. GNU Wget and climm both use such exceptions. Some packages (like Deluge) explicitly modify the GPL license by adding an extra section at the beginning of the license documenting the exception. Other packages use the LGPL-licensed GnuTLS, BSD-licensed Botan, or MPL-licensed NSS, which perform the same task.\nOpenSSL announced in August 2015 that it would require most contributors to sign a Contributor License Agreement (CLA), and that OpenSSL would eventually be relicensed under the terms of Apache License 2.0. This process commenced in March 2017, and was complete in 2018.On 7 September 2021, OpenSSL 3.0.0 was released under the Apache License 2.0.\n\n== Notable vulnerabilities ==\n\n\n*** Denial of service: ASN.1 parsing ***\nOpenSSL 0.9.6k has a bug where certain ASN.1 sequences triggered a large number of recursions on Windows machines, discovered on November 4, 2003. Windows could not handle large recursions correctly, so OpenSSL would crash as a result. Being able to send arbitrary large numbers of ASN.1 sequences would cause OpenSSL to crash as a result.\n\n\n*** OCSP stapling vulnerability ***\nWhen creating a handshake, the client could send an incorrectly formatted ClientHello message, leading to OpenSSL parsing more than the end of the message. Assigned the identifier CVE-2011-0014 by the CVE project, this affected all OpenSSL versions 0.9.8h to 0.9.8q and OpenSSL 1.0.0 to 1.0.0c. Since the parsing could lead to a read on an incorrect memory address, it was possible for the attacker to cause a DoS. It was also possible that some applications expose the contents of parsed OCSP extensions, leading to an attacker being able to read the contents of memory that came after the ClientHello.\n\n\n*** ASN.1 BIO vulnerability ***\nWhen using Basic Input/Output (BIO) or FILE based functions to read untrusted DER format data, OpenSSL is vulnerable. This vulnerability was discovered on April 19, 2012, and was assigned the CVE identifier CVE-2012-2110. While not directly affecting the SSL/TLS code of OpenSSL, any application that was using ASN.1 functions (particularly d2i_X509 and d2i_PKCS12) were also not affected.\n\n\n*** SSL, TLS and DTLS plaintext recovery attack ***\nIn handling CBC cipher-suites in SSL, TLS, and DTLS, OpenSSL was found vulnerable to a timing attack during the MAC processing. Nadhem Alfardan and Kenny Paterson discovered the problem, and published their findings on February 5, 2013. The vulnerability was assigned the CVE identifier CVE-2013-0169.\n\n\n*** Predictable private keys (Debian-specific) ***\nOpenSSL's pseudo-random number generator acquires entropy using complex programming methods. To keep the Valgrind analysis tool from issuing associated warnings, a maintainer of the Debian distribution applied a patch to Debian's variant of the OpenSSL suite, which inadvertently broke its random number generator by limiting the overall number of private keys it could generate to 32,768. The broken version was included in the Debian release of September 17, 2006 (version 0.9.8c-1), also compromising other Debian-based distributions, for example Ubuntu. Ready-to-use exploits are easily available.The error was reported by Debian on May 13, 2008. On the Debian 4.0 distribution (etch), these problems were fixed in version 0.9.8c-4etch3, while fixes for the Debian 5.0 distribution (lenny) were provided in version 0.9.8g-9.\n\n\n*** Heartbleed ***\n\nOpenSSL versions 1.0.1 through 1.0.1f have a severe memory handling bug in their implementation of the TLS Heartbeat Extension that could be used to reveal up to 64 KB of the application's memory with every heartbeat (CVE-2014-0160). By reading the memory of the web server, attackers could access sensitive data, including the server's private key. This could allow attackers to decode earlier eavesdropped communications if the encryption protocol used does not ensure perfect forward secrecy. Knowledge of the private key could also allow an attacker to mount a man-in-the-middle attack against any future communications. The vulnerability might also reveal unencrypted parts of other users' sensitive requests and responses, including session cookies and passwords, which might allow attackers to hijack the identity of another user of the service.At its disclosure on April 7, 2014, around 17% or half a million of the Internet's secure web servers certified by trusted authorities were believed to have been vulnerable to the attack. However, Heartbleed can affect both the server and client.\n\n\n*** CCS injection vulnerability ***\nThe CCS Injection Vulnerability (CVE-2014-0224) is a security bypass vulnerability that results from a weakness in OpenSSL methods used for keying material.This vulnerability can be exploited through the use of a man-in-the-middle attack, where an attacker may be able to decrypt and modify traffic in transit. A remote unauthenticated attacker could exploit this vulnerability by using a specially crafted handshake to force the use of weak keying material. Successful exploitation could lead to a security bypass condition where an attacker could gain access to potentially sensitive information. The attack can only be performed between a vulnerable client and server.\nOpenSSL clients are vulnerable in all versions of OpenSSL before the versions 0.9.8za, 1.0.0m and 1.0.1h. Servers are only known to be vulnerable in OpenSSL 1.0.1 and 1.0.2-beta1. Users of OpenSSL servers earlier than 1.0.1 are advised to upgrade as a precaution.\n\n\n*** ClientHello sigalgs DoS ***\nThis vulnerability (CVE-2015-0291) allows anyone to take a certificate, read its contents and modify it accurately to abuse the vulnerability causing a certificate to crash a client or server. If a client connects to an OpenSSL 1.0.2 server and renegotiates with an invalid signature algorithms extension, a null-pointer dereference occurs. This can cause a DoS attack against the server.\nA Stanford Security researcher, David Ramos, had a private exploit and presented it to the OpenSSL team, which then patched the issue.\nOpenSSL classified the bug as a high-severity issue, noting version 1.0.2 was found vulnerable.\n\n\n*** Key recovery attack on Diffie\u2013Hellman small subgroups ***\nThis vulnerability (CVE-2016-0701) allows, when some particular circumstances are met, to recover the OpenSSL server's private Diffie\u2013Hellman key. An Adobe System Security researcher, Antonio Sanso, privately reported the vulnerability.\nOpenSSL classified the bug as a high-severity issue, noting only version 1.0.2 was found vulnerable.\n\n== Forks ==\n\n\n*** Agglomerated SSL ***\nIn 2009, after frustrations with the original OpenSSL API, Marco Peereboom, an OpenBSD developer at the time, forked the original API by creating Agglomerated SSL (assl), which reuses OpenSSL API under the hood, but provides a much simpler external interface.  It has since been deprecated in light of the LibreSSL fork circa 2016.\n\n\n*** LibreSSL ***\n\nIn April 2014 in the wake of Heartbleed, members of the OpenBSD project forked OpenSSL starting with the 1.0.1g branch, to create a project named LibreSSL. In the first week of pruning the OpenSSL's codebase, more than 90,000 lines of C code had been removed from the fork.\n\n\n*** BoringSSL ***\nIn June 2014, Google announced its own fork of OpenSSL dubbed BoringSSL. Google plans to co-operate with OpenSSL and LibreSSL developers. Google has since developed a new library, Tink, based on BoringSSL.\n\n== Criticisms ==\n\n\n*** Backwards compatibility ***\nAmong developers communities, OpenSSL is often cited for coming with a bit of API compatibility breakage with each new major version, which requires software adaptations that tend to delay new version adoptions. This, combined with the fact that previous releases are generally maintained for no more than two years after a new major one is emitted tends to force some vendors to anticipate software migrations very early while still having little time left to update to a new release, sometimes at the risk of losing some compatibility with existing software or risking regressions.\n\n\n*** Delay between releases ***\nWhile LTS (long term supported) releases are maintained for 5 years, accumulated delays in release time frames tend to force operating system vendors to stay on the last supported release longer, leaving less margin when the new version is available. For example OpenSSL 3.0 was initially expected for Q4 2019 and was finally issued 21 months later without extending the expected end of support for previously supported version 1.1.1, and this despite the significant changes that required adaptations to existing software.\n\n\n*** Significant performance regressions ***\nThe reduced support delay of version 1.1.1 mentioned above causes further concerns to users whose workloads are sensitive to performance. Some time after general availability of 3.0, some users started to report serious performance regressions affecting this version in multi-threaded environments, many citing the inefficient use of locks in frequent low-level operations, citing slowdowns from 80 to 400 times. The OpenSSL team has created a meta-issue to try to centralize reports of such massive performance regressions. About half of these reporters indicate the impossibility for them to upgrade to 3.0 from earlier versions, adding to the trouble caused by the limited support time left on previous version 1.1.1.\n\n\n*** Consideration for users' requirements ***\nWhile the QUIC transport layer was being worked on to support the third version of the HTTP protocol, it was proposed to use TLS to provide security, and identified that some adaptations to TLS libraries would be needed. Such modifications were brought to BoringSSL which was the library being primarily used by QUIC developers by then, and later ported to other libraries. A port of this work was quickly proposed to OpenSSL. While some discussion started the same day, it quickly stalled and was first blocked on license considerations, then kept on hold once these concerns were cleared. Finally 10 months later the OpenSSL Management Committee announced on a blog post that this patch set would not be adopted for 3.0 on the fear that the API would change over time. Finally more than one year after planned release of 3.0 which was still not coming, a team of volunteers from Akamai and Microsoft decided to fork the project as QuicTLS and support these patches on top of the OpenSSL code in order to unblock QUIC development. This action was generally welcome by the community. Finally after OpenSSL 3.0 was finally released, the QUIC patch set was reconsidered and decided against, causing tens to hundreds of reactions of disappointment among the community. The pull request was closed, while users felt the need to publicly express their disappointment, or beg operating system vendors to support the alternative QuicTLS fork, or seek for alternative solutions. Finally Rich Salz, co-founder of the QuicTLS fork, announced his interest in seeing an Apache project forked from QuicTLS. As of 25 February 2023 there is still no QUIC-compatible long-term supported TLS library available by default in operating systems without requiring end-users to rebuild it themselves from sources."
    }
  },
  {
    "instruction": "Write an answer to the following question: How was data encryption handled in Peerio, and what cryptographic primitives were used?",
    "context": "",
    "output": "Peerio utilized end-to-end encryption, encrypting data in a way that only the sender and intended recipients could decrypt and read the data. The NaCl cryptographic framework was used, incorporating X25519 for public key agreement over elliptic curves, ed25519 for public key signatures, XSalsa20 for encryption and confidentiality, Poly1305 for ensuring the integrity of encrypted data, scrypt for memory-hard key derivation, and BLAKE2s for various hashing operations.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How was data encryption handled in Peerio, and what cryptographic primitives were used?",
      "answer": "Peerio utilized end-to-end encryption, encrypting data in a way that only the sender and intended recipients could decrypt and read the data. The NaCl cryptographic framework was used, incorporating X25519 for public key agreement over elliptic curves, ed25519 for public key signatures, XSalsa20 for encryption and confidentiality, Poly1305 for ensuring the integrity of encrypted data, scrypt for memory-hard key derivation, and BLAKE2s for various hashing operations."
    }
  },
  {
    "instruction": "Write an answer to the following question: How many funding rounds has Lastline gone through since its founding in 2011?",
    "context": "",
    "output": "Lastline has gone through four funding rounds since its founding in 2011.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How many funding rounds has Lastline gone through since its founding in 2011?",
      "answer": "Lastline has gone through four funding rounds since its founding in 2011."
    }
  },
  {
    "instruction": "Answer based on context:\n\nSXAL/MBAL\n\n==Introduction==\nIn cryptography, SXAL (substitution xor algorithm, sometimes called SXAL8) is a block cipher designed in 1993 by Yokohama-based Laurel Intelligent Systems. It is normally used in a special mode of operation called MBAL (multi-block algorithm). SXAL/MBAL has been used for encryption in a number of Japanese PC cards and smart cards.\nSXAL is an 8-round substitution\u2013permutation network with block size and key size of 64 bits each. All operations are byte-oriented. The algorithm uses a single 8\u00d78-bit S-box K, designed so that both K(X) and X XOR K(X) are injective functions. In each round, the bytes of the block are first permuted. Then each byte is XORed with a key byte and an earlier ciphertext byte, processed through the S-box, and XORed with the previous plaintext byte.\nThe key schedule is rather complex, processing the key with SXAL itself, beginning with a null key and using permuted intermediate results as later keys.\n\n== MBAL ==\nMBAL is an encryption algorithm built using SXAL that can be applied to messages any number of bytes in length (at least 8). It uses two 64-bit extended keys for key whitening on the first 64 bits. The algorithm consists of 9 steps:\n\nPre-whitening\nFm: An expanded version of SXAL applied to the entire message\nSXAL the block consisting of the first 4 and last 4 bytes\nReverse the byte order of the entire message\nFm\nReverse\nSXAL the ends\nFm\nPost-whiteningMBAL has been shown to be susceptible to both differential cryptanalysis and linear cryptanalysis.\n\nWhat is the role of the S-box K in SXAL?",
    "context": "",
    "output": "The S-box K in SXAL is designed such that both K(X) and X XOR K(X) are injective functions, and it is used for processing the bytes of the block during each round.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of the S-box K in SXAL?",
      "answer": "The S-box K in SXAL is designed such that both K(X) and X XOR K(X) are injective functions, and it is used for processing the bytes of the block during each round.",
      "context": "SXAL/MBAL\n\n==Introduction==\nIn cryptography, SXAL (substitution xor algorithm, sometimes called SXAL8) is a block cipher designed in 1993 by Yokohama-based Laurel Intelligent Systems. It is normally used in a special mode of operation called MBAL (multi-block algorithm). SXAL/MBAL has been used for encryption in a number of Japanese PC cards and smart cards.\nSXAL is an 8-round substitution\u2013permutation network with block size and key size of 64 bits each. All operations are byte-oriented. The algorithm uses a single 8\u00d78-bit S-box K, designed so that both K(X) and X XOR K(X) are injective functions. In each round, the bytes of the block are first permuted. Then each byte is XORed with a key byte and an earlier ciphertext byte, processed through the S-box, and XORed with the previous plaintext byte.\nThe key schedule is rather complex, processing the key with SXAL itself, beginning with a null key and using permuted intermediate results as later keys.\n\n== MBAL ==\nMBAL is an encryption algorithm built using SXAL that can be applied to messages any number of bytes in length (at least 8). It uses two 64-bit extended keys for key whitening on the first 64 bits. The algorithm consists of 9 steps:\n\nPre-whitening\nFm: An expanded version of SXAL applied to the entire message\nSXAL the block consisting of the first 4 and last 4 bytes\nReverse the byte order of the entire message\nFm\nReverse\nSXAL the ends\nFm\nPost-whiteningMBAL has been shown to be susceptible to both differential cryptanalysis and linear cryptanalysis."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the LARIAT platform simulate users and reflect vulnerabilities?",
    "context": "",
    "output": "The LARIAT platform simulates users and reflects vulnerabilities caused by design flaws and user interactions by using virtual users managed by Markov models, which allow them to act differently from each other in a realistic way. This results in a realistic simulation of an active network of users that can be targeted for malicious attacks to test the effectiveness of the attacks against network defenses.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the LARIAT platform simulate users and reflect vulnerabilities?",
      "answer": "The LARIAT platform simulates users and reflects vulnerabilities caused by design flaws and user interactions by using virtual users managed by Markov models, which allow them to act differently from each other in a realistic way. This results in a realistic simulation of an active network of users that can be targeted for malicious attacks to test the effectiveness of the attacks against network defenses."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are some of the firewall rule-set appliance-UTM filtering features, and how do they differ from advanced features?",
    "context": "",
    "output": "Firewall rule-set appliance-UTM filtering features refer to the basic firewall capabilities provided by firewall appliances, such as packet filtering, stateful inspection, and application-level gateway. Advanced features, on the other hand, include more sophisticated functionalities such as intrusion prevention, content filtering, and anti-malware protection.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are some of the firewall rule-set appliance-UTM filtering features, and how do they differ from advanced features?",
      "answer": "Firewall rule-set appliance-UTM filtering features refer to the basic firewall capabilities provided by firewall appliances, such as packet filtering, stateful inspection, and application-level gateway. Advanced features, on the other hand, include more sophisticated functionalities such as intrusion prevention, content filtering, and anti-malware protection."
    }
  },
  {
    "instruction": "2018 SingHealth data breach\n\n==Introduction==\nThe 2018 SingHealth data breach was a data breach incident initiated by unidentified state actors, which happened between 27 June and 4 July 2018. During that period, personal particulars of 1.5 million SingHealth patients and records of outpatient dispensed medicines belonging to 160,000 patients were stolen. Names, National Registration Identity Card (NRIC) numbers, addresses, dates of birth, race, and gender of patients who visited specialist outpatient clinics and polyclinics between 1 May 2015 and 4 July 2018 were maliciously accessed and copied. Information relating to patient diagnosis, test results and doctors' notes were unaffected. Information on Prime Minister Lee Hsien Loong was specifically targeted.\n\n== Discovery ==\nThe database administrators for the Integrated Health Information Systems (IHIS), the public healthcare IT provider, detected unusual activity on one of SingHealth's IT databases on 4 July, and implemented precautions against further intrusions. Network traffic monitoring was enhanced; additional malicious activity was detected after 4 July, but did not result in the theft of any data. Having ascertained that a cyberattack occurred, administrators notified the ministries and brought in the Cyber Security Agency (CSA) on 10 July to carry out forensic investigations. The agency determined that perpetrators gained privileged access to the IT network by compromising a front-end workstation, and obtained login credentials to access the database, while hiding their digital footprints. The attack was made public in a statement released by the Ministry of Communications and Information and Ministry of Health on 20 July. The ten-day delay between the discovery of the attack and the public announcement was attributed to time needed to fortify the IT systems, conduct preliminary investigations, identify affected patients and prepare the logistics of the announcement. Text messages were subsequently sent to patients whose data was affected.\n\n== Investigation ==\nOn 6 August 2018 in Parliament, S. Iswaran, Minister for Communications and Information, attributed the attack to sophisticated state-linked actors who wrote customized malware to circumvent SingHealth's antivirus and security tools. Iswaran did not name any state in the interest of national security.A Committee of Inquiry was convened on 24 July 2018 to investigate the causes of the attack and identify measures to help prevent similar attacks. The four-member committee is chaired by former chief district judge Richard Magnus, and comprise leaders of a cyber-security firm, a healthcare technology firm and the National Trades Union Congress respectively. The committee called on the Attorney-General's Chambers to lead evidence, and the Attorney-General's Chambers appointed the Cyber Security Agency to lead the investigations with the support of the Criminal Investigation Department. The committee held closed-door and public hearings from 28 August, with another tranche of hearings from 21 September to 5 October. In addition, the Personal Data Protection Commission investigated into possible breaches of the Personal Data Protection Act in protecting data and hence determine possible action.\n\n== Committee of Inquiry hearings ==\nThe Committee of Inquiry hearings began on 21 September 2018. In the first hearing, Solicitor-General Kwek Mean Luck said that a series of staff missteps and gaps in the system contributed to the breach. Some examples mentioned are the EMR system, which was in place since 1999. In addition, it was mentioned that the cyberattacker behind the incident started infecting workstations as early as August 2017 using a hacking tool. The version of Microsoft Outlook being used did not have a patch that prevents attacks by that hacking tool. Between December 2017 and May 2018, the cyberattacker moved sideways and gained access to a workstation to infect other computers with malware. Other inadequacies identified include not being able to identify multiple failed attempts to log into the system, which was done with non-existent accounts or accounts that do not have much privileges in the system. Eventually, the cyberattacker successfully gained entry through a coding vulnerability on 26 June, and hence sent SQL queries until 4 July when it was stopped by an administrator. In addition, there were three periods where staff failed to respond or responded after a few days when knowledge of the cyberattack was first known. On the same day, two staff members said that while a framework was in place to report cyberattacks, there is insufficient training on what to do, hence it was unclear to staff about what actions should be taken.At the next hearing on 24 September, it was revealed that Prime Minister Lee Hsien Loong's personal data and outpatient records along with two other unnamed people were searched by hackers who infiltrated into the servers using NRIC numbers. The rest of the queries were generally done on patient demographic data, like one that involved the first 20,000 records of such data from Singapore General Hospital. An assistant lead analyst who detected unusual activity investigated further even through that was not his scope, and sent alerts to different divisions to find the staff who can make sense of those queries. The analyst's supervisor told the analyst to continue monitoring the situation and that he assumed there was no medical data until being informed that there was such a leak. As the analyst informed a reporting officer, there was no point in reporting the query himself, asking the analyst to follow up on the queries. Details about reporting procedures and containment measures were mentioned.On the third day, a cybersecurity employee at Integrated Health Information Systems (IHiS), who was on holiday when the incident happened, did not follow up after having read the emails as it was thought to have been collection of data from workstations for investigation. In addition, only one computer at IHiS was used to carry out forensic examinations, resulting in delays diagnosing the issue. This is confirmed by the fourth day of the trial, where failings of judgement and organisational processes are exposed. For instance, meetings with the security management department were not conducted regularly, and no framework was created to set out appropriate responses to cybersecurity risks or to appoint covering officers if any staff go on leave. A clarification on processes was provided, where a standard operating procedure to escalate incidents was approved by the management in March 2018. It was also revealed the same day that staffers took six more days after 4 July to confirm the data breach as an IHiS employee mistakenly informed colleagues that no data was stolen, only confirmed after further tests are run by the superior finding that data was stolen. The queries were later recreated.It was also revealed on the fifth day that a server exploited by hackers did not receive security updates in more than a year since May 2017 due to the WannaCry ransomware attacks, compared to the normal duration where patches were done several times a month. Besides that, the computer's anti-virus software was too old and must be reinstalled. The manager was not supposed to manage the server on paper, but in practice, was given the role in 2014 as the server was located at the National Cancer Centre Singapore, thereby being convenient for staff members to approach him in case help was needed. Once the counterparts resigned, there was no one at IHiS present to take over managing the server. In fact, the IHiS director was not aware that the server was not managed by the firm in practice, only giving a directive in 2014 that IHiS will not manage research servers. The next day, a security loophole that was not plugged was scruntised. Even though the loophole was flagged by an IHiS employee, there was no action taken. In fact, the employee was dismissed after sending details of the flaw to a rival company.Towards the end of the second tranche of hearings on 5 October 2018, it was revealed a second attempt to hack into the servers was done on 19 July via another server as the attackers are skilled. This was stopped immediately as soon as it began. In addition, malware used was customised for the system and evaded detection from top anti-virus software. A tool called PowerShell was used in the process, being disabled on 13 July. Meanwhile, IHiS stepped up security with changing passwords, removing compromised accounts and rebooting servers.The third tranche of hearings started on 31 October 2018. Evidence was shown that managers were reluctant to report the incidents as that would mean an increased amount of work, thereby creating a bottleneck. Meanwhile, the chief information officer told the team to escalate the incident, saying a bottleneck is not acceptable, adding that there was no written protocol on how to report SingHealth-related cybersecurity incidents should IHiS staff discover any incident. Another pointed out that annual cybersecurity exercises are mandated for critical information infrastructure (CII) operators, so staff should be able to identify advanced persistent threats (APTs). However, these tests were for classroom settings and may not necessarily apply to the SingHealth case, thus defeating the purpose of these exercises if situational awareness was not there. There were also plans for secure Internet browsing in the healthcare sector by 2018, but it had to be delayed by a year due to technical issues.The following day, a 2016 audit that found systemic weaknesses in the network link between Singapore General Hospital and cloud-based systems was brought up, showing more inadequacies in the systems managed by IHiS. The incident was reported by the operations team as \"plugged\" to the management without anyone verifying that works to fix these vulnerabilities were done. The Cyber Security Agency also found similar vulnerabilities in its investigation. Due to this, there will be \"three lines of defence\", where compliance checks are performed by the operations team, technology team and internal audit team, and training will be stepped up in IHiS so that early detection of attacks are ensured. As pointed out the next day that even if the weaknesses were found, they may not be fixed as quickly as expected as public healthcare institutions operate around the clock resulting in little downtime.Later in the hearings, SingHealth executives said that they will enhance cyber safety awareness for all employees, as well as roll out new systems to capture patients' data rigorously. It will also allow patients to update their particulars instead of only doing it over the counter. More townhalls will be held to update employees about the latest cyber threats, with log-in messages strengthened to hone the importance of data protection. Storytelling formats will also be used to explain these concepts. More cyber security exercises simulating data breaches were called for in a subsequent hearing, with these allowing professionals to be more familiar with what to do in case a similar incident happens again. In addition, the expert recommended all data within the system to be encrypted including inactive data. As full encryption would be unfeasible due to operational concerns, personal data could be anonymised instead with 2-factor authentication to de-anonymise it. That same hearing, it was updated that many of the written submissions were found to be useful.Towards the final hearings, a former National Security Agency director suggested having the Government and industry partners work together and share information to learn and update each other about new threats that pop up. That is so as current protection measures are insufficient against ever evolving vulnerabilities. In the same hearing, the Ministry of Health's chief data advisor pointed out that Internet separation resulted in longer wait times for patients, declined productivity, increased staff fatigue and new cyber risks, especially when anti-virus software updates are done only on some computers instead of all within the network. Hence, to continue ISS, these factors would need to be considered. The next day, a security expert recommended having a centralised incident management and tracking system that logs all incidents that occur during a breach to reduce miscommunication, which is one of the causes for delayed reporting. In addition, the usage of different chat platforms meant that crucial details about the attack were lost and hence there was not many linkages to the incident.On the final day, Cyber Security Agency chief David Koh suggested changing the way IT staff in the healthcare sector report incidents so that faster response can be ensured during a cyberattack, along with a review of the sector's IT processes and staff training carried out. It was also suggested that cybersecurity processes be considered as a key instead of it merely existing as an afterthought. The hearings thus concluded on 14 November 2018.The closing submissions were held on 30 November 2018. Proposals to improve cybersecurity were shared, including the \"assume breach\" mindset in organisations thus taking necessary measures, having the right people and processes to complement those measures. It was also pointed out that administrator passwords are supposed to be 15 characters long, but one had an problematic password of eight characters which was unchanged since 2012. Lastly, even if measures were put in place to slow down cyberattacks, it is important to note that the attack was done via an advanced persistent threat (APT). Subsequently, the report was submitted to S. Iswaran on 31 December 2018 with the public version released on 10 January 2019.\n\n== Release of report ==\nOn 10 January 2019, the Committee of Inquiry released a report on the SingHealth breach. The report found that staff are inadequately trained in cybersecurity, thus they are unable to stop the attacks. The key staff did not take immediate action to stop the attacks fearing pressure. To make things worse, vulnerabilities in the network and systems are not patched quickly, coupled with the fact that the attackers are well-skilled. As a result, the attackers found it easy to break in. The report did point that if the staff had been adequately trained and vulnerabilities fixed quickly, this attack could have been averted. The report also found that this is the work of an Advanced Persistent Threat group.In the same report, the Committee of Inquiry made 16 recommendations to boost cybersecurity, separated into priority and additional recommendations. They are:\n\nPriority:\nAdopting an enhanced security structure and readiness by IHiS and public health institutions\nReview online security processes to assess ability to defend and respond to cyberattacks\nImproving staff awareness on cyberattacks\nPerform enhanced security checks, especially on critical information infrastructure (CII) systems\nSubject privileged administrator accounts to tighter control and greater monitoring\nImprove incident response processes\nForge partnerships between industries and the Government to achieve higher cybersecurity\nAdditional:\nIT security risk assessments and audits must be treated seriously and carried out regularly\nEnhanced safeguards must be put in place to protect confidentiality of electronic medical records\nImprove domain security against attacks\nImplement a robust patch management process\nImplement a software upgrade policy with a focus on cybersecurity\nImplement an Internet access strategy that limits exposure to external threats\nClearer guidelines on when and how to respond to cybersecurity incidents\nImprove competence of computer security incident response personnel\nConsider a post-breach independent forensic review of the networkOn 15 January 2019, S. Iswaran, Minister for Communications and Information announced in Parliament that the Government accepted the recommendations of the report and will fully adopt them. It has also sped up the implementation of the Cybersecurity Act to increase security of CIIs. Separately, Gan Kim Yong, Minister for Health announced that changes to enhance governance and operations in Singapore's healthcare institutions and IHiS will be made. The dual role of Ministry of Health's chief information security officer (MOH CISO) and the director of cybersecurity governance at IHiS will be separated, where the MOH CISO has a dedicated office and reports to the Permanent Secretary of MOH, while IHiS will have a separate director in charge of cybersecurity governance, with changes at the cluster level. This will help boost operations and governance of the IT systems. In addition, MOH will establish an enhanced \"Three Lines of Defence\" system for public healthcare, and pilot a \"Virtual Browser\" for the National University Health System. All public healthcare staff will remain on Internet Surfing Separation, which was implemented immediately after the cyberattack, and the mandatory contribution of patient medical data to the National Electronic Health Record (NEHR) system will continue to be deferred.\n\n== Aftermath ==\nFollowing the cyberattack, Internet access was temporarily removed from all public healthcare IT terminals with access to the healthcare network, and additional system monitoring and controls were implemented.The attack led to a two-week pause in Singapore's Smart Nation initiatives and a review of the public sector's cyber-security policies during that time. The review resulted in implementation of additional security measures, and urged public sector administrators to remove Internet access where possible and to use secure Information Exchange Gateways otherwise. The attack also renewed concerns among some healthcare practitioners regarding ongoing efforts to centralize electronic patient data in Singapore. Plans to pass laws in late 2018 making it compulsory for healthcare providers to submit data regarding patient visits and diagnoses to the National Electronic Health Record system were postponed. In addition, the Ministry of Health announced on 6 August 2018 that the National Electrical Health Record (NEHR) will be reviewed by an independent group made up of Cyber Security Agency and PricewaterhouseCoopers before asking doctors to submit all records to the NEHR, even though it was not affected by the cyberattack.On 24 July 2018, the Monetary Authority of Singapore told banks in Singapore to tighten customer verification processes in case leaked data was used to impersonate customers, with additional information requested. Banks are also told to conduct risk assessments and mitigate risks from misuse of information.The Integrated Health Information Systems (IHiS) has since strengthened public health systems against data breaches. All suspicious IT incidents will have to be reported within 24 hours. 18 other measures are also put in place, including two-factor authentication for all administrators, proactive threat hunting and intelligence, allowing only computers with latest security updates on hospital networks, and a new database activity monitoring. Studies are done to keep Internet Separation Scheme (ISS) permanent in some parts of the healthcare system with a virtual browser being piloted as an alternative.After the report was released, on 14 January 2019, Integrated Health Information Systems (IHiS) dismissed two employees and demoted one for being negligent in handling and misunderstanding the attack respectively, with financial penalties imposed on two middle management supervisors, and five members of the senior management including CEO Bruce Liang. Three employees were commended by IHiS for handling the incident diligently even when not part of their job scope. IHiS has since fast-tracked a suite of 18 measures for enhancing cybersecurity. The next day, the Personal Data Protection Commission fined IHiS $750,000 and SingHealth $250,000 for not doing enough to safeguard personal data under the Personal Data Protection Act, making it the largest fine imposed for data breaches.Subsequently, on 6 March 2019, cybersecurity company Symantec identified a state-sponsored group, known as Whitefly, behind the cyberattack. Although the country is not identified, that group has been found to be behind several related cyberattacks against Singapore-based entities since 2017.\n\nAnswer this question based on the above context: What was the specific security loophole that was not plugged in the SingHealth data breach?",
    "context": "",
    "output": "The specific security loophole that was not plugged in the SingHealth data breach was flagged by an IHiS employee, but no action was taken and the employee was dismissed after sending details of the flaw to a rival company.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was the specific security loophole that was not plugged in the SingHealth data breach?",
      "answer": "The specific security loophole that was not plugged in the SingHealth data breach was flagged by an IHiS employee, but no action was taken and the employee was dismissed after sending details of the flaw to a rival company.",
      "context": "2018 SingHealth data breach\n\n==Introduction==\nThe 2018 SingHealth data breach was a data breach incident initiated by unidentified state actors, which happened between 27 June and 4 July 2018. During that period, personal particulars of 1.5 million SingHealth patients and records of outpatient dispensed medicines belonging to 160,000 patients were stolen. Names, National Registration Identity Card (NRIC) numbers, addresses, dates of birth, race, and gender of patients who visited specialist outpatient clinics and polyclinics between 1 May 2015 and 4 July 2018 were maliciously accessed and copied. Information relating to patient diagnosis, test results and doctors' notes were unaffected. Information on Prime Minister Lee Hsien Loong was specifically targeted.\n\n== Discovery ==\nThe database administrators for the Integrated Health Information Systems (IHIS), the public healthcare IT provider, detected unusual activity on one of SingHealth's IT databases on 4 July, and implemented precautions against further intrusions. Network traffic monitoring was enhanced; additional malicious activity was detected after 4 July, but did not result in the theft of any data. Having ascertained that a cyberattack occurred, administrators notified the ministries and brought in the Cyber Security Agency (CSA) on 10 July to carry out forensic investigations. The agency determined that perpetrators gained privileged access to the IT network by compromising a front-end workstation, and obtained login credentials to access the database, while hiding their digital footprints. The attack was made public in a statement released by the Ministry of Communications and Information and Ministry of Health on 20 July. The ten-day delay between the discovery of the attack and the public announcement was attributed to time needed to fortify the IT systems, conduct preliminary investigations, identify affected patients and prepare the logistics of the announcement. Text messages were subsequently sent to patients whose data was affected.\n\n== Investigation ==\nOn 6 August 2018 in Parliament, S. Iswaran, Minister for Communications and Information, attributed the attack to sophisticated state-linked actors who wrote customized malware to circumvent SingHealth's antivirus and security tools. Iswaran did not name any state in the interest of national security.A Committee of Inquiry was convened on 24 July 2018 to investigate the causes of the attack and identify measures to help prevent similar attacks. The four-member committee is chaired by former chief district judge Richard Magnus, and comprise leaders of a cyber-security firm, a healthcare technology firm and the National Trades Union Congress respectively. The committee called on the Attorney-General's Chambers to lead evidence, and the Attorney-General's Chambers appointed the Cyber Security Agency to lead the investigations with the support of the Criminal Investigation Department. The committee held closed-door and public hearings from 28 August, with another tranche of hearings from 21 September to 5 October. In addition, the Personal Data Protection Commission investigated into possible breaches of the Personal Data Protection Act in protecting data and hence determine possible action.\n\n== Committee of Inquiry hearings ==\nThe Committee of Inquiry hearings began on 21 September 2018. In the first hearing, Solicitor-General Kwek Mean Luck said that a series of staff missteps and gaps in the system contributed to the breach. Some examples mentioned are the EMR system, which was in place since 1999. In addition, it was mentioned that the cyberattacker behind the incident started infecting workstations as early as August 2017 using a hacking tool. The version of Microsoft Outlook being used did not have a patch that prevents attacks by that hacking tool. Between December 2017 and May 2018, the cyberattacker moved sideways and gained access to a workstation to infect other computers with malware. Other inadequacies identified include not being able to identify multiple failed attempts to log into the system, which was done with non-existent accounts or accounts that do not have much privileges in the system. Eventually, the cyberattacker successfully gained entry through a coding vulnerability on 26 June, and hence sent SQL queries until 4 July when it was stopped by an administrator. In addition, there were three periods where staff failed to respond or responded after a few days when knowledge of the cyberattack was first known. On the same day, two staff members said that while a framework was in place to report cyberattacks, there is insufficient training on what to do, hence it was unclear to staff about what actions should be taken.At the next hearing on 24 September, it was revealed that Prime Minister Lee Hsien Loong's personal data and outpatient records along with two other unnamed people were searched by hackers who infiltrated into the servers using NRIC numbers. The rest of the queries were generally done on patient demographic data, like one that involved the first 20,000 records of such data from Singapore General Hospital. An assistant lead analyst who detected unusual activity investigated further even through that was not his scope, and sent alerts to different divisions to find the staff who can make sense of those queries. The analyst's supervisor told the analyst to continue monitoring the situation and that he assumed there was no medical data until being informed that there was such a leak. As the analyst informed a reporting officer, there was no point in reporting the query himself, asking the analyst to follow up on the queries. Details about reporting procedures and containment measures were mentioned.On the third day, a cybersecurity employee at Integrated Health Information Systems (IHiS), who was on holiday when the incident happened, did not follow up after having read the emails as it was thought to have been collection of data from workstations for investigation. In addition, only one computer at IHiS was used to carry out forensic examinations, resulting in delays diagnosing the issue. This is confirmed by the fourth day of the trial, where failings of judgement and organisational processes are exposed. For instance, meetings with the security management department were not conducted regularly, and no framework was created to set out appropriate responses to cybersecurity risks or to appoint covering officers if any staff go on leave. A clarification on processes was provided, where a standard operating procedure to escalate incidents was approved by the management in March 2018. It was also revealed the same day that staffers took six more days after 4 July to confirm the data breach as an IHiS employee mistakenly informed colleagues that no data was stolen, only confirmed after further tests are run by the superior finding that data was stolen. The queries were later recreated.It was also revealed on the fifth day that a server exploited by hackers did not receive security updates in more than a year since May 2017 due to the WannaCry ransomware attacks, compared to the normal duration where patches were done several times a month. Besides that, the computer's anti-virus software was too old and must be reinstalled. The manager was not supposed to manage the server on paper, but in practice, was given the role in 2014 as the server was located at the National Cancer Centre Singapore, thereby being convenient for staff members to approach him in case help was needed. Once the counterparts resigned, there was no one at IHiS present to take over managing the server. In fact, the IHiS director was not aware that the server was not managed by the firm in practice, only giving a directive in 2014 that IHiS will not manage research servers. The next day, a security loophole that was not plugged was scruntised. Even though the loophole was flagged by an IHiS employee, there was no action taken. In fact, the employee was dismissed after sending details of the flaw to a rival company.Towards the end of the second tranche of hearings on 5 October 2018, it was revealed a second attempt to hack into the servers was done on 19 July via another server as the attackers are skilled. This was stopped immediately as soon as it began. In addition, malware used was customised for the system and evaded detection from top anti-virus software. A tool called PowerShell was used in the process, being disabled on 13 July. Meanwhile, IHiS stepped up security with changing passwords, removing compromised accounts and rebooting servers.The third tranche of hearings started on 31 October 2018. Evidence was shown that managers were reluctant to report the incidents as that would mean an increased amount of work, thereby creating a bottleneck. Meanwhile, the chief information officer told the team to escalate the incident, saying a bottleneck is not acceptable, adding that there was no written protocol on how to report SingHealth-related cybersecurity incidents should IHiS staff discover any incident. Another pointed out that annual cybersecurity exercises are mandated for critical information infrastructure (CII) operators, so staff should be able to identify advanced persistent threats (APTs). However, these tests were for classroom settings and may not necessarily apply to the SingHealth case, thus defeating the purpose of these exercises if situational awareness was not there. There were also plans for secure Internet browsing in the healthcare sector by 2018, but it had to be delayed by a year due to technical issues.The following day, a 2016 audit that found systemic weaknesses in the network link between Singapore General Hospital and cloud-based systems was brought up, showing more inadequacies in the systems managed by IHiS. The incident was reported by the operations team as \"plugged\" to the management without anyone verifying that works to fix these vulnerabilities were done. The Cyber Security Agency also found similar vulnerabilities in its investigation. Due to this, there will be \"three lines of defence\", where compliance checks are performed by the operations team, technology team and internal audit team, and training will be stepped up in IHiS so that early detection of attacks are ensured. As pointed out the next day that even if the weaknesses were found, they may not be fixed as quickly as expected as public healthcare institutions operate around the clock resulting in little downtime.Later in the hearings, SingHealth executives said that they will enhance cyber safety awareness for all employees, as well as roll out new systems to capture patients' data rigorously. It will also allow patients to update their particulars instead of only doing it over the counter. More townhalls will be held to update employees about the latest cyber threats, with log-in messages strengthened to hone the importance of data protection. Storytelling formats will also be used to explain these concepts. More cyber security exercises simulating data breaches were called for in a subsequent hearing, with these allowing professionals to be more familiar with what to do in case a similar incident happens again. In addition, the expert recommended all data within the system to be encrypted including inactive data. As full encryption would be unfeasible due to operational concerns, personal data could be anonymised instead with 2-factor authentication to de-anonymise it. That same hearing, it was updated that many of the written submissions were found to be useful.Towards the final hearings, a former National Security Agency director suggested having the Government and industry partners work together and share information to learn and update each other about new threats that pop up. That is so as current protection measures are insufficient against ever evolving vulnerabilities. In the same hearing, the Ministry of Health's chief data advisor pointed out that Internet separation resulted in longer wait times for patients, declined productivity, increased staff fatigue and new cyber risks, especially when anti-virus software updates are done only on some computers instead of all within the network. Hence, to continue ISS, these factors would need to be considered. The next day, a security expert recommended having a centralised incident management and tracking system that logs all incidents that occur during a breach to reduce miscommunication, which is one of the causes for delayed reporting. In addition, the usage of different chat platforms meant that crucial details about the attack were lost and hence there was not many linkages to the incident.On the final day, Cyber Security Agency chief David Koh suggested changing the way IT staff in the healthcare sector report incidents so that faster response can be ensured during a cyberattack, along with a review of the sector's IT processes and staff training carried out. It was also suggested that cybersecurity processes be considered as a key instead of it merely existing as an afterthought. The hearings thus concluded on 14 November 2018.The closing submissions were held on 30 November 2018. Proposals to improve cybersecurity were shared, including the \"assume breach\" mindset in organisations thus taking necessary measures, having the right people and processes to complement those measures. It was also pointed out that administrator passwords are supposed to be 15 characters long, but one had an problematic password of eight characters which was unchanged since 2012. Lastly, even if measures were put in place to slow down cyberattacks, it is important to note that the attack was done via an advanced persistent threat (APT). Subsequently, the report was submitted to S. Iswaran on 31 December 2018 with the public version released on 10 January 2019.\n\n== Release of report ==\nOn 10 January 2019, the Committee of Inquiry released a report on the SingHealth breach. The report found that staff are inadequately trained in cybersecurity, thus they are unable to stop the attacks. The key staff did not take immediate action to stop the attacks fearing pressure. To make things worse, vulnerabilities in the network and systems are not patched quickly, coupled with the fact that the attackers are well-skilled. As a result, the attackers found it easy to break in. The report did point that if the staff had been adequately trained and vulnerabilities fixed quickly, this attack could have been averted. The report also found that this is the work of an Advanced Persistent Threat group.In the same report, the Committee of Inquiry made 16 recommendations to boost cybersecurity, separated into priority and additional recommendations. They are:\n\nPriority:\nAdopting an enhanced security structure and readiness by IHiS and public health institutions\nReview online security processes to assess ability to defend and respond to cyberattacks\nImproving staff awareness on cyberattacks\nPerform enhanced security checks, especially on critical information infrastructure (CII) systems\nSubject privileged administrator accounts to tighter control and greater monitoring\nImprove incident response processes\nForge partnerships between industries and the Government to achieve higher cybersecurity\nAdditional:\nIT security risk assessments and audits must be treated seriously and carried out regularly\nEnhanced safeguards must be put in place to protect confidentiality of electronic medical records\nImprove domain security against attacks\nImplement a robust patch management process\nImplement a software upgrade policy with a focus on cybersecurity\nImplement an Internet access strategy that limits exposure to external threats\nClearer guidelines on when and how to respond to cybersecurity incidents\nImprove competence of computer security incident response personnel\nConsider a post-breach independent forensic review of the networkOn 15 January 2019, S. Iswaran, Minister for Communications and Information announced in Parliament that the Government accepted the recommendations of the report and will fully adopt them. It has also sped up the implementation of the Cybersecurity Act to increase security of CIIs. Separately, Gan Kim Yong, Minister for Health announced that changes to enhance governance and operations in Singapore's healthcare institutions and IHiS will be made. The dual role of Ministry of Health's chief information security officer (MOH CISO) and the director of cybersecurity governance at IHiS will be separated, where the MOH CISO has a dedicated office and reports to the Permanent Secretary of MOH, while IHiS will have a separate director in charge of cybersecurity governance, with changes at the cluster level. This will help boost operations and governance of the IT systems. In addition, MOH will establish an enhanced \"Three Lines of Defence\" system for public healthcare, and pilot a \"Virtual Browser\" for the National University Health System. All public healthcare staff will remain on Internet Surfing Separation, which was implemented immediately after the cyberattack, and the mandatory contribution of patient medical data to the National Electronic Health Record (NEHR) system will continue to be deferred.\n\n== Aftermath ==\nFollowing the cyberattack, Internet access was temporarily removed from all public healthcare IT terminals with access to the healthcare network, and additional system monitoring and controls were implemented.The attack led to a two-week pause in Singapore's Smart Nation initiatives and a review of the public sector's cyber-security policies during that time. The review resulted in implementation of additional security measures, and urged public sector administrators to remove Internet access where possible and to use secure Information Exchange Gateways otherwise. The attack also renewed concerns among some healthcare practitioners regarding ongoing efforts to centralize electronic patient data in Singapore. Plans to pass laws in late 2018 making it compulsory for healthcare providers to submit data regarding patient visits and diagnoses to the National Electronic Health Record system were postponed. In addition, the Ministry of Health announced on 6 August 2018 that the National Electrical Health Record (NEHR) will be reviewed by an independent group made up of Cyber Security Agency and PricewaterhouseCoopers before asking doctors to submit all records to the NEHR, even though it was not affected by the cyberattack.On 24 July 2018, the Monetary Authority of Singapore told banks in Singapore to tighten customer verification processes in case leaked data was used to impersonate customers, with additional information requested. Banks are also told to conduct risk assessments and mitigate risks from misuse of information.The Integrated Health Information Systems (IHiS) has since strengthened public health systems against data breaches. All suspicious IT incidents will have to be reported within 24 hours. 18 other measures are also put in place, including two-factor authentication for all administrators, proactive threat hunting and intelligence, allowing only computers with latest security updates on hospital networks, and a new database activity monitoring. Studies are done to keep Internet Separation Scheme (ISS) permanent in some parts of the healthcare system with a virtual browser being piloted as an alternative.After the report was released, on 14 January 2019, Integrated Health Information Systems (IHiS) dismissed two employees and demoted one for being negligent in handling and misunderstanding the attack respectively, with financial penalties imposed on two middle management supervisors, and five members of the senior management including CEO Bruce Liang. Three employees were commended by IHiS for handling the incident diligently even when not part of their job scope. IHiS has since fast-tracked a suite of 18 measures for enhancing cybersecurity. The next day, the Personal Data Protection Commission fined IHiS $750,000 and SingHealth $250,000 for not doing enough to safeguard personal data under the Personal Data Protection Act, making it the largest fine imposed for data breaches.Subsequently, on 6 March 2019, cybersecurity company Symantec identified a state-sponsored group, known as Whitefly, behind the cyberattack. Although the country is not identified, that group has been found to be behind several related cyberattacks against Singapore-based entities since 2017."
    }
  },
  {
    "instruction": "Write an answer to the following question: How do cryptographic books approach the topic from a theoretical perspective?",
    "context": "",
    "output": "Cryptographic books often cover theoretical foundations, such as in Oded Goldreich's Foundations of Cryptography and Jonathan Katz and Yehuda Lindell's Introduction to Modern Cryptography. These books present cryptographic concepts and principles in a detailed and comprehensive manner, making them indispensable for those interested in the theory of cryptography.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do cryptographic books approach the topic from a theoretical perspective?",
      "answer": "Cryptographic books often cover theoretical foundations, such as in Oded Goldreich's Foundations of Cryptography and Jonathan Katz and Yehuda Lindell's Introduction to Modern Cryptography. These books present cryptographic concepts and principles in a detailed and comprehensive manner, making them indispensable for those interested in the theory of cryptography."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the role of CPU usage in BlackNurse attacks?",
    "context": "",
    "output": "CPU usage is a crucial factor in BlackNurse attacks because high CPU usage caused by processing ICMP packets with Type 3 Code 3 prevents firewalls from processing more requests, making them vulnerable to the attack.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of CPU usage in BlackNurse attacks?",
      "answer": "CPU usage is a crucial factor in BlackNurse attacks because high CPU usage caused by processing ICMP packets with Type 3 Code 3 prevents firewalls from processing more requests, making them vulnerable to the attack."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is a common mistake in using salts for password storage?",
    "context": "",
    "output": "A common mistake is reusing the same salt for all passwords, which can make it easier for attackers to use precomputed tables to crack them.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is a common mistake in using salts for password storage?",
      "answer": "A common mistake is reusing the same salt for all passwords, which can make it easier for attackers to use precomputed tables to crack them."
    }
  },
  {
    "instruction": "Write an answer to the following question: How do APT actors use social engineering and spear phishing in their attacks?",
    "context": "",
    "output": "APT actors may use social engineering and spear phishing to attempt to gain a foothold in the target environment. This may involve sending targeted emails with malicious attachments or links to the victim.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do APT actors use social engineering and spear phishing in their attacks?",
      "answer": "APT actors may use social engineering and spear phishing to attempt to gain a foothold in the target environment. This may involve sending targeted emails with malicious attachments or links to the victim."
    }
  },
  {
    "instruction": "Write an answer to the following question: How can ssh-agents be forwarded and what are the implications for security?",
    "context": "",
    "output": "Ssh-agents can be forwarded onto a server, making their keys available for other connections. On the local system, it is important that the root user is trustworthy, as the root user can read the key file directly. On the remote system, if the ssh-agent connection is forwarded, it is also important that the root user on the other end is trustworthy, as they can access the agent socket on the remote.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can ssh-agents be forwarded and what are the implications for security?",
      "answer": "Ssh-agents can be forwarded onto a server, making their keys available for other connections. On the local system, it is important that the root user is trustworthy, as the root user can read the key file directly. On the remote system, if the ssh-agent connection is forwarded, it is also important that the root user on the other end is trustworthy, as they can access the agent socket on the remote."
    }
  },
  {
    "instruction": "Gumblar\n\n==Introduction==\nGumblar is a malicious JavaScript trojan horse file that redirects a user's Google searches, and then installs rogue security software.  Also known as Troj/JSRedir-R this botnet first appeared in 2009. \n\n\n\n== Infection ==\n\n\n*** Windows Personal Computers ***\nGumblar.X infections were widely seen on systems running newer MacOS operating systems.  Visitors to an infected site will be redirected to an alternative site containing further malware. Initially, this alternative site was gumblar.cn, but it has since switched to a variety of domains. The site sends the visitor an infected PDF that is opened by the visitor's browser or Acrobat Reader. The PDF will then exploit a known vulnerability in Acrobat to gain access to the user's computer. Newer variations of Gumblar redirect users to sites running fake anti-virus software.\nThe virus will find FTP clients such as FileZilla and Dreamweaver and download the clients' stored passwords. Gumblar also enables promiscuous mode on the network card, allowing it to sniff local network traffic for FTP details. It is one of the first viruses to incorporate an automated packet analyzer.\n\n\n*** Servers ***\nUsing passwords obtained from site admins, the host site will access a website via FTP and infect that website. It will download large portions of the website and inject malicious code into the website's files before uploading the files back onto the server. The code is inserted in any file that contains a <body> tag, such as HTML, PHP, JavaScript, ASP and ASPx files. The inserted PHP code contains base64-encoded JavaScript that will infect computers that execute the code. In addition, some pages may have inline frames inserted into them. Typically, iframe code contains hidden links to malicious websites.\nThe virus will also modify .htaccess and HOSTS files, and create images.php files in directories named 'images'. The infection is not a server-wide exploit. It will only infect sites on the server that it has passwords to.\n\n== Gumblar variants ==\nDifferent companies use different names for Gumblar and variants. Initially, the malware was connecting to gumblar.cn domain but this server was shut down in May 2009. However, many badware variants have emerged after that and they connect to other malicious servers via iframe code.\nGumblar resurfaced in January 2010, stealing FTP usernames and passwords and infecting HTML, PHP and JavaScript files on webservers to help spread itself. This time it used multiple domains, making it harder to detect/stop.\n\nAnswer this question based on the above context: How does Gumblar use iframe code?",
    "context": "",
    "output": "Gumblar uses iframe code to connect to other malicious servers and infect computers that execute the code.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does Gumblar use iframe code?",
      "answer": "Gumblar uses iframe code to connect to other malicious servers and infect computers that execute the code.",
      "context": "Gumblar\n\n==Introduction==\nGumblar is a malicious JavaScript trojan horse file that redirects a user's Google searches, and then installs rogue security software.  Also known as Troj/JSRedir-R this botnet first appeared in 2009. \n\n\n\n== Infection ==\n\n\n*** Windows Personal Computers ***\nGumblar.X infections were widely seen on systems running newer MacOS operating systems.  Visitors to an infected site will be redirected to an alternative site containing further malware. Initially, this alternative site was gumblar.cn, but it has since switched to a variety of domains. The site sends the visitor an infected PDF that is opened by the visitor's browser or Acrobat Reader. The PDF will then exploit a known vulnerability in Acrobat to gain access to the user's computer. Newer variations of Gumblar redirect users to sites running fake anti-virus software.\nThe virus will find FTP clients such as FileZilla and Dreamweaver and download the clients' stored passwords. Gumblar also enables promiscuous mode on the network card, allowing it to sniff local network traffic for FTP details. It is one of the first viruses to incorporate an automated packet analyzer.\n\n\n*** Servers ***\nUsing passwords obtained from site admins, the host site will access a website via FTP and infect that website. It will download large portions of the website and inject malicious code into the website's files before uploading the files back onto the server. The code is inserted in any file that contains a <body> tag, such as HTML, PHP, JavaScript, ASP and ASPx files. The inserted PHP code contains base64-encoded JavaScript that will infect computers that execute the code. In addition, some pages may have inline frames inserted into them. Typically, iframe code contains hidden links to malicious websites.\nThe virus will also modify .htaccess and HOSTS files, and create images.php files in directories named 'images'. The infection is not a server-wide exploit. It will only infect sites on the server that it has passwords to.\n\n== Gumblar variants ==\nDifferent companies use different names for Gumblar and variants. Initially, the malware was connecting to gumblar.cn domain but this server was shut down in May 2009. However, many badware variants have emerged after that and they connect to other malicious servers via iframe code.\nGumblar resurfaced in January 2010, stealing FTP usernames and passwords and infecting HTML, PHP and JavaScript files on webservers to help spread itself. This time it used multiple domains, making it harder to detect/stop."
    }
  },
  {
    "instruction": "Context: Browser security\n\n==Introduction==\nBrowser security is the application of Internet security to web browsers in order to protect networked data and computer systems from breaches of privacy or malware. Security exploits of browsers often use JavaScript, sometimes with cross-site scripting (XSS) with a secondary payload using Adobe Flash. Security exploits can also take advantage of vulnerabilities (security holes) that are commonly exploited in all browsers (including Mozilla Firefox, Google Chrome, Opera, Microsoft Internet Explorer, and Safari).\n\n== Security ==\nWeb browsers can be breached in one or more of the following ways:\n\nOperating system is breached and malware is reading/modifying the browser memory space in privilege mode\nOperating system has a malware running as a background process, which is reading/modifying the browser memory space in privileged mode\nMain browser executable can be hacked\nBrowser components may be hacked\nBrowser plugins can be hacked\nBrowser network communications could be intercepted outside the machineThe browser may not be aware of any of the breaches above and may show user a safe connection is made.\nWhenever a browser communicates with a website, the website, as part of that communication, collects some information about the browser (in order to process the formatting of the page to be delivered, if nothing else).  If malicious code has been inserted into the website's content, or in a worst-case scenario, if that website has been specifically designed to host malicious code, then vulnerabilities specific to a particular browser can allow this malicious code to run processes within the browser application in unintended ways (and remember, one of the bits of information that a website collects from a browser communication is the browser's identity- allowing specific vulnerabilities to be exploited). Once an attacker is able to run processes on the visitor's machine, then exploiting known security vulnerabilities can allow the attacker to gain privileged access (if the browser isn't already running with privileged access) to the \"infected\" system in order to perform an even greater variety of malicious processes and activities on the machine or even the victim's whole network.Breaches of web browser security are usually for the purpose of bypassing protections to display pop-up advertising collecting personally identifiable information (PII) for either Internet marketing or identity theft, website tracking or web analytics about a user against their will using tools such as web bugs, Clickjacking, Likejacking (where Facebook's like button is targeted), HTTP cookies, zombie cookies or Flash cookies (Local Shared Objects or LSOs); installing adware, viruses, spyware such as Trojan horses (to gain access to users' personal computers via cracking) or other malware including online banking theft using man-in-the-browser attacks.\nIn depth study of vulnerabilities in Chromium web-browser indicates that, Improper Input Validation (CWE-20) and Improper Access Control (CWE-284) are the most occurring root causes for security vulnerabilities. Furthermore, among vulnerabilities examined at the time of this study, 106 vulnerabilities occurred in Chromium because of reusing or importing vulnerable versions of third party libraries.\nVulnerabilities in the web browser software itself can be minimized by keeping browser software updated, but will not be sufficient if the underlying operating system is compromised, for example, by a rootkit.  Some subcomponents of browsers such as scripting, add-ons, and cookies are particularly vulnerable (\"the confused deputy problem\") and also need to be addressed.\nFollowing the principle of defence in depth, a fully patched and correctly configured browser may not be sufficient to ensure that browser-related security issues cannot occur. For example, a rootkit can capture keystrokes while someone logs into a banking website, or carry out a man-in-the-middle attack by modifying network traffic to and from a web browser. DNS hijacking or DNS spoofing may be used to return false positives for mistyped website names, or to subvert search results for popular search engines. Malware such as RSPlug simply modifies a system's configuration to point at rogue DNS servers.\nBrowsers can use more secure methods of network communication to help prevent some of these attacks:\n\nDNS: DNSSec and DNSCrypt, for example with non-default DNS servers such as Google Public DNS or OpenDNS.\nHTTP: HTTP Secure and SPDY with digitally signed public key certificates or Extended Validation Certificates.Perimeter defenses, typically through firewalls and the use of filtering proxy servers that block malicious websites and perform antivirus scans of any file downloads, are commonly implemented as a best practice in large organizations to block malicious network traffic before it reaches a browser.\nThe topic of browser security has grown to the point of spawning the creation of entire organizations, such as The Browser Exploitation Framework Project,  creating platforms to collect tools to breach browser security, ostensibly in order to test browsers and network systems for vulnerabilities.\n\n\n*** Plugins and extensions ***\nAlthough not part of the browser per se, browser plugins and extensions extend the attack surface, exposing vulnerabilities in Adobe Flash Player, Adobe (Acrobat) Reader, Java plugin, and ActiveX that are commonly exploited. Researchers have extensively studied the security architecture of various web-browsers in particular those relying on plug-and-play designs. This study has identified 16 common vulnerability types, and 19 potential mitigations. Malware may also be implemented as a browser extension, such as a browser helper object in the case of Internet Explorer. In various other exploits websites which were designed to look authentic and included rogue 'update Adobe Flash' popups designed as visual cues to download malware payloads in their place. Some browsers like Google Chrome and Mozilla Firefox can block\u2014or warn users of\u2014insecure plugins.\n\n\n*** Adobe Flash ***\n\nAn August 2009 study by the Social Science Research Network found that 50% of websites using Flash were also employing Flash cookies, yet privacy policies rarely disclosed them, and user controls for privacy preferences were lacking. Most browsers' cache and history delete functions do not affect Flash Player's writing Local Shared Objects to its own cache, and the user community is much less aware of the existence and function of Flash cookies than HTTP cookies. Thus, users having deleted HTTP cookies and purged browser history files and caches may believe that they have purged all tracking data from their computers while in fact Flash browsing history remains. As well as manual removal, the BetterPrivacy add-on for Firefox can remove Flash cookies. Adblock Plus can be used to filter out specific threats and Flashblock can be used to give an option before allowing content on otherwise trusted sites.Charlie Miller recommended \"not to install Flash\" at the computer security conference CanSecWest. Several other security experts also recommend to either not install Adobe Flash Player or to block it.\n\n== Password security model ==\nThe contents of a web page are arbitrary and controlled by the entity owning the domain named displayed in the address bar. If HTTPS is used, then encryption is used to secure against attackers with access to the network from changing the page contents en route. When presented with a password field on a web page, a user is supposed to look at the address bar to determine whether the domain name in the address bar is the correct place to send the password. For example, for Google's single sign-on system (used on e.g. youtube.com), the user should always check that the address bar says \"https://accounts.google.com\" before inputting their password.\nAn un-compromised browser guarantees that the address bar is correct. This guarantee is one reason why browsers will generally display a warning when entering fullscreen mode, on top of where the address bar would normally be, so that a fullscreen website cannot make a fake browser user interface with a fake address bar.\n\n== Hardware browser ==\nThere have been attempts to market hardware-based browsers running from non-writable, read-only file systems. Data cannot be stored on the device and the media cannot be overwritten, presenting a clean executable each time it loads. The first such device was the ZeusGard Secure Hardware Browser, released in late 2013. The ZeusGard website has not been functional since mid-2016. Another device, the iCloak\u00ae Stik from the iCloak website provides a complete Live OS which completely replaces the computer's entire operating system and offers two web browsers from the read-only system. With iCloak they provide the Tor browser for Anonymous browsing as well as a regular Firefox browser for non-anonymous browsing. Any non-secured web traffic (not using https, for example), could still be subject to man-in-the-middle alteration or other network traffic-based manipulations.\n\n== LiveCD ==\nLiveCDs, which run an operating system from a non-writable source, typically come with Web browsers as part of their default image. If the original LiveCD image is free of malware, all of the software used, including the Web browser, will load free of malware every time the LiveCD image is booted.\n\n== Browser hardening ==\nBrowsing the Internet as a least-privilege user account (i.e. without administrator privileges) limits the ability of a security exploit in a web browser from compromising the whole operating system.Internet Explorer 4 and later allows the blacklisting and whitelisting of ActiveX controls, add-ons and browser extensions in various ways.\nInternet Explorer 7 added \"protected mode\", a technology that hardens the browser through the application of a security sandboxing feature of Windows Vista called Mandatory Integrity Control.Google Chrome provides a sandbox to limit web page access to the operating system.Suspected malware sites reported to Google, and confirmed by Google, are flagged as hosting malware in certain browsers.There are third-party extensions and plugins available to harden even the latest browsers, and some for older browsers and operating systems. Whitelist-based software such as NoScript can block JavaScript and Adobe Flash which is used for most attacks on privacy, allowing users to choose only sites they know are safe - AdBlock Plus also uses whitelist ad filtering rules subscriptions, though both the software itself and the filtering list maintainers have come under controversy for by-default allowing some sites to pass the pre-set filters. The US-CERT recommends to block Flash using NoScript.\n\n== Fuzzing ==\nModern web browsers undergo extensive fuzzing to uncover vulnerabilities. The Chromium code of Google Chrome is continuously fuzzed by the Chrome Security Team with 15,000 cores. For Microsoft Edge and Internet Explorer, Microsoft performed fuzzed testing with 670 machine-years during product development, generating more than 400 billion DOM manipulations from 1 billion HTML files.\n\n== Best practice ==\nLoad clean software: Boot from a known clean OS that has a known clean Web browser\nAdopt adequate countermeasures against the Cross-Origin Resource Sharing (CORS) vulnerability (example patches are provided for WebKit-based browsers)\nPrevent attacks via third-party software: Use a hardened Web browser or add-on-free-browsing mode\nPrevent DNS manipulation: Use trusted and secure DNS\nAvoid website-based exploits: Employ link-checking browser plug-ins commonly found in internet security software\nAvoid malicious content: Employ perimeter defenses and anti-malware software\nAnswer this question: What is the role of JavaScript and Adobe Flash in browser security breaches?",
    "context": "",
    "output": "JavaScript and Adobe Flash are commonly used in browser security breaches. JavaScript can be used to exploit vulnerabilities in web browsers, while Adobe Flash can be used to deliver secondary payloads in cross-site scripting (XSS) attacks.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of JavaScript and Adobe Flash in browser security breaches?",
      "answer": "JavaScript and Adobe Flash are commonly used in browser security breaches. JavaScript can be used to exploit vulnerabilities in web browsers, while Adobe Flash can be used to deliver secondary payloads in cross-site scripting (XSS) attacks.",
      "context": "Browser security\n\n==Introduction==\nBrowser security is the application of Internet security to web browsers in order to protect networked data and computer systems from breaches of privacy or malware. Security exploits of browsers often use JavaScript, sometimes with cross-site scripting (XSS) with a secondary payload using Adobe Flash. Security exploits can also take advantage of vulnerabilities (security holes) that are commonly exploited in all browsers (including Mozilla Firefox, Google Chrome, Opera, Microsoft Internet Explorer, and Safari).\n\n== Security ==\nWeb browsers can be breached in one or more of the following ways:\n\nOperating system is breached and malware is reading/modifying the browser memory space in privilege mode\nOperating system has a malware running as a background process, which is reading/modifying the browser memory space in privileged mode\nMain browser executable can be hacked\nBrowser components may be hacked\nBrowser plugins can be hacked\nBrowser network communications could be intercepted outside the machineThe browser may not be aware of any of the breaches above and may show user a safe connection is made.\nWhenever a browser communicates with a website, the website, as part of that communication, collects some information about the browser (in order to process the formatting of the page to be delivered, if nothing else).  If malicious code has been inserted into the website's content, or in a worst-case scenario, if that website has been specifically designed to host malicious code, then vulnerabilities specific to a particular browser can allow this malicious code to run processes within the browser application in unintended ways (and remember, one of the bits of information that a website collects from a browser communication is the browser's identity- allowing specific vulnerabilities to be exploited). Once an attacker is able to run processes on the visitor's machine, then exploiting known security vulnerabilities can allow the attacker to gain privileged access (if the browser isn't already running with privileged access) to the \"infected\" system in order to perform an even greater variety of malicious processes and activities on the machine or even the victim's whole network.Breaches of web browser security are usually for the purpose of bypassing protections to display pop-up advertising collecting personally identifiable information (PII) for either Internet marketing or identity theft, website tracking or web analytics about a user against their will using tools such as web bugs, Clickjacking, Likejacking (where Facebook's like button is targeted), HTTP cookies, zombie cookies or Flash cookies (Local Shared Objects or LSOs); installing adware, viruses, spyware such as Trojan horses (to gain access to users' personal computers via cracking) or other malware including online banking theft using man-in-the-browser attacks.\nIn depth study of vulnerabilities in Chromium web-browser indicates that, Improper Input Validation (CWE-20) and Improper Access Control (CWE-284) are the most occurring root causes for security vulnerabilities. Furthermore, among vulnerabilities examined at the time of this study, 106 vulnerabilities occurred in Chromium because of reusing or importing vulnerable versions of third party libraries.\nVulnerabilities in the web browser software itself can be minimized by keeping browser software updated, but will not be sufficient if the underlying operating system is compromised, for example, by a rootkit.  Some subcomponents of browsers such as scripting, add-ons, and cookies are particularly vulnerable (\"the confused deputy problem\") and also need to be addressed.\nFollowing the principle of defence in depth, a fully patched and correctly configured browser may not be sufficient to ensure that browser-related security issues cannot occur. For example, a rootkit can capture keystrokes while someone logs into a banking website, or carry out a man-in-the-middle attack by modifying network traffic to and from a web browser. DNS hijacking or DNS spoofing may be used to return false positives for mistyped website names, or to subvert search results for popular search engines. Malware such as RSPlug simply modifies a system's configuration to point at rogue DNS servers.\nBrowsers can use more secure methods of network communication to help prevent some of these attacks:\n\nDNS: DNSSec and DNSCrypt, for example with non-default DNS servers such as Google Public DNS or OpenDNS.\nHTTP: HTTP Secure and SPDY with digitally signed public key certificates or Extended Validation Certificates.Perimeter defenses, typically through firewalls and the use of filtering proxy servers that block malicious websites and perform antivirus scans of any file downloads, are commonly implemented as a best practice in large organizations to block malicious network traffic before it reaches a browser.\nThe topic of browser security has grown to the point of spawning the creation of entire organizations, such as The Browser Exploitation Framework Project,  creating platforms to collect tools to breach browser security, ostensibly in order to test browsers and network systems for vulnerabilities.\n\n\n*** Plugins and extensions ***\nAlthough not part of the browser per se, browser plugins and extensions extend the attack surface, exposing vulnerabilities in Adobe Flash Player, Adobe (Acrobat) Reader, Java plugin, and ActiveX that are commonly exploited. Researchers have extensively studied the security architecture of various web-browsers in particular those relying on plug-and-play designs. This study has identified 16 common vulnerability types, and 19 potential mitigations. Malware may also be implemented as a browser extension, such as a browser helper object in the case of Internet Explorer. In various other exploits websites which were designed to look authentic and included rogue 'update Adobe Flash' popups designed as visual cues to download malware payloads in their place. Some browsers like Google Chrome and Mozilla Firefox can block\u2014or warn users of\u2014insecure plugins.\n\n\n*** Adobe Flash ***\n\nAn August 2009 study by the Social Science Research Network found that 50% of websites using Flash were also employing Flash cookies, yet privacy policies rarely disclosed them, and user controls for privacy preferences were lacking. Most browsers' cache and history delete functions do not affect Flash Player's writing Local Shared Objects to its own cache, and the user community is much less aware of the existence and function of Flash cookies than HTTP cookies. Thus, users having deleted HTTP cookies and purged browser history files and caches may believe that they have purged all tracking data from their computers while in fact Flash browsing history remains. As well as manual removal, the BetterPrivacy add-on for Firefox can remove Flash cookies. Adblock Plus can be used to filter out specific threats and Flashblock can be used to give an option before allowing content on otherwise trusted sites.Charlie Miller recommended \"not to install Flash\" at the computer security conference CanSecWest. Several other security experts also recommend to either not install Adobe Flash Player or to block it.\n\n== Password security model ==\nThe contents of a web page are arbitrary and controlled by the entity owning the domain named displayed in the address bar. If HTTPS is used, then encryption is used to secure against attackers with access to the network from changing the page contents en route. When presented with a password field on a web page, a user is supposed to look at the address bar to determine whether the domain name in the address bar is the correct place to send the password. For example, for Google's single sign-on system (used on e.g. youtube.com), the user should always check that the address bar says \"https://accounts.google.com\" before inputting their password.\nAn un-compromised browser guarantees that the address bar is correct. This guarantee is one reason why browsers will generally display a warning when entering fullscreen mode, on top of where the address bar would normally be, so that a fullscreen website cannot make a fake browser user interface with a fake address bar.\n\n== Hardware browser ==\nThere have been attempts to market hardware-based browsers running from non-writable, read-only file systems. Data cannot be stored on the device and the media cannot be overwritten, presenting a clean executable each time it loads. The first such device was the ZeusGard Secure Hardware Browser, released in late 2013. The ZeusGard website has not been functional since mid-2016. Another device, the iCloak\u00ae Stik from the iCloak website provides a complete Live OS which completely replaces the computer's entire operating system and offers two web browsers from the read-only system. With iCloak they provide the Tor browser for Anonymous browsing as well as a regular Firefox browser for non-anonymous browsing. Any non-secured web traffic (not using https, for example), could still be subject to man-in-the-middle alteration or other network traffic-based manipulations.\n\n== LiveCD ==\nLiveCDs, which run an operating system from a non-writable source, typically come with Web browsers as part of their default image. If the original LiveCD image is free of malware, all of the software used, including the Web browser, will load free of malware every time the LiveCD image is booted.\n\n== Browser hardening ==\nBrowsing the Internet as a least-privilege user account (i.e. without administrator privileges) limits the ability of a security exploit in a web browser from compromising the whole operating system.Internet Explorer 4 and later allows the blacklisting and whitelisting of ActiveX controls, add-ons and browser extensions in various ways.\nInternet Explorer 7 added \"protected mode\", a technology that hardens the browser through the application of a security sandboxing feature of Windows Vista called Mandatory Integrity Control.Google Chrome provides a sandbox to limit web page access to the operating system.Suspected malware sites reported to Google, and confirmed by Google, are flagged as hosting malware in certain browsers.There are third-party extensions and plugins available to harden even the latest browsers, and some for older browsers and operating systems. Whitelist-based software such as NoScript can block JavaScript and Adobe Flash which is used for most attacks on privacy, allowing users to choose only sites they know are safe - AdBlock Plus also uses whitelist ad filtering rules subscriptions, though both the software itself and the filtering list maintainers have come under controversy for by-default allowing some sites to pass the pre-set filters. The US-CERT recommends to block Flash using NoScript.\n\n== Fuzzing ==\nModern web browsers undergo extensive fuzzing to uncover vulnerabilities. The Chromium code of Google Chrome is continuously fuzzed by the Chrome Security Team with 15,000 cores. For Microsoft Edge and Internet Explorer, Microsoft performed fuzzed testing with 670 machine-years during product development, generating more than 400 billion DOM manipulations from 1 billion HTML files.\n\n== Best practice ==\nLoad clean software: Boot from a known clean OS that has a known clean Web browser\nAdopt adequate countermeasures against the Cross-Origin Resource Sharing (CORS) vulnerability (example patches are provided for WebKit-based browsers)\nPrevent attacks via third-party software: Use a hardened Web browser or add-on-free-browsing mode\nPrevent DNS manipulation: Use trusted and secure DNS\nAvoid website-based exploits: Employ link-checking browser plug-ins commonly found in internet security software\nAvoid malicious content: Employ perimeter defenses and anti-malware software"
    }
  },
  {
    "instruction": "Write an answer to the following question: What are the countermeasures for smudge attacks?",
    "context": "",
    "output": "Countermeasures for smudge attacks include creating secure passwords, using anti-fingerprint protection, and using biometrics. Creating secure passwords can be the first step to protecting a device. Anti-fingerprint properties can allow people to keep their current password schemes and not worry about the leftover smudges. Biometrics is a type of authentication that identifies a user based on their behavior or physical characteristics, such as keystrokes, gait, and facial recognition, rather than what one can recall or memorize.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are the countermeasures for smudge attacks?",
      "answer": "Countermeasures for smudge attacks include creating secure passwords, using anti-fingerprint protection, and using biometrics. Creating secure passwords can be the first step to protecting a device. Anti-fingerprint properties can allow people to keep their current password schemes and not worry about the leftover smudges. Biometrics is a type of authentication that identifies a user based on their behavior or physical characteristics, such as keystrokes, gait, and facial recognition, rather than what one can recall or memorize."
    }
  },
  {
    "instruction": "Write an answer to the following question: Can you provide an example of a famous black hat hacker who was caught and later became a cybersecurity consultant?",
    "context": "",
    "output": "Kevin Mitnick is a well-known black hat hacker who was once the most wanted cybercriminal in the world. He hacked into over forty major corporations and served time in prison. After his release, he became a cybersecurity consultant, using his hacking expertise for white hat purposes.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Can you provide an example of a famous black hat hacker who was caught and later became a cybersecurity consultant?",
      "answer": "Kevin Mitnick is a well-known black hat hacker who was once the most wanted cybercriminal in the world. He hacked into over forty major corporations and served time in prison. After his release, he became a cybersecurity consultant, using his hacking expertise for white hat purposes."
    }
  },
  {
    "instruction": "Mix network\n\n==Introduction==\nMix networks are routing protocols that create hard-to-trace communications by using a chain of proxy servers known as mixes which take in messages from multiple senders, shuffle them, and send them back out in random order to the next destination (possibly another mix node). This breaks the link between the source of the request and the destination, making it harder for eavesdroppers to trace end-to-end communications. Furthermore, mixes only know the node that it immediately received the message from, and the immediate destination to send the shuffled messages to, making the network resistant to malicious mix nodes.Each message is encrypted to each proxy using public key cryptography; the resulting encryption is layered like a Russian doll (except that each \"doll\" is of the same size) with the message as the innermost layer.  Each proxy server strips off its own layer of encryption to reveal where to send the message next.  If all but one of the proxy servers are compromised by the tracer, untraceability can still be achieved against some weaker adversaries.\nThe concept of mix networks was first described by David Chaum in 1981.  Applications that are based on this concept include anonymous remailers (such as Mixmaster), onion routing, garlic routing, and key-based routing (including  Tor, I2P, and Freenet).\n\n== How it works ==\n\nParticipant A prepares a message for delivery to participant B by appending a random value R to the message, sealing it with the addressee's public key \n  \n    \n      \n        \n          K\n          \n            b\n          \n        \n      \n    \n    {\\displaystyle K_{b}}\n  , appending B's address, and then sealing the result with the mix's public key \n  \n    \n      \n        \n          K\n          \n            m\n          \n        \n      \n    \n    {\\displaystyle K_{m}}\n  .\nM opens it with his private key, now he knows B's address, and he sends \n  \n    \n      \n        \n          K\n          \n            b\n          \n        \n        (\n        m\n        e\n        s\n        s\n        a\n        g\n        e\n        ,\n        R\n        )\n      \n    \n    {\\displaystyle K_{b}(message,R)}\n   to B.\n\n\n*** Message format ***\n\n  \n    \n      \n        \n          K\n          \n            m\n          \n        \n        (\n        R\n        1\n        ,\n        \n          K\n          \n            b\n          \n        \n        (\n        R\n        0\n        ,\n        m\n        e\n        s\n        s\n        a\n        g\n        e\n        )\n        ,\n        B\n        )\n        \u27f6\n        (\n        \n          K\n          \n            b\n          \n        \n        (\n        R\n        0\n        ,\n        m\n        e\n        s\n        s\n        a\n        g\n        e\n        )\n        ,\n        B\n        )\n      \n    \n    {\\displaystyle K_{m}(R1,K_{b}(R0,message),B)\\longrightarrow (K_{b}(R0,message),B)}\n  \nTo accomplish this, the sender takes the mix's public key (\n  \n    \n      \n        \n          K\n          \n            m\n          \n        \n      \n    \n    {\\displaystyle K_{m}}\n  ), and uses it to encrypt an envelope containing a random string (\n  \n    \n      \n        R\n        1\n      \n    \n    {\\displaystyle R1}\n  ), a nested envelope addressed to the recipient, and the email address of the recipient (B). This nested envelope is encrypted with the recipient's public key (\n  \n    \n      \n        \n          K\n          \n            b\n          \n        \n      \n    \n    {\\displaystyle K_{b}}\n  ), and contains another random string (R0), along with the body of the message being sent. Upon receipt of the encrypted top-level envelope, the mix uses its secret key to open it. Inside, it finds the address of the recipient (B) and an encrypted message bound for B. The random string (\n  \n    \n      \n        R\n        1\n      \n    \n    {\\displaystyle R1}\n  ) is discarded.\n\n  \n    \n      \n        R\n        0\n      \n    \n    {\\displaystyle R0}\n   is needed in the message in order to prevent an attacker from guessing messages. It is assumed that the attacker can observe all incoming and outgoing messages. If the random string is not used (i.e. only \n  \n    \n      \n        (\n        \n          K\n          \n            b\n          \n        \n        (\n        m\n        e\n        s\n        s\n        a\n        g\n        e\n        )\n        )\n      \n    \n    {\\displaystyle (K_{b}(message))}\n   is sent to \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n  ) and an attacker has a good guess that the message \n  \n    \n      \n        m\n        e\n        s\n        s\n        a\n        g\n        \n          e\n          \u2032\n        \n      \n    \n    {\\displaystyle message'}\n   was sent, he can test whether \n  \n    \n      \n        \n          K\n          \n            b\n          \n        \n        (\n        m\n        e\n        s\n        s\n        a\n        g\n        \n          e\n          \u2032\n        \n        )\n\n== Vulnerabilities ==\nAlthough mix networks provide security even if an adversary is able to view the entire path, mixing is not absolutely perfect. Adversaries can provide long term correlation attacks and track the sender and receiver of the packets.\n\n\n*** Threat model ***\nAn adversary can perform a passive attack by monitoring the traffic to and from the mix network. Analyzing the arrival times between multiple packets can reveal information. Since no changes are actively made to the packets, an attack like this is hard to detect. In a worst case of an attack, we assume that all the links of the network are observable by the adversary and the strategies and infrastructure of the mix network are known.A packet on an input link cannot be correlated to a packet on the output link based on information about the time the packet was received, the size of the packet, or the content of the packet. Packet correlation based on packet timing is prevented by batching and correlation based on content and packet size is prevented by encryption and packet padding, respectively.\nInter-packet intervals, that is, the time difference between observation of two consecutive packets on two network links, is used to infer if the links carry the same connection. The encryption and padding does not affect the inter-packet interval related to the same IP flow. Sequences of inter-packet interval vary greatly between connections, for example in web browsing, the traffic occurs in bursts. This fact can be used to identify a connection.\n\n\n*** Active attack ***\nActive attacks can be performed by injecting bursts of packets that contain unique timing signatures into the targeted flow. The attacker can perform attacks to attempt to identify these packets on other network links. The attacker might not be able to create new packets due to the required knowledge of symmetric keys on all the subsequent  mixes. Replay packets cannot be used either as they are easily preventable through hashing and caching.\n\n\n*** Artificial gap ***\nLarge gaps can be created in the target flow, if the attacker drops large volumes of consecutive packets in the flow. For example, a simulation is run sending 3000 packets to the target flow, where the attacker drops the packets 1 second after the start of the flow. As the number of consecutive packets dropped increases, the effectiveness of defensive dropping decreases significantly. Introducing a large gap will almost always create a recognizable feature.\n\n\n*** Artificial bursts ***\nThe attacker can create artificial bursts. This is done by creating a signature from artificial packets by holding them on a link for a certain period of time and then releasing them all at once. Defensive dropping provides no defense in this scenario and the attacker can identify the target flow. There are other defense measures that can be taken to prevent this attack. One such solution can be adaptive padding algorithms. The more the packets are delayed, the easier it is to identify the behavior and thus better defense can be observed.\n\n\n*** Other time analysis attacks ***\nAn attacker may also look into other timing attacks other than inter-packet intervals. The attacker can actively modify packet streams to observe the changes caused in the network's behavior. Packets can be corrupted to force re-transmission of TCP packets, which the behavior is easily observable to reveal information.\n\n\n*** Sleeper attack ***\nAssuming an adversary can see messages being sent and received into threshold mixes but they can't see the internal working of these mixes or what is sent by the same. If the adversary has left their own messages in respective mixes and they receive one of the two, they are able to determine the message sent and the corresponding sender. The adversary has to place their messages (active component) in the mix at any given time and the messages must remain there prior to a message being sent. This is not typically an active attack. Weaker adversaries can use this attack in combination with other attacks to cause more issues.\nMix networks derive security by changing order of messages they receive to avoid creating significant relation between the incoming and outgoing messages. Mixes create interference between messages. The interference puts bounds on the rate of information leak to an observer of the mix. In a mix of size n, an adversary observing input to and output from the mix has an uncertainty of order n in determining a match. A sleeper attack can take advantage of this. In a layered network of threshold mixes with a sleeper in each mix, there is a layer receiving inputs from senders and a second layer of mixes that forward messages to the final destination. From this, the attacker can learn the received message could not have come from the sender into any layer 1 mix that did not fire. There is a higher probability of matching the sent and received messages with these sleepers thus communication is not completely anonymous. Mixes may also be purely timed: they randomize the order of messages received in a particular interval and attach some of them with the mixes, forwarding them at the end of the interval despite what has been received in that interval. Messages that are available for mixinthat tg will interfere, but if no messages are available, there is no interference with received messages.\nQ: How does a sleeper attack exploit the interference in mix networks?",
    "context": "",
    "output": "A sleeper attack takes advantage of the interference in mix networks, which puts bounds on the rate of information leak to an observer. By placing messages (active components) in the mix and observing the output, an attacker can learn information about the sent and received messages, potentially compromising the anonymity of the communication.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does a sleeper attack exploit the interference in mix networks?",
      "answer": "A sleeper attack takes advantage of the interference in mix networks, which puts bounds on the rate of information leak to an observer. By placing messages (active components) in the mix and observing the output, an attacker can learn information about the sent and received messages, potentially compromising the anonymity of the communication.",
      "context": "Mix network\n\n==Introduction==\nMix networks are routing protocols that create hard-to-trace communications by using a chain of proxy servers known as mixes which take in messages from multiple senders, shuffle them, and send them back out in random order to the next destination (possibly another mix node). This breaks the link between the source of the request and the destination, making it harder for eavesdroppers to trace end-to-end communications. Furthermore, mixes only know the node that it immediately received the message from, and the immediate destination to send the shuffled messages to, making the network resistant to malicious mix nodes.Each message is encrypted to each proxy using public key cryptography; the resulting encryption is layered like a Russian doll (except that each \"doll\" is of the same size) with the message as the innermost layer.  Each proxy server strips off its own layer of encryption to reveal where to send the message next.  If all but one of the proxy servers are compromised by the tracer, untraceability can still be achieved against some weaker adversaries.\nThe concept of mix networks was first described by David Chaum in 1981.  Applications that are based on this concept include anonymous remailers (such as Mixmaster), onion routing, garlic routing, and key-based routing (including  Tor, I2P, and Freenet).\n\n== How it works ==\n\nParticipant A prepares a message for delivery to participant B by appending a random value R to the message, sealing it with the addressee's public key \n  \n    \n      \n        \n          K\n          \n            b\n          \n        \n      \n    \n    {\\displaystyle K_{b}}\n  , appending B's address, and then sealing the result with the mix's public key \n  \n    \n      \n        \n          K\n          \n            m\n          \n        \n      \n    \n    {\\displaystyle K_{m}}\n  .\nM opens it with his private key, now he knows B's address, and he sends \n  \n    \n      \n        \n          K\n          \n            b\n          \n        \n        (\n        m\n        e\n        s\n        s\n        a\n        g\n        e\n        ,\n        R\n        )\n      \n    \n    {\\displaystyle K_{b}(message,R)}\n   to B.\n\n\n*** Message format ***\n\n  \n    \n      \n        \n          K\n          \n            m\n          \n        \n        (\n        R\n        1\n        ,\n        \n          K\n          \n            b\n          \n        \n        (\n        R\n        0\n        ,\n        m\n        e\n        s\n        s\n        a\n        g\n        e\n        )\n        ,\n        B\n        )\n        \u27f6\n        (\n        \n          K\n          \n            b\n          \n        \n        (\n        R\n        0\n        ,\n        m\n        e\n        s\n        s\n        a\n        g\n        e\n        )\n        ,\n        B\n        )\n      \n    \n    {\\displaystyle K_{m}(R1,K_{b}(R0,message),B)\\longrightarrow (K_{b}(R0,message),B)}\n  \nTo accomplish this, the sender takes the mix's public key (\n  \n    \n      \n        \n          K\n          \n            m\n          \n        \n      \n    \n    {\\displaystyle K_{m}}\n  ), and uses it to encrypt an envelope containing a random string (\n  \n    \n      \n        R\n        1\n      \n    \n    {\\displaystyle R1}\n  ), a nested envelope addressed to the recipient, and the email address of the recipient (B). This nested envelope is encrypted with the recipient's public key (\n  \n    \n      \n        \n          K\n          \n            b\n          \n        \n      \n    \n    {\\displaystyle K_{b}}\n  ), and contains another random string (R0), along with the body of the message being sent. Upon receipt of the encrypted top-level envelope, the mix uses its secret key to open it. Inside, it finds the address of the recipient (B) and an encrypted message bound for B. The random string (\n  \n    \n      \n        R\n        1\n      \n    \n    {\\displaystyle R1}\n  ) is discarded.\n\n  \n    \n      \n        R\n        0\n      \n    \n    {\\displaystyle R0}\n   is needed in the message in order to prevent an attacker from guessing messages. It is assumed that the attacker can observe all incoming and outgoing messages. If the random string is not used (i.e. only \n  \n    \n      \n        (\n        \n          K\n          \n            b\n          \n        \n        (\n        m\n        e\n        s\n        s\n        a\n        g\n        e\n        )\n        )\n      \n    \n    {\\displaystyle (K_{b}(message))}\n   is sent to \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n  ) and an attacker has a good guess that the message \n  \n    \n      \n        m\n        e\n        s\n        s\n        a\n        g\n        \n          e\n          \u2032\n        \n      \n    \n    {\\displaystyle message'}\n   was sent, he can test whether \n  \n    \n      \n        \n          K\n          \n            b\n          \n        \n        (\n        m\n        e\n        s\n        s\n        a\n        g\n        \n          e\n          \u2032\n        \n        )\n\n== Vulnerabilities ==\nAlthough mix networks provide security even if an adversary is able to view the entire path, mixing is not absolutely perfect. Adversaries can provide long term correlation attacks and track the sender and receiver of the packets.\n\n\n*** Threat model ***\nAn adversary can perform a passive attack by monitoring the traffic to and from the mix network. Analyzing the arrival times between multiple packets can reveal information. Since no changes are actively made to the packets, an attack like this is hard to detect. In a worst case of an attack, we assume that all the links of the network are observable by the adversary and the strategies and infrastructure of the mix network are known.A packet on an input link cannot be correlated to a packet on the output link based on information about the time the packet was received, the size of the packet, or the content of the packet. Packet correlation based on packet timing is prevented by batching and correlation based on content and packet size is prevented by encryption and packet padding, respectively.\nInter-packet intervals, that is, the time difference between observation of two consecutive packets on two network links, is used to infer if the links carry the same connection. The encryption and padding does not affect the inter-packet interval related to the same IP flow. Sequences of inter-packet interval vary greatly between connections, for example in web browsing, the traffic occurs in bursts. This fact can be used to identify a connection.\n\n\n*** Active attack ***\nActive attacks can be performed by injecting bursts of packets that contain unique timing signatures into the targeted flow. The attacker can perform attacks to attempt to identify these packets on other network links. The attacker might not be able to create new packets due to the required knowledge of symmetric keys on all the subsequent  mixes. Replay packets cannot be used either as they are easily preventable through hashing and caching.\n\n\n*** Artificial gap ***\nLarge gaps can be created in the target flow, if the attacker drops large volumes of consecutive packets in the flow. For example, a simulation is run sending 3000 packets to the target flow, where the attacker drops the packets 1 second after the start of the flow. As the number of consecutive packets dropped increases, the effectiveness of defensive dropping decreases significantly. Introducing a large gap will almost always create a recognizable feature.\n\n\n*** Artificial bursts ***\nThe attacker can create artificial bursts. This is done by creating a signature from artificial packets by holding them on a link for a certain period of time and then releasing them all at once. Defensive dropping provides no defense in this scenario and the attacker can identify the target flow. There are other defense measures that can be taken to prevent this attack. One such solution can be adaptive padding algorithms. The more the packets are delayed, the easier it is to identify the behavior and thus better defense can be observed.\n\n\n*** Other time analysis attacks ***\nAn attacker may also look into other timing attacks other than inter-packet intervals. The attacker can actively modify packet streams to observe the changes caused in the network's behavior. Packets can be corrupted to force re-transmission of TCP packets, which the behavior is easily observable to reveal information.\n\n\n*** Sleeper attack ***\nAssuming an adversary can see messages being sent and received into threshold mixes but they can't see the internal working of these mixes or what is sent by the same. If the adversary has left their own messages in respective mixes and they receive one of the two, they are able to determine the message sent and the corresponding sender. The adversary has to place their messages (active component) in the mix at any given time and the messages must remain there prior to a message being sent. This is not typically an active attack. Weaker adversaries can use this attack in combination with other attacks to cause more issues.\nMix networks derive security by changing order of messages they receive to avoid creating significant relation between the incoming and outgoing messages. Mixes create interference between messages. The interference puts bounds on the rate of information leak to an observer of the mix. In a mix of size n, an adversary observing input to and output from the mix has an uncertainty of order n in determining a match. A sleeper attack can take advantage of this. In a layered network of threshold mixes with a sleeper in each mix, there is a layer receiving inputs from senders and a second layer of mixes that forward messages to the final destination. From this, the attacker can learn the received message could not have come from the sender into any layer 1 mix that did not fire. There is a higher probability of matching the sent and received messages with these sleepers thus communication is not completely anonymous. Mixes may also be purely timed: they randomize the order of messages received in a particular interval and attach some of them with the mixes, forwarding them at the end of the interval despite what has been received in that interval. Messages that are available for mixinthat tg will interfere, but if no messages are available, there is no interference with received messages."
    }
  },
  {
    "instruction": "Cloud computing security\n\n==Introduction==\nCloud computing security or, more simply, cloud security  refers to a broad set of policies, technologies, applications, and controls utilized to protect virtualized IP, data, applications, services, and the associated infrastructure of cloud computing. It is a sub-domain of computer security, network security, and, more broadly, information security.\n\n\n\n== Security issues associated with the cloud ==\nCloud computing and storage provide users with capabilities to store and process their data in third-party data centers. Organizations use the cloud in a variety of different service models (with acronyms such as SaaS, PaaS, and IaaS) and deployment models (private, public, hybrid, and community).Security concerns associated with cloud computing are typically categorized in two ways: as security issues faced by cloud providers (organizations providing software-, platform-, or infrastructure-as-a-service via the cloud) and security issues faced by their customers (companies or organizations who host applications or store data on the cloud). The responsibility is shared, however, and is often detailed in a cloud provider's \"shared security responsibility model\" or \"shared responsibility model.\" The provider must ensure that their infrastructure is secure and that their clients\u2019 data and applications are protected, while the user must take measures to fortify their application and use strong passwords and authentication measures.When an organization elects to store data or host applications on the public cloud, it loses its ability to have physical access to the servers hosting its information. As a result, potentially sensitive data is at risk from insider attacks. According to a 2010 Cloud Security Alliance report, insider attacks are one of the top seven biggest threats in cloud computing. Therefore, cloud service providers must ensure that thorough background checks are conducted for employees who have physical access to the servers in the data center. Additionally, data centers are recommended to be frequently monitored for suspicious activity.\nIn order to conserve resources, cut costs, and maintain efficiency, cloud service providers often store more than one customer's data on the same server. As a result, there is a chance that one user's private data can be viewed by other users (possibly even competitors). To handle such sensitive situations, cloud service providers should ensure proper data isolation and logical storage segregation.The extensive use of virtualization in implementing cloud infrastructure brings unique security concerns for customers or tenants of a public cloud service.  Virtualization alters the relationship between the OS and underlying hardware \u2013 be it computing, storage or even networking. This introduces an additional layer \u2013 virtualization \u2013 that itself must be properly configured, managed and secured. Specific concerns include the potential to compromise the virtualization software, or \"hypervisor\". While these concerns are largely theoretical, they do exist. For example, a breach in the administrator workstation with the management software of the virtualization software can cause the whole data center to go down or be reconfigured to an attacker's liking.\n\n== Cloud security controls ==\nCloud security architecture is effective only if the correct defensive implementations are in place. An efficient cloud security architecture should recognize the issues that will arise with security management and follow all of the best practices, procedures, and guidelines to ensure a secure cloud environment. Security management addresses these issues with security controls. These controls protect cloud environments and are put in place to safeguard any weaknesses in the system and reduce the effect of an attack. While there are many types of controls behind a cloud security architecture, they can usually be found in one of the following categories:\n\nDeterrent controls\nThese controls are administrative mechanisms intended to reduce attacks on a cloud system and are utilized to ensure compliance with external controls. Much like a warning sign on a fence or a property, deterrent controls typically reduce the threat level by informing potential attackers that there will be adverse consequences for them if they proceed. (Some consider them a subset of preventive controls.) Examples of such controls could be considered as policies, procedures, standards, guidelines, laws, and regulations that guide an organization towards security. Although most malicious actors ignore such deterrent controls, such controls are intended to ward off those who are inexperienced or curious about compromising the IT infrastructure of an organization.Preventive controls\nThe main objective of preventive controls is to strengthen the system against incidents, generally by reducing if not actually eliminating vulnerabilities, as well as preventing unauthorized intruders from accessing or entering the system. This could be achieved by either adding software or feature implementations (such as firewall protection, endpoint protection, and multi-factor authentication), or removing unneeded functionalities so that the attack surface is minimized (as in unikernel applications). Additionally, educating individuals through security awareness training and exercises is included in such controls due to the human error being the weakest point of security. Strong authentication of cloud users, for instance, makes it less likely that unauthorized users can access cloud systems, and more likely that cloud users are positively identified. All in all, preventative controls affect the likelihood of a loss event occurring and are intended to prevent or eliminate the systems\u2019 exposure to malicious action.Detective controls\nDetective controls are intended to detect and react appropriately to any incidents that occur. In the event of an attack, a detective control will signal the preventative or corrective controls to address the issue. Detective security controls function not only when such an activity is in progress and after it has occurred. System and network security monitoring, including intrusion detection and prevention arrangements, are typically employed to detect attacks on cloud systems and the supporting communications infrastructure. Most organizations acquire or create a dedicated security operations center (SOC), where dedicated members continuously monitor the organization\u2019s IT infrastructure through logs and Security Information and Event Management (SIEM) software. SIEMs are security solutions that help organizations and security teams analyze \u201clog data in real-time for swift detection of security incidents.\u201d SIEMS are not the only examples of detective controls. There are also Physical security controls, Intrusion detection systems, and anti-virus/anti-malware tools, which all have different functions centered around the exact purpose of detecting security compromises within an IT infrastructure.Corrective controls\nCorrective controls reduce the consequences of an incident, generally by limiting the damage. Such controls include technical, physical, and administrative measures that occur during or after an incident to restore the systems or resources to their previous state after a security incident. There are plenty of examples of corrective controls, both physical and technical. For instance, re-issuing an access card or repairing physical damage can be considered corrective controls. However, technical controls such as terminating a process and administrative controls such as implementing an incident response plan could also be considered corrective controls. Corrective controls are focused on recovering and repairing any damage caused by a security incident or unauthorized activity. The value is needed to change the function of security.\n\n== Dimensions of cloud security ==\nCloud security engineering is characterized by the security layers, plan, design, programming, and best practices that exist inside a cloud security arrangement. Cloud security engineering requires the composed and visual model (design and UI) to be characterized by the tasks inside the Cloud. This cloud security engineering process includes such things as access to the executives, techniques, and controls to ensure applications and information. It also includes ways to deal with and keep up with permeability, consistency, danger stance, and by and large security. Processes for imparting security standards into cloud administrations and activities assume an approach that fulfills consistent guidelines and essential framework security parts.For interest in Cloud advancements to be viable, companies should recognize the various parts of the Cloud and how they remain to impact and help them. These interests may include investments in cloud computing and security, for example. This of course leads to leads to driving push for the Cloud advancements to succeed.\nThough the idea of cloud computing isn't new, associations are increasingly enforcing it because of its flexible scalability, relative trustability, and cost frugality of services. However, despite its rapid-fire relinquishment in some sectors and disciplines, it's apparent from exploration and statistics that security-related pitfalls are the most conspicuous hedge to its wide relinquishment.It is generally recommended that information security controls be selected and implemented according to and in proportion to the risks, typically by assessing the threats, vulnerabilities and impacts. Cloud security concerns can be grouped in various ways; Gartner named seven while the Cloud Security Alliance identified twelve areas of concern. Cloud access security brokers (CASBs) are software that sits between cloud users and cloud applications to provide visibility into cloud application usage, data protection and governance to monitor all activity and enforce security policies.\n\n== Security and privacy ==\nAny service without a \"hardened\" environment is considered a \"soft\" target. Virtual servers should be protected just like a physical server against data leakage, malware, and exploited vulnerabilities. \"Data loss or leakage represents 24.6% and cloud related malware 3.4% of threats causing cloud outages\u201d\n\n\n*** Identity management ***\nEvery enterprise will have its own identity management system to control access to information and computing resources. Cloud providers either integrate the customer's identity management system into their own infrastructure, using federation or SSO technology or a biometric-based identification system, or provide an identity management system of their own. CloudID, for instance, provides privacy-preserving cloud-based and cross-enterprise biometric identification. It links the confidential information of the users to their biometrics and stores it in an encrypted fashion. Making use of a searchable encryption technique, biometric identification is performed in the encrypted domain to make sure that the cloud provider or potential attackers do not gain access to any sensitive data or even the contents of the individual queries.\n\n\n*** Physical security ***\nCloud service providers physically secure the IT hardware (servers, routers, cables etc.) against unauthorized access, interference, theft, fires, floods etc. and ensure that essential supplies (such as electricity) are sufficiently robust to minimize the possibility of disruption.  This is normally achieved by serving cloud applications from professionally specified, designed, constructed, managed, monitored and maintained data centers.\n\n\n*** Personnel security ***\nVarious information security concerns relating to the IT and other professionals associated with cloud services are typically handled through pre-, para- and post-employment activities such as security screening potential recruits, security awareness and training programs, and proactive.\n\n\n*** Privacy ***\nProviders ensure that all critical data (credit card numbers, for example) are masked or encrypted and that only authorized users have access to data in its entirety. Moreover, digital identities and credentials must be protected as should any data that the provider collects or produces about customer activity in the cloud.\n\n\n*** Penetration testing ***\nPenetration testing is the process of performing offensive security tests on a system, service, or computer network to find security weaknesses in it. Since the cloud is a shared environment with other customers or tenants, following penetration testing rules of engagement step-by-step is a mandatory requirement. Scanning and penetration testing from inside or outside the cloud should be authorized by the cloud provider. Violation of acceptable use policies can lead to termination of the service.\n\n\n*** Cloud vulnerability and penetration testing ***\nScanning the cloud from outside and inside using free or commercial products is crucial because without a hardened environment your service is considered a soft target. Virtual servers should be hardened just like a physical server against data leakage, malware, and exploited vulnerabilities. \"Data loss or leakage represents 24.6% and cloud-related malware 3.4% of threats causing cloud outages\u201d\nScanning and penetration testing from inside or outside the cloud must be authorized by the cloud provider. Since the cloud is a shared environment with other customers or tenants, following penetration testing rules of engagement step-by-step is a mandatory requirement. Violation of acceptable use policies can lead to the termination of the service. Some key terminology to grasp when discussing penetration testing is the difference between application and network layer testing. Understanding what is asked of you as the tester is sometimes the most important step in the process. The network-layer testing refers to testing that includes internal/external connections as well as the interconnected systems throughout the local network. Oftentimes, social engineering attacks are carried out, as the most vulnerable link in security is often the employee.\nWhite-box testing\nTesting under the condition that the \u201cattacker\u201d has full knowledge of the internal network, its design, and implementation.\nGrey-box testing\nTesting under the condition that the \u201cattacker\u201d has partial knowledge of the internal network, its design, and implementation.\nBlack-box testing\nTesting under the condition that the \u201cattacker\u201d has no prior knowledge of the internal network, its design, and implementation.\n\n== Data security ==\nThere are numerous security threats associated with cloud data services. This includes traditional threats and non-traditional threats. Traditional threats include: network eavesdropping, illegal invasion, and denial of service attacks, but also specific cloud computing threats, such as side channel attacks, virtualization vulnerabilities, and abuse of cloud services. In order to mitigate these threats security controls often rely on monitoring the three areas of the CIA triad. The CIA Triad refers to confidentiality, integrity, as well as access controllability which can be further understood from the following.It is important to note that many effective security measures cover several or all of the three categories. Encryption for example prevents unauthorized access and as a result ensures the confidentiality, availability, and integrity of the data. Backups on the other hand generally cover integrity and firewalls only cover confidentiality and access controllability.\n\n\n*** Confidentiality ***\nData confidentiality is the property in that data contents are not made available or disclosed to illegal users. Outsourced data is stored in a cloud and out of the owners' direct control. Only authorized users can access the sensitive data while others, including CSPs, should not gain any information about the data. Meanwhile, data owners expect to fully utilize cloud data services, e.g., data search, data computation, and data sharing, without the leakage of the data contents to CSPs or other adversaries. Confidentiality refers to how data must be kept strictly confidential to the owner of said data\nAn example of security control that covers confidentiality is encryption so that only authorized users can access the data. Symmetric or asymmetric key paradigm can be used for encryption.\n\n\n*** Access controllability ***\nAccess controllability means that a data owner can perform the selective restriction of access to their data outsourced to the cloud. Legal users can be authorized by the owner to access the data, while others can not access it without permission. Further, it is desirable to enforce fine-grained access control to the outsourced data, i.e., different users should be granted different access privileges with regard to different data pieces. The access authorization must be controlled only by the owner in untrusted cloud environments.\nAccess control can also be referred to as availability. While unauthorized access should be strictly prohibited, access for administrative or even consumer uses should be allowed but monitored as well. Availability and Access control ensure that the proper amount of permissions is granted to the correct persons.\n\n\n*** Integrity ***\nData integrity demands maintaining and assuring the accuracy and completeness of data. A data owner always expects that her or his data in a cloud can be stored correctly and trustworthy. It means that the data should not be illegally tampered with, improperly modified, deliberately deleted, or maliciously fabricated. If any undesirable operations corrupt or delete the data, the owner should be able to detect the corruption or loss. Further, when a portion of the outsourced data is corrupted or lost, it can still be retrieved by the data users. Effective integrity security controls go beyond protection from malicious actors and protect data from unintentional alterations as well.\nAn example of security control that covers integrity is automated backups of information.\n\n== Risks and vulnerabilities of Cloud Computing ==\nWhile cloud computing is on the cutting edge of information technology there are risks and vulnerabilities to consider before investing fully in it. Security controls and services do exist for the cloud but as with any security system they are not guaranteed to succeed. Furthermore, some risks extend beyond asset security and may involve issues in productivity and even privacy as well.\n\n\n*** Privacy Concerns ***\nCloud computing is still an emerging technology and thus is developing in relatively new technological structures. As a result, all cloud services must undertake Privacy Impact Assessments or PIAs before releasing their platform. Consumers as well that intend to use clouds to store their customer's data must also be aware of the vulnerabilities of having non-physical storage for private information.\n\n\n*** Unauthorized Access to Management interface ***\nDue to the autonomous nature of the cloud, consumers are often given management interfaces to monitor their databases. By having controls in such a congregated location and by having the interface be easily accessible for convenience for users, there is a possibility that a single actor could gain access to the cloud's management interface; giving them a great deal of control and power over the database.\n\n\n*** Data Recovery Vulnerabilities ***\nThe cloud's capabilities with allocating resources as needed often result in resources in memory and otherwise being recycled to another user at a later event. For these memory or storage resources, it could be possible for current users to access information left by previous ones.\n\n\n*** Internet Vulnerabilities ***\nThe cloud requires an internet connection and therefore internet protocols to access. Therefore, it is open to many internet protocol vulnerabilities such as man-in-the-middle attacks. Furthermore, by having a heavy reliance on internet connectivity, if the connection fails consumers will be completely cut off from any cloud resources.\n\n\n*** Encryption Vulnerabilities ***\nCryptography is an ever-growing field and technology. What was secure 10 years ago may be considered a significant security risk by today's standards. As technology continues to advance and older technologies grow old, new methods of breaking encryptions will emerge as well as fatal flaws in older encryption methods. Cloud providers must keep up to date with their encryption as the data they typically contain is especially valuable.\n\n\n*** Legal issues ***\nPrivacy legislation often varies from country to country. By having information stored via the cloud it is difficult to determine under which jurisdictions the data falls under. Transborder clouds are especially popular given that the largest companies transcend several countries. Other legal dilemmas from the ambiguity of the cloud refer to how there is a difference in privacy regulation between information shared between and information shared inside of organizations.\n\n\n*** Attacks ***\nThere are several different types of attacks on cloud computing, one that is still very much untapped is infrastructure compromise. Though not completely known it is listed as the attack with the highest amount of payoff. What makes this so dangerous is that the person carrying out the attack is able to gain a level of privilege of having essentially root access to the machine. It is very hard to defend against attacks like these because they are so unpredictable and unknown, attacks of this type are also called zero day exploits because they are difficult to defend against since the vulnerabilities were previously unknown and unchecked until the attack has already occurred.\nDoS attacks aim to have systems be unavailable to their users. Since cloud computing software is used by large numbers of people, resolving these attacks is increasingly difficult. Now with cloud computing on the rise, this has left new opportunities for attacks because of the virtualization of data centers and cloud services being utilized more.With the global pandemic that started early in 2020 taking effect, there was a massive shift to remote work, because of this companies became more reliant on the cloud. This massive shift has not gone unnoticed, especially by cybercriminals and bad actors, many of which saw the opportunity to attack the cloud because of this new remote work environment. Companies have to constantly remind their employees to keep constant vigilance especially remotely. Constantly keeping up to date with the latest security measures and policies, mishaps in communication are some of the things that these cybercriminals are looking for and will prey upon.\nMoving work to the household was critical for workers to be able to continue, but as the move to remote work happened, several security issues arose quickly. The need for data privacy, using applications, personal devices, and the internet all came to the forefront. The pandemic has had large amounts of data being generated especially in the healthcare sector. Big data is accrued for the healthcare sector now more than ever due to the growing coronavirus pandemic. The cloud has to be able to organize and share the data with its users securely. Quality of data looks for four things: accuracy, redundancy, completeness and consistency.Users had to think about the fact that massive amounts of data are being shared globally. Different countries have certain laws and regulations that have to be adhered to. Differences in policy and jurisdiction give rise to the risk involved with the cloud. Workers are using their personal devices more now that they are working from home. Criminals see this increase as an opportunity to exploit people, software is developed to infect people's devices and gain access to their cloud. The current pandemic has put people in a situation where they are incredibly vulnerable and susceptible to attacks. The change to remote work was so sudden that many companies simply were unprepared to deal with the tasks and subsequent workload they have found themselves deeply entrenched in. Tighter security measures have to be put in place to ease that newfound tension within organizations.\n\n== Encryption ==\nSome advanced encryption algorithms which have been applied to cloud computing increase the protection of privacy. In a practice called crypto-shredding, the keys can simply be deleted when there is no more use of the data.\n\n\n*** Attribute-based encryption (ABE) ***\nAttribute-based encryption is a type of public-key encryption in which the secret key of a user and the ciphertext are dependent upon attributes (e.g. the country in which he lives, or the kind of subscription he has). In such a system, the decryption of a ciphertext is possible only if the set of attributes of the user key matches the attributes of the ciphertext.\nSome of the strengths of Attribute-based encryption are that it attempts to solve issues that exist in current public-key infrastructure(PKI) and identity-based encryption(IBE) implementations. By relying on attributes ABE circumvents needing to share keys directly, as with PKI, as well as having to know the identity of the receiver, as with IBE.\nThese benefits come at a cost as ABE suffers from the decryption key re-distribution problem. Since decryption keys in ABE only contain information regarding access structure or the attributes of the user it is hard to verify the user's actual identity. Thus malicious users can intentionally leak their attribute information so that unauthorized users can imitate and gain access.\n\n\n**** Ciphertext-policy ABE (CP-ABE) ****\nCiphertext-policy ABE (CP-ABE) is a type of public-key encryption. In the CP-ABE, the encryptor controls the access strategy. The main research work of CP-ABE is focused on the design of the access structure. A Ciphertext-policy attribute-based encryption scheme consists of four algorithms: Setup, Encrypt, KeyGen, and Decrypt. The Setup algorithm takes security parameters and an attribute universe description as input and outputs public parameters and a master key. The encryption algorithm takes data as input. It then encrypts it to produce ciphertext that only a user that possesses a set of attributes that satisfies the access structure will decrypt the message. The KeyGen algorithm then takes the master key and the user's attributes to develop a private key. Finally, the Decrypt algorithm takes the public parameters, the ciphertext, the private key, and user attributes as input. With this information, the algorithm first checks if the users\u2019 attributes satisfy the access structure and then decrypts the ciphertext to return the data.\n\n\n**** Key-policy ABE (KP-ABE) ****\nKey-policy Attribute-Based Encryption, or KP-ABE, is an important type of Attribute-Based Encryption. KP-ABE allows senders to encrypt their messages under a set of attributes, much like any Attribute Based Encryption system. For each encryption, private user keys are then generated which contain decryption algorithms for deciphering the message and these private user keys grant users access to specific messages that they correspond to. In a KP-ABE system, ciphertexts, or the encrypted messages, are tagged by the creators with a set of attributes, while the user's private keys are issued that specify which type of ciphertexts the key can decrypt. The private keys control which ciphertexts a user is able to decrypt. In KP-ABE, the attribute sets are used to describe the encrypted texts and the private keys are associated to the specified policy that users will have for the decryption of the ciphertexts. A drawback to KP-ABE is that in KP-ABE the encryptor does not control who has access to the encrypted data, except through descriptive attributes, which creates a reliance on the key-issuer granting and denying access to users. Hence, the creation of other ABE systems such as Ciphertext-Policy Attribute-Based Encryption.\n\n\n*** Fully homomorphic encryption (FHE) ***\nFully Homomorphic Encryption is a cryptosystem that supports arbitrary computation on ciphertext and also allows computing sum and product for the encrypted data without decryption. Another interesting feature of Fully Homomorphic Encryption or FHE for short is that it allows operations to be executed without the need of a secret key. FHE has been linked not only to cloud computing but to electronic voting as well. Fully Homomorphic Encryption has been especially helpful with the development of cloud computing and computing technologies. However, as these systems are developing the need for cloud security has also increased. FHE aims to secure data transmission as well as cloud computing storage with its encryption algorithms. Its goal is to be a much more secure and efficient method of encryption on a larger scale to handle the massive capabilities of the cloud.\n\n\n*** Searchable encryption (SE) ***\nSearchable encryption is a cryptographic system that offers secure search functions over encrypted data. SE schemes can be classified into two categories: SE based on secret-key (or symmetric-key) cryptography, and SE based on public-key cryptography. In order to improve search efficiency, symmetric-key SE generally builds keyword indexes to answer user queries. This has the obvious disadvantage of providing multimodal access routes for unauthorized data retrieval, bypassing the encryption algorithm by subjecting the framework to alternative parameters within the shared cloud environment.\n\n== Compliance ==\nNumerous laws and regulations pertaining to the storage and use of data.  In the US these include privacy or data protection laws, Payment Card Industry Data Security Standard (PCI DSS), the Health Insurance Portability and Accountability Act (HIPAA), the Sarbanes-Oxley Act, the Federal Information Security Management Act of 2002 (FISMA), and Children's Online Privacy Protection Act of 1998, among others.  Similar standards exist in other jurisdictions, e.g. Singapore's Multi-Tier Cloud Security Standard.\nSimilar laws may apply in different legal jurisdictions and may differ quite markedly from those enforced in the US.  Cloud service users may often need to be aware of the legal and regulatory differences between the jurisdictions.  For example, data stored by a cloud service provider may be located in, say, Singapore and mirrored in the US.Many of these regulations mandate particular controls (such as strong access controls and audit trails) and require regular reporting. Cloud customers must ensure that their cloud providers adequately fulfill such requirements as appropriate, enabling them to comply with their obligations since, to a large extent, they remain accountable.\n\nBusiness continuity and data recovery\nCloud providers have business continuity and data recovery plans in place to ensure that service can be maintained in case of a disaster or an emergency and that any data loss will be recovered. These plans may be shared with and reviewed by their customers, ideally dovetailing with the customers' own continuity arrangements. Joint continuity exercises may be appropriate, simulating a major Internet or electricity supply failure for instance.Log and audit trail\nIn addition to producing logs and audit trails, cloud providers work with their customers to ensure that these logs and audit trails are properly secured, maintained for as long as the customer requires, and are accessible for the purposes of forensic investigation (e.g., eDiscovery).Unique compliance requirements\nIn addition to the requirements to which customers are subject, the data centers used by cloud providers may also be subject to compliance requirements. Using a cloud service provider (CSP) can lead to additional security concerns around data jurisdiction since customer or tenant data may not remain on the same system, in the same data center, or even within the same provider's cloud.\nThe European Union\u2019s GDPR has introduced new compliance requirements for customer data.\n\n== Legal and contractual issues ==\n\nAside from the security and compliance issues enumerated above, cloud providers and their customers will negotiate terms around liability (stipulating how incidents involving data loss or compromise will be resolved, for example), intellectual property, and end-of-service (when data and applications are ultimately returned to the customer). In addition, there are considerations for acquiring data from the cloud that may be involved in litigation. These issues are discussed in service-level agreements (SLA).\n\n\n*** Public records ***\nLegal issues may also include records-keeping requirements in the public sector, where many agencies are required by law to retain and make available electronic records in a specific fashion. This may be determined by legislation, or law may require agencies to conform to the rules and practices set by a records-keeping agency. Public agencies using cloud computing and storage must take these concerns into account.\n\nWhat are the privacy concerns associated with cloud computing?",
    "context": "",
    "output": "Privacy concerns associated with cloud computing include the need for Privacy Impact Assessments (PIAs) before releasing a platform and vulnerabilities of having non-physical storage for private information.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are the privacy concerns associated with cloud computing?",
      "answer": "Privacy concerns associated with cloud computing include the need for Privacy Impact Assessments (PIAs) before releasing a platform and vulnerabilities of having non-physical storage for private information.",
      "context": "Cloud computing security\n\n==Introduction==\nCloud computing security or, more simply, cloud security  refers to a broad set of policies, technologies, applications, and controls utilized to protect virtualized IP, data, applications, services, and the associated infrastructure of cloud computing. It is a sub-domain of computer security, network security, and, more broadly, information security.\n\n\n\n== Security issues associated with the cloud ==\nCloud computing and storage provide users with capabilities to store and process their data in third-party data centers. Organizations use the cloud in a variety of different service models (with acronyms such as SaaS, PaaS, and IaaS) and deployment models (private, public, hybrid, and community).Security concerns associated with cloud computing are typically categorized in two ways: as security issues faced by cloud providers (organizations providing software-, platform-, or infrastructure-as-a-service via the cloud) and security issues faced by their customers (companies or organizations who host applications or store data on the cloud). The responsibility is shared, however, and is often detailed in a cloud provider's \"shared security responsibility model\" or \"shared responsibility model.\" The provider must ensure that their infrastructure is secure and that their clients\u2019 data and applications are protected, while the user must take measures to fortify their application and use strong passwords and authentication measures.When an organization elects to store data or host applications on the public cloud, it loses its ability to have physical access to the servers hosting its information. As a result, potentially sensitive data is at risk from insider attacks. According to a 2010 Cloud Security Alliance report, insider attacks are one of the top seven biggest threats in cloud computing. Therefore, cloud service providers must ensure that thorough background checks are conducted for employees who have physical access to the servers in the data center. Additionally, data centers are recommended to be frequently monitored for suspicious activity.\nIn order to conserve resources, cut costs, and maintain efficiency, cloud service providers often store more than one customer's data on the same server. As a result, there is a chance that one user's private data can be viewed by other users (possibly even competitors). To handle such sensitive situations, cloud service providers should ensure proper data isolation and logical storage segregation.The extensive use of virtualization in implementing cloud infrastructure brings unique security concerns for customers or tenants of a public cloud service.  Virtualization alters the relationship between the OS and underlying hardware \u2013 be it computing, storage or even networking. This introduces an additional layer \u2013 virtualization \u2013 that itself must be properly configured, managed and secured. Specific concerns include the potential to compromise the virtualization software, or \"hypervisor\". While these concerns are largely theoretical, they do exist. For example, a breach in the administrator workstation with the management software of the virtualization software can cause the whole data center to go down or be reconfigured to an attacker's liking.\n\n== Cloud security controls ==\nCloud security architecture is effective only if the correct defensive implementations are in place. An efficient cloud security architecture should recognize the issues that will arise with security management and follow all of the best practices, procedures, and guidelines to ensure a secure cloud environment. Security management addresses these issues with security controls. These controls protect cloud environments and are put in place to safeguard any weaknesses in the system and reduce the effect of an attack. While there are many types of controls behind a cloud security architecture, they can usually be found in one of the following categories:\n\nDeterrent controls\nThese controls are administrative mechanisms intended to reduce attacks on a cloud system and are utilized to ensure compliance with external controls. Much like a warning sign on a fence or a property, deterrent controls typically reduce the threat level by informing potential attackers that there will be adverse consequences for them if they proceed. (Some consider them a subset of preventive controls.) Examples of such controls could be considered as policies, procedures, standards, guidelines, laws, and regulations that guide an organization towards security. Although most malicious actors ignore such deterrent controls, such controls are intended to ward off those who are inexperienced or curious about compromising the IT infrastructure of an organization.Preventive controls\nThe main objective of preventive controls is to strengthen the system against incidents, generally by reducing if not actually eliminating vulnerabilities, as well as preventing unauthorized intruders from accessing or entering the system. This could be achieved by either adding software or feature implementations (such as firewall protection, endpoint protection, and multi-factor authentication), or removing unneeded functionalities so that the attack surface is minimized (as in unikernel applications). Additionally, educating individuals through security awareness training and exercises is included in such controls due to the human error being the weakest point of security. Strong authentication of cloud users, for instance, makes it less likely that unauthorized users can access cloud systems, and more likely that cloud users are positively identified. All in all, preventative controls affect the likelihood of a loss event occurring and are intended to prevent or eliminate the systems\u2019 exposure to malicious action.Detective controls\nDetective controls are intended to detect and react appropriately to any incidents that occur. In the event of an attack, a detective control will signal the preventative or corrective controls to address the issue. Detective security controls function not only when such an activity is in progress and after it has occurred. System and network security monitoring, including intrusion detection and prevention arrangements, are typically employed to detect attacks on cloud systems and the supporting communications infrastructure. Most organizations acquire or create a dedicated security operations center (SOC), where dedicated members continuously monitor the organization\u2019s IT infrastructure through logs and Security Information and Event Management (SIEM) software. SIEMs are security solutions that help organizations and security teams analyze \u201clog data in real-time for swift detection of security incidents.\u201d SIEMS are not the only examples of detective controls. There are also Physical security controls, Intrusion detection systems, and anti-virus/anti-malware tools, which all have different functions centered around the exact purpose of detecting security compromises within an IT infrastructure.Corrective controls\nCorrective controls reduce the consequences of an incident, generally by limiting the damage. Such controls include technical, physical, and administrative measures that occur during or after an incident to restore the systems or resources to their previous state after a security incident. There are plenty of examples of corrective controls, both physical and technical. For instance, re-issuing an access card or repairing physical damage can be considered corrective controls. However, technical controls such as terminating a process and administrative controls such as implementing an incident response plan could also be considered corrective controls. Corrective controls are focused on recovering and repairing any damage caused by a security incident or unauthorized activity. The value is needed to change the function of security.\n\n== Dimensions of cloud security ==\nCloud security engineering is characterized by the security layers, plan, design, programming, and best practices that exist inside a cloud security arrangement. Cloud security engineering requires the composed and visual model (design and UI) to be characterized by the tasks inside the Cloud. This cloud security engineering process includes such things as access to the executives, techniques, and controls to ensure applications and information. It also includes ways to deal with and keep up with permeability, consistency, danger stance, and by and large security. Processes for imparting security standards into cloud administrations and activities assume an approach that fulfills consistent guidelines and essential framework security parts.For interest in Cloud advancements to be viable, companies should recognize the various parts of the Cloud and how they remain to impact and help them. These interests may include investments in cloud computing and security, for example. This of course leads to leads to driving push for the Cloud advancements to succeed.\nThough the idea of cloud computing isn't new, associations are increasingly enforcing it because of its flexible scalability, relative trustability, and cost frugality of services. However, despite its rapid-fire relinquishment in some sectors and disciplines, it's apparent from exploration and statistics that security-related pitfalls are the most conspicuous hedge to its wide relinquishment.It is generally recommended that information security controls be selected and implemented according to and in proportion to the risks, typically by assessing the threats, vulnerabilities and impacts. Cloud security concerns can be grouped in various ways; Gartner named seven while the Cloud Security Alliance identified twelve areas of concern. Cloud access security brokers (CASBs) are software that sits between cloud users and cloud applications to provide visibility into cloud application usage, data protection and governance to monitor all activity and enforce security policies.\n\n== Security and privacy ==\nAny service without a \"hardened\" environment is considered a \"soft\" target. Virtual servers should be protected just like a physical server against data leakage, malware, and exploited vulnerabilities. \"Data loss or leakage represents 24.6% and cloud related malware 3.4% of threats causing cloud outages\u201d\n\n\n*** Identity management ***\nEvery enterprise will have its own identity management system to control access to information and computing resources. Cloud providers either integrate the customer's identity management system into their own infrastructure, using federation or SSO technology or a biometric-based identification system, or provide an identity management system of their own. CloudID, for instance, provides privacy-preserving cloud-based and cross-enterprise biometric identification. It links the confidential information of the users to their biometrics and stores it in an encrypted fashion. Making use of a searchable encryption technique, biometric identification is performed in the encrypted domain to make sure that the cloud provider or potential attackers do not gain access to any sensitive data or even the contents of the individual queries.\n\n\n*** Physical security ***\nCloud service providers physically secure the IT hardware (servers, routers, cables etc.) against unauthorized access, interference, theft, fires, floods etc. and ensure that essential supplies (such as electricity) are sufficiently robust to minimize the possibility of disruption.  This is normally achieved by serving cloud applications from professionally specified, designed, constructed, managed, monitored and maintained data centers.\n\n\n*** Personnel security ***\nVarious information security concerns relating to the IT and other professionals associated with cloud services are typically handled through pre-, para- and post-employment activities such as security screening potential recruits, security awareness and training programs, and proactive.\n\n\n*** Privacy ***\nProviders ensure that all critical data (credit card numbers, for example) are masked or encrypted and that only authorized users have access to data in its entirety. Moreover, digital identities and credentials must be protected as should any data that the provider collects or produces about customer activity in the cloud.\n\n\n*** Penetration testing ***\nPenetration testing is the process of performing offensive security tests on a system, service, or computer network to find security weaknesses in it. Since the cloud is a shared environment with other customers or tenants, following penetration testing rules of engagement step-by-step is a mandatory requirement. Scanning and penetration testing from inside or outside the cloud should be authorized by the cloud provider. Violation of acceptable use policies can lead to termination of the service.\n\n\n*** Cloud vulnerability and penetration testing ***\nScanning the cloud from outside and inside using free or commercial products is crucial because without a hardened environment your service is considered a soft target. Virtual servers should be hardened just like a physical server against data leakage, malware, and exploited vulnerabilities. \"Data loss or leakage represents 24.6% and cloud-related malware 3.4% of threats causing cloud outages\u201d\nScanning and penetration testing from inside or outside the cloud must be authorized by the cloud provider. Since the cloud is a shared environment with other customers or tenants, following penetration testing rules of engagement step-by-step is a mandatory requirement. Violation of acceptable use policies can lead to the termination of the service. Some key terminology to grasp when discussing penetration testing is the difference between application and network layer testing. Understanding what is asked of you as the tester is sometimes the most important step in the process. The network-layer testing refers to testing that includes internal/external connections as well as the interconnected systems throughout the local network. Oftentimes, social engineering attacks are carried out, as the most vulnerable link in security is often the employee.\nWhite-box testing\nTesting under the condition that the \u201cattacker\u201d has full knowledge of the internal network, its design, and implementation.\nGrey-box testing\nTesting under the condition that the \u201cattacker\u201d has partial knowledge of the internal network, its design, and implementation.\nBlack-box testing\nTesting under the condition that the \u201cattacker\u201d has no prior knowledge of the internal network, its design, and implementation.\n\n== Data security ==\nThere are numerous security threats associated with cloud data services. This includes traditional threats and non-traditional threats. Traditional threats include: network eavesdropping, illegal invasion, and denial of service attacks, but also specific cloud computing threats, such as side channel attacks, virtualization vulnerabilities, and abuse of cloud services. In order to mitigate these threats security controls often rely on monitoring the three areas of the CIA triad. The CIA Triad refers to confidentiality, integrity, as well as access controllability which can be further understood from the following.It is important to note that many effective security measures cover several or all of the three categories. Encryption for example prevents unauthorized access and as a result ensures the confidentiality, availability, and integrity of the data. Backups on the other hand generally cover integrity and firewalls only cover confidentiality and access controllability.\n\n\n*** Confidentiality ***\nData confidentiality is the property in that data contents are not made available or disclosed to illegal users. Outsourced data is stored in a cloud and out of the owners' direct control. Only authorized users can access the sensitive data while others, including CSPs, should not gain any information about the data. Meanwhile, data owners expect to fully utilize cloud data services, e.g., data search, data computation, and data sharing, without the leakage of the data contents to CSPs or other adversaries. Confidentiality refers to how data must be kept strictly confidential to the owner of said data\nAn example of security control that covers confidentiality is encryption so that only authorized users can access the data. Symmetric or asymmetric key paradigm can be used for encryption.\n\n\n*** Access controllability ***\nAccess controllability means that a data owner can perform the selective restriction of access to their data outsourced to the cloud. Legal users can be authorized by the owner to access the data, while others can not access it without permission. Further, it is desirable to enforce fine-grained access control to the outsourced data, i.e., different users should be granted different access privileges with regard to different data pieces. The access authorization must be controlled only by the owner in untrusted cloud environments.\nAccess control can also be referred to as availability. While unauthorized access should be strictly prohibited, access for administrative or even consumer uses should be allowed but monitored as well. Availability and Access control ensure that the proper amount of permissions is granted to the correct persons.\n\n\n*** Integrity ***\nData integrity demands maintaining and assuring the accuracy and completeness of data. A data owner always expects that her or his data in a cloud can be stored correctly and trustworthy. It means that the data should not be illegally tampered with, improperly modified, deliberately deleted, or maliciously fabricated. If any undesirable operations corrupt or delete the data, the owner should be able to detect the corruption or loss. Further, when a portion of the outsourced data is corrupted or lost, it can still be retrieved by the data users. Effective integrity security controls go beyond protection from malicious actors and protect data from unintentional alterations as well.\nAn example of security control that covers integrity is automated backups of information.\n\n== Risks and vulnerabilities of Cloud Computing ==\nWhile cloud computing is on the cutting edge of information technology there are risks and vulnerabilities to consider before investing fully in it. Security controls and services do exist for the cloud but as with any security system they are not guaranteed to succeed. Furthermore, some risks extend beyond asset security and may involve issues in productivity and even privacy as well.\n\n\n*** Privacy Concerns ***\nCloud computing is still an emerging technology and thus is developing in relatively new technological structures. As a result, all cloud services must undertake Privacy Impact Assessments or PIAs before releasing their platform. Consumers as well that intend to use clouds to store their customer's data must also be aware of the vulnerabilities of having non-physical storage for private information.\n\n\n*** Unauthorized Access to Management interface ***\nDue to the autonomous nature of the cloud, consumers are often given management interfaces to monitor their databases. By having controls in such a congregated location and by having the interface be easily accessible for convenience for users, there is a possibility that a single actor could gain access to the cloud's management interface; giving them a great deal of control and power over the database.\n\n\n*** Data Recovery Vulnerabilities ***\nThe cloud's capabilities with allocating resources as needed often result in resources in memory and otherwise being recycled to another user at a later event. For these memory or storage resources, it could be possible for current users to access information left by previous ones.\n\n\n*** Internet Vulnerabilities ***\nThe cloud requires an internet connection and therefore internet protocols to access. Therefore, it is open to many internet protocol vulnerabilities such as man-in-the-middle attacks. Furthermore, by having a heavy reliance on internet connectivity, if the connection fails consumers will be completely cut off from any cloud resources.\n\n\n*** Encryption Vulnerabilities ***\nCryptography is an ever-growing field and technology. What was secure 10 years ago may be considered a significant security risk by today's standards. As technology continues to advance and older technologies grow old, new methods of breaking encryptions will emerge as well as fatal flaws in older encryption methods. Cloud providers must keep up to date with their encryption as the data they typically contain is especially valuable.\n\n\n*** Legal issues ***\nPrivacy legislation often varies from country to country. By having information stored via the cloud it is difficult to determine under which jurisdictions the data falls under. Transborder clouds are especially popular given that the largest companies transcend several countries. Other legal dilemmas from the ambiguity of the cloud refer to how there is a difference in privacy regulation between information shared between and information shared inside of organizations.\n\n\n*** Attacks ***\nThere are several different types of attacks on cloud computing, one that is still very much untapped is infrastructure compromise. Though not completely known it is listed as the attack with the highest amount of payoff. What makes this so dangerous is that the person carrying out the attack is able to gain a level of privilege of having essentially root access to the machine. It is very hard to defend against attacks like these because they are so unpredictable and unknown, attacks of this type are also called zero day exploits because they are difficult to defend against since the vulnerabilities were previously unknown and unchecked until the attack has already occurred.\nDoS attacks aim to have systems be unavailable to their users. Since cloud computing software is used by large numbers of people, resolving these attacks is increasingly difficult. Now with cloud computing on the rise, this has left new opportunities for attacks because of the virtualization of data centers and cloud services being utilized more.With the global pandemic that started early in 2020 taking effect, there was a massive shift to remote work, because of this companies became more reliant on the cloud. This massive shift has not gone unnoticed, especially by cybercriminals and bad actors, many of which saw the opportunity to attack the cloud because of this new remote work environment. Companies have to constantly remind their employees to keep constant vigilance especially remotely. Constantly keeping up to date with the latest security measures and policies, mishaps in communication are some of the things that these cybercriminals are looking for and will prey upon.\nMoving work to the household was critical for workers to be able to continue, but as the move to remote work happened, several security issues arose quickly. The need for data privacy, using applications, personal devices, and the internet all came to the forefront. The pandemic has had large amounts of data being generated especially in the healthcare sector. Big data is accrued for the healthcare sector now more than ever due to the growing coronavirus pandemic. The cloud has to be able to organize and share the data with its users securely. Quality of data looks for four things: accuracy, redundancy, completeness and consistency.Users had to think about the fact that massive amounts of data are being shared globally. Different countries have certain laws and regulations that have to be adhered to. Differences in policy and jurisdiction give rise to the risk involved with the cloud. Workers are using their personal devices more now that they are working from home. Criminals see this increase as an opportunity to exploit people, software is developed to infect people's devices and gain access to their cloud. The current pandemic has put people in a situation where they are incredibly vulnerable and susceptible to attacks. The change to remote work was so sudden that many companies simply were unprepared to deal with the tasks and subsequent workload they have found themselves deeply entrenched in. Tighter security measures have to be put in place to ease that newfound tension within organizations.\n\n== Encryption ==\nSome advanced encryption algorithms which have been applied to cloud computing increase the protection of privacy. In a practice called crypto-shredding, the keys can simply be deleted when there is no more use of the data.\n\n\n*** Attribute-based encryption (ABE) ***\nAttribute-based encryption is a type of public-key encryption in which the secret key of a user and the ciphertext are dependent upon attributes (e.g. the country in which he lives, or the kind of subscription he has). In such a system, the decryption of a ciphertext is possible only if the set of attributes of the user key matches the attributes of the ciphertext.\nSome of the strengths of Attribute-based encryption are that it attempts to solve issues that exist in current public-key infrastructure(PKI) and identity-based encryption(IBE) implementations. By relying on attributes ABE circumvents needing to share keys directly, as with PKI, as well as having to know the identity of the receiver, as with IBE.\nThese benefits come at a cost as ABE suffers from the decryption key re-distribution problem. Since decryption keys in ABE only contain information regarding access structure or the attributes of the user it is hard to verify the user's actual identity. Thus malicious users can intentionally leak their attribute information so that unauthorized users can imitate and gain access.\n\n\n**** Ciphertext-policy ABE (CP-ABE) ****\nCiphertext-policy ABE (CP-ABE) is a type of public-key encryption. In the CP-ABE, the encryptor controls the access strategy. The main research work of CP-ABE is focused on the design of the access structure. A Ciphertext-policy attribute-based encryption scheme consists of four algorithms: Setup, Encrypt, KeyGen, and Decrypt. The Setup algorithm takes security parameters and an attribute universe description as input and outputs public parameters and a master key. The encryption algorithm takes data as input. It then encrypts it to produce ciphertext that only a user that possesses a set of attributes that satisfies the access structure will decrypt the message. The KeyGen algorithm then takes the master key and the user's attributes to develop a private key. Finally, the Decrypt algorithm takes the public parameters, the ciphertext, the private key, and user attributes as input. With this information, the algorithm first checks if the users\u2019 attributes satisfy the access structure and then decrypts the ciphertext to return the data.\n\n\n**** Key-policy ABE (KP-ABE) ****\nKey-policy Attribute-Based Encryption, or KP-ABE, is an important type of Attribute-Based Encryption. KP-ABE allows senders to encrypt their messages under a set of attributes, much like any Attribute Based Encryption system. For each encryption, private user keys are then generated which contain decryption algorithms for deciphering the message and these private user keys grant users access to specific messages that they correspond to. In a KP-ABE system, ciphertexts, or the encrypted messages, are tagged by the creators with a set of attributes, while the user's private keys are issued that specify which type of ciphertexts the key can decrypt. The private keys control which ciphertexts a user is able to decrypt. In KP-ABE, the attribute sets are used to describe the encrypted texts and the private keys are associated to the specified policy that users will have for the decryption of the ciphertexts. A drawback to KP-ABE is that in KP-ABE the encryptor does not control who has access to the encrypted data, except through descriptive attributes, which creates a reliance on the key-issuer granting and denying access to users. Hence, the creation of other ABE systems such as Ciphertext-Policy Attribute-Based Encryption.\n\n\n*** Fully homomorphic encryption (FHE) ***\nFully Homomorphic Encryption is a cryptosystem that supports arbitrary computation on ciphertext and also allows computing sum and product for the encrypted data without decryption. Another interesting feature of Fully Homomorphic Encryption or FHE for short is that it allows operations to be executed without the need of a secret key. FHE has been linked not only to cloud computing but to electronic voting as well. Fully Homomorphic Encryption has been especially helpful with the development of cloud computing and computing technologies. However, as these systems are developing the need for cloud security has also increased. FHE aims to secure data transmission as well as cloud computing storage with its encryption algorithms. Its goal is to be a much more secure and efficient method of encryption on a larger scale to handle the massive capabilities of the cloud.\n\n\n*** Searchable encryption (SE) ***\nSearchable encryption is a cryptographic system that offers secure search functions over encrypted data. SE schemes can be classified into two categories: SE based on secret-key (or symmetric-key) cryptography, and SE based on public-key cryptography. In order to improve search efficiency, symmetric-key SE generally builds keyword indexes to answer user queries. This has the obvious disadvantage of providing multimodal access routes for unauthorized data retrieval, bypassing the encryption algorithm by subjecting the framework to alternative parameters within the shared cloud environment.\n\n== Compliance ==\nNumerous laws and regulations pertaining to the storage and use of data.  In the US these include privacy or data protection laws, Payment Card Industry Data Security Standard (PCI DSS), the Health Insurance Portability and Accountability Act (HIPAA), the Sarbanes-Oxley Act, the Federal Information Security Management Act of 2002 (FISMA), and Children's Online Privacy Protection Act of 1998, among others.  Similar standards exist in other jurisdictions, e.g. Singapore's Multi-Tier Cloud Security Standard.\nSimilar laws may apply in different legal jurisdictions and may differ quite markedly from those enforced in the US.  Cloud service users may often need to be aware of the legal and regulatory differences between the jurisdictions.  For example, data stored by a cloud service provider may be located in, say, Singapore and mirrored in the US.Many of these regulations mandate particular controls (such as strong access controls and audit trails) and require regular reporting. Cloud customers must ensure that their cloud providers adequately fulfill such requirements as appropriate, enabling them to comply with their obligations since, to a large extent, they remain accountable.\n\nBusiness continuity and data recovery\nCloud providers have business continuity and data recovery plans in place to ensure that service can be maintained in case of a disaster or an emergency and that any data loss will be recovered. These plans may be shared with and reviewed by their customers, ideally dovetailing with the customers' own continuity arrangements. Joint continuity exercises may be appropriate, simulating a major Internet or electricity supply failure for instance.Log and audit trail\nIn addition to producing logs and audit trails, cloud providers work with their customers to ensure that these logs and audit trails are properly secured, maintained for as long as the customer requires, and are accessible for the purposes of forensic investigation (e.g., eDiscovery).Unique compliance requirements\nIn addition to the requirements to which customers are subject, the data centers used by cloud providers may also be subject to compliance requirements. Using a cloud service provider (CSP) can lead to additional security concerns around data jurisdiction since customer or tenant data may not remain on the same system, in the same data center, or even within the same provider's cloud.\nThe European Union\u2019s GDPR has introduced new compliance requirements for customer data.\n\n== Legal and contractual issues ==\n\nAside from the security and compliance issues enumerated above, cloud providers and their customers will negotiate terms around liability (stipulating how incidents involving data loss or compromise will be resolved, for example), intellectual property, and end-of-service (when data and applications are ultimately returned to the customer). In addition, there are considerations for acquiring data from the cloud that may be involved in litigation. These issues are discussed in service-level agreements (SLA).\n\n\n*** Public records ***\nLegal issues may also include records-keeping requirements in the public sector, where many agencies are required by law to retain and make available electronic records in a specific fashion. This may be determined by legislation, or law may require agencies to conform to the rules and practices set by a records-keeping agency. Public agencies using cloud computing and storage must take these concerns into account."
    }
  },
  {
    "instruction": "Answer based on context:\n\nZeroAccess botnet\n\n==Introduction==\nZeroAccess is a Trojan horse computer malware that affects Microsoft Windows operating systems. It is used to download other malware on an infected machine from a botnet while remaining hidden using rootkit techniques.\n\n== History and propagation ==\nThe ZeroAccess botnet was discovered at least around May 2011. The ZeroAccess rootkit responsible for the botnet's spread is estimated to have been present on at least 9 million systems. Estimates botnet size vary across sources; antivirus vendor Sophos estimated the botnet size at around 1 million active and infected machines in the third quarter of 2012, and security firm Kindsight estimated 2.2 million infected and active systems.The bot itself is spread through the ZeroAccess rootkit through a variety of attack vectors. One attack vector is a form of social engineering, where a user is persuaded to execute malicious code either by disguising it as a legitimate file, or including it hidden as an additional payload in an executable that announces itself as, for example, bypassing copyright protection (a keygen). A second attack vector utilizes an advertising network in order to have the user click on an advertisement that redirects them to a site hosting the malicious software itself. Finally, a third infection vector used is an affiliate scheme where third-party persons are paid for installing the rootkit on a system.In December 2013 a coalition led by Microsoft moved to destroy the command and control network for the botnet. The attack was ineffective though because not all C&C were seized, and its peer-to-peer command and control component was unaffected - meaning the botnet could still be updated at will.\n\n== Operation ==\nOnce a system has been infected with the ZeroAccess rootkit it will start one of the two main botnet operations: bitcoin mining or click fraud. Machines involved in bitcoin mining generate bitcoins for their controller, the estimated worth of which was 2.7 million US dollars per year in September 2012. The machines used for click fraud simulate clicks on website advertisements paid for on a pay per click basis. The estimated profit for this activity may be as high as 100,000 US dollars per day, costing advertisers $900,000 a day in fraudulent clicks. Typically, ZeroAccess infects the Master Boot Record (MBR) of the infected machine. It may alternatively infect a random driver in C:\\Windows\\System32\\Drivers giving it total control over the operating system. It also disables the Windows Security Center, Firewall, and Windows Defender from the operating system. ZeroAccess also hooks itself into the TCP/IP stack to help with the click fraud.\nThe software also looks for the Tidserv malware and removes it if it finds it.\n\nWhat are the two main operations of the ZeroAccess botnet?",
    "context": "",
    "output": "The two main operations of the ZeroAccess botnet are bitcoin mining and click fraud.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are the two main operations of the ZeroAccess botnet?",
      "answer": "The two main operations of the ZeroAccess botnet are bitcoin mining and click fraud.",
      "context": "ZeroAccess botnet\n\n==Introduction==\nZeroAccess is a Trojan horse computer malware that affects Microsoft Windows operating systems. It is used to download other malware on an infected machine from a botnet while remaining hidden using rootkit techniques.\n\n== History and propagation ==\nThe ZeroAccess botnet was discovered at least around May 2011. The ZeroAccess rootkit responsible for the botnet's spread is estimated to have been present on at least 9 million systems. Estimates botnet size vary across sources; antivirus vendor Sophos estimated the botnet size at around 1 million active and infected machines in the third quarter of 2012, and security firm Kindsight estimated 2.2 million infected and active systems.The bot itself is spread through the ZeroAccess rootkit through a variety of attack vectors. One attack vector is a form of social engineering, where a user is persuaded to execute malicious code either by disguising it as a legitimate file, or including it hidden as an additional payload in an executable that announces itself as, for example, bypassing copyright protection (a keygen). A second attack vector utilizes an advertising network in order to have the user click on an advertisement that redirects them to a site hosting the malicious software itself. Finally, a third infection vector used is an affiliate scheme where third-party persons are paid for installing the rootkit on a system.In December 2013 a coalition led by Microsoft moved to destroy the command and control network for the botnet. The attack was ineffective though because not all C&C were seized, and its peer-to-peer command and control component was unaffected - meaning the botnet could still be updated at will.\n\n== Operation ==\nOnce a system has been infected with the ZeroAccess rootkit it will start one of the two main botnet operations: bitcoin mining or click fraud. Machines involved in bitcoin mining generate bitcoins for their controller, the estimated worth of which was 2.7 million US dollars per year in September 2012. The machines used for click fraud simulate clicks on website advertisements paid for on a pay per click basis. The estimated profit for this activity may be as high as 100,000 US dollars per day, costing advertisers $900,000 a day in fraudulent clicks. Typically, ZeroAccess infects the Master Boot Record (MBR) of the infected machine. It may alternatively infect a random driver in C:\\Windows\\System32\\Drivers giving it total control over the operating system. It also disables the Windows Security Center, Firewall, and Windows Defender from the operating system. ZeroAccess also hooks itself into the TCP/IP stack to help with the click fraud.\nThe software also looks for the Tidserv malware and removes it if it finds it."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the Dolev-Yao model handle the complexity of the adversary's omnipotence?",
    "context": "",
    "output": "The Dolev-Yao model simplifies the adversary's omnipotence by limiting them to the constraints of the cryptographic methods used.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the Dolev-Yao model handle the complexity of the adversary's omnipotence?",
      "answer": "The Dolev-Yao model simplifies the adversary's omnipotence by limiting them to the constraints of the cryptographic methods used."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the effect of a sleeper attack on a layered network of threshold mixes with a sleeper in each mix?",
    "context": "",
    "output": "In a layered network of threshold mixes with a sleeper in each mix, an attacker can learn that the received message could not have come from a sender into any layer 1 mix that did not fire. This increases the probability of matching sent and received messages, potentially compromising the anonymity of the communication.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the effect of a sleeper attack on a layered network of threshold mixes with a sleeper in each mix?",
      "answer": "In a layered network of threshold mixes with a sleeper in each mix, an attacker can learn that the received message could not have come from a sender into any layer 1 mix that did not fire. This increases the probability of matching sent and received messages, potentially compromising the anonymity of the communication."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does Systrace help eliminate the need for potentially dangerous setuid programs?",
    "context": "",
    "output": "Systrace helps eliminate the need for potentially dangerous setuid programs by providing facilities for privilege elevation on a system call basis. This allows applications to execute certain actions with higher privileges only when necessary, reducing the need for setuid programs.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does Systrace help eliminate the need for potentially dangerous setuid programs?",
      "answer": "Systrace helps eliminate the need for potentially dangerous setuid programs by providing facilities for privilege elevation on a system call basis. This allows applications to execute certain actions with higher privileges only when necessary, reducing the need for setuid programs."
    }
  },
  {
    "instruction": "Write an answer to the following question: What standard was designed to overcome the shortcomings of SYN cookies and improve it?",
    "context": "",
    "output": "TCP Cookie Transactions (TCPCT) standard was designed to overcome the shortcomings of SYN cookies and improve it on a couple of aspects. However, TCPCT is a TCP extension and required support from both endpoints and it was moved to \"Historic\" status by RFC 7805 in 2016.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What standard was designed to overcome the shortcomings of SYN cookies and improve it?",
      "answer": "TCP Cookie Transactions (TCPCT) standard was designed to overcome the shortcomings of SYN cookies and improve it on a couple of aspects. However, TCPCT is a TCP extension and required support from both endpoints and it was moved to \"Historic\" status by RFC 7805 in 2016."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the purpose of identity assurance in online business transactions?",
    "context": "",
    "output": "The purpose of identity assurance in online business transactions is to enable entities to identify themselves remotely and reliably, and for relying parties to trust that the presented electronic identity credential truly represents the individual presenting the credential.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the purpose of identity assurance in online business transactions?",
      "answer": "The purpose of identity assurance in online business transactions is to enable entities to identify themselves remotely and reliably, and for relying parties to trust that the presented electronic identity credential truly represents the individual presenting the credential."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the difference between email phishing and spear phishing?",
    "context": "",
    "output": "Email phishing is a type of phishing attack that is not targeted and is sent in bulk to a wide audience, while spear phishing is a targeted phishing attack that uses personalized emails to trick a specific individual or organization into believing they are legitimate.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the difference between email phishing and spear phishing?",
      "answer": "Email phishing is a type of phishing attack that is not targeted and is sent in bulk to a wide audience, while spear phishing is a targeted phishing attack that uses personalized emails to trick a specific individual or organization into believing they are legitimate."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does X-KRSS differ from manual key creation in terms of key recovery?",
    "context": "",
    "output": "X-KRSS can generate the key material, making key recovery easier and more straightforward than when keys are created manually, as it eliminates the need for manual backup and recovery procedures.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does X-KRSS differ from manual key creation in terms of key recovery?",
      "answer": "X-KRSS can generate the key material, making key recovery easier and more straightforward than when keys are created manually, as it eliminates the need for manual backup and recovery procedures."
    }
  },
  {
    "instruction": "Bitdefender\n\n==Introduction==\nBitdefender is a Romanian cybersecurity technology company headquartered in Bucharest, Romania, with offices in the United States, Europe, Australia and the Middle East.The company was founded in 2001 by the current CEO and main shareholder, Florin Talpe\u0219. Bitdefender develops and delivers cybersecurity products and services, including endpoint protection, cloud and managed security, antivirus software and IoT security. Bitdefender products are distributed through partners in over 150 countries and the US market is estimated to generate more than 40% of its revenues.  As of 2020, the company employed more than 1,600 people worldwide.As of August 2021, Bitdefender was ranked 5th globally among Microsoft Windows anti-malware application vendors by market scores.\n\n== Bitdefender products ==\nBitdefender develops cybersecurity solutions for businesses and consumers. It offers a range of products and services including endpoint protection, cloud security, and managed detection & response. Its flagship product is Bitdefender Antivirus which protects against viruses, spyware, malware, phishing attacks, ransomware, and other threats.\n\n== Fighting cyber-crime ==\nBitdefender advises Europol's European Cybercrime Centre (EC3) in supporting investigations into criminal activity in cyberspace, sharing relevant data and knowledge about disruption, prevention, investigation and prosecution. The company is involved in ongoing cooperation with international law enforcement actors such as local, regional and international police offices to support the fight against crime.Bitdefender is also part of the Cybersecurity Tech Accord for a safer online world, a collaboration among global technology companies committed to protecting their customers and users and helping them defend against malicious threats.\n\n== Independent tests ==\nBitdefender has won a number of awards from AV-Comparatives, an anti-virus assessment firm.\n\n== Controversies and incidents ==\n\n\n*** Trojan.FakeAlert.5 ***\nOn March 20, 2010, computers running Bitdefender under 64-bit versions of Windows were affected by a malfunctioning update that classified every executable program as well as dll files as infected. These files were all marked as 'Trojan.FakeAlert.5' and were moved into quarantine. This action led to software and systems malfunctions that affected users around the world.  Bitdefender representatives announced the removal of the faulty update and a workaround for the users affected, except for those using the 2008 version.\n\n\n*** DarkSide ransomware ***\nIn 2021, Bitdefender was accused of self-promotion when releasing and publicly announcing a decryptor to the detriment of actual victims with regards to DarkSide, a hacking group.  In 2020, DarkSide switched their main encryption ransomware product over to an \"affiliate\" model wherein other attackers could download and use their software in exchange for a portion of the profits.  However, they introduced a bug in the process where affiliate hackers would all use the same private RSA key - meaning that a decryption package for a single target who paid the ransom would work on any target that had the ransomware installed.  Security researchers noticed and were quietly already helping victims of the software, but with no public notice, making it so that the attackers would only see an inexplicable decrease in ransom payments that could be written off as chance. At about the same time, Bitdefender researchers developed a decryptor and issued a blog post in January 2021 describing the flaw and offering the decryptor as a free download, in order to make as many organizations as possible aware of its existence to reduce the impact of Darkside ransomware attacks. This was criticized in an article in the MIT Technology Review: claiming, first, Bitdefender's program wasn't even safe - it was flawed and would \"damage\" files decrypted with it due to bugs within it. Second, the blog post tipped off DarkSide as to the nature of the flaw; DarkSide promptly patched the bug and sarcastically thanked Bitdefender for pointing it out, then went on with their campaign of extortion.  A notable incident that took place after Bitdefender's public disclosure was the Colonial Pipeline cyberattack in May 2021.  While the security researchers who had been using the flaw before acknowledge that it's probable DarkSide would eventually have noticed and fixed the issue, they still criticized Bitdefender for using the bug merely for a brief burst of publicity, rather than in the way that would most help victims of the scheme.  Bitdefender has defended their actions on their blog. The article and blog post triggered a discussion among cybersecurity professionals about the pros and cons of publicly disclosing decryptors.\n\n\n*** REvil Ransomware ***\nIn September 2021, Bitdefender published a universal decryptor utility that will help past victims of the REvil ransomware  recover their encrypted files.\n\nWhat was the name of the faulty update that affected computers running Bitdefender under 64-bit versions of Windows in 2010?",
    "context": "",
    "output": "The faulty update was classified as 'Trojan.FakeAlert.5' and led to software and systems malfunctions that affected users around the world.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was the name of the faulty update that affected computers running Bitdefender under 64-bit versions of Windows in 2010?",
      "answer": "The faulty update was classified as 'Trojan.FakeAlert.5' and led to software and systems malfunctions that affected users around the world.",
      "context": "Bitdefender\n\n==Introduction==\nBitdefender is a Romanian cybersecurity technology company headquartered in Bucharest, Romania, with offices in the United States, Europe, Australia and the Middle East.The company was founded in 2001 by the current CEO and main shareholder, Florin Talpe\u0219. Bitdefender develops and delivers cybersecurity products and services, including endpoint protection, cloud and managed security, antivirus software and IoT security. Bitdefender products are distributed through partners in over 150 countries and the US market is estimated to generate more than 40% of its revenues.  As of 2020, the company employed more than 1,600 people worldwide.As of August 2021, Bitdefender was ranked 5th globally among Microsoft Windows anti-malware application vendors by market scores.\n\n== Bitdefender products ==\nBitdefender develops cybersecurity solutions for businesses and consumers. It offers a range of products and services including endpoint protection, cloud security, and managed detection & response. Its flagship product is Bitdefender Antivirus which protects against viruses, spyware, malware, phishing attacks, ransomware, and other threats.\n\n== Fighting cyber-crime ==\nBitdefender advises Europol's European Cybercrime Centre (EC3) in supporting investigations into criminal activity in cyberspace, sharing relevant data and knowledge about disruption, prevention, investigation and prosecution. The company is involved in ongoing cooperation with international law enforcement actors such as local, regional and international police offices to support the fight against crime.Bitdefender is also part of the Cybersecurity Tech Accord for a safer online world, a collaboration among global technology companies committed to protecting their customers and users and helping them defend against malicious threats.\n\n== Independent tests ==\nBitdefender has won a number of awards from AV-Comparatives, an anti-virus assessment firm.\n\n== Controversies and incidents ==\n\n\n*** Trojan.FakeAlert.5 ***\nOn March 20, 2010, computers running Bitdefender under 64-bit versions of Windows were affected by a malfunctioning update that classified every executable program as well as dll files as infected. These files were all marked as 'Trojan.FakeAlert.5' and were moved into quarantine. This action led to software and systems malfunctions that affected users around the world.  Bitdefender representatives announced the removal of the faulty update and a workaround for the users affected, except for those using the 2008 version.\n\n\n*** DarkSide ransomware ***\nIn 2021, Bitdefender was accused of self-promotion when releasing and publicly announcing a decryptor to the detriment of actual victims with regards to DarkSide, a hacking group.  In 2020, DarkSide switched their main encryption ransomware product over to an \"affiliate\" model wherein other attackers could download and use their software in exchange for a portion of the profits.  However, they introduced a bug in the process where affiliate hackers would all use the same private RSA key - meaning that a decryption package for a single target who paid the ransom would work on any target that had the ransomware installed.  Security researchers noticed and were quietly already helping victims of the software, but with no public notice, making it so that the attackers would only see an inexplicable decrease in ransom payments that could be written off as chance. At about the same time, Bitdefender researchers developed a decryptor and issued a blog post in January 2021 describing the flaw and offering the decryptor as a free download, in order to make as many organizations as possible aware of its existence to reduce the impact of Darkside ransomware attacks. This was criticized in an article in the MIT Technology Review: claiming, first, Bitdefender's program wasn't even safe - it was flawed and would \"damage\" files decrypted with it due to bugs within it. Second, the blog post tipped off DarkSide as to the nature of the flaw; DarkSide promptly patched the bug and sarcastically thanked Bitdefender for pointing it out, then went on with their campaign of extortion.  A notable incident that took place after Bitdefender's public disclosure was the Colonial Pipeline cyberattack in May 2021.  While the security researchers who had been using the flaw before acknowledge that it's probable DarkSide would eventually have noticed and fixed the issue, they still criticized Bitdefender for using the bug merely for a brief burst of publicity, rather than in the way that would most help victims of the scheme.  Bitdefender has defended their actions on their blog. The article and blog post triggered a discussion among cybersecurity professionals about the pros and cons of publicly disclosing decryptors.\n\n\n*** REvil Ransomware ***\nIn September 2021, Bitdefender published a universal decryptor utility that will help past victims of the REvil ransomware  recover their encrypted files."
    }
  },
  {
    "instruction": "Write an answer to the following question: Is data theft always illegal?",
    "context": "",
    "output": "No, data theft is not always illegal. For example, in some jurisdictions, whistleblowing is protected by law.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Is data theft always illegal?",
      "answer": "No, data theft is not always illegal. For example, in some jurisdictions, whistleblowing is protected by law."
    }
  },
  {
    "instruction": "Resource Public Key Infrastructure\n\n==Introduction==\nResource Public Key Infrastructure (RPKI), also known as Resource Certification, is a specialized public key infrastructure (PKI) framework to support improved security for the Internet's BGP routing infrastructure.\nRPKI provides a way to connect Internet number resource information (such as Autonomous System numbers and IP addresses) to a trust anchor. The certificate structure mirrors the way in which Internet number resources are distributed. That is, resources are initially distributed by the IANA to the regional Internet registries (RIRs), who in turn distribute them to local Internet registries (LIRs), who then distribute the resources to their customers. RPKI can be used by the legitimate holders of the resources to control the operation of Internet routing protocols to prevent route hijacking and other attacks. In particular, RPKI is used to secure the Border Gateway Protocol (BGP) through BGP Route Origin Validation (ROV), as well as Neighbor Discovery Protocol (ND) for IPv6 through the Secure Neighbor Discovery protocol (SEND).\nThe RPKI architecture is documented in RFC 6480.  The RPKI specification is documented in a spread out series of RFCs: RFC 6481, RFC 6482, RFC 6483, RFC 6484, RFC 6485, RFC 6486, RFC 6487, RFC 6488, RFC 6489, RFC 6490, RFC 6491, RFC 6492, and RFC 6493. SEND is documented in RFC 6494 and RFC 6495.  These RFCs are a product of the IETF's SIDR (\"Secure Inter-Domain Routing\") working group, and are based on a threat analysis which was documented in RFC 4593. These standards cover BGP origin validation, while path validation is provided by BGPsec, which has been standardized separately in RFC 8205. Several implementations for prefix origin validation already exist.\n\n\n\n== Resource Certificates and child objects ==\nRPKI uses X.509 PKI certificates (RFC 5280) with extensions for IP addresses and AS identifiers (RFC 3779). It allows the members of regional Internet registries, known as local Internet registries (LIRs), to obtain a resource certificate listing the Internet number resources they hold. This offers them validatable proof of holdership, though the certificate does not contain identity information. Using the resource certificate, LIRs can create cryptographic attestations about the route announcements they authorise to be made with the prefixes they hold. These attestations, called Route Origin Authorizations (ROAs), are described below.\n\n\n*** Route Origin Authorizations ***\nA Route Origin Authorization (ROA) states which autonomous system (AS) is authorised to originate certain IP prefixes. In addition, it can determine the maximum length of the prefix that the AS is authorised to advertise.\n\n\n**** Maximum prefix length ****\nThe maximum prefix length is an optional field. When not defined, the AS is only authorised to advertise exactly the prefix specified. Any more specific announcement of the prefix will be considered invalid. This is a way to enforce aggregation and prevent hijacking through the announcement of a more specific prefix.\nWhen present, this specifies the length of the most specific IP prefix that the AS is authorised to advertise. For example, if the IP address prefix is 10.0.0.0/16 and the maximum length is 22, the AS is authorised to advertise any prefix under 10.0.0.0/16, as long as it is no more specific than /22. So, in this example, the AS would be authorised to advertise 10.0.0.0/16, 10.0.128.0/20 or 10.0.252.0/22, but not 10.0.255.0/24.\n\n\n**** RPKI route announcement validity ****\nWhen a ROA is created for a certain combination of origin AS and prefix, this will have an effect on the RPKI validity of one or more route announcements. They can be:\n\nVALID\nThe route announcement is covered by at least one ROA\nINVALID\nThe prefix is announced from an unauthorised AS. This means:\nThere is a ROA for this prefix for another AS, but no ROA authorising this AS; or\nThis could be a hijacking attempt\nThe announcement is more specific than is allowed by the maximum length set in a ROA that matches the prefix and AS\nUNKNOWN\nThe prefix in this announcement is not covered (or only partially covered) by an existing ROANote that invalid BGP updates may also be due to incorrectly configured ROAs.\n\n== Management ==\nThere are open source tools available to run the certificate authority and manage the resource certificate and child objects such as ROAs. In addition, the RIRs have a hosted RPKI platform available in their member portals. This allows LIRs to choose to rely on a hosted system, or run their own software.\n\n== Publication ==\nThe system does not use a single repository publication point to publish RPKI objects. Instead, the RPKI repository system consists of multiple distributed and delegated repository publication points. Each repository publication point is associated with one or more RPKI certificates' publication points. In practice this means that when running a certificate authority, an LIR can either publish all cryptographic material themselves, or they can rely on a third party for publication. When an LIR chooses to use the hosted system provided by the RIR, in principle publication is done in the RIR repository.\n\n== Validation ==\nRelying party software will fetch, cache, and validate repository data using rsync or the RPKI Repository Delta Protocol (RFC 8182).  It is important for a relying party to regularly synchronize with all the publication points to maintain a complete and timely view of repository data.  Incomplete or stale data can lead to erroneous routing decisions.\n\n== Routing decisions ==\nAfter validation of ROAs, the attestations can be compared to BGP routing and aid network operators in their decision making process. This can be done manually, but the validated prefix origin data can also be sent to a supported router using the RPKI to Router Protocol (RFC 6810), Cisco Systems offers native support on many platforms for fetching the RPKI data set and using it in the router configuration. Juniper offers support on all platforms that run version 12.2 or newer. Quagga obtains this functionality through BGP Secure Routing Extensions (BGP-SRx) or a RPKI implementation fully RFC-compliant based on RTRlib. The RTRlib provides an open source C implementation of the RTR protocol and prefix origin verification. The library is useful for developers of routing software but also for network operators. Developers can integrate the RTRlib into the BGP daemon to extend their implementation towards RPKI. Network operators may use the RTRlib to develop monitoring tools (e.g., to check the proper operation of caches or to evaluate their performance).\nRFC 6494 updates the certificate validation method of the Secure Neighbor Discovery protocol (SEND) security mechanisms for Neighbor Discovery Protocol (ND) to use RPKI for use in IPv6. It defines a SEND certificate profile utilizing a modified RFC 6487 RPKI certificate profile which must include a single RFC 3779 IP address delegation extension.\nQuestion: How does the validity of a route announcement in RPKI depend on the existence of a ROA?",
    "context": "",
    "output": "Answer: When a ROA is created for a certain combination of origin AS and prefix, it will have an effect on the RPKI validity of one or more route announcements. If there is a ROA for this prefix for another AS, but no ROA authorizing this AS, the announcement is considered invalid.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the validity of a route announcement in RPKI depend on the existence of a ROA?",
      "answer": "When a ROA is created for a certain combination of origin AS and prefix, it will have an effect on the RPKI validity of one or more route announcements. If there is a ROA for this prefix for another AS, but no ROA authorizing this AS, the announcement is considered invalid.",
      "context": "Resource Public Key Infrastructure\n\n==Introduction==\nResource Public Key Infrastructure (RPKI), also known as Resource Certification, is a specialized public key infrastructure (PKI) framework to support improved security for the Internet's BGP routing infrastructure.\nRPKI provides a way to connect Internet number resource information (such as Autonomous System numbers and IP addresses) to a trust anchor. The certificate structure mirrors the way in which Internet number resources are distributed. That is, resources are initially distributed by the IANA to the regional Internet registries (RIRs), who in turn distribute them to local Internet registries (LIRs), who then distribute the resources to their customers. RPKI can be used by the legitimate holders of the resources to control the operation of Internet routing protocols to prevent route hijacking and other attacks. In particular, RPKI is used to secure the Border Gateway Protocol (BGP) through BGP Route Origin Validation (ROV), as well as Neighbor Discovery Protocol (ND) for IPv6 through the Secure Neighbor Discovery protocol (SEND).\nThe RPKI architecture is documented in RFC 6480.  The RPKI specification is documented in a spread out series of RFCs: RFC 6481, RFC 6482, RFC 6483, RFC 6484, RFC 6485, RFC 6486, RFC 6487, RFC 6488, RFC 6489, RFC 6490, RFC 6491, RFC 6492, and RFC 6493. SEND is documented in RFC 6494 and RFC 6495.  These RFCs are a product of the IETF's SIDR (\"Secure Inter-Domain Routing\") working group, and are based on a threat analysis which was documented in RFC 4593. These standards cover BGP origin validation, while path validation is provided by BGPsec, which has been standardized separately in RFC 8205. Several implementations for prefix origin validation already exist.\n\n\n\n== Resource Certificates and child objects ==\nRPKI uses X.509 PKI certificates (RFC 5280) with extensions for IP addresses and AS identifiers (RFC 3779). It allows the members of regional Internet registries, known as local Internet registries (LIRs), to obtain a resource certificate listing the Internet number resources they hold. This offers them validatable proof of holdership, though the certificate does not contain identity information. Using the resource certificate, LIRs can create cryptographic attestations about the route announcements they authorise to be made with the prefixes they hold. These attestations, called Route Origin Authorizations (ROAs), are described below.\n\n\n*** Route Origin Authorizations ***\nA Route Origin Authorization (ROA) states which autonomous system (AS) is authorised to originate certain IP prefixes. In addition, it can determine the maximum length of the prefix that the AS is authorised to advertise.\n\n\n**** Maximum prefix length ****\nThe maximum prefix length is an optional field. When not defined, the AS is only authorised to advertise exactly the prefix specified. Any more specific announcement of the prefix will be considered invalid. This is a way to enforce aggregation and prevent hijacking through the announcement of a more specific prefix.\nWhen present, this specifies the length of the most specific IP prefix that the AS is authorised to advertise. For example, if the IP address prefix is 10.0.0.0/16 and the maximum length is 22, the AS is authorised to advertise any prefix under 10.0.0.0/16, as long as it is no more specific than /22. So, in this example, the AS would be authorised to advertise 10.0.0.0/16, 10.0.128.0/20 or 10.0.252.0/22, but not 10.0.255.0/24.\n\n\n**** RPKI route announcement validity ****\nWhen a ROA is created for a certain combination of origin AS and prefix, this will have an effect on the RPKI validity of one or more route announcements. They can be:\n\nVALID\nThe route announcement is covered by at least one ROA\nINVALID\nThe prefix is announced from an unauthorised AS. This means:\nThere is a ROA for this prefix for another AS, but no ROA authorising this AS; or\nThis could be a hijacking attempt\nThe announcement is more specific than is allowed by the maximum length set in a ROA that matches the prefix and AS\nUNKNOWN\nThe prefix in this announcement is not covered (or only partially covered) by an existing ROANote that invalid BGP updates may also be due to incorrectly configured ROAs.\n\n== Management ==\nThere are open source tools available to run the certificate authority and manage the resource certificate and child objects such as ROAs. In addition, the RIRs have a hosted RPKI platform available in their member portals. This allows LIRs to choose to rely on a hosted system, or run their own software.\n\n== Publication ==\nThe system does not use a single repository publication point to publish RPKI objects. Instead, the RPKI repository system consists of multiple distributed and delegated repository publication points. Each repository publication point is associated with one or more RPKI certificates' publication points. In practice this means that when running a certificate authority, an LIR can either publish all cryptographic material themselves, or they can rely on a third party for publication. When an LIR chooses to use the hosted system provided by the RIR, in principle publication is done in the RIR repository.\n\n== Validation ==\nRelying party software will fetch, cache, and validate repository data using rsync or the RPKI Repository Delta Protocol (RFC 8182).  It is important for a relying party to regularly synchronize with all the publication points to maintain a complete and timely view of repository data.  Incomplete or stale data can lead to erroneous routing decisions.\n\n== Routing decisions ==\nAfter validation of ROAs, the attestations can be compared to BGP routing and aid network operators in their decision making process. This can be done manually, but the validated prefix origin data can also be sent to a supported router using the RPKI to Router Protocol (RFC 6810), Cisco Systems offers native support on many platforms for fetching the RPKI data set and using it in the router configuration. Juniper offers support on all platforms that run version 12.2 or newer. Quagga obtains this functionality through BGP Secure Routing Extensions (BGP-SRx) or a RPKI implementation fully RFC-compliant based on RTRlib. The RTRlib provides an open source C implementation of the RTR protocol and prefix origin verification. The library is useful for developers of routing software but also for network operators. Developers can integrate the RTRlib into the BGP daemon to extend their implementation towards RPKI. Network operators may use the RTRlib to develop monitoring tools (e.g., to check the proper operation of caches or to evaluate their performance).\nRFC 6494 updates the certificate validation method of the Secure Neighbor Discovery protocol (SEND) security mechanisms for Neighbor Discovery Protocol (ND) to use RPKI for use in IPv6. It defines a SEND certificate profile utilizing a modified RFC 6487 RPKI certificate profile which must include a single RFC 3779 IP address delegation extension."
    }
  },
  {
    "instruction": "Write an answer to the following question: Why does MAPS fail to disambiguate the concepts of acknowledged ISP and end-users of IP addresses?",
    "context": "",
    "output": "MAPS does not provide a formal definition for acknowledged ISPs and end-users of IP addresses, making it difficult to differentiate between the two. This issue is further complicated when mailbox providers are confused with end-users of different kinds. As a result, using the DUL to block mail may lead to an obscure policy with potential global reliability issues for email delivery.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Why does MAPS fail to disambiguate the concepts of acknowledged ISP and end-users of IP addresses?",
      "answer": "MAPS does not provide a formal definition for acknowledged ISPs and end-users of IP addresses, making it difficult to differentiate between the two. This issue is further complicated when mailbox providers are confused with end-users of different kinds. As a result, using the DUL to block mail may lead to an obscure policy with potential global reliability issues for email delivery."
    }
  },
  {
    "instruction": "Data haven\n\n==Introduction==\nA data haven, like a corporate haven or tax haven, is a refuge for uninterrupted or unregulated data. Data havens are locations with legal environments that are friendly to the concept of a computer network freely holding data and even protecting its content and associated information. They tend to fit into three categories: a physical locality with weak information-system enforcement and extradition laws, a physical locality with intentionally strong protections of data, and virtual domains designed to secure data via technical means (such as encryption) regardless of any legal environment.\nTor's onion space (hidden service), HavenCo (centralized), and Freenet (decentralized) are three models of modern-day virtual data havens.\n\n== Purposes of data havens ==\nReasons for establishing data havens include access to free political speech for users in countries where censorship of the Internet is practiced.\nOther reasons can include:\n\nWhistleblowing\nDistributing software, data or speech that violates laws such as the DMCA\nCopyright infringement\nCircumventing data protection laws\nOnline gambling\nPornography\nCybercrime\n\n== History of the term ==\nThe 1978 report of the British government's Data Protection Committee expressed concern that different privacy standards in different countries would lead to the transfer of personal data to countries with weaker protections; it feared that Britain might become a \"data haven\". Also in 1978, Adrian Norman published a mock consulting study on the feasibility of setting up a company providing a wide range of data haven services, called \"Project Goldfish\".Science fiction novelist William Gibson used the term in his novels Count Zero and Mona Lisa Overdrive, as did Bruce Sterling in Islands in the Net.  The 1990s segments of Neal Stephenson's 1999 novel Cryptonomicon concern a small group of entrepreneurs attempting to create a data haven.\n\nQ: What is the role of legal environments in data havens?",
    "context": "",
    "output": "A: Legal environments play a significant role in data havens, as they are locations with legal environments that are friendly to the concept of a computer network freely holding data and even protecting its content and associated information.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of legal environments in data havens?",
      "answer": "Legal environments play a significant role in data havens, as they are locations with legal environments that are friendly to the concept of a computer network freely holding data and even protecting its content and associated information.",
      "context": "Data haven\n\n==Introduction==\nA data haven, like a corporate haven or tax haven, is a refuge for uninterrupted or unregulated data. Data havens are locations with legal environments that are friendly to the concept of a computer network freely holding data and even protecting its content and associated information. They tend to fit into three categories: a physical locality with weak information-system enforcement and extradition laws, a physical locality with intentionally strong protections of data, and virtual domains designed to secure data via technical means (such as encryption) regardless of any legal environment.\nTor's onion space (hidden service), HavenCo (centralized), and Freenet (decentralized) are three models of modern-day virtual data havens.\n\n== Purposes of data havens ==\nReasons for establishing data havens include access to free political speech for users in countries where censorship of the Internet is practiced.\nOther reasons can include:\n\nWhistleblowing\nDistributing software, data or speech that violates laws such as the DMCA\nCopyright infringement\nCircumventing data protection laws\nOnline gambling\nPornography\nCybercrime\n\n== History of the term ==\nThe 1978 report of the British government's Data Protection Committee expressed concern that different privacy standards in different countries would lead to the transfer of personal data to countries with weaker protections; it feared that Britain might become a \"data haven\". Also in 1978, Adrian Norman published a mock consulting study on the feasibility of setting up a company providing a wide range of data haven services, called \"Project Goldfish\".Science fiction novelist William Gibson used the term in his novels Count Zero and Mona Lisa Overdrive, as did Bruce Sterling in Islands in the Net.  The 1990s segments of Neal Stephenson's 1999 novel Cryptonomicon concern a small group of entrepreneurs attempting to create a data haven."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are the implications of the Computer Misuse Act 1990 on industry practices such as time-locking of software?",
    "context": "",
    "output": "The Computer Misuse Act 1990 has implications for previously relatively widespread or well-known industry practices such as time-locking of software, where functionality or whole programs are disabled to ensure that software will \"expire\" and thus no longer function.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are the implications of the Computer Misuse Act 1990 on industry practices such as time-locking of software?",
      "answer": "The Computer Misuse Act 1990 has implications for previously relatively widespread or well-known industry practices such as time-locking of software, where functionality or whole programs are disabled to ensure that software will \"expire\" and thus no longer function."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the Administrator account function in Windows NT and related systems?",
    "context": "",
    "output": "In Windows NT and related systems, a superuser is known as the Administrator account. This account may or may not exist depending on whether separation of duties has been implemented.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the Administrator account function in Windows NT and related systems?",
      "answer": "In Windows NT and related systems, a superuser is known as the Administrator account. This account may or may not exist depending on whether separation of duties has been implemented."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the goal of dominating the electromagnetic spectrum in military operations?",
    "context": "",
    "output": "The goal of dominating the electromagnetic spectrum is to disrupt all current and future communication systems, sensors, and weapons systems of the adversary, while maintaining control over friendly systems.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the goal of dominating the electromagnetic spectrum in military operations?",
      "answer": "The goal of dominating the electromagnetic spectrum is to disrupt all current and future communication systems, sensors, and weapons systems of the adversary, while maintaining control over friendly systems."
    }
  },
  {
    "instruction": "Write an answer to the following question: Who were the targets of the legal actions taken against DNSChanger?",
    "context": "",
    "output": "The legal actions taken against DNSChanger were aimed at six Estonian nationals and one Russian national, all connected to DNSChanger and Rove Digital.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Who were the targets of the legal actions taken against DNSChanger?",
      "answer": "The legal actions taken against DNSChanger were aimed at six Estonian nationals and one Russian national, all connected to DNSChanger and Rove Digital."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the FFIEC's guidance on using multi-factor authentication in business processes requiring different levels of assurance?",
    "context": "",
    "output": "The FFIEC's guidance on using multi-factor authentication in business processes requiring different levels of assurance discusses various forms of two-factor authentication and provides guidance on using them in business processes requiring different levels of assurance.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the FFIEC's guidance on using multi-factor authentication in business processes requiring different levels of assurance?",
      "answer": "The FFIEC's guidance on using multi-factor authentication in business processes requiring different levels of assurance discusses various forms of two-factor authentication and provides guidance on using them in business processes requiring different levels of assurance."
    }
  },
  {
    "instruction": "Write an answer to the following question: Why is the controversy surrounding the use of \"crypto\" for cryptocurrencies compared to the meaning of the word \"hacker\"?",
    "context": "",
    "output": "The controversy surrounding the use of \"crypto\" for cryptocurrencies is compared to the meaning of the word \"hacker\" because both terms can have multiple meanings and are used in different ways by different groups, leading to debates and controversies about their proper use.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Why is the controversy surrounding the use of \"crypto\" for cryptocurrencies compared to the meaning of the word \"hacker\"?",
      "answer": "The controversy surrounding the use of \"crypto\" for cryptocurrencies is compared to the meaning of the word \"hacker\" because both terms can have multiple meanings and are used in different ways by different groups, leading to debates and controversies about their proper use."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the current status of the Kelihos botnet?",
    "context": "",
    "output": "The current status of the Kelihos botnet is not explicitly mentioned in the given text. However, it is mentioned that Peter Yuryevich Levashov, who was allegedly involved in its operation, was extradited and pleaded guilty to related charges.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the current status of the Kelihos botnet?",
      "answer": "The current status of the Kelihos botnet is not explicitly mentioned in the given text. However, it is mentioned that Peter Yuryevich Levashov, who was allegedly involved in its operation, was extradited and pleaded guilty to related charges."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the use of a Trusted Platform Module (TPM) affect disk encryption?",
    "context": "",
    "output": "A limited number of disk encryption solutions have support for TPM, which can wrap the decryption key using the TPM and tie the hard disk drive to a particular device. This can prevent the disk from being accessed if it is removed from the device, but it can also create a single point of failure if something happens to the TPM or the motherboard.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the use of a Trusted Platform Module (TPM) affect disk encryption?",
      "answer": "A limited number of disk encryption solutions have support for TPM, which can wrap the decryption key using the TPM and tie the hard disk drive to a particular device. This can prevent the disk from being accessed if it is removed from the device, but it can also create a single point of failure if something happens to the TPM or the motherboard."
    }
  },
  {
    "instruction": "Context: Supervisor Mode Access Prevention\n\n==Introduction==\nSupervisor Mode Access Prevention (SMAP) is a feature of some CPU implementations such as the Intel Broadwell microarchitecture that allows supervisor mode programs to optionally set user-space memory mappings so that access to those mappings from supervisor mode will cause a trap. This makes it harder for malicious programs to \"trick\" the kernel into using instructions or data from a user-space program.\n\n== Benefits ==\nWithout Supervisor Mode Access Prevention, supervisor code usually has full read and write access to user-space memory mappings (or has the ability to obtain full access). This has led to the development of several security exploits, including privilege escalation exploits, which operate by causing the kernel to access user-space memory when it did not intend to. Operating systems can block these exploits by using SMAP to force unintended user-space memory accesses to trigger page faults. Additionally, SMAP can expose flawed kernel code which does not follow the intended procedures for accessing user-space memory.However, the use of SMAP in an operating system may lead to a larger kernel size and slower user-space memory accesses from supervisor code, because SMAP must be temporarily disabled any time supervisor code intends to access user-space memory.\n\n== Technical details ==\nProcessors indicate support for Supervisor Mode Access Prevention through the Extended Features CPUID leaf.\nSMAP is enabled when memory paging is active and the SMAP bit in the CR4 control register is set. SMAP can be temporarily disabled for explicit memory accesses by setting the EFLAGS.AC (Alignment Check) flag. The stac (Set AC Flag) and clac (Clear AC Flag) instructions can be used to easily set or clear the flag.When the SMAP bit in CR4 is set, explicit memory reads and writes to user-mode pages performed by code running with a privilege level less than 3 will always result in a page fault if the EFLAGS.AC flag is not set. Implicit reads and writes (such as those made to descriptor tables) to user-mode pages will always trigger a page fault if SMAP is enabled, regardless of the value of EFLAGS.AC.\n\n== Operating system support ==\nLinux kernel support for Supervisor Mode Access Prevention was implemented by H. Peter Anvin. It was merged into the mainline Linux 3.7 kernel and it is enabled by default for processors which support the feature.FreeBSD has supported Supervisor Mode Execution Prevention since 2012 and Supervisor Mode Access Prevention since 2018.OpenBSD has supported Supervisor Mode Access Prevention and the related Supervisor Mode Execution Prevention since 2012, with OpenBSD 5.3 being the first release with support for the feature enabled.NetBSD support for Supervisor Mode Execution Prevention (SMEP) was implemented by Maxime Villard in December 2015. Support for Supervisor Mode Access Prevention (SMAP) was also implemented by Maxime Villard, in August 2017. NetBSD 8.0  was the first release with both features supported and enabled.Haiku support for Supervisor Mode Execution Prevention (SMEP) was implemented by J\u00e9r\u00f4me Duval in January 2018.macOS has support for SMAP at least since macOS 10.13 released 2017.\nAnswer this question: How can operating systems utilize SMAP to block security exploits?",
    "context": "",
    "output": "Operating systems can use SMAP to force unintended user-space memory accesses to trigger page faults, thereby blocking security exploits such as privilege escalation attacks.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can operating systems utilize SMAP to block security exploits?",
      "answer": "Operating systems can use SMAP to force unintended user-space memory accesses to trigger page faults, thereby blocking security exploits such as privilege escalation attacks.",
      "context": "Supervisor Mode Access Prevention\n\n==Introduction==\nSupervisor Mode Access Prevention (SMAP) is a feature of some CPU implementations such as the Intel Broadwell microarchitecture that allows supervisor mode programs to optionally set user-space memory mappings so that access to those mappings from supervisor mode will cause a trap. This makes it harder for malicious programs to \"trick\" the kernel into using instructions or data from a user-space program.\n\n== Benefits ==\nWithout Supervisor Mode Access Prevention, supervisor code usually has full read and write access to user-space memory mappings (or has the ability to obtain full access). This has led to the development of several security exploits, including privilege escalation exploits, which operate by causing the kernel to access user-space memory when it did not intend to. Operating systems can block these exploits by using SMAP to force unintended user-space memory accesses to trigger page faults. Additionally, SMAP can expose flawed kernel code which does not follow the intended procedures for accessing user-space memory.However, the use of SMAP in an operating system may lead to a larger kernel size and slower user-space memory accesses from supervisor code, because SMAP must be temporarily disabled any time supervisor code intends to access user-space memory.\n\n== Technical details ==\nProcessors indicate support for Supervisor Mode Access Prevention through the Extended Features CPUID leaf.\nSMAP is enabled when memory paging is active and the SMAP bit in the CR4 control register is set. SMAP can be temporarily disabled for explicit memory accesses by setting the EFLAGS.AC (Alignment Check) flag. The stac (Set AC Flag) and clac (Clear AC Flag) instructions can be used to easily set or clear the flag.When the SMAP bit in CR4 is set, explicit memory reads and writes to user-mode pages performed by code running with a privilege level less than 3 will always result in a page fault if the EFLAGS.AC flag is not set. Implicit reads and writes (such as those made to descriptor tables) to user-mode pages will always trigger a page fault if SMAP is enabled, regardless of the value of EFLAGS.AC.\n\n== Operating system support ==\nLinux kernel support for Supervisor Mode Access Prevention was implemented by H. Peter Anvin. It was merged into the mainline Linux 3.7 kernel and it is enabled by default for processors which support the feature.FreeBSD has supported Supervisor Mode Execution Prevention since 2012 and Supervisor Mode Access Prevention since 2018.OpenBSD has supported Supervisor Mode Access Prevention and the related Supervisor Mode Execution Prevention since 2012, with OpenBSD 5.3 being the first release with support for the feature enabled.NetBSD support for Supervisor Mode Execution Prevention (SMEP) was implemented by Maxime Villard in December 2015. Support for Supervisor Mode Access Prevention (SMAP) was also implemented by Maxime Villard, in August 2017. NetBSD 8.0  was the first release with both features supported and enabled.Haiku support for Supervisor Mode Execution Prevention (SMEP) was implemented by J\u00e9r\u00f4me Duval in January 2018.macOS has support for SMAP at least since macOS 10.13 released 2017."
    }
  },
  {
    "instruction": "Write an answer to the following question: How is a delegated credential generated and used in TLS?",
    "context": "",
    "output": "A delegated credential is a short-lived key (from a few hours to a few days) that the certificate's owner delegates to the server for use in TLS. It is generated by signing a delegated public key and an expiration time using the certificate's private key, and is then used by the server to establish a secure connection with a browser.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How is a delegated credential generated and used in TLS?",
      "answer": "A delegated credential is a short-lived key (from a few hours to a few days) that the certificate's owner delegates to the server for use in TLS. It is generated by signing a delegated public key and an expiration time using the certificate's private key, and is then used by the server to establish a secure connection with a browser."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the consequence of a malicious user exploiting a symlink race vulnerability in the example given?",
    "context": "",
    "output": "In the example given, a malicious user exploiting a symlink race vulnerability can potentially gain access to sensitive information such as passwords, allowing them to log into the computer as the superuser.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the consequence of a malicious user exploiting a symlink race vulnerability in the example given?",
      "answer": "In the example given, a malicious user exploiting a symlink race vulnerability can potentially gain access to sensitive information such as passwords, allowing them to log into the computer as the superuser."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does ISO/IEC 27001 address information security risks?",
    "context": "",
    "output": "ISO/IEC 27001 requires organizations to systematically examine their information security risks, taking into account threats, vulnerabilities, and impacts, and to design and implement a coherent and comprehensive suite of information security controls to address unacceptable risks.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does ISO/IEC 27001 address information security risks?",
      "answer": "ISO/IEC 27001 requires organizations to systematically examine their information security risks, taking into account threats, vulnerabilities, and impacts, and to design and implement a coherent and comprehensive suite of information security controls to address unacceptable risks."
    }
  },
  {
    "instruction": "Write an answer to the following question: How did the PlayStation Network problems relate to the hacker's attacks?",
    "context": "",
    "output": "The PlayStation Network problems were not directly related to the hacker's attacks, but were instead attributed to an influx of new PS4 owners and increased holiday online activity.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How did the PlayStation Network problems relate to the hacker's attacks?",
      "answer": "The PlayStation Network problems were not directly related to the hacker's attacks, but were instead attributed to an influx of new PS4 owners and increased holiday online activity."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does encryption impact digital forensic efforts?",
    "context": "",
    "output": "Encryption, a commonly used anti-forensic technique, can make data virtually impossible to read without the designated key. This leaves important information, such as file name, size, and timestamps, unencrypted, but still makes a successful forensic investigation challenging.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does encryption impact digital forensic efforts?",
      "answer": "Encryption, a commonly used anti-forensic technique, can make data virtually impossible to read without the designated key. This leaves important information, such as file name, size, and timestamps, unencrypted, but still makes a successful forensic investigation challenging."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are the four modes of operation supported by Ettercap?",
    "context": "",
    "output": "The four modes of operation supported by Ettercap are IP-based, MAC-based, ARP-based, and PublicARP-based. These modes filter packets based on IP addresses, MAC addresses, or use ARP poisoning for sniffing on a switched LAN.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are the four modes of operation supported by Ettercap?",
      "answer": "The four modes of operation supported by Ettercap are IP-based, MAC-based, ARP-based, and PublicARP-based. These modes filter packets based on IP addresses, MAC addresses, or use ARP poisoning for sniffing on a switched LAN."
    }
  },
  {
    "instruction": "Write an answer to the following question: Why must applications be specifically coded to support Kerberos when using pam_krb5?",
    "context": "",
    "output": "pam_krb5 cannot itself get service tickets, so applications must be specifically coded to support Kerberos to fetch a service ticket for a particular application without prompting the user to enter credentials again.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Why must applications be specifically coded to support Kerberos when using pam_krb5?",
      "answer": "pam_krb5 cannot itself get service tickets, so applications must be specifically coded to support Kerberos to fetch a service ticket for a particular application without prompting the user to enter credentials again."
    }
  },
  {
    "instruction": "Write an answer to the following question: Can PMAC be used for real-time applications?",
    "context": "",
    "output": "Yes, PMAC can be used for real-time applications due to its parallelizable nature, which allows for faster processing times and better performance.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Can PMAC be used for real-time applications?",
      "answer": "Yes, PMAC can be used for real-time applications due to its parallelizable nature, which allows for faster processing times and better performance."
    }
  },
  {
    "instruction": "Write an answer to the following question: How can key logging or acoustic cryptanalysis be used to guess or copy the master password?",
    "context": "",
    "output": "Key logging involves recording every keystroke made on a keyboard, which can be used to guess or copy the master password. Acoustic cryptanalysis involves using the sounds made by a keyboard to guess or copy the master password.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can key logging or acoustic cryptanalysis be used to guess or copy the master password?",
      "answer": "Key logging involves recording every keystroke made on a keyboard, which can be used to guess or copy the master password. Acoustic cryptanalysis involves using the sounds made by a keyboard to guess or copy the master password."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are the disadvantages of using transparent proxies for web surfing?",
    "context": "",
    "output": "Transparent proxies do not offer any security or privacy benefits for web surfing, as they change request fields and reveal the user's real IP address.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are the disadvantages of using transparent proxies for web surfing?",
      "answer": "Transparent proxies do not offer any security or privacy benefits for web surfing, as they change request fields and reveal the user's real IP address."
    }
  },
  {
    "instruction": "SpyHunter (software)\n\n==Introduction==\nSpyHunter is an anti-spyware computer program for the Microsoft Windows (Windows XP and later) operating system. It is designed to remove malware, such as trojan horses, computer worms, rootkits, and other malicious software.\n\n\n\n== Details ==\nSpyHunter is currently at version 5, and receives daily definition updates. SpyHunter has a free version, which allows the user to scan their computer. Purchase is required to remove found malware. EnigmaSoftware also offers a service on its website called \"ESG MalwareTracker\", it shows the most infected countries where SpyHunter has detected malware.In the paid version, the user is able to receive support from a built-in HelpDesk. SpyHunter also has a custom fix from the Spyware Helpdesk team.\n\n== Lawsuits ==\nIn February 2016, Enigma Software filed a lawsuit against Bleeping Computer, a computer support website. It alleged that the latter engaged in a smear campaign with the purpose of driving potential customers away from SpyHunter to affiliate competing products. In turn, Bleeping Computer filed a lawsuit against Enigma Software also for an alleged smear campaign. In March 2017, Enigma Software announced in a press release that a settlement had been reached in the lawsuit against Bleeping Computer, and that both cases would be dismissed.In October 2016, Enigma Software filed a lawsuit against popular security software vendor, Malwarebytes, for anti-competitive behavior. The lawsuit arose after Malwarebytes' software began targeting SpyHunter as a potentially unwanted program. On November 7, 2017, Enigma's case was dismissed by the US District Court. Engima appealed to the United States Court of Appeals for the Ninth Circuit and the court reversed the lower court's decision. A panel of judges voted 2-1 that, \"We hold that the phrase \"otherwise objectionable\" does not include software that the provider finds objectionable for anti-competitive reasons.\" Despite this, Malwarebytes won the case on its merits after the Supreme Court denied their writ of certiorari on the immunity issue.\n\n== Controversies ==\nSpyHunter is often labeled an Potentially Unwanted Program due to its misleading results of always showing infections, including on clean computers, and injects tracking cookies into a users browser, raising concern whether it is legitimate or not. The company also floods web search results when searching for a specific threat, linking a download to SpyHunter, even if the product is not able to remove it.\n\nQ: How does SpyHunter affect web search results when searching for a specific threat?",
    "context": "",
    "output": "A: SpyHunter floods web search results when searching for a specific threat, linking a download to SpyHunter, even if the product is not able to remove it.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does SpyHunter affect web search results when searching for a specific threat?",
      "answer": "SpyHunter floods web search results when searching for a specific threat, linking a download to SpyHunter, even if the product is not able to remove it.",
      "context": "SpyHunter (software)\n\n==Introduction==\nSpyHunter is an anti-spyware computer program for the Microsoft Windows (Windows XP and later) operating system. It is designed to remove malware, such as trojan horses, computer worms, rootkits, and other malicious software.\n\n\n\n== Details ==\nSpyHunter is currently at version 5, and receives daily definition updates. SpyHunter has a free version, which allows the user to scan their computer. Purchase is required to remove found malware. EnigmaSoftware also offers a service on its website called \"ESG MalwareTracker\", it shows the most infected countries where SpyHunter has detected malware.In the paid version, the user is able to receive support from a built-in HelpDesk. SpyHunter also has a custom fix from the Spyware Helpdesk team.\n\n== Lawsuits ==\nIn February 2016, Enigma Software filed a lawsuit against Bleeping Computer, a computer support website. It alleged that the latter engaged in a smear campaign with the purpose of driving potential customers away from SpyHunter to affiliate competing products. In turn, Bleeping Computer filed a lawsuit against Enigma Software also for an alleged smear campaign. In March 2017, Enigma Software announced in a press release that a settlement had been reached in the lawsuit against Bleeping Computer, and that both cases would be dismissed.In October 2016, Enigma Software filed a lawsuit against popular security software vendor, Malwarebytes, for anti-competitive behavior. The lawsuit arose after Malwarebytes' software began targeting SpyHunter as a potentially unwanted program. On November 7, 2017, Enigma's case was dismissed by the US District Court. Engima appealed to the United States Court of Appeals for the Ninth Circuit and the court reversed the lower court's decision. A panel of judges voted 2-1 that, \"We hold that the phrase \"otherwise objectionable\" does not include software that the provider finds objectionable for anti-competitive reasons.\" Despite this, Malwarebytes won the case on its merits after the Supreme Court denied their writ of certiorari on the immunity issue.\n\n== Controversies ==\nSpyHunter is often labeled an Potentially Unwanted Program due to its misleading results of always showing infections, including on clean computers, and injects tracking cookies into a users browser, raising concern whether it is legitimate or not. The company also floods web search results when searching for a specific threat, linking a download to SpyHunter, even if the product is not able to remove it."
    }
  },
  {
    "instruction": "Context: DenyHosts\n\n==Introduction==\nDenyHosts is a log-based intrusion-prevention security tool for SSH servers written in Python. It is intended to prevent brute-force attacks on SSH servers by monitoring invalid login attempts in the authentication log and blocking the originating IP addresses. DenyHosts is developed by Phil Schwartz, who is also the developer of Kodos Python Regular Expression Debugger.\n\n\n\n== Operation ==\nDenyHosts checks the end of the authentication log for recent failed login attempts. It records information about their originating IP addresses and compares the number of invalid attempts to a user-specified threshold. If there have been too many invalid attempts it assumes a dictionary attack is occurring and prevents the IP address from making any further attempts by adding it to /etc/hosts.deny on the server. DenyHosts 2.0 and above support centralized synchronization, so that repeat offenders are blocked from many computers. The site denyhosts.net gathers statistics from computers running the software.\nDenyHosts is restricted to connections using IPv4. It does not work with IPv6.\nDenyHosts may be run manually, as a daemon, or as a cron job.\n\n== Discoveries ==\nIn July 2007, The Register reported that from May until July that year, \"compromised computers\" at Oracle UK were listed among the ten worst offenders for launching brute force SSH attacks on the Internet, according to public DenyHosts listings. After an investigation, Oracle denied suggestions that any of its computers had been compromised.\n\n== Vulnerabilities ==\nDaniel B. Cid wrote a paper showing that DenyHosts, as well the similar programs Fail2ban and BlockHosts, were vulnerable to remote log injection, an attack technique similar to SQL injection, in which a specially crafted user name is used to trigger a block against a site chosen by the attacker. This was fixed in version 2.6.\n\n== Forks and descendants ==\nSince there had been no further development by the original author Phil Schwartz after the release of version 2.6 (December 2006) and claimed version 2.7 (November 2008) for which no actual downloadable package is available, development was first continued in February 2012 by Matt Ruffalo in a GitHub repository. An independent and separate fork was started at the almost-identically named DenyHost SourceForge project site with the release of a different version 2.7 in May 2014. After version 2.9, the new SourceForge project has merged with the earlier GitHub repository, and newer versions are available via both means.\nThe software that runs the centralized synchronization server which DenyHosts versions 2.0 and above can use, has never been released. Independent synchronization server software has been developed by Jan-Pascal van Best since June 2015.\n\nQuestion: How can users run DenyHosts, and what are the available modes?\n\nAnswer:",
    "context": "",
    "output": "DenyHosts can be run manually, as a daemon, or as a cron job. These modes offer flexibility for users to manage and schedule the tool's operations.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can users run DenyHosts, and what are the available modes?",
      "answer": "DenyHosts can be run manually, as a daemon, or as a cron job. These modes offer flexibility for users to manage and schedule the tool's operations.",
      "context": "DenyHosts\n\n==Introduction==\nDenyHosts is a log-based intrusion-prevention security tool for SSH servers written in Python. It is intended to prevent brute-force attacks on SSH servers by monitoring invalid login attempts in the authentication log and blocking the originating IP addresses. DenyHosts is developed by Phil Schwartz, who is also the developer of Kodos Python Regular Expression Debugger.\n\n\n\n== Operation ==\nDenyHosts checks the end of the authentication log for recent failed login attempts. It records information about their originating IP addresses and compares the number of invalid attempts to a user-specified threshold. If there have been too many invalid attempts it assumes a dictionary attack is occurring and prevents the IP address from making any further attempts by adding it to /etc/hosts.deny on the server. DenyHosts 2.0 and above support centralized synchronization, so that repeat offenders are blocked from many computers. The site denyhosts.net gathers statistics from computers running the software.\nDenyHosts is restricted to connections using IPv4. It does not work with IPv6.\nDenyHosts may be run manually, as a daemon, or as a cron job.\n\n== Discoveries ==\nIn July 2007, The Register reported that from May until July that year, \"compromised computers\" at Oracle UK were listed among the ten worst offenders for launching brute force SSH attacks on the Internet, according to public DenyHosts listings. After an investigation, Oracle denied suggestions that any of its computers had been compromised.\n\n== Vulnerabilities ==\nDaniel B. Cid wrote a paper showing that DenyHosts, as well the similar programs Fail2ban and BlockHosts, were vulnerable to remote log injection, an attack technique similar to SQL injection, in which a specially crafted user name is used to trigger a block against a site chosen by the attacker. This was fixed in version 2.6.\n\n== Forks and descendants ==\nSince there had been no further development by the original author Phil Schwartz after the release of version 2.6 (December 2006) and claimed version 2.7 (November 2008) for which no actual downloadable package is available, development was first continued in February 2012 by Matt Ruffalo in a GitHub repository. An independent and separate fork was started at the almost-identically named DenyHost SourceForge project site with the release of a different version 2.7 in May 2014. After version 2.9, the new SourceForge project has merged with the earlier GitHub repository, and newer versions are available via both means.\nThe software that runs the centralized synchronization server which DenyHosts versions 2.0 and above can use, has never been released. Independent synchronization server software has been developed by Jan-Pascal van Best since June 2015."
    }
  },
  {
    "instruction": "ZoneAlarm Z100G\n\n==Introduction==\nZoneAlarm Secure Wireless Router Z100G is a discontinued Unified Threat Management security router for the home and SOHO market.\nThe Z100G was developed by SofaWare Technologies, a Check Point Company. The hardware is similar to SofaWare's Safe@Office and VPN-1 Edge lines, and the software differs only in what features the license allows the user to access and to what degree.\n\n== Features ==\nZoneAlarm Z100G provides networking and security related features, including -\n\nRouter with 4 Fast Ethernet LAN ports and one WAN port.\nWireless access point with 108 Mbit/s Super G and Extended Range (XR) technologies.\nStateful Inspection Firewall\nRemote Access VPN for a single user at a time\nIntrusion Prevention IPS\nGateway Antivirus\nWeb filtering\nUSB 2.0 Print Server\nSecurity Reporting\nIntegrated ActiveX Remote Desktop client to connect to internal computers\n\n== Performance ==\nFirewall Throughput - 70 Mbit/s\nVPN Throughput - 5 Mbit/s (AES)\nConcurrent Firewall Connections - 4,000\n\nDoes ZoneAlarm Z100G provide a print server? If so, what type?",
    "context": "",
    "output": "A: Yes, ZoneAlarm Z100G provides a USB 2.0 Print Server.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Does ZoneAlarm Z100G provide a print server? If so, what type?",
      "answer": "Yes, ZoneAlarm Z100G provides a USB 2.0 Print Server.",
      "context": "ZoneAlarm Z100G\n\n==Introduction==\nZoneAlarm Secure Wireless Router Z100G is a discontinued Unified Threat Management security router for the home and SOHO market.\nThe Z100G was developed by SofaWare Technologies, a Check Point Company. The hardware is similar to SofaWare's Safe@Office and VPN-1 Edge lines, and the software differs only in what features the license allows the user to access and to what degree.\n\n== Features ==\nZoneAlarm Z100G provides networking and security related features, including -\n\nRouter with 4 Fast Ethernet LAN ports and one WAN port.\nWireless access point with 108 Mbit/s Super G and Extended Range (XR) technologies.\nStateful Inspection Firewall\nRemote Access VPN for a single user at a time\nIntrusion Prevention IPS\nGateway Antivirus\nWeb filtering\nUSB 2.0 Print Server\nSecurity Reporting\nIntegrated ActiveX Remote Desktop client to connect to internal computers\n\n== Performance ==\nFirewall Throughput - 70 Mbit/s\nVPN Throughput - 5 Mbit/s (AES)\nConcurrent Firewall Connections - 4,000"
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the Indian Supreme Court view the interception of telecommunications in India?",
    "context": "",
    "output": "The Indian Supreme Court has upheld the constitutional validity of interceptions and monitoring under Section 5(2) of the Act through its order dated 18.12.1996 in Writ Petition (C) No.256/1991 by People's Union for Civil Liberties (PUCL) Vs. Union of India. The court has held that telephone tapping would infringe the Right to Life and Right to Freedom of Speech & Expression enshrined in Articles 21 and 19(1)(a) respectively of the Constitution of India, unless it is permitted under the procedure established by law. The court further observed that Section 5(2) of the Act clearly provides that \u2018occurrence of any public emergency\u2019 or \u2018interest of public safety\u2019 is a sine qua non for the application of these provisions.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the Indian Supreme Court view the interception of telecommunications in India?",
      "answer": "The Indian Supreme Court has upheld the constitutional validity of interceptions and monitoring under Section 5(2) of the Act through its order dated 18.12.1996 in Writ Petition (C) No.256/1991 by People's Union for Civil Liberties (PUCL) Vs. Union of India. The court has held that telephone tapping would infringe the Right to Life and Right to Freedom of Speech & Expression enshrined in Articles 21 and 19(1)(a) respectively of the Constitution of India, unless it is permitted under the procedure established by law. The court further observed that Section 5(2) of the Act clearly provides that \u2018occurrence of any public emergency\u2019 or \u2018interest of public safety\u2019 is a sine qua non for the application of these provisions."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the concept of product ciphers enhance the security of cryptographic systems?",
    "context": "",
    "output": "Product ciphers combine two or more transformations, such as substitution, permutation, and modular arithmetic, to create a more secure encryption system than the individual components. This combination helps resist cryptanalysis, making it harder for unauthorized parties to decipher the encrypted data. Claude Shannon first introduced this idea in his paper, Communication Theory of Secrecy Systems.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the concept of product ciphers enhance the security of cryptographic systems?",
      "answer": "Product ciphers combine two or more transformations, such as substitution, permutation, and modular arithmetic, to create a more secure encryption system than the individual components. This combination helps resist cryptanalysis, making it harder for unauthorized parties to decipher the encrypted data. Claude Shannon first introduced this idea in his paper, Communication Theory of Secrecy Systems."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the University of Michigan's scanner affect the anonymity provided by the Tor network?",
    "context": "",
    "output": "The University of Michigan's scanner can detect almost 90% of live bridges in a single scan, compromising the anonymity provided by the Tor network.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the University of Michigan's scanner affect the anonymity provided by the Tor network?",
      "answer": "The University of Michigan's scanner can detect almost 90% of live bridges in a single scan, compromising the anonymity provided by the Tor network."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is user behavior analytics and how can it be used to prevent cyberattacks?",
    "context": "",
    "output": "User behavior analytics is the use of data analytics to detect anomalies in user behavior that may indicate a potential cyberattack. It can be used in conjunction with Security Information and Event Management (SIEM) systems to help prevent cyberattacks.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is user behavior analytics and how can it be used to prevent cyberattacks?",
      "answer": "User behavior analytics is the use of data analytics to detect anomalies in user behavior that may indicate a potential cyberattack. It can be used in conjunction with Security Information and Event Management (SIEM) systems to help prevent cyberattacks."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the Mullvad browser differ from the Tor Browser in terms of functionality?",
    "context": "",
    "output": "The Mullvad browser works independently of the Tor network and is meant to be used with a VPN service instead.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the Mullvad browser differ from the Tor Browser in terms of functionality?",
      "answer": "The Mullvad browser works independently of the Tor network and is meant to be used with a VPN service instead."
    }
  },
  {
    "instruction": "Virus hoax\n\n==Introduction==\nA computer virus hoax is a message warning the recipients of a non-existent computer virus threat. The message is usually a chain e-mail that tells the recipients to forward it to everyone they know, but it can also be in the form of a pop-up window.\n\n\n\n== Identification ==\nMost hoaxes are sensational in nature and easily identified by the fact that they indicate that the virus will do nearly impossible things, like blow up the recipient's computer and set it on fire, or less sensationally, delete everything on the user's computer. They often include fake announcements claimed to originate from reputable computer organizations together with mainstream news media. These bogus sources are quoted in order to give the hoax more credibility. Typically, the warnings use emotive language, stress the urgent nature of the threat and encourage readers to forward the message to other people as soon as possible.Virus hoaxes are usually harmless and accomplish nothing more than annoying people who identify it as a hoax and wasting the time of people who forward the message. Nevertheless, a number of hoaxes have warned users that vital system files are viruses and encourage the user to delete the file, possibly damaging the system. Examples of this type include the jdbgmgr.exe virus hoax and the SULFNBK.EXE hoax.Some consider virus hoaxes and other chain e-mails to be a computer worm in and of themselves. They replicate by social engineering\u2014exploiting users' concern, ignorance, and disinclination to investigate before acting.\nHoaxes are distinct from computer pranks, which are harmless programs that perform unwanted and annoying actions on a computer, such as randomly moving the mouse, turning the screen display upside down, etc.\n\n== Action ==\nAnti-virus specialists agree that recipients should delete virus hoaxes when they receive them, instead of forwarding them.McAfee says:\n\nWe are advising users who receive the email to delete it and DO NOT pass it on as this is how an email HOAX propagates. \nF-Secure recommends:\n\nDo not forward hoax messages.\nHoax warnings are typically scare alerts started by malicious people \u2013 and passed on by innocent individuals that think they are helping the community by spreading the warning.\n\nCorporate users can get rid of the hoax problem by simply setting a strict company guideline: End users must not forward virus alarms. Ever. It's not the job of an end user anyway. If such message is received, end users could forward it to the IT department but not to anyone else.\n\n== Comparison ==\n\n== Telephone scam ==\n\nA telephone scam, commonly operated from call centres based in India, has been active since 2008. The victim is quoted his or her name and address, and is told: \"I'm calling for Microsoft (or an entity that sounds like it is connected to Microsoft, such as the \"Windows Service Center\" or \"Windows Technical Department\"). We've had a report from your internet service provider of serious virus problems from your Windows computer.\" The victim is then directed to open the Windows event viewer, which displays apparently critical warnings, and is directed to a website to download an application to allow the scammer to control his or her computer remotely.  The caller supposedly fixes the problems and demands a fee for the service.  In addition to the fraudulent fee, the process usually enables malware to be uploaded to the victim's computer.\n\n== Parodies ==\nThe virus hoax has become part of the culture of the twenty-first century and the gullibility of novice computer users convinced to delete files on the basis of hoaxes has been parodied in several popular jokes and songs.\nOne such parody is \"Weird Al\" Yankovic's song \"Virus Alert\" from the album Straight Outta Lynwood. The song makes fun of the exaggerated claims that are made in virus hoaxes, such as legally changing your name or opening a rift in time and space.Another parody of virus hoaxes is the honor system virus which has been circulated under the name Amish Computer Virus, manual virus, the Blond Computer Virus, the Irish Computer Virus, the Syrian Computer Virus, the Norwegian Computer Virus, Albanian Virus, Newfie Virus, the Unix Computer Virus, the Mac OS 9 virus, Discount virus and many others. This joke email claims to be authored by the Amish or other similar low-technology populations who have no computers, programming skills or electricity to create viruses and thus ask users to delete their own hard drive contents manually after forwarding the message to their friends.The Tuxissa virus is another parody of the virus hoax, based on the concept of the Melissa virus, but with its aim of installing Linux on the victim's computer without the owner's permission. The story says that it was spread via e-mail, contained in a message titled \"Important Message About Windows Security\". It was supposed to first spread the virus to other computers, then download a stripped-down version of Slackware and uncompress it onto the hard disk. The Windows Registry is finally deleted and the boot options changed. The virus then reboots the computer, leaving the user facing the Linux login prompt with all their Windows security problems solved.\n\nQ: How do virus hoaxes differ from computer pranks and what are the potential consequences of each?",
    "context": "",
    "output": "A: Virus hoaxes and computer pranks both involve the use of technology to play a trick on someone, but they differ in their potential consequences. A virus hoax is a false warning about a non-existent virus threat, while a computer prank is a harmless program that performs unwanted and annoying actions on a computer. A virus hoax has the potential to cause harm by encouraging users to delete vital system files, while a computer prank is generally harmless and only serves to annoy the recipient.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do virus hoaxes differ from computer pranks and what are the potential consequences of each?",
      "answer": "Virus hoaxes and computer pranks both involve the use of technology to play a trick on someone, but they differ in their potential consequences. A virus hoax is a false warning about a non-existent virus threat, while a computer prank is a harmless program that performs unwanted and annoying actions on a computer. A virus hoax has the potential to cause harm by encouraging users to delete vital system files, while a computer prank is generally harmless and only serves to annoy the recipient.",
      "context": "Virus hoax\n\n==Introduction==\nA computer virus hoax is a message warning the recipients of a non-existent computer virus threat. The message is usually a chain e-mail that tells the recipients to forward it to everyone they know, but it can also be in the form of a pop-up window.\n\n\n\n== Identification ==\nMost hoaxes are sensational in nature and easily identified by the fact that they indicate that the virus will do nearly impossible things, like blow up the recipient's computer and set it on fire, or less sensationally, delete everything on the user's computer. They often include fake announcements claimed to originate from reputable computer organizations together with mainstream news media. These bogus sources are quoted in order to give the hoax more credibility. Typically, the warnings use emotive language, stress the urgent nature of the threat and encourage readers to forward the message to other people as soon as possible.Virus hoaxes are usually harmless and accomplish nothing more than annoying people who identify it as a hoax and wasting the time of people who forward the message. Nevertheless, a number of hoaxes have warned users that vital system files are viruses and encourage the user to delete the file, possibly damaging the system. Examples of this type include the jdbgmgr.exe virus hoax and the SULFNBK.EXE hoax.Some consider virus hoaxes and other chain e-mails to be a computer worm in and of themselves. They replicate by social engineering\u2014exploiting users' concern, ignorance, and disinclination to investigate before acting.\nHoaxes are distinct from computer pranks, which are harmless programs that perform unwanted and annoying actions on a computer, such as randomly moving the mouse, turning the screen display upside down, etc.\n\n== Action ==\nAnti-virus specialists agree that recipients should delete virus hoaxes when they receive them, instead of forwarding them.McAfee says:\n\nWe are advising users who receive the email to delete it and DO NOT pass it on as this is how an email HOAX propagates. \nF-Secure recommends:\n\nDo not forward hoax messages.\nHoax warnings are typically scare alerts started by malicious people \u2013 and passed on by innocent individuals that think they are helping the community by spreading the warning.\n\nCorporate users can get rid of the hoax problem by simply setting a strict company guideline: End users must not forward virus alarms. Ever. It's not the job of an end user anyway. If such message is received, end users could forward it to the IT department but not to anyone else.\n\n== Comparison ==\n\n== Telephone scam ==\n\nA telephone scam, commonly operated from call centres based in India, has been active since 2008. The victim is quoted his or her name and address, and is told: \"I'm calling for Microsoft (or an entity that sounds like it is connected to Microsoft, such as the \"Windows Service Center\" or \"Windows Technical Department\"). We've had a report from your internet service provider of serious virus problems from your Windows computer.\" The victim is then directed to open the Windows event viewer, which displays apparently critical warnings, and is directed to a website to download an application to allow the scammer to control his or her computer remotely.  The caller supposedly fixes the problems and demands a fee for the service.  In addition to the fraudulent fee, the process usually enables malware to be uploaded to the victim's computer.\n\n== Parodies ==\nThe virus hoax has become part of the culture of the twenty-first century and the gullibility of novice computer users convinced to delete files on the basis of hoaxes has been parodied in several popular jokes and songs.\nOne such parody is \"Weird Al\" Yankovic's song \"Virus Alert\" from the album Straight Outta Lynwood. The song makes fun of the exaggerated claims that are made in virus hoaxes, such as legally changing your name or opening a rift in time and space.Another parody of virus hoaxes is the honor system virus which has been circulated under the name Amish Computer Virus, manual virus, the Blond Computer Virus, the Irish Computer Virus, the Syrian Computer Virus, the Norwegian Computer Virus, Albanian Virus, Newfie Virus, the Unix Computer Virus, the Mac OS 9 virus, Discount virus and many others. This joke email claims to be authored by the Amish or other similar low-technology populations who have no computers, programming skills or electricity to create viruses and thus ask users to delete their own hard drive contents manually after forwarding the message to their friends.The Tuxissa virus is another parody of the virus hoax, based on the concept of the Melissa virus, but with its aim of installing Linux on the victim's computer without the owner's permission. The story says that it was spread via e-mail, contained in a message titled \"Important Message About Windows Security\". It was supposed to first spread the virus to other computers, then download a stripped-down version of Slackware and uncompress it onto the hard disk. The Windows Registry is finally deleted and the boot options changed. The virus then reboots the computer, leaving the user facing the Linux login prompt with all their Windows security problems solved."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the goal of simulated phishing testing in terms of staff behavior?",
    "context": "",
    "output": "The goal of simulated phishing testing is to gauge staff compliance and measure progress in user behavior. This is because good training of staff is necessary to stop all malicious email attacks, and simulated phishing allows the direct measurement of staff compliance.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the goal of simulated phishing testing in terms of staff behavior?",
      "answer": "The goal of simulated phishing testing is to gauge staff compliance and measure progress in user behavior. This is because good training of staff is necessary to stop all malicious email attacks, and simulated phishing allows the direct measurement of staff compliance."
    }
  },
  {
    "instruction": "Write an answer to the following question: In what ways does the FORCEDENTRY exploit demonstrate the potential for vulnerabilities in JBIG2-encoded data?",
    "context": "",
    "output": "The FORCEDENTRY exploit demonstrates the potential for vulnerabilities in JBIG2-encoded data by using it to define a computer architecture and perform arithmetic operations within a single decompression pass through a JBIG2 stream.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "In what ways does the FORCEDENTRY exploit demonstrate the potential for vulnerabilities in JBIG2-encoded data?",
      "answer": "The FORCEDENTRY exploit demonstrates the potential for vulnerabilities in JBIG2-encoded data by using it to define a computer architecture and perform arithmetic operations within a single decompression pass through a JBIG2 stream."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are some types of constructions for bent functions?",
    "context": "",
    "output": "There are several types of constructions for bent functions, including combinatorial constructions such as iterative constructions, Maiorana-McFarland construction, partial spreads, Dillon's and Dobbertin's bent functions, minterm bent functions, and bent iterative functions, as well as algebraic constructions such as monomial bent functions with exponents of Gold, Dillon, Kasami, Canteaut-Leander, and Canteaut-Charpin-Kuyreghyan, and Niho bent functions.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are some types of constructions for bent functions?",
      "answer": "There are several types of constructions for bent functions, including combinatorial constructions such as iterative constructions, Maiorana-McFarland construction, partial spreads, Dillon's and Dobbertin's bent functions, minterm bent functions, and bent iterative functions, as well as algebraic constructions such as monomial bent functions with exponents of Gold, Dillon, Kasami, Canteaut-Leander, and Canteaut-Charpin-Kuyreghyan, and Niho bent functions."
    }
  },
  {
    "instruction": "Context: Microsoft Forefront\n\n==Introduction==\nMicrosoft Forefront is a discontinued family of line-of-business security software by Microsoft Corporation. Microsoft Forefront products are designed to help protect computer networks, network servers (such as Microsoft Exchange Server and Microsoft SharePoint Server) and individual devices. As of 2015, the only actively developed Forefront product is Forefront Identity Manager.\n\n== Components ==\nForefront includes the following products:\nIdentity Manager: State-based identity management software product, designed to manage users' digital identities, credentials and groupings throughout the lifecycle of their membership of an enterprise computer system\n\n\n*** Rebranded ***\n\nSystem Center Endpoint Protection: A business antivirus software product that can be controlled over the network, formerly known as Forefront Endpoint Protection, Forefront Client Security and Client Protection.\nExchange Online Protection: A software as a service version of Forefront Protect for Exchange Server: Instead of installing a security program on the server, the customer re-routes its email traffic to the Microsoft online service before receiving them. \n\n\n*** Discontinued ***\nThreat Management Gateway: Discontinued server product that provides three functions: Routing, firewall and web cache. Formerly called Internet Security and Acceleration Server or ISA Server.\n\nUnified Access Gateway: Discontinued server product that protects network assets by encrypting all inbound access request from authorized users. Supports Virtual Private Networks (VPN) and DirectAccess. Formerly called Intelligent Application Gateway.\nServer Management Console: Discontinued web-based application that enables management of multiple instances of Protection for Exchange, Protection for SharePoint and Microsoft Antigen from a single interface.\n\nProtection for Exchange: A discontinued software product that detects viruses, spyware, and spam by integrating multiple scanning engines from security partners in a single solution to protect Exchange messaging environments. FPE provides an administration console that includes customizable configuration settings, filtering options, monitoring features and reports, and integration with the Forefront Online Protection for Exchange (FOPE) product.  After installation, managing FPE on multiple Exchange servers can be done with the Protection Server Management Console. Additionally, FPE can be managed using Windows PowerShell, a command-line shell and task-based scripting technology that enables the automation of system administration tasks.\n\nProtection for SharePoint: A discontinued product that protects Microsoft SharePoint Server document libraries. It enforces rules that prevent documents containing malware, sensitive information, or out-of-policy content from being uploaded. Protection Server Management Console or Windows PowerShell can be used to manage Protection for SharePoint Server on multiple servers.\nSecurity for Office Communications Server: Protects computers running Microsoft Office Communications Server from malware. Formerly called Antigen for Instant Messaging.\n\nQuestion: How can System Center Endpoint Protection be controlled over the network?\n\nAnswer:",
    "context": "",
    "output": "System Center Endpoint Protection can be controlled over the network by using network-based management tools or software.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can System Center Endpoint Protection be controlled over the network?",
      "answer": "System Center Endpoint Protection can be controlled over the network by using network-based management tools or software.",
      "context": "Microsoft Forefront\n\n==Introduction==\nMicrosoft Forefront is a discontinued family of line-of-business security software by Microsoft Corporation. Microsoft Forefront products are designed to help protect computer networks, network servers (such as Microsoft Exchange Server and Microsoft SharePoint Server) and individual devices. As of 2015, the only actively developed Forefront product is Forefront Identity Manager.\n\n== Components ==\nForefront includes the following products:\nIdentity Manager: State-based identity management software product, designed to manage users' digital identities, credentials and groupings throughout the lifecycle of their membership of an enterprise computer system\n\n\n*** Rebranded ***\n\nSystem Center Endpoint Protection: A business antivirus software product that can be controlled over the network, formerly known as Forefront Endpoint Protection, Forefront Client Security and Client Protection.\nExchange Online Protection: A software as a service version of Forefront Protect for Exchange Server: Instead of installing a security program on the server, the customer re-routes its email traffic to the Microsoft online service before receiving them. \n\n\n*** Discontinued ***\nThreat Management Gateway: Discontinued server product that provides three functions: Routing, firewall and web cache. Formerly called Internet Security and Acceleration Server or ISA Server.\n\nUnified Access Gateway: Discontinued server product that protects network assets by encrypting all inbound access request from authorized users. Supports Virtual Private Networks (VPN) and DirectAccess. Formerly called Intelligent Application Gateway.\nServer Management Console: Discontinued web-based application that enables management of multiple instances of Protection for Exchange, Protection for SharePoint and Microsoft Antigen from a single interface.\n\nProtection for Exchange: A discontinued software product that detects viruses, spyware, and spam by integrating multiple scanning engines from security partners in a single solution to protect Exchange messaging environments. FPE provides an administration console that includes customizable configuration settings, filtering options, monitoring features and reports, and integration with the Forefront Online Protection for Exchange (FOPE) product.  After installation, managing FPE on multiple Exchange servers can be done with the Protection Server Management Console. Additionally, FPE can be managed using Windows PowerShell, a command-line shell and task-based scripting technology that enables the automation of system administration tasks.\n\nProtection for SharePoint: A discontinued product that protects Microsoft SharePoint Server document libraries. It enforces rules that prevent documents containing malware, sensitive information, or out-of-policy content from being uploaded. Protection Server Management Console or Windows PowerShell can be used to manage Protection for SharePoint Server on multiple servers.\nSecurity for Office Communications Server: Protects computers running Microsoft Office Communications Server from malware. Formerly called Antigen for Instant Messaging."
    }
  },
  {
    "instruction": "Spam email delivery\n\n==Introduction==\nSince Internet users and system administrators have deployed a vast array of techniques to block, filter, or otherwise banish spam from users' mailboxes and almost all Internet service providers forbid the use of their services to send spam or to operate spam-support services, special techniques are employed to deliver spam emails. Both commercial firms and volunteers run subscriber services dedicated to blocking or filtering spam.\n\n== Webmail ==\nA common practice of spammers is to create accounts on free web-mail services, such as Hotmail, to send spam or to receive e-mailed responses from potential customers. Because of the amount of mail sent by spammers, they require several e-mail accounts, and use web bots to automate the creation of these accounts.\nIn an effort to cut down on this abuse, many of these services have adopted a system called Captcha: users attempting to create a new account are presented with a graphic of a word, which uses a strange font, on a difficult to read background. Humans are able to read these graphics, and are required to enter the word to complete the application for a new account, while computers are unable to get accurate readings of the words using standard OCR techniques. Blind users of captchas typically get an audio sample.\nSpammers have, however, found a means of circumventing this measure. Reportedly, they have set up sites offering free pornography: to get access to the site, a user displays a graphic from one of these webmail sites, and must enter the word. Spammers can equip pornography-carrying emails (and any email type in general) to enter searches into the search engine so a larger number of windows can be opened. For example, by simply inputting the word \"porn\" into Google's search engine, spam messages can open up several sites related to the word \"porn.\" These messages make it very hard to trace the spammer as the search word(s) make it appear as if the spam receiver entered the word themselves. The search word will not appear in the recent searches and the windows will not appear in the History page unless a link is clicked on the site. Some porn-emails will link to specific sites and ask for the user to create an account and enter payment information. Once the user has successfully created the account, the user gains access to the pornographic material. Furthermore, standard image processing techniques work well against many Captchas.\n\n== Third-party computers ==\nEarly on, spammers discovered that if they sent large quantities of spam directly from their ISP accounts, recipients would complain and ISP's would shut their accounts down. Thus, one of the basic techniques of sending spam has become to send it from someone else's computer and network connection. By doing this, spammers protect themselves in several ways: they hide their tracks, get others' systems to do most of the work of delivering messages, and direct the efforts of investigators towards the other systems rather than the spammers themselves. Spammers may equip messages so they put in selected searches in search engines (I.E. Google) to open a greater amount of search windows. As long as the server's computer is open and on, the range of windows can increase. The increasing broadband usage gave rise to a great number of computers that are online as long as they are turned on, and whose owners do not always take steps to protect them from malware.  A botnet consisting of several hundred compromised machines can effortlessly churn out millions of messages per day.  This also complicates the tracing of spammers.\n\n\n*** Open relays ***\nIn the 1990s, the most common way spammers did this was to use open mail relays. An open relay is an MTA, or mail server, which is configured to pass along messages sent to it from any location, to any recipient. In the original SMTP mail architecture, this was the default behavior: a user could send mail to practically any mail server, which would pass it along towards the intended recipient's mail server.The standard was written in an era before spamming when there were few hosts on the internet, and those on the internet abide by a certain level of conduct. While this cooperative, and open approach was useful in ensuring that mail was delivered, it was vulnerable to abuse by spammers. Spammers could forward batches of spam through open relays, leaving the job of delivering the messages up to the relays.\nIn response, mail system administrators concerned about spam began to demand that other mail operators configure MTAs to cease being open relays. The first DNSBLs, such as MAPS RBL and the now-defunct ORBS, aimed chiefly at allowing mail sites to refuse mail from known open relays. By 2003 less than 1% of corporate mail servers were available as open relays, down from 91% in 1997.\n\n\n*** Open proxies ***\nWithin a few years, open relays became rare and spammers resorted to other tactics, most prominently the use of open proxies. A proxy is a network service for making indirect connections to other network services. The client connects to the proxy and instructs it to connect to a server. The server perceives an incoming connection from the proxy, not the original client. Proxies have many purposes, including Web-page caching, protection of privacy, filtering of Web content, and selectively bypassing firewalls.An open proxy is one which will create connections for any client to any server, without authentication. Like open relays, open proxies were once relatively common, as many administrators did not see a need to restrict access to them.\nA spammer can direct an open proxy to connect to a mail server, and send spam through it. The mail server logs a connection from the proxy\u2014not the spammer's own computer. This provides an even greater degree of concealment for the spammer than an open relay, since most relays log the client address in the headers of messages they pass. Open proxies have also been used to conceal the sources of attacks against other services besides mail, such as Web sites or IRC servers. As spam from proxies and other \"spammable\" resources grew, DNSBL operators started listing their IP addresses, as well as open relays.\n\n\n*** Web scripts ***\nBesides relays and proxies, spammers have used other insecure services to send spam. One example is FormMail.pl, a CGI script to allow Web-site users to send e-mail feedback from an HTML form. Several versions of this program, and others like it, allowed the user to redirect e-mail to arbitrary addresses. Spam sent through open FormMail scripts is frequently marked by the program's characteristic opening line: \"Below is the result of your feedback form.\"\nThe \u2018tell a friend about this page\u2019 features some websites offer may be vulnerable by design in that they allow the visitor to add their message to the email that is sent. Consequently, such scripts are often abused to send spam, particularly so-called 419 scams.\n\n\n*** Spammer viruses ***\nIn 2003, spam investigators saw a radical change in the way spammers sent spam. Rather than searching the global network for exploitable services such as open relays and proxies, spammers began creating \"services\" of their own. By commissioning computer viruses designed to deploy proxies and other spam-sending tools, spammers could harness hundreds of thousands of end-user computers.  The widespread change from Windows 9x to Windows XP for many home computers, which started in early 2002 and was well under way by 2003, greatly accelerated the use of home computers to act as remotely controlled spam proxies.  The original version of Windows XP as well as XP-SP1 had several major vulnerabilities that allowed the machines to be compromised over a network connection without requiring actions on the part of the user or owner.Most of the major Windows e-mail viruses of 2003, including the Sobig and Mimail virus families, functioned as spammer viruses: viruses designed expressly to make infected computers available as spamming tools.Besides sending spam, spammer viruses serve spammers in other ways. Beginning in July 2003, spammers started using some of these same viruses to perpetrate distributed denial-of-service (DDoS) attacks upon DNSBLs and other anti-spam resources. Although this was by no means the first time that illegal attacks have been used against anti-spam sites, it was perhaps the first wave of effective attacks.\nIn August of that year, engineering company Osirusoft ceased providing DNSBL mirrors of the SPEWS and other blocklists, after several days of unceasing attack from virus-infected hosts. The very next month, DNSBL operator Monkeys.com succumbed to the attacks as well. Other DNSBL operators, such as Spamhaus, have deployed global mirroring and other anti-DDoS methods to resist these attacks.\nZombie networks are particularly active in North America where about half of the Internet users are on a broadband connection and many leave their computers on all the time. In January, 2008, 8% of all e-mail spam was sent by the Storm botnet, created by the Storm Worm, first released in January, 2007. It is estimated that as many as 1 million or more computers have been infected and their owners are unwilling and unknowing participants. In the 3rd quarter of 2008 almost one in every 400 email messages contained a dangerous attachment, designed to infect the recipient's computer, eight times as often as in the previous quarter.\n\nBased on the above text, answer a question. How do spammers exploit open FormMail scripts to send spam emails?",
    "context": "",
    "output": "Spammers exploit open FormMail scripts by using them to send spam from a website's feedback form. This allows spammers to send spam from a seemingly legitimate source, making it more difficult to trace the source of the spam.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do spammers exploit open FormMail scripts to send spam emails?",
      "answer": "Spammers exploit open FormMail scripts by using them to send spam from a website's feedback form. This allows spammers to send spam from a seemingly legitimate source, making it more difficult to trace the source of the spam.",
      "context": "Spam email delivery\n\n==Introduction==\nSince Internet users and system administrators have deployed a vast array of techniques to block, filter, or otherwise banish spam from users' mailboxes and almost all Internet service providers forbid the use of their services to send spam or to operate spam-support services, special techniques are employed to deliver spam emails. Both commercial firms and volunteers run subscriber services dedicated to blocking or filtering spam.\n\n== Webmail ==\nA common practice of spammers is to create accounts on free web-mail services, such as Hotmail, to send spam or to receive e-mailed responses from potential customers. Because of the amount of mail sent by spammers, they require several e-mail accounts, and use web bots to automate the creation of these accounts.\nIn an effort to cut down on this abuse, many of these services have adopted a system called Captcha: users attempting to create a new account are presented with a graphic of a word, which uses a strange font, on a difficult to read background. Humans are able to read these graphics, and are required to enter the word to complete the application for a new account, while computers are unable to get accurate readings of the words using standard OCR techniques. Blind users of captchas typically get an audio sample.\nSpammers have, however, found a means of circumventing this measure. Reportedly, they have set up sites offering free pornography: to get access to the site, a user displays a graphic from one of these webmail sites, and must enter the word. Spammers can equip pornography-carrying emails (and any email type in general) to enter searches into the search engine so a larger number of windows can be opened. For example, by simply inputting the word \"porn\" into Google's search engine, spam messages can open up several sites related to the word \"porn.\" These messages make it very hard to trace the spammer as the search word(s) make it appear as if the spam receiver entered the word themselves. The search word will not appear in the recent searches and the windows will not appear in the History page unless a link is clicked on the site. Some porn-emails will link to specific sites and ask for the user to create an account and enter payment information. Once the user has successfully created the account, the user gains access to the pornographic material. Furthermore, standard image processing techniques work well against many Captchas.\n\n== Third-party computers ==\nEarly on, spammers discovered that if they sent large quantities of spam directly from their ISP accounts, recipients would complain and ISP's would shut their accounts down. Thus, one of the basic techniques of sending spam has become to send it from someone else's computer and network connection. By doing this, spammers protect themselves in several ways: they hide their tracks, get others' systems to do most of the work of delivering messages, and direct the efforts of investigators towards the other systems rather than the spammers themselves. Spammers may equip messages so they put in selected searches in search engines (I.E. Google) to open a greater amount of search windows. As long as the server's computer is open and on, the range of windows can increase. The increasing broadband usage gave rise to a great number of computers that are online as long as they are turned on, and whose owners do not always take steps to protect them from malware.  A botnet consisting of several hundred compromised machines can effortlessly churn out millions of messages per day.  This also complicates the tracing of spammers.\n\n\n*** Open relays ***\nIn the 1990s, the most common way spammers did this was to use open mail relays. An open relay is an MTA, or mail server, which is configured to pass along messages sent to it from any location, to any recipient. In the original SMTP mail architecture, this was the default behavior: a user could send mail to practically any mail server, which would pass it along towards the intended recipient's mail server.The standard was written in an era before spamming when there were few hosts on the internet, and those on the internet abide by a certain level of conduct. While this cooperative, and open approach was useful in ensuring that mail was delivered, it was vulnerable to abuse by spammers. Spammers could forward batches of spam through open relays, leaving the job of delivering the messages up to the relays.\nIn response, mail system administrators concerned about spam began to demand that other mail operators configure MTAs to cease being open relays. The first DNSBLs, such as MAPS RBL and the now-defunct ORBS, aimed chiefly at allowing mail sites to refuse mail from known open relays. By 2003 less than 1% of corporate mail servers were available as open relays, down from 91% in 1997.\n\n\n*** Open proxies ***\nWithin a few years, open relays became rare and spammers resorted to other tactics, most prominently the use of open proxies. A proxy is a network service for making indirect connections to other network services. The client connects to the proxy and instructs it to connect to a server. The server perceives an incoming connection from the proxy, not the original client. Proxies have many purposes, including Web-page caching, protection of privacy, filtering of Web content, and selectively bypassing firewalls.An open proxy is one which will create connections for any client to any server, without authentication. Like open relays, open proxies were once relatively common, as many administrators did not see a need to restrict access to them.\nA spammer can direct an open proxy to connect to a mail server, and send spam through it. The mail server logs a connection from the proxy\u2014not the spammer's own computer. This provides an even greater degree of concealment for the spammer than an open relay, since most relays log the client address in the headers of messages they pass. Open proxies have also been used to conceal the sources of attacks against other services besides mail, such as Web sites or IRC servers. As spam from proxies and other \"spammable\" resources grew, DNSBL operators started listing their IP addresses, as well as open relays.\n\n\n*** Web scripts ***\nBesides relays and proxies, spammers have used other insecure services to send spam. One example is FormMail.pl, a CGI script to allow Web-site users to send e-mail feedback from an HTML form. Several versions of this program, and others like it, allowed the user to redirect e-mail to arbitrary addresses. Spam sent through open FormMail scripts is frequently marked by the program's characteristic opening line: \"Below is the result of your feedback form.\"\nThe \u2018tell a friend about this page\u2019 features some websites offer may be vulnerable by design in that they allow the visitor to add their message to the email that is sent. Consequently, such scripts are often abused to send spam, particularly so-called 419 scams.\n\n\n*** Spammer viruses ***\nIn 2003, spam investigators saw a radical change in the way spammers sent spam. Rather than searching the global network for exploitable services such as open relays and proxies, spammers began creating \"services\" of their own. By commissioning computer viruses designed to deploy proxies and other spam-sending tools, spammers could harness hundreds of thousands of end-user computers.  The widespread change from Windows 9x to Windows XP for many home computers, which started in early 2002 and was well under way by 2003, greatly accelerated the use of home computers to act as remotely controlled spam proxies.  The original version of Windows XP as well as XP-SP1 had several major vulnerabilities that allowed the machines to be compromised over a network connection without requiring actions on the part of the user or owner.Most of the major Windows e-mail viruses of 2003, including the Sobig and Mimail virus families, functioned as spammer viruses: viruses designed expressly to make infected computers available as spamming tools.Besides sending spam, spammer viruses serve spammers in other ways. Beginning in July 2003, spammers started using some of these same viruses to perpetrate distributed denial-of-service (DDoS) attacks upon DNSBLs and other anti-spam resources. Although this was by no means the first time that illegal attacks have been used against anti-spam sites, it was perhaps the first wave of effective attacks.\nIn August of that year, engineering company Osirusoft ceased providing DNSBL mirrors of the SPEWS and other blocklists, after several days of unceasing attack from virus-infected hosts. The very next month, DNSBL operator Monkeys.com succumbed to the attacks as well. Other DNSBL operators, such as Spamhaus, have deployed global mirroring and other anti-DDoS methods to resist these attacks.\nZombie networks are particularly active in North America where about half of the Internet users are on a broadband connection and many leave their computers on all the time. In January, 2008, 8% of all e-mail spam was sent by the Storm botnet, created by the Storm Worm, first released in January, 2007. It is estimated that as many as 1 million or more computers have been infected and their owners are unwilling and unknowing participants. In the 3rd quarter of 2008 almost one in every 400 email messages contained a dangerous attachment, designed to infect the recipient's computer, eight times as often as in the previous quarter."
    }
  },
  {
    "instruction": "Website spoofing\n\n==Introduction==\nWebsite spoofing is the act of creating a website with the intention of misleading readers that the website has been created by a different person or organization. Normally, the spoof website will adopt the design of the target website, and it sometimes has a similar URL. A more sophisticated attack results in an attacker creating a \"shadow copy\" of the World Wide Web by having all of the victim's traffic go through the attacker's machine, causing the attacker to obtain the victim's sensitive information.Another technique is to use a 'cloaked' URL. By  using domain forwarding, or inserting control characters, the URL can appear to be genuine while concealing the actual address of the malicious website. Punycode can also be used for this purpose. Punycode-based attacks exploit the similar characters in different writing systems in common fonts. For example, on one large font, the greek letter tau (\u03c4) is similar in appearance to the latin undercase letter t. However, the greek letter tau is represented in punycode as 5xa, while the latin undercase letter is simply represented as t, since it is present on the ASCII system. In 2017, a security researcher managed to register the domain xn--80ak6aa92e.com and have it show on several mainstream browsers as apple.com. While the characters used didn't belong to the latin script, due to the default font on those browsers, the end result was non-latin characters that were indistinguishable from those on the latin script.The objective may be fraudulent, often associated with phishing or e-mail spoofing, or to criticize or make fun of the person or body whose website the spoofed site purports to represent. Because the purpose is often malicious, \"spoof\" (an expression whose base meaning is innocent parody) is a poor term for this activity so that more accountable organisations such as government departments and banks tend to avoid it, preferring more explicit descriptors such as \"fraudulent\" or \"phishing\".As an example of the use of this technique to parody an organisation, in November 2006 two spoof websites, www.msfirefox.com and www.msfirefox.net, were produced claiming that Microsoft had bought Firefox and released \"Microsoft Firefox 2007.\"\n\n\n\n== Prevention tools ==\n\n\n*** Anti-phishing software ***\nSpoofed websites predominate in efforts developing anti-phishing software though there are concerns about their effectiveness. A majority of efforts are focused on the PC market leaving mobile devices lacking You can see from the table below that few user studies have been run against the current tools in the market.\n\n\n*** DNS filtering ***\nDNS is the layer at which botnets control drones. In 2006, OpenDNS  began offering a free service to prevent users from entering website spoofing sites. Essentially, OpenDNS has gathered a large database from various anti-phishing and anti-botnet organizations as well as its own data to compile a list of known website spoofing offenders. When a user attempts to access one of these bad websites, they are blocked at the DNS level. APWG statistics show that most phishing attacks use URLs, not domain names, so there would be a large amount of website spoofing that OpenDNS would be unable to track. At the time of release, OpenDNS is unable to prevent unnamed phishing exploits that sit on Yahoo, Google etc.\nQ: What are the limitations of DNS filtering in preventing website spoofing?",
    "context": "",
    "output": "DNS filtering has limitations in preventing website spoofing, such as the inability to prevent unnamed phishing exploits that sit on popular websites like Yahoo and Google.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are the limitations of DNS filtering in preventing website spoofing?",
      "answer": "DNS filtering has limitations in preventing website spoofing, such as the inability to prevent unnamed phishing exploits that sit on popular websites like Yahoo and Google.",
      "context": "Website spoofing\n\n==Introduction==\nWebsite spoofing is the act of creating a website with the intention of misleading readers that the website has been created by a different person or organization. Normally, the spoof website will adopt the design of the target website, and it sometimes has a similar URL. A more sophisticated attack results in an attacker creating a \"shadow copy\" of the World Wide Web by having all of the victim's traffic go through the attacker's machine, causing the attacker to obtain the victim's sensitive information.Another technique is to use a 'cloaked' URL. By  using domain forwarding, or inserting control characters, the URL can appear to be genuine while concealing the actual address of the malicious website. Punycode can also be used for this purpose. Punycode-based attacks exploit the similar characters in different writing systems in common fonts. For example, on one large font, the greek letter tau (\u03c4) is similar in appearance to the latin undercase letter t. However, the greek letter tau is represented in punycode as 5xa, while the latin undercase letter is simply represented as t, since it is present on the ASCII system. In 2017, a security researcher managed to register the domain xn--80ak6aa92e.com and have it show on several mainstream browsers as apple.com. While the characters used didn't belong to the latin script, due to the default font on those browsers, the end result was non-latin characters that were indistinguishable from those on the latin script.The objective may be fraudulent, often associated with phishing or e-mail spoofing, or to criticize or make fun of the person or body whose website the spoofed site purports to represent. Because the purpose is often malicious, \"spoof\" (an expression whose base meaning is innocent parody) is a poor term for this activity so that more accountable organisations such as government departments and banks tend to avoid it, preferring more explicit descriptors such as \"fraudulent\" or \"phishing\".As an example of the use of this technique to parody an organisation, in November 2006 two spoof websites, www.msfirefox.com and www.msfirefox.net, were produced claiming that Microsoft had bought Firefox and released \"Microsoft Firefox 2007.\"\n\n\n\n== Prevention tools ==\n\n\n*** Anti-phishing software ***\nSpoofed websites predominate in efforts developing anti-phishing software though there are concerns about their effectiveness. A majority of efforts are focused on the PC market leaving mobile devices lacking You can see from the table below that few user studies have been run against the current tools in the market.\n\n\n*** DNS filtering ***\nDNS is the layer at which botnets control drones. In 2006, OpenDNS  began offering a free service to prevent users from entering website spoofing sites. Essentially, OpenDNS has gathered a large database from various anti-phishing and anti-botnet organizations as well as its own data to compile a list of known website spoofing offenders. When a user attempts to access one of these bad websites, they are blocked at the DNS level. APWG statistics show that most phishing attacks use URLs, not domain names, so there would be a large amount of website spoofing that OpenDNS would be unable to track. At the time of release, OpenDNS is unable to prevent unnamed phishing exploits that sit on Yahoo, Google etc."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the purpose of the Volume ID in the AACS system?",
    "context": "",
    "output": "The Volume ID is used in combination with the MKB to obtain the Volume Unique Key, which is used to decrypt the Encrypted Title Key and access the content of the disc.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the purpose of the Volume ID in the AACS system?",
      "answer": "The Volume ID is used in combination with the MKB to obtain the Volume Unique Key, which is used to decrypt the Encrypted Title Key and access the content of the disc."
    }
  },
  {
    "instruction": "Write an answer to the following question: How can unidirectional networks be used to secure file transfer?",
    "context": "",
    "output": "Unidirectional networks can be used to secure file transfer by using data diodes to transfer data deterministically (to predetermined locations) with a protocol \"break\" that allows the data to be transferred through the data diode. This ensures that data is transferred securely and that the integrity of the data is maintained.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can unidirectional networks be used to secure file transfer?",
      "answer": "Unidirectional networks can be used to secure file transfer by using data diodes to transfer data deterministically (to predetermined locations) with a protocol \"break\" that allows the data to be transferred through the data diode. This ensures that data is transferred securely and that the integrity of the data is maintained."
    }
  },
  {
    "instruction": "Write an answer to the following question: What can be inferred about the level of detail and comprehensiveness of the BDU compared to the U.S. National Vulnerability Database based on the number of entries in each database?",
    "context": "",
    "output": "Based on the number of entries, one can infer that the U.S. National Vulnerability Database is more comprehensive and detailed in terms of data security threats compared to the BDU.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What can be inferred about the level of detail and comprehensiveness of the BDU compared to the U.S. National Vulnerability Database based on the number of entries in each database?",
      "answer": "Based on the number of entries, one can infer that the U.S. National Vulnerability Database is more comprehensive and detailed in terms of data security threats compared to the BDU."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are the potential consequences of session poisoning?",
    "context": "",
    "output": "The potential consequences of session poisoning include unauthorized access, data manipulation, and other malicious activities, depending on the specific application and its functionality.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are the potential consequences of session poisoning?",
      "answer": "The potential consequences of session poisoning include unauthorized access, data manipulation, and other malicious activities, depending on the specific application and its functionality."
    }
  },
  {
    "instruction": "Robust random early detection\n\n==Introduction==\nRobust random early detection (RRED) is a queueing discipline for a network scheduler. The existing random early detection (RED) algorithm and its variants are found vulnerable to emerging attacks, especially the Low-rate Denial-of-Service attacks (LDoS). Experiments have confirmed that the existing RED-like algorithms are notably vulnerable under LDoS attacks due to the oscillating TCP queue size caused by the attacks.The Robust RED (RRED) algorithm was proposed to improve the TCP throughput against LDoS attacks. The basic idea behind the RRED is to detect and filter out attack packets before a normal RED algorithm is applied to incoming flows. RRED algorithm can significantly improve the performance of TCP under Low-rate denial-of-service attacks.\n\n== The design of Robust RED (RRED) ==\nA detection and filter block is added in front of a regular RED block on a router. The basic idea behind the RRED is to detect and filter out LDoS attack packets from incoming flows before they feed to the RED algorithm. How to distinguish an attacking packet from normal TCP packets is critical in the RRED design. \nWithin a benign TCP flow, the sender will delay sending new packets if loss is detected (e.g., a packet is dropped). Consequently, a packet is suspected to be an attacking packet if it is sent within a short-range after a packet is dropped. This is the basic idea of the detection algorithm of Robust RED (RRED).\n\n== Algorithm of the Robust RED (RRED) ==\nalgorithm RRED-ENQUE(pkt)\n01     f \u2190 RRED-FLOWHASH(pkt) \n02     Tmax \u2190 MAX(Flow[f].T1, T2)\n03     if pkt.arrivaltime is within [Tmax, Tmax+T*] then\n04         reduce local indicator by 1 for each bin corresponding to f\n05     else\n06         increase local indicator by 1 for each bin of f\n07     Flow[f].I \u2190 maximum of local indicators from bins of f \n08     if Flow[f].I \u2265 0 then\n09         RED-ENQUE(pkt)  // pass pkt to the RED block\n10         if RED drops pkt then\n11             T2 \u2190 pkt.arrivaltime\n12     else\n13         Flow[f].T1 \u2190 pkt.arrivaltime\n14         drop(pkt)\n15     return\n\nf.T1 is the arrival time of the last packet from flow f that is dropped by the detection and filter block.\nT2 is the arrival time of the last packet from any flow that is dropped by the random early detection (RED) block.\nTmax\n\n== The simulation code of the Robust RED (RRED) ==\nThe simulation code of the RRED algorithm is published as an active queue management and denial-of-service attack (AQM&DoS) simulation platform. The AQM&DoS Simulation Platform is able to simulate a variety of DoS attacks (Distributed DoS, Spoofing DoS, Low-rate DoS, etc.) and active queue management (AQM) algorithms (RED, RRED, SFB, etc.). It automatically calculates and records the average throughput of normal TCP flows before and after DoS attacks to facilitate the analysis of the impact of DoS attacks on normal TCP flows and AQM algorithms.\n\nWhat is the local indicator in the RRED algorithm and how is it updated?",
    "context": "",
    "output": "A: The local indicator in the RRED algorithm is a value that is updated for each bin of the flow f. It is increased by 1 if the packet's arrival time is not within the range of [Tmax, Tmax+T*], and reduced by 1 if it is within that range.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the local indicator in the RRED algorithm and how is it updated?",
      "answer": "The local indicator in the RRED algorithm is a value that is updated for each bin of the flow f. It is increased by 1 if the packet's arrival time is not within the range of [Tmax, Tmax+T*], and reduced by 1 if it is within that range.",
      "context": "Robust random early detection\n\n==Introduction==\nRobust random early detection (RRED) is a queueing discipline for a network scheduler. The existing random early detection (RED) algorithm and its variants are found vulnerable to emerging attacks, especially the Low-rate Denial-of-Service attacks (LDoS). Experiments have confirmed that the existing RED-like algorithms are notably vulnerable under LDoS attacks due to the oscillating TCP queue size caused by the attacks.The Robust RED (RRED) algorithm was proposed to improve the TCP throughput against LDoS attacks. The basic idea behind the RRED is to detect and filter out attack packets before a normal RED algorithm is applied to incoming flows. RRED algorithm can significantly improve the performance of TCP under Low-rate denial-of-service attacks.\n\n== The design of Robust RED (RRED) ==\nA detection and filter block is added in front of a regular RED block on a router. The basic idea behind the RRED is to detect and filter out LDoS attack packets from incoming flows before they feed to the RED algorithm. How to distinguish an attacking packet from normal TCP packets is critical in the RRED design. \nWithin a benign TCP flow, the sender will delay sending new packets if loss is detected (e.g., a packet is dropped). Consequently, a packet is suspected to be an attacking packet if it is sent within a short-range after a packet is dropped. This is the basic idea of the detection algorithm of Robust RED (RRED).\n\n== Algorithm of the Robust RED (RRED) ==\nalgorithm RRED-ENQUE(pkt)\n01     f \u2190 RRED-FLOWHASH(pkt) \n02     Tmax \u2190 MAX(Flow[f].T1, T2)\n03     if pkt.arrivaltime is within [Tmax, Tmax+T*] then\n04         reduce local indicator by 1 for each bin corresponding to f\n05     else\n06         increase local indicator by 1 for each bin of f\n07     Flow[f].I \u2190 maximum of local indicators from bins of f \n08     if Flow[f].I \u2265 0 then\n09         RED-ENQUE(pkt)  // pass pkt to the RED block\n10         if RED drops pkt then\n11             T2 \u2190 pkt.arrivaltime\n12     else\n13         Flow[f].T1 \u2190 pkt.arrivaltime\n14         drop(pkt)\n15     return\n\nf.T1 is the arrival time of the last packet from flow f that is dropped by the detection and filter block.\nT2 is the arrival time of the last packet from any flow that is dropped by the random early detection (RED) block.\nTmax\n\n== The simulation code of the Robust RED (RRED) ==\nThe simulation code of the RRED algorithm is published as an active queue management and denial-of-service attack (AQM&DoS) simulation platform. The AQM&DoS Simulation Platform is able to simulate a variety of DoS attacks (Distributed DoS, Spoofing DoS, Low-rate DoS, etc.) and active queue management (AQM) algorithms (RED, RRED, SFB, etc.). It automatically calculates and records the average throughput of normal TCP flows before and after DoS attacks to facilitate the analysis of the impact of DoS attacks on normal TCP flows and AQM algorithms."
    }
  },
  {
    "instruction": "Context: User-Managed Access\n\n==Introduction==\nUser-Managed Access (UMA) is an OAuth-based  access management protocol standard. Version 1.0 of the standard was approved by the Kantara Initiative on March 23, 2015.As described by the charter of the group that developed UMA, the purpose of the protocol specifications is to \u201cenable a resource owner to control the authorization of data sharing and other protected-resource access made between online services on the owner\u2019s behalf or with the owner\u2019s authorization by an autonomous requesting party\u201d. This purpose has privacy and consent implications for web applications and the Internet of Things (IoT), as explored by the collection of case studies contributed by participants in the standards group.\n\n\n\n== History and background ==\nThe Kantara Initiative's UMA Work Group held its first meeting on August 6, 2009. UMA's design principles and technical design have been informed by previous work by Sun Microsystems employees, begun in March 2008, on a protocol called ProtectServe. In turn, ProtectServe was influenced by the goals of the Vendor Relationship Management movement and an offshoot effort called feeds-based VRM.\nProtectServe and UMA's earliest versions leveraged the OAuth 1.0 protocol. As OAuth underwent significant change through the publication of the Web Resource Authorization Protocol (WRAP) specification and, subsequently, drafts of OAuth 2.0, the UMA specification has kept pace, and it now uses the OAuth 2.0 family of specifications for several key protocol flows.\nUMA does not use or depend on OpenID 2.0 as a means of user identification. However, it optionally uses the OAuth-based OpenID Connect protocol as a means of collecting identity claims from a requesting party in order to attempt to satisfy the authorizing user's access policy.\nUMA also does not use or depend on the eXtensible Access Control Markup Language (XACML) as a means of encoding user policy or requesting policy decisions. UMA does not dictate policy format, as policy evaluation is performed internally to the authorization server (AS) from the UMA perspective. Typically XACML would be used to implement the policies inside the AS. Its implementation is out-of-scope of UMA. The UMA protocol flows for requesting access permission have some features in common with the XACML protocol.\n\n== Standardization status ==\nThe UMA group conducts its work in the Kantara Initiative and has also contributed a series of Internet-Draft specifications to the Internet Engineering Task Force (IETF) as an eventual home for UMA standardization work. To this end, the WG has contributed several individual Internet-Drafts to the IETF for consideration. One of these, a specification for OAuth dynamic client registration, served as input for the more generalized mechanism ultimately developed for OAuth.\nUMA was presented to the OAuth Working Group at the IETF 104 conference in March 2019, but that did not result in any UMA specifications being adopted by the IETF.\n\n== Implementation and adoption status ==\nThe UMA core protocol has several implementations, including several open source implementations. Sources of active and available open-source implementations include ForgeRock, Gluu, IDENTOS Inc., MITREid Connect, Atricore, Node-UMA, Roland Hedberg, Keycloak, and  WSO2 Identity Server. A Kantara Initiative group is working on developing \"free and open-source software (FOSS), in several popular programming languages, that empowers developers to incorporate UMA protection and authorization API enablement into applications, services, and devices\".UMA-enabled products are available from Gluu, Jericho Systems, ForgeRock, IDENTOS Inc. and  WSO2 Identity Server\n\n== Comparison to OAuth 2.0 ==\n\nThe diagram (see right) highlights key additions that UMA makes to OAuth 2.0.\nIn a typical OAuth flow, a human resource owner (RO) operating a client application is redirected to an authorization server (AS) to log in and consent to the issuance of an access token so that the client application can gain access to the resource server (RS) on the RO\u2019s behalf in future, likely in a scoped (limited) fashion. The RS and AS are in all likelihood operating within the same security domain, and any communication between them is not standardized by the main OAuth specification.\nUMA adds three main concepts and corresponding structures and flows. First, it defines a standardized API at the AS, called the protection API, that the RS speaks to; this enables multiple RS\u2019s to communicate with one AS and vice versa, and because the API is itself secured with OAuth, allows for formal trust establishment between each pair. This also allows an AS to present an RO with a centralized user interface. Second, UMA defines a formal notion of a requesting party (RqP) that is autonomous from an RO, enabling party-to-party sharing and delegation of access authorization. An RO need not consent to token issuance at run time but can set policy at an AS, allowing an RqP to attempt access asynchronously. Third, UMA enables access attempts to result in successful issuance of tokens associated with authorization data based on a process of trust elevation in the RqP, for example, gathering identity claims or other claims from them.\n\n== Applicable use cases ==\nUMA's architecture can serve a variety of consumer-facing and enterprise-facing use cases. The UMA group collects case studies on its wiki.One example set of use cases is in healthcare IT and consumer health. In the OpenID Foundation organization, a working group called Health Relationship Trust (HEART) is working to \"harmonize and develop a set of privacy and security specifications that enable an individual to control the authorization of access to RESTful health-related data sharing APIs\", building upon, among other standards, UMA.\nAnother example set of use cases, which originally influenced UMA's development, is in the area of \"personal data stores\" in the fashion of vendor relationship management. In this conception, an individual can choose an operator of an authorization service that accepts connections from a variety of consumer-facing digital resource hosts in order to offer a dashboard with resource sharing management capabilities.\nAnswer this question: Can UMA be used for user identification, and if not, what protocols does it use for identification purposes?",
    "context": "",
    "output": "UMA does not use or depend on OpenID 2.0 or any other user identification protocols for user identification. Instead, it may optionally use the OAuth-based OpenID Connect protocol as a means of collecting identity claims from a requesting party.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Can UMA be used for user identification, and if not, what protocols does it use for identification purposes?",
      "answer": "UMA does not use or depend on OpenID 2.0 or any other user identification protocols for user identification. Instead, it may optionally use the OAuth-based OpenID Connect protocol as a means of collecting identity claims from a requesting party.",
      "context": "User-Managed Access\n\n==Introduction==\nUser-Managed Access (UMA) is an OAuth-based  access management protocol standard. Version 1.0 of the standard was approved by the Kantara Initiative on March 23, 2015.As described by the charter of the group that developed UMA, the purpose of the protocol specifications is to \u201cenable a resource owner to control the authorization of data sharing and other protected-resource access made between online services on the owner\u2019s behalf or with the owner\u2019s authorization by an autonomous requesting party\u201d. This purpose has privacy and consent implications for web applications and the Internet of Things (IoT), as explored by the collection of case studies contributed by participants in the standards group.\n\n\n\n== History and background ==\nThe Kantara Initiative's UMA Work Group held its first meeting on August 6, 2009. UMA's design principles and technical design have been informed by previous work by Sun Microsystems employees, begun in March 2008, on a protocol called ProtectServe. In turn, ProtectServe was influenced by the goals of the Vendor Relationship Management movement and an offshoot effort called feeds-based VRM.\nProtectServe and UMA's earliest versions leveraged the OAuth 1.0 protocol. As OAuth underwent significant change through the publication of the Web Resource Authorization Protocol (WRAP) specification and, subsequently, drafts of OAuth 2.0, the UMA specification has kept pace, and it now uses the OAuth 2.0 family of specifications for several key protocol flows.\nUMA does not use or depend on OpenID 2.0 as a means of user identification. However, it optionally uses the OAuth-based OpenID Connect protocol as a means of collecting identity claims from a requesting party in order to attempt to satisfy the authorizing user's access policy.\nUMA also does not use or depend on the eXtensible Access Control Markup Language (XACML) as a means of encoding user policy or requesting policy decisions. UMA does not dictate policy format, as policy evaluation is performed internally to the authorization server (AS) from the UMA perspective. Typically XACML would be used to implement the policies inside the AS. Its implementation is out-of-scope of UMA. The UMA protocol flows for requesting access permission have some features in common with the XACML protocol.\n\n== Standardization status ==\nThe UMA group conducts its work in the Kantara Initiative and has also contributed a series of Internet-Draft specifications to the Internet Engineering Task Force (IETF) as an eventual home for UMA standardization work. To this end, the WG has contributed several individual Internet-Drafts to the IETF for consideration. One of these, a specification for OAuth dynamic client registration, served as input for the more generalized mechanism ultimately developed for OAuth.\nUMA was presented to the OAuth Working Group at the IETF 104 conference in March 2019, but that did not result in any UMA specifications being adopted by the IETF.\n\n== Implementation and adoption status ==\nThe UMA core protocol has several implementations, including several open source implementations. Sources of active and available open-source implementations include ForgeRock, Gluu, IDENTOS Inc., MITREid Connect, Atricore, Node-UMA, Roland Hedberg, Keycloak, and  WSO2 Identity Server. A Kantara Initiative group is working on developing \"free and open-source software (FOSS), in several popular programming languages, that empowers developers to incorporate UMA protection and authorization API enablement into applications, services, and devices\".UMA-enabled products are available from Gluu, Jericho Systems, ForgeRock, IDENTOS Inc. and  WSO2 Identity Server\n\n== Comparison to OAuth 2.0 ==\n\nThe diagram (see right) highlights key additions that UMA makes to OAuth 2.0.\nIn a typical OAuth flow, a human resource owner (RO) operating a client application is redirected to an authorization server (AS) to log in and consent to the issuance of an access token so that the client application can gain access to the resource server (RS) on the RO\u2019s behalf in future, likely in a scoped (limited) fashion. The RS and AS are in all likelihood operating within the same security domain, and any communication between them is not standardized by the main OAuth specification.\nUMA adds three main concepts and corresponding structures and flows. First, it defines a standardized API at the AS, called the protection API, that the RS speaks to; this enables multiple RS\u2019s to communicate with one AS and vice versa, and because the API is itself secured with OAuth, allows for formal trust establishment between each pair. This also allows an AS to present an RO with a centralized user interface. Second, UMA defines a formal notion of a requesting party (RqP) that is autonomous from an RO, enabling party-to-party sharing and delegation of access authorization. An RO need not consent to token issuance at run time but can set policy at an AS, allowing an RqP to attempt access asynchronously. Third, UMA enables access attempts to result in successful issuance of tokens associated with authorization data based on a process of trust elevation in the RqP, for example, gathering identity claims or other claims from them.\n\n== Applicable use cases ==\nUMA's architecture can serve a variety of consumer-facing and enterprise-facing use cases. The UMA group collects case studies on its wiki.One example set of use cases is in healthcare IT and consumer health. In the OpenID Foundation organization, a working group called Health Relationship Trust (HEART) is working to \"harmonize and develop a set of privacy and security specifications that enable an individual to control the authorization of access to RESTful health-related data sharing APIs\", building upon, among other standards, UMA.\nAnother example set of use cases, which originally influenced UMA's development, is in the area of \"personal data stores\" in the fashion of vendor relationship management. In this conception, an individual can choose an operator of an authorization service that accepts connections from a variety of consumer-facing digital resource hosts in order to offer a dashboard with resource sharing management capabilities."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are the implications of zombie cookies on unique user statistics?",
    "context": "",
    "output": "Zombie cookies can skew unique user statistics by counting the same person as multiple unique users after deleting their tracking cookies. This can lead to inflated user statistics for sites using zombie cookies.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are the implications of zombie cookies on unique user statistics?",
      "answer": "Zombie cookies can skew unique user statistics by counting the same person as multiple unique users after deleting their tracking cookies. This can lead to inflated user statistics for sites using zombie cookies."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are some of the security concerns associated with Single Sign-On?",
    "context": "",
    "output": "Some of the security concerns associated with Single Sign-On include the increased negative impact in case the credentials are available to other people and misused, the need for protection of user credentials and the use of strong authentication methods, the high criticality of the authentication systems, and the risk of system failure.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are some of the security concerns associated with Single Sign-On?",
      "answer": "Some of the security concerns associated with Single Sign-On include the increased negative impact in case the credentials are available to other people and misused, the need for protection of user credentials and the use of strong authentication methods, the high criticality of the authentication systems, and the risk of system failure."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the purpose of the \"Other\" chapter in a certificate policy, and what topics might it cover?",
    "context": "",
    "output": "The \"Other\" chapter in a certificate policy covers all remaining points not explicitly addressed in other chapters. This may include PKI-associated legal matters, as well as any other aspects not covered in the previous chapters.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the purpose of the \"Other\" chapter in a certificate policy, and what topics might it cover?",
      "answer": "The \"Other\" chapter in a certificate policy covers all remaining points not explicitly addressed in other chapters. This may include PKI-associated legal matters, as well as any other aspects not covered in the previous chapters."
    }
  },
  {
    "instruction": "Write an answer to the following question: Which organizations are contributing to the development of the Token Binding standard?",
    "context": "",
    "output": "Industry participation in the development of the Token Binding standard is widespread and includes organizations such as Microsoft, Google, PayPal, Ping Identity, and Yubico.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Which organizations are contributing to the development of the Token Binding standard?",
      "answer": "Industry participation in the development of the Token Binding standard is widespread and includes organizations such as Microsoft, Google, PayPal, Ping Identity, and Yubico."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the ordering of releasing measurement data prevent dishonest users from acquiring the secret in the QSS protocol?",
    "context": "",
    "output": "By carefully choosing the order of releasing measurement data (receiver 1 releases measurement results, receiver 2 releases measurement results, receiver 2 releases measurement basis, and receiver 1 releases measurement basis), the QSS protocol prevents dishonest users from knowing which basis to share for tricking the other participants or controlling the correlation of measurements. This ensures that acting dishonestly will introduce errors in the eavesdropper testing phase, making it impossible for a dishonest participant to acquire the secret without being noticed by the other participants.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the ordering of releasing measurement data prevent dishonest users from acquiring the secret in the QSS protocol?",
      "answer": "By carefully choosing the order of releasing measurement data (receiver 1 releases measurement results, receiver 2 releases measurement results, receiver 2 releases measurement basis, and receiver 1 releases measurement basis), the QSS protocol prevents dishonest users from knowing which basis to share for tricking the other participants or controlling the correlation of measurements. This ensures that acting dishonestly will introduce errors in the eavesdropper testing phase, making it impossible for a dishonest participant to acquire the secret without being noticed by the other participants."
    }
  },
  {
    "instruction": "Write an answer to the following question: What actions did Sony's lawyers take after the lawsuit against George Hotz was approved?",
    "context": "",
    "output": "After the lawsuit was approved, Sony's lawyers were authorized to obtain the IP addresses of anyone who visited Hotz's website.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What actions did Sony's lawyers take after the lawsuit against George Hotz was approved?",
      "answer": "After the lawsuit was approved, Sony's lawyers were authorized to obtain the IP addresses of anyone who visited Hotz's website."
    }
  },
  {
    "instruction": "Lords of Dharmaraja\n\n==Introduction==\nLords of Dharmaraja is the name of a hacker group, allegedly operating in India. This group came into the limelight for threatening to release the source code of Symantec's product Norton Antivirus, and for allegations on Government of India \"arm-twisting\" international mobile manufacturers to spy on United States-China Economic and Security Review Commission(USCC). Symantec has confirmed that the Symantec Endpoint Protection 11.0 and Symantec Antivirus 10.2 version source code has been compromised and obtained by the group, while United States authorities are still investigating allegations suspecting India's hand in spying.This group is alleged, to have hacked and posted a threat by uploading the secret documents, memos, and source code of Symantec's product on Pastebin - a website renowned for source code snippets upload by several users, for public viewing. The group, it seems, has uploaded some secret documents, revealing Indian government arm-twisting international mobile manufacturers like RIM, Apple, and Nokia to assist in spying USCC. In addition to these, the group seems to have claimed in discovering source code related to dozen software companies, which have signed agreements with the Indian TANCS programme and \nCBI.After the hacker's posted their threats, Christopher Soghojan, a security and privacy researcher in USA, tweeted: \"Hackers leak Indian Military Intel memo suggesting Apple has provided intercept backdoor to govs\". He also provided the links to the gallery of images and documents. The documents appear to be related to Tactical Network for Cellular Surveillance (TANCS), technical agreement with mobile manufacturers, and email communication stuff associated with members of USCC.\n\n\n\n== Their claims ==\nAs reported in The Times of India article, the group posted a statement on Pastebin website saying, \"As of now, we start sharing with all our brothers and followers information from the Indian Militaty [sic] Intelligence servers, so far, we have discovered within the Indian Spy Programme source codes of a dozen software companies which have signed agreements with Indian TANCS programme and CBI.\"The group also said, \"Now we release confidential documentation we encountered of Symantec corporation and it's Norton AntiVirus source code which we are going to publish later on, we are working out mirrors as of now since we experience extreme pressure and censorship from US and India government agencies.\"When a correspondent of The Times of India tried to reach an alleged member of the Lords of Dharamraja with the name \"YamaTough,\" he did not reply. YamaTough also has a Twitter account; wherein, he described himself as an \"anonymous [avenger] of Indian independence frontier.\"\n\n== Allegations ==\n\n\n*** Cyber spying ***\nAs reported in The Times of India article, based on uploaded secret memos dated October 6, 2011, international mobile manufacturers like RIM, Apple, and Nokia along with domestic Micromax have given \"backdoor access\" for digital surveillance to Indian military intelligence officials in exchange for doing business in Indian market. In the memo, a decision was also made to sign an agreement with mobile manufacturers in exchange for \"business presence\" in the Indian market because military intelligence has no access to United States Chamber of Commerce's LAN due to VPN and communication gateways like POP servers, etc. The memos further reveal that this \"backdoor\" was allegedly used by Indian intelligence to spy on USCC.As reported in Rediff.com article based on leaked documents, Indian Army's intelligence arm Military intelligence along with Central Bureau of Investigation(CBI) were performing bilateral cellular and Internet surveillance operations right from April 2011. Later, in July 2011, during a meeting of the sub-committee of Military Intelligence, a detailed Cyber Defence Plan for 2011 was prepared and subsequently Military intelligence-Central Bureau of Investigation \"joint operations\" are being conducted daily.Another article on The Register based on uploaded documents says, \"CYCADA\" data intercept team are in operation on the networks using backdoors provided by mobile manufacturers. It also says that the leaked memos elicit conversations between members of USCC on currency issues and discussions on the western firms actions in assisting Chinese aircraft industry to improve its \"avionics\" and engine manufacturing too.As reported by the news agency Reuters, USCC officials have asked the \"concerned authorities to investigate the matter\" and didn't dispute the authenticity of intercepted mails pointing the \"backdoor channel\" as evident in the leaked documents. Also reported on Hindustan Times, Jonathan Weston, a spokesman for USCC, said \"We are aware of these reports and have contacted relevant authorities to investigate the matter.\" Apparently, US authorities are investigating the allegations pointing Indian government's spy-unit hacking into emails of US official panel - that monitors economic and security relations between United States and China.Mobile manufacturer officials, more or less, refused to comment on the issue, when The Times of India contacted the relevant spokesmen or authorities. Alan Hely, a senior director of Corporate Communications at Apple Inc., refused to comment on the leaked documents, but he denied any backdoor access been provided. RIM too, refused to comment on the leaked memos as rumors or speculations, when The Register contacted them; besides, RIM countered them saying, \"it does not do deals with specific countries and has no ability to provide its customer's encryption keys.\" A spokesman for Nokia was quoted as saying, \"The company takes the privacy of customers and their data seriously and is committed to comply with all applicable data protection and privacy laws.\"Speaking to Rediff.com on phone, Indian Army denied the reports of spying on USCC through mobile companies; however, military spokesman said that the uploaded documents were in fact forged with malicious intent.\n\n\n*** Symantec's Anti-virus source code ***\nThe hacker's group threatened to publish the entire source code of Norton Antivirus, a Symantec's product, allegedly stolen after the group has discovered it, while hacking the servers associated with India's Military Intelligence. To add weight to its threats, the group posted some of the hacked source code to Pastebin.\nImperva, a data security company, commented on the hacker group's claims and threats as that would potentially be an embarrassment on Symantec's part. Rob Rachwald from Imperva speculated that the hacker group might have retrieved the files as because the files probably resided on a \"test server\" or were posted to FTP; consequently, exposing them mistakenly and became public unintentionally through negligence. He further said that, \"governments do require source code of vendor products to prove that product is not spyware\".Symantec initially, tried to douse the fears saying that the documentation and preview code is nothing special; accordingly, Chris Paden from Symantec said that the published data and documents are no more than Symantec's API documentation which every software vendor, including Symantec will share with any client, including governments. Eventually, Symantec has confirmed that the source code of Symantec Endpoint Protection 11.0 and Symantec Antivirus 10.2 has been compromised to the hacker group.\n\nQ: What is the significance of the Tactical Network for Cellular Surveillance (TANCS) in the alleged cyber spying?",
    "context": "",
    "output": "A: Tactical Network for Cellular Surveillance (TANCS) is significant because it is a system used by the Indian military intelligence for cellular surveillance, which is one of the main focuses of the alleged cyber spying.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the significance of the Tactical Network for Cellular Surveillance (TANCS) in the alleged cyber spying?",
      "answer": "Tactical Network for Cellular Surveillance (TANCS) is significant because it is a system used by the Indian military intelligence for cellular surveillance, which is one of the main focuses of the alleged cyber spying.",
      "context": "Lords of Dharmaraja\n\n==Introduction==\nLords of Dharmaraja is the name of a hacker group, allegedly operating in India. This group came into the limelight for threatening to release the source code of Symantec's product Norton Antivirus, and for allegations on Government of India \"arm-twisting\" international mobile manufacturers to spy on United States-China Economic and Security Review Commission(USCC). Symantec has confirmed that the Symantec Endpoint Protection 11.0 and Symantec Antivirus 10.2 version source code has been compromised and obtained by the group, while United States authorities are still investigating allegations suspecting India's hand in spying.This group is alleged, to have hacked and posted a threat by uploading the secret documents, memos, and source code of Symantec's product on Pastebin - a website renowned for source code snippets upload by several users, for public viewing. The group, it seems, has uploaded some secret documents, revealing Indian government arm-twisting international mobile manufacturers like RIM, Apple, and Nokia to assist in spying USCC. In addition to these, the group seems to have claimed in discovering source code related to dozen software companies, which have signed agreements with the Indian TANCS programme and \nCBI.After the hacker's posted their threats, Christopher Soghojan, a security and privacy researcher in USA, tweeted: \"Hackers leak Indian Military Intel memo suggesting Apple has provided intercept backdoor to govs\". He also provided the links to the gallery of images and documents. The documents appear to be related to Tactical Network for Cellular Surveillance (TANCS), technical agreement with mobile manufacturers, and email communication stuff associated with members of USCC.\n\n\n\n== Their claims ==\nAs reported in The Times of India article, the group posted a statement on Pastebin website saying, \"As of now, we start sharing with all our brothers and followers information from the Indian Militaty [sic] Intelligence servers, so far, we have discovered within the Indian Spy Programme source codes of a dozen software companies which have signed agreements with Indian TANCS programme and CBI.\"The group also said, \"Now we release confidential documentation we encountered of Symantec corporation and it's Norton AntiVirus source code which we are going to publish later on, we are working out mirrors as of now since we experience extreme pressure and censorship from US and India government agencies.\"When a correspondent of The Times of India tried to reach an alleged member of the Lords of Dharamraja with the name \"YamaTough,\" he did not reply. YamaTough also has a Twitter account; wherein, he described himself as an \"anonymous [avenger] of Indian independence frontier.\"\n\n== Allegations ==\n\n\n*** Cyber spying ***\nAs reported in The Times of India article, based on uploaded secret memos dated October 6, 2011, international mobile manufacturers like RIM, Apple, and Nokia along with domestic Micromax have given \"backdoor access\" for digital surveillance to Indian military intelligence officials in exchange for doing business in Indian market. In the memo, a decision was also made to sign an agreement with mobile manufacturers in exchange for \"business presence\" in the Indian market because military intelligence has no access to United States Chamber of Commerce's LAN due to VPN and communication gateways like POP servers, etc. The memos further reveal that this \"backdoor\" was allegedly used by Indian intelligence to spy on USCC.As reported in Rediff.com article based on leaked documents, Indian Army's intelligence arm Military intelligence along with Central Bureau of Investigation(CBI) were performing bilateral cellular and Internet surveillance operations right from April 2011. Later, in July 2011, during a meeting of the sub-committee of Military Intelligence, a detailed Cyber Defence Plan for 2011 was prepared and subsequently Military intelligence-Central Bureau of Investigation \"joint operations\" are being conducted daily.Another article on The Register based on uploaded documents says, \"CYCADA\" data intercept team are in operation on the networks using backdoors provided by mobile manufacturers. It also says that the leaked memos elicit conversations between members of USCC on currency issues and discussions on the western firms actions in assisting Chinese aircraft industry to improve its \"avionics\" and engine manufacturing too.As reported by the news agency Reuters, USCC officials have asked the \"concerned authorities to investigate the matter\" and didn't dispute the authenticity of intercepted mails pointing the \"backdoor channel\" as evident in the leaked documents. Also reported on Hindustan Times, Jonathan Weston, a spokesman for USCC, said \"We are aware of these reports and have contacted relevant authorities to investigate the matter.\" Apparently, US authorities are investigating the allegations pointing Indian government's spy-unit hacking into emails of US official panel - that monitors economic and security relations between United States and China.Mobile manufacturer officials, more or less, refused to comment on the issue, when The Times of India contacted the relevant spokesmen or authorities. Alan Hely, a senior director of Corporate Communications at Apple Inc., refused to comment on the leaked documents, but he denied any backdoor access been provided. RIM too, refused to comment on the leaked memos as rumors or speculations, when The Register contacted them; besides, RIM countered them saying, \"it does not do deals with specific countries and has no ability to provide its customer's encryption keys.\" A spokesman for Nokia was quoted as saying, \"The company takes the privacy of customers and their data seriously and is committed to comply with all applicable data protection and privacy laws.\"Speaking to Rediff.com on phone, Indian Army denied the reports of spying on USCC through mobile companies; however, military spokesman said that the uploaded documents were in fact forged with malicious intent.\n\n\n*** Symantec's Anti-virus source code ***\nThe hacker's group threatened to publish the entire source code of Norton Antivirus, a Symantec's product, allegedly stolen after the group has discovered it, while hacking the servers associated with India's Military Intelligence. To add weight to its threats, the group posted some of the hacked source code to Pastebin.\nImperva, a data security company, commented on the hacker group's claims and threats as that would potentially be an embarrassment on Symantec's part. Rob Rachwald from Imperva speculated that the hacker group might have retrieved the files as because the files probably resided on a \"test server\" or were posted to FTP; consequently, exposing them mistakenly and became public unintentionally through negligence. He further said that, \"governments do require source code of vendor products to prove that product is not spyware\".Symantec initially, tried to douse the fears saying that the documentation and preview code is nothing special; accordingly, Chris Paden from Symantec said that the published data and documents are no more than Symantec's API documentation which every software vendor, including Symantec will share with any client, including governments. Eventually, Symantec has confirmed that the source code of Symantec Endpoint Protection 11.0 and Symantec Antivirus 10.2 has been compromised to the hacker group."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the impact of a successful CookieMonster attack?",
    "context": "",
    "output": "A successful CookieMonster attack can grant unauthorized access to sensitive personal or financial information on affected websites.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the impact of a successful CookieMonster attack?",
      "answer": "A successful CookieMonster attack can grant unauthorized access to sensitive personal or financial information on affected websites."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the role of Security Enhancements for Android (SE for Android) in Samsung Knox?",
    "context": "",
    "output": "SE for Android protects Android phones from malicious code or exploits. Samsung Knox provides periodic updates that check for patches to further protect the system.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of Security Enhancements for Android (SE for Android) in Samsung Knox?",
      "answer": "SE for Android protects Android phones from malicious code or exploits. Samsung Knox provides periodic updates that check for patches to further protect the system."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does FedRAMP aid in eliminating duplicative efforts in assessing cloud services?",
    "context": "",
    "output": "FedRAMP aids in eliminating duplicative efforts in assessing cloud services by requiring federal agencies to use FedRAMP when assessing, authorizing, and continuously monitoring cloud services, which saves government resources.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does FedRAMP aid in eliminating duplicative efforts in assessing cloud services?",
      "answer": "FedRAMP aids in eliminating duplicative efforts in assessing cloud services by requiring federal agencies to use FedRAMP when assessing, authorizing, and continuously monitoring cloud services, which saves government resources."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does SM3 ensure message integrity in digital signatures and message authentication codes?",
    "context": "",
    "output": "SM3 ensures message integrity in digital signatures and message authentication codes by producing a fixed-size hash value that uniquely identifies the message. Any change to the message will result in a different hash value, allowing recipients to detect tampering and ensure the integrity of the message.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does SM3 ensure message integrity in digital signatures and message authentication codes?",
      "answer": "SM3 ensures message integrity in digital signatures and message authentication codes by producing a fixed-size hash value that uniquely identifies the message. Any change to the message will result in a different hash value, allowing recipients to detect tampering and ensure the integrity of the message."
    }
  },
  {
    "instruction": "Answer based on context:\n\nWikiScanner\n\n==Introduction==\nWikiScanner (also known as Wikipedia Scanner) was a publicly searchable database that linked anonymous edits on Wikipedia to the organizations where those edits apparently originated. It did this by cross-referencing the edits with data on the owners of the associated block of IP addresses, though it did not investigate edits made under a username. It was created by Virgil Griffith and released on August 13, 2007.In his \"WikiScanner FAQ\" Griffith stated his belief that WikiScanner could help make Wikipedia more reliable for controversial topics. He also indicated that he had never been employed by the Wikimedia Foundation and claimed his work on WikiScanner was \"100% noncommercial\".\nOn December 21, 2012, a research group from Fondazione Bruno Kessler released an open-source clone of WikiScanner called WikiWatchdog.\nBy April 2013, attempts to run \"WikiScanner Classic\" from wikiscanner.virgil.gr returned to the WikiScanner home page, which identified itself as \"WIKIWATCHER.COM\"; and invoking \"WikiScanner2 PreviewNew!\" led to a \"failure to load the page due to timeout\" error.In 2007, Virgil Griffith said he had to take wikiscanner down, as it was costing him \"several thousand USD per month.\"  He added below this on his wikiscanner webpage that as a grad student at Caltech in 2008 he developed with the aid of several undergraduates \"a suite of Wikipedia-related tools known collectively as \"WikiWatcher\" which included: WikiScanner2 (Daniel), Wikiganda (Rishi), Poor Man's Checkuser, and BeaverScope,\" which he launched at the Hackers on Planet Earth (HOPE) conference that year.  They used used \"high-quality data\" from Quova, and among them WikiWatcher \"had some media successes, but when the summer was over there was no one to maintain the tools and they fell into disrepair.\"\n\n\n\n== Design ==\nThe tool's database contained 34 million entries on anonymous edits (those by users who were not logged in to Wikipedia) between February 7, 2002, and August 4, 2007. Griffith stated that the database was constructed by compiling the anonymous edits included amongst the monthly public database dumps of Wikipedia. He claimed to have connected the organizations to their IP address with the assistance of the IP2Location database, and through comparison had found \"187,529 different organizations with at least one anonymous Wikipedia edit.\"WikiScanner only worked on anonymous edits, which are made under an IP address, not edits by anyone logged in under a username. It could not distinguish between edits made by authorized users of an organization, unauthorized intruders, or users of public-access computers that may have been using an organization's network. In discussing edits made from computers in the Vatican, computer expert Kevin Curran was quoted by the BBC as saying that it was \"difficult to determine if the person was an employee or if they had maliciously hacked into the Vatican system and were 'spoofing' the IP address.\"The WikiScanner FAQ noted that edits could not be positively attributed to representatives of a company, only to a computer logged into a company's network. The FAQ went on to say there is no guarantee that an edit was made by an authorized user rather than an intruder. The likelihood of such intrusions depended upon an organizations' network security; organizations such as the Vatican Library have public access terminals or networks.\n\n== Media coverage and reaction ==\nAccording to Wired, which first broke the story on 13 August 2007, most edits were \"fairly innocuous\". Wired asked users to submit \"The most shameful Wikipedia spin jobs\", which generated many news stories about organizations, such as the Al-Jazeera network, Fox News Channel, staffers of Democratic Senator Robert Byrd and the CIA, that had edited Wikipedia articles.\nOn August 21, 2007, satirist Stephen Colbert who had long featured stories about Wikipedia and its \"truthiness\" on his program mocked WikiScanner creator Virgil Griffith's ambivalent stance on anonymity on Wikipedia, declaring it the \"right\" of corporations and governments to participate in the democratic process of deciding what is and is not true on Wikipedia.According to the BBC from August 15, 2007, WikiScanner found that some editorial contributions to Wikipedia had originated from computers operated by the Diebold company, the Democratic Congressional Campaign Committee, as well as the Vatican. The Times reported that an IP address at the BBC had made edits to Wikipedia. The BBC's Head of Interactive News, Pete Clifton  published a blog on August 16 acknowledging the earlier omission, but characterized the BBC's edits of Wikipedia in this manner: \"Some of the examples are pretty unedifying, but for every dodgy one there are many, many more uncontroversial edits where people at the BBC have added information or changed a detail in good faith\".The Associated Press reported on August 15, 2007, that computers owned by the Church of Scientology had been used to remove criticism from articles about Scientology on Wikipedia, including edits to the article Cult Awareness Network. The Associated Press admitted that edits to Wikipedia had been made anonymously from its own computers, though the news organization did not describe the content of the edits. In its story on WikiScanner, the New York Times too admitted that edits had been made from its own computers. Wired.com reported that the office of former Republican Senator Conrad Burns had also edited critical passages.According to Maltastar.com from August 16, WikiScanner has shown edits by other large organizations, including Amnesty International, Apple Inc., ChevronTexaco, Coca-Cola, the British Conservative Party, Dell Computers, EA Games, Exxon Mobil, the FBI, The Guardian, Microsoft, MySpace, the National Rifle Association of America, Nestl\u00e9, News of the World, the New York Times, the Government of Portugal, the US Republican Party, Reuters, Sony, the United Nations, Walmart, and a dog breeding association. The Canadian television network CTV reported edits by other organizations including Disney and the Canadian government.Reuters reported that CIA computers were used to edit an article regarding the 2003 United States invasion of Iraq, including editing a chart showing casualties. CIA computers also edited the article for former CIA chief William Colby. Reuters reported that an FBI computer edited an article on the United States prison at Guantanamo Bay.On August 24, 2007, headline reports in the Australian print and electronic media were made of anonymous edits to Wikipedia by staff in the Australian Department of Prime Minister and Cabinet in order to remove potentially damaging details from articles related to the Government. Information found using WikiScanner showed 126 anonymous edits from the department to articles on sometimes controversial issues and on government ministers. The department responded by saying that Prime Minister John Howard did not direct his staff to modify the articles, and later that day the head of the department said that the changes were not made by anyone in his department or the Prime Minister's office, but by another user with the same Internet service provider. Wikiscanner also identified Australian Department of Defence (DoD) employees as having made over 5,000 edits, prompting an unprecedented announcement from the DoD to block Defence staff from editing Wikipedia in case edits were interpreted as official comment.On August 26, 2007, The Boston Globe published an editorial about Wikipedia, described as a \"democratic fountain of facts\" and related WikiScanner technology, reporting as among those companies found to have edited Wikipedia were Pepsi, Wal-Mart, ExxonMobil and Royal Dutch Shell, in which specific case \"In 2005, someone using a computer inside Royal Dutch Shell, the oil company, rewrote a benign description of the company, claiming it is 'run by a group of geriatrics who find it impossible to make timely decisions and have an aversion to highly-profitable ventures.'\" The WikiScanner story was also covered by The Independent, which stated that many \"censorial interventions\" by editors with vested interests on a variety of articles in Wikipedia had been discovered.On December 18, 2007, Fortune magazine mentioned the use of WikiScanner in the 96th of its list of the \"101 Dumbest Moments in Business\", saying, \"A Washington Post employee is found to have changed a reference to the owner of a rival paper from Philip Anschutz to Charles Manson, while someone at The New York Times added the word 'jerk' 12 times to the entry on George W. Bush.\"During the period of May 27 to June 4, 2008, edits originating from an IP address belonging to Industry Canada were made to the Jim Prentice (Federal Minister of Industry) article on Wikipedia. The edits included the removal of references to new copyright legislation and the addition of two passages about Prentice's recent accomplishments as Minister of Industry.\n\n== Wikipedia reaction ==\nWikipedia co-founder Jimmy Wales spoke enthusiastically about WikiScanner, noting that \"It brings an additional level of transparency to what's going on at Wikipedia\" and that it was \"fabulous and I strongly support it.\" The BBC quoted an unnamed Wikipedia spokesperson's praise for the tool in taking transparency \"to another level\" and preventing \"an organisation or individuals from editing articles that they're really not supposed to.\" In responding to the edits from the Canadian Ministry of Industry, spokesman for the Wikimedia Foundation Jay Walsh noted that neutrality of language and guarding against conflicts of interest are two of the central pillars of Wikipedia, adding that \"The edits which should be trusted would come from people who don't possess a conflict of interest, in this case, it would be worthwhile saying that if someone is making edits from a computer within the government of Canada \u2026 if it was someone within that ministry, that would theoretically constitute a conflict of interest.\"Wales speculated on a possible warning to anonymous editors: \"When someone clicks on 'edit,' it would be interesting if we could say, 'Hi, thank you for editing. We see you're logged in from The New York Times. Keep in mind that we know that, and it's public information' \u2026 That might make them stop and think.\"\n\nWhat belief did Virgil Griffith express about how WikiScanner could help make Wikipedia more reliable for controversial topics?",
    "context": "",
    "output": "Virgil Griffith believed that WikiScanner could help make Wikipedia more reliable for controversial topics by exposing anonymous edits to those topics.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What belief did Virgil Griffith express about how WikiScanner could help make Wikipedia more reliable for controversial topics?",
      "answer": "Virgil Griffith believed that WikiScanner could help make Wikipedia more reliable for controversial topics by exposing anonymous edits to those topics.",
      "context": "WikiScanner\n\n==Introduction==\nWikiScanner (also known as Wikipedia Scanner) was a publicly searchable database that linked anonymous edits on Wikipedia to the organizations where those edits apparently originated. It did this by cross-referencing the edits with data on the owners of the associated block of IP addresses, though it did not investigate edits made under a username. It was created by Virgil Griffith and released on August 13, 2007.In his \"WikiScanner FAQ\" Griffith stated his belief that WikiScanner could help make Wikipedia more reliable for controversial topics. He also indicated that he had never been employed by the Wikimedia Foundation and claimed his work on WikiScanner was \"100% noncommercial\".\nOn December 21, 2012, a research group from Fondazione Bruno Kessler released an open-source clone of WikiScanner called WikiWatchdog.\nBy April 2013, attempts to run \"WikiScanner Classic\" from wikiscanner.virgil.gr returned to the WikiScanner home page, which identified itself as \"WIKIWATCHER.COM\"; and invoking \"WikiScanner2 PreviewNew!\" led to a \"failure to load the page due to timeout\" error.In 2007, Virgil Griffith said he had to take wikiscanner down, as it was costing him \"several thousand USD per month.\"  He added below this on his wikiscanner webpage that as a grad student at Caltech in 2008 he developed with the aid of several undergraduates \"a suite of Wikipedia-related tools known collectively as \"WikiWatcher\" which included: WikiScanner2 (Daniel), Wikiganda (Rishi), Poor Man's Checkuser, and BeaverScope,\" which he launched at the Hackers on Planet Earth (HOPE) conference that year.  They used used \"high-quality data\" from Quova, and among them WikiWatcher \"had some media successes, but when the summer was over there was no one to maintain the tools and they fell into disrepair.\"\n\n\n\n== Design ==\nThe tool's database contained 34 million entries on anonymous edits (those by users who were not logged in to Wikipedia) between February 7, 2002, and August 4, 2007. Griffith stated that the database was constructed by compiling the anonymous edits included amongst the monthly public database dumps of Wikipedia. He claimed to have connected the organizations to their IP address with the assistance of the IP2Location database, and through comparison had found \"187,529 different organizations with at least one anonymous Wikipedia edit.\"WikiScanner only worked on anonymous edits, which are made under an IP address, not edits by anyone logged in under a username. It could not distinguish between edits made by authorized users of an organization, unauthorized intruders, or users of public-access computers that may have been using an organization's network. In discussing edits made from computers in the Vatican, computer expert Kevin Curran was quoted by the BBC as saying that it was \"difficult to determine if the person was an employee or if they had maliciously hacked into the Vatican system and were 'spoofing' the IP address.\"The WikiScanner FAQ noted that edits could not be positively attributed to representatives of a company, only to a computer logged into a company's network. The FAQ went on to say there is no guarantee that an edit was made by an authorized user rather than an intruder. The likelihood of such intrusions depended upon an organizations' network security; organizations such as the Vatican Library have public access terminals or networks.\n\n== Media coverage and reaction ==\nAccording to Wired, which first broke the story on 13 August 2007, most edits were \"fairly innocuous\". Wired asked users to submit \"The most shameful Wikipedia spin jobs\", which generated many news stories about organizations, such as the Al-Jazeera network, Fox News Channel, staffers of Democratic Senator Robert Byrd and the CIA, that had edited Wikipedia articles.\nOn August 21, 2007, satirist Stephen Colbert who had long featured stories about Wikipedia and its \"truthiness\" on his program mocked WikiScanner creator Virgil Griffith's ambivalent stance on anonymity on Wikipedia, declaring it the \"right\" of corporations and governments to participate in the democratic process of deciding what is and is not true on Wikipedia.According to the BBC from August 15, 2007, WikiScanner found that some editorial contributions to Wikipedia had originated from computers operated by the Diebold company, the Democratic Congressional Campaign Committee, as well as the Vatican. The Times reported that an IP address at the BBC had made edits to Wikipedia. The BBC's Head of Interactive News, Pete Clifton  published a blog on August 16 acknowledging the earlier omission, but characterized the BBC's edits of Wikipedia in this manner: \"Some of the examples are pretty unedifying, but for every dodgy one there are many, many more uncontroversial edits where people at the BBC have added information or changed a detail in good faith\".The Associated Press reported on August 15, 2007, that computers owned by the Church of Scientology had been used to remove criticism from articles about Scientology on Wikipedia, including edits to the article Cult Awareness Network. The Associated Press admitted that edits to Wikipedia had been made anonymously from its own computers, though the news organization did not describe the content of the edits. In its story on WikiScanner, the New York Times too admitted that edits had been made from its own computers. Wired.com reported that the office of former Republican Senator Conrad Burns had also edited critical passages.According to Maltastar.com from August 16, WikiScanner has shown edits by other large organizations, including Amnesty International, Apple Inc., ChevronTexaco, Coca-Cola, the British Conservative Party, Dell Computers, EA Games, Exxon Mobil, the FBI, The Guardian, Microsoft, MySpace, the National Rifle Association of America, Nestl\u00e9, News of the World, the New York Times, the Government of Portugal, the US Republican Party, Reuters, Sony, the United Nations, Walmart, and a dog breeding association. The Canadian television network CTV reported edits by other organizations including Disney and the Canadian government.Reuters reported that CIA computers were used to edit an article regarding the 2003 United States invasion of Iraq, including editing a chart showing casualties. CIA computers also edited the article for former CIA chief William Colby. Reuters reported that an FBI computer edited an article on the United States prison at Guantanamo Bay.On August 24, 2007, headline reports in the Australian print and electronic media were made of anonymous edits to Wikipedia by staff in the Australian Department of Prime Minister and Cabinet in order to remove potentially damaging details from articles related to the Government. Information found using WikiScanner showed 126 anonymous edits from the department to articles on sometimes controversial issues and on government ministers. The department responded by saying that Prime Minister John Howard did not direct his staff to modify the articles, and later that day the head of the department said that the changes were not made by anyone in his department or the Prime Minister's office, but by another user with the same Internet service provider. Wikiscanner also identified Australian Department of Defence (DoD) employees as having made over 5,000 edits, prompting an unprecedented announcement from the DoD to block Defence staff from editing Wikipedia in case edits were interpreted as official comment.On August 26, 2007, The Boston Globe published an editorial about Wikipedia, described as a \"democratic fountain of facts\" and related WikiScanner technology, reporting as among those companies found to have edited Wikipedia were Pepsi, Wal-Mart, ExxonMobil and Royal Dutch Shell, in which specific case \"In 2005, someone using a computer inside Royal Dutch Shell, the oil company, rewrote a benign description of the company, claiming it is 'run by a group of geriatrics who find it impossible to make timely decisions and have an aversion to highly-profitable ventures.'\" The WikiScanner story was also covered by The Independent, which stated that many \"censorial interventions\" by editors with vested interests on a variety of articles in Wikipedia had been discovered.On December 18, 2007, Fortune magazine mentioned the use of WikiScanner in the 96th of its list of the \"101 Dumbest Moments in Business\", saying, \"A Washington Post employee is found to have changed a reference to the owner of a rival paper from Philip Anschutz to Charles Manson, while someone at The New York Times added the word 'jerk' 12 times to the entry on George W. Bush.\"During the period of May 27 to June 4, 2008, edits originating from an IP address belonging to Industry Canada were made to the Jim Prentice (Federal Minister of Industry) article on Wikipedia. The edits included the removal of references to new copyright legislation and the addition of two passages about Prentice's recent accomplishments as Minister of Industry.\n\n== Wikipedia reaction ==\nWikipedia co-founder Jimmy Wales spoke enthusiastically about WikiScanner, noting that \"It brings an additional level of transparency to what's going on at Wikipedia\" and that it was \"fabulous and I strongly support it.\" The BBC quoted an unnamed Wikipedia spokesperson's praise for the tool in taking transparency \"to another level\" and preventing \"an organisation or individuals from editing articles that they're really not supposed to.\" In responding to the edits from the Canadian Ministry of Industry, spokesman for the Wikimedia Foundation Jay Walsh noted that neutrality of language and guarding against conflicts of interest are two of the central pillars of Wikipedia, adding that \"The edits which should be trusted would come from people who don't possess a conflict of interest, in this case, it would be worthwhile saying that if someone is making edits from a computer within the government of Canada \u2026 if it was someone within that ministry, that would theoretically constitute a conflict of interest.\"Wales speculated on a possible warning to anonymous editors: \"When someone clicks on 'edit,' it would be interesting if we could say, 'Hi, thank you for editing. We see you're logged in from The New York Times. Keep in mind that we know that, and it's public information' \u2026 That might make them stop and think.\""
    }
  },
  {
    "instruction": "Network mapping\n\n==Introduction==\nNetwork mapping is the study of the physical connectivity of networks e.g. the Internet. Network mapping discovers the devices on the network and their connectivity. It is not to be confused with network discovery or network enumerating which discovers devices on the network and their characteristics such as (operating system, open ports, listening network services, etc.). The field of automated network mapping has taken on greater importance as networks become more dynamic and complex in nature.\n\n\n\n== Large-scale mapping project ==\nImages of some of the first attempts at a large scale map of the internet were produced by the Internet Mapping Project and appeared in Wired magazine. The maps produced by this project were based on the layer 3 or IP level connectivity of the Internet (see OSI model), but there are different aspects of internet structure that have also been mapped.\nMore recent efforts to map the internet have been improved by more sophisticated methods, allowing them to make faster and more sensible maps.  An example of such an effort is the OPTE project, which is attempting to develop a system capable of mapping the internet in a single day.\nThe \"Map of the Internet Project\" maps over 4 billion internet locations as cubes in 3D cyberspace.  Users can add URLs as cubes and re-arrange objects on the map.\nIn early 2011 Canadian based ISP PEER 1 Hosting created their own Map of the Internet that depicts a graph of 19,869 autonomous system nodes connected by 44,344 connections. The sizing and layout of the autonomous systems was calculated based on their eigenvector centrality, which is a measure of how central to the network each autonomous system is.\nGraph theory can be used to better understand maps of the internet and to help choose between the many ways to visualize internet maps. Some projects have attempted to incorporate geographical data into their internet maps (for example, to draw locations of routers and nodes on a map of the world), but others are only concerned with representing the more abstract structures of the internet, such as the allocation, structure, and purpose of IP space.\n\n== Enterprise network mapping ==\nMany organizations create network maps of their network system. These maps can be made manually using simple tools such as Microsoft Visio, or the mapping process can be simplified by using tools that integrate auto network discovery with Network mapping, one such example being the Fabric platform. Many of the vendors from the Notable network mappers list enable you to customize the maps and include your own labels, add un-discoverable items and background images. Sophisticated mapping is used to help visualize the network and understand relationships between end devices and the transport layers that provide service. Mostly, network scanners detect the network with all its components and deliver a list which is used for creating charts and maps using network mapping software. Items such as bottlenecks and root cause analysis can be easier to spot using these tools.\nThere are three main techniques used for network mapping: SNMP based approaches, active probing and route analytics.\nThe SNMP based approach retrieves data from Router and Switch MIBs in order to build the network map. The active probing approach relies on a series of traceroute-like probe packets in order to build the network map. The route analytics approach relies on information from the routing protocols to build the network map. Each of the three approaches have advantages and disadvantages in the methods that they use.\n\n== Internet mapping techniques ==\nThere are two prominent techniques used today to create Internet maps.  The first works on the data plane of the Internet and is called active probing.  It is used to infer Internet topology based on router adjacencies.  The second works on the control plane and infers autonomous system connectivity based on BGP data. A BGP speaker sends 19-byte keep-alive messages every 60 seconds to maintain the connection.\n\n\n*** Active probing ***\nThis technique relies on traceroute-like probing on the IP address space. These probes report back IP forwarding paths to the destination address.  By combining these paths one can infer router level topology for a given POP.  Active probing is advantageous in that the paths returned by probes constitute the actual forwarding path that data takes through networks.  It is also more likely to find peering links between ISPs. However, active probing requires massive amounts of probes to map the entire Internet. It is more likely to infer false topologies due to load balancing routers and routers with multiple IP address aliases.  Decreased global support for enhanced probing mechanisms such as source-route probing, ICMP Echo Broadcasting, and IP Address Resolution techniques leaves this type of probing in the realm of network diagnosis.\n\n\n*** AS PATH inference ***\nThis technique relies on various BGP collectors who collect routing updates and tables and provide this information publicly.  Each BGP entry contains a Path Vector attribute called the AS Path.  This path represents an autonomous system forwarding path from a given origin for a given set of prefixes.  These paths can be used to infer AS-level connectivity and in turn be used to build AS topology graphs.  However, these paths do not necessarily reflect how data is actually forwarded and adjacencies between AS nodes only represent a policy relationship between them.  A single AS link can in reality be several router links.  It is also much harder to infer peerings between two AS nodes as these peering relationships are only propagated to an ISP's customer networks.  Nevertheless, support for this type of mapping is increasing as more and more ISP's offer to peer with public route collectors such as Route-Views and RIPE. New toolsets are emerging such as Cyclops and NetViews that take advantage of a new experimental BGP collector BGPMon. NetViews can not only build topology maps in seconds but visualize topology changes moments after occurring at the actual router.  Hence, routing dynamics can be visualized in real time. \nIn comparison to what the tools using BGPMon does there is another tool netTransformer able to discover and generate BGP peering maps either through SNMP polling or by converting MRT dumps to a graphml file format. netTransformer allows us also to perform network diffs between any two dumps and thus to reason how does the BGP peering has evolved through the years. WhatsUp Gold, an IT monitoring tool, tracks networks, servers, applications, storage devices, virtual devices and incorporates infrastructure management, application performance management.\nQuestion: How does WhatsUp Gold, an IT monitoring tool, differ from other internet mapping tools in terms of network tracking and infrastructure management?",
    "context": "",
    "output": "Answer: WhatsUp Gold is an IT monitoring tool that tracks networks, servers, applications, storage devices, virtual devices, and incorporates infrastructure management, application performance management. In contrast, other internet mapping tools may not provide as comprehensive a view of the network infrastructure and may not include features for monitoring and managing network performance.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does WhatsUp Gold, an IT monitoring tool, differ from other internet mapping tools in terms of network tracking and infrastructure management?",
      "answer": "WhatsUp Gold is an IT monitoring tool that tracks networks, servers, applications, storage devices, virtual devices, and incorporates infrastructure management, application performance management. In contrast, other internet mapping tools may not provide as comprehensive a view of the network infrastructure and may not include features for monitoring and managing network performance.",
      "context": "Network mapping\n\n==Introduction==\nNetwork mapping is the study of the physical connectivity of networks e.g. the Internet. Network mapping discovers the devices on the network and their connectivity. It is not to be confused with network discovery or network enumerating which discovers devices on the network and their characteristics such as (operating system, open ports, listening network services, etc.). The field of automated network mapping has taken on greater importance as networks become more dynamic and complex in nature.\n\n\n\n== Large-scale mapping project ==\nImages of some of the first attempts at a large scale map of the internet were produced by the Internet Mapping Project and appeared in Wired magazine. The maps produced by this project were based on the layer 3 or IP level connectivity of the Internet (see OSI model), but there are different aspects of internet structure that have also been mapped.\nMore recent efforts to map the internet have been improved by more sophisticated methods, allowing them to make faster and more sensible maps.  An example of such an effort is the OPTE project, which is attempting to develop a system capable of mapping the internet in a single day.\nThe \"Map of the Internet Project\" maps over 4 billion internet locations as cubes in 3D cyberspace.  Users can add URLs as cubes and re-arrange objects on the map.\nIn early 2011 Canadian based ISP PEER 1 Hosting created their own Map of the Internet that depicts a graph of 19,869 autonomous system nodes connected by 44,344 connections. The sizing and layout of the autonomous systems was calculated based on their eigenvector centrality, which is a measure of how central to the network each autonomous system is.\nGraph theory can be used to better understand maps of the internet and to help choose between the many ways to visualize internet maps. Some projects have attempted to incorporate geographical data into their internet maps (for example, to draw locations of routers and nodes on a map of the world), but others are only concerned with representing the more abstract structures of the internet, such as the allocation, structure, and purpose of IP space.\n\n== Enterprise network mapping ==\nMany organizations create network maps of their network system. These maps can be made manually using simple tools such as Microsoft Visio, or the mapping process can be simplified by using tools that integrate auto network discovery with Network mapping, one such example being the Fabric platform. Many of the vendors from the Notable network mappers list enable you to customize the maps and include your own labels, add un-discoverable items and background images. Sophisticated mapping is used to help visualize the network and understand relationships between end devices and the transport layers that provide service. Mostly, network scanners detect the network with all its components and deliver a list which is used for creating charts and maps using network mapping software. Items such as bottlenecks and root cause analysis can be easier to spot using these tools.\nThere are three main techniques used for network mapping: SNMP based approaches, active probing and route analytics.\nThe SNMP based approach retrieves data from Router and Switch MIBs in order to build the network map. The active probing approach relies on a series of traceroute-like probe packets in order to build the network map. The route analytics approach relies on information from the routing protocols to build the network map. Each of the three approaches have advantages and disadvantages in the methods that they use.\n\n== Internet mapping techniques ==\nThere are two prominent techniques used today to create Internet maps.  The first works on the data plane of the Internet and is called active probing.  It is used to infer Internet topology based on router adjacencies.  The second works on the control plane and infers autonomous system connectivity based on BGP data. A BGP speaker sends 19-byte keep-alive messages every 60 seconds to maintain the connection.\n\n\n*** Active probing ***\nThis technique relies on traceroute-like probing on the IP address space. These probes report back IP forwarding paths to the destination address.  By combining these paths one can infer router level topology for a given POP.  Active probing is advantageous in that the paths returned by probes constitute the actual forwarding path that data takes through networks.  It is also more likely to find peering links between ISPs. However, active probing requires massive amounts of probes to map the entire Internet. It is more likely to infer false topologies due to load balancing routers and routers with multiple IP address aliases.  Decreased global support for enhanced probing mechanisms such as source-route probing, ICMP Echo Broadcasting, and IP Address Resolution techniques leaves this type of probing in the realm of network diagnosis.\n\n\n*** AS PATH inference ***\nThis technique relies on various BGP collectors who collect routing updates and tables and provide this information publicly.  Each BGP entry contains a Path Vector attribute called the AS Path.  This path represents an autonomous system forwarding path from a given origin for a given set of prefixes.  These paths can be used to infer AS-level connectivity and in turn be used to build AS topology graphs.  However, these paths do not necessarily reflect how data is actually forwarded and adjacencies between AS nodes only represent a policy relationship between them.  A single AS link can in reality be several router links.  It is also much harder to infer peerings between two AS nodes as these peering relationships are only propagated to an ISP's customer networks.  Nevertheless, support for this type of mapping is increasing as more and more ISP's offer to peer with public route collectors such as Route-Views and RIPE. New toolsets are emerging such as Cyclops and NetViews that take advantage of a new experimental BGP collector BGPMon. NetViews can not only build topology maps in seconds but visualize topology changes moments after occurring at the actual router.  Hence, routing dynamics can be visualized in real time. \nIn comparison to what the tools using BGPMon does there is another tool netTransformer able to discover and generate BGP peering maps either through SNMP polling or by converting MRT dumps to a graphml file format. netTransformer allows us also to perform network diffs between any two dumps and thus to reason how does the BGP peering has evolved through the years. WhatsUp Gold, an IT monitoring tool, tracks networks, servers, applications, storage devices, virtual devices and incorporates infrastructure management, application performance management."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the role of proof-of-possession in CMP?",
    "context": "",
    "output": "Proof-of-possession is a mechanism in CMP used to verify that the requester of a certificate has access to the corresponding private key. It is usually done by a self-signature of the requested certificate contents, but CMP supports also other methods.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of proof-of-possession in CMP?",
      "answer": "Proof-of-possession is a mechanism in CMP used to verify that the requester of a certificate has access to the corresponding private key. It is usually done by a self-signature of the requested certificate contents, but CMP supports also other methods."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are the common cryptographic libraries that provide support for DSA?",
    "context": "",
    "output": "The common cryptographic libraries that provide support for DSA include Botan, Bouncy Castle, cryptlib, Crypto++, libgcrypt, Nettle, OpenSSL, wolfCrypt, and GnuTLS.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are the common cryptographic libraries that provide support for DSA?",
      "answer": "The common cryptographic libraries that provide support for DSA include Botan, Bouncy Castle, cryptlib, Crypto++, libgcrypt, Nettle, OpenSSL, wolfCrypt, and GnuTLS."
    }
  },
  {
    "instruction": "Write an answer to the following question: What did the Treasury Department say about John Solomon's role in spreading disinformation about Biden?",
    "context": "",
    "output": "The Treasury Department said that journalists like John Solomon, a contributor to Fox News, were pivotal for the dissemination of disinformation about Biden and aided Giuliani and Derkach's efforts to spread anti-Biden material during Trump's impeachment.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What did the Treasury Department say about John Solomon's role in spreading disinformation about Biden?",
      "answer": "The Treasury Department said that journalists like John Solomon, a contributor to Fox News, were pivotal for the dissemination of disinformation about Biden and aided Giuliani and Derkach's efforts to spread anti-Biden material during Trump's impeachment."
    }
  },
  {
    "instruction": "Cyber and Information Domain Service\n\n==Introduction==\nThe Cyber and Information Domain Service (German: Cyber- und Informationsraum, German pronunciation: [\u02c8sa\u026a\u032fb\u0250 \u028ant \u026anf\u0254\u0281ma\u02c8t\u0361si\u032fo\u02d0ns\u02cc\u0281a\u028a\u032fm] (listen); CIR) is the youngest branch of Germany's military, the Bundeswehr. The decision to form a new  military branch was presented by Defense Minister Ursula von der Leyen on 26 April 2016, becoming operational on 1 April 2017. The headquarter of the Cyber and Information Domain Service is Bonn.\n\n== Organisation ==\nThe CIDS is commanded by the Chief of the Cyber and Information Domain Service (Inspekteur des Cyber- und Informationsraum) (InspCIR), a three-star general position, based in Bonn.\nChief CIDS and Commander CIDS HQ\nDeputy Commander CIDS HQ and Chief of Staff\nCommand Staff\nOperations Staff\nPlanning Staff\n Cyber and Information Domain Service Command (Kommando Cyber- und Informationsraum KdoCIR), in Bonn\n Strategic Reconnaissance Command (Kommando Strategische Aufkl\u00e4rung KSA), in Gelsdorf\n 911th Electronic Warfare Battalion\n 912th Electronic Warfare Battalion, mans the Oste-class SIGINT/ELINT and reconnaissance ships\n 931st Electronic Warfare Battalion\n 932nd Electronic Warfare Battalion, provides airborne troops for operations in enemy territory\n Bundeswehr Strategic Reconnaissance School\nBundeswehr Operational Communications Center\nCyber-Operations Center\nElectronic Warfare Analysis Center\nCentral Imaging Reconnaissance, operating the SAR-Lupe satellites\n Central Bundeswehr Investigation Authority for Technical Reconnaissance\n Bundeswehr Geoinformation Centre (Zentrum f\u00fcr Geoinformationswesen der Bundeswehr), in Euskirchen\n Information Technology Command (Kommando Informationstechnik der Bundeswehr), in Bonn\n Bundeswehr IT Operations Center\n Bundeswehr Information Technology School\n 281st Information Technology Battalion\n 282nd Information Technology Battalion\n 292nd Information Technology Battalion\n 293rd Information Technology Battalion\n 381st Information Technology Battalion\n 383rd Information Technology Battalion\nBundeswehr Cyber-Security Center\nBundeswehr Software Competence Center\nQuestion: What is the role of the Central Bundeswehr Investigation Authority for Technical Reconnaissance in the CIDS organization?",
    "context": "",
    "output": "Answer: The Central Bundeswehr Investigation Authority for Technical Reconnaissance is responsible for investigating technical reconnaissance operations, ensuring that the CIDS is operating within the bounds of the law and international agreements.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of the Central Bundeswehr Investigation Authority for Technical Reconnaissance in the CIDS organization?",
      "answer": "The Central Bundeswehr Investigation Authority for Technical Reconnaissance is responsible for investigating technical reconnaissance operations, ensuring that the CIDS is operating within the bounds of the law and international agreements.",
      "context": "Cyber and Information Domain Service\n\n==Introduction==\nThe Cyber and Information Domain Service (German: Cyber- und Informationsraum, German pronunciation: [\u02c8sa\u026a\u032fb\u0250 \u028ant \u026anf\u0254\u0281ma\u02c8t\u0361si\u032fo\u02d0ns\u02cc\u0281a\u028a\u032fm] (listen); CIR) is the youngest branch of Germany's military, the Bundeswehr. The decision to form a new  military branch was presented by Defense Minister Ursula von der Leyen on 26 April 2016, becoming operational on 1 April 2017. The headquarter of the Cyber and Information Domain Service is Bonn.\n\n== Organisation ==\nThe CIDS is commanded by the Chief of the Cyber and Information Domain Service (Inspekteur des Cyber- und Informationsraum) (InspCIR), a three-star general position, based in Bonn.\nChief CIDS and Commander CIDS HQ\nDeputy Commander CIDS HQ and Chief of Staff\nCommand Staff\nOperations Staff\nPlanning Staff\n Cyber and Information Domain Service Command (Kommando Cyber- und Informationsraum KdoCIR), in Bonn\n Strategic Reconnaissance Command (Kommando Strategische Aufkl\u00e4rung KSA), in Gelsdorf\n 911th Electronic Warfare Battalion\n 912th Electronic Warfare Battalion, mans the Oste-class SIGINT/ELINT and reconnaissance ships\n 931st Electronic Warfare Battalion\n 932nd Electronic Warfare Battalion, provides airborne troops for operations in enemy territory\n Bundeswehr Strategic Reconnaissance School\nBundeswehr Operational Communications Center\nCyber-Operations Center\nElectronic Warfare Analysis Center\nCentral Imaging Reconnaissance, operating the SAR-Lupe satellites\n Central Bundeswehr Investigation Authority for Technical Reconnaissance\n Bundeswehr Geoinformation Centre (Zentrum f\u00fcr Geoinformationswesen der Bundeswehr), in Euskirchen\n Information Technology Command (Kommando Informationstechnik der Bundeswehr), in Bonn\n Bundeswehr IT Operations Center\n Bundeswehr Information Technology School\n 281st Information Technology Battalion\n 282nd Information Technology Battalion\n 292nd Information Technology Battalion\n 293rd Information Technology Battalion\n 381st Information Technology Battalion\n 383rd Information Technology Battalion\nBundeswehr Cyber-Security Center\nBundeswehr Software Competence Center"
    }
  },
  {
    "instruction": "Write an answer to the following question: What security measures are taken for bastion hosts beyond being placed in a DMZ and having networking interfaces that can withstand high-bandwidth attacks?",
    "context": "",
    "output": "Bastion hosts often have extra attention paid to their security, undergo regular audits, and may have modified software to minimize the chances of penetration.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What security measures are taken for bastion hosts beyond being placed in a DMZ and having networking interfaces that can withstand high-bandwidth attacks?",
      "answer": "Bastion hosts often have extra attention paid to their security, undergo regular audits, and may have modified software to minimize the chances of penetration."
    }
  },
  {
    "instruction": "Write an answer to the following question: What was the impact of the mass assignment vulnerability discovered in Ruby on Rails in 2012, and how was it exploited?",
    "context": "",
    "output": "The mass assignment vulnerability discovered in Ruby on Rails in 2012 allowed for the bypassing of mapping restrictions and the injection of unauthorized SSH public keys into user accounts at GitHub. This vulnerability was exploited through specially crafted JSON structures that created internal objects, resulting in unauthorized access and data modification.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was the impact of the mass assignment vulnerability discovered in Ruby on Rails in 2012, and how was it exploited?",
      "answer": "The mass assignment vulnerability discovered in Ruby on Rails in 2012 allowed for the bypassing of mapping restrictions and the injection of unauthorized SSH public keys into user accounts at GitHub. This vulnerability was exploited through specially crafted JSON structures that created internal objects, resulting in unauthorized access and data modification."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the block size, total key size, and the number and type of operations used in CIKS-1?",
    "context": "",
    "output": "CIKS-1 has a block size of 64 bits, total key size of 256 bits, and utilizes four types of operations: data-dependent permutations, fixed permutations, XORs, and addition mod 4. It uses an 8-round structure in which half of the block determines the transformation of the other half in each round, with the key undergoing a transformation dependent on the data in each round.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the block size, total key size, and the number and type of operations used in CIKS-1?",
      "answer": "CIKS-1 has a block size of 64 bits, total key size of 256 bits, and utilizes four types of operations: data-dependent permutations, fixed permutations, XORs, and addition mod 4. It uses an 8-round structure in which half of the block determines the transformation of the other half in each round, with the key undergoing a transformation dependent on the data in each round."
    }
  },
  {
    "instruction": "Context: High-dimensional quantum key distribution\n\n==Introduction==\nHigh-dimensional quantum key distribution (HDQKD) is a technology for secure communication between two parties. It allows for higher information efficiency than traditional binary quantum key distribution (QKD) protocols, which are limited to 1 bit/photon. HDQKD also exhibits higher resilience to noise, enabling lower signal-to-noise ratios and longer transmission distances.\n\n== Implementation ==\nOne way to implement HDQKD is by using space division multiplexing technology and encoding quantum information in the spatial dimension, such as with optical angular momentum (OAM) modes. While OAM modes have been demonstrated for HDQKD over free-space links, transmission over long-distance fiber links is challenging due to intermodal crosstalk. An alternative approach is to use multicore fibers (MCFs) with separate cores, which offer a large multiplicity of cores and low crosstalk between cores.However, there are also challenges to implementing HDQKD with MCFs. Manipulating high-dimensional quantum states in MCFs requires precise phase stability, which can be difficult to achieve. In addition, transmitting quantum states through fibers can introduce noise and loss, leading to lower fidelity and higher quantum bit error rates (QBER).\n\nQuestion: What is one way to implement HDQKD?\n\nAnswer:",
    "context": "",
    "output": "One way to implement HDQKD is by using space division multiplexing technology and encoding quantum information in the spatial dimension, such as with optical angular momentum (OAM) modes.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is one way to implement HDQKD?",
      "answer": "One way to implement HDQKD is by using space division multiplexing technology and encoding quantum information in the spatial dimension, such as with optical angular momentum (OAM) modes.",
      "context": "High-dimensional quantum key distribution\n\n==Introduction==\nHigh-dimensional quantum key distribution (HDQKD) is a technology for secure communication between two parties. It allows for higher information efficiency than traditional binary quantum key distribution (QKD) protocols, which are limited to 1 bit/photon. HDQKD also exhibits higher resilience to noise, enabling lower signal-to-noise ratios and longer transmission distances.\n\n== Implementation ==\nOne way to implement HDQKD is by using space division multiplexing technology and encoding quantum information in the spatial dimension, such as with optical angular momentum (OAM) modes. While OAM modes have been demonstrated for HDQKD over free-space links, transmission over long-distance fiber links is challenging due to intermodal crosstalk. An alternative approach is to use multicore fibers (MCFs) with separate cores, which offer a large multiplicity of cores and low crosstalk between cores.However, there are also challenges to implementing HDQKD with MCFs. Manipulating high-dimensional quantum states in MCFs requires precise phase stability, which can be difficult to achieve. In addition, transmitting quantum states through fibers can introduce noise and loss, leading to lower fidelity and higher quantum bit error rates (QBER)."
    }
  },
  {
    "instruction": "Answer based on context:\n\nCyber self-defense\n\n==Introduction==\nIn cybersecurity, cyber self-defense refers to self-defense against cyberattack. While it generally emphasizes active cybersecurity measures by computer users themselves, cyber self-defense is sometimes used to refer to the self-defense of organizations as a whole, such as corporate entities or entire nations. Surveillance self-defense is a variant of cyber self-defense and largely overlaps with it. Active and passive cybersecurity measures provide defenders with higher levels of cybersecurity, intrusion detection, incident handling and remediation capabilities.  Various sectors and organizations are legally obligated to adhere to cyber security standards.\n\n\n\n== Background ==\nOrganizations may conduct a penetration test via internal team or hire a third-party organization to audit the organization's systems. Larger organizations may conduct internal attacker-defender scenarios with a \"red team\" attacking and a \"blue team\" defending.  The defenders, namely threat hunters, system administrators, and programmers, proactively manage information systems, remediate vulnerabilities, gather cyber threat intelligence, and harden their operating systems, code, connected devices, and networks.  Blue teams may include all information and physical security personnel employed by the organization. Physical security may be tested for weaknesses, and all employees may be the target of social engineering attacks and IT security audits.  Digital and physical systems may be audited with varying degrees of knowledge of relevant systems to simulate realistic conditions for attackers and for employees, who are frequently trained in security practices and measures.  In full-knowledge test scenarios, known as white box tests, the attacking party knows all available information regarding the client's systems.  In black box tests, the attacking party is provided with no information regarding the client's systems.  Gray box tests provide limited information to the attacking party.\nCybersecurity researcher Jeffrey Carr compares cyber self-defense to martial arts as one's computer and network attack surface may be shrunk to reduce the risk of exploitation.\n\n== Measures ==\n\n\n*** Authentication ***\nEnable multi-factor authentication.\nMinimize authentication risk by limiting the number of people who know one's three common authentication factors, such as \"something you are, something you know, or something you have.\" Unique information is characterized as possessing a particular degree of usefulness to a threat actor in gaining unauthorized access to a person's information.\nReduce one's social media footprint to mitigate risk profile.\nRegularly check one's social media security and privacy settings.\nCreate strong and unique passwords for each user account and change passwords frequently and after any security incident.\nUse a password manager to avoid storing passwords in physical form.  This incurs a greater software risk profile due to potential vulnerabilities in the password management software, but mitigates the risk of breaches if one's password list were stolen or lost and in the case keyloggers were present on machine.\nPay attention to what information one might accidentally reveal in online posts.\nChange default passwords to programs and services to prevent default credential vulnerability exploitation techniques.\nAppropriately use password brute force attack prevention software such as Fail2ban or an effective equivalent.\nNever give out logins or passwords to anyone unless absolutely necessary and if so, change them immediately thereafter.\nUse security questions and answers that are impossible for anybody else to answer even if they have access to one's social media posts or engage in social engineering.\n\n\n*** Anti-social engineering measures ***\nDo not plug in found external storage devices, such as  external hard drives, USB flash drives, and other digital media.\nBeware of social engineering techniques and the six key principles, reciprocity, commitment and consistency, social proof, authority, liking, and scarcity.\nBeware of shoulder surfing, wherein threat actors collect passwords and authentication information by physically observing the target user.\nBeware of piggybacking (tailgating) wherein a threat actor closely follows an authorized personnel into a secure facility.\nBeware of wardriving, wherein threat actors use mobile hacking stations to gain unauthorized access to WiFi.  Wardriving might also consist of the use of parabolic microphones to gather acoustic data, such as passwords and personally identifiable data.\nBe cautious when browsing and opening email attachments or links in emails, known as phishing.\nRefrain from interacting with fake phone calls voice fishing, also known as \"vishing\".\nScan links to malicious websites with Google Transparency Report to check for known malware.\n\n\n*** Preventative software measures ***\nUse, but do not rely solely on antivirus software, as evading it is trivial for threat actors. This is due to its reliance on an easily altered digital signature, a form of applied hash, of the previously known malicious code.\nUse an antimalware product, such as Malwarebytes Anti-Malware, in conjunction with an antivirus with vulnerability scanning features.\nUpdate and upgrade all of one's software and programs \u2014 including, but not limited to a user's operating system, firmware, software drivers, and device drivers. Use dedicated updating-software and enable automated update features.\nEncrypt one's computer and phone.\nRegularly create backups of one's data.\nUninstall insecure software such as Adobe Flash on one's operating system.  Refrain from accessing web pages and related plugins within one's web browser.\nOnly run software when necessary to reduce attack surface.\nRefrain from rooting one's phone or internet-facing device.\n\n\n*** Network and information security measures ***\nUsing a firewall on Internet-connected devices.\nNot running programs, services, or browsers with a super-user or privileged user account, such as root in Linux and Unix ) or as Administrator (Windows), unless one understands the security risks of such an action.\nAvoiding free WiFi and not logging into any accounts while using it.\nAppropriately using privacy and anonymity software such as Tor (anonymity network) for anonymous web browsing, given that this attracts some attention.\nAppropriately using HTTP and various Internet Protocol proxies and security measures, such as disabling HTTP header fields, filtering, and relaying traffic with proxy servers such as Squid Proxy, proxychains, socks4, and socks5.\nPublishing public keys for PGP authentication for being able to prove one's identity.\nUsing the strongest encryption method one's router offers and updating router firmware.\nUsing an intrusion detection system(IDS) or a SIEM (Security Information and Event Management System) to alert as to indicators of compromise, such as configuration changes in the operating system, privilege escalation, network security breaches, and unauthorized remote logins.\nUsing a demilitarized zone to reduce the number of systems and services openly facing the internet.\nUsing a virtual private network with IPsec to secure traffic at the transport layer of the OSI model to harden the IP stack.\n\n\n*** Reporting breaches and incidents ***\nGather evidence and document security and data breaches (intrusions).\nContact relevant authorities, administrators or organizations in the case of a cyberattack.\nBeware of website data breaches wherein stored passwords and personally identifiable information are publicized.\nRefer to a state's statute on security breach notification laws.\n\n== \"Hacking back\" ==\nLegal theorists and policy makers are increasingly considering authorizing the private sector to take active measures by \"hacking back\" (also known as hackbacks).  In contrast to active attack measures, passive defense measures present a reduced risk of cyberwarfare, legal, political, and economic fallout.\nA contemporary topic in debate and research is the question of 'when does a cyber-attack, or the threat thereof, give rise to a right of self-defense?'In March 2017, Tom Graves proposed the Active Cyber Defense Certainty Act (ACDC) that would enhance the Computer Fraud and Abuse Act (CFAA) to allow individuals and the private sector to use certain tools currently restricted under the CFAA to identify attackers and prevent attacks by hacking them. This presents a \"chicken or the egg\" problem, wherein if everyone were allowed to hack anyone, then everyone would hack everyone and only the most skilled and resourced would remain.\nBrad Maryman warns of unintended consequences, stating that in his view \"the notion that we should legislate and accept a level of undocumented and unmonitored cyber actions by anyone who thinks they have been hacked is unfathomable\".\n\nWhat are the risks associated with using default passwords for programs and services?",
    "context": "",
    "output": "The risks associated with using default passwords for programs and services include the possibility of exploitation by threat actors using default credential vulnerability techniques.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are the risks associated with using default passwords for programs and services?",
      "answer": "The risks associated with using default passwords for programs and services include the possibility of exploitation by threat actors using default credential vulnerability techniques.",
      "context": "Cyber self-defense\n\n==Introduction==\nIn cybersecurity, cyber self-defense refers to self-defense against cyberattack. While it generally emphasizes active cybersecurity measures by computer users themselves, cyber self-defense is sometimes used to refer to the self-defense of organizations as a whole, such as corporate entities or entire nations. Surveillance self-defense is a variant of cyber self-defense and largely overlaps with it. Active and passive cybersecurity measures provide defenders with higher levels of cybersecurity, intrusion detection, incident handling and remediation capabilities.  Various sectors and organizations are legally obligated to adhere to cyber security standards.\n\n\n\n== Background ==\nOrganizations may conduct a penetration test via internal team or hire a third-party organization to audit the organization's systems. Larger organizations may conduct internal attacker-defender scenarios with a \"red team\" attacking and a \"blue team\" defending.  The defenders, namely threat hunters, system administrators, and programmers, proactively manage information systems, remediate vulnerabilities, gather cyber threat intelligence, and harden their operating systems, code, connected devices, and networks.  Blue teams may include all information and physical security personnel employed by the organization. Physical security may be tested for weaknesses, and all employees may be the target of social engineering attacks and IT security audits.  Digital and physical systems may be audited with varying degrees of knowledge of relevant systems to simulate realistic conditions for attackers and for employees, who are frequently trained in security practices and measures.  In full-knowledge test scenarios, known as white box tests, the attacking party knows all available information regarding the client's systems.  In black box tests, the attacking party is provided with no information regarding the client's systems.  Gray box tests provide limited information to the attacking party.\nCybersecurity researcher Jeffrey Carr compares cyber self-defense to martial arts as one's computer and network attack surface may be shrunk to reduce the risk of exploitation.\n\n== Measures ==\n\n\n*** Authentication ***\nEnable multi-factor authentication.\nMinimize authentication risk by limiting the number of people who know one's three common authentication factors, such as \"something you are, something you know, or something you have.\" Unique information is characterized as possessing a particular degree of usefulness to a threat actor in gaining unauthorized access to a person's information.\nReduce one's social media footprint to mitigate risk profile.\nRegularly check one's social media security and privacy settings.\nCreate strong and unique passwords for each user account and change passwords frequently and after any security incident.\nUse a password manager to avoid storing passwords in physical form.  This incurs a greater software risk profile due to potential vulnerabilities in the password management software, but mitigates the risk of breaches if one's password list were stolen or lost and in the case keyloggers were present on machine.\nPay attention to what information one might accidentally reveal in online posts.\nChange default passwords to programs and services to prevent default credential vulnerability exploitation techniques.\nAppropriately use password brute force attack prevention software such as Fail2ban or an effective equivalent.\nNever give out logins or passwords to anyone unless absolutely necessary and if so, change them immediately thereafter.\nUse security questions and answers that are impossible for anybody else to answer even if they have access to one's social media posts or engage in social engineering.\n\n\n*** Anti-social engineering measures ***\nDo not plug in found external storage devices, such as  external hard drives, USB flash drives, and other digital media.\nBeware of social engineering techniques and the six key principles, reciprocity, commitment and consistency, social proof, authority, liking, and scarcity.\nBeware of shoulder surfing, wherein threat actors collect passwords and authentication information by physically observing the target user.\nBeware of piggybacking (tailgating) wherein a threat actor closely follows an authorized personnel into a secure facility.\nBeware of wardriving, wherein threat actors use mobile hacking stations to gain unauthorized access to WiFi.  Wardriving might also consist of the use of parabolic microphones to gather acoustic data, such as passwords and personally identifiable data.\nBe cautious when browsing and opening email attachments or links in emails, known as phishing.\nRefrain from interacting with fake phone calls voice fishing, also known as \"vishing\".\nScan links to malicious websites with Google Transparency Report to check for known malware.\n\n\n*** Preventative software measures ***\nUse, but do not rely solely on antivirus software, as evading it is trivial for threat actors. This is due to its reliance on an easily altered digital signature, a form of applied hash, of the previously known malicious code.\nUse an antimalware product, such as Malwarebytes Anti-Malware, in conjunction with an antivirus with vulnerability scanning features.\nUpdate and upgrade all of one's software and programs \u2014 including, but not limited to a user's operating system, firmware, software drivers, and device drivers. Use dedicated updating-software and enable automated update features.\nEncrypt one's computer and phone.\nRegularly create backups of one's data.\nUninstall insecure software such as Adobe Flash on one's operating system.  Refrain from accessing web pages and related plugins within one's web browser.\nOnly run software when necessary to reduce attack surface.\nRefrain from rooting one's phone or internet-facing device.\n\n\n*** Network and information security measures ***\nUsing a firewall on Internet-connected devices.\nNot running programs, services, or browsers with a super-user or privileged user account, such as root in Linux and Unix ) or as Administrator (Windows), unless one understands the security risks of such an action.\nAvoiding free WiFi and not logging into any accounts while using it.\nAppropriately using privacy and anonymity software such as Tor (anonymity network) for anonymous web browsing, given that this attracts some attention.\nAppropriately using HTTP and various Internet Protocol proxies and security measures, such as disabling HTTP header fields, filtering, and relaying traffic with proxy servers such as Squid Proxy, proxychains, socks4, and socks5.\nPublishing public keys for PGP authentication for being able to prove one's identity.\nUsing the strongest encryption method one's router offers and updating router firmware.\nUsing an intrusion detection system(IDS) or a SIEM (Security Information and Event Management System) to alert as to indicators of compromise, such as configuration changes in the operating system, privilege escalation, network security breaches, and unauthorized remote logins.\nUsing a demilitarized zone to reduce the number of systems and services openly facing the internet.\nUsing a virtual private network with IPsec to secure traffic at the transport layer of the OSI model to harden the IP stack.\n\n\n*** Reporting breaches and incidents ***\nGather evidence and document security and data breaches (intrusions).\nContact relevant authorities, administrators or organizations in the case of a cyberattack.\nBeware of website data breaches wherein stored passwords and personally identifiable information are publicized.\nRefer to a state's statute on security breach notification laws.\n\n== \"Hacking back\" ==\nLegal theorists and policy makers are increasingly considering authorizing the private sector to take active measures by \"hacking back\" (also known as hackbacks).  In contrast to active attack measures, passive defense measures present a reduced risk of cyberwarfare, legal, political, and economic fallout.\nA contemporary topic in debate and research is the question of 'when does a cyber-attack, or the threat thereof, give rise to a right of self-defense?'In March 2017, Tom Graves proposed the Active Cyber Defense Certainty Act (ACDC) that would enhance the Computer Fraud and Abuse Act (CFAA) to allow individuals and the private sector to use certain tools currently restricted under the CFAA to identify attackers and prevent attacks by hacking them. This presents a \"chicken or the egg\" problem, wherein if everyone were allowed to hack anyone, then everyone would hack everyone and only the most skilled and resourced would remain.\nBrad Maryman warns of unintended consequences, stating that in his view \"the notion that we should legislate and accept a level of undocumented and unmonitored cyber actions by anyone who thinks they have been hacked is unfathomable\"."
    }
  },
  {
    "instruction": "NIST Cybersecurity Framework\n\n==Introduction==\nNIST Cybersecurity Framework is a set of guidelines for mitigating organizational cybersecurity risks, published by the US National Institute of Standards and Technology (NIST) based on existing standards, guidelines, and practices. The framework \"provides a high level taxonomy of cybersecurity outcomes and a methodology to assess and manage those outcomes\", in addition to guidance on the protection of privacy and civil liberties in a cybersecurity context. It has been translated to many languages, and is used by several governments and a wide range of businesses and organizations.A 2016 study found that 70% of organizations surveyed see the NIST Cybersecurity Framework as a popular best practice for computer security, but many note that it requires significant investment.\n\n\n\n== Overview ==\nThe NIST Cybersecurity Framework is designed for individual businesses and other organizations to assess risks they face.\nVersion 1.0 was published by the US National Institute of Standards and Technology in 2014, originally aimed at operators of critical infrastructure.  In 2017, a draft version of the framework, version 1.1, was circulated for public comment. Version 1.1 was announced and made publicly available on April 16, 2018. Version 1.1 is still compatible with version 1.0. \nThe changes include guidance on how to perform self-assessments, additional detail on supply chain risk management, guidance on how to interact with supply chain stakeholders, and encourages a vulnerability disclosure process.\nThe framework is divided into three parts, \"Core\", \"Profile\" and \"Tiers\". The \"Framework Core\" contains an array of activities, outcomes and references about aspects and approaches to cybersecurity. The \"Framework Implementation Tiers\" are used by an organization to clarify for itself and its partners how it views cybersecurity risk and the degree of sophistication of its management approach. A \"Framework Profile\" is a list of outcomes that an organization has chosen from the categories and subcategories, based on its needs and risk assessments.\nAn organization typically starts by using the framework to develop a \"Current Profile\" which describes its cybersecurity activities and what outcomes it is achieving. It can then develop a \"Target Profile\", or adopt a baseline profile tailored to its sector (e.g. infrastructure industry) or type of organization. It can then define steps for switching from its current profile to its target profile.\n\n== Functions and categories of cybersecurity activities ==\n\nThe NIST Cybersecurity Framework organizes its \"core\" material into five \"functions\" which are subdivided into a total of 23 \"categories\". For each category, it defines a number of subcategories of cybersecurity outcomes and security controls, with 108 subcategories in all.\nFor each subcategory, it also provides \"Informative Resources\" referencing specific sections of a variety of other information security standards, including ISO 27001, COBIT, NIST SP 800-53, ANSI/ISA-62443, and the Council on CyberSecurity Critical Security Controls (CCS CSC, now managed by the Center for Internet Security).  Special Publications (SP) aside, most of the informative references requires a paid membership or purchase to access their respective guides.  The cost and complexity of the framework has resulted in bills from both houses of Congress that direct NIST to create Cybersecurity Framework guides that are more accessible to small and medium businesses.Here are the functions and categories, along with their unique identifiers and definitions, as stated in the framework document.\n\n\n*** Identify ***\n\"Develop the organizational understanding to manage cybersecurity risk to systems, assets, data, and capabilities.\"\n\nAsset Management (ID.AM): The data, personnel, devices, systems, and facilities that enable the organization to achieve business purposes are identified and managed consistent with their relative importance to business objectives and the organization's risk strategy.\nBusiness Environment (ID.BE): The organization's mission, objectives, stakeholders, and activities are understood and prioritized; this information is used to inform cybersecurity roles, responsibilities, and risk management decisions.\nGovernance (ID.GV):- The policies, procedures, and processes to manage and monitor the organization's regulatory, legal, risk, environmental, and operational requirements are understood and inform the management of cybersecurity risk.\nRisk Assessment (ID.RA): The organization understands the cybersecurity risk to organizational operations (including mission, functions, image, or reputation), organizational assets, and individuals.\nRisk Management Strategy (ID.RM): The organization's priorities, constraints, risk tolerances, and assumptions are established and used to support operational risk decisions.\nSupply Chain Risk Management (ID.SC): The organization's priorities, constraints, risk tolerances, and assumptions are established and used to support risk decisions associated with managing supply chain risk. The organization has in place the processes to identify, assess and manage supply chain risks.\n\n\n*** Protect ***\n\"Develop and implement the appropriate safeguards to ensure delivery of critical infrastructure services.\"\n\nAccess Control (PR.AC): Access to assets and associated facilities is limited to authorized users, processes, or devices, and to authorized activities and transactions.\nAwareness and Training (PR.AT): The organization's personnel and partners are provided cybersecurity awareness education and are adequately trained to perform their information security-related duties and responsibilities consistent with related policies, procedures, and agreements.\nData Security (PR.DS): Information and records (data) are managed consistent with the organization's risk strategy to protect the confidentiality, integrity, and availability of information.\nInformation Protection Processes and Procedures (PR.IP): Security policies (that address purpose, scope, roles, responsibilities, management commitment, and coordination among organizational entities), processes, and procedures are maintained and used to manage protection of information systems and assets.\nMaintenance (PR.MA): Maintenance and repairs of industrial control and information system components is performed consistent with policies and procedures.\nProtective Technology (PR.PT): Technical security solutions are managed to ensure the security and resilience of systems and assets, consistent with related policies, procedures, and agreements.\n\n\n*** Detect ***\n\"Develop and implement the appropriate activities to identify the occurrence of a cybersecurity event.\"\n\nAnomalies and Events (DE.AE): Anomalous activity is detected in a timely manner and the potential impact of events is understood.\nSecurity Continuous Monitoring (DE.CM): The information system and assets are monitored at discrete intervals to identify cybersecurity events and verify the effectiveness of protective measures.\nDetection Processes (DE.DP): Detection processes and procedures are maintained and tested to ensure timely and adequate awareness of anomalous events.\n\n\n*** Respond ***\n\"Develop and implement the appropriate activities to take action regarding a detected cybersecurity incident.\"\n\nResponse Planning (RS.RP): Response processes and procedures are executed and maintained, to ensure timely response to detected cybersecurity events.\nCommunications (RS.CO): Response activities are coordinated with internal and external stakeholders, as appropriate, to include external support from law enforcement agencies.\nAnalysis (RS.AN): Analysis is conducted to ensure adequate response and support recovery activities.\nMitigation (RS.MI): Activities are performed to prevent expansion of an event, mitigate its effects, and eradicate the incident.\nImprovements (RS.IM): Organizational response activities are improved by incorporating lessons learned from current and previous detection/response activities.\n\n\n*** Recover ***\n\"Develop and implement the appropriate activities to maintain plans for resilience and to restore any capabilities or services that were impaired due to a cybersecurity incident.\"\n\nRecovery Planning (RC.RP): Recovery processes and procedures are executed and maintained to ensure timely restoration of systems or assets affected by cybersecurity events.\nImprovements (RC.IM): Recovery planning and processes are improved by incorporating lessons learned into future activities.\nCommunications (RC.CO): Restoration activities are coordinated with internal and external parties, such as coordinating centers, Internet Service Providers, owners of attacking systems, victims, other CSIRTs, and vendors.\n\n== Online Informative References ==\nIn addition to informative references in the framework's core, NIST also maintains an online database of informative references.  Informative References show relationships between Framework Functions, Categories, and Subcategories and specific sections of standards, guidelines, and best practices common among Framework stakeholders. Informative References illustrate ways to achieve Framework outcomes. \n\nInformative References Home\nDerived Relationship Mapping\nInformative Reference Catalog\n\n== Updates ==\nIn 2021 NIST released Security Measures for \u201cEO-Critical Software\u201d Use Under Executive Order (EO) 14028 to outline security measures intended to better protect the use of deployed EO-critical software in agencies\u2019 operational environments.\n\nQ: What is the purpose of the \"Security Continuous Monitoring\" category in the NIST Cybersecurity Framework?",
    "context": "",
    "output": "A: The \"Security Continuous Monitoring\" category in the NIST Cybersecurity Framework involves monitoring systems and assets at discrete intervals to identify cybersecurity events and verify the effectiveness of protective measures.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the purpose of the \"Security Continuous Monitoring\" category in the NIST Cybersecurity Framework?",
      "answer": "The \"Security Continuous Monitoring\" category in the NIST Cybersecurity Framework involves monitoring systems and assets at discrete intervals to identify cybersecurity events and verify the effectiveness of protective measures.",
      "context": "NIST Cybersecurity Framework\n\n==Introduction==\nNIST Cybersecurity Framework is a set of guidelines for mitigating organizational cybersecurity risks, published by the US National Institute of Standards and Technology (NIST) based on existing standards, guidelines, and practices. The framework \"provides a high level taxonomy of cybersecurity outcomes and a methodology to assess and manage those outcomes\", in addition to guidance on the protection of privacy and civil liberties in a cybersecurity context. It has been translated to many languages, and is used by several governments and a wide range of businesses and organizations.A 2016 study found that 70% of organizations surveyed see the NIST Cybersecurity Framework as a popular best practice for computer security, but many note that it requires significant investment.\n\n\n\n== Overview ==\nThe NIST Cybersecurity Framework is designed for individual businesses and other organizations to assess risks they face.\nVersion 1.0 was published by the US National Institute of Standards and Technology in 2014, originally aimed at operators of critical infrastructure.  In 2017, a draft version of the framework, version 1.1, was circulated for public comment. Version 1.1 was announced and made publicly available on April 16, 2018. Version 1.1 is still compatible with version 1.0. \nThe changes include guidance on how to perform self-assessments, additional detail on supply chain risk management, guidance on how to interact with supply chain stakeholders, and encourages a vulnerability disclosure process.\nThe framework is divided into three parts, \"Core\", \"Profile\" and \"Tiers\". The \"Framework Core\" contains an array of activities, outcomes and references about aspects and approaches to cybersecurity. The \"Framework Implementation Tiers\" are used by an organization to clarify for itself and its partners how it views cybersecurity risk and the degree of sophistication of its management approach. A \"Framework Profile\" is a list of outcomes that an organization has chosen from the categories and subcategories, based on its needs and risk assessments.\nAn organization typically starts by using the framework to develop a \"Current Profile\" which describes its cybersecurity activities and what outcomes it is achieving. It can then develop a \"Target Profile\", or adopt a baseline profile tailored to its sector (e.g. infrastructure industry) or type of organization. It can then define steps for switching from its current profile to its target profile.\n\n== Functions and categories of cybersecurity activities ==\n\nThe NIST Cybersecurity Framework organizes its \"core\" material into five \"functions\" which are subdivided into a total of 23 \"categories\". For each category, it defines a number of subcategories of cybersecurity outcomes and security controls, with 108 subcategories in all.\nFor each subcategory, it also provides \"Informative Resources\" referencing specific sections of a variety of other information security standards, including ISO 27001, COBIT, NIST SP 800-53, ANSI/ISA-62443, and the Council on CyberSecurity Critical Security Controls (CCS CSC, now managed by the Center for Internet Security).  Special Publications (SP) aside, most of the informative references requires a paid membership or purchase to access their respective guides.  The cost and complexity of the framework has resulted in bills from both houses of Congress that direct NIST to create Cybersecurity Framework guides that are more accessible to small and medium businesses.Here are the functions and categories, along with their unique identifiers and definitions, as stated in the framework document.\n\n\n*** Identify ***\n\"Develop the organizational understanding to manage cybersecurity risk to systems, assets, data, and capabilities.\"\n\nAsset Management (ID.AM): The data, personnel, devices, systems, and facilities that enable the organization to achieve business purposes are identified and managed consistent with their relative importance to business objectives and the organization's risk strategy.\nBusiness Environment (ID.BE): The organization's mission, objectives, stakeholders, and activities are understood and prioritized; this information is used to inform cybersecurity roles, responsibilities, and risk management decisions.\nGovernance (ID.GV):- The policies, procedures, and processes to manage and monitor the organization's regulatory, legal, risk, environmental, and operational requirements are understood and inform the management of cybersecurity risk.\nRisk Assessment (ID.RA): The organization understands the cybersecurity risk to organizational operations (including mission, functions, image, or reputation), organizational assets, and individuals.\nRisk Management Strategy (ID.RM): The organization's priorities, constraints, risk tolerances, and assumptions are established and used to support operational risk decisions.\nSupply Chain Risk Management (ID.SC): The organization's priorities, constraints, risk tolerances, and assumptions are established and used to support risk decisions associated with managing supply chain risk. The organization has in place the processes to identify, assess and manage supply chain risks.\n\n\n*** Protect ***\n\"Develop and implement the appropriate safeguards to ensure delivery of critical infrastructure services.\"\n\nAccess Control (PR.AC): Access to assets and associated facilities is limited to authorized users, processes, or devices, and to authorized activities and transactions.\nAwareness and Training (PR.AT): The organization's personnel and partners are provided cybersecurity awareness education and are adequately trained to perform their information security-related duties and responsibilities consistent with related policies, procedures, and agreements.\nData Security (PR.DS): Information and records (data) are managed consistent with the organization's risk strategy to protect the confidentiality, integrity, and availability of information.\nInformation Protection Processes and Procedures (PR.IP): Security policies (that address purpose, scope, roles, responsibilities, management commitment, and coordination among organizational entities), processes, and procedures are maintained and used to manage protection of information systems and assets.\nMaintenance (PR.MA): Maintenance and repairs of industrial control and information system components is performed consistent with policies and procedures.\nProtective Technology (PR.PT): Technical security solutions are managed to ensure the security and resilience of systems and assets, consistent with related policies, procedures, and agreements.\n\n\n*** Detect ***\n\"Develop and implement the appropriate activities to identify the occurrence of a cybersecurity event.\"\n\nAnomalies and Events (DE.AE): Anomalous activity is detected in a timely manner and the potential impact of events is understood.\nSecurity Continuous Monitoring (DE.CM): The information system and assets are monitored at discrete intervals to identify cybersecurity events and verify the effectiveness of protective measures.\nDetection Processes (DE.DP): Detection processes and procedures are maintained and tested to ensure timely and adequate awareness of anomalous events.\n\n\n*** Respond ***\n\"Develop and implement the appropriate activities to take action regarding a detected cybersecurity incident.\"\n\nResponse Planning (RS.RP): Response processes and procedures are executed and maintained, to ensure timely response to detected cybersecurity events.\nCommunications (RS.CO): Response activities are coordinated with internal and external stakeholders, as appropriate, to include external support from law enforcement agencies.\nAnalysis (RS.AN): Analysis is conducted to ensure adequate response and support recovery activities.\nMitigation (RS.MI): Activities are performed to prevent expansion of an event, mitigate its effects, and eradicate the incident.\nImprovements (RS.IM): Organizational response activities are improved by incorporating lessons learned from current and previous detection/response activities.\n\n\n*** Recover ***\n\"Develop and implement the appropriate activities to maintain plans for resilience and to restore any capabilities or services that were impaired due to a cybersecurity incident.\"\n\nRecovery Planning (RC.RP): Recovery processes and procedures are executed and maintained to ensure timely restoration of systems or assets affected by cybersecurity events.\nImprovements (RC.IM): Recovery planning and processes are improved by incorporating lessons learned into future activities.\nCommunications (RC.CO): Restoration activities are coordinated with internal and external parties, such as coordinating centers, Internet Service Providers, owners of attacking systems, victims, other CSIRTs, and vendors.\n\n== Online Informative References ==\nIn addition to informative references in the framework's core, NIST also maintains an online database of informative references.  Informative References show relationships between Framework Functions, Categories, and Subcategories and specific sections of standards, guidelines, and best practices common among Framework stakeholders. Informative References illustrate ways to achieve Framework outcomes. \n\nInformative References Home\nDerived Relationship Mapping\nInformative Reference Catalog\n\n== Updates ==\nIn 2021 NIST released Security Measures for \u201cEO-Critical Software\u201d Use Under Executive Order (EO) 14028 to outline security measures intended to better protect the use of deployed EO-critical software in agencies\u2019 operational environments."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the first known virus for the Pocket PC platform?",
    "context": "",
    "output": "Duts is the first known virus for the Pocket PC platform. It attempts to infect all EXE files that are larger than 4096 bytes in the current directory.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the first known virus for the Pocket PC platform?",
      "answer": "Duts is the first known virus for the Pocket PC platform. It attempts to infect all EXE files that are larger than 4096 bytes in the current directory."
    }
  },
  {
    "instruction": "Write an answer to the following question: How long did it take for an attacker to break LILI-128 using a notebook running MATLAB in 2007?",
    "context": "",
    "output": "An attacker was able to break LILI-128 using a notebook running MATLAB in 1.61 hours in 2007.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How long did it take for an attacker to break LILI-128 using a notebook running MATLAB in 2007?",
      "answer": "An attacker was able to break LILI-128 using a notebook running MATLAB in 1.61 hours in 2007."
    }
  },
  {
    "instruction": "Write an answer to the following question: How did the unidentified security researcher from the Netherlands under the pseudonym \"WhatsappHack\" exploit the authentication process flaw to hijack WhatsApp accounts in 2011?",
    "context": "",
    "output": "The unidentified security researcher from the Netherlands under the pseudonym \"WhatsappHack\" exploited the authentication process flaw by trying to log in to a person's account from another phone number and intercepting the verification text message that would be sent out. The researcher provided methods to accomplish this on both Symbian and Android operating systems.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How did the unidentified security researcher from the Netherlands under the pseudonym \"WhatsappHack\" exploit the authentication process flaw to hijack WhatsApp accounts in 2011?",
      "answer": "The unidentified security researcher from the Netherlands under the pseudonym \"WhatsappHack\" exploited the authentication process flaw by trying to log in to a person's account from another phone number and intercepting the verification text message that would be sent out. The researcher provided methods to accomplish this on both Symbian and Android operating systems."
    }
  },
  {
    "instruction": "Block cipher\n\n==Introduction==\nIn cryptography, a block cipher is a deterministic algorithm operating on fixed-length groups of bits, called blocks. Block ciphers are specified elementary components in the design of many cryptographic protocols and are widely used to encrypt large amounts of data, including in data exchange protocols. A block cipher uses blocks as an unvarying transformation.\nEven a secure block cipher is suitable for the encryption of only a single block of data at a time, using a fixed key. A multitude of modes of operation has been designed to allow their repeated use in a secure way to achieve the security goals of confidentiality and authenticity. However, block ciphers may also feature as building blocks in other cryptographic protocols, such as universal hash functions and pseudorandom number generators.\n\n== Definition ==\nA block cipher consists of two paired algorithms, one for encryption, E, and the other for decryption, D. Both algorithms accept two inputs: an input block of size n bits and a key of size k bits; and both yield an n-bit output block. The decryption algorithm D is defined to be the inverse function of encryption, i.e., D\n\n== Design ==\n\n\n*** Iterated block ciphers ***\nMost block cipher algorithms are classified as iterated block ciphers which means that they transform fixed-size blocks of plaintext into identically sized blocks of ciphertext, via the repeated application of an invertible transformation known as the round function, with each iteration referred to as a round.Usually, the round function R takes different round keys Ki as a second input, which is derived from the original key:\n\n  \n    \n      \n        \n          M\n          \n            i\n\n== Modes of operation ==\n\nA block cipher by itself allows encryption only of a single data block of the cipher's block length. For a variable-length message, the data must first be partitioned into separate cipher blocks. In the simplest case, known as electronic codebook (ECB) mode, a message is first split into separate blocks of the cipher's block size (possibly extending the last block with padding bits), and then each block is encrypted and decrypted independently. However, such a naive method is generally insecure because equal plaintext blocks will always generate equal ciphertext blocks (for the same key), so patterns in the plaintext message become evident in the ciphertext output.To overcome this limitation, several so-called block cipher modes of operation have been designed and specified in national recommendations such as NIST 800-38A and BSI TR-02102 and international standards such as ISO/IEC 10116. The general concept is to use randomization of the plaintext data based on an additional input value, frequently called an initialization vector, to create what is termed probabilistic encryption. In the popular cipher block chaining (CBC) mode, for encryption to be secure the initialization vector passed along with the plaintext message must be a random or pseudo-random value, which is added in an exclusive-or manner to the first plaintext block before it is encrypted. The resultant ciphertext block is then used as the new initialization vector for the next plaintext block. In the cipher feedback (CFB) mode, which emulates a self-synchronizing stream cipher, the initialization vector is first encrypted and then added to the plaintext block. The output feedback (OFB) mode repeatedly encrypts the initialization vector to create a key stream for the emulation of a synchronous stream cipher. The newer counter (CTR) mode similarly creates a key stream, but has the advantage of only needing unique and not (pseudo-)random values as initialization vectors; the needed randomness is derived internally by using the initialization vector as a block counter and encrypting this counter for each block.From a security-theoretic point of view, modes of operation must provide what is known as semantic security. Informally, it means that given some ciphertext under an unknown key one cannot practically derive any information from the ciphertext (other than the length of the message) over what one would have known without seeing the ciphertext. It has been shown that all of the modes discussed above, with the exception of the ECB mode, provide this property under so-called chosen plaintext attacks.\n\n== Padding ==\n\nSome modes such as the CBC mode only operate on complete plaintext blocks. Simply extending the last block of a message with zero bits is insufficient since it does not allow a receiver to easily distinguish messages that differ only in the number of padding bits. More importantly, such a simple solution gives rise to very efficient padding oracle attacks. A suitable padding scheme is therefore needed to extend the last plaintext block to the cipher's block size. While many popular schemes described in standards and in the literature have been shown to be vulnerable to padding oracle attacks, a solution that adds a one-bit and then extends the last block with zero-bits, standardized as \"padding method 2\" in ISO/IEC 9797-1, has been proven secure against these attacks.\n\n== Cryptanalysis ==\n\n\n*** Brute-force attacks ***\n This property results in the cipher's security degrading quadratically, and needs to be taken into account when selecting a block size. There is a trade-off though as large block sizes can result in the algorithm becoming inefficient to operate. Earlier block ciphers such as the DES have typically selected a 64-bit block size, while newer designs such as the AES support block sizes of 128 bits or more, with some ciphers supporting a range of different block sizes.\n\n\n*** Differential cryptanalysis ***\n\n\n*** Linear cryptanalysis ***\n\nA linear cryptanalysis is a form of cryptanalysis based on finding affine approximations to the action of a cipher. Linear cryptanalysis is one of the two most widely used attacks on block ciphers; the other being differential cryptanalysis.The discovery is attributed to Mitsuru Matsui, who first applied the technique to the FEAL cipher (Matsui and Yamagishi, 1992).\n\n\n*** Integral cryptanalysis ***\n\nIntegral cryptanalysis is a cryptanalytic attack that is particularly applicable to block ciphers based on substitution\u2013permutation networks. Unlike differential cryptanalysis, which uses pairs of chosen plaintexts with a fixed XOR difference, integral cryptanalysis uses sets or even multisets of chosen plaintexts of which part is held constant and another part varies through all possibilities. For example, an attack might use 256 chosen plaintexts that have all but 8 of their bits the same, but all differ in those 8 bits. Such a set necessarily has an XOR sum of 0, and the XOR sums of the corresponding sets of ciphertexts provide information about the cipher's operation. This contrast between the differences between pairs of texts and the sums of larger sets of texts inspired the name \"integral cryptanalysis\", borrowing the terminology of calculus.\n\n\n*** Other techniques ***\n\nIn addition to linear and differential cryptanalysis, there is a growing catalog of attacks: truncated differential cryptanalysis, partial differential cryptanalysis, integral cryptanalysis, which encompasses square and integral attacks, slide attacks, boomerang attacks, the XSL attack, impossible differential cryptanalysis, and algebraic attacks. For a new block cipher design to have any credibility, it must demonstrate evidence of security against known attacks.\n\n== Provable security ==\nWhen a block cipher is used in a given mode of operation, the resulting algorithm should ideally be about as secure as the block cipher itself. ECB (discussed above) emphatically lacks this property: regardless of how secure the underlying block cipher is, ECB mode can easily be attacked. On the other hand, CBC mode can be proven to be secure under the assumption that the underlying block cipher is likewise secure. Note, however, that making statements like this requires formal mathematical definitions for what it means for an encryption algorithm or a block cipher to \"be secure\". This section describes two common notions for what properties a block cipher should have. Each corresponds to a mathematical model that can be used to prove properties of higher-level algorithms, such as CBC.\nThis general approach to cryptography \u2013 proving higher-level algorithms (such as CBC) are secure under explicitly stated assumptions regarding their components (such as a block cipher) \u2013 is known as provable security.\n\n\n*** Standard model ***\n\nInformally, a block cipher is secure in the standard model if an attacker cannot tell the difference between the block cipher (equipped with a random key) and a random permutation.\nTo be a bit more precise, let E be an n-bit block cipher. We imagine the following game:\n\nThe person running the game flips a coin.\nIf the coin lands on heads, he chooses a random key K and defines the function f\n\n== Practical evaluation ==\nBlock ciphers may be evaluated according to multiple criteria in practice. Common factors include:\nKey parameters, such as its key size and block size, both of which provide an upper bound on the security of the cipher.\nThe estimated security level, which is based on the confidence gained in the block cipher design after it has largely withstood major efforts in cryptanalysis over time, the design's mathematical soundness, and the existence of practical or certificational attacks.\nThe cipher's complexity and its suitability for implementation in hardware or software. Hardware implementations may measure the complexity in terms of gate count or energy consumption, which are important parameters for resource-constrained devices.\nThe cipher's performance in terms of processing throughput on various platforms, including its memory requirements.\nThe cost of the cipher refers to licensing requirements that may apply due to intellectual property rights.\nThe flexibility of the cipher includes its ability to support multiple key sizes and block lengths.\n\n== Notable block ciphers ==\n\n\n*** Lucifer / DES ***\n\nLucifer is generally considered to be the first civilian block cipher, developed at IBM in the 1970s based on work done by Horst Feistel. A revised version of the algorithm was adopted as a U.S. government Federal Information Processing Standard: FIPS PUB 46 Data Encryption Standard (DES). It was chosen by the U.S. National Bureau of Standards (NBS) after a public invitation for submissions and some internal changes by NBS (and, potentially, the NSA). DES was publicly released in 1976 and has been widely used.DES was designed to, among other things, resist a certain cryptanalytic attack known to the NSA and rediscovered by IBM, though unknown publicly until rediscovered again and published by Eli Biham and Adi Shamir in the late 1980s. The technique is called differential cryptanalysis and remains one of the few general attacks against block ciphers; linear cryptanalysis is another but may have been unknown even to the NSA, prior to its publication by Mitsuru Matsui. DES prompted a large amount of other work and publications in cryptography and cryptanalysis in the open community and it inspired many new cipher designs.DES has a block size of 64 bits and a key size of 56 bits. 64-bit blocks became common in block cipher designs after DES. Key length depended on several factors, including government regulation. Many observers in the 1970s commented that the 56-bit key length used for DES was too short. As time went on, its inadequacy became apparent, especially after a special-purpose machine designed to break DES was demonstrated in 1998 by the Electronic Frontier Foundation. An extension to DES, Triple DES, triple-encrypts each block with either two independent keys (112-bit key and 80-bit security) or three independent keys (168-bit key and 112-bit security). It was widely adopted as a replacement. As of 2011, the three-key version is still considered secure, though the National Institute of Standards and Technology (NIST) standards no longer permit the use of the two-key version in new applications, due to its 80-bit security level.\n\n\n*** IDEA ***\nThe International Data Encryption Algorithm (IDEA) is a block cipher designed by James Massey of ETH Zurich and Xuejia Lai; it was first described in 1991, as an intended replacement for DES.\nIDEA operates on 64-bit blocks using a 128-bit key and consists of a series of eight identical transformations (a round) and an output transformation (the half-round). The processes for encryption and decryption are similar. IDEA derives much of its security by interleaving operations from different groups \u2013 modular addition and multiplication, and bitwise exclusive or (XOR) \u2013 which are algebraically \"incompatible\" in some sense.\nThe designers analysed IDEA to measure its strength against differential cryptanalysis and concluded that it is immune under certain assumptions. No successful linear or algebraic weaknesses have been reported. As of 2012, the best attack which applies to all keys can break a full 8.5-round IDEA using a narrow-bicliques attack about four times faster than brute force.\n\n\n*** RC5 ***\n\nRC5 is a block cipher designed by Ronald Rivest in 1994 which, unlike many other ciphers, has a variable block size (32, 64, or 128 bits), key size (0 to 2040 bits), and a number of rounds (0 to 255). The original suggested choice of parameters was a block size of 64 bits, a 128-bit key, and 12 rounds.\nA key feature of RC5 is the use of data-dependent rotations; one of the goals of RC5 was to prompt the study and evaluation of such operations as a cryptographic primitive. RC5 also consists of a number of modular additions and XORs. The general structure of the algorithm is a Feistel-like a network. The encryption and decryption routines can be specified in a few lines of code. The key schedule, however, is more complex, expanding the key using an essentially one-way function with the binary expansions of both e and the golden ratio as sources of \"nothing up my sleeve numbers\". The tantalizing simplicity of the algorithm together with the novelty of the data-dependent rotations has made RC5 an attractive object of study for cryptanalysts.\n12-round RC5 (with 64-bit blocks) is susceptible to a differential attack using 244 chosen plaintexts. 18\u201320 rounds are suggested as sufficient protection.\n\n\n*** Rijndael / AES ***\n\nThe Rijndael cipher developed by Belgian cryptographers, Joan Daemen and Vincent Rijmen was one of the competing designs to replace DES. It won the 5-year public competition to become the AES, (Advanced Encryption Standard).\nAdopted by NIST in 2001, AES has a fixed block size of 128 bits and a key size of 128, 192, or 256 bits, whereas Rijndael can be specified with block and key sizes in any multiple of 32 bits, with a minimum of 128 bits. The block size has a maximum of 256 bits, but the key size has no theoretical maximum. AES operates on a 4\u00d74 column-major order matrix of bytes, termed the state (versions of Rijndael with a larger block size have additional columns in the state).\n\n\n*** Blowfish ***\n\nBlowfish is a block cipher, designed in 1993 by Bruce Schneier and included in a large number of cipher suites and encryption products. Blowfish has a 64-bit block size and a variable key length from 1 bit up to 448 bits. It is a 16-round Feistel cipher and uses large key-dependent S-boxes. Notable features of the design include the key-dependent S-boxes and a highly complex key schedule.\nIt was designed as a general-purpose algorithm, intended as an alternative to the aging DES and free of the problems and constraints associated with other algorithms. At the time Blowfish was released, many other designs were proprietary, encumbered by patents, or were commercial/government secrets. Schneier has stated that \"Blowfish is unpatented, and will remain so in all countries. The algorithm is hereby placed in the public domain, and can be freely used by anyone.\" The same applies to Twofish, a successor algorithm from Schneier.\n\n== Generalizations ==\n\n\n*** Tweakable block ciphers ***\nM. Liskov, R. Rivest, and D. Wagner have described a generalized version of block ciphers called \"tweakable\" block ciphers. A tweakable block cipher accepts a second input called the tweak along with its usual plaintext or ciphertext input. The tweak, along with the key, selects the permutation computed by the cipher. If changing tweaks is sufficiently lightweight (compared with a usually fairly expensive key setup operation), then some interesting new operation modes become possible. The disk encryption theory article describes some of these modes.\n\n\n*** Format-preserving encryption ***\n\nBlock ciphers traditionally work over a binary alphabet. That is, both the input and the output are binary strings, consisting of n zeroes and ones. In some situations, however, one may wish to have a block cipher that works over some other alphabet; for example, encrypting 16-digit credit card numbers in such a way that the ciphertext is also a 16-digit number might facilitate adding an encryption layer to legacy software. This is an example of format-preserving encryption. More generally, format-preserving encryption requires a keyed permutation on some finite language. This makes format-preserving encryption schemes a natural generalization of (tweakable) block ciphers. In contrast, traditional encryption schemes, such as CBC, are not permutations because the same plaintext can encrypt multiple different ciphertexts, even when using a fixed key.\n\n== Relation to other cryptographic primitives ==\nBlock ciphers can be used to build other cryptographic primitives, such as those below. For these other primitives to be cryptographically secure, care has to be taken to build them the right way.\n\nStream ciphers can be built using block ciphers. OFB mode and CTR mode are block modes that turn a block cipher into a stream cipher.\nCryptographic hash functions can be built using block ciphers. See the one-way compression function for descriptions of several such methods. The methods resemble the block cipher modes of operation usually used for encryption.\nCryptographically secure pseudorandom number generators (CSPRNGs) can be built using block ciphers.\nSecure pseudorandom permutations of arbitrarily sized finite sets can be constructed with block ciphers; see Format-Preserving Encryption.\nA publicly known unpredictable permutation combined with key whitening is enough to construct a block cipher -- such as the single-key Even-Mansour cipher, perhaps the simplest possible provably secure block cipher.\nMessage authentication codes (MACs) are often built from block ciphers. CBC-MAC, OMAC, and PMAC are such MACs.\nAuthenticated encryption is also built from block ciphers. It means to both encrypt and MAC at the same time. That is to both provide confidentiality and authentication. CCM, EAX, GCM, and OCB are such authenticated encryption modes.Just as block ciphers can be used to build hash functions, like SHA-1 and SHA-2 are based on block ciphers which are also used independently as SHACAL, hash functions can be used to build block ciphers. Examples of such block ciphers are BEAR and LION.\n\nWhat are some common factors considered in the practical evaluation of block ciphers?",
    "context": "",
    "output": "Some common factors considered in the practical evaluation of block ciphers include the key and block size, estimated security level, complexity and suitability for implementation in hardware or software, performance in terms of processing throughput and memory requirements, and cost due",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are some common factors considered in the practical evaluation of block ciphers?",
      "answer": "Some common factors considered in the practical evaluation of block ciphers include the key and block size, estimated security level, complexity and suitability for implementation in hardware or software, performance in terms of processing throughput and memory requirements, and cost due",
      "context": "Block cipher\n\n==Introduction==\nIn cryptography, a block cipher is a deterministic algorithm operating on fixed-length groups of bits, called blocks. Block ciphers are specified elementary components in the design of many cryptographic protocols and are widely used to encrypt large amounts of data, including in data exchange protocols. A block cipher uses blocks as an unvarying transformation.\nEven a secure block cipher is suitable for the encryption of only a single block of data at a time, using a fixed key. A multitude of modes of operation has been designed to allow their repeated use in a secure way to achieve the security goals of confidentiality and authenticity. However, block ciphers may also feature as building blocks in other cryptographic protocols, such as universal hash functions and pseudorandom number generators.\n\n== Definition ==\nA block cipher consists of two paired algorithms, one for encryption, E, and the other for decryption, D. Both algorithms accept two inputs: an input block of size n bits and a key of size k bits; and both yield an n-bit output block. The decryption algorithm D is defined to be the inverse function of encryption, i.e., D\n\n== Design ==\n\n\n*** Iterated block ciphers ***\nMost block cipher algorithms are classified as iterated block ciphers which means that they transform fixed-size blocks of plaintext into identically sized blocks of ciphertext, via the repeated application of an invertible transformation known as the round function, with each iteration referred to as a round.Usually, the round function R takes different round keys Ki as a second input, which is derived from the original key:\n\n  \n    \n      \n        \n          M\n          \n            i\n\n== Modes of operation ==\n\nA block cipher by itself allows encryption only of a single data block of the cipher's block length. For a variable-length message, the data must first be partitioned into separate cipher blocks. In the simplest case, known as electronic codebook (ECB) mode, a message is first split into separate blocks of the cipher's block size (possibly extending the last block with padding bits), and then each block is encrypted and decrypted independently. However, such a naive method is generally insecure because equal plaintext blocks will always generate equal ciphertext blocks (for the same key), so patterns in the plaintext message become evident in the ciphertext output.To overcome this limitation, several so-called block cipher modes of operation have been designed and specified in national recommendations such as NIST 800-38A and BSI TR-02102 and international standards such as ISO/IEC 10116. The general concept is to use randomization of the plaintext data based on an additional input value, frequently called an initialization vector, to create what is termed probabilistic encryption. In the popular cipher block chaining (CBC) mode, for encryption to be secure the initialization vector passed along with the plaintext message must be a random or pseudo-random value, which is added in an exclusive-or manner to the first plaintext block before it is encrypted. The resultant ciphertext block is then used as the new initialization vector for the next plaintext block. In the cipher feedback (CFB) mode, which emulates a self-synchronizing stream cipher, the initialization vector is first encrypted and then added to the plaintext block. The output feedback (OFB) mode repeatedly encrypts the initialization vector to create a key stream for the emulation of a synchronous stream cipher. The newer counter (CTR) mode similarly creates a key stream, but has the advantage of only needing unique and not (pseudo-)random values as initialization vectors; the needed randomness is derived internally by using the initialization vector as a block counter and encrypting this counter for each block.From a security-theoretic point of view, modes of operation must provide what is known as semantic security. Informally, it means that given some ciphertext under an unknown key one cannot practically derive any information from the ciphertext (other than the length of the message) over what one would have known without seeing the ciphertext. It has been shown that all of the modes discussed above, with the exception of the ECB mode, provide this property under so-called chosen plaintext attacks.\n\n== Padding ==\n\nSome modes such as the CBC mode only operate on complete plaintext blocks. Simply extending the last block of a message with zero bits is insufficient since it does not allow a receiver to easily distinguish messages that differ only in the number of padding bits. More importantly, such a simple solution gives rise to very efficient padding oracle attacks. A suitable padding scheme is therefore needed to extend the last plaintext block to the cipher's block size. While many popular schemes described in standards and in the literature have been shown to be vulnerable to padding oracle attacks, a solution that adds a one-bit and then extends the last block with zero-bits, standardized as \"padding method 2\" in ISO/IEC 9797-1, has been proven secure against these attacks.\n\n== Cryptanalysis ==\n\n\n*** Brute-force attacks ***\n This property results in the cipher's security degrading quadratically, and needs to be taken into account when selecting a block size. There is a trade-off though as large block sizes can result in the algorithm becoming inefficient to operate. Earlier block ciphers such as the DES have typically selected a 64-bit block size, while newer designs such as the AES support block sizes of 128 bits or more, with some ciphers supporting a range of different block sizes.\n\n\n*** Differential cryptanalysis ***\n\n\n*** Linear cryptanalysis ***\n\nA linear cryptanalysis is a form of cryptanalysis based on finding affine approximations to the action of a cipher. Linear cryptanalysis is one of the two most widely used attacks on block ciphers; the other being differential cryptanalysis.The discovery is attributed to Mitsuru Matsui, who first applied the technique to the FEAL cipher (Matsui and Yamagishi, 1992).\n\n\n*** Integral cryptanalysis ***\n\nIntegral cryptanalysis is a cryptanalytic attack that is particularly applicable to block ciphers based on substitution\u2013permutation networks. Unlike differential cryptanalysis, which uses pairs of chosen plaintexts with a fixed XOR difference, integral cryptanalysis uses sets or even multisets of chosen plaintexts of which part is held constant and another part varies through all possibilities. For example, an attack might use 256 chosen plaintexts that have all but 8 of their bits the same, but all differ in those 8 bits. Such a set necessarily has an XOR sum of 0, and the XOR sums of the corresponding sets of ciphertexts provide information about the cipher's operation. This contrast between the differences between pairs of texts and the sums of larger sets of texts inspired the name \"integral cryptanalysis\", borrowing the terminology of calculus.\n\n\n*** Other techniques ***\n\nIn addition to linear and differential cryptanalysis, there is a growing catalog of attacks: truncated differential cryptanalysis, partial differential cryptanalysis, integral cryptanalysis, which encompasses square and integral attacks, slide attacks, boomerang attacks, the XSL attack, impossible differential cryptanalysis, and algebraic attacks. For a new block cipher design to have any credibility, it must demonstrate evidence of security against known attacks.\n\n== Provable security ==\nWhen a block cipher is used in a given mode of operation, the resulting algorithm should ideally be about as secure as the block cipher itself. ECB (discussed above) emphatically lacks this property: regardless of how secure the underlying block cipher is, ECB mode can easily be attacked. On the other hand, CBC mode can be proven to be secure under the assumption that the underlying block cipher is likewise secure. Note, however, that making statements like this requires formal mathematical definitions for what it means for an encryption algorithm or a block cipher to \"be secure\". This section describes two common notions for what properties a block cipher should have. Each corresponds to a mathematical model that can be used to prove properties of higher-level algorithms, such as CBC.\nThis general approach to cryptography \u2013 proving higher-level algorithms (such as CBC) are secure under explicitly stated assumptions regarding their components (such as a block cipher) \u2013 is known as provable security.\n\n\n*** Standard model ***\n\nInformally, a block cipher is secure in the standard model if an attacker cannot tell the difference between the block cipher (equipped with a random key) and a random permutation.\nTo be a bit more precise, let E be an n-bit block cipher. We imagine the following game:\n\nThe person running the game flips a coin.\nIf the coin lands on heads, he chooses a random key K and defines the function f\n\n== Practical evaluation ==\nBlock ciphers may be evaluated according to multiple criteria in practice. Common factors include:\nKey parameters, such as its key size and block size, both of which provide an upper bound on the security of the cipher.\nThe estimated security level, which is based on the confidence gained in the block cipher design after it has largely withstood major efforts in cryptanalysis over time, the design's mathematical soundness, and the existence of practical or certificational attacks.\nThe cipher's complexity and its suitability for implementation in hardware or software. Hardware implementations may measure the complexity in terms of gate count or energy consumption, which are important parameters for resource-constrained devices.\nThe cipher's performance in terms of processing throughput on various platforms, including its memory requirements.\nThe cost of the cipher refers to licensing requirements that may apply due to intellectual property rights.\nThe flexibility of the cipher includes its ability to support multiple key sizes and block lengths.\n\n== Notable block ciphers ==\n\n\n*** Lucifer / DES ***\n\nLucifer is generally considered to be the first civilian block cipher, developed at IBM in the 1970s based on work done by Horst Feistel. A revised version of the algorithm was adopted as a U.S. government Federal Information Processing Standard: FIPS PUB 46 Data Encryption Standard (DES). It was chosen by the U.S. National Bureau of Standards (NBS) after a public invitation for submissions and some internal changes by NBS (and, potentially, the NSA). DES was publicly released in 1976 and has been widely used.DES was designed to, among other things, resist a certain cryptanalytic attack known to the NSA and rediscovered by IBM, though unknown publicly until rediscovered again and published by Eli Biham and Adi Shamir in the late 1980s. The technique is called differential cryptanalysis and remains one of the few general attacks against block ciphers; linear cryptanalysis is another but may have been unknown even to the NSA, prior to its publication by Mitsuru Matsui. DES prompted a large amount of other work and publications in cryptography and cryptanalysis in the open community and it inspired many new cipher designs.DES has a block size of 64 bits and a key size of 56 bits. 64-bit blocks became common in block cipher designs after DES. Key length depended on several factors, including government regulation. Many observers in the 1970s commented that the 56-bit key length used for DES was too short. As time went on, its inadequacy became apparent, especially after a special-purpose machine designed to break DES was demonstrated in 1998 by the Electronic Frontier Foundation. An extension to DES, Triple DES, triple-encrypts each block with either two independent keys (112-bit key and 80-bit security) or three independent keys (168-bit key and 112-bit security). It was widely adopted as a replacement. As of 2011, the three-key version is still considered secure, though the National Institute of Standards and Technology (NIST) standards no longer permit the use of the two-key version in new applications, due to its 80-bit security level.\n\n\n*** IDEA ***\nThe International Data Encryption Algorithm (IDEA) is a block cipher designed by James Massey of ETH Zurich and Xuejia Lai; it was first described in 1991, as an intended replacement for DES.\nIDEA operates on 64-bit blocks using a 128-bit key and consists of a series of eight identical transformations (a round) and an output transformation (the half-round). The processes for encryption and decryption are similar. IDEA derives much of its security by interleaving operations from different groups \u2013 modular addition and multiplication, and bitwise exclusive or (XOR) \u2013 which are algebraically \"incompatible\" in some sense.\nThe designers analysed IDEA to measure its strength against differential cryptanalysis and concluded that it is immune under certain assumptions. No successful linear or algebraic weaknesses have been reported. As of 2012, the best attack which applies to all keys can break a full 8.5-round IDEA using a narrow-bicliques attack about four times faster than brute force.\n\n\n*** RC5 ***\n\nRC5 is a block cipher designed by Ronald Rivest in 1994 which, unlike many other ciphers, has a variable block size (32, 64, or 128 bits), key size (0 to 2040 bits), and a number of rounds (0 to 255). The original suggested choice of parameters was a block size of 64 bits, a 128-bit key, and 12 rounds.\nA key feature of RC5 is the use of data-dependent rotations; one of the goals of RC5 was to prompt the study and evaluation of such operations as a cryptographic primitive. RC5 also consists of a number of modular additions and XORs. The general structure of the algorithm is a Feistel-like a network. The encryption and decryption routines can be specified in a few lines of code. The key schedule, however, is more complex, expanding the key using an essentially one-way function with the binary expansions of both e and the golden ratio as sources of \"nothing up my sleeve numbers\". The tantalizing simplicity of the algorithm together with the novelty of the data-dependent rotations has made RC5 an attractive object of study for cryptanalysts.\n12-round RC5 (with 64-bit blocks) is susceptible to a differential attack using 244 chosen plaintexts. 18\u201320 rounds are suggested as sufficient protection.\n\n\n*** Rijndael / AES ***\n\nThe Rijndael cipher developed by Belgian cryptographers, Joan Daemen and Vincent Rijmen was one of the competing designs to replace DES. It won the 5-year public competition to become the AES, (Advanced Encryption Standard).\nAdopted by NIST in 2001, AES has a fixed block size of 128 bits and a key size of 128, 192, or 256 bits, whereas Rijndael can be specified with block and key sizes in any multiple of 32 bits, with a minimum of 128 bits. The block size has a maximum of 256 bits, but the key size has no theoretical maximum. AES operates on a 4\u00d74 column-major order matrix of bytes, termed the state (versions of Rijndael with a larger block size have additional columns in the state).\n\n\n*** Blowfish ***\n\nBlowfish is a block cipher, designed in 1993 by Bruce Schneier and included in a large number of cipher suites and encryption products. Blowfish has a 64-bit block size and a variable key length from 1 bit up to 448 bits. It is a 16-round Feistel cipher and uses large key-dependent S-boxes. Notable features of the design include the key-dependent S-boxes and a highly complex key schedule.\nIt was designed as a general-purpose algorithm, intended as an alternative to the aging DES and free of the problems and constraints associated with other algorithms. At the time Blowfish was released, many other designs were proprietary, encumbered by patents, or were commercial/government secrets. Schneier has stated that \"Blowfish is unpatented, and will remain so in all countries. The algorithm is hereby placed in the public domain, and can be freely used by anyone.\" The same applies to Twofish, a successor algorithm from Schneier.\n\n== Generalizations ==\n\n\n*** Tweakable block ciphers ***\nM. Liskov, R. Rivest, and D. Wagner have described a generalized version of block ciphers called \"tweakable\" block ciphers. A tweakable block cipher accepts a second input called the tweak along with its usual plaintext or ciphertext input. The tweak, along with the key, selects the permutation computed by the cipher. If changing tweaks is sufficiently lightweight (compared with a usually fairly expensive key setup operation), then some interesting new operation modes become possible. The disk encryption theory article describes some of these modes.\n\n\n*** Format-preserving encryption ***\n\nBlock ciphers traditionally work over a binary alphabet. That is, both the input and the output are binary strings, consisting of n zeroes and ones. In some situations, however, one may wish to have a block cipher that works over some other alphabet; for example, encrypting 16-digit credit card numbers in such a way that the ciphertext is also a 16-digit number might facilitate adding an encryption layer to legacy software. This is an example of format-preserving encryption. More generally, format-preserving encryption requires a keyed permutation on some finite language. This makes format-preserving encryption schemes a natural generalization of (tweakable) block ciphers. In contrast, traditional encryption schemes, such as CBC, are not permutations because the same plaintext can encrypt multiple different ciphertexts, even when using a fixed key.\n\n== Relation to other cryptographic primitives ==\nBlock ciphers can be used to build other cryptographic primitives, such as those below. For these other primitives to be cryptographically secure, care has to be taken to build them the right way.\n\nStream ciphers can be built using block ciphers. OFB mode and CTR mode are block modes that turn a block cipher into a stream cipher.\nCryptographic hash functions can be built using block ciphers. See the one-way compression function for descriptions of several such methods. The methods resemble the block cipher modes of operation usually used for encryption.\nCryptographically secure pseudorandom number generators (CSPRNGs) can be built using block ciphers.\nSecure pseudorandom permutations of arbitrarily sized finite sets can be constructed with block ciphers; see Format-Preserving Encryption.\nA publicly known unpredictable permutation combined with key whitening is enough to construct a block cipher -- such as the single-key Even-Mansour cipher, perhaps the simplest possible provably secure block cipher.\nMessage authentication codes (MACs) are often built from block ciphers. CBC-MAC, OMAC, and PMAC are such MACs.\nAuthenticated encryption is also built from block ciphers. It means to both encrypt and MAC at the same time. That is to both provide confidentiality and authentication. CCM, EAX, GCM, and OCB are such authenticated encryption modes.Just as block ciphers can be used to build hash functions, like SHA-1 and SHA-2 are based on block ciphers which are also used independently as SHACAL, hash functions can be used to build block ciphers. Examples of such block ciphers are BEAR and LION."
    }
  },
  {
    "instruction": "IBM 4769\n\n==Introduction==\nThe IBM 4769 PCIe Cryptographic Coprocessor is a hardware security module (HSM) that includes a secure cryptoprocessor implemented on a high-security, tamper resistant, programmable PCIe board. Specialized cryptographic electronics, microprocessor, memory, and random number generator housed within a tamper-responding environment provide a highly secure subsystem in which data processing and cryptography can be performed. Sensitive key material is never exposed outside the physical secure boundary in a clear format.\nThe IBM 4769 is designed to meet FIPS PUB 140-2 Level 4, the highest level of certification achievable for commercial cryptographic devices. The 4769 is part of IBM's pervasive encryption and enterprise security schemes. The IBM 4769 data sheet describes the coprocessor in detail.\nIBM supplies two cryptographic-system implementations:\n\nThe PKCS#11 implementation, called IBM Enterprise PKCS11 (EP11), creates a high-security solution for application programs developed for this industry-standard API.\nThe IBM Common Cryptographic Architecture (CCA) implementation provides many functions of special interest in the finance industry, extensive support for distributed key management, and a base on which custom processing and cryptographic functions can be added.Applications may include financial PIN transactions, bank-to-clearing-house transactions, EMV transactions for integrated circuit (chip) based credit cards, and general-purpose cryptographic applications using symmetric key algorithms, hashing algorithms, and public key algorithms.\nThe operational keys (symmetric or asymmetric private (RSA or Elliptic Curve)) are generated in the coprocessor and are then saved either in a keystore file or in application memory, encrypted under the master key of that coprocessor. Any coprocessor with an identical master key can use those keys. See elliptic curve cryptography (ECC) for more information about ECC. New hardware in the 4769 adds support to accelerate the Elliptic Curves 25519 and Ed448, as well as the format preserving encryption (FPE) algorithms FF1, FF2, FF2.1, FF3, and FF3.1.\nIBM supports the 4769 on certain IBM Z mainframes as Crypto Express7S (CEX7S) - feature codes 0898 and 0899. The 4769 / CEX7S is part of IBM's support for pervasive encryption and drive to encrypt all data.\n\n\nQuestion: How does the IBM 4769 PCIe Cryptographic Coprocessor ensure the security of sensitive key material during data processing and cryptography?",
    "context": "",
    "output": "Answer: The IBM 4769 PCIe Cryptographic Coprocessor keeps sensitive key material secure by never exposing it outside the physical secure boundary in a clear format. It houses specialized cryptographic electronics, a microprocessor, memory, and a random number generator within a tamper-responding environment, providing a highly secure subsystem for data processing and cryptography.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the IBM 4769 PCIe Cryptographic Coprocessor ensure the security of sensitive key material during data processing and cryptography?",
      "answer": "The IBM 4769 PCIe Cryptographic Coprocessor keeps sensitive key material secure by never exposing it outside the physical secure boundary in a clear format. It houses specialized cryptographic electronics, a microprocessor, memory, and a random number generator within a tamper-responding environment, providing a highly secure subsystem for data processing and cryptography.",
      "context": "IBM 4769\n\n==Introduction==\nThe IBM 4769 PCIe Cryptographic Coprocessor is a hardware security module (HSM) that includes a secure cryptoprocessor implemented on a high-security, tamper resistant, programmable PCIe board. Specialized cryptographic electronics, microprocessor, memory, and random number generator housed within a tamper-responding environment provide a highly secure subsystem in which data processing and cryptography can be performed. Sensitive key material is never exposed outside the physical secure boundary in a clear format.\nThe IBM 4769 is designed to meet FIPS PUB 140-2 Level 4, the highest level of certification achievable for commercial cryptographic devices. The 4769 is part of IBM's pervasive encryption and enterprise security schemes. The IBM 4769 data sheet describes the coprocessor in detail.\nIBM supplies two cryptographic-system implementations:\n\nThe PKCS#11 implementation, called IBM Enterprise PKCS11 (EP11), creates a high-security solution for application programs developed for this industry-standard API.\nThe IBM Common Cryptographic Architecture (CCA) implementation provides many functions of special interest in the finance industry, extensive support for distributed key management, and a base on which custom processing and cryptographic functions can be added.Applications may include financial PIN transactions, bank-to-clearing-house transactions, EMV transactions for integrated circuit (chip) based credit cards, and general-purpose cryptographic applications using symmetric key algorithms, hashing algorithms, and public key algorithms.\nThe operational keys (symmetric or asymmetric private (RSA or Elliptic Curve)) are generated in the coprocessor and are then saved either in a keystore file or in application memory, encrypted under the master key of that coprocessor. Any coprocessor with an identical master key can use those keys. See elliptic curve cryptography (ECC) for more information about ECC. New hardware in the 4769 adds support to accelerate the Elliptic Curves 25519 and Ed448, as well as the format preserving encryption (FPE) algorithms FF1, FF2, FF2.1, FF3, and FF3.1.\nIBM supports the 4769 on certain IBM Z mainframes as Crypto Express7S (CEX7S) - feature codes 0898 and 0899. The 4769 / CEX7S is part of IBM's support for pervasive encryption and drive to encrypt all data.\n\n"
    }
  },
  {
    "instruction": "Write an answer to the following question: How does authbind affect the original process's socket?",
    "context": "",
    "output": "Authbind's helper program calls the real bind() system call on file descriptor 0, which also affects the original process's socket. This allows the original process to continue with the socket bound to the requested address and port.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does authbind affect the original process's socket?",
      "answer": "Authbind's helper program calls the real bind() system call on file descriptor 0, which also affects the original process's socket. This allows the original process to continue with the socket bound to the requested address and port."
    }
  },
  {
    "instruction": "Write an answer to the following question: When was the last product update released for the Cisco Systems VPN Client?",
    "context": "",
    "output": "The last product update for the Cisco Systems VPN Client was released on July 30, 2012.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "When was the last product update released for the Cisco Systems VPN Client?",
      "answer": "The last product update for the Cisco Systems VPN Client was released on July 30, 2012."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are some of the emerging trends and technologies in firewall appliances and software, and how do they impact the overall security posture?",
    "context": "",
    "output": "Some of the emerging trends and technologies in firewall appliances and software include artificial intelligence (AI), machine learning (ML), automation, orchestration, and cloud-based services. These trends and technologies offer potential benefits, such as improved detection and response, reduced costs and complexity, and increased agility and scalability. However, they also introduce potential challenges, such as privacy concerns, legal and regulatory compliance, and security risks. Therefore, it is important to carefully evaluate and adopt these trends and technologies based on the specific requirements and constraints of the network environment.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are some of the emerging trends and technologies in firewall appliances and software, and how do they impact the overall security posture?",
      "answer": "Some of the emerging trends and technologies in firewall appliances and software include artificial intelligence (AI), machine learning (ML), automation, orchestration, and cloud-based services. These trends and technologies offer potential benefits, such as improved detection and response, reduced costs and complexity, and increased agility and scalability. However, they also introduce potential challenges, such as privacy concerns, legal and regulatory compliance, and security risks. Therefore, it is important to carefully evaluate and adopt these trends and technologies based on the specific requirements and constraints of the network environment."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the role of the British Government Communications Headquarters (GCHQ) in operating the Ayios Nikolaos Station in Cyprus and the GCHQ Bude in Cornwall, United Kingdom?",
    "context": "",
    "output": "The British Government Communications Headquarters (GCHQ) is responsible for operating the Ayios Nikolaos Station in Cyprus and the GCHQ Bude in Cornwall, United Kingdom. These facilities are used for SIGINT operations and intelligence processing and analysis.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of the British Government Communications Headquarters (GCHQ) in operating the Ayios Nikolaos Station in Cyprus and the GCHQ Bude in Cornwall, United Kingdom?",
      "answer": "The British Government Communications Headquarters (GCHQ) is responsible for operating the Ayios Nikolaos Station in Cyprus and the GCHQ Bude in Cornwall, United Kingdom. These facilities are used for SIGINT operations and intelligence processing and analysis."
    }
  },
  {
    "instruction": "Cohen's cryptosystem\n\n==Introduction==\nCohen's cryptosystem is a public-key cryptosystem proposed in 1998 by Bram Cohen.\n\n== Key generation ==\nIn Cohen's cryptosystem, private key is a positive integer \n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n  .\nThe algorithm uses \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n   public-keys \n  \n    \n      \n        \n          w\n          \n            0\n          \n        \n        ,\n        \u2026\n        ,\n        \n          w\n          \n            k\n            \u2212\n            1\n          \n        \n      \n    \n    {\\displaystyle w_{0},\\ldots ,w_{k-1}}\n   defined as follows:\nGenerate \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n   random integers \n  \n    \n      \n        \n          u\n          \n            0\n          \n        \n        ,\n        \u2026\n        ,\n        \n          u\n          \n            k\n            \u2212\n            1\n          \n        \n      \n    \n    {\\displaystyle u_{0},\\ldots ,u_{k-1}}\n   chosen randomly and uniformly between \n  \n    \n      \n        \u2212\n        B\n      \n    \n    {\\displaystyle -B}\n   and \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n  . Where \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n   is some bound.\nLet \n  \n    \n      \n        A\n\n== Encrypting a bit ==\nTo encrypt a bit \n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n   Alice randomly adds \n  \n    \n      \n        \n          \n            k\n            2\n          \n        \n      \n    \n    {\\displaystyle {\\frac {k}{2}}}\n   public keys and multiplies the result by either 1 (if she wishes to send a 0) or by \u22121 (if she wishes to send a 1) to obtain the ciphertext \n  \n    \n      \n        c\n\n== De-cryption ==\nTo de-crypt, Bob computes \n  \n    \n      \n        h\n\nQ: What is the relationship between the private key and the public keys in Cohen's cryptosystem?",
    "context": "",
    "output": "A: The private key p is used to generate the k public keys in Cohen's cryptosystem.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the relationship between the private key and the public keys in Cohen's cryptosystem?",
      "answer": "The private key p is used to generate the k public keys in Cohen's cryptosystem.",
      "context": "Cohen's cryptosystem\n\n==Introduction==\nCohen's cryptosystem is a public-key cryptosystem proposed in 1998 by Bram Cohen.\n\n== Key generation ==\nIn Cohen's cryptosystem, private key is a positive integer \n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n  .\nThe algorithm uses \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n   public-keys \n  \n    \n      \n        \n          w\n          \n            0\n          \n        \n        ,\n        \u2026\n        ,\n        \n          w\n          \n            k\n            \u2212\n            1\n          \n        \n      \n    \n    {\\displaystyle w_{0},\\ldots ,w_{k-1}}\n   defined as follows:\nGenerate \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n   random integers \n  \n    \n      \n        \n          u\n          \n            0\n          \n        \n        ,\n        \u2026\n        ,\n        \n          u\n          \n            k\n            \u2212\n            1\n          \n        \n      \n    \n    {\\displaystyle u_{0},\\ldots ,u_{k-1}}\n   chosen randomly and uniformly between \n  \n    \n      \n        \u2212\n        B\n      \n    \n    {\\displaystyle -B}\n   and \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n  . Where \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n   is some bound.\nLet \n  \n    \n      \n        A\n\n== Encrypting a bit ==\nTo encrypt a bit \n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n   Alice randomly adds \n  \n    \n      \n        \n          \n            k\n            2\n          \n        \n      \n    \n    {\\displaystyle {\\frac {k}{2}}}\n   public keys and multiplies the result by either 1 (if she wishes to send a 0) or by \u22121 (if she wishes to send a 1) to obtain the ciphertext \n  \n    \n      \n        c\n\n== De-cryption ==\nTo de-crypt, Bob computes \n  \n    \n      \n        h"
    }
  },
  {
    "instruction": "Computer fraud\n\n==Introduction==\nComputer fraud is the act of using a computer to take or alter electronic data, or to gain unlawful use of a computer or system.  In the United States, computer fraud is specifically proscribed by the Computer Fraud and Abuse Act, which criminalizes computer-related acts under federal jurisdiction. Types of computer fraud include:\n\nDistributing hoax emails\nAccessing unauthorized computers\nEngaging in data mining via spyware and malware\nHacking into computer systems to illegally access personal information, such as credit cards or Social Security numbers\nSending computer viruses or worms with the intent to destroy or ruin another party's computer or system.Phishing, social engineering, viruses, and DDoS attacks are fairly well-known tactics used to disrupt service or gain access to another's network, but this list is not inclusive.\n\n== Notable incidents ==\nThe Melissa Virus/WormThe Melissa Virus appeared on thousands of email systems on March 26, 1999. It was disguised in each instance as an important message from a colleague or friend. The virus was designed to send an infected email to the first 50 email addresses on the users\u2019 Microsoft Outlook address book. Each infected computer would infect 50 additional computers, which in turn would infect another 50 computers. The virus proliferated rapidly and exponentially, resulting in substantial interruption and impairment of public communications and services. Many system administrators had to disconnect their computer systems from the Internet. Companies such as Microsoft, Intel, Lockheed Martin and Lucent Technologies were forced to shut down their email gateways due to the vast amount of emails the virus was generating. The Melissa virus is the most costly outbreak to date, causing more than $400 million in damages to North American businesses.\nAfter an investigation conducted by multiple branches of government and law enforcement, the Melissa Virus/Worm was attributed to David L. Smith, a 32-year-old New Jersey programmer, who was eventually charged with computer fraud. Smith was one of the first people ever to be prosecuted for the act of writing a virus. He was sentenced to 20 months in federal prison and was fined $5,000. In addition, he was also ordered to serve three years of supervised release after completion of his prison sentence. The investigation involved members of New Jersey State Police High Technology Crime Unit, the Federal Bureau of Investigation (FBI), the Justice Department\u2019s Computer Crime and Intellectual Property Section, and the Defense Criminal Investigative Service.\n\nAnswer this question based on the above context: Who investigated the Melissa Virus/Worm?",
    "context": "",
    "output": "The investigation of the Melissa Virus/Worm involved members of the New Jersey State Police High Technology Crime Unit, the Federal Bureau of Investigation (FBI), the Justice Department\u2019s Computer Crime and Intellectual Property Section, and the Defense Criminal Investigative Service.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Who investigated the Melissa Virus/Worm?",
      "answer": "The investigation of the Melissa Virus/Worm involved members of the New Jersey State Police High Technology Crime Unit, the Federal Bureau of Investigation (FBI), the Justice Department\u2019s Computer Crime and Intellectual Property Section, and the Defense Criminal Investigative Service.",
      "context": "Computer fraud\n\n==Introduction==\nComputer fraud is the act of using a computer to take or alter electronic data, or to gain unlawful use of a computer or system.  In the United States, computer fraud is specifically proscribed by the Computer Fraud and Abuse Act, which criminalizes computer-related acts under federal jurisdiction. Types of computer fraud include:\n\nDistributing hoax emails\nAccessing unauthorized computers\nEngaging in data mining via spyware and malware\nHacking into computer systems to illegally access personal information, such as credit cards or Social Security numbers\nSending computer viruses or worms with the intent to destroy or ruin another party's computer or system.Phishing, social engineering, viruses, and DDoS attacks are fairly well-known tactics used to disrupt service or gain access to another's network, but this list is not inclusive.\n\n== Notable incidents ==\nThe Melissa Virus/WormThe Melissa Virus appeared on thousands of email systems on March 26, 1999. It was disguised in each instance as an important message from a colleague or friend. The virus was designed to send an infected email to the first 50 email addresses on the users\u2019 Microsoft Outlook address book. Each infected computer would infect 50 additional computers, which in turn would infect another 50 computers. The virus proliferated rapidly and exponentially, resulting in substantial interruption and impairment of public communications and services. Many system administrators had to disconnect their computer systems from the Internet. Companies such as Microsoft, Intel, Lockheed Martin and Lucent Technologies were forced to shut down their email gateways due to the vast amount of emails the virus was generating. The Melissa virus is the most costly outbreak to date, causing more than $400 million in damages to North American businesses.\nAfter an investigation conducted by multiple branches of government and law enforcement, the Melissa Virus/Worm was attributed to David L. Smith, a 32-year-old New Jersey programmer, who was eventually charged with computer fraud. Smith was one of the first people ever to be prosecuted for the act of writing a virus. He was sentenced to 20 months in federal prison and was fined $5,000. In addition, he was also ordered to serve three years of supervised release after completion of his prison sentence. The investigation involved members of New Jersey State Police High Technology Crime Unit, the Federal Bureau of Investigation (FBI), the Justice Department\u2019s Computer Crime and Intellectual Property Section, and the Defense Criminal Investigative Service."
    }
  },
  {
    "instruction": "Write an answer to the following question: What kind of issues does Trojan:Win32/FakeSysdef scan for?",
    "context": "",
    "output": "Trojan:Win32/FakeSysdef scans the computer for hardware failures related to system memory, hard drives, and system functionality as a whole.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What kind of issues does Trojan:Win32/FakeSysdef scan for?",
      "answer": "Trojan:Win32/FakeSysdef scans the computer for hardware failures related to system memory, hard drives, and system functionality as a whole."
    }
  },
  {
    "instruction": "Authentication\n\n==Introduction==\nAuthentication (from Greek: \u03b1\u1f50\u03b8\u03b5\u03bd\u03c4\u03b9\u03ba\u03cc\u03c2 authentikos, \"real, genuine\", from \u03b1\u1f50\u03b8\u03ad\u03bd\u03c4\u03b7\u03c2 authentes, \"author\") is the act of proving an assertion, such as the identity of a computer system user. In contrast with identification, the act of indicating a person or thing's identity, authentication is the process of verifying that identity. It might involve validating personal identity documents, verifying the authenticity of a website with a digital certificate, determining the age of an artifact by carbon dating, or ensuring that a product or document is not counterfeit.\n\n== Methods ==\n\nAuthentication is relevant to multiple fields. In art, antiques, and anthropology, a common problem is verifying that a given artifact was produced by a certain person or in a certain place or period of history. In computer science, verifying a user's identity is often required to allow access to confidential data or systems.Authentication can be considered to be of three types:\nThe first type of authentication is accepting proof of identity given by a credible person who has first-hand evidence that the identity is genuine. When authentication is required of art or physical objects, this proof could be a friend, family member, or colleague attesting to the item's provenance, perhaps by having witnessed the item in its creator's possession. With autographed sports memorabilia, this could involve someone attesting that they witnessed the object being signed. A vendor selling branded items implies authenticity, while they may not have evidence that every step in the supply chain was authenticated. Centralized authority-based trust relationships back most secure internet communication through known public certificate authorities; decentralized peer-based trust, also known as a web of trust, is used for personal services such as email or files and trust is established by known individuals signing each other's cryptographic key for instance.\nThe second type of authentication is comparing the attributes of the object itself to what is known about objects of that origin. For example, an art expert might look for similarities in the style of painting, check the location and form of a signature, or compare the object to an old photograph. An archaeologist, on the other hand, might use carbon dating to verify the age of an artifact, do a chemical and spectroscopic analysis of the materials used, or compare the style of construction or decoration to other artifacts of similar origin. The physics of sound and light, and comparison with a known physical environment, can be used to examine the authenticity of audio recordings, photographs, or videos. Documents can be verified as being created on ink or paper readily available at the time of the item's implied creation.\nAttribute comparison may be vulnerable to forgery. In general, it relies on the facts that creating a forgery indistinguishable from a genuine artifact requires expert knowledge, that mistakes are easily made, and that the amount of effort required to do so is considerably greater than the amount of profit that can be gained from the forgery.\nIn art and antiques, certificates are of great importance for authenticating an object of interest and value. Certificates can, however, also be forged, and the authentication of these poses a problem. For instance, the son of Han van Meegeren, the well-known art-forger, forged the work of his father and provided a certificate for its provenance as well.\nCriminal and civil penalties for fraud, forgery, and counterfeiting can reduce the incentive for falsification, depending on the risk of getting caught.\nCurrency and other financial instruments commonly use this second type of authentication method. Bills, coins, and cheques incorporate hard-to-duplicate physical features, such as fine printing or engraving, distinctive feel, watermarks, and holographic imagery, which are easy for trained receivers to verify.\nThe third type of authentication relies on documentation or other external affirmations. In criminal courts, the rules of evidence often require establishing the chain of custody of evidence presented. This can be accomplished through a written evidence log, or by testimony from the police detectives and forensics staff that handled it. Some antiques are accompanied by certificates attesting to their authenticity. Signed sports memorabilia is usually accompanied by a certificate of authenticity. These external records have their own problems of forgery and perjury and are also vulnerable to being separated from the artifact and lost.\nIn computer science, a user can be given access to secure systems based on user credentials that imply authenticity. A network administrator can give a user a password, or provide the user with a key card or other access devices to allow system access. In this case, authenticity is implied but not guaranteed.\nConsumer goods such as pharmaceuticals, perfume, and clothing can use all  forms of authentication to prevent counterfeit goods from taking advantage of a popular brand's reputation. As mentioned above, having an item for sale in a reputable store implicitly attests to it being genuine, the first type of authentication. The second type of authentication might involve comparing the quality and craftsmanship of an item, such as an expensive handbag, to genuine articles. The third type of authentication could be the presence of a trademark on the item, which is a legally protected marking, or any other identifying feature which aids consumers in the identification of genuine brand-name goods. With software, companies have taken great steps to protect from counterfeiters, including adding holograms, security rings, security threads and color shifting ink.\n\n== Authentication factors ==\nThe ways in which someone may be authenticated fall into three categories, based on what is known as the factors of authentication: something the user knows, something the user has, and something the user is. Each authentication factor covers a range of elements used to authenticate or verify a person's identity before being granted access, approving a transaction request, signing a document or other work product, granting authority to others, and establishing a chain of authority.\nSecurity research has determined that for a positive authentication, elements from at least two, and preferably all three, factors should be verified. The three factors (classes) and some of the elements of each factor are:\n\nKnowledge: Something the user knows (e.g., a password, partial password, passphrase, personal identification number (PIN), challenge\u2013response (the user must answer a question or pattern), security question).\nOwnership: Something the user has (e.g., wrist band, ID card, security token, implanted device, cell phone with a built-in hardware token, software token, or cell phone holding a software token).\nInherence: Something the user is or does (e.g., fingerprint, retinal pattern, DNA sequence (there are assorted definitions of what is sufficient), signature, face, voice, unique bio-electric signals, or other biometric identifiers).\n\n\n*** Single-factor authentication ***\nAs the weakest level of authentication, only a single component from one of the three categories of factors is used to authenticate an individual's identity. The use of only one factor does not offer much protection from misuse or malicious intrusion. This type of authentication is not recommended for financial or personally relevant transactions that warrant a higher level of security.\n\n\n*** Multi-factor authentication ***\n\nMulti-factor authentication involves two or more authentication factors (something you know, something you have, or something you are). Two-factor authentication is a special case of multi-factor authentication involving exactly two factors.For example, using a bank card (something the user has) along with a PIN (something the user knows) provides two-factor authentication. Business networks may require users to provide a password (knowledge factor) and a pseudorandom number from a security token (ownership factor). Access to a very-high-security system might require a mantrap screening of height, weight, facial, and fingerprint checks (several inherence factor elements) plus a PIN and a day code (knowledge factor elements), but this is still a two-factor authentication.\n\n== Authentication types ==\n\n\n*** Strong authentication ***\nThe United States government's National Information Assurance Glossary defines strong authentication as a layered authentication approach relying on two or more authenticators to establish the identity of an originator or receiver of information.The European Central Bank (ECB) has defined strong authentication as \"a procedure based on two or more of the three authentication factors\". The factors that are used must be mutually independent and at least one factor must be \"non-reusable and non-replicable\", except in the case of an inherence factor and must also be incapable of being stolen off the Internet. In the European, as well as in the US-American understanding, strong authentication is very similar to multi-factor authentication or 2FA, but exceeding those with more rigorous requirements.The FIDO Alliance has been striving to establish technical specifications for strong authentication.\n\n\n*** Continuous authentication ***\nConventional computer systems authenticate users only at the initial log-in session, which can be the cause of a critical security flaw. To resolve this problem, systems need continuous user authentication methods that continuously monitor and authenticate users based on some biometric trait(s). A study used behavioural biometrics based on writing styles as a continuous authentication method.Recent research has shown the possibility of using smartphones sensors and accessories to extract some behavioral attributes such as touch dynamics, keystroke dynamics and gait recognition. These attributes are known as behavioral biometrics and could be used to verify or identify users implicitly and continuously on smartphones. The authentication systems that have been built based on these behavioral biometric traits are known as active or continuous authentication systems.\n\n\n*** Digital authentication ***\nThe term digital authentication, also known as electronic authentication or e-authentication, refers to a group of processes where the confidence for user identities is established and presented via electronic methods to an information system. The digital authentication process creates technical challenges because of the need to authenticate individuals or entities remotely over a network.\nThe American National Institute of Standards and Technology (NIST) has created a generic model for digital authentication that describes the processes that are used to accomplish secure authentication:\n\nEnrollment \u2013 an individual applies to a credential service provider (CSP) to initiate the enrollment process. After successfully proving the applicant's identity, the CSP allows the applicant to become a subscriber.\nAuthentication \u2013 After becoming a subscriber, the user receives an authenticator e.g., a token and credentials, such as a user name. He or she is then permitted to perform online transactions within an authenticated session with a relying party, where they must provide proof that he or she possesses one or more authenticators.\nLife-cycle maintenance \u2013 the CSP is charged with the task of maintaining the user's credential over the course of its lifetime, while the subscriber is responsible for maintaining his or her authenticator(s).The authentication of information can pose special problems with electronic communication, such as vulnerability to man-in-the-middle attacks, whereby a third party taps into the communication stream, and poses as each of the two other communicating parties, in order to intercept information from each. Extra identity factors can be required to authenticate each party's identity.\n\n\n*** Product authentication ***\n\nCounterfeit products are often offered to consumers as being authentic. Counterfeit consumer goods, such as electronics, music, apparel, and counterfeit medications, have been sold as being legitimate. Efforts to control the supply chain and educate consumers help ensure that authentic products are sold and used. Even security printing on packages, labels, and nameplates, however, is subject to counterfeiting.In their anti-counterfeiting technology guide, the EUIPO Observatory on Infringements of Intellectual Property Rights categorizes the main anti-counterfeiting technologies on the market currently into five main categories: electronic, marking, chemical and physical, mechanical, and technologies for digital media.Products or their packaging can include a variable QR Code. A QR Code alone is easy to verify but offers a weak level of authentication as it offers no protection against counterfeits unless scan data is analyzed at the system level to detect anomalies. To increase the security level, the QR Code can be combined with a digital watermark or copy detection pattern that are robust to copy attempts and can be authenticated with a smartphone.\nA secure key storage device can be used for authentication in consumer electronics, network authentication, license management, supply chain management, etc. Generally, the device to be authenticated needs some sort of wireless or wired digital connection to either a host system or a network. Nonetheless, the component being authenticated need not be electronic in nature as an authentication chip can be mechanically attached and read through a connector to the host e.g. an authenticated ink tank for use with a printer. For products and services that these secure coprocessors can be applied to, they can offer a solution that can be much more difficult to counterfeit than most other options while at the same time being more easily verified.\n\n\n**** Packaging ****\nPackaging and labeling can be engineered to help reduce the risks of counterfeit consumer goods or the theft and resale of products. Some package constructions are more difficult to copy and some have pilfer indicating seals. Counterfeit goods, unauthorized sales (diversion), material substitution and tampering can all be reduced with these anti-counterfeiting technologies. Packages may include authentication seals and use security printing to help indicate that the package and contents are not counterfeit; these too are subject to counterfeiting. Packages also can include anti-theft devices, such as dye-packs, RFID tags, or electronic article surveillance tags that can be activated or detected by devices at exit points and require specialized tools to deactivate. Anti-counterfeiting technologies that can be used with packaging include:\n\nTaggant fingerprinting \u2013 uniquely coded microscopic materials that are verified from a database\nEncrypted micro-particles \u2013 unpredictably placed markings (numbers, layers and colors) not visible to the human eye\nHolograms \u2013 graphics printed on seals, patches, foils or labels and used at the point of sale for visual verification\nMicro-printing \u2013 second-line authentication often used on currencies\nSerialized barcodes\nUV printing \u2013 marks only visible under UV light\nTrack and trace systems \u2013 use codes to link products to the database tracking system\nWater indicators \u2013 become visible when contacted with water\nDNA tracking \u2013 genes embedded onto labels that can be traced\nColor-shifting ink or film \u2013 visible marks that switch colors or texture when tilted\nTamper evident seals and tapes \u2013 destructible or graphically verifiable at point of sale\n2d barcodes \u2013 data codes that can be tracked\nRFID chips\nNFC chips\n\n== Information content ==\nLiterary forgery can involve imitating the style of a famous author. If an original manuscript, typewritten text, or recording is available, then the medium itself (or its packaging \u2013 anything from a box to e-mail headers) can help prove or disprove the authenticity of the document. However, text, audio, and video can be copied into new media, possibly leaving only the informational content itself to use in authentication. Various systems have been invented to allow authors to provide a means for readers to reliably authenticate that a given message originated from or was relayed by them. These involve authentication factors like:\n\nA difficult-to-reproduce physical artifact, such as a seal, signature, watermark, special stationery, or fingerprint.\nA shared secret, such as a passphrase, in the content of the message.\nAn electronic signature; public-key infrastructure is often used to cryptographically guarantee that a message has been signed by the holder of a particular private key.The opposite problem is the detection of plagiarism, where information from a different author is passed off as a person's own work. A common technique for proving plagiarism is the discovery of another copy of the same or very similar text, which has different attribution. In some cases, excessively high quality or a style mismatch may raise suspicion of plagiarism.\n\n\n*** Literacy and literature authentication ***\nIn literacy, authentication is a readers\u2019 process of questioning the veracity of an aspect of literature and then verifying those questions via research. The fundamental question for authentication of literature is \u2013 Does one believe it? Related to that, an authentication project is therefore a reading and writing activity in which students document the relevant research process (). It builds students' critical literacy. The documentation materials for literature go beyond narrative texts and likely include informational texts, primary sources, and multimedia. The process typically involves both internet and hands-on library research. When authenticating historical fiction in particular, readers consider the extent that the major historical events, as well as the culture portrayed (e.g., the language, clothing, food, gender roles), are believable for the period.\n\n== History and state-of-the-art ==\n\nHistorically, fingerprints have been used as the most authoritative method of authentication, but court cases in the US and elsewhere have raised fundamental doubts about fingerprint reliability. Outside of the legal system as well, fingerprints are easily spoofable, with British Telecom's top computer security official noting that \"few\" fingerprint readers have not already been tricked by one spoof or another. Hybrid or two-tiered authentication methods offer a compelling the solution, such as private keys encrypted by fingerprint inside of a USB device.\nIn a computer data context, cryptographic methods have been developed which are not spoofable if the originator's key has not been compromised. That the originator (or anyone other than an attacker) knows (or doesn't know) about a compromise is irrelevant. However, it is not known whether these cryptographically based authentication methods are provably secure, since unanticipated mathematical developments may make them vulnerable to attack in the future. If that were to occur, it may call into question much of the authentication in the past. In particular, a digitally signed contract may be questioned when a new attack on the cryptography underlying the signature is discovered.\n\n== Authorization ==\n\nThe process of authorization is distinct from that of authentication. Whereas authentication is the process of verifying that \"you are who you say you are\", authorization is the process of verifying that \"you are permitted to do what you are trying to do\". While authorization often happens immediately after authentication (e.g., when logging into a computer system), this does not mean authorization presupposes authentication: an anonymous agent could be authorized to a limited action set.\n\n== Access control ==\nOne familiar use of authentication and authorization is access control. A computer system that is supposed to be used only by those authorized must attempt to detect and exclude the unauthorized. Access to it is therefore usually controlled by insisting on an authentication procedure to establish with some degree of confidence the identity of the user, granting privileges established for that identity.\n\nHow can behavioral biometrics be used in continuous authentication on smartphones?",
    "context": "",
    "output": "A: Behavioral biometrics, such as touch dynamics, keystroke dynamics, and gait recognition, can be used in continuous authentication on smartphones to verify or identify users implicitly and continuously. These attributes are extracted using smartphones sensors and accessories and are used to build active or continuous authentication systems.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can behavioral biometrics be used in continuous authentication on smartphones?",
      "answer": "Behavioral biometrics, such as touch dynamics, keystroke dynamics, and gait recognition, can be used in continuous authentication on smartphones to verify or identify users implicitly and continuously. These attributes are extracted using smartphones sensors and accessories and are used to build active or continuous authentication systems.",
      "context": "Authentication\n\n==Introduction==\nAuthentication (from Greek: \u03b1\u1f50\u03b8\u03b5\u03bd\u03c4\u03b9\u03ba\u03cc\u03c2 authentikos, \"real, genuine\", from \u03b1\u1f50\u03b8\u03ad\u03bd\u03c4\u03b7\u03c2 authentes, \"author\") is the act of proving an assertion, such as the identity of a computer system user. In contrast with identification, the act of indicating a person or thing's identity, authentication is the process of verifying that identity. It might involve validating personal identity documents, verifying the authenticity of a website with a digital certificate, determining the age of an artifact by carbon dating, or ensuring that a product or document is not counterfeit.\n\n== Methods ==\n\nAuthentication is relevant to multiple fields. In art, antiques, and anthropology, a common problem is verifying that a given artifact was produced by a certain person or in a certain place or period of history. In computer science, verifying a user's identity is often required to allow access to confidential data or systems.Authentication can be considered to be of three types:\nThe first type of authentication is accepting proof of identity given by a credible person who has first-hand evidence that the identity is genuine. When authentication is required of art or physical objects, this proof could be a friend, family member, or colleague attesting to the item's provenance, perhaps by having witnessed the item in its creator's possession. With autographed sports memorabilia, this could involve someone attesting that they witnessed the object being signed. A vendor selling branded items implies authenticity, while they may not have evidence that every step in the supply chain was authenticated. Centralized authority-based trust relationships back most secure internet communication through known public certificate authorities; decentralized peer-based trust, also known as a web of trust, is used for personal services such as email or files and trust is established by known individuals signing each other's cryptographic key for instance.\nThe second type of authentication is comparing the attributes of the object itself to what is known about objects of that origin. For example, an art expert might look for similarities in the style of painting, check the location and form of a signature, or compare the object to an old photograph. An archaeologist, on the other hand, might use carbon dating to verify the age of an artifact, do a chemical and spectroscopic analysis of the materials used, or compare the style of construction or decoration to other artifacts of similar origin. The physics of sound and light, and comparison with a known physical environment, can be used to examine the authenticity of audio recordings, photographs, or videos. Documents can be verified as being created on ink or paper readily available at the time of the item's implied creation.\nAttribute comparison may be vulnerable to forgery. In general, it relies on the facts that creating a forgery indistinguishable from a genuine artifact requires expert knowledge, that mistakes are easily made, and that the amount of effort required to do so is considerably greater than the amount of profit that can be gained from the forgery.\nIn art and antiques, certificates are of great importance for authenticating an object of interest and value. Certificates can, however, also be forged, and the authentication of these poses a problem. For instance, the son of Han van Meegeren, the well-known art-forger, forged the work of his father and provided a certificate for its provenance as well.\nCriminal and civil penalties for fraud, forgery, and counterfeiting can reduce the incentive for falsification, depending on the risk of getting caught.\nCurrency and other financial instruments commonly use this second type of authentication method. Bills, coins, and cheques incorporate hard-to-duplicate physical features, such as fine printing or engraving, distinctive feel, watermarks, and holographic imagery, which are easy for trained receivers to verify.\nThe third type of authentication relies on documentation or other external affirmations. In criminal courts, the rules of evidence often require establishing the chain of custody of evidence presented. This can be accomplished through a written evidence log, or by testimony from the police detectives and forensics staff that handled it. Some antiques are accompanied by certificates attesting to their authenticity. Signed sports memorabilia is usually accompanied by a certificate of authenticity. These external records have their own problems of forgery and perjury and are also vulnerable to being separated from the artifact and lost.\nIn computer science, a user can be given access to secure systems based on user credentials that imply authenticity. A network administrator can give a user a password, or provide the user with a key card or other access devices to allow system access. In this case, authenticity is implied but not guaranteed.\nConsumer goods such as pharmaceuticals, perfume, and clothing can use all  forms of authentication to prevent counterfeit goods from taking advantage of a popular brand's reputation. As mentioned above, having an item for sale in a reputable store implicitly attests to it being genuine, the first type of authentication. The second type of authentication might involve comparing the quality and craftsmanship of an item, such as an expensive handbag, to genuine articles. The third type of authentication could be the presence of a trademark on the item, which is a legally protected marking, or any other identifying feature which aids consumers in the identification of genuine brand-name goods. With software, companies have taken great steps to protect from counterfeiters, including adding holograms, security rings, security threads and color shifting ink.\n\n== Authentication factors ==\nThe ways in which someone may be authenticated fall into three categories, based on what is known as the factors of authentication: something the user knows, something the user has, and something the user is. Each authentication factor covers a range of elements used to authenticate or verify a person's identity before being granted access, approving a transaction request, signing a document or other work product, granting authority to others, and establishing a chain of authority.\nSecurity research has determined that for a positive authentication, elements from at least two, and preferably all three, factors should be verified. The three factors (classes) and some of the elements of each factor are:\n\nKnowledge: Something the user knows (e.g., a password, partial password, passphrase, personal identification number (PIN), challenge\u2013response (the user must answer a question or pattern), security question).\nOwnership: Something the user has (e.g., wrist band, ID card, security token, implanted device, cell phone with a built-in hardware token, software token, or cell phone holding a software token).\nInherence: Something the user is or does (e.g., fingerprint, retinal pattern, DNA sequence (there are assorted definitions of what is sufficient), signature, face, voice, unique bio-electric signals, or other biometric identifiers).\n\n\n*** Single-factor authentication ***\nAs the weakest level of authentication, only a single component from one of the three categories of factors is used to authenticate an individual's identity. The use of only one factor does not offer much protection from misuse or malicious intrusion. This type of authentication is not recommended for financial or personally relevant transactions that warrant a higher level of security.\n\n\n*** Multi-factor authentication ***\n\nMulti-factor authentication involves two or more authentication factors (something you know, something you have, or something you are). Two-factor authentication is a special case of multi-factor authentication involving exactly two factors.For example, using a bank card (something the user has) along with a PIN (something the user knows) provides two-factor authentication. Business networks may require users to provide a password (knowledge factor) and a pseudorandom number from a security token (ownership factor). Access to a very-high-security system might require a mantrap screening of height, weight, facial, and fingerprint checks (several inherence factor elements) plus a PIN and a day code (knowledge factor elements), but this is still a two-factor authentication.\n\n== Authentication types ==\n\n\n*** Strong authentication ***\nThe United States government's National Information Assurance Glossary defines strong authentication as a layered authentication approach relying on two or more authenticators to establish the identity of an originator or receiver of information.The European Central Bank (ECB) has defined strong authentication as \"a procedure based on two or more of the three authentication factors\". The factors that are used must be mutually independent and at least one factor must be \"non-reusable and non-replicable\", except in the case of an inherence factor and must also be incapable of being stolen off the Internet. In the European, as well as in the US-American understanding, strong authentication is very similar to multi-factor authentication or 2FA, but exceeding those with more rigorous requirements.The FIDO Alliance has been striving to establish technical specifications for strong authentication.\n\n\n*** Continuous authentication ***\nConventional computer systems authenticate users only at the initial log-in session, which can be the cause of a critical security flaw. To resolve this problem, systems need continuous user authentication methods that continuously monitor and authenticate users based on some biometric trait(s). A study used behavioural biometrics based on writing styles as a continuous authentication method.Recent research has shown the possibility of using smartphones sensors and accessories to extract some behavioral attributes such as touch dynamics, keystroke dynamics and gait recognition. These attributes are known as behavioral biometrics and could be used to verify or identify users implicitly and continuously on smartphones. The authentication systems that have been built based on these behavioral biometric traits are known as active or continuous authentication systems.\n\n\n*** Digital authentication ***\nThe term digital authentication, also known as electronic authentication or e-authentication, refers to a group of processes where the confidence for user identities is established and presented via electronic methods to an information system. The digital authentication process creates technical challenges because of the need to authenticate individuals or entities remotely over a network.\nThe American National Institute of Standards and Technology (NIST) has created a generic model for digital authentication that describes the processes that are used to accomplish secure authentication:\n\nEnrollment \u2013 an individual applies to a credential service provider (CSP) to initiate the enrollment process. After successfully proving the applicant's identity, the CSP allows the applicant to become a subscriber.\nAuthentication \u2013 After becoming a subscriber, the user receives an authenticator e.g., a token and credentials, such as a user name. He or she is then permitted to perform online transactions within an authenticated session with a relying party, where they must provide proof that he or she possesses one or more authenticators.\nLife-cycle maintenance \u2013 the CSP is charged with the task of maintaining the user's credential over the course of its lifetime, while the subscriber is responsible for maintaining his or her authenticator(s).The authentication of information can pose special problems with electronic communication, such as vulnerability to man-in-the-middle attacks, whereby a third party taps into the communication stream, and poses as each of the two other communicating parties, in order to intercept information from each. Extra identity factors can be required to authenticate each party's identity.\n\n\n*** Product authentication ***\n\nCounterfeit products are often offered to consumers as being authentic. Counterfeit consumer goods, such as electronics, music, apparel, and counterfeit medications, have been sold as being legitimate. Efforts to control the supply chain and educate consumers help ensure that authentic products are sold and used. Even security printing on packages, labels, and nameplates, however, is subject to counterfeiting.In their anti-counterfeiting technology guide, the EUIPO Observatory on Infringements of Intellectual Property Rights categorizes the main anti-counterfeiting technologies on the market currently into five main categories: electronic, marking, chemical and physical, mechanical, and technologies for digital media.Products or their packaging can include a variable QR Code. A QR Code alone is easy to verify but offers a weak level of authentication as it offers no protection against counterfeits unless scan data is analyzed at the system level to detect anomalies. To increase the security level, the QR Code can be combined with a digital watermark or copy detection pattern that are robust to copy attempts and can be authenticated with a smartphone.\nA secure key storage device can be used for authentication in consumer electronics, network authentication, license management, supply chain management, etc. Generally, the device to be authenticated needs some sort of wireless or wired digital connection to either a host system or a network. Nonetheless, the component being authenticated need not be electronic in nature as an authentication chip can be mechanically attached and read through a connector to the host e.g. an authenticated ink tank for use with a printer. For products and services that these secure coprocessors can be applied to, they can offer a solution that can be much more difficult to counterfeit than most other options while at the same time being more easily verified.\n\n\n**** Packaging ****\nPackaging and labeling can be engineered to help reduce the risks of counterfeit consumer goods or the theft and resale of products. Some package constructions are more difficult to copy and some have pilfer indicating seals. Counterfeit goods, unauthorized sales (diversion), material substitution and tampering can all be reduced with these anti-counterfeiting technologies. Packages may include authentication seals and use security printing to help indicate that the package and contents are not counterfeit; these too are subject to counterfeiting. Packages also can include anti-theft devices, such as dye-packs, RFID tags, or electronic article surveillance tags that can be activated or detected by devices at exit points and require specialized tools to deactivate. Anti-counterfeiting technologies that can be used with packaging include:\n\nTaggant fingerprinting \u2013 uniquely coded microscopic materials that are verified from a database\nEncrypted micro-particles \u2013 unpredictably placed markings (numbers, layers and colors) not visible to the human eye\nHolograms \u2013 graphics printed on seals, patches, foils or labels and used at the point of sale for visual verification\nMicro-printing \u2013 second-line authentication often used on currencies\nSerialized barcodes\nUV printing \u2013 marks only visible under UV light\nTrack and trace systems \u2013 use codes to link products to the database tracking system\nWater indicators \u2013 become visible when contacted with water\nDNA tracking \u2013 genes embedded onto labels that can be traced\nColor-shifting ink or film \u2013 visible marks that switch colors or texture when tilted\nTamper evident seals and tapes \u2013 destructible or graphically verifiable at point of sale\n2d barcodes \u2013 data codes that can be tracked\nRFID chips\nNFC chips\n\n== Information content ==\nLiterary forgery can involve imitating the style of a famous author. If an original manuscript, typewritten text, or recording is available, then the medium itself (or its packaging \u2013 anything from a box to e-mail headers) can help prove or disprove the authenticity of the document. However, text, audio, and video can be copied into new media, possibly leaving only the informational content itself to use in authentication. Various systems have been invented to allow authors to provide a means for readers to reliably authenticate that a given message originated from or was relayed by them. These involve authentication factors like:\n\nA difficult-to-reproduce physical artifact, such as a seal, signature, watermark, special stationery, or fingerprint.\nA shared secret, such as a passphrase, in the content of the message.\nAn electronic signature; public-key infrastructure is often used to cryptographically guarantee that a message has been signed by the holder of a particular private key.The opposite problem is the detection of plagiarism, where information from a different author is passed off as a person's own work. A common technique for proving plagiarism is the discovery of another copy of the same or very similar text, which has different attribution. In some cases, excessively high quality or a style mismatch may raise suspicion of plagiarism.\n\n\n*** Literacy and literature authentication ***\nIn literacy, authentication is a readers\u2019 process of questioning the veracity of an aspect of literature and then verifying those questions via research. The fundamental question for authentication of literature is \u2013 Does one believe it? Related to that, an authentication project is therefore a reading and writing activity in which students document the relevant research process (). It builds students' critical literacy. The documentation materials for literature go beyond narrative texts and likely include informational texts, primary sources, and multimedia. The process typically involves both internet and hands-on library research. When authenticating historical fiction in particular, readers consider the extent that the major historical events, as well as the culture portrayed (e.g., the language, clothing, food, gender roles), are believable for the period.\n\n== History and state-of-the-art ==\n\nHistorically, fingerprints have been used as the most authoritative method of authentication, but court cases in the US and elsewhere have raised fundamental doubts about fingerprint reliability. Outside of the legal system as well, fingerprints are easily spoofable, with British Telecom's top computer security official noting that \"few\" fingerprint readers have not already been tricked by one spoof or another. Hybrid or two-tiered authentication methods offer a compelling the solution, such as private keys encrypted by fingerprint inside of a USB device.\nIn a computer data context, cryptographic methods have been developed which are not spoofable if the originator's key has not been compromised. That the originator (or anyone other than an attacker) knows (or doesn't know) about a compromise is irrelevant. However, it is not known whether these cryptographically based authentication methods are provably secure, since unanticipated mathematical developments may make them vulnerable to attack in the future. If that were to occur, it may call into question much of the authentication in the past. In particular, a digitally signed contract may be questioned when a new attack on the cryptography underlying the signature is discovered.\n\n== Authorization ==\n\nThe process of authorization is distinct from that of authentication. Whereas authentication is the process of verifying that \"you are who you say you are\", authorization is the process of verifying that \"you are permitted to do what you are trying to do\". While authorization often happens immediately after authentication (e.g., when logging into a computer system), this does not mean authorization presupposes authentication: an anonymous agent could be authorized to a limited action set.\n\n== Access control ==\nOne familiar use of authentication and authorization is access control. A computer system that is supposed to be used only by those authorized must attempt to detect and exclude the unauthorized. Access to it is therefore usually controlled by insisting on an authentication procedure to establish with some degree of confidence the identity of the user, granting privileges established for that identity."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does Dorkbot steal user credentials?",
    "context": "",
    "output": "Dorkbot can steal user credentials through form grabbing, FTP, POP3, or by accessing cached login details in Internet Explorer and Firefox.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does Dorkbot steal user credentials?",
      "answer": "Dorkbot can steal user credentials through form grabbing, FTP, POP3, or by accessing cached login details in Internet Explorer and Firefox."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the role of ANSSI in the context of cyber defense?",
    "context": "",
    "output": "ANSSI is responsible for monitoring, detecting, alerting, and reacting to computer attacks, particularly on the networks of the French State.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of ANSSI in the context of cyber defense?",
      "answer": "ANSSI is responsible for monitoring, detecting, alerting, and reacting to computer attacks, particularly on the networks of the French State."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are the main techniques used in the rebound attack on hash functions?",
    "context": "",
    "output": "The rebound attack utilizes rotational and differential cryptanalysis techniques to find collisions and other interesting properties in hash functions.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are the main techniques used in the rebound attack on hash functions?",
      "answer": "The rebound attack utilizes rotational and differential cryptanalysis techniques to find collisions and other interesting properties in hash functions."
    }
  },
  {
    "instruction": "Write an answer to the following question: What was the impact of Albert Gonzalez's actions on the companies that were hacked?",
    "context": "",
    "output": "Albert Gonzalez's actions resulted in the theft of millions of credit and debit card numbers from various companies, including TJX, Heartland Payment Systems, and Dave & Busters. These hacks caused significant financial losses for the companies, as well as damage to their reputations. The hacks also put millions of customers at risk of identity theft and financial fraud.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was the impact of Albert Gonzalez's actions on the companies that were hacked?",
      "answer": "Albert Gonzalez's actions resulted in the theft of millions of credit and debit card numbers from various companies, including TJX, Heartland Payment Systems, and Dave & Busters. These hacks caused significant financial losses for the companies, as well as damage to their reputations. The hacks also put millions of customers at risk of identity theft and financial fraud."
    }
  },
  {
    "instruction": "Write an answer to the following question: How did the original design of Snefru fail to withstand cryptographic attacks and what was done to improve its security?",
    "context": "",
    "output": "The original design of Snefru was shown to be insecure by Eli Biham and Adi Shamir, who were able to use differential cryptanalysis to find hash collisions. To improve its security, the design was modified by increasing the number of iterations of the main pass of the algorithm from two to eight. While differential cryptanalysis can still break the revised version with less complexity than brute force search, the attack requires an impractical number of operations, making it a certificational weakness rather than a practical vulnerability.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How did the original design of Snefru fail to withstand cryptographic attacks and what was done to improve its security?",
      "answer": "The original design of Snefru was shown to be insecure by Eli Biham and Adi Shamir, who were able to use differential cryptanalysis to find hash collisions. To improve its security, the design was modified by increasing the number of iterations of the main pass of the algorithm from two to eight. While differential cryptanalysis can still break the revised version with less complexity than brute force search, the attack requires an impractical number of operations, making it a certificational weakness rather than a practical vulnerability."
    }
  },
  {
    "instruction": "Write an answer to the following question: How has Zscaler's acquisition of TrustPath impacted its ability to provide customers with real-time threat intelligence and automated security responses?",
    "context": "",
    "output": "Zscaler's acquisition of TrustPath has improved its ability to provide customers with real-time threat intelligence and automated security responses.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How has Zscaler's acquisition of TrustPath impacted its ability to provide customers with real-time threat intelligence and automated security responses?",
      "answer": "Zscaler's acquisition of TrustPath has improved its ability to provide customers with real-time threat intelligence and automated security responses."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are the limitations of ECH in TLS 1.3 negotiation?",
    "context": "",
    "output": "To use ECH, the client must not propose TLS versions below 1.3. Also, real-world deployment of ESNI has exposed interoperability limitations. For example, specifications permit the Pre-Shared Key extension to contain any data to facilitate session resumption, even transmission of a cleartext copy of exactly the same server name that is encrypted by ESNI.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are the limitations of ECH in TLS 1.3 negotiation?",
      "answer": "To use ECH, the client must not propose TLS versions below 1.3. Also, real-world deployment of ESNI has exposed interoperability limitations. For example, specifications permit the Pre-Shared Key extension to contain any data to facilitate session resumption, even transmission of a cleartext copy of exactly the same server name that is encrypted by ESNI."
    }
  },
  {
    "instruction": "SpywareBlaster\n\n==Introduction==\nSpywareBlaster is an antispyware and antiadware program for Microsoft Windows designed to block the installation of ActiveX malware.\n\n\n\n== Overview ==\nSpywareBlaster is a program intended to prevent the download, installation and execution of most spyware, adware, browser hijackers, dialers and other malicious programs based on ActiveX.\nSpywareBlaster works on the basis of \"blacklists\" (Activating the \"Killbit\") Clsid of known malware programs, preventing them from infecting the protected computer. This approach differs from many other anti-spyware programs, which typically offer the user a chance to scan the hard drive and computer memory to remove unwanted software after it has been installed.\nSpywareBlaster allows the user to prevent privacy risks such as tracking cookies. Another feature is the ability to restrict the actions of websites known as distributors of adware and spyware. SpywareBlaster supports several web browsers, including Internet Explorer, Mozilla Firefox, Google Chrome and Microsoft Edge.\nSpywareBlaster is currently distributed as freeware, for non-commercial users.\n\nBased on the above text, answer a question. What are some examples of the types of malicious programs that SpywareBlaster can prevent?",
    "context": "",
    "output": "SpywareBlaster can prevent the installation of spyware, adware, browser hijackers, dialers, and other malicious programs based on ActiveX.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are some examples of the types of malicious programs that SpywareBlaster can prevent?",
      "answer": "SpywareBlaster can prevent the installation of spyware, adware, browser hijackers, dialers, and other malicious programs based on ActiveX.",
      "context": "SpywareBlaster\n\n==Introduction==\nSpywareBlaster is an antispyware and antiadware program for Microsoft Windows designed to block the installation of ActiveX malware.\n\n\n\n== Overview ==\nSpywareBlaster is a program intended to prevent the download, installation and execution of most spyware, adware, browser hijackers, dialers and other malicious programs based on ActiveX.\nSpywareBlaster works on the basis of \"blacklists\" (Activating the \"Killbit\") Clsid of known malware programs, preventing them from infecting the protected computer. This approach differs from many other anti-spyware programs, which typically offer the user a chance to scan the hard drive and computer memory to remove unwanted software after it has been installed.\nSpywareBlaster allows the user to prevent privacy risks such as tracking cookies. Another feature is the ability to restrict the actions of websites known as distributors of adware and spyware. SpywareBlaster supports several web browsers, including Internet Explorer, Mozilla Firefox, Google Chrome and Microsoft Edge.\nSpywareBlaster is currently distributed as freeware, for non-commercial users."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does Rootkit Hunter's use of online databases enhance its detection capabilities?",
    "context": "",
    "output": "Rootkit Hunter's use of online databases enhances its detection capabilities by providing a source of known good SHA-1 hashes and other information that can be used to compare and detect potential security issues on a system.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does Rootkit Hunter's use of online databases enhance its detection capabilities?",
      "answer": "Rootkit Hunter's use of online databases enhances its detection capabilities by providing a source of known good SHA-1 hashes and other information that can be used to compare and detect potential security issues on a system."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the significance of system high mode in the context of a hierarchical data classification scheme, and how does it differ from other security modes?",
    "context": "",
    "output": "System high mode is a security mode used in automated information systems (AIS) that handle data classified in a hierarchical scheme, such as Top Secret, Secret, and Unclassified. Unlike other security modes, system high mode does not require the system to contribute to the protection or separation of unequal security classifications. Instead, all data in the AIS is treated as if it were classified at the highest security level. This means that Unclassified information in a system high AIS must be treated as Secret and cannot be shared with unclassified destinations. System high mode does not allow for the secure declassification of data by automated means, as there is no reliable way to trust the features of the data after it has been processed by the system.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the significance of system high mode in the context of a hierarchical data classification scheme, and how does it differ from other security modes?",
      "answer": "System high mode is a security mode used in automated information systems (AIS) that handle data classified in a hierarchical scheme, such as Top Secret, Secret, and Unclassified. Unlike other security modes, system high mode does not require the system to contribute to the protection or separation of unequal security classifications. Instead, all data in the AIS is treated as if it were classified at the highest security level. This means that Unclassified information in a system high AIS must be treated as Secret and cannot be shared with unclassified destinations. System high mode does not allow for the secure declassification of data by automated means, as there is no reliable way to trust the features of the data after it has been processed by the system."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the primary SAML use case?",
    "context": "",
    "output": "The primary SAML use case is Web Browser Single Sign-On (SSO), where a user utilizes a user agent (usually a web browser) to request a web resource protected by a SAML service provider. The service provider then requests authentication from a SAML identity provider through the user agent.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the primary SAML use case?",
      "answer": "The primary SAML use case is Web Browser Single Sign-On (SSO), where a user utilizes a user agent (usually a web browser) to request a web resource protected by a SAML service provider. The service provider then requests authentication from a SAML identity provider through the user agent."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the purpose of using fictional scenarios in wargames?",
    "context": "",
    "output": "Fictional scenarios in wargames provide a safe and controlled environment for cybersecurity experts to practice their skills and learn how to respond to various types of cyber attacks. These scenarios can help participants develop a better understanding of potential threats and how to defend against them.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the purpose of using fictional scenarios in wargames?",
      "answer": "Fictional scenarios in wargames provide a safe and controlled environment for cybersecurity experts to practice their skills and learn how to respond to various types of cyber attacks. These scenarios can help participants develop a better understanding of potential threats and how to defend against them."
    }
  },
  {
    "instruction": "Computer surveillance in the workplace\n\n==Introduction==\nComputer surveillance in the workplace is the use of computers to monitor activity in a workplace. Computer monitoring is a method of collecting performance data which employers obtain through digitalised employee monitoring. Computer surveillance may nowadays be used alongside traditional security applications, such as closed-circuit television.\n\n== Computer usage monitoring ==\nDepending upon the technology and methods used, monitoring applications may track all activity or may target specific activities of employees on a company-owned computer or terminal. They may monitor various devices installed on the computer (e.g., web cameras and microphones). This includes not only recordings from these devices but also remote broadcasting of live feed from webcams and microphones.Tools used for monitoring employee computer usage incorporate: \n\nScreen monitoring records video or static images detailing the contents, or screen capture, of the entire video display or the content of the screen activity within a particular program or computer application. Monitoring tools may collect real time video, accelerated or time-lapse video or screen shots, or may take video or still image captures at regular intervals (e.g., once every 4 minutes). They may collect images constantly or only collect information while the user is interacting with the equipment (e.g., capturing screens when the mouse or keyboard is active).\nData monitoring tracks the content of and changes to files stored on the local hard drive or in the user's \"private\" network share.\nKeystroke monitoring (e.g., number of keystrokes per minute) may track the performance of keyboard-intensive work such as word processing or data entry.  Keystroke logging captures all keyboard input to enable the employer to monitor anything typed into the monitored machine.\nIdle time monitoring keeps track of time when the employee is away from the computer or the computer is not being actively used.\nPrinter monitoring records documents files that are printed from the computer.\nRemovable drives monitoring tracks external devices that are connected to the computer.\nVideo/audio monitoring makes recordings and snapshots from connected devices webcam and microphone and broadcasts video/sound live.This is also known as employee monitoring in the industry. Employee monitoring is used for multiple reasons, including compliance and Insider threat management. Employee monitoring software can monitor application software, including email, instant message, filesystem and print jobs.\n\n== Internet usage ==\nInternet surveillance is the monitoring of Internet data traffic, web access, and other online activity. This may include monitoring any Internet traffic including encrypted web browser traffic via Transport Layer Security and Secure Sockets Layer connections, personal web-based email, and personal banking sites. Research done by American Management Association that nearly 30 percent of all employers in the United States monitor employee e-mails.\n\n== Legislation ==\nLabor union contracts and other forms of employment agreements may offer some protection from monitoring.   Additionally, in the United States, public sector employees may have some protection under the Fourth Amendment to the United States Constitution. Employees in California may have additional protection under specific portions of state statute.Employers may be required to maintain documentation of emails and other communications for regulatory or compliance purposes. The monitoring of email and instant messaging communications may be part of these requirements.Some software used for this type of surveillance may impose additional restrictions or notification requirements based on their End User License Agreement (EULA). For example, Spectorsoft requires that employees have signed a contract stating that their computer activity may be monitored when they were employed. Additional legal issues may arise if information obtained from the monitoring is used for illegal or malicious purposes.\n\n== Employee perception ==\nIn organizations without stated computer usage or monitoring policy, employees typically use the company's equipment at their respective discretion and, in most cases, there may be no visible restrictions or monitoring of the activities performed on this computer. The use of computer surveillance within the employee discipline or evaluation process may be viewed by employees as an invasion of privacy or a lack of trust. Employers have the right to monitor their employees in the United States but of course, there are specific rules and regulations they must follow depending on the state legislation.Despite the fact that almost 80% of all major companies in America actively monitor their employees., public opinion is still mostly on the employees\u2019 side. Most of Americans still think that monitoring in the workplace is not entirely acceptable. According to Pew Research Center, only 6% of respondents do not care about being monitored at work.Employee's relationship with employers may be affected with being monitored at work. The freedom, privacy, respect, and responsibility aspect between human relations may be taken away from an employee when being monitored.\nQuestion: How does internet surveillance affect employee's personal activities on the internet?",
    "context": "",
    "output": "Answer: Internet surveillance can monitor any internet traffic including encrypted web browser traffic, personal web-based email, and personal banking sites. This can affect employee's privacy and freedom to use the internet for personal activities during work hours.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does internet surveillance affect employee's personal activities on the internet?",
      "answer": "Internet surveillance can monitor any internet traffic including encrypted web browser traffic, personal web-based email, and personal banking sites. This can affect employee's privacy and freedom to use the internet for personal activities during work hours.",
      "context": "Computer surveillance in the workplace\n\n==Introduction==\nComputer surveillance in the workplace is the use of computers to monitor activity in a workplace. Computer monitoring is a method of collecting performance data which employers obtain through digitalised employee monitoring. Computer surveillance may nowadays be used alongside traditional security applications, such as closed-circuit television.\n\n== Computer usage monitoring ==\nDepending upon the technology and methods used, monitoring applications may track all activity or may target specific activities of employees on a company-owned computer or terminal. They may monitor various devices installed on the computer (e.g., web cameras and microphones). This includes not only recordings from these devices but also remote broadcasting of live feed from webcams and microphones.Tools used for monitoring employee computer usage incorporate: \n\nScreen monitoring records video or static images detailing the contents, or screen capture, of the entire video display or the content of the screen activity within a particular program or computer application. Monitoring tools may collect real time video, accelerated or time-lapse video or screen shots, or may take video or still image captures at regular intervals (e.g., once every 4 minutes). They may collect images constantly or only collect information while the user is interacting with the equipment (e.g., capturing screens when the mouse or keyboard is active).\nData monitoring tracks the content of and changes to files stored on the local hard drive or in the user's \"private\" network share.\nKeystroke monitoring (e.g., number of keystrokes per minute) may track the performance of keyboard-intensive work such as word processing or data entry.  Keystroke logging captures all keyboard input to enable the employer to monitor anything typed into the monitored machine.\nIdle time monitoring keeps track of time when the employee is away from the computer or the computer is not being actively used.\nPrinter monitoring records documents files that are printed from the computer.\nRemovable drives monitoring tracks external devices that are connected to the computer.\nVideo/audio monitoring makes recordings and snapshots from connected devices webcam and microphone and broadcasts video/sound live.This is also known as employee monitoring in the industry. Employee monitoring is used for multiple reasons, including compliance and Insider threat management. Employee monitoring software can monitor application software, including email, instant message, filesystem and print jobs.\n\n== Internet usage ==\nInternet surveillance is the monitoring of Internet data traffic, web access, and other online activity. This may include monitoring any Internet traffic including encrypted web browser traffic via Transport Layer Security and Secure Sockets Layer connections, personal web-based email, and personal banking sites. Research done by American Management Association that nearly 30 percent of all employers in the United States monitor employee e-mails.\n\n== Legislation ==\nLabor union contracts and other forms of employment agreements may offer some protection from monitoring.   Additionally, in the United States, public sector employees may have some protection under the Fourth Amendment to the United States Constitution. Employees in California may have additional protection under specific portions of state statute.Employers may be required to maintain documentation of emails and other communications for regulatory or compliance purposes. The monitoring of email and instant messaging communications may be part of these requirements.Some software used for this type of surveillance may impose additional restrictions or notification requirements based on their End User License Agreement (EULA). For example, Spectorsoft requires that employees have signed a contract stating that their computer activity may be monitored when they were employed. Additional legal issues may arise if information obtained from the monitoring is used for illegal or malicious purposes.\n\n== Employee perception ==\nIn organizations without stated computer usage or monitoring policy, employees typically use the company's equipment at their respective discretion and, in most cases, there may be no visible restrictions or monitoring of the activities performed on this computer. The use of computer surveillance within the employee discipline or evaluation process may be viewed by employees as an invasion of privacy or a lack of trust. Employers have the right to monitor their employees in the United States but of course, there are specific rules and regulations they must follow depending on the state legislation.Despite the fact that almost 80% of all major companies in America actively monitor their employees., public opinion is still mostly on the employees\u2019 side. Most of Americans still think that monitoring in the workplace is not entirely acceptable. According to Pew Research Center, only 6% of respondents do not care about being monitored at work.Employee's relationship with employers may be affected with being monitored at work. The freedom, privacy, respect, and responsibility aspect between human relations may be taken away from an employee when being monitored."
    }
  },
  {
    "instruction": "Encryption\n\n==Introduction==\nIn cryptography, encryption is the process of encoding information. This process converts the original representation of the information, known as plaintext, into an alternative form known as ciphertext. Ideally, only authorized parties can decipher a ciphertext back to plaintext and access the original information. Encryption does not itself prevent interference but denies the intelligible content to a would-be interceptor. \nFor technical reasons, an encryption scheme usually uses a pseudo-random encryption key generated by an algorithm. It is possible to decrypt the message without possessing the key but, for a well-designed encryption scheme, considerable computational resources and skills are required. An authorized recipient can easily decrypt the message with the key provided by the originator to recipients but not to unauthorized users. \nHistorically, various forms of encryption have been used to aid in cryptography. Early encryption techniques were often used in military messaging. Since then, new techniques have emerged and become commonplace in all areas of modern computing. Modern encryption schemes use the concepts of public-key and symmetric-key. Modern encryption techniques ensure security because modern computers are inefficient at cracking the encryption.\n\n\n\n== Encryption in cryptography ==\nIn the context of cryptography, encryption serves as a mechanism to ensure confidentiality. Since data may be visible on the Internet, sensitive information such as passwords and personal communication may be exposed to potential interceptors. The process of encrypting and decrypting messages involves keys. The two main types of keys in cryptographic systems are symmetric-key and public-key (also known as asymmetric-key).Many complex cryptographic algorithms often use simple modular arithmetic in their implementations.\n\n\n*** Types ***\nIn symmetric-key schemes, the encryption and decryption keys are the same. Communicating parties must have the same key in order to achieve secure communication. The German Enigma Machine utilized a new symmetric-key each day for encoding and decoding messages.\nIn public-key encryption schemes, the encryption key is published for anyone to use and encrypt messages. However, only the receiving party has access to the decryption key that enables messages to be read. Public-key encryption was first described in a secret document in 1973; beforehand, all encryption schemes were symmetric-key (also called private-key).:\u200a478\u200a Although published subsequently, the work of Diffie and Hellman was published in a journal with a large readership, and the value of the methodology was explicitly described. The method became known as the Diffie-Hellman key exchange.\nRSA (Rivest\u2013Shamir\u2013Adleman) is another notable public-key cryptosystem. Created in 1978, it is still used today for applications involving digital signatures. Using number theory, the RSA algorithm selects two prime numbers, which help generate both the encryption and decryption keys.A publicly available public-key encryption application called Pretty Good Privacy (PGP) was written in 1991 by Phil Zimmermann, and distributed free of charge with source code. PGP was purchased by Symantec in 2010 and is regularly updated.\n\n== Uses ==\nEncryption has long been used by militaries and governments to facilitate secret communication. It is now commonly used in protecting information within many kinds of civilian systems. For example, the Computer Security Institute reported that in 2007, 71% of companies surveyed utilized encryption for some of their data in transit, and 53% utilized encryption for some of their data in storage. Encryption can be used to protect data \"at rest\", such as information stored on computers and storage devices (e.g. USB flash drives). In recent years, there have been numerous reports of confidential data, such as customers' personal records, being exposed through loss or theft of laptops or backup drives; encrypting such files at rest helps protect them if physical security measures fail. Digital rights management systems, which prevent unauthorized use or reproduction of copyrighted material and protect software against reverse engineering (see also copy protection), is another somewhat different example of using encryption on data at rest.Encryption is also used to protect data in transit, for example data being transferred via networks (e.g. the Internet, e-commerce), mobile telephones, wireless microphones, wireless intercom systems, Bluetooth devices and bank automatic teller machines. There have been numerous reports of data in transit being intercepted in recent years. Data should also be encrypted when transmitted across networks in order to protect against eavesdropping of network traffic by unauthorized users.\n\n\n*** Data erasure ***\n\nConventional methods for permanently deleting data from a storage device involve overwriting the device's whole content with zeros, ones, or other patterns \u2013 a process which can take a significant amount of time, depending on the capacity and the type of storage medium. Cryptography offers a way of making the erasure almost instantaneous. This method is called crypto-shredding. An example implementation of this method can be found on iOS devices, where the cryptographic key is kept in a dedicated 'effaceable storage'. Because the key is stored on the same device, this setup on its own does not offer full privacy or security protection if an unauthorized person gains physical access to the device.\n\n== Limitations ==\nEncryption is used in the 21st century to protect digital data and information systems. As computing power increased over the years, encryption technology has only become more advanced and secure. However, this advancement in technology has also exposed a potential limitation of today's encryption methods.\nThe length of the encryption key is an indicator of the strength of the encryption method. For example, the original encryption key, DES (Data Encryption Standard), was 56 bits, meaning it had 2^56 combination possibilities. With today's computing power, a 56-bit key is no longer secure, being vulnerable to hacking by brute force attack.Quantum computing utilizes properties of quantum mechanics in order to process large amounts of data simultaneously. Quantum computing has been found to achieve computing speeds thousands of times faster than today's supercomputers. This computing power presents a challenge to today's encryption technology. For example, RSA encryption utilizes the multiplication of very large prime numbers to create a semiprime number for its public key. Decoding this key without its private key requires this semiprime number to be factored, which can take a very long time to do with modern computers. It would take a supercomputer anywhere between weeks to months to factor in this key. However, quantum computing can use quantum algorithms to factor this semiprime number in the same amount of time it takes for normal computers to generate it. This would make all data protected by current public-key encryption vulnerable to quantum computing attacks. Other encryption techniques like elliptic curve cryptography and symmetric key encryption are also vulnerable to quantum computing.While quantum computing could be a threat to encryption security in the future, quantum computing as it currently stands is still very limited. Quantum computing currently is not commercially available, cannot handle large amounts of code, and only exists as computational devices, not computers. Furthermore, quantum computing advancements will be able to be utilized in favor of encryption as well. The National Security Agency (NSA) is currently preparing post-quantum encryption standards for the future. Quantum encryption promises a level of security that will be able to counter the threat of quantum computing.\n\n== Attacks and countermeasures ==\nEncryption is an important tool but is not sufficient alone to ensure the security or privacy of sensitive information throughout its lifetime. Most applications of encryption protect information only at rest or in transit, leaving sensitive data in clear text and potentially vulnerable to improper disclosure during processing, such as by a cloud service for example. Homomorphic encryption and secure multi-party computation are emerging techniques to compute on encrypted data; these techniques are general and Turing complete but incur high computational and/or communication costs.\nIn response to encryption of data at rest, cyber-adversaries have developed new types of attacks. These more recent threats to encryption of data at rest include cryptographic attacks, stolen ciphertext attacks, attacks on encryption keys, insider attacks, data corruption or integrity attacks, data destruction attacks, and ransomware attacks. Data fragmentation and active defense data protection technologies attempt to counter some of these attacks, by distributing, moving, or mutating ciphertext so it is more difficult to identify, steal, corrupt, or destroy.\n\n== The debate around encryption ==\nThe question of balancing the need for national security with the right to privacy has been debated for years, since encryption has become critical in today's digital society. The modern encryption debate started around the '90 when US government tried to ban cryptography because, according to them, it would threaten national security. The debate is polarized around two opposing views. Those who see strong encryption as a problem making it easier for criminals to hide their illegal acts online and others who argue that encryption keep digital communications safe. The debate heated up in 2014, when Big Tech like Apple and Google set encryption by default in their devices. This was the start of a series of controversies that puts governments, companies and internet users at stake.\n\n\n*** Integrity protection of ciphertexts ***\nEncryption, by itself, can protect the confidentiality of messages, but other techniques are still needed to protect the integrity and authenticity of a message; for example, verification of a message authentication code (MAC) or a digital signature usually done by a hashing algorithm or a PGP signature. Authenticated encryption algorithms are designed to provide both encryption and integrity protection together. Standards for cryptographic software and hardware to perform encryption are widely available, but successfully using encryption to ensure security may be a challenging problem. A single error in system design or execution can allow successful attacks. Sometimes an adversary can obtain unencrypted information without directly undoing the encryption. See for example traffic analysis, TEMPEST, or Trojan horse.Integrity protection mechanisms such as MACs and digital signatures must be applied to the ciphertext when it is first created, typically on the same device used to compose the message, to protect a message end-to-end along its full transmission path; otherwise, any node between the sender and the encryption agent could potentially tamper with it. Encrypting at the time of creation is only secure if the encryption device itself has correct keys and has not been tampered with. If an endpoint device has been configured to trust a root certificate that an attacker controls, for example, then the attacker can both inspect and tamper with encrypted data by performing a man-in-the-middle attack anywhere along the message's path. The common practice of TLS interception by network operators represents a controlled and institutionally sanctioned form of such an attack, but countries have also attempted to employ such attacks as a form of control and censorship.\n\n\n*** Ciphertext length and padding ***\n\nEven when encryption correctly hides a message's content and it cannot be tampered with at rest or in transit, a message's length is a form of metadata that can still leak sensitive information about the message. For example, the well-known CRIME and BREACH attacks against HTTPS were side-channel attacks that relied on information leakage via the length of encrypted content. Traffic analysis is a broad class of techniques that often employs message lengths to infer sensitive implementation about traffic flows by aggregating information about a large number of messages.\nPadding a message's payload before encrypting it can help obscure the cleartext's true length, at the cost of increasing the ciphertext's size and introducing or increasing bandwidth overhead. Messages may be padded randomly or deterministically, with each approach having different tradeoffs. Encrypting and padding messages to form padded uniform random blobs or PURBs is a practice guaranteeing that the cipher text leaks no metadata about its cleartext's content, and leaks asymptotically minimal \n  \n    \n      \n        O\n        (\n        log\n        \u2061\n        log\n        \u2061\n        M\n        )\n      \n    \n    {\\displaystyle O(\\log \\log M)}\n   information via its length.\n\nQ: What are PURBs and how do they guarantee metadata privacy?",
    "context": "",
    "output": "A: PURBs are padded uniform random blobs that encrypt and pad messages to form padded uniform random blobs. This practice guarantees that the ciphertext leaks no metadata about its cleartext's content and leaks asymptotically minimal information via its length.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are PURBs and how do they guarantee metadata privacy?",
      "answer": "PURBs are padded uniform random blobs that encrypt and pad messages to form padded uniform random blobs. This practice guarantees that the ciphertext leaks no metadata about its cleartext's content and leaks asymptotically minimal information via its length.",
      "context": "Encryption\n\n==Introduction==\nIn cryptography, encryption is the process of encoding information. This process converts the original representation of the information, known as plaintext, into an alternative form known as ciphertext. Ideally, only authorized parties can decipher a ciphertext back to plaintext and access the original information. Encryption does not itself prevent interference but denies the intelligible content to a would-be interceptor. \nFor technical reasons, an encryption scheme usually uses a pseudo-random encryption key generated by an algorithm. It is possible to decrypt the message without possessing the key but, for a well-designed encryption scheme, considerable computational resources and skills are required. An authorized recipient can easily decrypt the message with the key provided by the originator to recipients but not to unauthorized users. \nHistorically, various forms of encryption have been used to aid in cryptography. Early encryption techniques were often used in military messaging. Since then, new techniques have emerged and become commonplace in all areas of modern computing. Modern encryption schemes use the concepts of public-key and symmetric-key. Modern encryption techniques ensure security because modern computers are inefficient at cracking the encryption.\n\n\n\n== Encryption in cryptography ==\nIn the context of cryptography, encryption serves as a mechanism to ensure confidentiality. Since data may be visible on the Internet, sensitive information such as passwords and personal communication may be exposed to potential interceptors. The process of encrypting and decrypting messages involves keys. The two main types of keys in cryptographic systems are symmetric-key and public-key (also known as asymmetric-key).Many complex cryptographic algorithms often use simple modular arithmetic in their implementations.\n\n\n*** Types ***\nIn symmetric-key schemes, the encryption and decryption keys are the same. Communicating parties must have the same key in order to achieve secure communication. The German Enigma Machine utilized a new symmetric-key each day for encoding and decoding messages.\nIn public-key encryption schemes, the encryption key is published for anyone to use and encrypt messages. However, only the receiving party has access to the decryption key that enables messages to be read. Public-key encryption was first described in a secret document in 1973; beforehand, all encryption schemes were symmetric-key (also called private-key).:\u200a478\u200a Although published subsequently, the work of Diffie and Hellman was published in a journal with a large readership, and the value of the methodology was explicitly described. The method became known as the Diffie-Hellman key exchange.\nRSA (Rivest\u2013Shamir\u2013Adleman) is another notable public-key cryptosystem. Created in 1978, it is still used today for applications involving digital signatures. Using number theory, the RSA algorithm selects two prime numbers, which help generate both the encryption and decryption keys.A publicly available public-key encryption application called Pretty Good Privacy (PGP) was written in 1991 by Phil Zimmermann, and distributed free of charge with source code. PGP was purchased by Symantec in 2010 and is regularly updated.\n\n== Uses ==\nEncryption has long been used by militaries and governments to facilitate secret communication. It is now commonly used in protecting information within many kinds of civilian systems. For example, the Computer Security Institute reported that in 2007, 71% of companies surveyed utilized encryption for some of their data in transit, and 53% utilized encryption for some of their data in storage. Encryption can be used to protect data \"at rest\", such as information stored on computers and storage devices (e.g. USB flash drives). In recent years, there have been numerous reports of confidential data, such as customers' personal records, being exposed through loss or theft of laptops or backup drives; encrypting such files at rest helps protect them if physical security measures fail. Digital rights management systems, which prevent unauthorized use or reproduction of copyrighted material and protect software against reverse engineering (see also copy protection), is another somewhat different example of using encryption on data at rest.Encryption is also used to protect data in transit, for example data being transferred via networks (e.g. the Internet, e-commerce), mobile telephones, wireless microphones, wireless intercom systems, Bluetooth devices and bank automatic teller machines. There have been numerous reports of data in transit being intercepted in recent years. Data should also be encrypted when transmitted across networks in order to protect against eavesdropping of network traffic by unauthorized users.\n\n\n*** Data erasure ***\n\nConventional methods for permanently deleting data from a storage device involve overwriting the device's whole content with zeros, ones, or other patterns \u2013 a process which can take a significant amount of time, depending on the capacity and the type of storage medium. Cryptography offers a way of making the erasure almost instantaneous. This method is called crypto-shredding. An example implementation of this method can be found on iOS devices, where the cryptographic key is kept in a dedicated 'effaceable storage'. Because the key is stored on the same device, this setup on its own does not offer full privacy or security protection if an unauthorized person gains physical access to the device.\n\n== Limitations ==\nEncryption is used in the 21st century to protect digital data and information systems. As computing power increased over the years, encryption technology has only become more advanced and secure. However, this advancement in technology has also exposed a potential limitation of today's encryption methods.\nThe length of the encryption key is an indicator of the strength of the encryption method. For example, the original encryption key, DES (Data Encryption Standard), was 56 bits, meaning it had 2^56 combination possibilities. With today's computing power, a 56-bit key is no longer secure, being vulnerable to hacking by brute force attack.Quantum computing utilizes properties of quantum mechanics in order to process large amounts of data simultaneously. Quantum computing has been found to achieve computing speeds thousands of times faster than today's supercomputers. This computing power presents a challenge to today's encryption technology. For example, RSA encryption utilizes the multiplication of very large prime numbers to create a semiprime number for its public key. Decoding this key without its private key requires this semiprime number to be factored, which can take a very long time to do with modern computers. It would take a supercomputer anywhere between weeks to months to factor in this key. However, quantum computing can use quantum algorithms to factor this semiprime number in the same amount of time it takes for normal computers to generate it. This would make all data protected by current public-key encryption vulnerable to quantum computing attacks. Other encryption techniques like elliptic curve cryptography and symmetric key encryption are also vulnerable to quantum computing.While quantum computing could be a threat to encryption security in the future, quantum computing as it currently stands is still very limited. Quantum computing currently is not commercially available, cannot handle large amounts of code, and only exists as computational devices, not computers. Furthermore, quantum computing advancements will be able to be utilized in favor of encryption as well. The National Security Agency (NSA) is currently preparing post-quantum encryption standards for the future. Quantum encryption promises a level of security that will be able to counter the threat of quantum computing.\n\n== Attacks and countermeasures ==\nEncryption is an important tool but is not sufficient alone to ensure the security or privacy of sensitive information throughout its lifetime. Most applications of encryption protect information only at rest or in transit, leaving sensitive data in clear text and potentially vulnerable to improper disclosure during processing, such as by a cloud service for example. Homomorphic encryption and secure multi-party computation are emerging techniques to compute on encrypted data; these techniques are general and Turing complete but incur high computational and/or communication costs.\nIn response to encryption of data at rest, cyber-adversaries have developed new types of attacks. These more recent threats to encryption of data at rest include cryptographic attacks, stolen ciphertext attacks, attacks on encryption keys, insider attacks, data corruption or integrity attacks, data destruction attacks, and ransomware attacks. Data fragmentation and active defense data protection technologies attempt to counter some of these attacks, by distributing, moving, or mutating ciphertext so it is more difficult to identify, steal, corrupt, or destroy.\n\n== The debate around encryption ==\nThe question of balancing the need for national security with the right to privacy has been debated for years, since encryption has become critical in today's digital society. The modern encryption debate started around the '90 when US government tried to ban cryptography because, according to them, it would threaten national security. The debate is polarized around two opposing views. Those who see strong encryption as a problem making it easier for criminals to hide their illegal acts online and others who argue that encryption keep digital communications safe. The debate heated up in 2014, when Big Tech like Apple and Google set encryption by default in their devices. This was the start of a series of controversies that puts governments, companies and internet users at stake.\n\n\n*** Integrity protection of ciphertexts ***\nEncryption, by itself, can protect the confidentiality of messages, but other techniques are still needed to protect the integrity and authenticity of a message; for example, verification of a message authentication code (MAC) or a digital signature usually done by a hashing algorithm or a PGP signature. Authenticated encryption algorithms are designed to provide both encryption and integrity protection together. Standards for cryptographic software and hardware to perform encryption are widely available, but successfully using encryption to ensure security may be a challenging problem. A single error in system design or execution can allow successful attacks. Sometimes an adversary can obtain unencrypted information without directly undoing the encryption. See for example traffic analysis, TEMPEST, or Trojan horse.Integrity protection mechanisms such as MACs and digital signatures must be applied to the ciphertext when it is first created, typically on the same device used to compose the message, to protect a message end-to-end along its full transmission path; otherwise, any node between the sender and the encryption agent could potentially tamper with it. Encrypting at the time of creation is only secure if the encryption device itself has correct keys and has not been tampered with. If an endpoint device has been configured to trust a root certificate that an attacker controls, for example, then the attacker can both inspect and tamper with encrypted data by performing a man-in-the-middle attack anywhere along the message's path. The common practice of TLS interception by network operators represents a controlled and institutionally sanctioned form of such an attack, but countries have also attempted to employ such attacks as a form of control and censorship.\n\n\n*** Ciphertext length and padding ***\n\nEven when encryption correctly hides a message's content and it cannot be tampered with at rest or in transit, a message's length is a form of metadata that can still leak sensitive information about the message. For example, the well-known CRIME and BREACH attacks against HTTPS were side-channel attacks that relied on information leakage via the length of encrypted content. Traffic analysis is a broad class of techniques that often employs message lengths to infer sensitive implementation about traffic flows by aggregating information about a large number of messages.\nPadding a message's payload before encrypting it can help obscure the cleartext's true length, at the cost of increasing the ciphertext's size and introducing or increasing bandwidth overhead. Messages may be padded randomly or deterministically, with each approach having different tradeoffs. Encrypting and padding messages to form padded uniform random blobs or PURBs is a practice guaranteeing that the cipher text leaks no metadata about its cleartext's content, and leaks asymptotically minimal \n  \n    \n      \n        O\n        (\n        log\n        \u2061\n        log\n        \u2061\n        M\n        )\n      \n    \n    {\\displaystyle O(\\log \\log M)}\n   information via its length."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does containerization enhance security compared to traditional operating systems?",
    "context": "",
    "output": "Containerization provides improved security through the use of a chroot mechanism, which isolates containers from each other and from the host system. However, this security is not perfect, as demonstrated by potential privilege escalation vulnerabilities.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does containerization enhance security compared to traditional operating systems?",
      "answer": "Containerization provides improved security through the use of a chroot mechanism, which isolates containers from each other and from the host system. However, this security is not perfect, as demonstrated by potential privilege escalation vulnerabilities."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is a 'black hat' in the context of email abuse?",
    "context": "",
    "output": "A 'black hat' is an ISP that enables spamming, for example, a hosting provider that does not act upon spam complaints.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is a 'black hat' in the context of email abuse?",
      "answer": "A 'black hat' is an ISP that enables spamming, for example, a hosting provider that does not act upon spam complaints."
    }
  },
  {
    "instruction": "Strong cryptography\n\n==Introduction==\nStrong cryptography or cryptographically strong are general terms applied to cryptographic systems or components that are considered highly resistant to cryptanalysis.\nDemonstrating the resistance of any cryptographic scheme to attack is a complex matter, requiring extensive testing and reviews, preferably in a public forum. Good algorithms and protocols are required, and good system design and implementation is needed as well. For instance, the operating system on which the cryptographic software runs should be as carefully secured as possible. Users may handle passwords insecurely, or trust 'service' personnel overly much, or simply misuse the software. (See social engineering.) \"Strong\" thus is an imprecise term and may not apply in particular situations.\n\n== Background ==\nThe use of computers changed the process of cryptanalysis, famously with Bletchley Park's Colossus.  But just as the development of digital computers and electronics helped in cryptanalysis, it also made possible much more complex ciphers. It is typically the case that use of a quality cipher is very efficient, while breaking it requires an effort many orders of magnitude larger - making cryptanalysis so inefficient and impractical as to be effectively impossible.\nSince the publication of Data Encryption Standard, the Diffie-Hellman and RSA algorithm in the 1970s, cryptography has had deep connections with abstract mathematics and become a widely used tool in communications, computer networks, and computer security generally.\n\n== Cryptographically strong algorithms ==\nThis term \"cryptographically strong\" is often used to describe an encryption algorithm, and implies, in comparison to some other algorithm (which is thus cryptographically weak), greater resistance to attack. But it can also be used to describe hashing and unique identifier and filename creation algorithms. See for example the description of the Microsoft .NET runtime library function Path.GetRandomFileName. In this usage, the term means \"difficult to guess\".\nAn encryption algorithm is intended to be unbreakable (in which case it is as strong as it can ever be), but might be breakable (in which case it is as weak as it can ever be) so there is not, in principle, a continuum of strength as the idiom would seem to imply: Algorithm A is stronger than Algorithm B which is stronger than Algorithm C, and so on. The situation is made more complex, and less subsumable into a single strength metric, by the fact that there are many types of cryptanalytic attack and that any given algorithm is likely to force the attacker to do more work to break it when using one attack than another.\nThere is only one known unbreakable cryptographic system, the one-time pad, which is not generally possible to use because of the difficulties involved in exchanging one-time pads without their being compromised. So any encryption algorithm can be compared to the perfect algorithm, the one-time pad.\nThe usual sense in which this term is (loosely) used, is in reference to a particular attack, brute force key search \u2014 especially in explanations for newcomers to the field. Indeed, with this attack (always assuming keys to have been randomly chosen), there is a continuum of resistance depending on the length of the key used. But even so there are two major problems: many algorithms allow use of different length keys at different times, and any algorithm can forgo use of the full key length possible. Thus, Blowfish and RC5 are block cipher algorithms whose design specifically allowed for several key lengths, and who cannot therefore be said to have any particular strength with respect to brute force key search. Furthermore, US export regulations restrict key length for exportable cryptographic products and in several cases in the 1980s and 1990s (e.g., famously in the case of Lotus Notes' export approval) only partial keys were used, decreasing 'strength' against brute force attack for those (export) versions. More or less the same thing happened outside the US as well, as for example in the case of more than one of the cryptographic algorithms in the GSM cellular telephone standard.\nThe term is commonly used to convey that some algorithm is suitable for some task in cryptography or information security, but also resists cryptanalysis and has no, or fewer, security weaknesses. Tasks are varied, and might include:\n\ngenerating randomness\nencrypting data\nproviding a method to ensure data integrityCryptographically strong would seem to mean that the described method has some kind of maturity, perhaps even approved for use against different kinds of systematic attacks in theory and/or practice. Indeed, that the method may resist those attacks long enough to protect the information carried (and what stands behind the information) for a useful length of time. But due to the complexity and subtlety of the field, neither is almost ever the case. Since such assurances are not actually available in real practice, sleight of hand in language which implies that they are will generally be misleading.\nThere will always be uncertainty as advances (e.g., in cryptanalytic theory or merely affordable computer capacity) may reduce the effort needed to successfully use some attack method against an algorithm.\nIn addition, actual use of cryptographic algorithms requires their encapsulation in a cryptosystem, and doing so often introduces vulnerabilities which are not due to faults in an algorithm. For example, essentially all algorithms require random choice of keys, and any cryptosystem which does not provide such keys will be subject to attack regardless of any attack resistant qualities of the encryption algorithm(s) used.\n\n== Legal issues ==\n\nSince use of strong cryptography makes the job of intelligence agencies more difficult, many countries have enacted laws or regulations restricting or simply banning the non-official use of strong cryptography. For instance, the United States previously defined cryptographic products as munitions since World War II and prohibited export of cryptography beyond a certain 'strength' (measured in part by key size). However, the U.S. restrictions eased in the 1990s along with the rising need for secure e-Commerce and web-connected public software applications. The Clinton Administration issued new rules in 2000 allowing export of products containing strong cryptography, subject to certain limitations. President and government of Russia in 90s has issued a few decrees formally banning uncertified cryptosystems from use by government agencies. Presidential decree of 1995 also attempted to ban individuals from producing and selling cryptography systems without having appropriate license, but it wasn't enforced in any way as it was suspected to be contradictory the Russian Constitution of 1993 and wasn't a law per se. The decree of No.313 issued in 2012 further amended previous ones allowing to produce and distribute products with embedded cryptosystems and requiring no license as such, even though it declares some restrictions. France had quite strict regulations in this field, but has relaxed them in recent years.\n\n== Examples ==\n\n\n*** Strong ***\nPGP is generally considered an example of strong cryptography, with versions running under most popular operating systems and on various hardware platforms. The open source standard for PGP operations is OpenPGP, and GnuPG is an implementation of that standard from the FSF. However, the IDEA signature key in classical PGP is only 64 bits long, therefore no longer immune to collision attacks. OpenPGP therefore uses the SHA-2 hash function and AES cryptography.\nThe AES algorithm is considered strong after being selected in a lengthy selection process that was open and involved numerous tests.\nElliptic curve cryptography is another system which is based on a graphical geometrical function.\nThe latest version of TLS protocol (version 1.3), used to secure Internet transactions, is generally considered strong. Several vulnerabilities exist in previous versions, including demonstrated attacks such as POODLE. Worse, some cipher-suites are deliberately weakened to use a 40-bit effective key to allow export under pre-1996 U.S. regulations.\n\n\n*** Weak ***\nExamples that are not considered cryptographically strong include:\n\nThe DES, whose 56-bit keys allow attacks via exhaustive search.\nTriple-DES (3DES / EDE3-DES). see DES - this also suffers a meanwhile known phenomenon, called the \"sweet32\" or \"birthday oracle\"\nWired Equivalent Privacy which is subject to a number of attacks due to flaws in its design.\nSSL v2 and v3.  TLS 1.0 and TLS 1.1 are also deprecated now [see RFC7525] because of irreversible flaws which are still present by design and because they do not provide elliptical handshake (EC) for ciphers, no modern cryptography, no CCM/GCM ciphermodes. TLS1.x are also announced off by the PCIDSS 3.2 for commercial business/banking implementations on web frontends. Only TLS1.2 and TLS 1.3 are allowed and recommended, modern ciphers, handshakes and ciphermodes must be used exclusively.\nThe MD5 and SHA-1 hash functions, no longer immune to collision attacks.\nThe RC4 stream cipher.\nThe Clipper Chip, a failed initiative of the U.S. government that included key escrow provisions, allowing the government to gain access to the keys.\nThe 40-bit Content Scramble System used to encrypt most DVD-Video discs.\nAlmost all classical ciphers.\nMost rotary ciphers, such as the Enigma machine.\nSome flawed RSA implementations exist, leading to weak, biased keys and other vulnerabilities (\"Bleichenbacher Oracle\", \"ROBOT\" attack).\nRSA keys weaker than 2048 bits.\nDH keys weaker than 2048 bits.\nECDHE keys weaker than 192 bits; also, not all known older named curves still in use for this are vetted \"safe\".\nDHE/EDHE is guessable/weak when using/re-using known default prime values on the server\nThe CBC block cipher mode of operation is considered weak for TLS (the CCM/GCM modes are now recommended).\n\nWhat is strong cryptography and what are its general requirements?",
    "context": "",
    "output": "A: Strong cryptography, also known as cryptographically strong, refers to cryptographic systems or components that are highly resistant to cryptanalysis. These systems typically require good algorithms, protocols, and system design, as well as careful implementation and operation. Factors such as securely handling passwords, securing the operating system, and avoiding social engineering are also crucial.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is strong cryptography and what are its general requirements?",
      "answer": "Strong cryptography, also known as cryptographically strong, refers to cryptographic systems or components that are highly resistant to cryptanalysis. These systems typically require good algorithms, protocols, and system design, as well as careful implementation and operation. Factors such as securely handling passwords, securing the operating system, and avoiding social engineering are also crucial.",
      "context": "Strong cryptography\n\n==Introduction==\nStrong cryptography or cryptographically strong are general terms applied to cryptographic systems or components that are considered highly resistant to cryptanalysis.\nDemonstrating the resistance of any cryptographic scheme to attack is a complex matter, requiring extensive testing and reviews, preferably in a public forum. Good algorithms and protocols are required, and good system design and implementation is needed as well. For instance, the operating system on which the cryptographic software runs should be as carefully secured as possible. Users may handle passwords insecurely, or trust 'service' personnel overly much, or simply misuse the software. (See social engineering.) \"Strong\" thus is an imprecise term and may not apply in particular situations.\n\n== Background ==\nThe use of computers changed the process of cryptanalysis, famously with Bletchley Park's Colossus.  But just as the development of digital computers and electronics helped in cryptanalysis, it also made possible much more complex ciphers. It is typically the case that use of a quality cipher is very efficient, while breaking it requires an effort many orders of magnitude larger - making cryptanalysis so inefficient and impractical as to be effectively impossible.\nSince the publication of Data Encryption Standard, the Diffie-Hellman and RSA algorithm in the 1970s, cryptography has had deep connections with abstract mathematics and become a widely used tool in communications, computer networks, and computer security generally.\n\n== Cryptographically strong algorithms ==\nThis term \"cryptographically strong\" is often used to describe an encryption algorithm, and implies, in comparison to some other algorithm (which is thus cryptographically weak), greater resistance to attack. But it can also be used to describe hashing and unique identifier and filename creation algorithms. See for example the description of the Microsoft .NET runtime library function Path.GetRandomFileName. In this usage, the term means \"difficult to guess\".\nAn encryption algorithm is intended to be unbreakable (in which case it is as strong as it can ever be), but might be breakable (in which case it is as weak as it can ever be) so there is not, in principle, a continuum of strength as the idiom would seem to imply: Algorithm A is stronger than Algorithm B which is stronger than Algorithm C, and so on. The situation is made more complex, and less subsumable into a single strength metric, by the fact that there are many types of cryptanalytic attack and that any given algorithm is likely to force the attacker to do more work to break it when using one attack than another.\nThere is only one known unbreakable cryptographic system, the one-time pad, which is not generally possible to use because of the difficulties involved in exchanging one-time pads without their being compromised. So any encryption algorithm can be compared to the perfect algorithm, the one-time pad.\nThe usual sense in which this term is (loosely) used, is in reference to a particular attack, brute force key search \u2014 especially in explanations for newcomers to the field. Indeed, with this attack (always assuming keys to have been randomly chosen), there is a continuum of resistance depending on the length of the key used. But even so there are two major problems: many algorithms allow use of different length keys at different times, and any algorithm can forgo use of the full key length possible. Thus, Blowfish and RC5 are block cipher algorithms whose design specifically allowed for several key lengths, and who cannot therefore be said to have any particular strength with respect to brute force key search. Furthermore, US export regulations restrict key length for exportable cryptographic products and in several cases in the 1980s and 1990s (e.g., famously in the case of Lotus Notes' export approval) only partial keys were used, decreasing 'strength' against brute force attack for those (export) versions. More or less the same thing happened outside the US as well, as for example in the case of more than one of the cryptographic algorithms in the GSM cellular telephone standard.\nThe term is commonly used to convey that some algorithm is suitable for some task in cryptography or information security, but also resists cryptanalysis and has no, or fewer, security weaknesses. Tasks are varied, and might include:\n\ngenerating randomness\nencrypting data\nproviding a method to ensure data integrityCryptographically strong would seem to mean that the described method has some kind of maturity, perhaps even approved for use against different kinds of systematic attacks in theory and/or practice. Indeed, that the method may resist those attacks long enough to protect the information carried (and what stands behind the information) for a useful length of time. But due to the complexity and subtlety of the field, neither is almost ever the case. Since such assurances are not actually available in real practice, sleight of hand in language which implies that they are will generally be misleading.\nThere will always be uncertainty as advances (e.g., in cryptanalytic theory or merely affordable computer capacity) may reduce the effort needed to successfully use some attack method against an algorithm.\nIn addition, actual use of cryptographic algorithms requires their encapsulation in a cryptosystem, and doing so often introduces vulnerabilities which are not due to faults in an algorithm. For example, essentially all algorithms require random choice of keys, and any cryptosystem which does not provide such keys will be subject to attack regardless of any attack resistant qualities of the encryption algorithm(s) used.\n\n== Legal issues ==\n\nSince use of strong cryptography makes the job of intelligence agencies more difficult, many countries have enacted laws or regulations restricting or simply banning the non-official use of strong cryptography. For instance, the United States previously defined cryptographic products as munitions since World War II and prohibited export of cryptography beyond a certain 'strength' (measured in part by key size). However, the U.S. restrictions eased in the 1990s along with the rising need for secure e-Commerce and web-connected public software applications. The Clinton Administration issued new rules in 2000 allowing export of products containing strong cryptography, subject to certain limitations. President and government of Russia in 90s has issued a few decrees formally banning uncertified cryptosystems from use by government agencies. Presidential decree of 1995 also attempted to ban individuals from producing and selling cryptography systems without having appropriate license, but it wasn't enforced in any way as it was suspected to be contradictory the Russian Constitution of 1993 and wasn't a law per se. The decree of No.313 issued in 2012 further amended previous ones allowing to produce and distribute products with embedded cryptosystems and requiring no license as such, even though it declares some restrictions. France had quite strict regulations in this field, but has relaxed them in recent years.\n\n== Examples ==\n\n\n*** Strong ***\nPGP is generally considered an example of strong cryptography, with versions running under most popular operating systems and on various hardware platforms. The open source standard for PGP operations is OpenPGP, and GnuPG is an implementation of that standard from the FSF. However, the IDEA signature key in classical PGP is only 64 bits long, therefore no longer immune to collision attacks. OpenPGP therefore uses the SHA-2 hash function and AES cryptography.\nThe AES algorithm is considered strong after being selected in a lengthy selection process that was open and involved numerous tests.\nElliptic curve cryptography is another system which is based on a graphical geometrical function.\nThe latest version of TLS protocol (version 1.3), used to secure Internet transactions, is generally considered strong. Several vulnerabilities exist in previous versions, including demonstrated attacks such as POODLE. Worse, some cipher-suites are deliberately weakened to use a 40-bit effective key to allow export under pre-1996 U.S. regulations.\n\n\n*** Weak ***\nExamples that are not considered cryptographically strong include:\n\nThe DES, whose 56-bit keys allow attacks via exhaustive search.\nTriple-DES (3DES / EDE3-DES). see DES - this also suffers a meanwhile known phenomenon, called the \"sweet32\" or \"birthday oracle\"\nWired Equivalent Privacy which is subject to a number of attacks due to flaws in its design.\nSSL v2 and v3.  TLS 1.0 and TLS 1.1 are also deprecated now [see RFC7525] because of irreversible flaws which are still present by design and because they do not provide elliptical handshake (EC) for ciphers, no modern cryptography, no CCM/GCM ciphermodes. TLS1.x are also announced off by the PCIDSS 3.2 for commercial business/banking implementations on web frontends. Only TLS1.2 and TLS 1.3 are allowed and recommended, modern ciphers, handshakes and ciphermodes must be used exclusively.\nThe MD5 and SHA-1 hash functions, no longer immune to collision attacks.\nThe RC4 stream cipher.\nThe Clipper Chip, a failed initiative of the U.S. government that included key escrow provisions, allowing the government to gain access to the keys.\nThe 40-bit Content Scramble System used to encrypt most DVD-Video discs.\nAlmost all classical ciphers.\nMost rotary ciphers, such as the Enigma machine.\nSome flawed RSA implementations exist, leading to weak, biased keys and other vulnerabilities (\"Bleichenbacher Oracle\", \"ROBOT\" attack).\nRSA keys weaker than 2048 bits.\nDH keys weaker than 2048 bits.\nECDHE keys weaker than 192 bits; also, not all known older named curves still in use for this are vetted \"safe\".\nDHE/EDHE is guessable/weak when using/re-using known default prime values on the server\nThe CBC block cipher mode of operation is considered weak for TLS (the CCM/GCM modes are now recommended)."
    }
  },
  {
    "instruction": "Write an answer to the following question: What kind of platforms does Tiger support?",
    "context": "",
    "output": "Tiger supports multiple UNIX platforms, making it a widely applicable security solution for Unix-like operating systems.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What kind of platforms does Tiger support?",
      "answer": "Tiger supports multiple UNIX platforms, making it a widely applicable security solution for Unix-like operating systems."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the significance of the header in LUKS encrypted device?",
    "context": "",
    "output": "The header in a LUKS encrypted device is an unencrypted area at the beginning of the encrypted volume. It allows multiple different passphrases to be used, with the ability to change and remove them with ease. However, if the header is lost or corrupted, the device will no longer be decryptable.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the significance of the header in LUKS encrypted device?",
      "answer": "The header in a LUKS encrypted device is an unencrypted area at the beginning of the encrypted volume. It allows multiple different passphrases to be used, with the ability to change and remove them with ease. However, if the header is lost or corrupted, the device will no longer be decryptable."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are CRYPTREC's responsibilities beyond evaluating and recommending cryptographic techniques?",
    "context": "",
    "output": "CRYPTREC also provides technical evaluation and recommendations concerning regulations that implement Japanese laws, such as the Electronic Signatures and Certification Services Law, the Basic Law on the Formulation of an Advanced Information and Telecommunications Network Society of 2000, and the Public Individual Certification Law of December 2002. Additionally, CRYPTEC has responsibilities with regard to the Japanese contribution to the ISO/IEC JTC 1/SC27 standardization effort.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are CRYPTREC's responsibilities beyond evaluating and recommending cryptographic techniques?",
      "answer": "CRYPTREC also provides technical evaluation and recommendations concerning regulations that implement Japanese laws, such as the Electronic Signatures and Certification Services Law, the Basic Law on the Formulation of an Advanced Information and Telecommunications Network Society of 2000, and the Public Individual Certification Law of December 2002. Additionally, CRYPTEC has responsibilities with regard to the Japanese contribution to the ISO/IEC JTC 1/SC27 standardization effort."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is used for RSA for key establishment and digital signatures in the Commercial National Security Algorithm Suite?",
    "context": "",
    "output": "RSA uses a minimum 3072-bit modulus for key establishment and digital signatures in the Commercial National Security Algorithm Suite.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is used for RSA for key establishment and digital signatures in the Commercial National Security Algorithm Suite?",
      "answer": "RSA uses a minimum 3072-bit modulus for key establishment and digital signatures in the Commercial National Security Algorithm Suite."
    }
  },
  {
    "instruction": "Answer based on context:\n\nMathew Bevan\n\n==Introduction==\nMathew Bevan (born 10 June 1974) is a British hacker from Cardiff, Wales. In 1996 he was arrested for hacking into secure U.S. Government networks under the handle Kuji. At the age of 21, he hacked into the files of the Griffiss Air Force Base Research Laboratory in New York.Intent on proving a UFO Conspiracy Theory; his sole tool was a Amiga with a blue box program called Roxbox. He was one of two hackers said to have nearly started a third world war. according to Supervisory Special Agent Jim Christy, at the time working for the Air Force Office of Special Investigations\n\n== Background ==\nBullied by his peers,  Bevan had a difficult time with school and turned to the online world at night for an escape. Having been told ways to negate the phone system, he could call anywhere in the world without charges appearing on his bill. Bevan began to lead a double-life, a normal school life during the day followed by his now well-publicized nocturnal activities.\nOn 21 June 1996 he was arrested in connection with hacking incidents relating to several sensitive USAF, NASA, and NATO establishments. The United States Senate had already misinterpreted the situation and branded Bevan's pseudonym Kuji as a \"Foreign Agent, possibly of Eastern European origin\".A U.S. Air Force investigator summed up the risks and concerns brought about by their hacking, how Bevan's alleged partner Richard Pryce (Datastream Cowboy), then 16 years old, hacked his way into a research facility in Korea, and dumped the contents of the Korean Atomic Research Institute's database on the USAF system. The concern was that if North Korea noticed, they would think the transfer of data was an intrusion by the U.S. Air Force, and threaten physical retaliation for the espionage; fortunately it turned out to be South Korean data, significantly less volatile.\nAt Woolwich Crown Court, Friday 21 November 1997 some 18 months later, the CPS decided that it was no longer in the public interest to pursue the case. They offered 'no evidence' which resulted in a full acquittal being recorded. He used to live in Devizes, Wiltshire.\nBevan has commented on the Gary McKinnon case as being very similar to his own.\n\nWhat was the UFO conspiracy theory that Mathew Bevan intended to prove through hacking?",
    "context": "",
    "output": "Mathew Bevan intended to prove a UFO conspiracy theory through hacking.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was the UFO conspiracy theory that Mathew Bevan intended to prove through hacking?",
      "answer": "Mathew Bevan intended to prove a UFO conspiracy theory through hacking.",
      "context": "Mathew Bevan\n\n==Introduction==\nMathew Bevan (born 10 June 1974) is a British hacker from Cardiff, Wales. In 1996 he was arrested for hacking into secure U.S. Government networks under the handle Kuji. At the age of 21, he hacked into the files of the Griffiss Air Force Base Research Laboratory in New York.Intent on proving a UFO Conspiracy Theory; his sole tool was a Amiga with a blue box program called Roxbox. He was one of two hackers said to have nearly started a third world war. according to Supervisory Special Agent Jim Christy, at the time working for the Air Force Office of Special Investigations\n\n== Background ==\nBullied by his peers,  Bevan had a difficult time with school and turned to the online world at night for an escape. Having been told ways to negate the phone system, he could call anywhere in the world without charges appearing on his bill. Bevan began to lead a double-life, a normal school life during the day followed by his now well-publicized nocturnal activities.\nOn 21 June 1996 he was arrested in connection with hacking incidents relating to several sensitive USAF, NASA, and NATO establishments. The United States Senate had already misinterpreted the situation and branded Bevan's pseudonym Kuji as a \"Foreign Agent, possibly of Eastern European origin\".A U.S. Air Force investigator summed up the risks and concerns brought about by their hacking, how Bevan's alleged partner Richard Pryce (Datastream Cowboy), then 16 years old, hacked his way into a research facility in Korea, and dumped the contents of the Korean Atomic Research Institute's database on the USAF system. The concern was that if North Korea noticed, they would think the transfer of data was an intrusion by the U.S. Air Force, and threaten physical retaliation for the espionage; fortunately it turned out to be South Korean data, significantly less volatile.\nAt Woolwich Crown Court, Friday 21 November 1997 some 18 months later, the CPS decided that it was no longer in the public interest to pursue the case. They offered 'no evidence' which resulted in a full acquittal being recorded. He used to live in Devizes, Wiltshire.\nBevan has commented on the Gary McKinnon case as being very similar to his own."
    }
  },
  {
    "instruction": "Write an answer to the following question: How do internet cafes in China operate and how are they regulated?",
    "context": "",
    "output": "Internet cafes in China are regulated by the Chinese government and local government officials. Minors are not allowed to enter internet cafes, but this law is widely ignored. Internet cafe records may be confiscated by local government officials or the PSB.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do internet cafes in China operate and how are they regulated?",
      "answer": "Internet cafes in China are regulated by the Chinese government and local government officials. Minors are not allowed to enter internet cafes, but this law is widely ignored. Internet cafe records may be confiscated by local government officials or the PSB."
    }
  },
  {
    "instruction": "Write an answer to the following question: What was the initial purpose of the company that developed RoboForm when it was founded?",
    "context": "",
    "output": "The company that developed RoboForm was founded to capitalize on research into text parsing, compilation, and transformation and produce useful, commercially-viable technologies.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was the initial purpose of the company that developed RoboForm when it was founded?",
      "answer": "The company that developed RoboForm was founded to capitalize on research into text parsing, compilation, and transformation and produce useful, commercially-viable technologies."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the \"Consumer Broadband and Digital Television Promotion Act\" (CBDTPA)?",
    "context": "",
    "output": "The CBDTPA was a bill proposed in the United States Congress that would have prohibited technology that could be used to read digital content under copyright without Digital Rights Management (DRM) that prevented access to this material without the permission of the copyright holder.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the \"Consumer Broadband and Digital Television Promotion Act\" (CBDTPA)?",
      "answer": "The CBDTPA was a bill proposed in the United States Congress that would have prohibited technology that could be used to read digital content under copyright without Digital Rights Management (DRM) that prevented access to this material without the permission of the copyright holder."
    }
  },
  {
    "instruction": "Confusion and diffusion\n\n==Introduction==\nIn cryptography, confusion and diffusion are two properties of the operation of a secure cipher identified by Claude Shannon in his 1945 classified report A Mathematical Theory of Cryptography.  These properties, when present, work together to thwart the application of statistics and other methods of cryptanalysis. \nConfusion in a symmetric cipher is obscuring the local correlation between the input (plaintext) and output (ciphertext) by varying the application of the key to the data, while diffusion is hiding the plaintext statistics by spreading it over a larger area of ciphertext. Although ciphers can be confusion-only (substitution cipher, one-time pad) or diffusion-only (transposition cipher), any \"reasonable\" block cipher uses both confusion and diffusion. These concepts are also important in the design of cryptographic hash functions and pseudorandom number generators, where decorrelation of the generated values is the main feature, diffusion (and its avalanche effect) is also applicable to non-cryptographic hash functions.\n\n== Definition ==\n\n\n*** Confusion ***\nConfusion means that each binary digit (bit) of the ciphertext should depend on several parts of the key, obscuring the connections between the two.The property of confusion hides the relationship between the ciphertext and the key.\nThis property makes it difficult to find the key from the ciphertext and if a single bit in a key is changed, the calculation of  most or all of the bits in the ciphertext will be affected.\nConfusion increases the ambiguity of ciphertext and it is used by both block and stream ciphers.\nIn substitution\u2013permutation networks, confusion is provided by substitution boxes.\n\n\n*** Diffusion ***\nDiffusion means that if we change a single bit of the plaintext, then about half of the bits in the ciphertext should change, and similarly, if we change one bit of the ciphertext, then about half of the plaintext bits should change. This is equivalent to the expectation that encryption schemes exhibit an avalanche effect.\nThe purpose of diffusion is to hide the statistical relationship between the ciphertext and the plain text. For example, diffusion ensures that any patterns in the plaintext, such as redundant bits, are not apparent in the ciphertext. Block ciphers achieve this by \"diffusing\" the information about the plaintext's structure across the rows and columns of the cipher.\nIn substitution\u2013permutation networks, diffusion is provided by permutation boxes (a.k.a. permutation layer). In the beginning of the 21st century a consensus had appeared where the designers preferred the permutation layer to consist of linear Boolean functions, although nonlinear functions can be used, too.\n\n== Theory ==\nIn Shannon's original definitions, confusion refers to making the relationship between the ciphertext and the symmetric key as complex and involved as possible; diffusion refers to dissipating the statistical structure of plaintext over the bulk of ciphertext. This complexity is generally implemented through a well-defined and repeatable series of substitutions and permutations. Substitution refers to the replacement of certain components (usually bits) with other components, following certain rules. Permutation refers to manipulation of the order of bits according to some algorithm. To be effective, any non-uniformity of plaintext bits needs to be redistributed across much larger structures in the ciphertext, making that non-uniformity much harder to detect.\nIn particular, for a randomly chosen input, if one flips the i-th bit, then the probability that the j-th output bit will change should be one half, for any i and j\u2014this is termed the strict avalanche criterion. More generally, one may require that flipping a fixed set of bits should change each output bit with probability one half.\nOne aim of confusion is to make it very hard to find the key even if one has a large number of plaintext-ciphertext pairs produced with the same key. Therefore, each bit of the ciphertext should depend on the entire key, and in different ways on different bits of the key. In particular, changing one bit of the key should change the ciphertext completely.\n\n== Practical applications ==\nDesign of a modern block cipher uses both confusion and diffusion,\nwith confusion changing data between the input and the output by applying a key-dependent non-linear transformation (linear calculations are easier to reverse and thus are easier to break).\nConfusion inevitably involves some diffusion, so a design with a very wide-input S-box can provide the necessary diffusion properties, but will be very costly in implementation. Therefore the practical ciphers utilize relatively small S-boxes, operating on small groups of bits (\"bundles\"). For example, the design of AES has 8-bit S-boxes, Serpent \u2212 4-bit, BaseKing and 3-way \u2212 3-bit. Small S-boxes provide almost no diffusion, so the resources are spent on simpler diffusion transformations. For example, the wide trail strategy popularized by the Rijndael design, involves a linear mixing transformation that provides high diffusion, although he security proofs do not depend on the diffusion layer being linear.One of the most researched cipher structures uses the substitution-permutation network (SPN) where each round includes a layer of local nonlinear permutations (S-boxes) for confusion and a linear diffusion transformation (usually a multiplication by a matrix over a finite field). Modern block ciphers mostly follow the  confusion layer/diffusion layer model, with the efficiency of the diffusion layer estimated using the so called branch number, a numerical parameter that can reach the value \n  \n    \n      \n        s\n        +\n        1\n      \n    \n    {\\displaystyle s+1}\n   for s input bundles for the perfect diffusion transformation. Since the transformations that have high branch numbers (and thus require a lot of bundles as inputs) are costly in implementation, the diffusion layer is sometimes (for example, in the AES) composed from two sublayers, \"local diffusion\" that processes subsets of the bundles in a bricklayer fashion (each subset is transformed independently) and  \"dispersion\" that makes the bits that were \"close\" (within one subset of bundles) to become \"distant\" (spread to different subsets and thus be locally diffused within these new subsets on the next round).\n\n\n*** Analysis of AES ***\nThe Advanced Encryption Standard (AES) has both excellent confusion and diffusion. Its confusion look-up tables are very non-linear and good at destroying patterns. Its diffusion stage spreads every part of the input to every part of the output: changing one bit of input changes half the output bits on average. Both confusion and diffusion are repeated multiple times for each input to increase the amount of scrambling. The secret key is mixed in at every stage so that an attacker cannot precalculate what the cipher does.\nNone of this happens when a simple one-stage scramble is based on a key. Input patterns would flow straight through to the output. It might look random to the eye but analysis would find obvious patterns and the cipher could be broken.\n\nWhat is the role of permutation in the implementation of confusion in cryptography?",
    "context": "",
    "output": "A: Permutation refers to the manipulation of the order of bits according to some algorithm. This is used in conjunction with substitution to redistributed any non-uniformity of plaintext bits across much larger structures in the ciphertext, making that non-uniformity much harder to detect.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of permutation in the implementation of confusion in cryptography?",
      "answer": "Permutation refers to the manipulation of the order of bits according to some algorithm. This is used in conjunction with substitution to redistributed any non-uniformity of plaintext bits across much larger structures in the ciphertext, making that non-uniformity much harder to detect.",
      "context": "Confusion and diffusion\n\n==Introduction==\nIn cryptography, confusion and diffusion are two properties of the operation of a secure cipher identified by Claude Shannon in his 1945 classified report A Mathematical Theory of Cryptography.  These properties, when present, work together to thwart the application of statistics and other methods of cryptanalysis. \nConfusion in a symmetric cipher is obscuring the local correlation between the input (plaintext) and output (ciphertext) by varying the application of the key to the data, while diffusion is hiding the plaintext statistics by spreading it over a larger area of ciphertext. Although ciphers can be confusion-only (substitution cipher, one-time pad) or diffusion-only (transposition cipher), any \"reasonable\" block cipher uses both confusion and diffusion. These concepts are also important in the design of cryptographic hash functions and pseudorandom number generators, where decorrelation of the generated values is the main feature, diffusion (and its avalanche effect) is also applicable to non-cryptographic hash functions.\n\n== Definition ==\n\n\n*** Confusion ***\nConfusion means that each binary digit (bit) of the ciphertext should depend on several parts of the key, obscuring the connections between the two.The property of confusion hides the relationship between the ciphertext and the key.\nThis property makes it difficult to find the key from the ciphertext and if a single bit in a key is changed, the calculation of  most or all of the bits in the ciphertext will be affected.\nConfusion increases the ambiguity of ciphertext and it is used by both block and stream ciphers.\nIn substitution\u2013permutation networks, confusion is provided by substitution boxes.\n\n\n*** Diffusion ***\nDiffusion means that if we change a single bit of the plaintext, then about half of the bits in the ciphertext should change, and similarly, if we change one bit of the ciphertext, then about half of the plaintext bits should change. This is equivalent to the expectation that encryption schemes exhibit an avalanche effect.\nThe purpose of diffusion is to hide the statistical relationship between the ciphertext and the plain text. For example, diffusion ensures that any patterns in the plaintext, such as redundant bits, are not apparent in the ciphertext. Block ciphers achieve this by \"diffusing\" the information about the plaintext's structure across the rows and columns of the cipher.\nIn substitution\u2013permutation networks, diffusion is provided by permutation boxes (a.k.a. permutation layer). In the beginning of the 21st century a consensus had appeared where the designers preferred the permutation layer to consist of linear Boolean functions, although nonlinear functions can be used, too.\n\n== Theory ==\nIn Shannon's original definitions, confusion refers to making the relationship between the ciphertext and the symmetric key as complex and involved as possible; diffusion refers to dissipating the statistical structure of plaintext over the bulk of ciphertext. This complexity is generally implemented through a well-defined and repeatable series of substitutions and permutations. Substitution refers to the replacement of certain components (usually bits) with other components, following certain rules. Permutation refers to manipulation of the order of bits according to some algorithm. To be effective, any non-uniformity of plaintext bits needs to be redistributed across much larger structures in the ciphertext, making that non-uniformity much harder to detect.\nIn particular, for a randomly chosen input, if one flips the i-th bit, then the probability that the j-th output bit will change should be one half, for any i and j\u2014this is termed the strict avalanche criterion. More generally, one may require that flipping a fixed set of bits should change each output bit with probability one half.\nOne aim of confusion is to make it very hard to find the key even if one has a large number of plaintext-ciphertext pairs produced with the same key. Therefore, each bit of the ciphertext should depend on the entire key, and in different ways on different bits of the key. In particular, changing one bit of the key should change the ciphertext completely.\n\n== Practical applications ==\nDesign of a modern block cipher uses both confusion and diffusion,\nwith confusion changing data between the input and the output by applying a key-dependent non-linear transformation (linear calculations are easier to reverse and thus are easier to break).\nConfusion inevitably involves some diffusion, so a design with a very wide-input S-box can provide the necessary diffusion properties, but will be very costly in implementation. Therefore the practical ciphers utilize relatively small S-boxes, operating on small groups of bits (\"bundles\"). For example, the design of AES has 8-bit S-boxes, Serpent \u2212 4-bit, BaseKing and 3-way \u2212 3-bit. Small S-boxes provide almost no diffusion, so the resources are spent on simpler diffusion transformations. For example, the wide trail strategy popularized by the Rijndael design, involves a linear mixing transformation that provides high diffusion, although he security proofs do not depend on the diffusion layer being linear.One of the most researched cipher structures uses the substitution-permutation network (SPN) where each round includes a layer of local nonlinear permutations (S-boxes) for confusion and a linear diffusion transformation (usually a multiplication by a matrix over a finite field). Modern block ciphers mostly follow the  confusion layer/diffusion layer model, with the efficiency of the diffusion layer estimated using the so called branch number, a numerical parameter that can reach the value \n  \n    \n      \n        s\n        +\n        1\n      \n    \n    {\\displaystyle s+1}\n   for s input bundles for the perfect diffusion transformation. Since the transformations that have high branch numbers (and thus require a lot of bundles as inputs) are costly in implementation, the diffusion layer is sometimes (for example, in the AES) composed from two sublayers, \"local diffusion\" that processes subsets of the bundles in a bricklayer fashion (each subset is transformed independently) and  \"dispersion\" that makes the bits that were \"close\" (within one subset of bundles) to become \"distant\" (spread to different subsets and thus be locally diffused within these new subsets on the next round).\n\n\n*** Analysis of AES ***\nThe Advanced Encryption Standard (AES) has both excellent confusion and diffusion. Its confusion look-up tables are very non-linear and good at destroying patterns. Its diffusion stage spreads every part of the input to every part of the output: changing one bit of input changes half the output bits on average. Both confusion and diffusion are repeated multiple times for each input to increase the amount of scrambling. The secret key is mixed in at every stage so that an attacker cannot precalculate what the cipher does.\nNone of this happens when a simple one-stage scramble is based on a key. Input patterns would flow straight through to the output. It might look random to the eye but analysis would find obvious patterns and the cipher could be broken."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the purpose of the Fragment Offset field in the IP header?",
    "context": "",
    "output": "The Fragment Offset field in the IP header is used to indicate which part of the original IP packet a particular IP fragment contains. The field is 13 bits long and contains the offset of the data in the current IP fragment, in the original IP packet. The offset is given in units of 8 bytes.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the purpose of the Fragment Offset field in the IP header?",
      "answer": "The Fragment Offset field in the IP header is used to indicate which part of the original IP packet a particular IP fragment contains. The field is 13 bits long and contains the offset of the data in the current IP fragment, in the original IP packet. The offset is given in units of 8 bytes."
    }
  },
  {
    "instruction": "Write an answer to the following question: In what ways does Incapsula's WAF protect websites from academic web archiving and referrer spam?",
    "context": "",
    "output": "Incapsula's WAF safeguards websites from academic web archiving and referrer spam by filtering out malicious traffic and ensuring website security.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "In what ways does Incapsula's WAF protect websites from academic web archiving and referrer spam?",
      "answer": "Incapsula's WAF safeguards websites from academic web archiving and referrer spam by filtering out malicious traffic and ensuring website security."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the MixColumns function in AES and how does it operate?",
    "context": "",
    "output": "The MixColumns function in AES is an invertible linear transformation that combines the four bytes of each column of the state using a fixed matrix. This function provides diffusion in the cipher, ensuring that each input byte affects all four output bytes.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the MixColumns function in AES and how does it operate?",
      "answer": "The MixColumns function in AES is an invertible linear transformation that combines the four bytes of each column of the state using a fixed matrix. This function provides diffusion in the cipher, ensuring that each input byte affects all four output bytes."
    }
  },
  {
    "instruction": "Context: Trusted Platform Module\n\n==Introduction==\nTrusted Platform Module (TPM, also known as ISO/IEC 11889) is an international standard for a secure cryptoprocessor, a dedicated microcontroller designed to secure hardware through integrated cryptographic keys. The term can also refer to a chip conforming to the standard.\nOne of Windows 11's system requirements is TPM 2.0. Microsoft has stated that this is to help increase security against firmware attacks.\n\n\n\n== Overview ==\nTrusted Platform Module provides\n\nA hardware random number generator\nFacilities for the secure generation of cryptographic keys for limited uses.\nRemote attestation: Creates a nearly unforgeable hash key summary of the hardware and software configuration.  One could use the hash to verify that the hardware and software have not been changed. The software in charge of hashing the setup determines the extent of the summary.\nBinding: Encrypts data using the TPM bind key, a unique RSA key descended from a storage key. Computers that incorporate a TPM can create cryptographic keys and encrypt them so that they can only be decrypted by the TPM. This process, often called wrapping or binding a key, can help protect the key from disclosure. Each TPM has a master wrapping key, called the storage root key, which is stored within the TPM itself. User-level RSA key containers are stored with the Windows user profile for a particular user and can be used to encrypt and decrypt information for applications that run under that specific user identity.\nSealing: Similar to binding, but in addition, specifies the TPM state for the data to be decrypted (unsealed).\nOther Trusted Computing functions for the data to be decrypted (unsealed).Computer programs can use a TPM to authenticate hardware devices, since each TPM chip has a unique and secret Endorsement Key (EK) burned in as it is produced. Security embedded in hardware provides more protection than a software-only solution.  Its use is restricted in some countries.\n\n== Uses ==\n\n\n*** Platform integrity ***\nThe primary scope of TPM is to ensure the integrity of a platform. In this context, \"integrity\" means \"behave as intended\", and a \"platform\" is any computer device regardless of its operating system. This is to ensure that the boot process starts from a trusted combination of hardware and software, and continues until the operating system has fully booted and applications are running.\nWhen TPM is used, the firmware and the operating system are responsible for ensuring integrity.\nFor example, Unified Extensible Firmware Interface (UEFI) can use TPM to form a root of trust: The TPM contains several Platform Configuration Registers (PCRs) that allow secure storage and reporting of security-relevant metrics. These metrics can be used to detect changes to previous configurations and decide how to proceed. Examples of such use can be found in Linux Unified Key Setup (LUKS), BitLocker and PrivateCore vCage memory encryption. (See below.)\nAnother example of platform integrity via TPM is in the use of Microsoft Office 365 licensing and Outlook Exchange.An example of TPM use for platform integrity is the Trusted Execution Technology (TXT), which creates a chain of trust. It could remotely attest that a computer is using the specified hardware and software.\n\n\n*** Disk encryption ***\nFull disk encryption utilities, such as dm-crypt and BitLocker, can use this technology to protect the keys used to encrypt the computer's storage devices and provide integrity authentication for a trusted boot pathway that includes firmware and boot sector.\n\n\n*** Other uses and concerns ***\nAny application can use a TPM chip for:\n\nDigital rights management (DRM)\nWindows Defender\nWindows Domain logon\nProtection and enforcement of software licenses\nPrevention of cheating in online gamesOther uses exist, some of which give rise to privacy concerns. The \"physical presence\" feature of TPM addresses some of these concerns by requiring BIOS-level confirmation for operations such as activating, deactivating, clearing or changing ownership of TPM by someone who is physically present at the console of the machine.\n\n\n*** By organizations ***\nThe United States Department of Defense (DoD) specifies that \"new computer assets (e.g., server, desktop, laptop, thin client, tablet, smartphone, personal digital assistant, mobile phone) procured to support DoD will include a TPM version 1.2 or higher where required by Defense Information Systems Agency (DISA) Security Technical Implementation Guides (STIGs) and where such technology is available.\" DoD anticipates that TPM is to be used for device identification, authentication, encryption, and device integrity verification.\n\n== TPM implementations ==\n\nIn 2006, new laptops began being sold with a built-in TPM chip. In the future, this concept could be co-located on an existing motherboard chip in computers, or any other device where the TPM facilities could be employed, such as a cellphone. On a PC, either the LPC bus or the SPI bus is used to connect to the TPM chip.\nThe Trusted Computing Group (TCG) has certified TPM chips manufactured by Infineon Technologies, Nuvoton, and STMicroelectronics, having assigned TPM vendor IDs to Advanced Micro Devices, Atmel, Broadcom, IBM, Infineon, Intel, Lenovo, National Semiconductor, Nationz Technologies, Nuvoton, Qualcomm, Rockchip, Standard Microsystems Corporation, STMicroelectronics, Samsung, Sinosun, Texas Instruments, and Winbond.There are five different types of TPM 2.0 implementations (listed in order from most to least secure):\nDiscrete TPMs are dedicated chips that implement TPM functionality in their own tamper resistant semiconductor package. They are the most secure, certified to FIPS-140 with level 3 physical security resistance to attack versus routines implemented in software, and their packages are required to implement some tamper resistance. For example the TPM for the brake controller in a car is protected from hacking by sophisticated methods.\nIntegrated TPMs are part of another chip. While they use hardware that resists software bugs, they are not required to implement tamper resistance. Intel has integrated TPMs in some of its chipsets.\nFirmware TPMs (fTPMs) are firmware-based (e.g. UEFI) solutions that run in a CPU's trusted execution environment. Intel, AMD and Qualcomm have implemented firmware TPMs.\nHypervisor TPMs (vTPMs) are virtual TPMs provided by and rely on hypervisors, in an isolated execution environment that is hidden from the software running inside virtual machines to secure their code from the software in the virtual machines. They can provide a security level comparable to a firmware TPM. Google Cloud Platform has implemented vTPM.\nSoftware TPMs are software emulators of TPMs that run with no more protection than a regular program gets within an operating system. They depend entirely on the environment that they run in, so they provide no more security than what can be provided by the normal execution environment. They are useful for development purposes.The official TCG reference implementation of the TPM 2.0 Specification has been developed by Microsoft. It is licensed under BSD License and the source code is available on GitHub.\nMicrosoft provides a Visual Studio solution and Linux autotools build scripts.\nIn 2018, Intel open-sourced its Trusted Platform Module 2.0 (TPM2) software stack with support for Linux and Microsoft Windows. The source code is hosted on GitHub and licensed under BSD License.Infineon funded the development of an open source TPM middleware that complies with the Software Stack (TSS) Enhanced System API (ESAPI) specification of the TCG. It was developed by Fraunhofer Institute for Secure Information Technology (SIT).IBM's Software TPM 2.0 is an implementation of the TCG TPM 2.0 specification. It is based on the TPM specification Parts 3 and 4 and source code donated by Microsoft. It contains additional files to complete the implementation. The source code is hosted on SourceForge and GitHub and licensed under BSD License.\nIn 2022, AMD announced that under certain circumstances their fTPM implementation causes performance problems. A fix is available in form of a BIOS-Update.\n\n== TPM 1.2 versus TPM 2.0 ==\nWhile TPM 2.0 addresses many of the same use cases and has similar features, the details are different. TPM 2.0 is not backward compatible with TPM 1.2.\nThe TPM 2.0 policy authorization includes the 1.2 HMAC, locality, physical presence, and PCR. It adds authorization based on an asymmetric digital signature, indirection to another authorization secret, counters and time limits, NVRAM values, a particular command or command parameters, and physical presence. It permits the ANDing and ORing of these authorization primitives to construct complex authorization policies.\n\n== Attacks ==\nIn 2010, Christopher Tarnovsky presented an attack against TPMs at Black Hat Briefings, where he claimed to be able to extract secrets from a single TPM. He was able to do this after 6 months of work by inserting a probe and spying on an internal bus for the Infineon SLE 66 CL PC.In 2015, as part of the Snowden revelations, it was revealed that in 2010 a US CIA team claimed at an internal conference to have carried out a differential power analysis attack against TPMs that was able to extract secrets.In 2018, a design flaw in the TPM 2.0 specification for the static root of trust for measurement (SRTM) was reported (CVE-2018-6622). It allows an adversary to reset and forge platform configuration registers which are designed to securely hold measurements of software that are used for bootstrapping a computer. Fixing it requires hardware-specific firmware patches. An attacker abuses power interrupts and TPM state restores to trick TPM into thinking that it is running on non-tampered components.Main Trusted Boot (tboot) distributions before November 2017 are affected by a dynamic root of trust for measurement (DRTM) attack CVE-2017-16837, which affects computers running on Intel's Trusted eXecution Technology (TXT) for the boot-up routine.In case of physical access, computers with TPM are vulnerable to cold boot attacks as long as the system is on or can be booted without a passphrase from shutdown or hibernation, which is the default setup for Windows computers with BitLocker full disk encryption.In 2021, the Dolos Group showed an attack on a discrete TPM, where the TPM chip itself had some tamper resistance, but the other endpoints of its communication bus did not. They read a full-disk-encryption key as it was transmitted across the motherboard, and used it to decrypt the laptop's SSD.\n\n\n*** 2017 weak key generation controversy ***\n\nIn October 2017, it was reported that a code library developed by Infineon, which had been in widespread use in its TPMs, contained a vulnerability, known as ROCA, which generated weak RSA key pairs that allowed private keys to be inferred from public keys. As a result, all systems depending upon the privacy of such weak keys are vulnerable to compromise, such as identity theft or spoofing.Cryptosystems that store encryption keys directly in the TPM without blinding could be at particular risk to these types of attacks, as passwords and other factors would be meaningless if the attacks can extract encryption secrets.Infineon has released firmware updates for its TPMs to manufacturers who have used them.\n\n== Availability ==\nCurrently, a TPM is used by nearly all PC and notebook manufacturers.\n\n\n*** TPM ***\nThe TPM is implemented by several vendors:\n\nInfineon provides both TPM chips and TPM software, which are delivered as OEM versions with new computers as well as separately by Infineon for products with TPM technology which comply with TCG standards. For example, Infineon licensed TPM management software to Broadcom Corp. in 2004.\nMicrochip (formerly Atmel) manufactures TPM devices that it claims to be compliant to the Trusted Platform Module specification version 1.2 revision 116 and offered with several interfaces (LPC, SPI, and I2C), modes (FIPS 140-2 certified and standard mode), temperature grades (commercial and industrial), and packages (TSSOP and QFN). Their TPMs support PCs and embedded devices. They also provides TPM development kits to support integration of its TPM devices into various embedded designs.\nNuvoton Technology Corporation provides TPM devices for PC applications. Nuvoton also provides TPM devices for embedded systems and Internet of Things (IoT) applications via I2C and SPI host interfaces. Nuvoton's TPM complies with Common Criteria (CC) with assurance level EAL 4 augmented with ALC_FLR.1, AVA_VAN.4 and ALC_DVS.2, FIPS 140-2 level 2 with Physical Security and EMI/EMC level 3 and Trusted Computing Group Compliance requirements, all supported within a single device. TPMs produced by Winbond are now part of Nuvoton.\nSTMicroelectronics has provided TPMs for PC platforms and embedded systems since 2005. The product offering  includes discrete devices with several interfaces supporting Serial Peripheral Interface (SPI) and I\u00b2C and different qualification grades (consumer, industrial and automotive). The TPM products are Common Criteria (CC) certified EAL4+ augmented with ALC_FLR.1 and AVA_VAN.5, FIPS 140-2 level 2 certified with physical security level 3 and also Trusted Computing Group (TCG) certified.There are also hybrid types; for example, TPM can be integrated into an Ethernet controller, thus eliminating the need for a separate motherboard component.\n\n\n*** Field upgrade ***\nField upgrade is the TCG term for updating the TPM firmware. The update can be between TPM 1.2 and TPM 2.0, or between firmware versions. Some vendors limit the number of transitions between 1.2 and 2.0, and some restrict rollback to previous versions. Platform OEMs such as HP supply an upgrade tool.\nSince July 28, 2016, all new Microsoft device models, lines, or series (or updating the hardware configuration of an existing model, line, or series with a major update, such as CPU, graphic cards) implement, and enable by default TPM 2.0.\nWhile TPM 1.2 parts are discrete silicon components, which are typically soldered on the motherboard, TPM 2.0 is available as a discrete (dTPM) silicon component in a single semiconductor package, an integrated component incorporated in one or more semiconductor packages - alongside other logic units in the same package(s), and as a firmware (fTPM) based component running in a trusted execution environment (TEE) on a general purpose System-on-a-chip (SoC).\n\n\n*** Virtual TPM ***\nGoogle Compute Engine offers virtualized TPMs (vTPMs) as part of Google Cloud's Shielded VMs product.\nThe libtpms library provides software emulation of a Trusted Platform Module (TPM 1.2 and TPM 2.0). It targets the integration of TPM functionality into hypervisors, primarily into Qemu.\n\n\n*** Operating systems ***\nWindows 11 requires TPM 2.0 support as a minimum system requirement. On many systems TPM is disabled by default which requires changing settings in the computer's UEFI to enable it.\nThe Trusted Platform Module 2.0 (TPM 2.0) has been supported by the Linux kernel since version 3.20.\n\n\n*** Platforms ***\nGoogle includes TPMs in Chromebooks as part of their security model.\nOracle ships TPMs in their X- and T-Series Systems such as T3 or T4 series of servers. Support is included in Solaris 11.\nIn 2006, with the introduction of first Macintosh models with Intel processors, Apple started to ship Macs with TPM. Apple never provided an official driver, but there was a port under GPL available. Apple has not shipped a computer with TPM since 2006.\nIn 2011, Taiwanese manufacturer MSI launched its Windpad 110W tablet featuring an AMD CPU and Infineon Security Platform TPM, which ships with controlling software version 3.7. The chip is disabled by default but can be enabled with the included, pre-installed software.\n\n\n*** Virtualization ***\nVMware ESXi hypervisor has supported TPM since 4.x, and from 5.0 it is enabled by default.\nXen hypervisor has support of virtualized TPMs. Each guest gets its own unique, emulated, software TPM.\nKVM, combined with QEMU, has support for virtualized TPMs. As of 2012, it supports passing through the physical TPM chip to a single dedicated guest. QEMU 2.11 released in December 2017 also provides emulated TPMs to guests.\nVirtualBox has support for virtual TPM 1.2 and 2.0 devices starting with version 7.0 released in October 2022.\n\n\n*** Software ***\nMicrosoft operating systems Windows Vista and later use the chip in conjunction with the included disk encryption component named BitLocker. Microsoft had announced that from January 1, 2015, all computers will have to be equipped with a TPM 2.0 module in order to pass Windows 8.1 hardware certification. However, in a December 2014 review of the Windows Certification Program this was instead made an optional requirement. However, TPM 2.0 is required for connected standby systems. Virtual machines running on Hyper-V can have their own virtual TPM module starting with Windows 10 1511 and Windows Server 2016. Microsoft Windows includes two TPM related commands: tpmtool, a utility that can be used to retrieve information about the TPM, and tpmvscmgr, a command-line tool that allows creating and deleting TPM virtual smart cards on a computer.\n\n== Endorsement keys ==\nTPM endorsement keys (EKs) are asymmetric key pairs unique to each TPM. They use the RSA and ECC algorithms. The TPM manufacturer usually provisions endorsement key certificates in TPM non-volatile memory. The certificates assert that the TPM is authentic. Starting with TPM 2.0, the certificates are in X.509 DER format.\nThese manufacturers typically provide their certificate authority root (and sometimes intermediate) certificates on their web sites.\n\nAMD\nInfineon\nIntel\nNationZ \nNuvoton\nST Micro\n\n== TPM software libraries ==\nTo utilize a TPM, the user needs a software library that communicates with the TPM and provides a friendlier API than the raw TPM communication. Currently, there are several such open-source TPM 2.0 libraries. Some of them also support TPM 1.2, but mostly TPM 1.2 chips are now deprecated and modern development is focused on TPM 2.0.\nTypically, a TPM library provides an API with one-to-one mappings to TPM commands. The TCG specification calls this layer the System API(SAPI). This way the user has more control over the TPM operations, however the complexity is high. To hide some of the complexity most libraries also offer simpler ways to invoke complex TPM operations. The TCG specification call these two layers Enhanced System API(ESAPI) and Feature API(FAPI).\nThere is currently only one stack that follows the TCG specification. All the other available open-source TPM libraries use their own form of richer API.\n\n(*) There is a separate project called \"CHARRA\" by Fraunhofer that uses the tpm2-tss library for Remote Attestation. The other stacks have accompanying attestation servers or directly include examples for attestation. IBM offer their open-source Remote Attestation Server called \"IBM ACS\" on SourceForge and Google have \"Go-Attestation\" available on GitHub, while \"wolfTPM\" offers time and local attestation examples directly in its open-source code, also on GitHub.\n(**) There is an application note about an example project for the AURIX 32-bit SoC using the tpm2-tss library.\n(***) Requires additional libraries (dotnet) to run on Linux.\nThese TPM libraries are sometimes also called TPM stacks, because they provide the interface for the developer or user to interact with the TPM. As seen from the table, the TPM stacks abstract the operating system and transport layer, so the user could migrate one application between platforms. For example, by using TPM stack API the user would interact the same way with a TPM, regardless if the physical chip is connected over SPI, I2C or LPC interface to the Host system.\n\nQuestion: How does TPM aid in platform integrity for Microsoft Office 365 licensing and Outlook Exchange?\n\nAnswer:",
    "context": "",
    "output": "TPM can be used for platform integrity in Microsoft Office 365 licensing and Outlook Exchange by ensuring that the boot process starts from a trusted combination of hardware and software and continues until the operating system has fully booted and applications are running.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does TPM aid in platform integrity for Microsoft Office 365 licensing and Outlook Exchange?",
      "answer": "TPM can be used for platform integrity in Microsoft Office 365 licensing and Outlook Exchange by ensuring that the boot process starts from a trusted combination of hardware and software and continues until the operating system has fully booted and applications are running.",
      "context": "Trusted Platform Module\n\n==Introduction==\nTrusted Platform Module (TPM, also known as ISO/IEC 11889) is an international standard for a secure cryptoprocessor, a dedicated microcontroller designed to secure hardware through integrated cryptographic keys. The term can also refer to a chip conforming to the standard.\nOne of Windows 11's system requirements is TPM 2.0. Microsoft has stated that this is to help increase security against firmware attacks.\n\n\n\n== Overview ==\nTrusted Platform Module provides\n\nA hardware random number generator\nFacilities for the secure generation of cryptographic keys for limited uses.\nRemote attestation: Creates a nearly unforgeable hash key summary of the hardware and software configuration.  One could use the hash to verify that the hardware and software have not been changed. The software in charge of hashing the setup determines the extent of the summary.\nBinding: Encrypts data using the TPM bind key, a unique RSA key descended from a storage key. Computers that incorporate a TPM can create cryptographic keys and encrypt them so that they can only be decrypted by the TPM. This process, often called wrapping or binding a key, can help protect the key from disclosure. Each TPM has a master wrapping key, called the storage root key, which is stored within the TPM itself. User-level RSA key containers are stored with the Windows user profile for a particular user and can be used to encrypt and decrypt information for applications that run under that specific user identity.\nSealing: Similar to binding, but in addition, specifies the TPM state for the data to be decrypted (unsealed).\nOther Trusted Computing functions for the data to be decrypted (unsealed).Computer programs can use a TPM to authenticate hardware devices, since each TPM chip has a unique and secret Endorsement Key (EK) burned in as it is produced. Security embedded in hardware provides more protection than a software-only solution.  Its use is restricted in some countries.\n\n== Uses ==\n\n\n*** Platform integrity ***\nThe primary scope of TPM is to ensure the integrity of a platform. In this context, \"integrity\" means \"behave as intended\", and a \"platform\" is any computer device regardless of its operating system. This is to ensure that the boot process starts from a trusted combination of hardware and software, and continues until the operating system has fully booted and applications are running.\nWhen TPM is used, the firmware and the operating system are responsible for ensuring integrity.\nFor example, Unified Extensible Firmware Interface (UEFI) can use TPM to form a root of trust: The TPM contains several Platform Configuration Registers (PCRs) that allow secure storage and reporting of security-relevant metrics. These metrics can be used to detect changes to previous configurations and decide how to proceed. Examples of such use can be found in Linux Unified Key Setup (LUKS), BitLocker and PrivateCore vCage memory encryption. (See below.)\nAnother example of platform integrity via TPM is in the use of Microsoft Office 365 licensing and Outlook Exchange.An example of TPM use for platform integrity is the Trusted Execution Technology (TXT), which creates a chain of trust. It could remotely attest that a computer is using the specified hardware and software.\n\n\n*** Disk encryption ***\nFull disk encryption utilities, such as dm-crypt and BitLocker, can use this technology to protect the keys used to encrypt the computer's storage devices and provide integrity authentication for a trusted boot pathway that includes firmware and boot sector.\n\n\n*** Other uses and concerns ***\nAny application can use a TPM chip for:\n\nDigital rights management (DRM)\nWindows Defender\nWindows Domain logon\nProtection and enforcement of software licenses\nPrevention of cheating in online gamesOther uses exist, some of which give rise to privacy concerns. The \"physical presence\" feature of TPM addresses some of these concerns by requiring BIOS-level confirmation for operations such as activating, deactivating, clearing or changing ownership of TPM by someone who is physically present at the console of the machine.\n\n\n*** By organizations ***\nThe United States Department of Defense (DoD) specifies that \"new computer assets (e.g., server, desktop, laptop, thin client, tablet, smartphone, personal digital assistant, mobile phone) procured to support DoD will include a TPM version 1.2 or higher where required by Defense Information Systems Agency (DISA) Security Technical Implementation Guides (STIGs) and where such technology is available.\" DoD anticipates that TPM is to be used for device identification, authentication, encryption, and device integrity verification.\n\n== TPM implementations ==\n\nIn 2006, new laptops began being sold with a built-in TPM chip. In the future, this concept could be co-located on an existing motherboard chip in computers, or any other device where the TPM facilities could be employed, such as a cellphone. On a PC, either the LPC bus or the SPI bus is used to connect to the TPM chip.\nThe Trusted Computing Group (TCG) has certified TPM chips manufactured by Infineon Technologies, Nuvoton, and STMicroelectronics, having assigned TPM vendor IDs to Advanced Micro Devices, Atmel, Broadcom, IBM, Infineon, Intel, Lenovo, National Semiconductor, Nationz Technologies, Nuvoton, Qualcomm, Rockchip, Standard Microsystems Corporation, STMicroelectronics, Samsung, Sinosun, Texas Instruments, and Winbond.There are five different types of TPM 2.0 implementations (listed in order from most to least secure):\nDiscrete TPMs are dedicated chips that implement TPM functionality in their own tamper resistant semiconductor package. They are the most secure, certified to FIPS-140 with level 3 physical security resistance to attack versus routines implemented in software, and their packages are required to implement some tamper resistance. For example the TPM for the brake controller in a car is protected from hacking by sophisticated methods.\nIntegrated TPMs are part of another chip. While they use hardware that resists software bugs, they are not required to implement tamper resistance. Intel has integrated TPMs in some of its chipsets.\nFirmware TPMs (fTPMs) are firmware-based (e.g. UEFI) solutions that run in a CPU's trusted execution environment. Intel, AMD and Qualcomm have implemented firmware TPMs.\nHypervisor TPMs (vTPMs) are virtual TPMs provided by and rely on hypervisors, in an isolated execution environment that is hidden from the software running inside virtual machines to secure their code from the software in the virtual machines. They can provide a security level comparable to a firmware TPM. Google Cloud Platform has implemented vTPM.\nSoftware TPMs are software emulators of TPMs that run with no more protection than a regular program gets within an operating system. They depend entirely on the environment that they run in, so they provide no more security than what can be provided by the normal execution environment. They are useful for development purposes.The official TCG reference implementation of the TPM 2.0 Specification has been developed by Microsoft. It is licensed under BSD License and the source code is available on GitHub.\nMicrosoft provides a Visual Studio solution and Linux autotools build scripts.\nIn 2018, Intel open-sourced its Trusted Platform Module 2.0 (TPM2) software stack with support for Linux and Microsoft Windows. The source code is hosted on GitHub and licensed under BSD License.Infineon funded the development of an open source TPM middleware that complies with the Software Stack (TSS) Enhanced System API (ESAPI) specification of the TCG. It was developed by Fraunhofer Institute for Secure Information Technology (SIT).IBM's Software TPM 2.0 is an implementation of the TCG TPM 2.0 specification. It is based on the TPM specification Parts 3 and 4 and source code donated by Microsoft. It contains additional files to complete the implementation. The source code is hosted on SourceForge and GitHub and licensed under BSD License.\nIn 2022, AMD announced that under certain circumstances their fTPM implementation causes performance problems. A fix is available in form of a BIOS-Update.\n\n== TPM 1.2 versus TPM 2.0 ==\nWhile TPM 2.0 addresses many of the same use cases and has similar features, the details are different. TPM 2.0 is not backward compatible with TPM 1.2.\nThe TPM 2.0 policy authorization includes the 1.2 HMAC, locality, physical presence, and PCR. It adds authorization based on an asymmetric digital signature, indirection to another authorization secret, counters and time limits, NVRAM values, a particular command or command parameters, and physical presence. It permits the ANDing and ORing of these authorization primitives to construct complex authorization policies.\n\n== Attacks ==\nIn 2010, Christopher Tarnovsky presented an attack against TPMs at Black Hat Briefings, where he claimed to be able to extract secrets from a single TPM. He was able to do this after 6 months of work by inserting a probe and spying on an internal bus for the Infineon SLE 66 CL PC.In 2015, as part of the Snowden revelations, it was revealed that in 2010 a US CIA team claimed at an internal conference to have carried out a differential power analysis attack against TPMs that was able to extract secrets.In 2018, a design flaw in the TPM 2.0 specification for the static root of trust for measurement (SRTM) was reported (CVE-2018-6622). It allows an adversary to reset and forge platform configuration registers which are designed to securely hold measurements of software that are used for bootstrapping a computer. Fixing it requires hardware-specific firmware patches. An attacker abuses power interrupts and TPM state restores to trick TPM into thinking that it is running on non-tampered components.Main Trusted Boot (tboot) distributions before November 2017 are affected by a dynamic root of trust for measurement (DRTM) attack CVE-2017-16837, which affects computers running on Intel's Trusted eXecution Technology (TXT) for the boot-up routine.In case of physical access, computers with TPM are vulnerable to cold boot attacks as long as the system is on or can be booted without a passphrase from shutdown or hibernation, which is the default setup for Windows computers with BitLocker full disk encryption.In 2021, the Dolos Group showed an attack on a discrete TPM, where the TPM chip itself had some tamper resistance, but the other endpoints of its communication bus did not. They read a full-disk-encryption key as it was transmitted across the motherboard, and used it to decrypt the laptop's SSD.\n\n\n*** 2017 weak key generation controversy ***\n\nIn October 2017, it was reported that a code library developed by Infineon, which had been in widespread use in its TPMs, contained a vulnerability, known as ROCA, which generated weak RSA key pairs that allowed private keys to be inferred from public keys. As a result, all systems depending upon the privacy of such weak keys are vulnerable to compromise, such as identity theft or spoofing.Cryptosystems that store encryption keys directly in the TPM without blinding could be at particular risk to these types of attacks, as passwords and other factors would be meaningless if the attacks can extract encryption secrets.Infineon has released firmware updates for its TPMs to manufacturers who have used them.\n\n== Availability ==\nCurrently, a TPM is used by nearly all PC and notebook manufacturers.\n\n\n*** TPM ***\nThe TPM is implemented by several vendors:\n\nInfineon provides both TPM chips and TPM software, which are delivered as OEM versions with new computers as well as separately by Infineon for products with TPM technology which comply with TCG standards. For example, Infineon licensed TPM management software to Broadcom Corp. in 2004.\nMicrochip (formerly Atmel) manufactures TPM devices that it claims to be compliant to the Trusted Platform Module specification version 1.2 revision 116 and offered with several interfaces (LPC, SPI, and I2C), modes (FIPS 140-2 certified and standard mode), temperature grades (commercial and industrial), and packages (TSSOP and QFN). Their TPMs support PCs and embedded devices. They also provides TPM development kits to support integration of its TPM devices into various embedded designs.\nNuvoton Technology Corporation provides TPM devices for PC applications. Nuvoton also provides TPM devices for embedded systems and Internet of Things (IoT) applications via I2C and SPI host interfaces. Nuvoton's TPM complies with Common Criteria (CC) with assurance level EAL 4 augmented with ALC_FLR.1, AVA_VAN.4 and ALC_DVS.2, FIPS 140-2 level 2 with Physical Security and EMI/EMC level 3 and Trusted Computing Group Compliance requirements, all supported within a single device. TPMs produced by Winbond are now part of Nuvoton.\nSTMicroelectronics has provided TPMs for PC platforms and embedded systems since 2005. The product offering  includes discrete devices with several interfaces supporting Serial Peripheral Interface (SPI) and I\u00b2C and different qualification grades (consumer, industrial and automotive). The TPM products are Common Criteria (CC) certified EAL4+ augmented with ALC_FLR.1 and AVA_VAN.5, FIPS 140-2 level 2 certified with physical security level 3 and also Trusted Computing Group (TCG) certified.There are also hybrid types; for example, TPM can be integrated into an Ethernet controller, thus eliminating the need for a separate motherboard component.\n\n\n*** Field upgrade ***\nField upgrade is the TCG term for updating the TPM firmware. The update can be between TPM 1.2 and TPM 2.0, or between firmware versions. Some vendors limit the number of transitions between 1.2 and 2.0, and some restrict rollback to previous versions. Platform OEMs such as HP supply an upgrade tool.\nSince July 28, 2016, all new Microsoft device models, lines, or series (or updating the hardware configuration of an existing model, line, or series with a major update, such as CPU, graphic cards) implement, and enable by default TPM 2.0.\nWhile TPM 1.2 parts are discrete silicon components, which are typically soldered on the motherboard, TPM 2.0 is available as a discrete (dTPM) silicon component in a single semiconductor package, an integrated component incorporated in one or more semiconductor packages - alongside other logic units in the same package(s), and as a firmware (fTPM) based component running in a trusted execution environment (TEE) on a general purpose System-on-a-chip (SoC).\n\n\n*** Virtual TPM ***\nGoogle Compute Engine offers virtualized TPMs (vTPMs) as part of Google Cloud's Shielded VMs product.\nThe libtpms library provides software emulation of a Trusted Platform Module (TPM 1.2 and TPM 2.0). It targets the integration of TPM functionality into hypervisors, primarily into Qemu.\n\n\n*** Operating systems ***\nWindows 11 requires TPM 2.0 support as a minimum system requirement. On many systems TPM is disabled by default which requires changing settings in the computer's UEFI to enable it.\nThe Trusted Platform Module 2.0 (TPM 2.0) has been supported by the Linux kernel since version 3.20.\n\n\n*** Platforms ***\nGoogle includes TPMs in Chromebooks as part of their security model.\nOracle ships TPMs in their X- and T-Series Systems such as T3 or T4 series of servers. Support is included in Solaris 11.\nIn 2006, with the introduction of first Macintosh models with Intel processors, Apple started to ship Macs with TPM. Apple never provided an official driver, but there was a port under GPL available. Apple has not shipped a computer with TPM since 2006.\nIn 2011, Taiwanese manufacturer MSI launched its Windpad 110W tablet featuring an AMD CPU and Infineon Security Platform TPM, which ships with controlling software version 3.7. The chip is disabled by default but can be enabled with the included, pre-installed software.\n\n\n*** Virtualization ***\nVMware ESXi hypervisor has supported TPM since 4.x, and from 5.0 it is enabled by default.\nXen hypervisor has support of virtualized TPMs. Each guest gets its own unique, emulated, software TPM.\nKVM, combined with QEMU, has support for virtualized TPMs. As of 2012, it supports passing through the physical TPM chip to a single dedicated guest. QEMU 2.11 released in December 2017 also provides emulated TPMs to guests.\nVirtualBox has support for virtual TPM 1.2 and 2.0 devices starting with version 7.0 released in October 2022.\n\n\n*** Software ***\nMicrosoft operating systems Windows Vista and later use the chip in conjunction with the included disk encryption component named BitLocker. Microsoft had announced that from January 1, 2015, all computers will have to be equipped with a TPM 2.0 module in order to pass Windows 8.1 hardware certification. However, in a December 2014 review of the Windows Certification Program this was instead made an optional requirement. However, TPM 2.0 is required for connected standby systems. Virtual machines running on Hyper-V can have their own virtual TPM module starting with Windows 10 1511 and Windows Server 2016. Microsoft Windows includes two TPM related commands: tpmtool, a utility that can be used to retrieve information about the TPM, and tpmvscmgr, a command-line tool that allows creating and deleting TPM virtual smart cards on a computer.\n\n== Endorsement keys ==\nTPM endorsement keys (EKs) are asymmetric key pairs unique to each TPM. They use the RSA and ECC algorithms. The TPM manufacturer usually provisions endorsement key certificates in TPM non-volatile memory. The certificates assert that the TPM is authentic. Starting with TPM 2.0, the certificates are in X.509 DER format.\nThese manufacturers typically provide their certificate authority root (and sometimes intermediate) certificates on their web sites.\n\nAMD\nInfineon\nIntel\nNationZ \nNuvoton\nST Micro\n\n== TPM software libraries ==\nTo utilize a TPM, the user needs a software library that communicates with the TPM and provides a friendlier API than the raw TPM communication. Currently, there are several such open-source TPM 2.0 libraries. Some of them also support TPM 1.2, but mostly TPM 1.2 chips are now deprecated and modern development is focused on TPM 2.0.\nTypically, a TPM library provides an API with one-to-one mappings to TPM commands. The TCG specification calls this layer the System API(SAPI). This way the user has more control over the TPM operations, however the complexity is high. To hide some of the complexity most libraries also offer simpler ways to invoke complex TPM operations. The TCG specification call these two layers Enhanced System API(ESAPI) and Feature API(FAPI).\nThere is currently only one stack that follows the TCG specification. All the other available open-source TPM libraries use their own form of richer API.\n\n(*) There is a separate project called \"CHARRA\" by Fraunhofer that uses the tpm2-tss library for Remote Attestation. The other stacks have accompanying attestation servers or directly include examples for attestation. IBM offer their open-source Remote Attestation Server called \"IBM ACS\" on SourceForge and Google have \"Go-Attestation\" available on GitHub, while \"wolfTPM\" offers time and local attestation examples directly in its open-source code, also on GitHub.\n(**) There is an application note about an example project for the AURIX 32-bit SoC using the tpm2-tss library.\n(***) Requires additional libraries (dotnet) to run on Linux.\nThese TPM libraries are sometimes also called TPM stacks, because they provide the interface for the developer or user to interact with the TPM. As seen from the table, the TPM stacks abstract the operating system and transport layer, so the user could migrate one application between platforms. For example, by using TPM stack API the user would interact the same way with a TPM, regardless if the physical chip is connected over SPI, I2C or LPC interface to the Host system."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the significance of kernel randomization in OpenBSD and how does it improve system security?",
    "context": "",
    "output": "Kernel randomization in OpenBSD involves modifying the linker so that on every boot, the kernel is relinked, as well as all other randomizations. This ensures that every new kernel is unique and the relative offsets between functions and data are unique, making it harder for attackers to exploit known kernel vulnerabilities.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the significance of kernel randomization in OpenBSD and how does it improve system security?",
      "answer": "Kernel randomization in OpenBSD involves modifying the linker so that on every boot, the kernel is relinked, as well as all other randomizations. This ensures that every new kernel is unique and the relative offsets between functions and data are unique, making it harder for attackers to exploit known kernel vulnerabilities."
    }
  },
  {
    "instruction": "Write an answer to the following question: What happens during the association request frame process that can reveal the SSID?",
    "context": "",
    "output": "During the association request frame process, the SSID is transmitted between the computer and the access point. Sniffing programs can intercept and analyze these frames to detect cloaked networks and their SSIDs.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What happens during the association request frame process that can reveal the SSID?",
      "answer": "During the association request frame process, the SSID is transmitted between the computer and the access point. Sniffing programs can intercept and analyze these frames to detect cloaked networks and their SSIDs."
    }
  },
  {
    "instruction": "Context: SXAL/MBAL\n\n==Introduction==\nIn cryptography, SXAL (substitution xor algorithm, sometimes called SXAL8) is a block cipher designed in 1993 by Yokohama-based Laurel Intelligent Systems. It is normally used in a special mode of operation called MBAL (multi-block algorithm). SXAL/MBAL has been used for encryption in a number of Japanese PC cards and smart cards.\nSXAL is an 8-round substitution\u2013permutation network with block size and key size of 64 bits each. All operations are byte-oriented. The algorithm uses a single 8\u00d78-bit S-box K, designed so that both K(X) and X XOR K(X) are injective functions. In each round, the bytes of the block are first permuted. Then each byte is XORed with a key byte and an earlier ciphertext byte, processed through the S-box, and XORed with the previous plaintext byte.\nThe key schedule is rather complex, processing the key with SXAL itself, beginning with a null key and using permuted intermediate results as later keys.\n\n== MBAL ==\nMBAL is an encryption algorithm built using SXAL that can be applied to messages any number of bytes in length (at least 8). It uses two 64-bit extended keys for key whitening on the first 64 bits. The algorithm consists of 9 steps:\n\nPre-whitening\nFm: An expanded version of SXAL applied to the entire message\nSXAL the block consisting of the first 4 and last 4 bytes\nReverse the byte order of the entire message\nFm\nReverse\nSXAL the ends\nFm\nPost-whiteningMBAL has been shown to be susceptible to both differential cryptanalysis and linear cryptanalysis.\nAnswer this question: How does SXAL differ from other block ciphers in terms of its operations?",
    "context": "",
    "output": "SXAL is a block cipher that uses byte-oriented operations, as opposed to bit-oriented operations used in other block ciphers.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does SXAL differ from other block ciphers in terms of its operations?",
      "answer": "SXAL is a block cipher that uses byte-oriented operations, as opposed to bit-oriented operations used in other block ciphers.",
      "context": "SXAL/MBAL\n\n==Introduction==\nIn cryptography, SXAL (substitution xor algorithm, sometimes called SXAL8) is a block cipher designed in 1993 by Yokohama-based Laurel Intelligent Systems. It is normally used in a special mode of operation called MBAL (multi-block algorithm). SXAL/MBAL has been used for encryption in a number of Japanese PC cards and smart cards.\nSXAL is an 8-round substitution\u2013permutation network with block size and key size of 64 bits each. All operations are byte-oriented. The algorithm uses a single 8\u00d78-bit S-box K, designed so that both K(X) and X XOR K(X) are injective functions. In each round, the bytes of the block are first permuted. Then each byte is XORed with a key byte and an earlier ciphertext byte, processed through the S-box, and XORed with the previous plaintext byte.\nThe key schedule is rather complex, processing the key with SXAL itself, beginning with a null key and using permuted intermediate results as later keys.\n\n== MBAL ==\nMBAL is an encryption algorithm built using SXAL that can be applied to messages any number of bytes in length (at least 8). It uses two 64-bit extended keys for key whitening on the first 64 bits. The algorithm consists of 9 steps:\n\nPre-whitening\nFm: An expanded version of SXAL applied to the entire message\nSXAL the block consisting of the first 4 and last 4 bytes\nReverse the byte order of the entire message\nFm\nReverse\nSXAL the ends\nFm\nPost-whiteningMBAL has been shown to be susceptible to both differential cryptanalysis and linear cryptanalysis."
    }
  },
  {
    "instruction": "Write an answer to the following question: How did the OSVDB handle new information added to an existing entry?",
    "context": "",
    "output": "New information added to an existing entry in the OSVDB was reviewed and approved by core volunteers called \"moderators\", and was then made available to anyone browsing the site.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How did the OSVDB handle new information added to an existing entry?",
      "answer": "New information added to an existing entry in the OSVDB was reviewed and approved by core volunteers called \"moderators\", and was then made available to anyone browsing the site."
    }
  },
  {
    "instruction": "MediaDefender\n\n==Introduction==\nMediaDefender, Inc. (now Peer Media Technologies) was a company that fought copyright infringement that offered services designed to prevent alleged copyright infringement using peer-to-peer distribution. They used unusual tactics such as flooding peer-to-peer networks with decoy files that tie up users' computers and bandwidth. MediaDefender was based in Los Angeles, California in the United States. As of March 2007, the company had approximately 60 employees and used 2,000 servers hosted in California with contracts for 9 Gbit/s of bandwidth.These types of organizations are being hired to attempt to stymie peer-to-peer (P2P) traders through a variety of methods including posting fake files online and recording individuals who contribute copyrighted material, but also marketing to individuals using P2P networks. Clients include Universal Pictures, 20th Century Fox, Virgin Records, HBO, Paramount Pictures, and BMG. On August 1, 2005, the digital media entertainment company ARTISTdirect announced that it had acquired MediaDefender for $42.5 million in cash.\nIn May 2008, MediaDefender performed a distributed-denial-of-service attack on Revision3, despite the fact that they were not hosting unauthorized materials. Jim Louderback, Revision3's CEO, charged that these attacks violated the Economic Espionage Act and the Computer Fraud and Abuse Act. As of May 2008, the Federal Bureau of Investigation was investigating the incident.In August 2009, ARTISTdirect restructured MediaDefender and MediaSentry, creating Peer Media Technologies.\n\n== Miivi.com ==\nIn February 2007, MediaDefender launched a video sharing site called Miivi.com. On July 4, 2007, file-sharing news site TorrentFreak alleged that Miivi.com was created to trap uploaders of copyrighted content. The site's origins were discovered by a blogger who looked up Miivi.com domain registration information.After the allegation was re-posted throughout the blogosphere, Miivi.com was shut down on July 4, 2007. In an interview with Ars Technica, chief executive Randy Saaf stated that \"MediaDefender was working on an internal project that involved video and didn't realize that people would be trying to go to it and so we didn't password-protect the site\". MediaDefender blamed file-sharing groups such as The Pirate Bay for starting the story. Following MediaDefender's subsequent email leak, TorrentFreak alleged that MediaDefender's statement was revealed to be a deliberate falsehood. Saaf denied that MiiVi was \"a devious product\" and that the company aimed to entrap users, stating only that it was part of MediaDefender's \"trade secrets.\"The MPAA denied any involvement with MediaDefender. On September 14, 2007, internal emails from MediaDefender were leaked on to BitTorrent file sharing networks, which contradicted MediaDefender's claims of MiiVi being an \"internal test site,\" revealing additional detailed information about the website and that the site was closed when the connection between it and MediaDefender became public knowledge. It was scheduled to be re-launched as www.viide.com, but has not yet been opened up to the public.\n\n== Leaked information ==\nBeginning on September 14, 2007, MediaDefender experienced a security breach caused by a group of hackers led by high school student \"Ethan\". This group called themselves MediaDefender-Defenders. According to an SEC filing, this ultimately cost parent company ARTISTdirect at least $825,000. The breach included emails, a phone conversation, and a number of internal anti-infringement tools, including some source code.\n\n\n*** Leaked e-mails ***\nOn September 14, 2007, 6,621 of the company's internal e-mails were leaked, containing information contradicting previous statements and details of strategies intended to deceive copyright infringers. The emails link MediaDefender to projects that management previously denied involvement in. The Associated Press and other media outlets suggest that the leak may confirm speculation that MiiVi.com was an anti-copyright infringement \"honeypot\" site. One e-mail suggests using the MiiVi client program to turn users' PCs into drones for MediaDefender's eMule spoofing activities. The leaked e-mails discuss responses to unexpected and negative press, and expose upcoming projects, problems in and around the office, Domino's pizza orders, and other personal information about employees. Beyond strategic information, the leak also exposed login information for FTP and MySQL servers, making available a large library of MP3 files likely including artists represented by MediaDefender's clients. The emails also revealed that MediaDefender probably was negotiating with the New York Attorney General's office to allow them access to information about users accessing pornographic material. As of September 15, 2007, there had been no official response from the company. However, evidence exists that MediaDefender had been employing both legal and illegal actions to remove copies of the leaked emails from their respective hosting sites. In addition to the usual cease-and-desist letters from their legal department, IP addresses that are owned by MediaDefender were found to have been used in denial-of-service attacks against sites hosting the leaked emails.The e-mails also revealed direction by MediaDefender founder Randy Saaf to have developer Ben Ebert attempt to eliminate the information about MiiVi from MediaDefender's English Wikipedia entry. Ebert responds in an email on the same day saying, \"I will attempt to get all referenes [sic] to miivi removed from wiki. I should easily be able to get It contested. We'll see if I can get rid of it.\"\n\n\n*** Leaked phone conversation ***\nOn September 16, 2007, MediaDefender-Defenders released a 25-minute excerpt of a phone conversation between the New York Attorney General's office and MediaDefender as a torrent on The Pirate Bay. MediaDefender-Defenders claims in information released with the phone conversation that they have infiltrated the \"internals\" of the company.\n\n\n*** Leaked source code ***\nOn September 20, 2007, MediaDefender-Defenders released the source code of TrapperKeeper, MediaDefender's decoy systems on The Pirate Bay. A large chunk of MediaDefender's software was available by Bittorrent.\n\n== Revision3 controversy ==\nRevision3 is an Internet television network which distributes video content legally through various means, including the BitTorrent protocol. During the Memorial Day weekend in 2008, Revision3 came under a Denial of Service attack originating from MediaDefender IP addresses. The attack left the company's service inaccessible until mid-Tuesday the following week. Revision3 CEO Jim Louderback accused MediaDefender of injecting its decoy files into Revision3's BitTorrent service through a vulnerability, then automatically perpetrating the attack after Revision3 increased security.Randy Saaf defended MediaDefender's actions by stating \"Our systems were targeting a tracker not even knowing it was Revision3's tracker\", adding that the denial-of-service attack resulted when \"Revision3 changed some configurations\" to their BitTorrent tracker.\n\nWhat was the origin of the allegations against Miivi.com and how did MediaDefender respond?",
    "context": "",
    "output": "A: The allegations against Miivi.com were discovered through domain registration information by a blogger. MediaDefender initially denied the allegations, stating that the site was an internal test site, but later closed it when the connection to MediaDefender became public knowledge.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was the origin of the allegations against Miivi.com and how did MediaDefender respond?",
      "answer": "The allegations against Miivi.com were discovered through domain registration information by a blogger. MediaDefender initially denied the allegations, stating that the site was an internal test site, but later closed it when the connection to MediaDefender became public knowledge.",
      "context": "MediaDefender\n\n==Introduction==\nMediaDefender, Inc. (now Peer Media Technologies) was a company that fought copyright infringement that offered services designed to prevent alleged copyright infringement using peer-to-peer distribution. They used unusual tactics such as flooding peer-to-peer networks with decoy files that tie up users' computers and bandwidth. MediaDefender was based in Los Angeles, California in the United States. As of March 2007, the company had approximately 60 employees and used 2,000 servers hosted in California with contracts for 9 Gbit/s of bandwidth.These types of organizations are being hired to attempt to stymie peer-to-peer (P2P) traders through a variety of methods including posting fake files online and recording individuals who contribute copyrighted material, but also marketing to individuals using P2P networks. Clients include Universal Pictures, 20th Century Fox, Virgin Records, HBO, Paramount Pictures, and BMG. On August 1, 2005, the digital media entertainment company ARTISTdirect announced that it had acquired MediaDefender for $42.5 million in cash.\nIn May 2008, MediaDefender performed a distributed-denial-of-service attack on Revision3, despite the fact that they were not hosting unauthorized materials. Jim Louderback, Revision3's CEO, charged that these attacks violated the Economic Espionage Act and the Computer Fraud and Abuse Act. As of May 2008, the Federal Bureau of Investigation was investigating the incident.In August 2009, ARTISTdirect restructured MediaDefender and MediaSentry, creating Peer Media Technologies.\n\n== Miivi.com ==\nIn February 2007, MediaDefender launched a video sharing site called Miivi.com. On July 4, 2007, file-sharing news site TorrentFreak alleged that Miivi.com was created to trap uploaders of copyrighted content. The site's origins were discovered by a blogger who looked up Miivi.com domain registration information.After the allegation was re-posted throughout the blogosphere, Miivi.com was shut down on July 4, 2007. In an interview with Ars Technica, chief executive Randy Saaf stated that \"MediaDefender was working on an internal project that involved video and didn't realize that people would be trying to go to it and so we didn't password-protect the site\". MediaDefender blamed file-sharing groups such as The Pirate Bay for starting the story. Following MediaDefender's subsequent email leak, TorrentFreak alleged that MediaDefender's statement was revealed to be a deliberate falsehood. Saaf denied that MiiVi was \"a devious product\" and that the company aimed to entrap users, stating only that it was part of MediaDefender's \"trade secrets.\"The MPAA denied any involvement with MediaDefender. On September 14, 2007, internal emails from MediaDefender were leaked on to BitTorrent file sharing networks, which contradicted MediaDefender's claims of MiiVi being an \"internal test site,\" revealing additional detailed information about the website and that the site was closed when the connection between it and MediaDefender became public knowledge. It was scheduled to be re-launched as www.viide.com, but has not yet been opened up to the public.\n\n== Leaked information ==\nBeginning on September 14, 2007, MediaDefender experienced a security breach caused by a group of hackers led by high school student \"Ethan\". This group called themselves MediaDefender-Defenders. According to an SEC filing, this ultimately cost parent company ARTISTdirect at least $825,000. The breach included emails, a phone conversation, and a number of internal anti-infringement tools, including some source code.\n\n\n*** Leaked e-mails ***\nOn September 14, 2007, 6,621 of the company's internal e-mails were leaked, containing information contradicting previous statements and details of strategies intended to deceive copyright infringers. The emails link MediaDefender to projects that management previously denied involvement in. The Associated Press and other media outlets suggest that the leak may confirm speculation that MiiVi.com was an anti-copyright infringement \"honeypot\" site. One e-mail suggests using the MiiVi client program to turn users' PCs into drones for MediaDefender's eMule spoofing activities. The leaked e-mails discuss responses to unexpected and negative press, and expose upcoming projects, problems in and around the office, Domino's pizza orders, and other personal information about employees. Beyond strategic information, the leak also exposed login information for FTP and MySQL servers, making available a large library of MP3 files likely including artists represented by MediaDefender's clients. The emails also revealed that MediaDefender probably was negotiating with the New York Attorney General's office to allow them access to information about users accessing pornographic material. As of September 15, 2007, there had been no official response from the company. However, evidence exists that MediaDefender had been employing both legal and illegal actions to remove copies of the leaked emails from their respective hosting sites. In addition to the usual cease-and-desist letters from their legal department, IP addresses that are owned by MediaDefender were found to have been used in denial-of-service attacks against sites hosting the leaked emails.The e-mails also revealed direction by MediaDefender founder Randy Saaf to have developer Ben Ebert attempt to eliminate the information about MiiVi from MediaDefender's English Wikipedia entry. Ebert responds in an email on the same day saying, \"I will attempt to get all referenes [sic] to miivi removed from wiki. I should easily be able to get It contested. We'll see if I can get rid of it.\"\n\n\n*** Leaked phone conversation ***\nOn September 16, 2007, MediaDefender-Defenders released a 25-minute excerpt of a phone conversation between the New York Attorney General's office and MediaDefender as a torrent on The Pirate Bay. MediaDefender-Defenders claims in information released with the phone conversation that they have infiltrated the \"internals\" of the company.\n\n\n*** Leaked source code ***\nOn September 20, 2007, MediaDefender-Defenders released the source code of TrapperKeeper, MediaDefender's decoy systems on The Pirate Bay. A large chunk of MediaDefender's software was available by Bittorrent.\n\n== Revision3 controversy ==\nRevision3 is an Internet television network which distributes video content legally through various means, including the BitTorrent protocol. During the Memorial Day weekend in 2008, Revision3 came under a Denial of Service attack originating from MediaDefender IP addresses. The attack left the company's service inaccessible until mid-Tuesday the following week. Revision3 CEO Jim Louderback accused MediaDefender of injecting its decoy files into Revision3's BitTorrent service through a vulnerability, then automatically perpetrating the attack after Revision3 increased security.Randy Saaf defended MediaDefender's actions by stating \"Our systems were targeting a tracker not even knowing it was Revision3's tracker\", adding that the denial-of-service attack resulted when \"Revision3 changed some configurations\" to their BitTorrent tracker."
    }
  },
  {
    "instruction": "Write an answer to the following question: What type of technology does a SOC typically use for access monitoring and controlling lighting, alarms, and vehicle barriers?",
    "context": "",
    "output": "A SOC typically uses data processing technology for access monitoring and controlling lighting, alarms, and vehicle barriers.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What type of technology does a SOC typically use for access monitoring and controlling lighting, alarms, and vehicle barriers?",
      "answer": "A SOC typically uses data processing technology for access monitoring and controlling lighting, alarms, and vehicle barriers."
    }
  },
  {
    "instruction": "Write an answer to the following question: How can detecting the presence of text in attached images with artifacts help in image spam detection?",
    "context": "",
    "output": "Detecting the presence of text in attached images with artifacts can help identify adversarial attempts to obfuscate the text, which can be indicative of spam. This can help improve the accuracy of image spam detection.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can detecting the presence of text in attached images with artifacts help in image spam detection?",
      "answer": "Detecting the presence of text in attached images with artifacts can help identify adversarial attempts to obfuscate the text, which can be indicative of spam. This can help improve the accuracy of image spam detection."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the role of the Authentication Server (AS) and key distribution center (KDC) in KINK?",
    "context": "",
    "output": "The Authentication Server (AS) authenticates KINK peers, while the key distribution center (KDC) controls the distribution of keying material for encryption and IPsec security policy management.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of the Authentication Server (AS) and key distribution center (KDC) in KINK?",
      "answer": "The Authentication Server (AS) authenticates KINK peers, while the key distribution center (KDC) controls the distribution of keying material for encryption and IPsec security policy management."
    }
  },
  {
    "instruction": "Write an answer to the following question: Who designed and implemented GBDE, and when was it introduced?",
    "context": "",
    "output": "GBDE was designed and implemented by Poul-Henning Kamp and Network Associates Inc. (now known as McAfee), and it was initially introduced in FreeBSD version 5.0.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Who designed and implemented GBDE, and when was it introduced?",
      "answer": "GBDE was designed and implemented by Poul-Henning Kamp and Network Associates Inc. (now known as McAfee), and it was initially introduced in FreeBSD version 5.0."
    }
  },
  {
    "instruction": "Smart-ID\n\n==Introduction==\nSmart-ID is an electronic authentication tool developed by SK ID Solutions, an Estonian company. Users can log in to various electronic services and sign documents with an electronic signature.Smart-ID meets the European Union's eIDAS Regulation and the European Central Bank's standards for a secure authentication solution. Smart-ID is a Qualified Signature Creator Device (QSCD) that can issue a Qualified Electronic Signature (QES).\nThe Smart-ID app is compatible with both iOS and Android devices and does not require a SIM card.\nBy 2021, the Smart-ID application was launched in the Huawei AppGallery.\nAs of May 2023, Smart-ID has 3,298,969 active users across the Baltic States (Latvia, Lithuania, and Estonia). Every month, the Smart-ID processes 79 million transactions. In March 2023, Smart-ID users made an exceptional 85 million transactions.\n\n\n\n== Overview ==\nThe Smart-ID app is available for download on Google Play and Apple's App Store. Android 4.4 and iOS 11 are the oldest supported operating system versions for Smart-ID.\nSmart-ID works on the premise of two-factor authentication, combining an intelligent device (something the user owns) with PINs (something the user knows).\nA new user must first authenticate themselves with an ID card or a mobile phone number and then confirm a PIN1 and PIN2 code, either manually or automatically produced. The first PIN is used to authenticate a person's identity when accessing e-banking or e-services, while the second PIN is used to support electronic signatures and authenticate transactions (e.g., transfers). The PIN1 code must be four digits long, while the PIN2 code must be five digits long.\nTo log in to an e-service, the user must use Smart-ID as the authentication method and enter their unique Smart-ID user ID. A notification will open on the user's smart device where the software is installed and display a verification code. If the code matches the code presented to the user by the e-service, then the user can confirm the match by entering their PIN1 code. The user must verify the action with their PIN2 code when giving digital signatures.\nA Smart-ID account is valid for three years. The report can be updated, changed, and deleted at any given time, free of charge.\nSmart-ID is available in five languages: Estonian, Latvian, Lithuanian, Russian, and English.An international survey conducted in 2021 revealed that Smart-ID is the most reliable authentication solution in Baltic countries. In January 2023, the number of times Smart-ID was used to access State Authentication Service (TARA) in Estonia has surpassed those of Mobile-ID and ID-cards for the first time since July 2022.\n\n== Security ==\nSmart-ID is based on Cybernetica's SplitKey authentication and digital signature platform technology, for which the company has filed a patent application. Public key cryptography, digital signature methods, and critical public infrastructures are all used in the technology. The user's PIN is not saved on the device and is only needed to decrypt the private key in the Smart-ID app. When the user inputs the PIN, the private key is cracked, and the answer is transmitted to the Smart-ID server, where a portion of the key given by the app is joined with the server's encrypted key.\nThe app will block the user from accessing it for three hours if they input the incorrect PIN three times in a row. If this happens once again, the app will lock for 24 hours. If this happens a third time, the account will be permanently disabled. PINs cannot be changed or recovered once an account has been created. The user must create a new account if the account is permanently blocked.\nSmart-ID uses the Apple and Google messaging networks to notify the app when new data is saved on its servers.\n\n== Phishing ==\nIn February 2019, unknown criminals attempted to create Smart-ID accounts with stolen IDs obtained via phishing customers' text messages and website addresses, according to a monthly report by the Estonian Information System Manager in April 2019. The Latvian Information Technology Security Incident Assessment Body Cert was also notified of these intrusions on March 1.\nFraudsters sent emails to potential victims pretending to be bank representatives. The mails linked users to a phishing page after redirecting them to a phony bank login page. Victims were asked to log in using their identification information and PIN1 code. The fraudsters then began the process of generating a new Smart-ID account. As a result, the victim had to input a PIN2 number, which permitted the fraudster to finish setting up a new tab with the victim's personal information.\nFraudsters in Estonia were able to log in to multiple e-services utilizing Smart-ID using a Smart-ID account and the victim's data. On behalf of the victims, fraudsters also employed online banking services. Later, the Estonian Information System Manager identified several victims, some of whom had also experienced financial losses.\nThe Estonian Information System Manager requested a full report on the event from SK ID Solutions. The organization opted not to criticize the corporation after receiving the information, although it did propose that the procedure of creating Smart-ID accounts be reviewed. According to the Estonian Banking Association, Estonian banks have not discontinued using Smart-ID and do not think it is required.\nSmart-ID was exposed to a thorough review process in September 2019 to determine this authentication instrument's level of security. Reviewers discovered no flaws, and SK ID Solutions and the Estonian Information System Manager signed a contract. Estonia later introduced Smart-ID and other authentication mechanisms to the central public services portal.\nQ: What is the duration of a Smart-ID account's validity?",
    "context": "",
    "output": "A Smart-ID account is valid for three years.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the duration of a Smart-ID account's validity?",
      "answer": "A Smart-ID account is valid for three years.",
      "context": "Smart-ID\n\n==Introduction==\nSmart-ID is an electronic authentication tool developed by SK ID Solutions, an Estonian company. Users can log in to various electronic services and sign documents with an electronic signature.Smart-ID meets the European Union's eIDAS Regulation and the European Central Bank's standards for a secure authentication solution. Smart-ID is a Qualified Signature Creator Device (QSCD) that can issue a Qualified Electronic Signature (QES).\nThe Smart-ID app is compatible with both iOS and Android devices and does not require a SIM card.\nBy 2021, the Smart-ID application was launched in the Huawei AppGallery.\nAs of May 2023, Smart-ID has 3,298,969 active users across the Baltic States (Latvia, Lithuania, and Estonia). Every month, the Smart-ID processes 79 million transactions. In March 2023, Smart-ID users made an exceptional 85 million transactions.\n\n\n\n== Overview ==\nThe Smart-ID app is available for download on Google Play and Apple's App Store. Android 4.4 and iOS 11 are the oldest supported operating system versions for Smart-ID.\nSmart-ID works on the premise of two-factor authentication, combining an intelligent device (something the user owns) with PINs (something the user knows).\nA new user must first authenticate themselves with an ID card or a mobile phone number and then confirm a PIN1 and PIN2 code, either manually or automatically produced. The first PIN is used to authenticate a person's identity when accessing e-banking or e-services, while the second PIN is used to support electronic signatures and authenticate transactions (e.g., transfers). The PIN1 code must be four digits long, while the PIN2 code must be five digits long.\nTo log in to an e-service, the user must use Smart-ID as the authentication method and enter their unique Smart-ID user ID. A notification will open on the user's smart device where the software is installed and display a verification code. If the code matches the code presented to the user by the e-service, then the user can confirm the match by entering their PIN1 code. The user must verify the action with their PIN2 code when giving digital signatures.\nA Smart-ID account is valid for three years. The report can be updated, changed, and deleted at any given time, free of charge.\nSmart-ID is available in five languages: Estonian, Latvian, Lithuanian, Russian, and English.An international survey conducted in 2021 revealed that Smart-ID is the most reliable authentication solution in Baltic countries. In January 2023, the number of times Smart-ID was used to access State Authentication Service (TARA) in Estonia has surpassed those of Mobile-ID and ID-cards for the first time since July 2022.\n\n== Security ==\nSmart-ID is based on Cybernetica's SplitKey authentication and digital signature platform technology, for which the company has filed a patent application. Public key cryptography, digital signature methods, and critical public infrastructures are all used in the technology. The user's PIN is not saved on the device and is only needed to decrypt the private key in the Smart-ID app. When the user inputs the PIN, the private key is cracked, and the answer is transmitted to the Smart-ID server, where a portion of the key given by the app is joined with the server's encrypted key.\nThe app will block the user from accessing it for three hours if they input the incorrect PIN three times in a row. If this happens once again, the app will lock for 24 hours. If this happens a third time, the account will be permanently disabled. PINs cannot be changed or recovered once an account has been created. The user must create a new account if the account is permanently blocked.\nSmart-ID uses the Apple and Google messaging networks to notify the app when new data is saved on its servers.\n\n== Phishing ==\nIn February 2019, unknown criminals attempted to create Smart-ID accounts with stolen IDs obtained via phishing customers' text messages and website addresses, according to a monthly report by the Estonian Information System Manager in April 2019. The Latvian Information Technology Security Incident Assessment Body Cert was also notified of these intrusions on March 1.\nFraudsters sent emails to potential victims pretending to be bank representatives. The mails linked users to a phishing page after redirecting them to a phony bank login page. Victims were asked to log in using their identification information and PIN1 code. The fraudsters then began the process of generating a new Smart-ID account. As a result, the victim had to input a PIN2 number, which permitted the fraudster to finish setting up a new tab with the victim's personal information.\nFraudsters in Estonia were able to log in to multiple e-services utilizing Smart-ID using a Smart-ID account and the victim's data. On behalf of the victims, fraudsters also employed online banking services. Later, the Estonian Information System Manager identified several victims, some of whom had also experienced financial losses.\nThe Estonian Information System Manager requested a full report on the event from SK ID Solutions. The organization opted not to criticize the corporation after receiving the information, although it did propose that the procedure of creating Smart-ID accounts be reviewed. According to the Estonian Banking Association, Estonian banks have not discontinued using Smart-ID and do not think it is required.\nSmart-ID was exposed to a thorough review process in September 2019 to determine this authentication instrument's level of security. Reviewers discovered no flaws, and SK ID Solutions and the Estonian Information System Manager signed a contract. Estonia later introduced Smart-ID and other authentication mechanisms to the central public services portal."
    }
  },
  {
    "instruction": "Write an answer to the following question: How do some specific hashing algorithms, such as DES, Triple DES, bcrypt, scrypt, and Argon2, run slowly on GPUs?",
    "context": "",
    "output": "Some algorithms, such as DES, Triple DES, bcrypt, scrypt, and Argon2, run slowly, or are specifically designed to run slowly, on GPUs. This makes them more difficult to crack using GPUs and custom integrated circuits.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do some specific hashing algorithms, such as DES, Triple DES, bcrypt, scrypt, and Argon2, run slowly on GPUs?",
      "answer": "Some algorithms, such as DES, Triple DES, bcrypt, scrypt, and Argon2, run slowly, or are specifically designed to run slowly, on GPUs. This makes them more difficult to crack using GPUs and custom integrated circuits."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the camfecter software work?",
    "context": "",
    "output": "The camfecter software works just like the original webcam software present in the victim computer, with the difference being that the camfecter controls the software instead of the webcam's owner.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the camfecter software work?",
      "answer": "The camfecter software works just like the original webcam software present in the victim computer, with the difference being that the camfecter controls the software instead of the webcam's owner."
    }
  },
  {
    "instruction": "X.509\n\n==Introduction==\nIn cryptography, X.509 is an International Telecommunication Union (ITU) standard defining the format of public key certificates. X.509 certificates are used in many Internet protocols, including TLS/SSL, which is the basis for HTTPS, the secure protocol for browsing the web. They are also used in offline applications, like electronic signatures.An X.509 certificate binds an identity to a public key using a digital signature. A certificate contains an identity (a hostname, or an organization, or an individual) and a public key (RSA, DSA, ECDSA, ed25519, etc.), and is either signed by a certificate authority or is self-signed. When a certificate is signed by a trusted certificate authority, or validated by other means, someone holding that certificate can use the public key it contains to establish secure communications with another party, or validate documents digitally signed by the corresponding private key.\nX.509 also defines certificate revocation lists, which are a means to distribute information about certificates that have been deemed invalid by a signing authority, as well as a certification path validation algorithm, which allows for certificates to be signed by intermediate CA certificates, which are, in turn, signed by other certificates, eventually reaching a trust anchor.\nX.509 is defined by the International Telecommunications Union's \"Standardization Sector\" (ITU-T's SG17), in ITU-T Study Group 17 and is based on ASN.1, another ITU-T standard.\n\n\n\n== History and usage ==\nX.509 was initially issued on July 3, 1988, and was begun in association with the X.500 standard. The first tasks of it was providing users with secure access to information resources and avoiding a cryptographic man-in-the-middle attack. It assumes a strict hierarchical system of certificate authorities (CAs) for issuing the certificates. This contrasts with web of trust models, like PGP, where anyone (not just special CAs) may sign and thus attest to the validity of others' key certificates.\nVersion 3 of X.509 includes the flexibility to support other topologies like bridges and meshes. It can be used in a peer-to-peer, OpenPGP-like web of trust, but was rarely used that way as of 2004. The X.500 system has only been implemented by sovereign nations for state identity information sharing treaty fulfillment purposes, and the IETF's Public-Key Infrastructure (X.509) (PKIX) working group has adapted the standard to the more flexible organization of the Internet. In fact, the term X.509 certificate usually refers to the IETF's PKIX certificate and CRL profile of the X.509 v3 certificate standard, as specified in RFC 5280, commonly called PKIX for Public Key Infrastructure (X.509).An early issue with Public Key Infrastructure (PKI) and X.509 certificates was the well known \"which directory\" problem. The problem is the client does not know where to fetch missing intermediate certificates because the global X.500 directory never materialized. The problem was mitigated by including all intermediate certificates in a request. For example, early web servers only sent the web server's certificate to the client. Clients that lacked an intermediate CA certificate or where to find them failed to build a valid path from the CA to the server's certificate. To work around the problem, web servers now send all the intermediate certificates along with the web server's certificate.While PKIX refers to the IETF's or Internet's PKI standard, there are many other PKIs with different policies. For example, the US Government has its own PKI with its own policies, and the CA/Browser Forum has its own PKI with its own policies. The US Government's PKI is a massive book of over 2500 pages. If an organization's PKI diverges too much from that of the IETF or CA/Browser Forum, then the organization risks losing interoperability with common tools like web browsers, cURL, and Wget. For example, if a PKI has a policy of only issuing certificates on Monday, then common tools like cURL and Wget will not enforce the policy and allow a certificate issued on a Tuesday.\n\n== Certificates ==\nX.509 certificates bind an identity to a public key using a digital signature. In the X.509 system, there are two types of certificates. The first is a CA certificate. The second is an end-entity certificate. A CA certificate can issue other certificates. The top level, self-signed CA certificate is sometimes called the Root CA certificate. Other CA certificates are called intermediate CA or subordinate CA certificates. An end-entity certificate identifies the user, like a person, organization or business. An end-entity certificate cannot issue other certificates. An end-entity certificate is sometimes called a leaf certificate since no other certificates can be issued below it.\nAn organization that wants a signed certificate requests one from a CA using a protocol like Certificate Signing Request (CSR), Simple Certificate Enrollment Protocol (SCEP) or Certificate Management Protocol (CMP). The organization first generates a key pair, keeping the private key secret and using it to sign the CSR. The CSR contains information identifying the applicant and the applicant's public key that is used to verify the signature of the CSR - and the Distinguished Name (DN) that is unique for the person, organization or business. The CSR may be accompanied by other credentials or proofs of identity required by the certificate authority.\nThe CSR will be validated using a Registration Authority (RA), and then the certification authority will issue a certificate binding a public key to a particular distinguished name. The roles registration authority and certification authority are usually separate business units under separation of duties to reduce the risk of fraud.\nAn organization's trusted root certificates can be distributed to all employees so that they can use the company PKI system. Browsers such as Internet Explorer, Firefox, Opera, Safari and Chrome come with a predetermined set of root certificates pre-installed, so SSL certificates from major certificate authorities will work instantly; in effect the browsers' developers determine which CAs are trusted third parties for the browsers' users. For example, Firefox provides a CSV and/or HTML file containing a list of Included CAs.X.509 and  RFC 5280 also include standards for certificate revocation list (CRL) implementations. Another IETF-approved way of checking a certificate's validity is the Online Certificate Status Protocol (OCSP). Firefox 3.0 enabled OCSP checking by default, as did versions of Windows from at least Vista and later.\n\n\n*** Structure of a certificate ***\nThe structure foreseen by the standards is expressed in a formal language, Abstract Syntax Notation One (ASN.1).\nThe structure of an X.509 v3 digital certificate is as follows:\n\nCertificate\nVersion Number\nSerial Number\nSignature Algorithm ID\nIssuer Name\nValidity period\nNot Before\nNot After\nSubject name\nSubject Public Key Info\nPublic Key Algorithm\nSubject Public Key\nIssuer Unique Identifier (optional)\nSubject Unique Identifier (optional)\nExtensions (optional)\n...\nCertificate Signature Algorithm\nCertificate SignatureThe Extensions field, if present, is a sequence of one or more certificate extensions. Each extension has its own unique ID, expressed as object identifier (OID), which is a set of values, together with either a critical or non-critical indication. A certificate-using system must reject the certificate if it encounters a critical extension that it does not recognize, or a critical extension that contains information that it cannot process. A non-critical extension may be ignored if it is not recognized, but must be processed if it is recognized.The structure of version 1 is given in RFC 1422.\nThe inner format of issuer and subject unique identifiers specified in X.520 The Directory: Selected attribute types recommendation.\nITU-T introduced issuer and subject unique identifiers in version 2 to permit the reuse of issuer or subject name after some time. An example of reuse will be when a CA goes bankrupt and its name is deleted from the country's public list. After some time another CA with the same name may register itself, even though it is unrelated to the first one. However, IETF recommends that no issuer and subject names be reused. Therefore, version 2 is not widely deployed in the Internet.Extensions were introduced in version 3. A CA can use extensions to issue a certificate only for a specific purpose (e.g. only for signing digital objects).\nIn all versions, the serial number must be unique for each certificate issued by a specific CA (as mentioned in RFC 5280).\n\n\n*** Extensions informing a specific usage of a certificate ***\nRFC 5280 (and its predecessors) defines a number of certificate extensions which indicate how the certificate should be used. Most of them are arcs from the joint-iso-ccitt(2) ds(5) id-ce(29) OID. Some of the most common, defined in section 4.2.1, are:\n\nBasic Constraints, { id-ce 19 }, are used to indicate whether the certificate is a CA certificate and can certify or issue other certificates. A constraint can be marked as critical. If a constraint is marked critical, then an agent must fail to process the certificate if the agent does not understand the constraint. An agent can continue to process a non-critical constraint it does not understand.\nKey Usage, { id-ce 15 }, provides a bitmap specifying the cryptographic operations which may be performed using the public key contained in the certificate; for example, it could indicate that the key should be used for signatures but not for encipherment.\nExtended Key Usage, { id-ce 37 }, is used, typically on a leaf certificate, to indicate the purpose of the public key contained in the certificate. It contains a list of OIDs, each of which indicates an allowed use. For example, { id-pkix 3 1 } indicates that the key may be used on the server end of a TLS or SSL connection; { id-pkix 3 4 } indicates that the key may be used to secure email.In general when using RFC 5280, if a certificate has several extensions restricting its use, all restrictions must be satisfied for a given use to be appropriate. The RFC gives the specific example of a certificate containing both keyUsage and extendedKeyUsage: in this case, both must be processed and the certificate can only be used if both extensions are coherent in specifying the usage of a certificate. For example, NSS uses both extensions to specify certificate usage.\n\n\n*** Extended Validation certificates ***\nCertification authorities operating under the CA/Browser Forum's PKI issue certificates with varying levels of validation. The different validations provide different levels of assurances that a certificate represents what it is supposed to. For example, a web server can be validated at the lowest level of assurances using an email called Domain Validation (DV). Or a web server can be validated at a higher level of assurances using more detailed methods called Extended Validation (EV). \nIn practice, a DV certificate means a certificate was issued for a domain like example.com after someone responded to an email sent to webmaster@example.com. An EV certificate means a certificate was issued for a domain like example.com, and a company like Example, LLC is the owner of the domain, and the owner was verified by Articles of Incorporation.\nExtended validation does not add any additional security controls, so the secure channel setup using an EV certificate is not \"stronger\" than a channel setup using a different level of validation like DV.\nExtended validation is signaled in a certificate using X.509 v3 extension. Each CA uses a different Object Identifier (OID) to assert extended validation. There is no single OID to indicate extended validation, which complicates user agent programming. Each user agent must have a list of OIDs that indicate extended validation.\nThe CA/Browser Forum's PKI recognizes extended validation and many browsers provide visual feedback to the user to indicate a site provides an EV certificate. Other PKIs, like the Internet's PKI (PKIX), do not place any special emphasis on extended validation. Tools using PKIX policies, like cURL and Wget, simply treat an EV certificate like any other certificate.\nSecurity expert Peter Gutmann states CA's created EV certificates to restore profit levels after the Race to the Bottom cut into profits. During the race to the bottom CA's cut prices to lure consumers to purchase their certificates. As a result, profits were reduced and CA's dropped the level of validation they were performing to the point there were nearly no assurances on a certificate.\n\n\n*** Certificate filename extensions ***\nThere are several commonly used filename extensions for X.509 certificates. Unfortunately, some of these extensions are also used for other data such as private keys.\n\n.pem \u2013 (Privacy-enhanced Electronic Mail) Base64 encoded DER certificate, enclosed between -----BEGIN CERTIFICATE----- and -----END CERTIFICATE-----\n.cer, .crt, .der \u2013 usually in binary DER form, but Base64-encoded certificates are common too (see .pem above)\n.p7b, .p7c \u2013 PKCS#7 SignedData structure without data, just certificate(s) or CRL(s)\n.p12 \u2013 PKCS#12, may contain certificate(s) (public) and private keys (password protected)\n.pfx \u2013 PFX, predecessor of PKCS#12 (usually contains data in PKCS#12 format, e.g., with PFX files generated in IIS)PKCS#7 is a standard for signing or encrypting (officially called \"enveloping\") data. Since the certificate is needed to verify signed data, it is possible to include them in the SignedData structure. A .P7C file is a degenerated SignedData structure, without any data to sign.PKCS#12 evolved from the personal information exchange (PFX) standard and is used to exchange public and private objects in a single file.\n\n== Certificate chains and cross-certification ==\nA certificate chain (see the equivalent concept of \"certification path\" defined by RFC 5280 section 3.2) is a list of certificates (usually starting with an end-entity certificate) followed by one or more CA certificates (usually the last one being a self-signed certificate), with the following properties:\n\nThe Issuer of each certificate (except the last one) matches the Subject of the next certificate in the list\nEach certificate (except the last one) is signed by the secret key corresponding to the next certificate in the chain (i.e. the signature of one certificate can be verified using the public key contained in the following certificate)\nThe last certificate in the list is a trust anchor: a certificate that you trust because it was delivered to you by some trustworthy procedureCertificate chains are used in order to check that the public key (PK) contained in a target certificate (the first certificate in the chain) and other data contained in it effectively belongs to its subject. In order to ascertain this, the signature on the target certificate is verified by using the PK contained in the following certificate, whose signature is verified using the next certificate, and so on until the last certificate in the chain is reached. As the last certificate is a trust anchor, successfully reaching it will prove that the target certificate can be trusted.\nThe description in the preceding paragraph is a simplified view on the certification path validation process as defined by RFC 5280 section 6, which involves additional checks, such as verifying validity dates on certificates, looking up CRLs, etc.\n\nExamining how certificate chains are built and validated, it is important to note that a concrete certificate can be part of very different certificate chains (all of them valid). This is because several CA certificates can be generated for the same subject and public key, but be signed with different private keys (from different CAs or different private keys from the same CA). So, although a single X.509 certificate can have only one issuer and one CA signature, it can be validly linked to more than one certificate, building completely different certificate chains. This is crucial for cross-certification between PKIs and other applications.\nSee the following examples:\n\n\n*** Examples ***\nIn these diagrams:\n\nEach box represents a certificate, with its Subject in bold\nA \u2192 B means \"A is signed by B\" (or, more precisely, \"A is signed by the secret key corresponding to the public key contained in B\").\nCertificates with the same color (that are not white/transparent) contain the same public key\n\n\n**** Example 1: Cross-certification at root Certification Authority (CA) level between two PKIs ****\nIn order to manage that user certificates existing in PKI 2 (like \"User 2\") are trusted by PKI 1, CA1 generates a certificate (cert2.1) containing the public key of CA2.\nNow both \"cert2 and cert2.1 (in green) have the same subject and public key, so there are two valid chains for cert2.2 (User 2): \"cert2.2 \u2192 cert2\" and \"cert2.2 \u2192 cert2.1 \u2192 cert1\".\nSimilarly, CA2 can generate a certificate (cert1.1) containing the public key of CA1 so that user certificates existing in PKI 1 (like \"User 1\") are trusted by PKI 2.\n\n\n**** Example 2: CA certificate renewal ****\nUnderstanding Certification Path Construction (PDF). PKI Forum. September 2002. To allow for graceful transition from the old signing key pair to the new signing key pair, the CA should issue a certificate that contains the old public key signed by the new private signing key and a certificate that contains the new public key signed by the old private signing key. Both of these certificates are self-issued, but neither is self-signed. Note that these are in addition to the two self-signed certificates (one old, one new).\nSince both cert1 and cert3 contain the same public key (the old one), there are two valid certificate chains for cert5: \"cert5 \u2192 cert1\" and \"cert5 \u2192 cert3 \u2192 cert2\", and analogously for cert6. This allows that old user certificates (such as cert5) and new certificates (such as cert6) can be trusted indifferently by a party having either the new root CA certificate or the old one as trust anchor during the transition to the new CA keys.\n\n== Sample X.509 certificates ==\nThis is an example of a decoded X.509 certificate that was used in the past by wikipedia.org and several other Wikipedia websites. It was issued by GlobalSign, as stated in the Issuer field. Its Subject field describes Wikipedia as an organization, and its Subject Alternative Name (SAN) field for DNS describes the hostnames for which it could be used. The Subject Public Key Info field contains an ECDSA public key, while the signature at the bottom was generated by GlobalSign's RSA private key. (The signatures in these examples are truncated.)\n\n\n*** End-entity certificate ***\nCertificate:\n    Data:\n        Version: 3 (0x2)\n        Serial Number:\n            10:e6:fc:62:b7:41:8a:d5:00:5e:45:b6\n        Signature Algorithm: sha256WithRSAEncryption\n        Issuer: C\n\n== Security ==\nThere are a number of publications about PKI problems by Bruce Schneier, Peter Gutmann and other security experts.\n\n\n*** Architectural weaknesses ***\nUse of blocklisting invalid certificates (using CRLs and OCSP),\nIf the client only trusts certificates when CRLs are available, then they lose the offline capability that makes PKI attractive. So most clients do trust certificates when CRLs are not available, but in that case an attacker that controls the communication channel can disable the CRLs. Adam Langley of Google has said soft-fail CRL checks are like a safety belt that works except when you have an accident.\nCRLs are notably a poor choice because of large sizes and convoluted distribution patterns,\nAmbiguous OCSP semantics and lack of historical revocation status,\nRevocation of root certificates is not addressed,\nAggregation problem: Identity claims (authenticate with an identifier), attribute claims (submit a bag of vetted attributes), and policy claims are combined in a single container. This raises privacy, policy mapping, and maintenance issues.\nDelegation problem: CAs cannot technically restrict subordinate CAs from issuing certificates outside a limited namespaces or attribute set; this feature of X.509 is not in use. Therefore, a large number of CAs exist on the Internet, and classifying them and their policies is an insurmountable task. Delegation of authority within an organization cannot be handled at all, as in common business practice.\nFederation problem: Certificate chains that are the result of subordinate CAs, bridge CAs, and cross-signing make validation complex and expensive in terms of processing time. Path validation semantics may be ambiguous. The hierarchy with a third-party trusted party is the only model. This is inconvenient when a bilateral trust relationship is already in place.\nIssuance of an Extended Validation (EV) certificate for a hostname doesn't prevent issuance of a lower-validation certificate valid for the same hostname, which means that the higher validation level of EV doesn't protect against man-in-the-middle attacks.\n\n\n*** Problems with certification authorities ***\nThe person or organization that purchases a certificate will often utilize the least expensive certification authority. In response, CA's have cut prices and removed more expensive validation checks in what is known as a Race to the Bottom. The Race to the Bottom is partly addressed by Extended Validation (EV) certificates, yet trust value in the eyes of security experts are diminishing. According to Peter Gutmann, EV certificates do not add any additional security controls. Rather, EV certificates merely restore CA profits to levels prior to the Race to the Bottom by allowing a CA to charge more for a service they should have been providing all along.\nCertification authorities attempt to deny almost all warranties to the user and relying parties in their Certification Practice Statement (CPS). For example, Apple Inc states in their CPS, \"To the extent permitted by applicable law, Subscriber agreements, if applicable, disclaim warranties from Apple, including any warranty of merchantability or fitness for a particular purpose\".\nAccording to Peter Gutmann, \"Users use an undefined certification request protocol to obtain a certificate which is published in an unclear location in a nonexistent directory with no real means to revoke it\"\nLike all businesses, CAs are subject to the legal jurisdictions they operate within, and may be legally compelled to compromise the interests of their customers and their users. Intelligence agencies have also made use of false certificates issued through extralegal compromise of CAs, such as DigiNotar, to carry out man-in-the-middle attacks. Another example is a revocation request of the CA of the Dutch government, because of a Dutch law passed in 2018, giving new powers for the Dutch intelligence and security services\n\n\n*** Implementation issues ***\nImplementations suffer from design flaws, bugs, different interpretations of standards and lack of interoperability of different standards. Some problems are:\nMany implementations turn off revocation check:\nSeen as obstacle, policies are not enforced\nIf it was turned on in all browsers by default, including code signing, it would probably crash the infrastructure\nDNs are complex and little understood (lack of canonicalization, internationalization problems)\nrfc822Name has two notations\nName and policy constraints hardly supported\nKey usage ignored, first certificate in a list being used\nEnforcement of custom OIDs is difficult\nAttributes should not be made critical because it makes clients crash\nUnspecified length of attributes lead to product-specific limits\nThere are implementation errors with X.509 that allow e.g. falsified subject names using null-terminated strings or code injection attacks in certificates\nBy using illegal 0x80 padded subidentifiers of object identifiers, wrong implementations or by using integer overflows of the client's browsers, an attacker can include an unknown attribute in the CSR, which the CA will sign, which the client wrongly interprets as \"CN\" (OID\n\n== PKI standards for X.509 ==\nPKCS7 (Cryptographic Message Syntax Standard \u2014 public keys with proof of identity for signed and/or encrypted message for PKI)\nTransport Layer Security (TLS) and its predecessor SSL \u2014 cryptographic protocols for Internet secure communications.\nOnline Certificate Status Protocol (OCSP) / certificate revocation list (CRL) \u2014 this is to check certificate revocation status\nPKCS12 (Personal Information Exchange Syntax Standard) \u2014 used to store a private key with the appropriate public key certificate\nCertification Path Building \u2014 guidance and recommendations for building X.509 public-key certification paths within applications (i.e., validating an end-entity certificate using a CA certificate)\n\n== PKIX Working Group ==\nIn 1995, the Internet Engineering Task Force in conjunction with the National Institute of Standards and Technology formed the Public-Key Infrastructure (X.509) working group. The working group, concluded in June 2014, is commonly referred to as \"PKIX.\" It produced RFCs and other standards documentation on using and deploying X.509 in practice. In particular it produced RFC 3280 and its successor RFC 5280, which define how to use X.509 in Internet protocols.\n\n== Major protocols and standards using X.509 certificates ==\nTLS/SSL and HTTPS use the RFC 5280 profile of X.509, as do S/MIME (Secure Multipurpose Internet Mail Extensions) and the EAP-TLS method for WiFi authentication. Any protocol that uses TLS, such as SMTP, POP, IMAP, LDAP, XMPP, and many more, inherently uses X.509.\nIPsec can use the RFC 4945 profile for authenticating peers.\nThe OpenCable security specification defines its own profile of X.509 for use in the cable industry.\nDevices like smart cards and TPMs often carry certificates to identify themselves or their owners. These certificates are in X.509 form.\nThe WS-Security standard defines authentication either through TLS or through its own certificate profile. Both methods use X.509.\nThe Microsoft Authenticode code signing system uses X.509 to identify authors of computer programs.\nThe OPC UA industrial automation communication standard uses X.509.\nSSH generally uses a Trust On First Use security model and doesn't have need for certificates. However, the popular OpenSSH implementation does support a CA-signed identity model based on its own non-X.509 certificate format.\n\nAnswer this question based on the above context: What are certificate revocation lists (CRLs) in the context of X.509?",
    "context": "",
    "output": "Certificate revocation lists (CRLs) are a standard for distributing information about certificates that have been deemed invalid by a signing authority. They are part of the X.509 standard and allow for the revocation of certificates before their expiration date.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are certificate revocation lists (CRLs) in the context of X.509?",
      "answer": "Certificate revocation lists (CRLs) are a standard for distributing information about certificates that have been deemed invalid by a signing authority. They are part of the X.509 standard and allow for the revocation of certificates before their expiration date.",
      "context": "X.509\n\n==Introduction==\nIn cryptography, X.509 is an International Telecommunication Union (ITU) standard defining the format of public key certificates. X.509 certificates are used in many Internet protocols, including TLS/SSL, which is the basis for HTTPS, the secure protocol for browsing the web. They are also used in offline applications, like electronic signatures.An X.509 certificate binds an identity to a public key using a digital signature. A certificate contains an identity (a hostname, or an organization, or an individual) and a public key (RSA, DSA, ECDSA, ed25519, etc.), and is either signed by a certificate authority or is self-signed. When a certificate is signed by a trusted certificate authority, or validated by other means, someone holding that certificate can use the public key it contains to establish secure communications with another party, or validate documents digitally signed by the corresponding private key.\nX.509 also defines certificate revocation lists, which are a means to distribute information about certificates that have been deemed invalid by a signing authority, as well as a certification path validation algorithm, which allows for certificates to be signed by intermediate CA certificates, which are, in turn, signed by other certificates, eventually reaching a trust anchor.\nX.509 is defined by the International Telecommunications Union's \"Standardization Sector\" (ITU-T's SG17), in ITU-T Study Group 17 and is based on ASN.1, another ITU-T standard.\n\n\n\n== History and usage ==\nX.509 was initially issued on July 3, 1988, and was begun in association with the X.500 standard. The first tasks of it was providing users with secure access to information resources and avoiding a cryptographic man-in-the-middle attack. It assumes a strict hierarchical system of certificate authorities (CAs) for issuing the certificates. This contrasts with web of trust models, like PGP, where anyone (not just special CAs) may sign and thus attest to the validity of others' key certificates.\nVersion 3 of X.509 includes the flexibility to support other topologies like bridges and meshes. It can be used in a peer-to-peer, OpenPGP-like web of trust, but was rarely used that way as of 2004. The X.500 system has only been implemented by sovereign nations for state identity information sharing treaty fulfillment purposes, and the IETF's Public-Key Infrastructure (X.509) (PKIX) working group has adapted the standard to the more flexible organization of the Internet. In fact, the term X.509 certificate usually refers to the IETF's PKIX certificate and CRL profile of the X.509 v3 certificate standard, as specified in RFC 5280, commonly called PKIX for Public Key Infrastructure (X.509).An early issue with Public Key Infrastructure (PKI) and X.509 certificates was the well known \"which directory\" problem. The problem is the client does not know where to fetch missing intermediate certificates because the global X.500 directory never materialized. The problem was mitigated by including all intermediate certificates in a request. For example, early web servers only sent the web server's certificate to the client. Clients that lacked an intermediate CA certificate or where to find them failed to build a valid path from the CA to the server's certificate. To work around the problem, web servers now send all the intermediate certificates along with the web server's certificate.While PKIX refers to the IETF's or Internet's PKI standard, there are many other PKIs with different policies. For example, the US Government has its own PKI with its own policies, and the CA/Browser Forum has its own PKI with its own policies. The US Government's PKI is a massive book of over 2500 pages. If an organization's PKI diverges too much from that of the IETF or CA/Browser Forum, then the organization risks losing interoperability with common tools like web browsers, cURL, and Wget. For example, if a PKI has a policy of only issuing certificates on Monday, then common tools like cURL and Wget will not enforce the policy and allow a certificate issued on a Tuesday.\n\n== Certificates ==\nX.509 certificates bind an identity to a public key using a digital signature. In the X.509 system, there are two types of certificates. The first is a CA certificate. The second is an end-entity certificate. A CA certificate can issue other certificates. The top level, self-signed CA certificate is sometimes called the Root CA certificate. Other CA certificates are called intermediate CA or subordinate CA certificates. An end-entity certificate identifies the user, like a person, organization or business. An end-entity certificate cannot issue other certificates. An end-entity certificate is sometimes called a leaf certificate since no other certificates can be issued below it.\nAn organization that wants a signed certificate requests one from a CA using a protocol like Certificate Signing Request (CSR), Simple Certificate Enrollment Protocol (SCEP) or Certificate Management Protocol (CMP). The organization first generates a key pair, keeping the private key secret and using it to sign the CSR. The CSR contains information identifying the applicant and the applicant's public key that is used to verify the signature of the CSR - and the Distinguished Name (DN) that is unique for the person, organization or business. The CSR may be accompanied by other credentials or proofs of identity required by the certificate authority.\nThe CSR will be validated using a Registration Authority (RA), and then the certification authority will issue a certificate binding a public key to a particular distinguished name. The roles registration authority and certification authority are usually separate business units under separation of duties to reduce the risk of fraud.\nAn organization's trusted root certificates can be distributed to all employees so that they can use the company PKI system. Browsers such as Internet Explorer, Firefox, Opera, Safari and Chrome come with a predetermined set of root certificates pre-installed, so SSL certificates from major certificate authorities will work instantly; in effect the browsers' developers determine which CAs are trusted third parties for the browsers' users. For example, Firefox provides a CSV and/or HTML file containing a list of Included CAs.X.509 and  RFC 5280 also include standards for certificate revocation list (CRL) implementations. Another IETF-approved way of checking a certificate's validity is the Online Certificate Status Protocol (OCSP). Firefox 3.0 enabled OCSP checking by default, as did versions of Windows from at least Vista and later.\n\n\n*** Structure of a certificate ***\nThe structure foreseen by the standards is expressed in a formal language, Abstract Syntax Notation One (ASN.1).\nThe structure of an X.509 v3 digital certificate is as follows:\n\nCertificate\nVersion Number\nSerial Number\nSignature Algorithm ID\nIssuer Name\nValidity period\nNot Before\nNot After\nSubject name\nSubject Public Key Info\nPublic Key Algorithm\nSubject Public Key\nIssuer Unique Identifier (optional)\nSubject Unique Identifier (optional)\nExtensions (optional)\n...\nCertificate Signature Algorithm\nCertificate SignatureThe Extensions field, if present, is a sequence of one or more certificate extensions. Each extension has its own unique ID, expressed as object identifier (OID), which is a set of values, together with either a critical or non-critical indication. A certificate-using system must reject the certificate if it encounters a critical extension that it does not recognize, or a critical extension that contains information that it cannot process. A non-critical extension may be ignored if it is not recognized, but must be processed if it is recognized.The structure of version 1 is given in RFC 1422.\nThe inner format of issuer and subject unique identifiers specified in X.520 The Directory: Selected attribute types recommendation.\nITU-T introduced issuer and subject unique identifiers in version 2 to permit the reuse of issuer or subject name after some time. An example of reuse will be when a CA goes bankrupt and its name is deleted from the country's public list. After some time another CA with the same name may register itself, even though it is unrelated to the first one. However, IETF recommends that no issuer and subject names be reused. Therefore, version 2 is not widely deployed in the Internet.Extensions were introduced in version 3. A CA can use extensions to issue a certificate only for a specific purpose (e.g. only for signing digital objects).\nIn all versions, the serial number must be unique for each certificate issued by a specific CA (as mentioned in RFC 5280).\n\n\n*** Extensions informing a specific usage of a certificate ***\nRFC 5280 (and its predecessors) defines a number of certificate extensions which indicate how the certificate should be used. Most of them are arcs from the joint-iso-ccitt(2) ds(5) id-ce(29) OID. Some of the most common, defined in section 4.2.1, are:\n\nBasic Constraints, { id-ce 19 }, are used to indicate whether the certificate is a CA certificate and can certify or issue other certificates. A constraint can be marked as critical. If a constraint is marked critical, then an agent must fail to process the certificate if the agent does not understand the constraint. An agent can continue to process a non-critical constraint it does not understand.\nKey Usage, { id-ce 15 }, provides a bitmap specifying the cryptographic operations which may be performed using the public key contained in the certificate; for example, it could indicate that the key should be used for signatures but not for encipherment.\nExtended Key Usage, { id-ce 37 }, is used, typically on a leaf certificate, to indicate the purpose of the public key contained in the certificate. It contains a list of OIDs, each of which indicates an allowed use. For example, { id-pkix 3 1 } indicates that the key may be used on the server end of a TLS or SSL connection; { id-pkix 3 4 } indicates that the key may be used to secure email.In general when using RFC 5280, if a certificate has several extensions restricting its use, all restrictions must be satisfied for a given use to be appropriate. The RFC gives the specific example of a certificate containing both keyUsage and extendedKeyUsage: in this case, both must be processed and the certificate can only be used if both extensions are coherent in specifying the usage of a certificate. For example, NSS uses both extensions to specify certificate usage.\n\n\n*** Extended Validation certificates ***\nCertification authorities operating under the CA/Browser Forum's PKI issue certificates with varying levels of validation. The different validations provide different levels of assurances that a certificate represents what it is supposed to. For example, a web server can be validated at the lowest level of assurances using an email called Domain Validation (DV). Or a web server can be validated at a higher level of assurances using more detailed methods called Extended Validation (EV). \nIn practice, a DV certificate means a certificate was issued for a domain like example.com after someone responded to an email sent to webmaster@example.com. An EV certificate means a certificate was issued for a domain like example.com, and a company like Example, LLC is the owner of the domain, and the owner was verified by Articles of Incorporation.\nExtended validation does not add any additional security controls, so the secure channel setup using an EV certificate is not \"stronger\" than a channel setup using a different level of validation like DV.\nExtended validation is signaled in a certificate using X.509 v3 extension. Each CA uses a different Object Identifier (OID) to assert extended validation. There is no single OID to indicate extended validation, which complicates user agent programming. Each user agent must have a list of OIDs that indicate extended validation.\nThe CA/Browser Forum's PKI recognizes extended validation and many browsers provide visual feedback to the user to indicate a site provides an EV certificate. Other PKIs, like the Internet's PKI (PKIX), do not place any special emphasis on extended validation. Tools using PKIX policies, like cURL and Wget, simply treat an EV certificate like any other certificate.\nSecurity expert Peter Gutmann states CA's created EV certificates to restore profit levels after the Race to the Bottom cut into profits. During the race to the bottom CA's cut prices to lure consumers to purchase their certificates. As a result, profits were reduced and CA's dropped the level of validation they were performing to the point there were nearly no assurances on a certificate.\n\n\n*** Certificate filename extensions ***\nThere are several commonly used filename extensions for X.509 certificates. Unfortunately, some of these extensions are also used for other data such as private keys.\n\n.pem \u2013 (Privacy-enhanced Electronic Mail) Base64 encoded DER certificate, enclosed between -----BEGIN CERTIFICATE----- and -----END CERTIFICATE-----\n.cer, .crt, .der \u2013 usually in binary DER form, but Base64-encoded certificates are common too (see .pem above)\n.p7b, .p7c \u2013 PKCS#7 SignedData structure without data, just certificate(s) or CRL(s)\n.p12 \u2013 PKCS#12, may contain certificate(s) (public) and private keys (password protected)\n.pfx \u2013 PFX, predecessor of PKCS#12 (usually contains data in PKCS#12 format, e.g., with PFX files generated in IIS)PKCS#7 is a standard for signing or encrypting (officially called \"enveloping\") data. Since the certificate is needed to verify signed data, it is possible to include them in the SignedData structure. A .P7C file is a degenerated SignedData structure, without any data to sign.PKCS#12 evolved from the personal information exchange (PFX) standard and is used to exchange public and private objects in a single file.\n\n== Certificate chains and cross-certification ==\nA certificate chain (see the equivalent concept of \"certification path\" defined by RFC 5280 section 3.2) is a list of certificates (usually starting with an end-entity certificate) followed by one or more CA certificates (usually the last one being a self-signed certificate), with the following properties:\n\nThe Issuer of each certificate (except the last one) matches the Subject of the next certificate in the list\nEach certificate (except the last one) is signed by the secret key corresponding to the next certificate in the chain (i.e. the signature of one certificate can be verified using the public key contained in the following certificate)\nThe last certificate in the list is a trust anchor: a certificate that you trust because it was delivered to you by some trustworthy procedureCertificate chains are used in order to check that the public key (PK) contained in a target certificate (the first certificate in the chain) and other data contained in it effectively belongs to its subject. In order to ascertain this, the signature on the target certificate is verified by using the PK contained in the following certificate, whose signature is verified using the next certificate, and so on until the last certificate in the chain is reached. As the last certificate is a trust anchor, successfully reaching it will prove that the target certificate can be trusted.\nThe description in the preceding paragraph is a simplified view on the certification path validation process as defined by RFC 5280 section 6, which involves additional checks, such as verifying validity dates on certificates, looking up CRLs, etc.\n\nExamining how certificate chains are built and validated, it is important to note that a concrete certificate can be part of very different certificate chains (all of them valid). This is because several CA certificates can be generated for the same subject and public key, but be signed with different private keys (from different CAs or different private keys from the same CA). So, although a single X.509 certificate can have only one issuer and one CA signature, it can be validly linked to more than one certificate, building completely different certificate chains. This is crucial for cross-certification between PKIs and other applications.\nSee the following examples:\n\n\n*** Examples ***\nIn these diagrams:\n\nEach box represents a certificate, with its Subject in bold\nA \u2192 B means \"A is signed by B\" (or, more precisely, \"A is signed by the secret key corresponding to the public key contained in B\").\nCertificates with the same color (that are not white/transparent) contain the same public key\n\n\n**** Example 1: Cross-certification at root Certification Authority (CA) level between two PKIs ****\nIn order to manage that user certificates existing in PKI 2 (like \"User 2\") are trusted by PKI 1, CA1 generates a certificate (cert2.1) containing the public key of CA2.\nNow both \"cert2 and cert2.1 (in green) have the same subject and public key, so there are two valid chains for cert2.2 (User 2): \"cert2.2 \u2192 cert2\" and \"cert2.2 \u2192 cert2.1 \u2192 cert1\".\nSimilarly, CA2 can generate a certificate (cert1.1) containing the public key of CA1 so that user certificates existing in PKI 1 (like \"User 1\") are trusted by PKI 2.\n\n\n**** Example 2: CA certificate renewal ****\nUnderstanding Certification Path Construction (PDF). PKI Forum. September 2002. To allow for graceful transition from the old signing key pair to the new signing key pair, the CA should issue a certificate that contains the old public key signed by the new private signing key and a certificate that contains the new public key signed by the old private signing key. Both of these certificates are self-issued, but neither is self-signed. Note that these are in addition to the two self-signed certificates (one old, one new).\nSince both cert1 and cert3 contain the same public key (the old one), there are two valid certificate chains for cert5: \"cert5 \u2192 cert1\" and \"cert5 \u2192 cert3 \u2192 cert2\", and analogously for cert6. This allows that old user certificates (such as cert5) and new certificates (such as cert6) can be trusted indifferently by a party having either the new root CA certificate or the old one as trust anchor during the transition to the new CA keys.\n\n== Sample X.509 certificates ==\nThis is an example of a decoded X.509 certificate that was used in the past by wikipedia.org and several other Wikipedia websites. It was issued by GlobalSign, as stated in the Issuer field. Its Subject field describes Wikipedia as an organization, and its Subject Alternative Name (SAN) field for DNS describes the hostnames for which it could be used. The Subject Public Key Info field contains an ECDSA public key, while the signature at the bottom was generated by GlobalSign's RSA private key. (The signatures in these examples are truncated.)\n\n\n*** End-entity certificate ***\nCertificate:\n    Data:\n        Version: 3 (0x2)\n        Serial Number:\n            10:e6:fc:62:b7:41:8a:d5:00:5e:45:b6\n        Signature Algorithm: sha256WithRSAEncryption\n        Issuer: C\n\n== Security ==\nThere are a number of publications about PKI problems by Bruce Schneier, Peter Gutmann and other security experts.\n\n\n*** Architectural weaknesses ***\nUse of blocklisting invalid certificates (using CRLs and OCSP),\nIf the client only trusts certificates when CRLs are available, then they lose the offline capability that makes PKI attractive. So most clients do trust certificates when CRLs are not available, but in that case an attacker that controls the communication channel can disable the CRLs. Adam Langley of Google has said soft-fail CRL checks are like a safety belt that works except when you have an accident.\nCRLs are notably a poor choice because of large sizes and convoluted distribution patterns,\nAmbiguous OCSP semantics and lack of historical revocation status,\nRevocation of root certificates is not addressed,\nAggregation problem: Identity claims (authenticate with an identifier), attribute claims (submit a bag of vetted attributes), and policy claims are combined in a single container. This raises privacy, policy mapping, and maintenance issues.\nDelegation problem: CAs cannot technically restrict subordinate CAs from issuing certificates outside a limited namespaces or attribute set; this feature of X.509 is not in use. Therefore, a large number of CAs exist on the Internet, and classifying them and their policies is an insurmountable task. Delegation of authority within an organization cannot be handled at all, as in common business practice.\nFederation problem: Certificate chains that are the result of subordinate CAs, bridge CAs, and cross-signing make validation complex and expensive in terms of processing time. Path validation semantics may be ambiguous. The hierarchy with a third-party trusted party is the only model. This is inconvenient when a bilateral trust relationship is already in place.\nIssuance of an Extended Validation (EV) certificate for a hostname doesn't prevent issuance of a lower-validation certificate valid for the same hostname, which means that the higher validation level of EV doesn't protect against man-in-the-middle attacks.\n\n\n*** Problems with certification authorities ***\nThe person or organization that purchases a certificate will often utilize the least expensive certification authority. In response, CA's have cut prices and removed more expensive validation checks in what is known as a Race to the Bottom. The Race to the Bottom is partly addressed by Extended Validation (EV) certificates, yet trust value in the eyes of security experts are diminishing. According to Peter Gutmann, EV certificates do not add any additional security controls. Rather, EV certificates merely restore CA profits to levels prior to the Race to the Bottom by allowing a CA to charge more for a service they should have been providing all along.\nCertification authorities attempt to deny almost all warranties to the user and relying parties in their Certification Practice Statement (CPS). For example, Apple Inc states in their CPS, \"To the extent permitted by applicable law, Subscriber agreements, if applicable, disclaim warranties from Apple, including any warranty of merchantability or fitness for a particular purpose\".\nAccording to Peter Gutmann, \"Users use an undefined certification request protocol to obtain a certificate which is published in an unclear location in a nonexistent directory with no real means to revoke it\"\nLike all businesses, CAs are subject to the legal jurisdictions they operate within, and may be legally compelled to compromise the interests of their customers and their users. Intelligence agencies have also made use of false certificates issued through extralegal compromise of CAs, such as DigiNotar, to carry out man-in-the-middle attacks. Another example is a revocation request of the CA of the Dutch government, because of a Dutch law passed in 2018, giving new powers for the Dutch intelligence and security services\n\n\n*** Implementation issues ***\nImplementations suffer from design flaws, bugs, different interpretations of standards and lack of interoperability of different standards. Some problems are:\nMany implementations turn off revocation check:\nSeen as obstacle, policies are not enforced\nIf it was turned on in all browsers by default, including code signing, it would probably crash the infrastructure\nDNs are complex and little understood (lack of canonicalization, internationalization problems)\nrfc822Name has two notations\nName and policy constraints hardly supported\nKey usage ignored, first certificate in a list being used\nEnforcement of custom OIDs is difficult\nAttributes should not be made critical because it makes clients crash\nUnspecified length of attributes lead to product-specific limits\nThere are implementation errors with X.509 that allow e.g. falsified subject names using null-terminated strings or code injection attacks in certificates\nBy using illegal 0x80 padded subidentifiers of object identifiers, wrong implementations or by using integer overflows of the client's browsers, an attacker can include an unknown attribute in the CSR, which the CA will sign, which the client wrongly interprets as \"CN\" (OID\n\n== PKI standards for X.509 ==\nPKCS7 (Cryptographic Message Syntax Standard \u2014 public keys with proof of identity for signed and/or encrypted message for PKI)\nTransport Layer Security (TLS) and its predecessor SSL \u2014 cryptographic protocols for Internet secure communications.\nOnline Certificate Status Protocol (OCSP) / certificate revocation list (CRL) \u2014 this is to check certificate revocation status\nPKCS12 (Personal Information Exchange Syntax Standard) \u2014 used to store a private key with the appropriate public key certificate\nCertification Path Building \u2014 guidance and recommendations for building X.509 public-key certification paths within applications (i.e., validating an end-entity certificate using a CA certificate)\n\n== PKIX Working Group ==\nIn 1995, the Internet Engineering Task Force in conjunction with the National Institute of Standards and Technology formed the Public-Key Infrastructure (X.509) working group. The working group, concluded in June 2014, is commonly referred to as \"PKIX.\" It produced RFCs and other standards documentation on using and deploying X.509 in practice. In particular it produced RFC 3280 and its successor RFC 5280, which define how to use X.509 in Internet protocols.\n\n== Major protocols and standards using X.509 certificates ==\nTLS/SSL and HTTPS use the RFC 5280 profile of X.509, as do S/MIME (Secure Multipurpose Internet Mail Extensions) and the EAP-TLS method for WiFi authentication. Any protocol that uses TLS, such as SMTP, POP, IMAP, LDAP, XMPP, and many more, inherently uses X.509.\nIPsec can use the RFC 4945 profile for authenticating peers.\nThe OpenCable security specification defines its own profile of X.509 for use in the cable industry.\nDevices like smart cards and TPMs often carry certificates to identify themselves or their owners. These certificates are in X.509 form.\nThe WS-Security standard defines authentication either through TLS or through its own certificate profile. Both methods use X.509.\nThe Microsoft Authenticode code signing system uses X.509 to identify authors of computer programs.\nThe OPC UA industrial automation communication standard uses X.509.\nSSH generally uses a Trust On First Use security model and doesn't have need for certificates. However, the popular OpenSSH implementation does support a CA-signed identity model based on its own non-X.509 certificate format."
    }
  },
  {
    "instruction": "Context: Comodo Cybersecurity\n\n==Introduction==\nXcitium, formerly known as Comodo Security Solutions, Inc., is a cybersecurity company headquartered in Bloomfield, New Jersey.\n\n== Companies ==\nComodo CA Limited (Sectigo): Based in the City of Salford, Greater Manchester, UK, is a digital certificate authority that issues SSL and other digital certificates. In November 2018, Francisco Partners announced that Comodo Certificate Authority (Comodo CA) is rebranding as Sectigo.\nComodo Security Solutions, Inc: Based in Clifton, New Jersey, US, develops security software for commercial and consumer use.\nDNS.com: Based in Louisville, Kentucky, US, the company provides managed DNS services.\n\n== Industry affiliations ==\nComodo is a member of the following industry organizations:\n\nCertificate Authority Security Council (CASC): In February 2013, Comodo became a founding member of this industry advocacy organization dedicated to addressing industry issues and educating the public on internet security.\nCommon Computing Security Standards Forum (CCSF): In 2009 Comodo was a founding member of the CCSF, an industry organization that promotes industry standards that protect end users.  Comodo CEO Melih Abdulhayo\u011flu is considered the founder of the CCSF.\nCA/Browser Forum: In 2005, Comodo was a founding member of a new consortium of certificate authorities and web browser vendors dedicated to promoting industry standards and baseline requirements for internet security. Melih Abdulhayo\u011flu invited top browser providers and certification authorities to a round table to discuss the creation of a central authority responsible for delivering digital certificate issuance best practice guidelines.\n\n== Products ==\nComodo Dragon (web browser)\nComodo Ice Dragon (web browser)\nComodo Internet Security\nComodo System Utilities\nComodo Mobile Security\nComodo Endpoint Protection\nXcitium EDR\n\n== Controversies ==\n\n\n*** LinkedIn ***\nAfter a competitor commented on a Comodo employee posting that Comodo \"stops all malware\", the company CEO aggressively engaged on LinkedIn, such as insinuating that commenters were not qualified to work in cybersecurity, and replying to the majority of posts that the competitor's CEO was the one who \"started it\".\n\n\n*** Symantec ***\nIn response to Symantec's comment asserting paid antivirus is superior to free antivirus, the CEO of Comodo Group challenged Symantec on 18 September 2010 to see whether paid or free products can better defend the consumer against malware. GCN'S John Breeden understood Comodo's stance on free Antivirus software and challenging Symantec: \"This is actually a pretty smart move based on previous reviews of AV performance we've done in the GCN Lab. Our most recent AV review this year showed no functional difference between free and paid programs in terms of stopping viruses, and it's been that way for many years. In fact you have to go all the way back to 2006 to find an AV roundup where viruses were missed by some companies.\"Symantec responded saying that if Comodo is interested they should have their product included in tests by independent reviewers.Comodo volunteered to a Symantec vs. Comodo independent review.  Though this showdown did not take place, Comodo has since been included in multiple independent reviews with AV-Test, PC World, Best Antivirus Reviews, AV-Comparatives, and PC Mag.\n\n\n*** Certificate hacking ***\nOn 23 March 2011, Comodo posted a report that 8 days earlier, on 15 March 2011, a user account with an affiliate registration authority had been compromised and was used to create a new user account that issued nine certificate signing requests. Nine certificates for seven domains were issued. The attack was traced to IP address 212.95.136.18, which originates in Tehran, Iran. Moxie Marlinspike analyzed the IP address on his website the next day and found it to have English localization. Though the firm initially reported that the breach was the result of a \"state-driven attack\", it subsequently stated that the origin of the attack may be the \"result of an attacker attempting to lay a false trail.\".The attack was immediately thwarted, with Comodo revoking all of the bogus certificates. Comodo also stated that it was actively looking into ways to improve the security of its affiliates.In an update on 31 March 2011, Comodo stated that it detected and thwarted an intrusion into a reseller user account on 26 March 2011. The new controls implemented by Comodo following the incident on 15 March 2011, removed any risk of the fraudulent issue of certificates. Comodo believed the attack was from the same perpetrator as the incident on 15 March 2011.In regards to this second incident, Comodo stated, \"Our CA infrastructure was not compromised. Our keys in our HSMs were not compromised. No certificates have been fraudulently issued. The attempt to fraudulently access the certificate ordering platform to issue a certificate failed.\"\nOn 26 March 2011, a person under the username \"ComodoHacker\" verified that they were the attacker by posting the private keys online and posted a series of messages detailing how poor Comodo's security is and bragging about his abilities:I hacked Comodo from InstantSSL.it, their CEO's e-mail address mfpenco@mfpenco.com\nTheir Comodo username/password was: user: gtadmin password: globaltrust\nTheir DB name was: globaltrust and instantsslcms\nEnough said, huh? Yes, enough said, someone who should know already knows...\nAnyway, at first I should mention we have no relation to Iranian Cyber Army, we don't change DNSes, we\njust hack and own.\nI see Comodo CEO and other wrote that it was a managed attack, it was a planned attack, a group of\ncyber criminals did it, etc.\nLet me explain:\na) I'm not a group, I'm single hacker with experience of 1000 hacker, I'm single programmer with\nexperience of 1000 programmer, I'm single planner/project manager with experience of 1000 project\nmanagers, so you are right, it's managed by 1000 hackers, but it was only I with experience of 1000\n\nhackers.Such issues have been widely reported, and have led to criticism of how certificates are issued and revoked. As of 2016, all of the certificates remain revoked. Microsoft issued a security advisory and update to address the issue at the time of the event.For Comodo's lacking response on the issue computer security researcher Moxie Marlinspike called the whole event extremely embarrassing for Comodo and rethinking SSL security. It was also implied that the attacker followed an online video tutorial and searched for basic opsecSuch attacks are not unique to Comodo \u2013 the specifics will vary from CA to CA, RA to RA, but there are so many of these entities, all of them trusted by default, that further holes are deemed to be inevitable.\n\n\n*** Association with PrivDog ***\nIn February 2015, Comodo was associated with a man-in-the-middle enabling tool known as PrivDog, which claims to protect users against malicious advertising.PrivDog issued a statement on 23 February 2015, saying, \"A minor intermittent defect has been detected in a third party library used by the PrivDog standalone application which potentially affects a very small number of users. This potential issue is only present in PrivDog versions, 3.0.96.0 and 3.0.97.0. The potential issue is not present in the PrivDog plug-in that is distributed with Comodo Browsers, and Comodo has not distributed this version to its users. there are potentially a maximum of 6,294 users in the USA and 57,568 users globally that this could potentially impact. The third party library used by PrivDog is not the same third party library used by Superfish....The potential issue has already been corrected. There will be an update tomorrow which will automatically update all 57,568 users of these specific PrivDog versions.\"\n\n\n*** Certificates issued to known malware distributors ***\nIn 2009 Microsoft MVP Michael Burgess accused Comodo of issuing digital certificates to known malware distributors. Comodo responded when notified and revoked the certificates in question, which were used to sign the known malware.\n\n\n*** Chromodo browser, ACL, no ASLR, VNC weak authentication ***\nIn January 2016, Tavis Ormandy reported that Comodo's Chromodo browser exhibited a number of vulnerabilities, including disabling of the same-origin policy.The vulnerability wasn't in the browser itself, which was based on the open-source code behind Google's Chrome browser. Rather, the issue was with an add-on. As soon as Comodo became aware of the issue in early February 2016, the company released a statement and a fix: \"As an industry, software in general is always being updated, patched, fixed, addressed, improved \u2013 it goes hand in hand with any development cycle...What is critical in software development is how companies address an issue if a certain vulnerability is found \u2013 ensuring it never puts the customer at risk.\" Those using Chromodo immediately received an update. The Chromodo browser was subsequently discontinued by Comodo.\nOrmandy noted that Comodo received a \"Excellence in Information Security Testing\" award from Verizon despite the vulnerability in its browser, despite having its VNC delivered with a default of weak authentication, despite not enabling address space layout randomization (ASLR), and despite using access control lists (ACLs) throughout its product. Ormandy has the opinion that Verizon's certification methodology is at fault here.\n\n\n*** Let's Encrypt trademark registration application ***\nIn October 2015, Comodo applied for \"Let's Encrypt\", \"Comodo Let's Encrypt\", and \"Let's Encrypt with Comodo\" trademarks. These trademark applications were filed almost a year after the Internet Security Research Group, parent organization of Let's Encrypt, started using the name Let's Encrypt publicly in November 2014, and despite the fact Comodo's \"intent to use\" trademark filings acknowledge that it has never used \"Let's Encrypt\" as a brand.\nOn 24 June 2016, Comodo publicly posted in its forum that it had filed for \"express abandonment\" of their trademark applications.Comodo's Chief Technical Officer Robin Alden said, \"Comodo has filed for express abandonment of the trademark applications at this time instead of waiting and allowing them to lapse. Following collaboration between Let's Encrypt and Comodo, the trademark issue is now resolved and behind us, and we'd like to thank the Let's Encrypt team for helping to bring it to a resolution.\"\n\n\n*** Dangling markup injection vulnerability ***\nOn 25 July 2016, Matthew Bryant showed that Comodo's website is vulnerable to dangling markup injection attacks and can send emails to system administrators from Comodo's servers to approve a wildcard certificate issue request which can be used to issue arbitrary wildcard certificates via Comodo's 30-Day PositiveSSL product.Bryant reached out in June 2016, and on 25 July 2016, Comodo's Chief Technical Officer Robin Alden confirmed a fix was put in place, within the responsible disclosure date per industry standards.\n\nQuestion: What is the opinion of Tavis Ormandy regarding Verizon's certification methodology for software security?\n\nAnswer:",
    "context": "",
    "output": "Tavis Ormandy believes that Verizon's certification methodology is at fault for certifying software with known vulnerabilities.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the opinion of Tavis Ormandy regarding Verizon's certification methodology for software security?",
      "answer": "Tavis Ormandy believes that Verizon's certification methodology is at fault for certifying software with known vulnerabilities.",
      "context": "Comodo Cybersecurity\n\n==Introduction==\nXcitium, formerly known as Comodo Security Solutions, Inc., is a cybersecurity company headquartered in Bloomfield, New Jersey.\n\n== Companies ==\nComodo CA Limited (Sectigo): Based in the City of Salford, Greater Manchester, UK, is a digital certificate authority that issues SSL and other digital certificates. In November 2018, Francisco Partners announced that Comodo Certificate Authority (Comodo CA) is rebranding as Sectigo.\nComodo Security Solutions, Inc: Based in Clifton, New Jersey, US, develops security software for commercial and consumer use.\nDNS.com: Based in Louisville, Kentucky, US, the company provides managed DNS services.\n\n== Industry affiliations ==\nComodo is a member of the following industry organizations:\n\nCertificate Authority Security Council (CASC): In February 2013, Comodo became a founding member of this industry advocacy organization dedicated to addressing industry issues and educating the public on internet security.\nCommon Computing Security Standards Forum (CCSF): In 2009 Comodo was a founding member of the CCSF, an industry organization that promotes industry standards that protect end users.  Comodo CEO Melih Abdulhayo\u011flu is considered the founder of the CCSF.\nCA/Browser Forum: In 2005, Comodo was a founding member of a new consortium of certificate authorities and web browser vendors dedicated to promoting industry standards and baseline requirements for internet security. Melih Abdulhayo\u011flu invited top browser providers and certification authorities to a round table to discuss the creation of a central authority responsible for delivering digital certificate issuance best practice guidelines.\n\n== Products ==\nComodo Dragon (web browser)\nComodo Ice Dragon (web browser)\nComodo Internet Security\nComodo System Utilities\nComodo Mobile Security\nComodo Endpoint Protection\nXcitium EDR\n\n== Controversies ==\n\n\n*** LinkedIn ***\nAfter a competitor commented on a Comodo employee posting that Comodo \"stops all malware\", the company CEO aggressively engaged on LinkedIn, such as insinuating that commenters were not qualified to work in cybersecurity, and replying to the majority of posts that the competitor's CEO was the one who \"started it\".\n\n\n*** Symantec ***\nIn response to Symantec's comment asserting paid antivirus is superior to free antivirus, the CEO of Comodo Group challenged Symantec on 18 September 2010 to see whether paid or free products can better defend the consumer against malware. GCN'S John Breeden understood Comodo's stance on free Antivirus software and challenging Symantec: \"This is actually a pretty smart move based on previous reviews of AV performance we've done in the GCN Lab. Our most recent AV review this year showed no functional difference between free and paid programs in terms of stopping viruses, and it's been that way for many years. In fact you have to go all the way back to 2006 to find an AV roundup where viruses were missed by some companies.\"Symantec responded saying that if Comodo is interested they should have their product included in tests by independent reviewers.Comodo volunteered to a Symantec vs. Comodo independent review.  Though this showdown did not take place, Comodo has since been included in multiple independent reviews with AV-Test, PC World, Best Antivirus Reviews, AV-Comparatives, and PC Mag.\n\n\n*** Certificate hacking ***\nOn 23 March 2011, Comodo posted a report that 8 days earlier, on 15 March 2011, a user account with an affiliate registration authority had been compromised and was used to create a new user account that issued nine certificate signing requests. Nine certificates for seven domains were issued. The attack was traced to IP address 212.95.136.18, which originates in Tehran, Iran. Moxie Marlinspike analyzed the IP address on his website the next day and found it to have English localization. Though the firm initially reported that the breach was the result of a \"state-driven attack\", it subsequently stated that the origin of the attack may be the \"result of an attacker attempting to lay a false trail.\".The attack was immediately thwarted, with Comodo revoking all of the bogus certificates. Comodo also stated that it was actively looking into ways to improve the security of its affiliates.In an update on 31 March 2011, Comodo stated that it detected and thwarted an intrusion into a reseller user account on 26 March 2011. The new controls implemented by Comodo following the incident on 15 March 2011, removed any risk of the fraudulent issue of certificates. Comodo believed the attack was from the same perpetrator as the incident on 15 March 2011.In regards to this second incident, Comodo stated, \"Our CA infrastructure was not compromised. Our keys in our HSMs were not compromised. No certificates have been fraudulently issued. The attempt to fraudulently access the certificate ordering platform to issue a certificate failed.\"\nOn 26 March 2011, a person under the username \"ComodoHacker\" verified that they were the attacker by posting the private keys online and posted a series of messages detailing how poor Comodo's security is and bragging about his abilities:I hacked Comodo from InstantSSL.it, their CEO's e-mail address mfpenco@mfpenco.com\nTheir Comodo username/password was: user: gtadmin password: globaltrust\nTheir DB name was: globaltrust and instantsslcms\nEnough said, huh? Yes, enough said, someone who should know already knows...\nAnyway, at first I should mention we have no relation to Iranian Cyber Army, we don't change DNSes, we\njust hack and own.\nI see Comodo CEO and other wrote that it was a managed attack, it was a planned attack, a group of\ncyber criminals did it, etc.\nLet me explain:\na) I'm not a group, I'm single hacker with experience of 1000 hacker, I'm single programmer with\nexperience of 1000 programmer, I'm single planner/project manager with experience of 1000 project\nmanagers, so you are right, it's managed by 1000 hackers, but it was only I with experience of 1000\n\nhackers.Such issues have been widely reported, and have led to criticism of how certificates are issued and revoked. As of 2016, all of the certificates remain revoked. Microsoft issued a security advisory and update to address the issue at the time of the event.For Comodo's lacking response on the issue computer security researcher Moxie Marlinspike called the whole event extremely embarrassing for Comodo and rethinking SSL security. It was also implied that the attacker followed an online video tutorial and searched for basic opsecSuch attacks are not unique to Comodo \u2013 the specifics will vary from CA to CA, RA to RA, but there are so many of these entities, all of them trusted by default, that further holes are deemed to be inevitable.\n\n\n*** Association with PrivDog ***\nIn February 2015, Comodo was associated with a man-in-the-middle enabling tool known as PrivDog, which claims to protect users against malicious advertising.PrivDog issued a statement on 23 February 2015, saying, \"A minor intermittent defect has been detected in a third party library used by the PrivDog standalone application which potentially affects a very small number of users. This potential issue is only present in PrivDog versions, 3.0.96.0 and 3.0.97.0. The potential issue is not present in the PrivDog plug-in that is distributed with Comodo Browsers, and Comodo has not distributed this version to its users. there are potentially a maximum of 6,294 users in the USA and 57,568 users globally that this could potentially impact. The third party library used by PrivDog is not the same third party library used by Superfish....The potential issue has already been corrected. There will be an update tomorrow which will automatically update all 57,568 users of these specific PrivDog versions.\"\n\n\n*** Certificates issued to known malware distributors ***\nIn 2009 Microsoft MVP Michael Burgess accused Comodo of issuing digital certificates to known malware distributors. Comodo responded when notified and revoked the certificates in question, which were used to sign the known malware.\n\n\n*** Chromodo browser, ACL, no ASLR, VNC weak authentication ***\nIn January 2016, Tavis Ormandy reported that Comodo's Chromodo browser exhibited a number of vulnerabilities, including disabling of the same-origin policy.The vulnerability wasn't in the browser itself, which was based on the open-source code behind Google's Chrome browser. Rather, the issue was with an add-on. As soon as Comodo became aware of the issue in early February 2016, the company released a statement and a fix: \"As an industry, software in general is always being updated, patched, fixed, addressed, improved \u2013 it goes hand in hand with any development cycle...What is critical in software development is how companies address an issue if a certain vulnerability is found \u2013 ensuring it never puts the customer at risk.\" Those using Chromodo immediately received an update. The Chromodo browser was subsequently discontinued by Comodo.\nOrmandy noted that Comodo received a \"Excellence in Information Security Testing\" award from Verizon despite the vulnerability in its browser, despite having its VNC delivered with a default of weak authentication, despite not enabling address space layout randomization (ASLR), and despite using access control lists (ACLs) throughout its product. Ormandy has the opinion that Verizon's certification methodology is at fault here.\n\n\n*** Let's Encrypt trademark registration application ***\nIn October 2015, Comodo applied for \"Let's Encrypt\", \"Comodo Let's Encrypt\", and \"Let's Encrypt with Comodo\" trademarks. These trademark applications were filed almost a year after the Internet Security Research Group, parent organization of Let's Encrypt, started using the name Let's Encrypt publicly in November 2014, and despite the fact Comodo's \"intent to use\" trademark filings acknowledge that it has never used \"Let's Encrypt\" as a brand.\nOn 24 June 2016, Comodo publicly posted in its forum that it had filed for \"express abandonment\" of their trademark applications.Comodo's Chief Technical Officer Robin Alden said, \"Comodo has filed for express abandonment of the trademark applications at this time instead of waiting and allowing them to lapse. Following collaboration between Let's Encrypt and Comodo, the trademark issue is now resolved and behind us, and we'd like to thank the Let's Encrypt team for helping to bring it to a resolution.\"\n\n\n*** Dangling markup injection vulnerability ***\nOn 25 July 2016, Matthew Bryant showed that Comodo's website is vulnerable to dangling markup injection attacks and can send emails to system administrators from Comodo's servers to approve a wildcard certificate issue request which can be used to issue arbitrary wildcard certificates via Comodo's 30-Day PositiveSSL product.Bryant reached out in June 2016, and on 25 July 2016, Comodo's Chief Technical Officer Robin Alden confirmed a fix was put in place, within the responsible disclosure date per industry standards."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are the vulnerabilities of MBAL in terms of cryptanalysis?",
    "context": "",
    "output": "MBAL has been shown to be susceptible to both differential cryptanalysis and linear cryptanalysis.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are the vulnerabilities of MBAL in terms of cryptanalysis?",
      "answer": "MBAL has been shown to be susceptible to both differential cryptanalysis and linear cryptanalysis."
    }
  },
  {
    "instruction": "Write an answer to the following question: What was Project Chanology, and how did it respond to the Church of Scientology's actions?",
    "context": "",
    "output": "Project Chanology was a series of denial-of-service attacks against Scientology websites, prank calls, and black faxes to Scientology centers. This was Anonymous' response to the Church of Scientology issuing a copyright violation claim against YouTube for a leaked video featuring Tom Cruise. Anonymous saw this action as a form of Internet censorship.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was Project Chanology, and how did it respond to the Church of Scientology's actions?",
      "answer": "Project Chanology was a series of denial-of-service attacks against Scientology websites, prank calls, and black faxes to Scientology centers. This was Anonymous' response to the Church of Scientology issuing a copyright violation claim against YouTube for a leaked video featuring Tom Cruise. Anonymous saw this action as a form of Internet censorship."
    }
  },
  {
    "instruction": "Write an answer to the following question: What was the MOD's response to overhearing LOD's plans for a security company?",
    "context": "",
    "output": "After eavesdropping on Chris Goggans's phone calls and discovering the plan for a security company, ComSec, the MOD continued to monitor the situation and escalate the war through prank calls and other means.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was the MOD's response to overhearing LOD's plans for a security company?",
      "answer": "After eavesdropping on Chris Goggans's phone calls and discovering the plan for a security company, ComSec, the MOD continued to monitor the situation and escalate the war through prank calls and other means."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does Exec Shield affect the virtual memory layout of applications?",
    "context": "",
    "output": "Exec Shield works on all x86 CPUs utilizing the Code Segment limit. However, it won't fully protect arbitrary virtual memory layouts. If the CS limit is raised, for example by calling mprotect() to make higher memory executable, then the protections are lost below that limit.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does Exec Shield affect the virtual memory layout of applications?",
      "answer": "Exec Shield works on all x86 CPUs utilizing the Code Segment limit. However, it won't fully protect arbitrary virtual memory layouts. If the CS limit is raised, for example by calling mprotect() to make higher memory executable, then the protections are lost below that limit."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the role of the Central Management System (CMS) in managing security operations at FireEye?",
    "context": "",
    "output": "The Central Management System (CMS) consolidates the management, reporting, and data sharing of Web MPS, Email MPS, File MPS, and Malware Analysis System (MAS) into a single network-based appliance, acting as a distribution hub for malware security intelligence.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of the Central Management System (CMS) in managing security operations at FireEye?",
      "answer": "The Central Management System (CMS) consolidates the management, reporting, and data sharing of Web MPS, Email MPS, File MPS, and Malware Analysis System (MAS) into a single network-based appliance, acting as a distribution hub for malware security intelligence."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is a potential vulnerability of deep learning approaches for detecting DGA domain names?",
    "context": "",
    "output": "Deep learning approaches can be vulnerable to adversarial techniques, making their effectiveness in a real-world scenario subject to certain limitations.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is a potential vulnerability of deep learning approaches for detecting DGA domain names?",
      "answer": "Deep learning approaches can be vulnerable to adversarial techniques, making their effectiveness in a real-world scenario subject to certain limitations."
    }
  },
  {
    "instruction": "Write an answer to the following question: Which encryption algorithm was developed by IBM in the 1970s and was the first widely used symmetric-key encryption algorithm?",
    "context": "",
    "output": "The Data Encryption Standard (DES) was developed by IBM in the 1970s and was the first widely used symmetric-key encryption algorithm.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Which encryption algorithm was developed by IBM in the 1970s and was the first widely used symmetric-key encryption algorithm?",
      "answer": "The Data Encryption Standard (DES) was developed by IBM in the 1970s and was the first widely used symmetric-key encryption algorithm."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the difference between a dictionary attack and a brute force attack?",
    "context": "",
    "output": "A dictionary attack is a type of brute force attack, but it is more sophisticated and targeted. While a brute force attack tries every possible combination of characters, a dictionary attack only tries those combinations that are deemed most likely to succeed, based on pre-arranged listings of words and passwords. This makes dictionary attacks more efficient and more likely to succeed than a brute force attack.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the difference between a dictionary attack and a brute force attack?",
      "answer": "A dictionary attack is a type of brute force attack, but it is more sophisticated and targeted. While a brute force attack tries every possible combination of characters, a dictionary attack only tries those combinations that are deemed most likely to succeed, based on pre-arranged listings of words and passwords. This makes dictionary attacks more efficient and more likely to succeed than a brute force attack."
    }
  },
  {
    "instruction": "Identity Governance Framework\n\n==Introduction==\nThe Identity Governance Framework was a project of the Liberty Alliance for standards to help enterprises determine and control how identity information is used, stored, and propagated using protocols such as LDAP, SAML, and WS-Trust and ID-WSF.\n\n\n\n== Purpose ==\nThe Identity Governance Framework (IGF) enables organizations to define policies that regulate and control the exchange of identity information between application systems both internally and with external partners. Identity information may include things like names, addresses, social security numbers or other information that would be otherwise considered related to an individual's identity.\nThe policy information is both useful to privacy auditors for assessing the use of identity information in applications and to policy enforcement systems for ensuring that appropriate use of identity information takes place.\n\nHow does the IGF help organizations assess the use of identity information in applications?",
    "context": "",
    "output": "A: The IGF helps organizations assess the use of identity information in applications by providing policy information that can be used by privacy auditors. This helps ensure that the use of sensitive information is in compliance with relevant laws and regulations.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the IGF help organizations assess the use of identity information in applications?",
      "answer": "The IGF helps organizations assess the use of identity information in applications by providing policy information that can be used by privacy auditors. This helps ensure that the use of sensitive information is in compliance with relevant laws and regulations.",
      "context": "Identity Governance Framework\n\n==Introduction==\nThe Identity Governance Framework was a project of the Liberty Alliance for standards to help enterprises determine and control how identity information is used, stored, and propagated using protocols such as LDAP, SAML, and WS-Trust and ID-WSF.\n\n\n\n== Purpose ==\nThe Identity Governance Framework (IGF) enables organizations to define policies that regulate and control the exchange of identity information between application systems both internally and with external partners. Identity information may include things like names, addresses, social security numbers or other information that would be otherwise considered related to an individual's identity.\nThe policy information is both useful to privacy auditors for assessing the use of identity information in applications and to policy enforcement systems for ensuring that appropriate use of identity information takes place."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the significance of semantic security compared to perfect secrecy?",
    "context": "",
    "output": "Semantic security is a weaker notion than perfect secrecy, as it allows for a negligible amount of information to be extracted from the ciphertext. However, it is more practical for real-world scenarios, as perfect secrecy often comes at the cost of efficiency.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the significance of semantic security compared to perfect secrecy?",
      "answer": "Semantic security is a weaker notion than perfect secrecy, as it allows for a negligible amount of information to be extracted from the ciphertext. However, it is more practical for real-world scenarios, as perfect secrecy often comes at the cost of efficiency."
    }
  },
  {
    "instruction": "SAINT (software)\n\n==Introduction==\nSAINT (Security Administrator\u2019s Integrated Network Tool) is computer software used for scanning computer networks for security vulnerabilities, and exploiting found vulnerabilities.\n\n\n\n== SAINT Network Vulnerability Scanner ==\nThe SAINT scanner screens every live system on a network for TCP and UDP services. For each service it finds running, it launches a set of probes designed to detect anything that could allow an attacker to gain unauthorized access, create a denial-of-service, or gain sensitive information about the network.SAINT provides support to the Security Content Automation Protocol (SCAP) specification as an Unauthenticated Vulnerability Scanner and Authenticated Vulnerability and Patch Scanner. SAINT is also an approved scanning vendor with the Payment Card Industry (PCI).The Four Steps of a SAINT Scan:\n\nStep 1 \u2013 SAINT screens every live system on a network for TCP and UDP services.\nStep 2 \u2013 For each service it finds running, it launches a set of probes designed to detect anything that could allow an attacker to gain unauthorized access, create a denial-of-service, or gain sensitive information about the network.\nStep 3 \u2013 The scanner checks for vulnerabilities.\nStep 4 \u2013 When vulnerabilities are detected, the results are categorized in several ways, allowing customers to target the data they find most useful.SAINT can group vulnerabilities according to severity, type, or count. It can also provide information about a particular host or group of hosts. SAINT describes each of the vulnerabilities it locates; references Common Vulnerabilities and Exposures (CVE), CERT advisories, and IAVA (Information Assurance Vulnerability Alerts); and describes ways to correct the vulnerabilities. In many cases, the SAINT scanner provides links to patches or new software versions that will eliminate the detected vulnerabilities.A vulnerability is a flaw in a system, device, or application that, if leveraged by an attacker, could impact the security of the system. Exploits take advantage of a vulnerability by compromising or destructing the vulnerable system, device, or application. Remediation is the process of repairing or providing a remedy for a vulnerability, thereby eliminating the risk of being exploited. Vulnerability scanning is used to identify and evaluate the security posture of a network. Historically, scanners were developed for specific purposes such as scanning only Windows desktops, applications, or network devices. SAINT offers heterogeneous scanning that identifies vulnerabilities across operating systems, desktop applications, network devices, Web applications, databases, and more.\n\n== SAINTexploit Penetration Testing Tool ==\nThe integrated penetration testing tool, SAINTexploit, demonstrates the path an attacker could use to breach a network and quantifies the risk to the network. SAINTexploit includes a Web site emulator and e-mail forgery tool.Penetration testing tools from SAINT are designed to simulate both internal and external real-world attacks. This type of testing identifies the methods of gaining access to a target and understanding the techniques used by attackers. There are many levels and types of penetration testing and the scope of the project should be well defined. Targets included in the scope could include popular protocols, network devices, databases, Web applications, desktop applications, and various flavors of operating systems.\nSAINT focuses on the development of exploits where a shell can be established. A shell, or shellcode, is where all exploits included offer a command shell/direct connection to the target from the computer performing the testing. Exploits target operating systems, desktop applications, databases, Web applications, protocols, and network devices. The most common exploit types included in SAINTexploit include the following:\n\u2022 Remote Exploit \u2013 These attacks are launched across the Internet or network against a vulnerable target without the user having previous access to the system.\n\u2022 Client Exploit \u2013 The victim must access the attacker\u2019s resource for a successful attack to take place. Common client exploits include e-mail forgery attacks, enticing the user to visit a Web site, or to open a file.\n\u2022 Local Exploit \u2013 In order to launch a local attack, the attacker must have previous access to the victim. (Also known as privilege elevation and tunneling). In this case, the victim's machine is used as the launch pad for connecting to other vulnerable targets.\n\n== SAINTmanager Remote Management Console ==\nSAINT\u2019s remote management console, SAINTmanager, enables enterprise-wide vulnerability scanning. The browser-based console provides the ability to centrally manage an entire network of SAINT vulnerability scanners from a single interface.\n\n== SAINTCloud ==\nSAINTCloud enables cloud based vulnerability scanning, penetration testing, and compliance audits without having to download and install software.\nRead the text above and answer this question: What is SAINTCloud and what are its benefits?",
    "context": "",
    "output": "SAINTCloud is a cloud-based vulnerability scanning, penetration testing, and compliance auditing solution that eliminates the need for software downloads and installations, providing flexibility and convenience for organizations.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is SAINTCloud and what are its benefits?",
      "answer": "SAINTCloud is a cloud-based vulnerability scanning, penetration testing, and compliance auditing solution that eliminates the need for software downloads and installations, providing flexibility and convenience for organizations.",
      "context": "SAINT (software)\n\n==Introduction==\nSAINT (Security Administrator\u2019s Integrated Network Tool) is computer software used for scanning computer networks for security vulnerabilities, and exploiting found vulnerabilities.\n\n\n\n== SAINT Network Vulnerability Scanner ==\nThe SAINT scanner screens every live system on a network for TCP and UDP services. For each service it finds running, it launches a set of probes designed to detect anything that could allow an attacker to gain unauthorized access, create a denial-of-service, or gain sensitive information about the network.SAINT provides support to the Security Content Automation Protocol (SCAP) specification as an Unauthenticated Vulnerability Scanner and Authenticated Vulnerability and Patch Scanner. SAINT is also an approved scanning vendor with the Payment Card Industry (PCI).The Four Steps of a SAINT Scan:\n\nStep 1 \u2013 SAINT screens every live system on a network for TCP and UDP services.\nStep 2 \u2013 For each service it finds running, it launches a set of probes designed to detect anything that could allow an attacker to gain unauthorized access, create a denial-of-service, or gain sensitive information about the network.\nStep 3 \u2013 The scanner checks for vulnerabilities.\nStep 4 \u2013 When vulnerabilities are detected, the results are categorized in several ways, allowing customers to target the data they find most useful.SAINT can group vulnerabilities according to severity, type, or count. It can also provide information about a particular host or group of hosts. SAINT describes each of the vulnerabilities it locates; references Common Vulnerabilities and Exposures (CVE), CERT advisories, and IAVA (Information Assurance Vulnerability Alerts); and describes ways to correct the vulnerabilities. In many cases, the SAINT scanner provides links to patches or new software versions that will eliminate the detected vulnerabilities.A vulnerability is a flaw in a system, device, or application that, if leveraged by an attacker, could impact the security of the system. Exploits take advantage of a vulnerability by compromising or destructing the vulnerable system, device, or application. Remediation is the process of repairing or providing a remedy for a vulnerability, thereby eliminating the risk of being exploited. Vulnerability scanning is used to identify and evaluate the security posture of a network. Historically, scanners were developed for specific purposes such as scanning only Windows desktops, applications, or network devices. SAINT offers heterogeneous scanning that identifies vulnerabilities across operating systems, desktop applications, network devices, Web applications, databases, and more.\n\n== SAINTexploit Penetration Testing Tool ==\nThe integrated penetration testing tool, SAINTexploit, demonstrates the path an attacker could use to breach a network and quantifies the risk to the network. SAINTexploit includes a Web site emulator and e-mail forgery tool.Penetration testing tools from SAINT are designed to simulate both internal and external real-world attacks. This type of testing identifies the methods of gaining access to a target and understanding the techniques used by attackers. There are many levels and types of penetration testing and the scope of the project should be well defined. Targets included in the scope could include popular protocols, network devices, databases, Web applications, desktop applications, and various flavors of operating systems.\nSAINT focuses on the development of exploits where a shell can be established. A shell, or shellcode, is where all exploits included offer a command shell/direct connection to the target from the computer performing the testing. Exploits target operating systems, desktop applications, databases, Web applications, protocols, and network devices. The most common exploit types included in SAINTexploit include the following:\n\u2022 Remote Exploit \u2013 These attacks are launched across the Internet or network against a vulnerable target without the user having previous access to the system.\n\u2022 Client Exploit \u2013 The victim must access the attacker\u2019s resource for a successful attack to take place. Common client exploits include e-mail forgery attacks, enticing the user to visit a Web site, or to open a file.\n\u2022 Local Exploit \u2013 In order to launch a local attack, the attacker must have previous access to the victim. (Also known as privilege elevation and tunneling). In this case, the victim's machine is used as the launch pad for connecting to other vulnerable targets.\n\n== SAINTmanager Remote Management Console ==\nSAINT\u2019s remote management console, SAINTmanager, enables enterprise-wide vulnerability scanning. The browser-based console provides the ability to centrally manage an entire network of SAINT vulnerability scanners from a single interface.\n\n== SAINTCloud ==\nSAINTCloud enables cloud based vulnerability scanning, penetration testing, and compliance audits without having to download and install software."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the difference between certification path construction and certification path validation?",
    "context": "",
    "output": "Certification path construction involves determining the path between an X.509 digital certificate and a trusted root, while certification path validation involves checking the certification path for validity according to a particular validation policy.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the difference between certification path construction and certification path validation?",
      "answer": "Certification path construction involves determining the path between an X.509 digital certificate and a trusted root, while certification path validation involves checking the certification path for validity according to a particular validation policy."
    }
  },
  {
    "instruction": "FRISK Software International\n\n==Introduction==\nFRISK Software International (established in 1993) was an Icelandic software company that developed F-Prot antivirus and F-Prot AVES antivirus and anti-spam service. The company was founded in 1993. It was acquired by Cyren in 2012.\n\n== F-Prot Antivirus ==\nF-Prot Antivirus (stylized F-PROT) is an antivirus product developed by FRISK Software International. It is available in related versions for several platforms. It is available for Microsoft Windows, Microsoft Exchange Server, Linux, Solaris, AIX and IBM eServers.\nFRISK Software International allows others to develop applications using their scanning engine, through the use of a SDK. Many software vendors use the F-Prot Antivirus engine, including SUSE.\nF-Prot Antivirus reached end-of-life on July 31st 2021 and is no longer maintained.\n\n== Fri\u00f0rik Sk\u00falason ==\nFri\u00f0rik Sk\u00falason, also sometimes known as \"Frisk\", is the founder of FRISK Software International and one of the founding members of CARO (Computer Antivirus Research Organization).\nHe originally developed F-Prot Antivirus while doing computer support work. He was, for many years, the technical editor of the Virus Bulletin. Sk\u00falason served as the head of FRISK Software International until its eventual acquisition by Cyren in 2012, after which he joined Cyren as the vice-president of Antivirus technologies.\n\nAnswer this question based on the above context: What is the significance of Fri\u00f0rik Sk\u00falason being a member of CARO?",
    "context": "",
    "output": "Fri\u00f0rik Sk\u00falason being a member of CARO indicates his expertise and involvement in the field of computer antivirus research.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the significance of Fri\u00f0rik Sk\u00falason being a member of CARO?",
      "answer": "Fri\u00f0rik Sk\u00falason being a member of CARO indicates his expertise and involvement in the field of computer antivirus research.",
      "context": "FRISK Software International\n\n==Introduction==\nFRISK Software International (established in 1993) was an Icelandic software company that developed F-Prot antivirus and F-Prot AVES antivirus and anti-spam service. The company was founded in 1993. It was acquired by Cyren in 2012.\n\n== F-Prot Antivirus ==\nF-Prot Antivirus (stylized F-PROT) is an antivirus product developed by FRISK Software International. It is available in related versions for several platforms. It is available for Microsoft Windows, Microsoft Exchange Server, Linux, Solaris, AIX and IBM eServers.\nFRISK Software International allows others to develop applications using their scanning engine, through the use of a SDK. Many software vendors use the F-Prot Antivirus engine, including SUSE.\nF-Prot Antivirus reached end-of-life on July 31st 2021 and is no longer maintained.\n\n== Fri\u00f0rik Sk\u00falason ==\nFri\u00f0rik Sk\u00falason, also sometimes known as \"Frisk\", is the founder of FRISK Software International and one of the founding members of CARO (Computer Antivirus Research Organization).\nHe originally developed F-Prot Antivirus while doing computer support work. He was, for many years, the technical editor of the Virus Bulletin. Sk\u00falason served as the head of FRISK Software International until its eventual acquisition by Cyren in 2012, after which he joined Cyren as the vice-president of Antivirus technologies."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does DirectAccess handle the client's operating system compatibility?",
    "context": "",
    "output": "DirectAccess supports Windows 7 and Windows 8 \"Enterprise\" edition clients, and with Windows Server 2012, DirectAccess is fully integrated into the operating system and provides native IPv6 and IPv4 support.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does DirectAccess handle the client's operating system compatibility?",
      "answer": "DirectAccess supports Windows 7 and Windows 8 \"Enterprise\" edition clients, and with Windows Server 2012, DirectAccess is fully integrated into the operating system and provides native IPv6 and IPv4 support."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the feature of Bitvise software that provides two-factor authentication and compatibility with RFC 6238 authenticator apps?",
    "context": "",
    "output": "The TCP/IP tunneling feature of Bitvise software provides two-factor authentication and compatibility with RFC 6238 authenticator apps.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the feature of Bitvise software that provides two-factor authentication and compatibility with RFC 6238 authenticator apps?",
      "answer": "The TCP/IP tunneling feature of Bitvise software provides two-factor authentication and compatibility with RFC 6238 authenticator apps."
    }
  },
  {
    "instruction": "Write an answer to the following question: Why do many websites enforce complex composition rules for passwords?",
    "context": "",
    "output": "Many websites enforce complex composition rules for passwords based on a 2003 report by the National Institute of Standards and Technology (NIST), but these rules have been criticized for having the opposite effect on security and leading to harder-to-remember passwords that are easy to crack.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Why do many websites enforce complex composition rules for passwords?",
      "answer": "Many websites enforce complex composition rules for passwords based on a 2003 report by the National Institute of Standards and Technology (NIST), but these rules have been criticized for having the opposite effect on security and leading to harder-to-remember passwords that are easy to crack."
    }
  },
  {
    "instruction": "Application protocol-based intrusion detection system\n\n==Introduction==\nAn application protocol-based intrusion detection system (APIDS) is an intrusion detection system that focuses its monitoring and analysis on a specific application protocol or protocols in use by the computing system.\n\n\n\n== Overview ==\nAn APIDS will monitor the dynamic behavior and state of the protocol and will typically consist of a system or agent that would typically sit between a process, or group of servers, monitoring and analyzing the application protocol between two connected devices.\nA typical place for an APIDS would be between a web server and the database management system, monitoring the SQL protocol specific to the middleware/business logic as it interacts with the database.\n\n== Monitoring dynamic behavior ==\nAt a basic level an APIDS would look for, and enforce, the correct (legal) use of the protocol.\nHowever at a more advanced level the APIDS can learn, be taught or even reduce what is often an infinite protocol set, to an acceptable understanding of the subset of that application protocol that is used by the application being monitored/protected.\nThus, an APIDS, correctly configured, will allow an application to be \"fingerprinted\", thus should that application be subverted or changed, so will the fingerprint change.\n\nBased on the above text, answer a question. What is the role of an APIDS in monitoring the application protocol between two connected devices?",
    "context": "",
    "output": "An APIDS sits between two connected devices and monitors and analyzes the application protocol, enforcing the correct use of the protocol. It can also learn and reduce the protocol set to an acceptable understanding of the subset of the application protocol used by the monitored application.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of an APIDS in monitoring the application protocol between two connected devices?",
      "answer": "An APIDS sits between two connected devices and monitors and analyzes the application protocol, enforcing the correct use of the protocol. It can also learn and reduce the protocol set to an acceptable understanding of the subset of the application protocol used by the monitored application.",
      "context": "Application protocol-based intrusion detection system\n\n==Introduction==\nAn application protocol-based intrusion detection system (APIDS) is an intrusion detection system that focuses its monitoring and analysis on a specific application protocol or protocols in use by the computing system.\n\n\n\n== Overview ==\nAn APIDS will monitor the dynamic behavior and state of the protocol and will typically consist of a system or agent that would typically sit between a process, or group of servers, monitoring and analyzing the application protocol between two connected devices.\nA typical place for an APIDS would be between a web server and the database management system, monitoring the SQL protocol specific to the middleware/business logic as it interacts with the database.\n\n== Monitoring dynamic behavior ==\nAt a basic level an APIDS would look for, and enforce, the correct (legal) use of the protocol.\nHowever at a more advanced level the APIDS can learn, be taught or even reduce what is often an infinite protocol set, to an acceptable understanding of the subset of that application protocol that is used by the application being monitored/protected.\nThus, an APIDS, correctly configured, will allow an application to be \"fingerprinted\", thus should that application be subverted or changed, so will the fingerprint change."
    }
  },
  {
    "instruction": "Secure telephone\n\n==Introduction==\nA secure telephone is a telephone that provides voice security in the form of end-to-end encryption for the telephone call, and in some cases also the mutual authentication of the call parties, protecting them against a man-in-the-middle attack. Concerns about massive growth of telephone tapping incidents led to growing demand for secure telephones.\nThe practical availability of secure telephones is restricted by several factors; notably politics, export issues, incompatibility between different products (the devices on each side of the call have to use the same protocol), and high (though recently decreasing) price of the devices.\n\n== Well-known products ==\nThe best-known product on the US government market is the STU-III family. However, this system has now been replaced by the Secure Terminal Equipment (STE) and SCIP standards which defines specifications for the design of equipment to secure both data and voice. The SCIP standard was developed by the NSA and the US DOD to derive more interoperability between secure communication equipment. A new family of standard secure phones has been developed based on Philip Zimmermann's VoIP encryption standard ZRTP.\n\n== VoIP and direct connection phones ==\nAs the popularity of VoIP grows, secure telephony is becoming more widely used. Many major hardware and software providers offer it as a standard feature at no extra cost.\nExamples include the Gizmo5 and Twinkle. Both of the former work with offerings from the founder of PGP, Phil Zimmermann, and his VoIP secure protocol, ZRTP. ZRTP is implemented in, amongst others, Ripcord Networks product SecurePC with up to NSA Suite B compliant Elliptic Curve math libraries. ZRTP is also being made available for mobile GSM CSD as a new standard for non-VoIP secure calls.\nThe U.S. National Security Agency is developing a secure phone based on Google's Android called Fishbowl.\n\n== Historically significant products ==\n\nScramblers were used to secure voice traffic during World War II, but were often intercepted and decoded due to scrambling's inherent insecurity. The first true secure telephone was SIGSALY, a massive device that weighed over 50 tons. The NSA, formed after World War II, developed a series of secure telephones, including the STU I, STU II and STU-III, as well as voice encryption devices for military telephones.\nIn 1989 an Irish company called Intrepid developed one of the most advanced secure phones. Called Milcode, the phone was the first to implement code-excited linear prediction (or CELP) which dramatically improved voice quality and user operability over previous LPC (Linear Predictive Coding) and LPC-10e versions.\nMilcode also boasted significantly higher levels of security than previous secure telephones. The base model offered a proprietary encryption algorithm with a key length of 512 bits, and a more advanced model with a key length of 1024 bits. Key exchange used a public key, based on Diffie-Hellman, as opposed to a plug-in datakey. A new key was generated for each phone call. Milcode was also able to encrypt fax and data and was electromagnetically shielded to NATO TEMPEST standards.\nOther products of historical significance are PGPfone and Nautilus (designed as a non-key escrow alternative to Clipper, now officially discontinued, but still available on SourceForge), SpeakFreely, and the security VoIP protocol wrapper Zfone developed by the creator of PGP.\nScrambling, generally using a form of voice inversion, was available from electronic hobbyist kit suppliers and is common on FRS radios. Analog scrambling is still used, as some telecommunications circuits, such as HF links and telephone lines in the developing world, are of very low quality.\n\nQ: What is the Fishbowl and what is its significance in secure telephony?",
    "context": "",
    "output": "A: The Fishbowl is a secure phone being developed by the U.S. National Security Agency based on Google's Android.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the Fishbowl and what is its significance in secure telephony?",
      "answer": "The Fishbowl is a secure phone being developed by the U.S. National Security Agency based on Google's Android.",
      "context": "Secure telephone\n\n==Introduction==\nA secure telephone is a telephone that provides voice security in the form of end-to-end encryption for the telephone call, and in some cases also the mutual authentication of the call parties, protecting them against a man-in-the-middle attack. Concerns about massive growth of telephone tapping incidents led to growing demand for secure telephones.\nThe practical availability of secure telephones is restricted by several factors; notably politics, export issues, incompatibility between different products (the devices on each side of the call have to use the same protocol), and high (though recently decreasing) price of the devices.\n\n== Well-known products ==\nThe best-known product on the US government market is the STU-III family. However, this system has now been replaced by the Secure Terminal Equipment (STE) and SCIP standards which defines specifications for the design of equipment to secure both data and voice. The SCIP standard was developed by the NSA and the US DOD to derive more interoperability between secure communication equipment. A new family of standard secure phones has been developed based on Philip Zimmermann's VoIP encryption standard ZRTP.\n\n== VoIP and direct connection phones ==\nAs the popularity of VoIP grows, secure telephony is becoming more widely used. Many major hardware and software providers offer it as a standard feature at no extra cost.\nExamples include the Gizmo5 and Twinkle. Both of the former work with offerings from the founder of PGP, Phil Zimmermann, and his VoIP secure protocol, ZRTP. ZRTP is implemented in, amongst others, Ripcord Networks product SecurePC with up to NSA Suite B compliant Elliptic Curve math libraries. ZRTP is also being made available for mobile GSM CSD as a new standard for non-VoIP secure calls.\nThe U.S. National Security Agency is developing a secure phone based on Google's Android called Fishbowl.\n\n== Historically significant products ==\n\nScramblers were used to secure voice traffic during World War II, but were often intercepted and decoded due to scrambling's inherent insecurity. The first true secure telephone was SIGSALY, a massive device that weighed over 50 tons. The NSA, formed after World War II, developed a series of secure telephones, including the STU I, STU II and STU-III, as well as voice encryption devices for military telephones.\nIn 1989 an Irish company called Intrepid developed one of the most advanced secure phones. Called Milcode, the phone was the first to implement code-excited linear prediction (or CELP) which dramatically improved voice quality and user operability over previous LPC (Linear Predictive Coding) and LPC-10e versions.\nMilcode also boasted significantly higher levels of security than previous secure telephones. The base model offered a proprietary encryption algorithm with a key length of 512 bits, and a more advanced model with a key length of 1024 bits. Key exchange used a public key, based on Diffie-Hellman, as opposed to a plug-in datakey. A new key was generated for each phone call. Milcode was also able to encrypt fax and data and was electromagnetically shielded to NATO TEMPEST standards.\nOther products of historical significance are PGPfone and Nautilus (designed as a non-key escrow alternative to Clipper, now officially discontinued, but still available on SourceForge), SpeakFreely, and the security VoIP protocol wrapper Zfone developed by the creator of PGP.\nScrambling, generally using a form of voice inversion, was available from electronic hobbyist kit suppliers and is common on FRS radios. Analog scrambling is still used, as some telecommunications circuits, such as HF links and telephone lines in the developing world, are of very low quality."
    }
  },
  {
    "instruction": "Write an answer to the following question: Who is the owner of the company that developed the Pegasus spyware, and what is their stance on the allegations of misuse of their product?",
    "context": "",
    "output": "The owner of the company that developed the Pegasus spyware is categorically refuting all allegations and denying \"false claims\" about its clients' activities. They stated that the list of the phone numbers in question has nothing to do with the Pegasus spyware and that they would continue to investigate all credible claims of misuse and take appropriate action.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Who is the owner of the company that developed the Pegasus spyware, and what is their stance on the allegations of misuse of their product?",
      "answer": "The owner of the company that developed the Pegasus spyware is categorically refuting all allegations and denying \"false claims\" about its clients' activities. They stated that the list of the phone numbers in question has nothing to do with the Pegasus spyware and that they would continue to investigate all credible claims of misuse and take appropriate action."
    }
  },
  {
    "instruction": "Secure Remote Password protocol\n\n==Introduction==\nThe Secure Remote Password protocol (SRP) is an augmented password-authenticated key exchange (PAKE) protocol, specifically designed to work around existing patents.Like all PAKE protocols, an eavesdropper or man in the middle cannot obtain enough information to be able to brute-force guess a password or apply a dictionary attack without further interactions with the parties for each guess. Furthermore, being an augmented PAKE protocol, the server does not store password-equivalent data. This means that an attacker who steals the server data cannot masquerade as the client unless they first perform a brute force search for the password.\nIn layman's terms, during SRP (or any other PAKE protocol) authentication, one party (the \"client\" or \"user\") demonstrates to another party (the \"server\") that they know the password, without sending the password itself nor any other information from which the password can be derived. The password never leaves the client and is unknown to the server.\nFurthermore, the server also needs to know about the password (but not the password itself) in order to instigate the secure connection. This means that the server also authenticates itself to the client which prevents phishing without reliance on the user parsing complex URLs.\nNewer alternative algorithms include AuCPace\nand OPAQUE\n\n\n\n== Overview ==\nThe SRP protocol has a number of desirable properties: it allows a user to authenticate themselves to a server, it is resistant to dictionary attacks mounted by an eavesdropper, and it does not require a trusted third party. It effectively conveys a zero-knowledge password proof from the user to the server. In revision 6 of the protocol only one password can be guessed per connection attempt. One of the interesting properties of the protocol is that even if one or two of the cryptographic primitives it uses are attacked, it is still secure. The SRP protocol has been revised several times, and is currently at revision 6a.\nThe SRP protocol creates a large private key shared between the two parties in a manner similar to Diffie\u2013Hellman key exchange based on the client side having the user password and the server side having a cryptographic verifier derived from the password. The shared public key is derived from two random numbers, one generated by the client, and the other generated by the server, which are unique to the login attempt. In cases where encrypted communications as well as authentication are required, the SRP protocol is more secure than the alternative SSH protocol and faster than using Diffie\u2013Hellman key exchange with signed messages. It is also independent of third parties, unlike Kerberos. The SRP protocol, version 3 is described in RFC 2945. SRP version 6 is also used for strong password authentication in SSL/TLS (in TLS-SRP) and other standards such as EAP and SAML, and is being standardized in IEEE P1363 and ISO/IEC 11770-4.\n\n== Protocol ==\nThe following notation is used in this description of the protocol, version 6:\n\nq and N\n\nHow does SRP differ from other PAKE protocols in terms of server data storage?",
    "context": "",
    "output": "A: Unlike other PAKE protocols, SRP does not store password-equivalent data on the server. This means that even if an attacker steals the server data, they cannot masquerade as the client without performing a brute force search for the password.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does SRP differ from other PAKE protocols in terms of server data storage?",
      "answer": "Unlike other PAKE protocols, SRP does not store password-equivalent data on the server. This means that even if an attacker steals the server data, they cannot masquerade as the client without performing a brute force search for the password.",
      "context": "Secure Remote Password protocol\n\n==Introduction==\nThe Secure Remote Password protocol (SRP) is an augmented password-authenticated key exchange (PAKE) protocol, specifically designed to work around existing patents.Like all PAKE protocols, an eavesdropper or man in the middle cannot obtain enough information to be able to brute-force guess a password or apply a dictionary attack without further interactions with the parties for each guess. Furthermore, being an augmented PAKE protocol, the server does not store password-equivalent data. This means that an attacker who steals the server data cannot masquerade as the client unless they first perform a brute force search for the password.\nIn layman's terms, during SRP (or any other PAKE protocol) authentication, one party (the \"client\" or \"user\") demonstrates to another party (the \"server\") that they know the password, without sending the password itself nor any other information from which the password can be derived. The password never leaves the client and is unknown to the server.\nFurthermore, the server also needs to know about the password (but not the password itself) in order to instigate the secure connection. This means that the server also authenticates itself to the client which prevents phishing without reliance on the user parsing complex URLs.\nNewer alternative algorithms include AuCPace\nand OPAQUE\n\n\n\n== Overview ==\nThe SRP protocol has a number of desirable properties: it allows a user to authenticate themselves to a server, it is resistant to dictionary attacks mounted by an eavesdropper, and it does not require a trusted third party. It effectively conveys a zero-knowledge password proof from the user to the server. In revision 6 of the protocol only one password can be guessed per connection attempt. One of the interesting properties of the protocol is that even if one or two of the cryptographic primitives it uses are attacked, it is still secure. The SRP protocol has been revised several times, and is currently at revision 6a.\nThe SRP protocol creates a large private key shared between the two parties in a manner similar to Diffie\u2013Hellman key exchange based on the client side having the user password and the server side having a cryptographic verifier derived from the password. The shared public key is derived from two random numbers, one generated by the client, and the other generated by the server, which are unique to the login attempt. In cases where encrypted communications as well as authentication are required, the SRP protocol is more secure than the alternative SSH protocol and faster than using Diffie\u2013Hellman key exchange with signed messages. It is also independent of third parties, unlike Kerberos. The SRP protocol, version 3 is described in RFC 2945. SRP version 6 is also used for strong password authentication in SSL/TLS (in TLS-SRP) and other standards such as EAP and SAML, and is being standardized in IEEE P1363 and ISO/IEC 11770-4.\n\n== Protocol ==\nThe following notation is used in this description of the protocol, version 6:\n\nq and N"
    }
  },
  {
    "instruction": "Write an answer to the following question: How does Private Disk handle compatibility across various Windows operating systems?",
    "context": "",
    "output": "Private Disk is compatible with Windows 9x and Windows NT operating systems, ensuring that users can access encrypted data on different Windows versions.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does Private Disk handle compatibility across various Windows operating systems?",
      "answer": "Private Disk is compatible with Windows 9x and Windows NT operating systems, ensuring that users can access encrypted data on different Windows versions."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is file slack, and how does shred handle it in Unix-like operating systems?",
    "context": "",
    "output": "File slack is the unused space in file allocations. By default, shred overwrites file slack, which may be necessary to securely delete files on a file system with 4 KB clusters that require 8 KB of storage for a 5 KB file.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is file slack, and how does shred handle it in Unix-like operating systems?",
      "answer": "File slack is the unused space in file allocations. By default, shred overwrites file slack, which may be necessary to securely delete files on a file system with 4 KB clusters that require 8 KB of storage for a 5 KB file."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the role of the mangle table in Netfilter?",
    "context": "",
    "output": "The mangle table in Netfilter is used to modify packets after Connection Tracking. This enables additional modifications by rules that follow, such as NAT or further filtering.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of the mangle table in Netfilter?",
      "answer": "The mangle table in Netfilter is used to modify packets after Connection Tracking. This enables additional modifications by rules that follow, such as NAT or further filtering."
    }
  },
  {
    "instruction": "Write an answer to the following question: How is the Internet Storm Center (ISC) related to the SANS Institute?",
    "context": "",
    "output": "The Internet Storm Center (ISC) is a program of the SANS Technology Institute, which is a branch of the SANS Institute.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How is the Internet Storm Center (ISC) related to the SANS Institute?",
      "answer": "The Internet Storm Center (ISC) is a program of the SANS Technology Institute, which is a branch of the SANS Institute."
    }
  },
  {
    "instruction": "Clario Tech\n\n==Introduction==\nClario is a security software development company that offers consumer-facing digital security and privacy applications for use on a range of operating systems including iOS, Android, macOS.Clario Tech allegedly has more than 800 team members in various worldwide locations, the majority appear to be operating from Ukraine. The workforce consists of software developers, marketing specialists, security researchers and customer support agents. In 2019, the company announced it would invest $30 million during 2020 to develop its cybersecurity products and make them accessible for all.\n\n\n\n== Products ==\n\n\n*** Clario ***\nClario security application was officially launched at the Consumer Electronic Awards in January 2020 in Las Vegas. Clario announced its aim was to offer a new online security product via a user-friendly dashboard, integrating cybersecurity technology with 24/7 human support against digital threats.The cybersecurity application has been reviewed in various publications including the Evening Standard who called it the \u201cUber of cybersecurity\u201d.In response to the COVID-19 pandemic, Clario launched a 24/7 IT support hotline for anyone to call if they experienced technology issues while in lockdown. The company\u2019s 600+ team were on hand to respond to any reported issues.\nClario received the AV-TEST certification in December 2020 and was featured in the honorable mentions list in the Privacy Focused tool nomination as part of the Product Hunt\u2019s 2020 Golden Kitty Award Winners in 2020.\n\n\n*** MacUpdate ***\nMacUpdate is a Macintosh software download website founded in 1997 by Joel Mueller. In 2017, the site was sold to Zeobit, and subsequently was acquired by Clario Tech in 2020.\n\n\n*** MacKeeper ***\nMacKeeper is utility software that offers system cleaning, privacy features and antivirus for macOS. Clario Tech has become the owner of the MacKeeper software since 2019 with aim to accelerate the transformation of MacKeeper.\n\n== Clario cybersecurity research ==\nClario Tech has undertaken numerous pieces of research into cybersecurity trends in 2020 and 2021. These include \"Which Company Uses the Most of Your Data?\", \"The State of Cybercrime in US and UK\", \"Cybercrime Hotspots\".\n\nBased on the above text, answer a question. How many team members does Clario Tech have and where are they located?",
    "context": "",
    "output": "Clario Tech has more than 800 team members, the majority of whom are operating from Ukraine.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How many team members does Clario Tech have and where are they located?",
      "answer": "Clario Tech has more than 800 team members, the majority of whom are operating from Ukraine.",
      "context": "Clario Tech\n\n==Introduction==\nClario is a security software development company that offers consumer-facing digital security and privacy applications for use on a range of operating systems including iOS, Android, macOS.Clario Tech allegedly has more than 800 team members in various worldwide locations, the majority appear to be operating from Ukraine. The workforce consists of software developers, marketing specialists, security researchers and customer support agents. In 2019, the company announced it would invest $30 million during 2020 to develop its cybersecurity products and make them accessible for all.\n\n\n\n== Products ==\n\n\n*** Clario ***\nClario security application was officially launched at the Consumer Electronic Awards in January 2020 in Las Vegas. Clario announced its aim was to offer a new online security product via a user-friendly dashboard, integrating cybersecurity technology with 24/7 human support against digital threats.The cybersecurity application has been reviewed in various publications including the Evening Standard who called it the \u201cUber of cybersecurity\u201d.In response to the COVID-19 pandemic, Clario launched a 24/7 IT support hotline for anyone to call if they experienced technology issues while in lockdown. The company\u2019s 600+ team were on hand to respond to any reported issues.\nClario received the AV-TEST certification in December 2020 and was featured in the honorable mentions list in the Privacy Focused tool nomination as part of the Product Hunt\u2019s 2020 Golden Kitty Award Winners in 2020.\n\n\n*** MacUpdate ***\nMacUpdate is a Macintosh software download website founded in 1997 by Joel Mueller. In 2017, the site was sold to Zeobit, and subsequently was acquired by Clario Tech in 2020.\n\n\n*** MacKeeper ***\nMacKeeper is utility software that offers system cleaning, privacy features and antivirus for macOS. Clario Tech has become the owner of the MacKeeper software since 2019 with aim to accelerate the transformation of MacKeeper.\n\n== Clario cybersecurity research ==\nClario Tech has undertaken numerous pieces of research into cybersecurity trends in 2020 and 2021. These include \"Which Company Uses the Most of Your Data?\", \"The State of Cybercrime in US and UK\", \"Cybercrime Hotspots\"."
    }
  },
  {
    "instruction": "Context: Usher (software)\n\n==Introduction==\nUsher is an enterprise security platform released by Microstrategy, Inc. in 2015. The technology is designed to replace user-entered passwords with biometric identity and multi-step authentication methods, and features digital badges and geo-fencing administration options. The service takes the form of a mobile application that allows users to access both physical and digital space based on more passive identification methods (facial recognition, Bluetooth discovery, etc).\n\n\n\n== Overview ==\nUsher has been positioned as a \"password killer\" that is based on moving towards security credentials more tied to identity and place. Applications that can be managed via Usher include Salesforce.com, Google Apps, and select Microsoft software.The security features of the product are backed up by Usher Analytics, which allows administrators to assess data in real time to identify threats and behavioral abnormalities.\n\n== Clients ==\nOrganizations that use Usher include: \n\nGeorgetown University\n1776\nSaudi Arabia Ministry of Foreign Affairs\nBlackbox BI Consultancy\nAnswer this question: How does Usher differ from traditional password-based authentication methods?",
    "context": "",
    "output": "Usher differs from traditional password-based authentication methods as it is based on moving towards security credentials more tied to identity and place, rather than relying solely on user-entered passwords.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does Usher differ from traditional password-based authentication methods?",
      "answer": "Usher differs from traditional password-based authentication methods as it is based on moving towards security credentials more tied to identity and place, rather than relying solely on user-entered passwords.",
      "context": "Usher (software)\n\n==Introduction==\nUsher is an enterprise security platform released by Microstrategy, Inc. in 2015. The technology is designed to replace user-entered passwords with biometric identity and multi-step authentication methods, and features digital badges and geo-fencing administration options. The service takes the form of a mobile application that allows users to access both physical and digital space based on more passive identification methods (facial recognition, Bluetooth discovery, etc).\n\n\n\n== Overview ==\nUsher has been positioned as a \"password killer\" that is based on moving towards security credentials more tied to identity and place. Applications that can be managed via Usher include Salesforce.com, Google Apps, and select Microsoft software.The security features of the product are backed up by Usher Analytics, which allows administrators to assess data in real time to identify threats and behavioral abnormalities.\n\n== Clients ==\nOrganizations that use Usher include: \n\nGeorgetown University\n1776\nSaudi Arabia Ministry of Foreign Affairs\nBlackbox BI Consultancy"
    }
  },
  {
    "instruction": "Write an answer to the following question: How can websites prevent cross-site request forgery attacks?",
    "context": "",
    "output": "Most CSRF prevention techniques work by embedding additional authentication data into requests that allows the web application to detect requests from unauthorized locations. This can include the synchronizer token pattern, the cookie-to-header token method, or other methods.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can websites prevent cross-site request forgery attacks?",
      "answer": "Most CSRF prevention techniques work by embedding additional authentication data into requests that allows the web application to detect requests from unauthorized locations. This can include the synchronizer token pattern, the cookie-to-header token method, or other methods."
    }
  },
  {
    "instruction": "Write an answer to the following question: What information does the Time service send back to the originating source in the RFC 868 time server?",
    "context": "",
    "output": "The Time service sends back to the originating source the time in seconds since midnight on January first 1900 in the RFC 868 time server.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What information does the Time service send back to the originating source in the RFC 868 time server?",
      "answer": "The Time service sends back to the originating source the time in seconds since midnight on January first 1900 in the RFC 868 time server."
    }
  },
  {
    "instruction": "Write an answer to the following question: When was the last news article on the official Suhosin website published?",
    "context": "",
    "output": "The last news article on the official Suhosin website is from 2007.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "When was the last news article on the official Suhosin website published?",
      "answer": "The last news article on the official Suhosin website is from 2007."
    }
  },
  {
    "instruction": "Answer based on context:\n\nSecurity Protocols Open Repository\n\n==Introduction==\nSPORE, the Security Protocols Open Repository, is an online library of security protocols with comments and links to papers. Each protocol is downloadable in a variety of formats, including rules for use with automatic protocol verification tools. All protocols are described using BAN logic or the style used by Clark and Jacob, and their goals. The database includes details on formal proofs or known attacks, with references to comments, analysis & papers. A large number of protocols are listed, including many which have been shown to be insecure.\nIt is a continuation of the seminal work by John Clark and Jeremy Jacob.They seek contributions for new protocols, links and comments.\n\n\n\nHow does SPORE support the continuous development and improvement of security protocols, and what are its goals regarding community involvement?",
    "context": "",
    "output": "SPORE encourages contributions from the community in the form of new protocols, links, and comments. By fostering this collaborative environment, SPORE seeks to promote the ongoing development and improvement of security protocols. The ultimate goal is to create a rich and diverse repository that facilitates the identification of secure and efficient security protocols for various applications.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does SPORE support the continuous development and improvement of security protocols, and what are its goals regarding community involvement?",
      "answer": "SPORE encourages contributions from the community in the form of new protocols, links, and comments. By fostering this collaborative environment, SPORE seeks to promote the ongoing development and improvement of security protocols. The ultimate goal is to create a rich and diverse repository that facilitates the identification of secure and efficient security protocols for various applications.",
      "context": "Security Protocols Open Repository\n\n==Introduction==\nSPORE, the Security Protocols Open Repository, is an online library of security protocols with comments and links to papers. Each protocol is downloadable in a variety of formats, including rules for use with automatic protocol verification tools. All protocols are described using BAN logic or the style used by Clark and Jacob, and their goals. The database includes details on formal proofs or known attacks, with references to comments, analysis & papers. A large number of protocols are listed, including many which have been shown to be insecure.\nIt is a continuation of the seminal work by John Clark and Jeremy Jacob.They seek contributions for new protocols, links and comments.\n\n"
    }
  },
  {
    "instruction": "Telehack\n\n==Introduction==\nTelehack is an online simulation of a stylized interface for ARPANET and Usenet, created anonymously in 2010. It is a full multi-user simulation, including 26,600+ simulated hosts with files spanning the years 1985 to 1990.Users can explore a pre-Web 1.0 archive of files, documents, scripts and newsgroup posts saved from BBSes thanks to textfiles.com.\n\n\n\nBased on the above text, answer a question. What is the significance of the 1985-1990 timeframe in Telehack's content, and how does it relate to the development of the internet?",
    "context": "",
    "output": "The 1985-1990 timeframe in Telehack's content represents a critical period in the development of the internet. During this time, the Advanced Research Projects Agency Network (ARPANET) transitioned to the National Science Foundation Network (NSFNET), leading to the growth of the internet as we know it today. Usenet, a worldwide distributed discussion system, also flourished during this period, making it an essential part of early online communication. By providing access to files, documents, scripts, and newsgroup posts from this era, Telehack offers a glimpse into the pre-Web 1.0 internet landscape.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the significance of the 1985-1990 timeframe in Telehack's content, and how does it relate to the development of the internet?",
      "answer": "The 1985-1990 timeframe in Telehack's content represents a critical period in the development of the internet. During this time, the Advanced Research Projects Agency Network (ARPANET) transitioned to the National Science Foundation Network (NSFNET), leading to the growth of the internet as we know it today. Usenet, a worldwide distributed discussion system, also flourished during this period, making it an essential part of early online communication. By providing access to files, documents, scripts, and newsgroup posts from this era, Telehack offers a glimpse into the pre-Web 1.0 internet landscape.",
      "context": "Telehack\n\n==Introduction==\nTelehack is an online simulation of a stylized interface for ARPANET and Usenet, created anonymously in 2010. It is a full multi-user simulation, including 26,600+ simulated hosts with files spanning the years 1985 to 1990.Users can explore a pre-Web 1.0 archive of files, documents, scripts and newsgroup posts saved from BBSes thanks to textfiles.com.\n\n"
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the verifying algorithm in KCDSA?",
    "context": "",
    "output": "In KCDSA, the verifying algorithm involves checking that the values of r and s are within the valid range, computing e based on the message and the public verification key y, and then checking if the equation s*g^e = r+k*y holds.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the verifying algorithm in KCDSA?",
      "answer": "In KCDSA, the verifying algorithm involves checking that the values of r and s are within the valid range, computing e based on the message and the public verification key y, and then checking if the equation s*g^e = r+k*y holds."
    }
  },
  {
    "instruction": "Write an answer to the following question: Which tool is commonly used to create PKCS #12 files?",
    "context": "",
    "output": "PKCS #12 files are usually created using OpenSSL.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Which tool is commonly used to create PKCS #12 files?",
      "answer": "PKCS #12 files are usually created using OpenSSL."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the role of intrusion detection management in managed security services?",
    "context": "",
    "output": "Intrusion detection management is a category of managed security services that involves providing intrusion alerts to a customer, keeping up to date with new defenses against intrusion, and regularly reporting on intrusion attempts and activity. It may also involve monitoring, maintaining the firewall's traffic routing rules, and generating regular traffic and management reports to the customer.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of intrusion detection management in managed security services?",
      "answer": "Intrusion detection management is a category of managed security services that involves providing intrusion alerts to a customer, keeping up to date with new defenses against intrusion, and regularly reporting on intrusion attempts and activity. It may also involve monitoring, maintaining the firewall's traffic routing rules, and generating regular traffic and management reports to the customer."
    }
  },
  {
    "instruction": "Capability-based security\n\n==Introduction==\nCapability-based security is a concept in the design of secure computing systems, one of the existing security models. A capability (known in some systems as a key) is a communicable, unforgeable token of authority. It refers to a value that references an object along with an associated set of access rights. A user program on a capability-based operating system must use a capability to access an object. Capability-based security refers to the principle of designing user programs such that they directly share capabilities with each other according to the principle of least privilege, and to the operating system infrastructure necessary to make such transactions efficient and secure. Capability-based security is to be contrasted with an approach that uses traditional UNIX permissions and Access Control Lists.\nAlthough most operating systems implement a facility which resembles capabilities, they typically do not provide enough support to allow for the exchange of capabilities among possibly mutually untrusting entities to be the primary means of granting and distributing access rights throughout the system. A capability-based system, in contrast, is designed with that goal in mind.\n\n\n\n== Introduction ==\nCapabilities achieve their objective of improving system security by being used in place of forgeable references. A forgeable reference (for example, a path name) identifies an object, but does not specify which access rights are appropriate for that object and the user program which holds that reference. Consequently, any attempt to access the referenced object must be validated by the operating system, based on the ambient authority of the requesting program, typically via the use of an access-control list (ACL). Instead, in a system with capabilities, the mere fact that a user program possesses that capability entitles it to use the referenced object in accordance with the rights that are specified by that capability. In theory, a system with capabilities removes the need for any access control list or similar mechanism by giving all entities all and only the capabilities they will actually need.\nA capability is typically implemented as a privileged data structure that consists of a section that specifies access rights, and a section that uniquely identifies the object to be accessed. The user does not access the data structure or object directly, but instead via a handle. In practice, it is used much like a file descriptor in a traditional operating system (a traditional handle), but to access every object on the system. Capabilities are typically stored by the operating system in a list, with some mechanism in place to prevent the program from directly modifying the contents of the capability (so as to forge access rights or change the object it points to). Some systems have also been based on capability-based addressing (hardware support for capabilities), such as Plessey System 250.\nPrograms possessing capabilities can perform functions on them, such as passing them on to other programs, converting them to a less-privileged version, or deleting them. The operating system must ensure that only specific operations can occur to the capabilities in the system, in order to maintain the integrity of the security policy.\nCapabilities as discussed in this article should not be confused with Portable Operating System Interface (POSIX) 1e/2c \"Capabilities\". The latter are coarse-grained privileges that cannot be transferred between processes.\n\n== Examples ==\nA capability is defined to be a protected object reference which, by virtue of its possession by a user process, grants that process the capability (hence the name) to interact with an object in certain ways. Those ways might include reading data associated with an object, modifying the object, executing the data in the object as a process, and other conceivable access rights. The capability logically consists of a reference that uniquely identifies a particular object and a set of one or more of these rights.\nSuppose that, in a user process's memory space, there exists the following string:\n\n/etc/passwd\n\nAlthough this identifies a unique object on the system, it does not specify access rights and hence is not a capability. Suppose there is instead the following pair of values:\n\n/etc/passwd\nO_RDWR\n\nThis pair identifies an object along with a set of access rights. The pair, however, is still not a capability because the user process's possession of these values says nothing about whether that access would actually be legitimate.\nNow suppose that the user program successfully executes the following statement:\n\nThe variable fd now contains the index of a file descriptor in the process's file descriptor table. This file descriptor is a capability. Its existence in the process's file descriptor table is sufficient to show that the process does indeed have legitimate access to the object. A key feature of this arrangement is that the file descriptor table is in kernel memory and cannot be directly manipulated by the user program.\n\n== Sharing between processes ==\nIn traditional operating systems, programs often communicate with each other and with storage using references like those in the first two examples. Path names are often passed as command-line parameters, sent via sockets, and stored on disk. These references are not capabilities, and must be validated before they can be used. In these systems, a central question is \"on whose authority is a given reference to be evaluated?\" This becomes a critical issue especially for processes which must act on behalf of two different authority-bearing entities. They become susceptible to a programming error known as the confused deputy problem, very frequently resulting in a security hole.\nIn a capability-based system, the capabilities themselves are passed between processes and storage using a mechanism that is known by the operating system to maintain the integrity of those capabilities.\nOne novel approach to solving this problem involves the use of an orthogonally persistent operating system. In such a system, there is no need for entities to be discarded and their capabilities be invalidated, and hence require an ACL-like mechanism to restore those capabilities at a later time. The operating system maintains the integrity and security of the capabilities contained within all storage, both volatile and nonvolatile, at all times; in part by performing all serialization tasks by itself, rather than requiring user programs to do so, as is the case in most operating systems. Because user programs are relieved of this responsibility, there is no need to trust them to reproduce only legal capabilities, nor to validate requests for access using an access control mechanism. An example implementation is the Flex machine from the early 1980s.\n\n== POSIX capabilities ==\nPortable Operating System Interface (POSIX) draft 1003.1e specifies a concept of permissions called \"capabilities\". However, POSIX capabilities differ from capabilities in this article. A POSIX capability is not associated with any object; a process having CAP_NET_BIND_SERVICE capability can listen on any TCP port under 1024. This system is found in Linux.In contrast, Capsicum Unix hybridizes a true capability-system model with a Unix design and POSIX API. Capsicum capabilities are a refined form of file descriptor, a delegable right between processes and additional object types beyond classic POSIX, such as processes, can be referenced via capabilities. In Capsicum capability mode, processes are unable to utilize global namespaces (such as the filesystem namespace) to look up objects, and must instead inherit or be delegated them. This system is found natively in FreeBSD, but patches are available to other systems.\n\n== Implementations ==\nNotable research and commercial systems employing capability-based security include the following:\n\nTahoe-LAFS, an open-source capability-based filesystem\nGNOSIS, an operating system developed at Tymshare\nKeyKOS, successor to GNOSIS\nEROS, The Extremely Reliable Operating System, successor to KeyKOS\nCapROS, a project to further develop the EROS code base for commercial use\nCambridge CAP computer\nHydra (operating system), part of the C.mmp project at Carnegie Mellon University\nStarOS, part of the CM* project at Carnegie Mellon University\nIBM System/38 and AS/400\nIntel iAPX 432\nPlessey System 250\nFlex\nL4 microkernel family:\nOKL4 from Open Kernel Labs\nseL4 from NICTA\nFiasco.OC and NOVA from TU Dresden\nAmoeba distributed operating system\nFreeBSD Capsicum\nGenode\nGoogle Fuchsia\nWebAssembly System Interface (WASI)\n\nAnswer this question based on the above context: How does a capability-based security system differ from traditional UNIX permissions and Access Control Lists?",
    "context": "",
    "output": "Capability-based security refers to the principle of designing user programs such that they directly share capabilities with each other according to the principle of least privilege, while traditional UNIX permissions and Access Control Lists use a different approach to grant and distribute access rights throughout the system.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does a capability-based security system differ from traditional UNIX permissions and Access Control Lists?",
      "answer": "Capability-based security refers to the principle of designing user programs such that they directly share capabilities with each other according to the principle of least privilege, while traditional UNIX permissions and Access Control Lists use a different approach to grant and distribute access rights throughout the system.",
      "context": "Capability-based security\n\n==Introduction==\nCapability-based security is a concept in the design of secure computing systems, one of the existing security models. A capability (known in some systems as a key) is a communicable, unforgeable token of authority. It refers to a value that references an object along with an associated set of access rights. A user program on a capability-based operating system must use a capability to access an object. Capability-based security refers to the principle of designing user programs such that they directly share capabilities with each other according to the principle of least privilege, and to the operating system infrastructure necessary to make such transactions efficient and secure. Capability-based security is to be contrasted with an approach that uses traditional UNIX permissions and Access Control Lists.\nAlthough most operating systems implement a facility which resembles capabilities, they typically do not provide enough support to allow for the exchange of capabilities among possibly mutually untrusting entities to be the primary means of granting and distributing access rights throughout the system. A capability-based system, in contrast, is designed with that goal in mind.\n\n\n\n== Introduction ==\nCapabilities achieve their objective of improving system security by being used in place of forgeable references. A forgeable reference (for example, a path name) identifies an object, but does not specify which access rights are appropriate for that object and the user program which holds that reference. Consequently, any attempt to access the referenced object must be validated by the operating system, based on the ambient authority of the requesting program, typically via the use of an access-control list (ACL). Instead, in a system with capabilities, the mere fact that a user program possesses that capability entitles it to use the referenced object in accordance with the rights that are specified by that capability. In theory, a system with capabilities removes the need for any access control list or similar mechanism by giving all entities all and only the capabilities they will actually need.\nA capability is typically implemented as a privileged data structure that consists of a section that specifies access rights, and a section that uniquely identifies the object to be accessed. The user does not access the data structure or object directly, but instead via a handle. In practice, it is used much like a file descriptor in a traditional operating system (a traditional handle), but to access every object on the system. Capabilities are typically stored by the operating system in a list, with some mechanism in place to prevent the program from directly modifying the contents of the capability (so as to forge access rights or change the object it points to). Some systems have also been based on capability-based addressing (hardware support for capabilities), such as Plessey System 250.\nPrograms possessing capabilities can perform functions on them, such as passing them on to other programs, converting them to a less-privileged version, or deleting them. The operating system must ensure that only specific operations can occur to the capabilities in the system, in order to maintain the integrity of the security policy.\nCapabilities as discussed in this article should not be confused with Portable Operating System Interface (POSIX) 1e/2c \"Capabilities\". The latter are coarse-grained privileges that cannot be transferred between processes.\n\n== Examples ==\nA capability is defined to be a protected object reference which, by virtue of its possession by a user process, grants that process the capability (hence the name) to interact with an object in certain ways. Those ways might include reading data associated with an object, modifying the object, executing the data in the object as a process, and other conceivable access rights. The capability logically consists of a reference that uniquely identifies a particular object and a set of one or more of these rights.\nSuppose that, in a user process's memory space, there exists the following string:\n\n/etc/passwd\n\nAlthough this identifies a unique object on the system, it does not specify access rights and hence is not a capability. Suppose there is instead the following pair of values:\n\n/etc/passwd\nO_RDWR\n\nThis pair identifies an object along with a set of access rights. The pair, however, is still not a capability because the user process's possession of these values says nothing about whether that access would actually be legitimate.\nNow suppose that the user program successfully executes the following statement:\n\nThe variable fd now contains the index of a file descriptor in the process's file descriptor table. This file descriptor is a capability. Its existence in the process's file descriptor table is sufficient to show that the process does indeed have legitimate access to the object. A key feature of this arrangement is that the file descriptor table is in kernel memory and cannot be directly manipulated by the user program.\n\n== Sharing between processes ==\nIn traditional operating systems, programs often communicate with each other and with storage using references like those in the first two examples. Path names are often passed as command-line parameters, sent via sockets, and stored on disk. These references are not capabilities, and must be validated before they can be used. In these systems, a central question is \"on whose authority is a given reference to be evaluated?\" This becomes a critical issue especially for processes which must act on behalf of two different authority-bearing entities. They become susceptible to a programming error known as the confused deputy problem, very frequently resulting in a security hole.\nIn a capability-based system, the capabilities themselves are passed between processes and storage using a mechanism that is known by the operating system to maintain the integrity of those capabilities.\nOne novel approach to solving this problem involves the use of an orthogonally persistent operating system. In such a system, there is no need for entities to be discarded and their capabilities be invalidated, and hence require an ACL-like mechanism to restore those capabilities at a later time. The operating system maintains the integrity and security of the capabilities contained within all storage, both volatile and nonvolatile, at all times; in part by performing all serialization tasks by itself, rather than requiring user programs to do so, as is the case in most operating systems. Because user programs are relieved of this responsibility, there is no need to trust them to reproduce only legal capabilities, nor to validate requests for access using an access control mechanism. An example implementation is the Flex machine from the early 1980s.\n\n== POSIX capabilities ==\nPortable Operating System Interface (POSIX) draft 1003.1e specifies a concept of permissions called \"capabilities\". However, POSIX capabilities differ from capabilities in this article. A POSIX capability is not associated with any object; a process having CAP_NET_BIND_SERVICE capability can listen on any TCP port under 1024. This system is found in Linux.In contrast, Capsicum Unix hybridizes a true capability-system model with a Unix design and POSIX API. Capsicum capabilities are a refined form of file descriptor, a delegable right between processes and additional object types beyond classic POSIX, such as processes, can be referenced via capabilities. In Capsicum capability mode, processes are unable to utilize global namespaces (such as the filesystem namespace) to look up objects, and must instead inherit or be delegated them. This system is found natively in FreeBSD, but patches are available to other systems.\n\n== Implementations ==\nNotable research and commercial systems employing capability-based security include the following:\n\nTahoe-LAFS, an open-source capability-based filesystem\nGNOSIS, an operating system developed at Tymshare\nKeyKOS, successor to GNOSIS\nEROS, The Extremely Reliable Operating System, successor to KeyKOS\nCapROS, a project to further develop the EROS code base for commercial use\nCambridge CAP computer\nHydra (operating system), part of the C.mmp project at Carnegie Mellon University\nStarOS, part of the CM* project at Carnegie Mellon University\nIBM System/38 and AS/400\nIntel iAPX 432\nPlessey System 250\nFlex\nL4 microkernel family:\nOKL4 from Open Kernel Labs\nseL4 from NICTA\nFiasco.OC and NOVA from TU Dresden\nAmoeba distributed operating system\nFreeBSD Capsicum\nGenode\nGoogle Fuchsia\nWebAssembly System Interface (WASI)"
    }
  },
  {
    "instruction": "Speck (cipher)\n\n==Introduction==\nSpeck is a family of lightweight block ciphers publicly released by the National Security Agency (NSA) in June 2013. Speck has been optimized for performance in software implementations, while its sister algorithm, Simon, has been optimized for hardware implementations. Speck is an add\u2013rotate\u2013xor (ARX) cipher.\nThe NSA began working on the Simon and Speck ciphers in 2011. The agency anticipated some agencies in the US federal government would need a cipher that would operate well on a diverse collection of Internet of Things devices while maintaining an acceptable level of security.\n\n== Cipher description ==\nSpeck supports a variety of block and key sizes.  A block is always two words, but the words may be 16, 24, 32, 48 or 64 bits in size.  The corresponding key is 2, 3 or 4 words.  The round function consists of two rotations, adding the right word to the left word, xoring the key into the left word, then xoring the left word into the right word.  The number of rounds depends on the parameters selected, as follows:\nThe key schedule uses the same round function as the main block cipher.\n\n== Reference code ==\nThe following is the designers' reference implementation, written in C, of the Speck variant with a 128-bit block size and key, where key\n\n== Performance ==\nAccording to ECRYPT's stream cipher benchmarks (eBASC), Speck is one of the fastest ciphers available, both for long as well as short messages. Some median performances for long messages (128-bit, 128-block size version) are: 1.99 cycles per byte (cpb) on an AMD Ryzen 7 1700; 1.27 cpb on an Intel Core i5-6600; 15.96 cpb on a Broadcom BCM2836 Cortex A7. For example, on the ARMv7 platform, Speck is about 3 times faster than AES.When implemented on 8-bit AVR microcontroller, Speck encryption with 64-bit blocks and 128-bit key consumes 192 bytes of flash memory, temporary variables consume 112 bytes of RAM, and takes 164 cycles to encrypt each byte in the block.Salsa20 is a stream cipher with comparable performance, but it is difficult to use stream ciphers securely in some applications where block ciphers like Speck work well. This led Google to add an implementation of Speck in Linux kernel version 4.17, planning to offer it as an option for disk encryption on low-end Android devices that would otherwise be unencrypted due to slow AES performance on processors that lack AES instructions. Speck was later dropped from the Linux kernel due to backlash and concerns, and Google switched to the Adiantum algorithm instead.\n\n== Security ==\n\n\n*** Cryptanalysis ***\nThe designers claim that Speck, though a \"lightweight\" cipher, is designed to have the full security possible for each block and key size, against standard chosen-plaintext (CPA) and chosen-ciphertext (CCA) attacks.  Resistance against related-key attacks was also stated as a goal, though a less crucial one as attacks in that model are not relevant for typical use cases.:\u200a2\u200a  No effort was made to resist attacks in the known-key distinguishing attack model, nor did the designers evaluate Speck for use as a hash function.:\u200a8\u200aAs of 2018, no successful attack on full-round Speck of any variant is known.  Due to interest in Simon and Speck, about 70 cryptanalysis papers have been published on them.:\u200a10\u200a  As is typical for iterated ciphers, reduced-round variants have been successfully attacked.  The best published attacks on Speck in the standard attack model (CPA/CCA with unknown key) are differential cryptanalysis attacks; these make it through about 70\u201375% of the rounds of most variants, though these best attacks are only marginally faster than brute-force.:\u200a12\u200a  The design team states that while designing Speck, they found differential attacks to be the limiting attacks, i.e. the type of attack that makes it through the most rounds; they then set the number of rounds to leave a security margin similar to AES-128's at approximately 30%.:\u200a12\u201313\u200a\nSpeck has been criticized for having too small a security margin, i.e. too few rounds between the best attacks and the full cipher, in comparison to more conservative ciphers such as ChaCha20.\nCiphers with small security margins are more likely to be broken by future advances in cryptanalysis.  Speck's design team counters that there is a real-world cost to unnecessarily large security margins, especially on lightweight devices, that cryptanalysis during the design phase allowed the number of rounds to be set appropriately, and that they targeted AES's security margin.:\u200a17\u200aSpeck includes a round counter in the key schedule.  The designers state this was included to block slide and rotational cryptanalysis attacks.:\u200a16\u200a  Still, rotational-XOR cryptanalysis has been used to find distinguishers against reduced-round versions of Speck. Though the authors don't describe standard key-recovery attacks based on their distinguishers, their best distinguishers on Speck32 and Speck48 in the known-key distinguishing attack model for certain weak key classes make it through slightly more rounds than the best differential distinguishers.  One of the authors has said that his research was resource-constrained and that rotational-XOR distinguishers on more rounds are probably possible. However, this type of cryptanalysis assumes the related-key or even the known-key attack models, which are not a concern in typical cryptographic protocols and solutions.:\u200a8\u200a  The designers also state that Speck was not designed to resist known-key distinguishing attacks (which do not directly compromise the confidentiality of ciphers).:\u200a8\u200aThe designers state that NSA cryptanalysis found the algorithms to have no weaknesses, and security commensurate with their key lengths.:\u200a2\u200a  The design team says that their cryptanalysis included linear and differential cryptanalysis using standard techniques such as Matsui's algorithm and SAT/SMT solvers, though a full list of techniques used is not given.:\u200a10\u200a  Speck's designers have been criticized for not providing more details on NSA cryptanalysis of the ciphers.The NSA has approved Simon128/256 and Speck128/256 for use in U.S. National Security Systems, though AES-256 is still recommended for non-constrained applications.\n\n\n*** Side-channel attacks ***\nBeing an ARX cipher, Speck does not use S-boxes or other lookup tables; it is therefore naturally immune to cache-timing attacks.:\u200a12\u200a This contrasts with ciphers that use lookup tables such as AES, which have been shown to be vulnerable to such attacks.  However, like most block ciphers (including AES) Speck is vulnerable to power analysis attacks unless hardware countermeasures are taken.:\u200a12\u200a\n\n\n*** Block and key sizes ***\nAlthough the Speck family of ciphers includes variants with the same block and key sizes as AES (Speck128/128, Speck128/192, and Speck128/256), it also includes variants with block size as low as 32 bits and key size as low as 64 bits.  These small block and key sizes are insecure for general use, as they can allow birthday attacks and brute-force attacks, regardless of the formal security of the cipher.  The designers state that these block and key sizes were included for highly resource-constrained devices where nothing better is possible, or where only very small amounts of data are ever encrypted, e.g. in RFID protocols.:\u200a2\u20133\u200a  Only the variant with a 128-bit block size and 256-bit key size is approved for use in U.S. National Security Systems.\n\n== Standardization efforts and controversies ==\nInitial attempts to standardise Simon and Speck failed to meet International Organization for Standardization super-majority required by the process and the ciphers were not adopted. Expert delegates to the ISO from several countries including Germany, Japan and Israel opposed the efforts by the NSA to standardise the Simon and Speck ciphers, citing concerns that the NSA is pushing for their standardisation with knowledge of exploitable weaknesses in the ciphers. The position was based on partial evidence of weaknesses in the ciphers, lack of clear need for standardisation of the new ciphers, and the NSA's previous involvement in the creation and promotion of the backdoored Dual_EC_DRBG cryptographic algorithm.In response to concerns, the NSA stated that more than 70 security analysis papers from some of the world's leading cryptographers support NSA's conclusion that the algorithms are secure and NSA affirmed that it is not aware of any cryptanalytic techniques that would allow them or anyone else to exploit Simon or SpeckAfter initial attempts to standardise the ciphers failed, the ISO standardised Simon and Speck in other working groups. As of October 2018, the Simon and Speck ciphers have been standardized by ISO as a part of the RFID air interface standard, International Standard ISO/29167-21 (for Simon) and International Standard ISO/29167-22 (for Speck), making them available for use by commercial entities.On August 7, 2018, Speck was removed from the Linux kernel 4.20 release completely.\n\nQ: How does Speck compare to other ciphers such as Salsa20 and AES in terms of performance?",
    "context": "",
    "output": "A: Speck is faster than AES on ARMv7 platforms and is about 3 times faster than AES on 8-bit AVR microcontroller. Salsa20 is a stream cipher with comparable performance, but it is difficult to use stream ciphers securely in some applications where block ciphers like Speck work well.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does Speck compare to other ciphers such as Salsa20 and AES in terms of performance?",
      "answer": "Speck is faster than AES on ARMv7 platforms and is about 3 times faster than AES on 8-bit AVR microcontroller. Salsa20 is a stream cipher with comparable performance, but it is difficult to use stream ciphers securely in some applications where block ciphers like Speck work well.",
      "context": "Speck (cipher)\n\n==Introduction==\nSpeck is a family of lightweight block ciphers publicly released by the National Security Agency (NSA) in June 2013. Speck has been optimized for performance in software implementations, while its sister algorithm, Simon, has been optimized for hardware implementations. Speck is an add\u2013rotate\u2013xor (ARX) cipher.\nThe NSA began working on the Simon and Speck ciphers in 2011. The agency anticipated some agencies in the US federal government would need a cipher that would operate well on a diverse collection of Internet of Things devices while maintaining an acceptable level of security.\n\n== Cipher description ==\nSpeck supports a variety of block and key sizes.  A block is always two words, but the words may be 16, 24, 32, 48 or 64 bits in size.  The corresponding key is 2, 3 or 4 words.  The round function consists of two rotations, adding the right word to the left word, xoring the key into the left word, then xoring the left word into the right word.  The number of rounds depends on the parameters selected, as follows:\nThe key schedule uses the same round function as the main block cipher.\n\n== Reference code ==\nThe following is the designers' reference implementation, written in C, of the Speck variant with a 128-bit block size and key, where key\n\n== Performance ==\nAccording to ECRYPT's stream cipher benchmarks (eBASC), Speck is one of the fastest ciphers available, both for long as well as short messages. Some median performances for long messages (128-bit, 128-block size version) are: 1.99 cycles per byte (cpb) on an AMD Ryzen 7 1700; 1.27 cpb on an Intel Core i5-6600; 15.96 cpb on a Broadcom BCM2836 Cortex A7. For example, on the ARMv7 platform, Speck is about 3 times faster than AES.When implemented on 8-bit AVR microcontroller, Speck encryption with 64-bit blocks and 128-bit key consumes 192 bytes of flash memory, temporary variables consume 112 bytes of RAM, and takes 164 cycles to encrypt each byte in the block.Salsa20 is a stream cipher with comparable performance, but it is difficult to use stream ciphers securely in some applications where block ciphers like Speck work well. This led Google to add an implementation of Speck in Linux kernel version 4.17, planning to offer it as an option for disk encryption on low-end Android devices that would otherwise be unencrypted due to slow AES performance on processors that lack AES instructions. Speck was later dropped from the Linux kernel due to backlash and concerns, and Google switched to the Adiantum algorithm instead.\n\n== Security ==\n\n\n*** Cryptanalysis ***\nThe designers claim that Speck, though a \"lightweight\" cipher, is designed to have the full security possible for each block and key size, against standard chosen-plaintext (CPA) and chosen-ciphertext (CCA) attacks.  Resistance against related-key attacks was also stated as a goal, though a less crucial one as attacks in that model are not relevant for typical use cases.:\u200a2\u200a  No effort was made to resist attacks in the known-key distinguishing attack model, nor did the designers evaluate Speck for use as a hash function.:\u200a8\u200aAs of 2018, no successful attack on full-round Speck of any variant is known.  Due to interest in Simon and Speck, about 70 cryptanalysis papers have been published on them.:\u200a10\u200a  As is typical for iterated ciphers, reduced-round variants have been successfully attacked.  The best published attacks on Speck in the standard attack model (CPA/CCA with unknown key) are differential cryptanalysis attacks; these make it through about 70\u201375% of the rounds of most variants, though these best attacks are only marginally faster than brute-force.:\u200a12\u200a  The design team states that while designing Speck, they found differential attacks to be the limiting attacks, i.e. the type of attack that makes it through the most rounds; they then set the number of rounds to leave a security margin similar to AES-128's at approximately 30%.:\u200a12\u201313\u200a\nSpeck has been criticized for having too small a security margin, i.e. too few rounds between the best attacks and the full cipher, in comparison to more conservative ciphers such as ChaCha20.\nCiphers with small security margins are more likely to be broken by future advances in cryptanalysis.  Speck's design team counters that there is a real-world cost to unnecessarily large security margins, especially on lightweight devices, that cryptanalysis during the design phase allowed the number of rounds to be set appropriately, and that they targeted AES's security margin.:\u200a17\u200aSpeck includes a round counter in the key schedule.  The designers state this was included to block slide and rotational cryptanalysis attacks.:\u200a16\u200a  Still, rotational-XOR cryptanalysis has been used to find distinguishers against reduced-round versions of Speck. Though the authors don't describe standard key-recovery attacks based on their distinguishers, their best distinguishers on Speck32 and Speck48 in the known-key distinguishing attack model for certain weak key classes make it through slightly more rounds than the best differential distinguishers.  One of the authors has said that his research was resource-constrained and that rotational-XOR distinguishers on more rounds are probably possible. However, this type of cryptanalysis assumes the related-key or even the known-key attack models, which are not a concern in typical cryptographic protocols and solutions.:\u200a8\u200a  The designers also state that Speck was not designed to resist known-key distinguishing attacks (which do not directly compromise the confidentiality of ciphers).:\u200a8\u200aThe designers state that NSA cryptanalysis found the algorithms to have no weaknesses, and security commensurate with their key lengths.:\u200a2\u200a  The design team says that their cryptanalysis included linear and differential cryptanalysis using standard techniques such as Matsui's algorithm and SAT/SMT solvers, though a full list of techniques used is not given.:\u200a10\u200a  Speck's designers have been criticized for not providing more details on NSA cryptanalysis of the ciphers.The NSA has approved Simon128/256 and Speck128/256 for use in U.S. National Security Systems, though AES-256 is still recommended for non-constrained applications.\n\n\n*** Side-channel attacks ***\nBeing an ARX cipher, Speck does not use S-boxes or other lookup tables; it is therefore naturally immune to cache-timing attacks.:\u200a12\u200a This contrasts with ciphers that use lookup tables such as AES, which have been shown to be vulnerable to such attacks.  However, like most block ciphers (including AES) Speck is vulnerable to power analysis attacks unless hardware countermeasures are taken.:\u200a12\u200a\n\n\n*** Block and key sizes ***\nAlthough the Speck family of ciphers includes variants with the same block and key sizes as AES (Speck128/128, Speck128/192, and Speck128/256), it also includes variants with block size as low as 32 bits and key size as low as 64 bits.  These small block and key sizes are insecure for general use, as they can allow birthday attacks and brute-force attacks, regardless of the formal security of the cipher.  The designers state that these block and key sizes were included for highly resource-constrained devices where nothing better is possible, or where only very small amounts of data are ever encrypted, e.g. in RFID protocols.:\u200a2\u20133\u200a  Only the variant with a 128-bit block size and 256-bit key size is approved for use in U.S. National Security Systems.\n\n== Standardization efforts and controversies ==\nInitial attempts to standardise Simon and Speck failed to meet International Organization for Standardization super-majority required by the process and the ciphers were not adopted. Expert delegates to the ISO from several countries including Germany, Japan and Israel opposed the efforts by the NSA to standardise the Simon and Speck ciphers, citing concerns that the NSA is pushing for their standardisation with knowledge of exploitable weaknesses in the ciphers. The position was based on partial evidence of weaknesses in the ciphers, lack of clear need for standardisation of the new ciphers, and the NSA's previous involvement in the creation and promotion of the backdoored Dual_EC_DRBG cryptographic algorithm.In response to concerns, the NSA stated that more than 70 security analysis papers from some of the world's leading cryptographers support NSA's conclusion that the algorithms are secure and NSA affirmed that it is not aware of any cryptanalytic techniques that would allow them or anyone else to exploit Simon or SpeckAfter initial attempts to standardise the ciphers failed, the ISO standardised Simon and Speck in other working groups. As of October 2018, the Simon and Speck ciphers have been standardized by ISO as a part of the RFID air interface standard, International Standard ISO/29167-21 (for Simon) and International Standard ISO/29167-22 (for Speck), making them available for use by commercial entities.On August 7, 2018, Speck was removed from the Linux kernel 4.20 release completely."
    }
  },
  {
    "instruction": "Write an answer to the following question: How did Phorm's Webwise service affect BBC WebWise in the UK?",
    "context": "",
    "output": "Phorm's Webwise service shared the same name as BBC WebWise, and the BBC was listed as an opponent on grounds of 'Likelihood of confusion' in Phorm's application for use of the 'Webwise' trade mark name.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How did Phorm's Webwise service affect BBC WebWise in the UK?",
      "answer": "Phorm's Webwise service shared the same name as BBC WebWise, and the BBC was listed as an opponent on grounds of 'Likelihood of confusion' in Phorm's application for use of the 'Webwise' trade mark name."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does AnonCoders justify their attacks on various websites, and what is their primary motivation?",
    "context": "",
    "output": "AnonCoders justifies their attacks on various websites by claiming to protest crimes allegedly committed against the Palestinian people on behalf of Israel. Their primary motivation is to draw attention to their cause and to retaliate against what they perceive as unjust actions taken by Israel and other entities.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does AnonCoders justify their attacks on various websites, and what is their primary motivation?",
      "answer": "AnonCoders justifies their attacks on various websites by claiming to protest crimes allegedly committed against the Palestinian people on behalf of Israel. Their primary motivation is to draw attention to their cause and to retaliate against what they perceive as unjust actions taken by Israel and other entities."
    }
  },
  {
    "instruction": "Petya and NotPetya\n\n==Introduction==\nPetya is a family of encrypting malware that was first discovered in 2016. The malware targets Microsoft Windows\u2013based systems, infecting the master boot record to execute a payload that encrypts a hard drive's file system table and prevents Windows from booting. It subsequently demands that the user make a payment in Bitcoin in order to regain access to the system.\nVariants of Petya were first seen in March 2016, which propagated via infected e-mail attachments. In June 2017, a new variant of Petya was used for a global cyberattack, primarily targeting Ukraine. The new variant propagates via the EternalBlue exploit, which is generally believed to have been developed by the U.S. National Security Agency (NSA), and was used earlier in the year by the WannaCry ransomware. Kaspersky Lab referred to this new version as NotPetya to distinguish it from the 2016 variants, due to these differences in operation. It looked like ransomware, but without functioning recovery feature it was equivalent to a wiper. The NotPetya attacks have been blamed on the Russian government, specifically the Sandworm hacking group within the GRU Russian military intelligence organization, by security researchers, Google, and several governments.\n\n== 2017 cyberattack ==\n\nOn 27 June 2017, a major global cyberattack began (Ukrainian companies were among the first to state they were being attacked), utilizing a new variant of Petya. On that day, Kaspersky Lab reported infections in France, Germany, Italy, Poland, the United Kingdom, and the United States, but that the majority of infections targeted Russia and Ukraine, where more than 80 companies were initially attacked, including the National Bank of Ukraine. ESET estimated on 28 June 2017 that 80% of all infections were in Ukraine, with Germany second hardest hit with about 9%. Russian president Vladimir Putin's press secretary, Dmitry Peskov, stated that the attack had caused no serious damage in Russia. Experts believed this was a politically-motivated attack against Ukraine, since it occurred on the eve of the Ukrainian holiday Constitution Day.Kaspersky dubbed this variant \"NotPetya\", as it has major differences in its operations in comparison to earlier variants. McAfee engineer Christiaan Beek stated that this variant was designed to spread quickly, and that it had been targeting \"complete energy companies, the power grid, bus stations, gas stations, the airport, and banks\".It was believed that the software update mechanism of M.E.Doc\u2014a Ukrainian tax preparation program that, according to F-Secure analyst Mikko Hypp\u00f6nen, \"appears to be de facto\" among companies doing business in the country\u2014had been compromised to spread the malware. Analysis by ESET found that a backdoor had been present in the update system for at least six weeks prior to the attack, describing it as a \"thoroughly well-planned and well-executed operation\". The developers of M.E.Doc denied that they were entirely responsible for the cyberattack, stating that they too were victims.On 4 July 2017, Ukraine's cybercrime unit seized the company's servers after detecting \"new activity\" that it believed would result in \"uncontrolled proliferation\" of malware. Ukraine police advised M.E.Doc users to stop using the software, as it presumed that the backdoor was still present. Analysis of the seized servers showed that software updates had not been applied since 2013, there was evidence of Russian presence, and an employee's account on the servers had been compromised; the head of the units warned that M.E.Doc could be found criminally responsible for enabling the attack because of its negligence in maintaining the security of their servers.\n\n== Operation ==\nPetya's payload infects the computer's master boot record (MBR), overwrites the Windows bootloader, and triggers a restart. Upon startup, the payload encrypts the Master File Table of the NTFS file system, and then displays the ransom message demanding a payment made in Bitcoin. Meanwhile, the computer's screen displays a purportedly output by chkdsk, Windows' file system scanner, suggesting that the hard drive's sectors are being repaired.The original payload required the user to grant it administrative privileges; one variant of Petya was bundled with a second payload, Mischa, which activated if Petya failed to install. Mischa is a more conventional ransomware payload that encrypts user documents, as well as executable files, and does not require administrative privileges to execute. The earlier versions of Petya disguised their payload as a PDF file, attached to an e-mail. United States Computer Emergency Response Team (US-CERT) and National Cybersecurity and Communications Integration Center (NCCIC) released Malware Initial Findings Report (MIFR) about Petya on 30 June 2017.The \"NotPetya\" variant used in the 2017 attack uses EternalBlue, an exploit that takes advantage of a vulnerability in Windows' Server Message Block (SMB) protocol.  EternalBlue is generally believed to have been developed by the U.S. National Security Agency (NSA); it was leaked in April 2017 and was also used by WannaCry. The malware harvests passwords (using tweaked build of open-source Mimikatz) and uses other techniques to spread to other computers on the same network, and uses those passwords in conjunction with PSExec to run code on other local computers. Additionally, although it still purports to be ransomware, the encryption routine was modified so that the malware could not technically revert its changes. This characteristic, along with other unusual signs in comparison to WannaCry (including the relatively low unlock fee of US$300, and using a single, fixed Bitcoin wallet to collect ransom payments rather than generating a unique ID for each specific infection for tracking purposes), prompted researchers to speculate that this attack was not intended to be a profit-generating venture, but to damage devices quickly, and ride off the media attention WannaCry received by claiming to be ransomware.\n\n== Mitigation ==\n\nIt was found that it may be possible to stop the encryption process if an infected computer is immediately shut down when the fictitious chkdsk screen appears, and a security analyst proposed that creating read-only files named perfc and/or perfc.dat in the Windows installation directory could prevent the payload of the current strain from executing. The email address listed on the ransom screen was suspended by its provider, Posteo, for being a violation of its terms of use. As a result, infected users could not actually send the required payment confirmation to the perpetrator. Additionally, if the computer's filesystem was FAT based, the MFT encryption sequence was skipped, and only the ransomware's message was displayed, allowing data to be recovered trivially.Microsoft had already released patches for supported versions of Windows in March 2017 to address the EternalBlue vulnerability. This was followed by patches for unsupported versions of Windows (such as Windows XP) in May 2017, in the direct wake of WannaCry. Wired believed that \"based on the extent of damage Petya has caused so far, though, it appears that many companies have put off patching, despite the clear and potentially devastating threat of a similar ransomware spread.\" Some enterprises may consider it too disruptive to install updates on certain systems, either due to possible downtime or compatibility concerns, which can be problematic in some environments.\n\n== Impact ==\nIn a report published by Wired, a White House assessment pegged the total damages brought about by NotPetya to more than $10 billion. This assessment was repeated by former Homeland Security advisor Tom Bossert, who at the time of the attack was the most senior cybersecurity focused official in the US government.During the attack initiated on 27 June 2017, the radiation monitoring system at Ukraine's Chernobyl Nuclear Power Plant went offline. Several Ukrainian ministries, banks and metro systems were also affected. It is said to have been the most destructive cyberattack ever.Among those affected elsewhere included British advertising company WPP, Maersk Line, American pharmaceutical company Merck & Co. (internationally doing business as MSD), Russian oil company Rosneft (its oil production was unaffected), multinational law firm DLA Piper, French construction company Saint-Gobain and its retail and subsidiary outlets in Estonia, British consumer goods company Reckitt Benckiser, German personal care company Beiersdorf, German logistics company DHL, United States food company Mondelez International, and American hospital operator Heritage Valley Health System. The Cadbury's Chocolate Factory in Hobart, Tasmania, is the first company in Australia to be affected by Petya. On 28 June 2017, JNPT, India's largest container port, had reportedly been affected, with all operations coming to a standstill. Princeton Community Hospital in rural West Virginia will scrap and replace its entire computer network on its path to recovery.The business interruption to Maersk, the world's largest container ship and supply vessel operator, was estimated between $200m and $300m in lost revenues.The business impact on FedEx is estimated to be $400m in 2018, according to the company's 2019 annual report.Jens Stoltenberg, NATO Secretary-General, pressed the alliance to strengthen its cyber defenses, saying that a cyberattack could trigger the Article 5 principle of collective defense.Mondelez International's insurance carrier, Zurich American Insurance Company, has refused to pay out a claim for cleaning up damage from a Notpetya infection, on the grounds that Notpetya is an \"act of war\" that is not covered by the policy.  Mondelez sued Zurich American for $100 million in 2018; the suit was settled in 2022 with the terms of the settlement remaining confidential.\n\n== Reaction ==\nEuropol said it was aware of and urgently responding to reports of a cyber attack in member states of the European Union. The United States Department of Homeland Security was involved and coordinating with its international and local partners. In a letter to the NSA, Democratic Congressman Ted Lieu asked the agency to collaborate more actively with technology companies to notify them of software vulnerabilities and help them prevent future attacks based on malware created by the NSA.\nOn 15 February 2018, the Trump administration blamed Russia for the attack and warned that there would be \"international consequences\". The United Kingdom and the Australian government also issued similar statements.In October 2020 the DOJ named further GRU officers in an indictment.\nAt the same time, the UK government blamed GRU's Sandworm also for attacks on the 2020 Summer Games.\n\n== Other notable low-level malware ==\nCIH (1998)\nStuxnet (2010)\nWannaCry (2017)\n\nAnswer this question based on the above context: Who is Zurich American Insurance Company and why did they refuse to pay out a claim for cleaning up damage from a Notpetya infection?",
    "context": "",
    "output": "Zurich American Insurance Company is an insurance carrier for Mondelez International. They refused to pay out a claim for cleaning up damage from a Notpetya infection on the grounds that Notpetya is an \"act of war\" that is not covered by the policy.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Who is Zurich American Insurance Company and why did they refuse to pay out a claim for cleaning up damage from a Notpetya infection?",
      "answer": "Zurich American Insurance Company is an insurance carrier for Mondelez International. They refused to pay out a claim for cleaning up damage from a Notpetya infection on the grounds that Notpetya is an \"act of war\" that is not covered by the policy.",
      "context": "Petya and NotPetya\n\n==Introduction==\nPetya is a family of encrypting malware that was first discovered in 2016. The malware targets Microsoft Windows\u2013based systems, infecting the master boot record to execute a payload that encrypts a hard drive's file system table and prevents Windows from booting. It subsequently demands that the user make a payment in Bitcoin in order to regain access to the system.\nVariants of Petya were first seen in March 2016, which propagated via infected e-mail attachments. In June 2017, a new variant of Petya was used for a global cyberattack, primarily targeting Ukraine. The new variant propagates via the EternalBlue exploit, which is generally believed to have been developed by the U.S. National Security Agency (NSA), and was used earlier in the year by the WannaCry ransomware. Kaspersky Lab referred to this new version as NotPetya to distinguish it from the 2016 variants, due to these differences in operation. It looked like ransomware, but without functioning recovery feature it was equivalent to a wiper. The NotPetya attacks have been blamed on the Russian government, specifically the Sandworm hacking group within the GRU Russian military intelligence organization, by security researchers, Google, and several governments.\n\n== 2017 cyberattack ==\n\nOn 27 June 2017, a major global cyberattack began (Ukrainian companies were among the first to state they were being attacked), utilizing a new variant of Petya. On that day, Kaspersky Lab reported infections in France, Germany, Italy, Poland, the United Kingdom, and the United States, but that the majority of infections targeted Russia and Ukraine, where more than 80 companies were initially attacked, including the National Bank of Ukraine. ESET estimated on 28 June 2017 that 80% of all infections were in Ukraine, with Germany second hardest hit with about 9%. Russian president Vladimir Putin's press secretary, Dmitry Peskov, stated that the attack had caused no serious damage in Russia. Experts believed this was a politically-motivated attack against Ukraine, since it occurred on the eve of the Ukrainian holiday Constitution Day.Kaspersky dubbed this variant \"NotPetya\", as it has major differences in its operations in comparison to earlier variants. McAfee engineer Christiaan Beek stated that this variant was designed to spread quickly, and that it had been targeting \"complete energy companies, the power grid, bus stations, gas stations, the airport, and banks\".It was believed that the software update mechanism of M.E.Doc\u2014a Ukrainian tax preparation program that, according to F-Secure analyst Mikko Hypp\u00f6nen, \"appears to be de facto\" among companies doing business in the country\u2014had been compromised to spread the malware. Analysis by ESET found that a backdoor had been present in the update system for at least six weeks prior to the attack, describing it as a \"thoroughly well-planned and well-executed operation\". The developers of M.E.Doc denied that they were entirely responsible for the cyberattack, stating that they too were victims.On 4 July 2017, Ukraine's cybercrime unit seized the company's servers after detecting \"new activity\" that it believed would result in \"uncontrolled proliferation\" of malware. Ukraine police advised M.E.Doc users to stop using the software, as it presumed that the backdoor was still present. Analysis of the seized servers showed that software updates had not been applied since 2013, there was evidence of Russian presence, and an employee's account on the servers had been compromised; the head of the units warned that M.E.Doc could be found criminally responsible for enabling the attack because of its negligence in maintaining the security of their servers.\n\n== Operation ==\nPetya's payload infects the computer's master boot record (MBR), overwrites the Windows bootloader, and triggers a restart. Upon startup, the payload encrypts the Master File Table of the NTFS file system, and then displays the ransom message demanding a payment made in Bitcoin. Meanwhile, the computer's screen displays a purportedly output by chkdsk, Windows' file system scanner, suggesting that the hard drive's sectors are being repaired.The original payload required the user to grant it administrative privileges; one variant of Petya was bundled with a second payload, Mischa, which activated if Petya failed to install. Mischa is a more conventional ransomware payload that encrypts user documents, as well as executable files, and does not require administrative privileges to execute. The earlier versions of Petya disguised their payload as a PDF file, attached to an e-mail. United States Computer Emergency Response Team (US-CERT) and National Cybersecurity and Communications Integration Center (NCCIC) released Malware Initial Findings Report (MIFR) about Petya on 30 June 2017.The \"NotPetya\" variant used in the 2017 attack uses EternalBlue, an exploit that takes advantage of a vulnerability in Windows' Server Message Block (SMB) protocol.  EternalBlue is generally believed to have been developed by the U.S. National Security Agency (NSA); it was leaked in April 2017 and was also used by WannaCry. The malware harvests passwords (using tweaked build of open-source Mimikatz) and uses other techniques to spread to other computers on the same network, and uses those passwords in conjunction with PSExec to run code on other local computers. Additionally, although it still purports to be ransomware, the encryption routine was modified so that the malware could not technically revert its changes. This characteristic, along with other unusual signs in comparison to WannaCry (including the relatively low unlock fee of US$300, and using a single, fixed Bitcoin wallet to collect ransom payments rather than generating a unique ID for each specific infection for tracking purposes), prompted researchers to speculate that this attack was not intended to be a profit-generating venture, but to damage devices quickly, and ride off the media attention WannaCry received by claiming to be ransomware.\n\n== Mitigation ==\n\nIt was found that it may be possible to stop the encryption process if an infected computer is immediately shut down when the fictitious chkdsk screen appears, and a security analyst proposed that creating read-only files named perfc and/or perfc.dat in the Windows installation directory could prevent the payload of the current strain from executing. The email address listed on the ransom screen was suspended by its provider, Posteo, for being a violation of its terms of use. As a result, infected users could not actually send the required payment confirmation to the perpetrator. Additionally, if the computer's filesystem was FAT based, the MFT encryption sequence was skipped, and only the ransomware's message was displayed, allowing data to be recovered trivially.Microsoft had already released patches for supported versions of Windows in March 2017 to address the EternalBlue vulnerability. This was followed by patches for unsupported versions of Windows (such as Windows XP) in May 2017, in the direct wake of WannaCry. Wired believed that \"based on the extent of damage Petya has caused so far, though, it appears that many companies have put off patching, despite the clear and potentially devastating threat of a similar ransomware spread.\" Some enterprises may consider it too disruptive to install updates on certain systems, either due to possible downtime or compatibility concerns, which can be problematic in some environments.\n\n== Impact ==\nIn a report published by Wired, a White House assessment pegged the total damages brought about by NotPetya to more than $10 billion. This assessment was repeated by former Homeland Security advisor Tom Bossert, who at the time of the attack was the most senior cybersecurity focused official in the US government.During the attack initiated on 27 June 2017, the radiation monitoring system at Ukraine's Chernobyl Nuclear Power Plant went offline. Several Ukrainian ministries, banks and metro systems were also affected. It is said to have been the most destructive cyberattack ever.Among those affected elsewhere included British advertising company WPP, Maersk Line, American pharmaceutical company Merck & Co. (internationally doing business as MSD), Russian oil company Rosneft (its oil production was unaffected), multinational law firm DLA Piper, French construction company Saint-Gobain and its retail and subsidiary outlets in Estonia, British consumer goods company Reckitt Benckiser, German personal care company Beiersdorf, German logistics company DHL, United States food company Mondelez International, and American hospital operator Heritage Valley Health System. The Cadbury's Chocolate Factory in Hobart, Tasmania, is the first company in Australia to be affected by Petya. On 28 June 2017, JNPT, India's largest container port, had reportedly been affected, with all operations coming to a standstill. Princeton Community Hospital in rural West Virginia will scrap and replace its entire computer network on its path to recovery.The business interruption to Maersk, the world's largest container ship and supply vessel operator, was estimated between $200m and $300m in lost revenues.The business impact on FedEx is estimated to be $400m in 2018, according to the company's 2019 annual report.Jens Stoltenberg, NATO Secretary-General, pressed the alliance to strengthen its cyber defenses, saying that a cyberattack could trigger the Article 5 principle of collective defense.Mondelez International's insurance carrier, Zurich American Insurance Company, has refused to pay out a claim for cleaning up damage from a Notpetya infection, on the grounds that Notpetya is an \"act of war\" that is not covered by the policy.  Mondelez sued Zurich American for $100 million in 2018; the suit was settled in 2022 with the terms of the settlement remaining confidential.\n\n== Reaction ==\nEuropol said it was aware of and urgently responding to reports of a cyber attack in member states of the European Union. The United States Department of Homeland Security was involved and coordinating with its international and local partners. In a letter to the NSA, Democratic Congressman Ted Lieu asked the agency to collaborate more actively with technology companies to notify them of software vulnerabilities and help them prevent future attacks based on malware created by the NSA.\nOn 15 February 2018, the Trump administration blamed Russia for the attack and warned that there would be \"international consequences\". The United Kingdom and the Australian government also issued similar statements.In October 2020 the DOJ named further GRU officers in an indictment.\nAt the same time, the UK government blamed GRU's Sandworm also for attacks on the 2020 Summer Games.\n\n== Other notable low-level malware ==\nCIH (1998)\nStuxnet (2010)\nWannaCry (2017)"
    }
  },
  {
    "instruction": "Tor (network)\n\n==Introduction==\nTor, short for \"The Onion Router,\" is free and open-source software for enabling anonymous communication. It directs Internet traffic via a free, worldwide, volunteer overlay network that consists of more than seven thousand relays.Using Tor makes it more difficult to trace a user's Internet activity. Tor protects personal privacy by concealing a user's location and usage from anyone performing network surveillance or traffic analysis. It protects the user's freedom and ability to communicate confidentially through IP address anonymity using Tor exit nodes.\n\n== Usage ==\n\nTor enables its users to surf the Internet, chat and send instant messages anonymously, and is used by a wide variety of people for both licit and illicit purposes. Tor has, for example, been used by criminal enterprises, hacktivism groups, and law enforcement agencies at cross purposes, sometimes simultaneously; likewise, agencies within the U.S. government variously fund Tor (the U.S. State Department, the National Science Foundation, and \u2013 through the Broadcasting Board of Governors, which itself partially funded Tor until October 2012 \u2013 Radio Free Asia) and seek to subvert it.Tor is not meant to completely solve the issue of anonymity on the web. Tor is not designed to completely erase tracking but instead to reduce the likelihood for sites to trace actions and data back to the user.Tor is also used for illegal activities. These can include privacy protection or censorship circumvention, as well as distribution of child abuse content, drug sales, or malware distribution.Tor has been described by The Economist, in relation to Bitcoin and Silk Road, as being \"a dark corner of the web\". It has been targeted by the American National Security Agency and the British GCHQ signals intelligence agencies, albeit with marginal success, and more successfully by the British National Crime Agency in its Operation Notarise. At the same time, GCHQ has been using a tool named \"Shadowcat\" for \"end-to-end encrypted access to VPS over SSH using the Tor network\". Tor can be used for anonymous defamation, unauthorized news leaks of sensitive information, copyright infringement, distribution of illegal sexual content, selling controlled substances, weapons, and stolen credit card numbers, money laundering, bank fraud, credit card fraud, identity theft and the exchange of counterfeit currency; the black market utilizes the Tor infrastructure, at least in part, in conjunction with Bitcoin. It has also been used to brick IoT devices.In its complaint against Ross William Ulbricht of Silk Road, the US Federal Bureau of Investigation acknowledged that Tor has \"known legitimate uses\". According to CNET, Tor's anonymity function is \"endorsed by the Electronic Frontier Foundation (EFF) and other civil liberties groups as a method for whistleblowers and human rights workers to communicate with journalists\". EFF's Surveillance Self-Defense guide includes a description of where Tor fits in a larger strategy for protecting privacy and anonymity.In 2014, the EFF's Eva Galperin told Businessweek that \"Tor's biggest problem is press. No one hears about that time someone wasn't stalked by their abuser. They hear how somebody got away with downloading child porn.\"The Tor Project states that Tor users include \"normal people\" who wish to keep their Internet activities private from websites and advertisers, people concerned about cyber-spying, and users who are evading censorship such as activists, journalists, and military professionals. In November 2013, Tor had about four million users. According to the Wall Street Journal, in 2012 about 14% of Tor's traffic connected from the United States, with people in \"Internet-censoring countries\" as its second-largest user base. Tor is increasingly used by victims of domestic violence and the social workers and agencies that assist them, even though shelter workers may or may not have had professional training on cyber-security matters. Properly deployed, however, it precludes digital stalking, which has increased due to the prevalence of digital media in contemporary online life. Along with SecureDrop, Tor is used by news organizations such as The Guardian, The New Yorker, ProPublica and The Intercept to protect the privacy of whistleblowers.In March 2015, the Parliamentary Office of Science and Technology released a briefing which stated that \"There is widespread agreement that banning online anonymity systems altogether is not seen as an acceptable policy option in the U.K.\" and that \"Even if it were, there would be technical challenges.\" The report further noted that Tor \"plays only a minor role in the online viewing and distribution of indecent images of children\" (due in part to its inherent latency); its usage by the Internet Watch Foundation, the utility of its onion services for whistleblowers, and its circumvention of the Great Firewall of China were touted.Tor's executive director, Andrew Lewman, also said in August 2014 that agents of the NSA and the GCHQ have anonymously provided Tor with bug reports.The Tor Project's FAQ offers supporting reasons for the EFF's endorsement:\n\nCriminals can already do bad things. Since they're willing to break laws, they already have lots of options available that provide better privacy than Tor provides...\nTor aims to provide protection for ordinary people who want to follow the law. Only criminals have privacy right now, and we need to fix that...\n\nSo yes, criminals could in theory use Tor, but they already have better options, and it seems unlikely that taking Tor away from the world will stop them from doing their bad things. At the same time, Tor and other privacy measures can fight identity theft, physical crimes like stalking, and so on.\n\n== Operation ==\n\nTor aims to conceal its users' identities and their online activity from surveillance and traffic analysis by separating identification and routing. It is an implementation of onion routing, which encrypts and then randomly bounces communications through a network of relays run by volunteers around the globe. These onion routers employ encryption in a multi-layered manner (hence the onion metaphor) to ensure perfect forward secrecy between relays, thereby providing users with anonymity in a network location. That anonymity extends to the hosting of censorship-resistant content by Tor's anonymous onion service feature. Furthermore, by keeping some of the entry relays (bridge relays) secret, users can evade Internet censorship that relies upon blocking public Tor relays.Because the IP address of the sender and the recipient are not both in cleartext at any hop along the way, anyone eavesdropping at any point along the communication channel cannot directly identify both ends. Furthermore, to the recipient, it appears that the last Tor node (called the exit node), rather than the sender, is the originator of the communication.\n\n\n*** Originating traffic ***\n\nA Tor user's SOCKS-aware applications can be configured to direct their network traffic through a Tor instance's SOCKS interface, which is listening on TCP port 9050 (for standalone Tor) or 9150 (for Tor Browser bundle) at localhost. Tor periodically creates virtual circuits through the Tor network through which it can multiplex and onion-route that traffic to its destination. Once inside a Tor network, the traffic is sent from router to router along the circuit, ultimately reaching an exit node at which point the cleartext packet is available and is forwarded on to its original destination. Viewed from the destination, the traffic appears to originate at the Tor exit node.\n\nTor's application independence sets it apart from most other anonymity networks: it works at the Transmission Control Protocol (TCP) stream level. Applications whose traffic is commonly anonymized using Tor include Internet Relay Chat (IRC), instant messaging, and World Wide Web browsing.\n\n\n*** Onion services ***\n\nTor can also provide anonymity to websites and other servers. Servers configured to receive inbound connections only through Tor are called onion services (formerly, hidden services). Rather than revealing a server's IP address (and thus its network location), an onion service is accessed through its onion address, usually via the Tor Browser. The Tor network understands these addresses by looking up their corresponding public keys and introduction points from a distributed hash table within the network. It can route data to and from onion services, even those hosted behind firewalls or network address translators (NAT), while preserving the anonymity of both parties. Tor is necessary to access these onion services.Onion services were first specified in 2003 and have been deployed on the Tor network since 2004. Other than the database that stores the onion service descriptors, Tor is decentralized by design; there is no direct readable list of all onion services, although a number of onion services catalog publicly known onion addresses. TorSearch is an internet search engine that indexes pages to help find content in websites located on the Tor network.Because onion services route their traffic entirely through the Tor network, connection to an onion service is encrypted end-to-end and not subject to eavesdropping. There are, however, security issues involving Tor onion services. For example, services that are reachable through Tor onion services and the public Internet are susceptible to correlation attacks and thus not perfectly hidden. Other pitfalls include misconfigured services (e.g. identifying information included by default in web server error responses), uptime and downtime statistics, intersection attacks, and user error. The open source OnionScan program, written by independent security researcher Sarah Jamie Lewis, comprehensively examines onion services for numerous flaws and vulnerabilities. (Lewis has also pioneered the field of \"Onion Dildonics\", sex toys which make use of Tor through the Ricochet protocol)Onion services can also be accessed from a standard web browser without client-side connection to the Tor network, using services like Tor2web. Popular sources of .onion links include Pastebin, Twitter, Reddit, and other Internet forums.\n\n== Weaknesses ==\nLike all current low-latency anonymity networks, Tor cannot and does not attempt to protect against monitoring of traffic at the boundaries of the Tor network (i.e., the traffic entering and exiting the network). While Tor does provide protection against traffic analysis, it cannot prevent traffic confirmation (also called end-to-end correlation).A 2009 study revealed that Tor and the alternative network system JonDonym (Java Anon Proxy, JAP) are considered more resilient to website fingerprinting techniques than other tunneling protocols.The reason for this is that conventional single-hop VPN protocols do not need to reconstruct packet data nearly as much as a multi-hop service like Tor or JonDonym. Website fingerprinting yielded greater than 90% accuracy for identifying HTTP packets on conventional VPN protocols versus Tor which yielded only 2.96% accuracy. However, some protocols like OpenSSH and OpenVPN required a large amount of data before HTTP packets were identified.Researchers from the University of Michigan developed a network scanner allowing identification of 86% of live Tor \"bridges\" with a single scan.\n\n\n*** Consensus blocking ***\nLike many decentralized systems, Tor relies on a consensus mechanism to periodically update its current operating parameters, which for Tor are network parameters like which nodes are good/bad relays, exits, guards, and how much traffic each can handle. Tor's architecture for deciding the consensus relies on a small number of directory authority nodes voting on current network parameters. Currently, there are eight directory authority nodes, and their health is publicly monitored. The IP addresses of the authority nodes are hard coded into each Tor client. The authority nodes vote every hour to update the consensus, and clients download the most recent consensus on startup. A network congestion attack, such as a DDoS, can prevent the consensus nodes from communicating and thus prevent voting to update the consensus.\n\n\n*** Eavesdropping ***\n\n\n**** Autonomous system (AS) eavesdropping ****\nIf the same autonomous system (AS), responsible for routing packets at least partly, is present on both path segments from a client to entry relay and from exit relay to destination, such an AS can statistically correlate traffic on the entry and exit segments of the path (i.e. traffic confirmation) and potentially infer the destination with which the client communicated. In 2012, LASTor proposed a method to predict a set of potential ASes on these two segments and then avoid choosing this path during the path selection algorithm on the client side. In this paper, they also improve latency by choosing shorter geographical paths between a client and destination.\n\n\n**** Exit node eavesdropping ****\nIn September 2007, Dan Egerstad, a Swedish security consultant, revealed he had intercepted usernames and passwords for email accounts by operating and monitoring Tor exit nodes. As Tor cannot encrypt the traffic between an exit node and the target server, any exit node is in a position to capture traffic passing through it that does not use end-to-end encryption such as Secure Sockets Layer (SSL) or Transport Layer Security (TLS). While this may not inherently breach the anonymity of the source, traffic intercepted in this way by malicious Tor exit nodes operators can expose information about the source in either or both of payload and protocol data. Furthermore, Egerstad is circumspect about the possible subversion of Tor by intelligence agencies:\nIf you actually look into where these Tor nodes are hosted and how big they are, some of these nodes cost thousands of dollars each month just to host because they're using lots of bandwidth, they're heavy-duty servers and so on. Who would pay for this and be anonymous?\nIn October 2019, a Tor researcher revealed that since at least 2017, there were hundreds of highly suspicious entry, relay, and exit nodes, run by an unknown group, in an unprecedented scale. It was alleged that this number of servers could pose the risk of a sybil attack as it could map Tor users' routes inside the network, increasing risk of deanonymization. At some point there were about 900 nodes running and by November 2021 about 600 of them were purged. \nAlthough described as being a deanonymization attempt, the motives and the achievements of this possibly on-going event are still unknown.\n\n\n**** Internal communication attack ****\nIn October 2011, a research team from ESIEA claimed to have discovered a way to compromise the Tor network by decrypting communication passing over it. The technique they describe requires creating a map of Tor network nodes, controlling one-third of them, and then acquiring their encryption keys and algorithm seeds. Then, using these known keys and seeds, they claim the ability to decrypt two encryption layers out of three. They claim to break the third key by a statistical attack. In order to redirect Tor traffic to the nodes they controlled, they used a denial-of-service attack. A response to this claim has been published on the official Tor Blog stating these rumors of Tor's compromise are greatly exaggerated.\n\n\n*** Traffic-analysis attack ***\nThere are two methods of traffic-analysis attack, passive and active. In the passive traffic-analysis method, the attacker extracts features from the traffic of a specific flow on one side of the network and looks for those features on the other side of the network. In the active traffic-analysis method, the attacker alters the timings of the packets of a flow according to a specific pattern and looks for that pattern on the other side of the network; therefore, the attacker can link the flows in one side to the other side of the network and break the anonymity of it. It is shown that, although timing noise is added to the packets, there are active traffic analysis methods that are robust against such a noise.Steven Murdoch and George Danezis from University of Cambridge presented an article at the 2005 IEEE Symposium on security and privacy on traffic-analysis techniques that allow adversaries with only a partial view of the network to infer which nodes are being used to relay the anonymous streams. These techniques greatly reduce the anonymity provided by Tor. Murdoch and Danezis have also shown that otherwise unrelated streams can be linked back to the same initiator. This attack, however, fails to reveal the identity of the original user. Murdoch has been working with and has been funded by Tor since 2006.\n\n\n*** Tor exit node block ***\nOperators of Internet sites have the ability to prevent traffic from Tor exit nodes or to offer reduced functionality for Tor users. For example, it is not generally possible to edit Wikipedia when using Tor or when using an IP address also used by a Tor exit node. The BBC blocks the IP addresses of all known Tor exit nodes from its iPlayer service, although non-exit relays and bridges are not blocked.\n\n\n*** Bad apple attack ***\nIn March 2011, researchers with the Rocquencourt French Institute for Research in Computer Science and Automation (Institut national de recherche en informatique et en automatique, INRIA), documented an attack that is capable of revealing the IP addresses of BitTorrent users on the Tor network. The \"bad apple attack\" exploits Tor's design and takes advantage of insecure application used to associate the simultaneous use of a secure application with the IP address of the Tor user in question. One method of attack depends on control of an exit node or hijacking tracker responses, while a secondary attack method is based in part on the statistical exploitation of distributed hash table tracking. According to the study:The results presented in the bad apple attack research paper are based on an attack launched against the Tor network by the authors of the study. The attack targeted six exit nodes, lasted for twenty-three days, and revealed a total of 10,000 IP addresses of active Tor users. This study is significant because it is the first documented attack designed to target P2P file-sharing applications on Tor. BitTorrent may generate as much as 40% of all traffic on Tor. Furthermore, the bad apple attack is effective against insecure use of any application over Tor, not just BitTorrent.\n\n\n*** Sniper attack ***\nJansen et al.., describes a DDoS attack targeted at the Tor node software, as well as defenses against that attack and its variants. The attack works using a colluding client and server, and filling the queues of the exit node until the node runs out of memory, and hence can serve no other (genuine) clients. By attacking a significant proportion of the exit nodes this way, an attacker can degrade the network and increase the chance of targets using nodes controlled by the attacker.\n\n\n*** Heartbleed bug ***\nThe Heartbleed OpenSSL bug disrupted the Tor network for several days in April 2014 while private keys were renewed. The Tor Project recommended Tor relay operators and onion service operators revoke and generate fresh keys after patching OpenSSL, but noted Tor relays use two sets of keys and Tor's multi-hop design minimizes the impact of exploiting a single relay. Five hundred eighty-six relays, later found to be susceptible to the Heartbleed bug, were taken offline as a precautionary measure.\n\n\n*** Relay early traffic confirmation attack ***\n\nOn 30 July 2014, the Tor Project issued the security advisory \"relay early traffic confirmation attack\" in which the project discovered a group of relays that tried to de-anonymize onion service users and operators. In summary, the attacking onion service directory node changed the headers of cells being relayed tagging them as \"relay\" or \"relay early\" cells differently to encode additional information and sent them back to the requesting user/operator. If the user's/operator's guard/entry node was also part of the attacking relays, the attacking relays might be able to capture the IP address of the user/operator along with the onion service information that the user/operator was requesting. The attacking relays were stable enough to be designated as \"suitable as hidden service directory\" and \"suitable as entry guard\"; therefore, both the onion service users and the onion services might have used those relays as guards and hidden service directory nodes.The attacking nodes joined the network early in the year on 30 January and the project removed them on 4 July. Although the attack's beginning is unclear, the project implied that between February and July, IP addresses of onion service users and operators might have been exposed.The project mentioned the following mitigations besides removing the attacking relays from the network:\n\npatched relay software to prevent relays from relaying cells with \"relay early\" headers that were not intended.\nplanned update for users' proxy software so that they could inspect if they received \"relay early\" cells from the relays (as they are not supposed to), along with the settings to connect to just one guard node instead of selecting randomly from 3 to reduce the probability of connecting to an attacking relay\nrecommended that onion services should consider changing their locations\nreminded users and onion service operators that Tor could not prevent de-anonymization if the attacker controlled or could listen to both ends of the Tor circuit, like in this attack.In November 2014 there was speculation in the aftermath of Operation Onymous, resulting in 17 arrests internationally, that a Tor weakness had been exploited. A representative of Europol was secretive about the method used, saying: \"This is something we want to keep for ourselves. The way we do this, we can't share with the whole world, because we want to do it again and again and again.\"\nA BBC source cited a \"technical breakthrough\"\nthat allowed tracking physical locations of servers, and the initial number of infiltrated sites led to the exploit speculation. Andrew Lewman\u2014a Tor Project representative\u2014downplayed this possibility, suggesting that execution of more traditional police work was more likely.In November 2015 court documents on the matter\naddressed concerns about security research ethics and the right of not being unreasonably searched as guaranteed by the US Fourth Amendment. Moreover, the documents, along with expert opinions, may also show the connection between the network attack and the law enforcement operation including:\n\nthe search warrant for an administrator of Silkroad 2.0 indicated that from January 2014 until July, the FBI received information from a \"university-based research institute\" with the information being \"reliable IP addresses for Tor and onion services such as SR2\" that led to the identification of \"at least another seventeen black markets on Tor\" and \"approximately 78 IP addresses that accessed a vendor .onion address.\" One of these IP addresses led to the arrest of the administrator\nthe chronology and nature of the attack fitted well with the operation\na senior researcher of International Computer Science Institute, part of University of California, Berkeley, said in an interview that the institute which worked with the FBI was \"almost certainly\" Carnegie Mellon University (CMU), and this concurred with the Tor Project's assessment and with an earlier analysis of Edward Felten, a computer security professor at Princeton University, about researchers from CMU's CERT/CC being involvedIn his analysis published on 31 July, besides raising ethical issues, Felten also questioned the fulfillment of CERT/CC's purposes which were to prevent attacks, inform the implementers of vulnerabilities, and eventually inform the public. Because in this case, CERT/CC's staff did the opposite which was to carry out a large-scale long-lasting attack, withhold vulnerability information from the implementers, and withhold the same information from the public. CERT/CC is a non-profit, computer security research organization publicly funded through the US federal government.\n\n\n*** Mouse fingerprinting ***\nIn March 2016, a security researcher based in Barcelona demonstrated laboratory techniques using time measurement via JavaScript at the 1-millisecond level which could potentially identify and correlate a user's unique mouse movements, provided the user has visited the same \"fingerprinting\" website with both the Tor browser and a regular browser. This proof of concept exploits the \"time measurement via JavaScript\" issue, which had been an open ticket on the Tor Project for ten months.\n\n\n*** Circuit fingerprinting attack ***\nIn 2015, the administrators of Agora, a darknet market, announced they were taking the site offline in response to a recently discovered security vulnerability in Tor. They did not say what the vulnerability was, but Wired speculated it was the \"Circuit Fingerprinting Attack\" presented at the USENIX security conference.\n\n\n*** Volume information ***\nA study showed \"anonymization solutions protect only partially against target selection that may lead to efficient surveillance\" as they typically \"do not hide the volume information necessary to do target selection\".\n\n== Implementations ==\n\nThe main implementation of Tor is written primarily in C.\n\n\n*** Tor Browser ***\n\nThe Tor Browser is a web browser capable of accessing the Tor network. It was created as the Tor Browser Bundle by Steven J. Murdoch and announced in January 2008. The Tor Browser consists of a modified Mozilla Firefox ESR web browser, the TorButton, TorLauncher, NoScript and the Tor proxy. Users can run the Tor Browser from removable media. It can operate under Microsoft Windows, macOS, Android and Linux.The default search engine is DuckDuckGo (until version 4.5, Startpage.com was its default). The Tor Browser automatically starts Tor background processes and routes traffic through the Tor network. Upon termination of a session the browser deletes privacy-sensitive data such as HTTP cookies and the browsing history. This is effective in reducing web tracking and canvas fingerprinting, and it also helps to prevent creation of a filter bubble.To allow download from places where accessing the Tor Project URL may be risky or blocked, a GitHub repository is maintained with links for releases hosted in other domains.\n\n\n**** Firefox/Tor browser attack ****\nIn 2011, the Dutch authority investigating child pornography discovered the IP address of a Tor onion service site called \"Pedoboard\" from an unprotected administrator's account and gave it to the FBI, who traced it to Aaron McGrath. After a year of surveillance, the FBI launched \"Operation Torpedo\" which resulted in McGrath's arrest and allowed them to install their Network Investigative Technique (NIT) malware on the servers for retrieving information from the users of the three onion service sites that McGrath controlled. The technique, exploiting a Firefox/Tor browser's vulnerability that had been patched and targeting users that had not updated, had a Flash application pinging a user's IP address directly back to an FBI server, and resulted in revealing at least 25 US users as well as numerous users from other countries. McGrath was sentenced to 20 years in prison in early 2014, with at least 18 other users including a former Acting HHS Cyber Security Director being sentenced in subsequent cases.In August 2013 it was discovered that the Firefox browsers in many older versions of the Tor Browser Bundle were vulnerable to a JavaScript-deployed shellcode attack, as NoScript was not enabled by default. Attackers used this vulnerability to extract users' MAC and IP addresses and Windows computer names. News reports linked this to a Federal Bureau of Investigation (FBI) operation targeting Freedom Hosting's owner, Eric Eoin Marques, who was arrested on a provisional extradition warrant issued by a United States' court on 29 July. The FBI extradited Marques from Ireland to the state of Maryland on 4 charges: distributing; conspiring to distribute; and advertising child pornography, as well as aiding and abetting advertising of child pornography. The warrant alleged that Marques was \"the largest facilitator of child porn on the planet\". The FBI acknowledged the attack in a 12 September 2013 court filing in Dublin; further technical details from a training presentation leaked by Edward Snowden revealed the code name for the exploit as \"EgotisticalGiraffe\".In 2022, Kaspersky researchers found that when looking up \"Tor Browser\" in Chinese on YouTube, one of the URLs provided under the top-ranked Chinese-language video actually pointed to a malware disguised as Tor Browser. Once installed, it saves browsing history and form data that genuine Tor forgot by default, and even downloads malicious components to computers with IP addresses in China. Kaspersky researchers noted that the malware was not stealing data to sell for profit, but was designed to identify users.\n\n\n*** Tor Messenger ***\nOn 29 October 2015, the Tor Project released Tor Messenger Beta, an instant messaging program based on Instantbird with Tor and OTR built in and used by default. Like Pidgin and Adium, Tor Messenger supports multiple different instant messaging protocols; however, it accomplishes this without relying on libpurple, implementing all chat protocols in the memory-safe language JavaScript instead.According to Lucian Armasu of Toms Hardware, in April 2018, the Tor Project shut down the Tor Messenger project for three reasons: the developers of \"Instabird\"  [sic] discontinued support for their own software, limited resources and known metadata problems. The Tor Messenger developers explained that overcoming any vulnerabilities discovered in the future would be impossible due to the project relying on outdated software dependencies.\n\n\n*** Tor Phone ***\n\nIn 2016, Tor developer Mike Perry announced a prototype tor-enabled smartphone bases on CopperheadOS. It was meant as  a direction for Tor on mobile. The project was called 'Mission Improbable'. Copperhead's then lead developer Daniel Micay welcomed the prototype. Using Tor with Orbot and Tor Browser are supported by custom Android operating systems CalyxOS and DivestOS. GrapheneOS supports using Orbot VPN but not Tor Browser.\n\n\n*** Third-party applications ***\nThe Vuze (formerly Azureus) BitTorrent client, Bitmessage anonymous messaging system, and TorChat instant messenger include Tor support. The Briar messenger routes all messaging via Tor by default. OnionShare allows users to share files using Tor.The Guardian Project is actively developing a free and open-source suite of applications and firmware for the Android operating system to improve the security of mobile communications. The applications include the ChatSecure instant messaging client, Orbot Tor implementation (also available for iOS), Orweb (discontinued) privacy-enhanced mobile browser, Orfox, the mobile counterpart of the Tor Browser, ProxyMob Firefox add-on, and ObscuraCam.Onion Browser is open-source, privacy-enhancing web browser for iOS, which uses Tor. It is available in the iOS App Store, and source code is available on GitHub.Brave added support for Tor in its desktop browser's private-browsing mode. Users can switch to Tor-enabled browsing by clicking on the hamburger menu on the top right corner of the browser.\n\n\t\t\n\t\t\n\t\t\n\t\t\n\n\n*** Security-focused operating systems ***\nSeveral security-focused operating systems make or made extensive use of Tor. These include Hardened Linux From Scratch, Incognito, Libert\u00e9 Linux, Qubes OS, Subgraph, Parrot OS, Tails, Tor-ramdisk, and Whonix.\n\n== Reception, impact, and legislation ==\n\nTor has been praised for providing privacy and anonymity to vulnerable Internet users such as political activists fearing surveillance and arrest, ordinary web users seeking to circumvent censorship, and people who have been threatened with violence or abuse by stalkers. The U.S. National Security Agency (NSA) has called Tor \"the king of high-secure, low-latency Internet anonymity\", and BusinessWeek magazine has described it as \"perhaps the most effective means of defeating the online surveillance efforts of intelligence agencies around the world\". Other media have described Tor as \"a sophisticated privacy tool\", \"easy to use\" and \"so secure that even the world's most sophisticated electronic spies haven't figured out how to crack it\".Advocates for Tor say it supports freedom of expression, including in countries where the Internet is censored, by protecting the privacy and anonymity of users. The mathematical underpinnings of Tor lead it to be characterized as acting \"like a piece of infrastructure, and governments naturally fall into paying for infrastructure they want to use\".The project was originally developed on behalf of the U.S. intelligence community and continues to receive U.S. government funding, and has been criticized as \"more resembl[ing] a spook project than a tool designed by a culture that values accountability or transparency\". As of 2012, 80% of The Tor Project's $2M annual budget came from the United States government, with the U.S. State Department, the Broadcasting Board of Governors, and the National Science Foundation as major contributors, aiming \"to aid democracy advocates in authoritarian states\". Other public sources of funding include DARPA, the U.S. Naval Research Laboratory, and the Government of Sweden. Some have proposed that the government values Tor's commitment to free speech, and uses the darknet to gather intelligence. Tor also receives funding from NGOs including Human Rights Watch, and private sponsors including Reddit and Google. Dingledine said that the United States Department of Defense funds are more similar to a research grant than a procurement contract. Tor executive director Andrew Lewman said that even though it accepts funds from the U.S. federal government, the Tor service did not collaborate with the NSA to reveal identities of users.Critics say that Tor is not as secure as it claims, pointing to U.S. law enforcement's investigations and shutdowns of Tor-using sites such as web-hosting company Freedom Hosting and online marketplace Silk Road. In October 2013, after analyzing documents leaked by Edward Snowden, The Guardian reported that the NSA had repeatedly tried to crack Tor and had failed to break its core security, although it had had some success attacking the computers of individual Tor users. The Guardian also published a 2012 NSA classified slide deck, entitled \"Tor Stinks\", which said: \"We will never be able to de-anonymize all Tor users all the time\", but \"with manual analysis we can de-anonymize a very small fraction of Tor users\". When Tor users are arrested, it is typically due to human error, not to the core technology being hacked or cracked. On 7 November 2014, for example, a joint operation by the FBI, ICE Homeland Security investigations and European Law enforcement agencies led to 17 arrests and the seizure of 27 sites containing 400 pages. A late 2014 report by Der Spiegel using a new cache of Snowden leaks revealed, however, that as of 2012 the NSA deemed Tor on its own as a \"major threat\" to its mission, and when used in conjunction with other privacy tools such as OTR, Cspace, ZRTP, RedPhone, Tails, and TrueCrypt was ranked as \"catastrophic,\" leading to a \"near-total loss/lack of insight to target communications, presence...\"\n\n\n*** 2011 ***\nIn March 2011, The Tor Project received the Free Software Foundation's 2010 Award for Projects of Social Benefit. The citation read, \"Using free software, Tor has enabled roughly 36 million people around the world to experience freedom of access and expression on the Internet while keeping them in control of their privacy and anonymity. Its network has proved pivotal in dissident movements in both Iran and more recently Egypt.\"Iran tried to block Tor at least twice in 2011. One attempt simply blocked all servers with 2-hour-expiry security certificates; it was successful for less than 24 hours.\n\n\n*** 2012 ***\nIn 2012, Foreign Policy magazine named Dingledine, Mathewson, and Syverson among its Top 100 Global Thinkers \"for making the web safe for whistleblowers\".\n\n\n*** 2013 ***\nIn 2013, Jacob Appelbaum described Tor as a \"part of an ecosystem of software that helps people regain and reclaim their autonomy. It helps to enable people to have agency of all kinds; it helps others to help each other and it helps you to help yourself. It runs, it is open and it is supported by a large community spread across all walks of life.\"In June 2013, whistleblower Edward Snowden used Tor to send information about PRISM to The Washington Post and The Guardian.\n\n\n*** 2014 ***\nIn 2014, the Russian government offered a $111,000 contract to \"study the possibility of obtaining technical information about users and users' equipment on the Tor anonymous network\".In September 2014, in response to reports that Comcast had been discouraging customers from using the Tor Browser, Comcast issued a public statement that \"We have no policy against Tor, or any other browser or software.\"In October 2014, The Tor Project hired the public relations firm Thomson Communications to improve its public image (particularly regarding the terms \"Dark Net\" and \"hidden services,\" which are widely viewed as being problematic) and to educate journalists about the technical aspects of Tor.Turkey blocked downloads of Tor Browser from the Tor Project.\n\n\n*** 2015 ***\nIn June 2015, the special rapporteur from the United Nations' Office of the High Commissioner for Human Rights specifically mentioned Tor in the context of the debate in the U.S. about allowing so-called backdoors in encryption programs for law enforcement purposes in an interview for The Washington Post.\nIn July 2015, the Tor Project announced an alliance with the Library Freedom Project to establish exit nodes in public libraries. The pilot program, which established a middle relay running on the excess bandwidth afforded by the Kilton Library in Lebanon, New Hampshire, making it the first library in the U.S. to host a Tor node, was briefly put on hold when the local city manager and deputy sheriff voiced concerns over the cost of defending search warrants for information passed through the Tor exit node. Although the Department of Homeland Security (DHS) had alerted New Hampshire authorities to the fact that Tor is sometimes used by criminals, the Lebanon Deputy Police Chief and the Deputy City Manager averred that no pressure to strong-arm the library was applied, and the service was re-established on 15 September 2015. U.S. Rep. Zoe Lofgren (D-Calif) released a letter on 10 December 2015, in which she asked the DHS to clarify its procedures, stating that \"While the Kilton Public Library's board ultimately voted to restore their Tor relay, I am no less disturbed by the possibility that DHS employees are pressuring or persuading public and private entities to discontinue or degrade services that protect the privacy and anonymity of U.S. citizens.\" In a 2016 interview, Kilton Library IT Manager Chuck McAndrew stressed the importance of getting libraries involved with Tor: \"Librarians have always cared deeply about protecting privacy, intellectual freedom, and access to information (the freedom to read). Surveillance has a very well-documented chilling effect on intellectual freedom. It is the job of librarians to remove barriers to information.\" The second library to host a Tor node was the Las Naves Public Library in Valencia, Spain, implemented in the first months of 2016.In August 2015, an IBM security research group, called \"X-Force\", put out a quarterly report that advised companies to block Tor on security grounds, citing a \"steady increase\" in attacks from Tor exit nodes as well as botnet traffic.In September 2015, Luke Millanta created OnionView (now defunct), a web service that plots the location of active Tor relay nodes onto an interactive map of the world. The project's purpose was to detail the network's size and escalating growth rate.In December 2015, Daniel Ellsberg (of the Pentagon Papers), Cory Doctorow (of Boing Boing), Edward Snowden, and artist-activist Molly Crabapple, amongst others, announced their support of Tor.\n\n\n*** 2016 ***\nIn March 2016, New Hampshire state representative Keith Ammon introduced a bill allowing public libraries to run privacy software. The bill specifically referenced Tor. The text was crafted with extensive input from Alison Macrina, the director of the Library Freedom Project. The bill was passed by the House 268\u201362.Also in March 2016, the first Tor node, specifically a middle relay, was established at a library in Canada, the Graduate Resource Centre (GRC) in the Faculty of Information and Media Studies (FIMS) at the University of Western Ontario. Given that the running of a Tor exit node is an unsettled area of Canadian law, and that in general institutions are more capable than individuals to cope with legal pressures, Alison Macrina of the Library Freedom Project has opined that in some ways she would like to see intelligence agencies and law enforcement attempt to intervene in the event that an exit node were established.On 16 May 2016, CNN reported on the case of core Tor developer isis agora lovecruft, who had fled to Germany under the threat of a subpoena by the FBI during the Thanksgiving break of the previous year. The Electronic Frontier Foundation legally represented lovecruft.On 2 December 2016, The New Yorker reported on burgeoning digital privacy and security workshops in the San Francisco Bay Area, particularly at the hackerspace Noisebridge, in the wake of the 2016 United States presidential election; downloading the Tor browser was mentioned. Also, in December 2016, Turkey has blocked the usage of Tor, together with ten of the most used VPN services in Turkey, which were popular ways of accessing banned social media sites and services.Tor (and Bitcoin) was fundamental to the operation of the darkweb marketplace AlphaBay, which was taken down in an international law enforcement operation in July 2017. Despite federal claims that Tor would not shield a user, however, elementary operational security errors outside of the ambit of the Tor network led to the site's downfall.\n\n\n*** 2017 ***\nIn June 2017 the Democratic Socialists of America recommended intermittent Tor usage. And in August 2017, according to reportage cybersecurity firms which specialize in monitoring and researching the dark Web (which relies on Tor as its infrastructure) on behalf of banks and retailers routinely share their findings with the FBI and with other law enforcement agencies \"when possible and necessary\" regarding illegal content. The Russian-speaking underground offering a crime-as-a-service model is regarded as being particularly robust.\n\n\n*** 2018 ***\nIn June 2018, Venezuela blocked access to the Tor network. The block affected both direct connections to the network and connections being made via bridge relays.On 20 June 2018, Bavarian police raided the homes of the board members of the non-profit Zwiebelfreunde, a member of torservers.net, which handles the European financial transactions of riseup.net in connection with a blog post there which apparently promised violence against the upcoming Alternative for Germany convention. Tor came out strongly against the raid against its support organization, which provides legal and financial aid for the setting up and maintenance of high-speed relays and exit nodes. According to torservers.net, on 23 August 2018 the German court at Landgericht M\u00fcnchen ruled that the raid and seizures were illegal. The hardware and documentation seized had been kept under seal, and purportedly were neither analyzed nor evaluated by the Bavarian police.Since October 2018, Chinese online communities within Tor have begun to dwindle due to increased efforts to stop them by the Chinese government.\n\n\n*** 2019 ***\nIn November 2019, Edward Snowden called for a full, unabridged simplified Chinese translation of his autobiography, Permanent Record, as the Chinese publisher had violated their agreement by expurgating all mentions of Tor and other matters deemed politically sensitive by the Chinese Communist Party.\n\n\n*** 2021 ***\nOn 8 December 2021, the Russian government agency Roskomnadzor announced it has banned Tor and six VPN services for failing to abide by the Russian Internet blacklist. Russian ISPs unsuccessfully attempted to block Tor's main website as well as several bridges beginning on 1 December 2021. The Tor Project has appealed to Russian courts over this ban.\n\n\n*** 2022 ***\nIn response to Internet censorship during the Russian invasion of Ukraine, the BBC and VOA have directed Russian audiences to Tor. The Russian government increased efforts to block access to Tor through technical and political means, while the network reported an increase in traffic from Russia, and increased Russian use of its anti-censorship Snowflake tool.Russian courts temporarily lifted the blockade on Tor's website (but not connections to relays) on May 24, 2022 due to Russian law requiring that the Tor Project be involved in the case. However, the blockade was reinstated on July 21, 2022.Iran implemented rolling internet blackouts during the Mahsa Amini protests, and Tor and Snowflake were used to circumvent them.China, with its highly centralized control of its internet, had effectively blocked Tor.\n\n== Improved security ==\nTor responded to earlier vulnerabilities listed above by patching them and improving security. In one way or another, human (user) errors can lead to detection. The Tor Project website provides the best practices (instructions) on how to properly use the Tor browser. When improperly used, Tor is not secure. For example, Tor warns its users that not all traffic is protected; only the traffic routed through the Tor browser is protected. Users are also warned to use HTTPS versions of websites, not to torrent with Tor, not to enable browser plugins, not to open documents downloaded through Tor while online, and to use safe bridges. Users are also warned that they cannot provide their name or other revealing information in web forums over Tor and stay anonymous at the same time.Despite intelligence agencies' claims that 80% of Tor users would be de-anonymized within 6 months in the year 2013, that has still not happened. In fact, as late as September 2016, the FBI could not locate, de-anonymize and identify the Tor user who hacked into the email account of a staffer on Hillary Clinton's email server.The best tactic of law enforcement agencies to de-anonymize users appears to remain with Tor-relay adversaries running poisoned nodes, as well as counting on the users themselves using the Tor browser improperly. For example, downloading a video through the Tor browser and then opening the same file on an unprotected hard drive while online can make the users' real IP addresses available to authorities.\n\n\n*** Odds of detection ***\nWhen properly used, odds of being de-anonymized through Tor are said to be extremely low. Tor project's co-founder Nick Mathewson explained that the problem of \"Tor-relay adversaries\" running poisoned nodes means that a theoretical adversary of this kind is not the network's greatest threat:\n\n\"No adversary is truly global, but no adversary needs to be truly global,\" he says. \"Eavesdropping on the entire Internet is a several-billion-dollar problem. Running a few computers to eavesdrop on a lot of traffic, a selective denial of service attack to drive traffic to your computers, that's like a tens-of-thousands-of-dollars problem.\" At the most basic level, an attacker who runs two poisoned Tor nodes\u2014one entry, one exit\u2014is able to analyse traffic and thereby identify the tiny, unlucky percentage of users whose circuit happened to cross both of those nodes. In 2016 the Tor network offers a total of around 7,000 relays, around 2,000 guard (entry) nodes and around 1,000 exit nodes. So the odds of such an event happening are one in two million (1\u20442000 \u00d7 1\u20441000), give or take.\"\nTor does not provide protection against end-to-end timing attacks: if an attacker can watch the traffic coming out of the target computer, and also the traffic arriving at the target's chosen destination (e.g. a server hosting a .onion site), that attacker can use statistical analysis to discover that they are part of the same circuit.\n\n\n*** Levels of security ***\nDepending on individual user needs, Tor browser offers three levels of security located under the Security Level (the small gray shield at the top-right of the screen) icon > Advanced Security Settings. In addition to encrypting the data, including constantly changing an IP address through a virtual circuit comprising successive, randomly selected Tor relays, several other layers of security are at a user's disposal:\nStandard (default) \u2013 at this security level, all browser features are enabled.\nThis level provides the most usable experience, and the lowest level of security.\nSafer \u2013 at this security level, the following changes apply:\nJavaScript is disabled on non-HTTPS sites.\nOn sites where JavaScript is enabled, performance optimizations are disabled. Scripts on some sites may run slower.\nSome mechanisms of displaying math equations are disabled.\nAudio and video (HTML5 media), and WebGL are click-to-play.\nSafest \u2013 at this security level, these additional changes apply:\nJavaScript is disabled by default on all sites.\nSome fonts, icons, math symbols, and images are disabled.\nAudio and video (HTML5 media), and WebGL are click-to-play.\n\n== Citations ==\n\n== General and cited references ==\nQ: What is the bad apple attack, and how does it exploit Tor's design to reveal the IP addresses of BitTorrent users on the Tor network?",
    "context": "",
    "output": "The bad apple attack is a documented attack that targets P2P file-sharing applications on Tor, specifically BitTorrent, which may generate as much as 40% of all traffic on Tor. The attack exploits Tor's design and takes advantage of insecure application used to associate the simultaneous use of a secure application with the IP address of the Tor user in question.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the bad apple attack, and how does it exploit Tor's design to reveal the IP addresses of BitTorrent users on the Tor network?",
      "answer": "The bad apple attack is a documented attack that targets P2P file-sharing applications on Tor, specifically BitTorrent, which may generate as much as 40% of all traffic on Tor. The attack exploits Tor's design and takes advantage of insecure application used to associate the simultaneous use of a secure application with the IP address of the Tor user in question.",
      "context": "Tor (network)\n\n==Introduction==\nTor, short for \"The Onion Router,\" is free and open-source software for enabling anonymous communication. It directs Internet traffic via a free, worldwide, volunteer overlay network that consists of more than seven thousand relays.Using Tor makes it more difficult to trace a user's Internet activity. Tor protects personal privacy by concealing a user's location and usage from anyone performing network surveillance or traffic analysis. It protects the user's freedom and ability to communicate confidentially through IP address anonymity using Tor exit nodes.\n\n== Usage ==\n\nTor enables its users to surf the Internet, chat and send instant messages anonymously, and is used by a wide variety of people for both licit and illicit purposes. Tor has, for example, been used by criminal enterprises, hacktivism groups, and law enforcement agencies at cross purposes, sometimes simultaneously; likewise, agencies within the U.S. government variously fund Tor (the U.S. State Department, the National Science Foundation, and \u2013 through the Broadcasting Board of Governors, which itself partially funded Tor until October 2012 \u2013 Radio Free Asia) and seek to subvert it.Tor is not meant to completely solve the issue of anonymity on the web. Tor is not designed to completely erase tracking but instead to reduce the likelihood for sites to trace actions and data back to the user.Tor is also used for illegal activities. These can include privacy protection or censorship circumvention, as well as distribution of child abuse content, drug sales, or malware distribution.Tor has been described by The Economist, in relation to Bitcoin and Silk Road, as being \"a dark corner of the web\". It has been targeted by the American National Security Agency and the British GCHQ signals intelligence agencies, albeit with marginal success, and more successfully by the British National Crime Agency in its Operation Notarise. At the same time, GCHQ has been using a tool named \"Shadowcat\" for \"end-to-end encrypted access to VPS over SSH using the Tor network\". Tor can be used for anonymous defamation, unauthorized news leaks of sensitive information, copyright infringement, distribution of illegal sexual content, selling controlled substances, weapons, and stolen credit card numbers, money laundering, bank fraud, credit card fraud, identity theft and the exchange of counterfeit currency; the black market utilizes the Tor infrastructure, at least in part, in conjunction with Bitcoin. It has also been used to brick IoT devices.In its complaint against Ross William Ulbricht of Silk Road, the US Federal Bureau of Investigation acknowledged that Tor has \"known legitimate uses\". According to CNET, Tor's anonymity function is \"endorsed by the Electronic Frontier Foundation (EFF) and other civil liberties groups as a method for whistleblowers and human rights workers to communicate with journalists\". EFF's Surveillance Self-Defense guide includes a description of where Tor fits in a larger strategy for protecting privacy and anonymity.In 2014, the EFF's Eva Galperin told Businessweek that \"Tor's biggest problem is press. No one hears about that time someone wasn't stalked by their abuser. They hear how somebody got away with downloading child porn.\"The Tor Project states that Tor users include \"normal people\" who wish to keep their Internet activities private from websites and advertisers, people concerned about cyber-spying, and users who are evading censorship such as activists, journalists, and military professionals. In November 2013, Tor had about four million users. According to the Wall Street Journal, in 2012 about 14% of Tor's traffic connected from the United States, with people in \"Internet-censoring countries\" as its second-largest user base. Tor is increasingly used by victims of domestic violence and the social workers and agencies that assist them, even though shelter workers may or may not have had professional training on cyber-security matters. Properly deployed, however, it precludes digital stalking, which has increased due to the prevalence of digital media in contemporary online life. Along with SecureDrop, Tor is used by news organizations such as The Guardian, The New Yorker, ProPublica and The Intercept to protect the privacy of whistleblowers.In March 2015, the Parliamentary Office of Science and Technology released a briefing which stated that \"There is widespread agreement that banning online anonymity systems altogether is not seen as an acceptable policy option in the U.K.\" and that \"Even if it were, there would be technical challenges.\" The report further noted that Tor \"plays only a minor role in the online viewing and distribution of indecent images of children\" (due in part to its inherent latency); its usage by the Internet Watch Foundation, the utility of its onion services for whistleblowers, and its circumvention of the Great Firewall of China were touted.Tor's executive director, Andrew Lewman, also said in August 2014 that agents of the NSA and the GCHQ have anonymously provided Tor with bug reports.The Tor Project's FAQ offers supporting reasons for the EFF's endorsement:\n\nCriminals can already do bad things. Since they're willing to break laws, they already have lots of options available that provide better privacy than Tor provides...\nTor aims to provide protection for ordinary people who want to follow the law. Only criminals have privacy right now, and we need to fix that...\n\nSo yes, criminals could in theory use Tor, but they already have better options, and it seems unlikely that taking Tor away from the world will stop them from doing their bad things. At the same time, Tor and other privacy measures can fight identity theft, physical crimes like stalking, and so on.\n\n== Operation ==\n\nTor aims to conceal its users' identities and their online activity from surveillance and traffic analysis by separating identification and routing. It is an implementation of onion routing, which encrypts and then randomly bounces communications through a network of relays run by volunteers around the globe. These onion routers employ encryption in a multi-layered manner (hence the onion metaphor) to ensure perfect forward secrecy between relays, thereby providing users with anonymity in a network location. That anonymity extends to the hosting of censorship-resistant content by Tor's anonymous onion service feature. Furthermore, by keeping some of the entry relays (bridge relays) secret, users can evade Internet censorship that relies upon blocking public Tor relays.Because the IP address of the sender and the recipient are not both in cleartext at any hop along the way, anyone eavesdropping at any point along the communication channel cannot directly identify both ends. Furthermore, to the recipient, it appears that the last Tor node (called the exit node), rather than the sender, is the originator of the communication.\n\n\n*** Originating traffic ***\n\nA Tor user's SOCKS-aware applications can be configured to direct their network traffic through a Tor instance's SOCKS interface, which is listening on TCP port 9050 (for standalone Tor) or 9150 (for Tor Browser bundle) at localhost. Tor periodically creates virtual circuits through the Tor network through which it can multiplex and onion-route that traffic to its destination. Once inside a Tor network, the traffic is sent from router to router along the circuit, ultimately reaching an exit node at which point the cleartext packet is available and is forwarded on to its original destination. Viewed from the destination, the traffic appears to originate at the Tor exit node.\n\nTor's application independence sets it apart from most other anonymity networks: it works at the Transmission Control Protocol (TCP) stream level. Applications whose traffic is commonly anonymized using Tor include Internet Relay Chat (IRC), instant messaging, and World Wide Web browsing.\n\n\n*** Onion services ***\n\nTor can also provide anonymity to websites and other servers. Servers configured to receive inbound connections only through Tor are called onion services (formerly, hidden services). Rather than revealing a server's IP address (and thus its network location), an onion service is accessed through its onion address, usually via the Tor Browser. The Tor network understands these addresses by looking up their corresponding public keys and introduction points from a distributed hash table within the network. It can route data to and from onion services, even those hosted behind firewalls or network address translators (NAT), while preserving the anonymity of both parties. Tor is necessary to access these onion services.Onion services were first specified in 2003 and have been deployed on the Tor network since 2004. Other than the database that stores the onion service descriptors, Tor is decentralized by design; there is no direct readable list of all onion services, although a number of onion services catalog publicly known onion addresses. TorSearch is an internet search engine that indexes pages to help find content in websites located on the Tor network.Because onion services route their traffic entirely through the Tor network, connection to an onion service is encrypted end-to-end and not subject to eavesdropping. There are, however, security issues involving Tor onion services. For example, services that are reachable through Tor onion services and the public Internet are susceptible to correlation attacks and thus not perfectly hidden. Other pitfalls include misconfigured services (e.g. identifying information included by default in web server error responses), uptime and downtime statistics, intersection attacks, and user error. The open source OnionScan program, written by independent security researcher Sarah Jamie Lewis, comprehensively examines onion services for numerous flaws and vulnerabilities. (Lewis has also pioneered the field of \"Onion Dildonics\", sex toys which make use of Tor through the Ricochet protocol)Onion services can also be accessed from a standard web browser without client-side connection to the Tor network, using services like Tor2web. Popular sources of .onion links include Pastebin, Twitter, Reddit, and other Internet forums.\n\n== Weaknesses ==\nLike all current low-latency anonymity networks, Tor cannot and does not attempt to protect against monitoring of traffic at the boundaries of the Tor network (i.e., the traffic entering and exiting the network). While Tor does provide protection against traffic analysis, it cannot prevent traffic confirmation (also called end-to-end correlation).A 2009 study revealed that Tor and the alternative network system JonDonym (Java Anon Proxy, JAP) are considered more resilient to website fingerprinting techniques than other tunneling protocols.The reason for this is that conventional single-hop VPN protocols do not need to reconstruct packet data nearly as much as a multi-hop service like Tor or JonDonym. Website fingerprinting yielded greater than 90% accuracy for identifying HTTP packets on conventional VPN protocols versus Tor which yielded only 2.96% accuracy. However, some protocols like OpenSSH and OpenVPN required a large amount of data before HTTP packets were identified.Researchers from the University of Michigan developed a network scanner allowing identification of 86% of live Tor \"bridges\" with a single scan.\n\n\n*** Consensus blocking ***\nLike many decentralized systems, Tor relies on a consensus mechanism to periodically update its current operating parameters, which for Tor are network parameters like which nodes are good/bad relays, exits, guards, and how much traffic each can handle. Tor's architecture for deciding the consensus relies on a small number of directory authority nodes voting on current network parameters. Currently, there are eight directory authority nodes, and their health is publicly monitored. The IP addresses of the authority nodes are hard coded into each Tor client. The authority nodes vote every hour to update the consensus, and clients download the most recent consensus on startup. A network congestion attack, such as a DDoS, can prevent the consensus nodes from communicating and thus prevent voting to update the consensus.\n\n\n*** Eavesdropping ***\n\n\n**** Autonomous system (AS) eavesdropping ****\nIf the same autonomous system (AS), responsible for routing packets at least partly, is present on both path segments from a client to entry relay and from exit relay to destination, such an AS can statistically correlate traffic on the entry and exit segments of the path (i.e. traffic confirmation) and potentially infer the destination with which the client communicated. In 2012, LASTor proposed a method to predict a set of potential ASes on these two segments and then avoid choosing this path during the path selection algorithm on the client side. In this paper, they also improve latency by choosing shorter geographical paths between a client and destination.\n\n\n**** Exit node eavesdropping ****\nIn September 2007, Dan Egerstad, a Swedish security consultant, revealed he had intercepted usernames and passwords for email accounts by operating and monitoring Tor exit nodes. As Tor cannot encrypt the traffic between an exit node and the target server, any exit node is in a position to capture traffic passing through it that does not use end-to-end encryption such as Secure Sockets Layer (SSL) or Transport Layer Security (TLS). While this may not inherently breach the anonymity of the source, traffic intercepted in this way by malicious Tor exit nodes operators can expose information about the source in either or both of payload and protocol data. Furthermore, Egerstad is circumspect about the possible subversion of Tor by intelligence agencies:\nIf you actually look into where these Tor nodes are hosted and how big they are, some of these nodes cost thousands of dollars each month just to host because they're using lots of bandwidth, they're heavy-duty servers and so on. Who would pay for this and be anonymous?\nIn October 2019, a Tor researcher revealed that since at least 2017, there were hundreds of highly suspicious entry, relay, and exit nodes, run by an unknown group, in an unprecedented scale. It was alleged that this number of servers could pose the risk of a sybil attack as it could map Tor users' routes inside the network, increasing risk of deanonymization. At some point there were about 900 nodes running and by November 2021 about 600 of them were purged. \nAlthough described as being a deanonymization attempt, the motives and the achievements of this possibly on-going event are still unknown.\n\n\n**** Internal communication attack ****\nIn October 2011, a research team from ESIEA claimed to have discovered a way to compromise the Tor network by decrypting communication passing over it. The technique they describe requires creating a map of Tor network nodes, controlling one-third of them, and then acquiring their encryption keys and algorithm seeds. Then, using these known keys and seeds, they claim the ability to decrypt two encryption layers out of three. They claim to break the third key by a statistical attack. In order to redirect Tor traffic to the nodes they controlled, they used a denial-of-service attack. A response to this claim has been published on the official Tor Blog stating these rumors of Tor's compromise are greatly exaggerated.\n\n\n*** Traffic-analysis attack ***\nThere are two methods of traffic-analysis attack, passive and active. In the passive traffic-analysis method, the attacker extracts features from the traffic of a specific flow on one side of the network and looks for those features on the other side of the network. In the active traffic-analysis method, the attacker alters the timings of the packets of a flow according to a specific pattern and looks for that pattern on the other side of the network; therefore, the attacker can link the flows in one side to the other side of the network and break the anonymity of it. It is shown that, although timing noise is added to the packets, there are active traffic analysis methods that are robust against such a noise.Steven Murdoch and George Danezis from University of Cambridge presented an article at the 2005 IEEE Symposium on security and privacy on traffic-analysis techniques that allow adversaries with only a partial view of the network to infer which nodes are being used to relay the anonymous streams. These techniques greatly reduce the anonymity provided by Tor. Murdoch and Danezis have also shown that otherwise unrelated streams can be linked back to the same initiator. This attack, however, fails to reveal the identity of the original user. Murdoch has been working with and has been funded by Tor since 2006.\n\n\n*** Tor exit node block ***\nOperators of Internet sites have the ability to prevent traffic from Tor exit nodes or to offer reduced functionality for Tor users. For example, it is not generally possible to edit Wikipedia when using Tor or when using an IP address also used by a Tor exit node. The BBC blocks the IP addresses of all known Tor exit nodes from its iPlayer service, although non-exit relays and bridges are not blocked.\n\n\n*** Bad apple attack ***\nIn March 2011, researchers with the Rocquencourt French Institute for Research in Computer Science and Automation (Institut national de recherche en informatique et en automatique, INRIA), documented an attack that is capable of revealing the IP addresses of BitTorrent users on the Tor network. The \"bad apple attack\" exploits Tor's design and takes advantage of insecure application used to associate the simultaneous use of a secure application with the IP address of the Tor user in question. One method of attack depends on control of an exit node or hijacking tracker responses, while a secondary attack method is based in part on the statistical exploitation of distributed hash table tracking. According to the study:The results presented in the bad apple attack research paper are based on an attack launched against the Tor network by the authors of the study. The attack targeted six exit nodes, lasted for twenty-three days, and revealed a total of 10,000 IP addresses of active Tor users. This study is significant because it is the first documented attack designed to target P2P file-sharing applications on Tor. BitTorrent may generate as much as 40% of all traffic on Tor. Furthermore, the bad apple attack is effective against insecure use of any application over Tor, not just BitTorrent.\n\n\n*** Sniper attack ***\nJansen et al.., describes a DDoS attack targeted at the Tor node software, as well as defenses against that attack and its variants. The attack works using a colluding client and server, and filling the queues of the exit node until the node runs out of memory, and hence can serve no other (genuine) clients. By attacking a significant proportion of the exit nodes this way, an attacker can degrade the network and increase the chance of targets using nodes controlled by the attacker.\n\n\n*** Heartbleed bug ***\nThe Heartbleed OpenSSL bug disrupted the Tor network for several days in April 2014 while private keys were renewed. The Tor Project recommended Tor relay operators and onion service operators revoke and generate fresh keys after patching OpenSSL, but noted Tor relays use two sets of keys and Tor's multi-hop design minimizes the impact of exploiting a single relay. Five hundred eighty-six relays, later found to be susceptible to the Heartbleed bug, were taken offline as a precautionary measure.\n\n\n*** Relay early traffic confirmation attack ***\n\nOn 30 July 2014, the Tor Project issued the security advisory \"relay early traffic confirmation attack\" in which the project discovered a group of relays that tried to de-anonymize onion service users and operators. In summary, the attacking onion service directory node changed the headers of cells being relayed tagging them as \"relay\" or \"relay early\" cells differently to encode additional information and sent them back to the requesting user/operator. If the user's/operator's guard/entry node was also part of the attacking relays, the attacking relays might be able to capture the IP address of the user/operator along with the onion service information that the user/operator was requesting. The attacking relays were stable enough to be designated as \"suitable as hidden service directory\" and \"suitable as entry guard\"; therefore, both the onion service users and the onion services might have used those relays as guards and hidden service directory nodes.The attacking nodes joined the network early in the year on 30 January and the project removed them on 4 July. Although the attack's beginning is unclear, the project implied that between February and July, IP addresses of onion service users and operators might have been exposed.The project mentioned the following mitigations besides removing the attacking relays from the network:\n\npatched relay software to prevent relays from relaying cells with \"relay early\" headers that were not intended.\nplanned update for users' proxy software so that they could inspect if they received \"relay early\" cells from the relays (as they are not supposed to), along with the settings to connect to just one guard node instead of selecting randomly from 3 to reduce the probability of connecting to an attacking relay\nrecommended that onion services should consider changing their locations\nreminded users and onion service operators that Tor could not prevent de-anonymization if the attacker controlled or could listen to both ends of the Tor circuit, like in this attack.In November 2014 there was speculation in the aftermath of Operation Onymous, resulting in 17 arrests internationally, that a Tor weakness had been exploited. A representative of Europol was secretive about the method used, saying: \"This is something we want to keep for ourselves. The way we do this, we can't share with the whole world, because we want to do it again and again and again.\"\nA BBC source cited a \"technical breakthrough\"\nthat allowed tracking physical locations of servers, and the initial number of infiltrated sites led to the exploit speculation. Andrew Lewman\u2014a Tor Project representative\u2014downplayed this possibility, suggesting that execution of more traditional police work was more likely.In November 2015 court documents on the matter\naddressed concerns about security research ethics and the right of not being unreasonably searched as guaranteed by the US Fourth Amendment. Moreover, the documents, along with expert opinions, may also show the connection between the network attack and the law enforcement operation including:\n\nthe search warrant for an administrator of Silkroad 2.0 indicated that from January 2014 until July, the FBI received information from a \"university-based research institute\" with the information being \"reliable IP addresses for Tor and onion services such as SR2\" that led to the identification of \"at least another seventeen black markets on Tor\" and \"approximately 78 IP addresses that accessed a vendor .onion address.\" One of these IP addresses led to the arrest of the administrator\nthe chronology and nature of the attack fitted well with the operation\na senior researcher of International Computer Science Institute, part of University of California, Berkeley, said in an interview that the institute which worked with the FBI was \"almost certainly\" Carnegie Mellon University (CMU), and this concurred with the Tor Project's assessment and with an earlier analysis of Edward Felten, a computer security professor at Princeton University, about researchers from CMU's CERT/CC being involvedIn his analysis published on 31 July, besides raising ethical issues, Felten also questioned the fulfillment of CERT/CC's purposes which were to prevent attacks, inform the implementers of vulnerabilities, and eventually inform the public. Because in this case, CERT/CC's staff did the opposite which was to carry out a large-scale long-lasting attack, withhold vulnerability information from the implementers, and withhold the same information from the public. CERT/CC is a non-profit, computer security research organization publicly funded through the US federal government.\n\n\n*** Mouse fingerprinting ***\nIn March 2016, a security researcher based in Barcelona demonstrated laboratory techniques using time measurement via JavaScript at the 1-millisecond level which could potentially identify and correlate a user's unique mouse movements, provided the user has visited the same \"fingerprinting\" website with both the Tor browser and a regular browser. This proof of concept exploits the \"time measurement via JavaScript\" issue, which had been an open ticket on the Tor Project for ten months.\n\n\n*** Circuit fingerprinting attack ***\nIn 2015, the administrators of Agora, a darknet market, announced they were taking the site offline in response to a recently discovered security vulnerability in Tor. They did not say what the vulnerability was, but Wired speculated it was the \"Circuit Fingerprinting Attack\" presented at the USENIX security conference.\n\n\n*** Volume information ***\nA study showed \"anonymization solutions protect only partially against target selection that may lead to efficient surveillance\" as they typically \"do not hide the volume information necessary to do target selection\".\n\n== Implementations ==\n\nThe main implementation of Tor is written primarily in C.\n\n\n*** Tor Browser ***\n\nThe Tor Browser is a web browser capable of accessing the Tor network. It was created as the Tor Browser Bundle by Steven J. Murdoch and announced in January 2008. The Tor Browser consists of a modified Mozilla Firefox ESR web browser, the TorButton, TorLauncher, NoScript and the Tor proxy. Users can run the Tor Browser from removable media. It can operate under Microsoft Windows, macOS, Android and Linux.The default search engine is DuckDuckGo (until version 4.5, Startpage.com was its default). The Tor Browser automatically starts Tor background processes and routes traffic through the Tor network. Upon termination of a session the browser deletes privacy-sensitive data such as HTTP cookies and the browsing history. This is effective in reducing web tracking and canvas fingerprinting, and it also helps to prevent creation of a filter bubble.To allow download from places where accessing the Tor Project URL may be risky or blocked, a GitHub repository is maintained with links for releases hosted in other domains.\n\n\n**** Firefox/Tor browser attack ****\nIn 2011, the Dutch authority investigating child pornography discovered the IP address of a Tor onion service site called \"Pedoboard\" from an unprotected administrator's account and gave it to the FBI, who traced it to Aaron McGrath. After a year of surveillance, the FBI launched \"Operation Torpedo\" which resulted in McGrath's arrest and allowed them to install their Network Investigative Technique (NIT) malware on the servers for retrieving information from the users of the three onion service sites that McGrath controlled. The technique, exploiting a Firefox/Tor browser's vulnerability that had been patched and targeting users that had not updated, had a Flash application pinging a user's IP address directly back to an FBI server, and resulted in revealing at least 25 US users as well as numerous users from other countries. McGrath was sentenced to 20 years in prison in early 2014, with at least 18 other users including a former Acting HHS Cyber Security Director being sentenced in subsequent cases.In August 2013 it was discovered that the Firefox browsers in many older versions of the Tor Browser Bundle were vulnerable to a JavaScript-deployed shellcode attack, as NoScript was not enabled by default. Attackers used this vulnerability to extract users' MAC and IP addresses and Windows computer names. News reports linked this to a Federal Bureau of Investigation (FBI) operation targeting Freedom Hosting's owner, Eric Eoin Marques, who was arrested on a provisional extradition warrant issued by a United States' court on 29 July. The FBI extradited Marques from Ireland to the state of Maryland on 4 charges: distributing; conspiring to distribute; and advertising child pornography, as well as aiding and abetting advertising of child pornography. The warrant alleged that Marques was \"the largest facilitator of child porn on the planet\". The FBI acknowledged the attack in a 12 September 2013 court filing in Dublin; further technical details from a training presentation leaked by Edward Snowden revealed the code name for the exploit as \"EgotisticalGiraffe\".In 2022, Kaspersky researchers found that when looking up \"Tor Browser\" in Chinese on YouTube, one of the URLs provided under the top-ranked Chinese-language video actually pointed to a malware disguised as Tor Browser. Once installed, it saves browsing history and form data that genuine Tor forgot by default, and even downloads malicious components to computers with IP addresses in China. Kaspersky researchers noted that the malware was not stealing data to sell for profit, but was designed to identify users.\n\n\n*** Tor Messenger ***\nOn 29 October 2015, the Tor Project released Tor Messenger Beta, an instant messaging program based on Instantbird with Tor and OTR built in and used by default. Like Pidgin and Adium, Tor Messenger supports multiple different instant messaging protocols; however, it accomplishes this without relying on libpurple, implementing all chat protocols in the memory-safe language JavaScript instead.According to Lucian Armasu of Toms Hardware, in April 2018, the Tor Project shut down the Tor Messenger project for three reasons: the developers of \"Instabird\"  [sic] discontinued support for their own software, limited resources and known metadata problems. The Tor Messenger developers explained that overcoming any vulnerabilities discovered in the future would be impossible due to the project relying on outdated software dependencies.\n\n\n*** Tor Phone ***\n\nIn 2016, Tor developer Mike Perry announced a prototype tor-enabled smartphone bases on CopperheadOS. It was meant as  a direction for Tor on mobile. The project was called 'Mission Improbable'. Copperhead's then lead developer Daniel Micay welcomed the prototype. Using Tor with Orbot and Tor Browser are supported by custom Android operating systems CalyxOS and DivestOS. GrapheneOS supports using Orbot VPN but not Tor Browser.\n\n\n*** Third-party applications ***\nThe Vuze (formerly Azureus) BitTorrent client, Bitmessage anonymous messaging system, and TorChat instant messenger include Tor support. The Briar messenger routes all messaging via Tor by default. OnionShare allows users to share files using Tor.The Guardian Project is actively developing a free and open-source suite of applications and firmware for the Android operating system to improve the security of mobile communications. The applications include the ChatSecure instant messaging client, Orbot Tor implementation (also available for iOS), Orweb (discontinued) privacy-enhanced mobile browser, Orfox, the mobile counterpart of the Tor Browser, ProxyMob Firefox add-on, and ObscuraCam.Onion Browser is open-source, privacy-enhancing web browser for iOS, which uses Tor. It is available in the iOS App Store, and source code is available on GitHub.Brave added support for Tor in its desktop browser's private-browsing mode. Users can switch to Tor-enabled browsing by clicking on the hamburger menu on the top right corner of the browser.\n\n\t\t\n\t\t\n\t\t\n\t\t\n\n\n*** Security-focused operating systems ***\nSeveral security-focused operating systems make or made extensive use of Tor. These include Hardened Linux From Scratch, Incognito, Libert\u00e9 Linux, Qubes OS, Subgraph, Parrot OS, Tails, Tor-ramdisk, and Whonix.\n\n== Reception, impact, and legislation ==\n\nTor has been praised for providing privacy and anonymity to vulnerable Internet users such as political activists fearing surveillance and arrest, ordinary web users seeking to circumvent censorship, and people who have been threatened with violence or abuse by stalkers. The U.S. National Security Agency (NSA) has called Tor \"the king of high-secure, low-latency Internet anonymity\", and BusinessWeek magazine has described it as \"perhaps the most effective means of defeating the online surveillance efforts of intelligence agencies around the world\". Other media have described Tor as \"a sophisticated privacy tool\", \"easy to use\" and \"so secure that even the world's most sophisticated electronic spies haven't figured out how to crack it\".Advocates for Tor say it supports freedom of expression, including in countries where the Internet is censored, by protecting the privacy and anonymity of users. The mathematical underpinnings of Tor lead it to be characterized as acting \"like a piece of infrastructure, and governments naturally fall into paying for infrastructure they want to use\".The project was originally developed on behalf of the U.S. intelligence community and continues to receive U.S. government funding, and has been criticized as \"more resembl[ing] a spook project than a tool designed by a culture that values accountability or transparency\". As of 2012, 80% of The Tor Project's $2M annual budget came from the United States government, with the U.S. State Department, the Broadcasting Board of Governors, and the National Science Foundation as major contributors, aiming \"to aid democracy advocates in authoritarian states\". Other public sources of funding include DARPA, the U.S. Naval Research Laboratory, and the Government of Sweden. Some have proposed that the government values Tor's commitment to free speech, and uses the darknet to gather intelligence. Tor also receives funding from NGOs including Human Rights Watch, and private sponsors including Reddit and Google. Dingledine said that the United States Department of Defense funds are more similar to a research grant than a procurement contract. Tor executive director Andrew Lewman said that even though it accepts funds from the U.S. federal government, the Tor service did not collaborate with the NSA to reveal identities of users.Critics say that Tor is not as secure as it claims, pointing to U.S. law enforcement's investigations and shutdowns of Tor-using sites such as web-hosting company Freedom Hosting and online marketplace Silk Road. In October 2013, after analyzing documents leaked by Edward Snowden, The Guardian reported that the NSA had repeatedly tried to crack Tor and had failed to break its core security, although it had had some success attacking the computers of individual Tor users. The Guardian also published a 2012 NSA classified slide deck, entitled \"Tor Stinks\", which said: \"We will never be able to de-anonymize all Tor users all the time\", but \"with manual analysis we can de-anonymize a very small fraction of Tor users\". When Tor users are arrested, it is typically due to human error, not to the core technology being hacked or cracked. On 7 November 2014, for example, a joint operation by the FBI, ICE Homeland Security investigations and European Law enforcement agencies led to 17 arrests and the seizure of 27 sites containing 400 pages. A late 2014 report by Der Spiegel using a new cache of Snowden leaks revealed, however, that as of 2012 the NSA deemed Tor on its own as a \"major threat\" to its mission, and when used in conjunction with other privacy tools such as OTR, Cspace, ZRTP, RedPhone, Tails, and TrueCrypt was ranked as \"catastrophic,\" leading to a \"near-total loss/lack of insight to target communications, presence...\"\n\n\n*** 2011 ***\nIn March 2011, The Tor Project received the Free Software Foundation's 2010 Award for Projects of Social Benefit. The citation read, \"Using free software, Tor has enabled roughly 36 million people around the world to experience freedom of access and expression on the Internet while keeping them in control of their privacy and anonymity. Its network has proved pivotal in dissident movements in both Iran and more recently Egypt.\"Iran tried to block Tor at least twice in 2011. One attempt simply blocked all servers with 2-hour-expiry security certificates; it was successful for less than 24 hours.\n\n\n*** 2012 ***\nIn 2012, Foreign Policy magazine named Dingledine, Mathewson, and Syverson among its Top 100 Global Thinkers \"for making the web safe for whistleblowers\".\n\n\n*** 2013 ***\nIn 2013, Jacob Appelbaum described Tor as a \"part of an ecosystem of software that helps people regain and reclaim their autonomy. It helps to enable people to have agency of all kinds; it helps others to help each other and it helps you to help yourself. It runs, it is open and it is supported by a large community spread across all walks of life.\"In June 2013, whistleblower Edward Snowden used Tor to send information about PRISM to The Washington Post and The Guardian.\n\n\n*** 2014 ***\nIn 2014, the Russian government offered a $111,000 contract to \"study the possibility of obtaining technical information about users and users' equipment on the Tor anonymous network\".In September 2014, in response to reports that Comcast had been discouraging customers from using the Tor Browser, Comcast issued a public statement that \"We have no policy against Tor, or any other browser or software.\"In October 2014, The Tor Project hired the public relations firm Thomson Communications to improve its public image (particularly regarding the terms \"Dark Net\" and \"hidden services,\" which are widely viewed as being problematic) and to educate journalists about the technical aspects of Tor.Turkey blocked downloads of Tor Browser from the Tor Project.\n\n\n*** 2015 ***\nIn June 2015, the special rapporteur from the United Nations' Office of the High Commissioner for Human Rights specifically mentioned Tor in the context of the debate in the U.S. about allowing so-called backdoors in encryption programs for law enforcement purposes in an interview for The Washington Post.\nIn July 2015, the Tor Project announced an alliance with the Library Freedom Project to establish exit nodes in public libraries. The pilot program, which established a middle relay running on the excess bandwidth afforded by the Kilton Library in Lebanon, New Hampshire, making it the first library in the U.S. to host a Tor node, was briefly put on hold when the local city manager and deputy sheriff voiced concerns over the cost of defending search warrants for information passed through the Tor exit node. Although the Department of Homeland Security (DHS) had alerted New Hampshire authorities to the fact that Tor is sometimes used by criminals, the Lebanon Deputy Police Chief and the Deputy City Manager averred that no pressure to strong-arm the library was applied, and the service was re-established on 15 September 2015. U.S. Rep. Zoe Lofgren (D-Calif) released a letter on 10 December 2015, in which she asked the DHS to clarify its procedures, stating that \"While the Kilton Public Library's board ultimately voted to restore their Tor relay, I am no less disturbed by the possibility that DHS employees are pressuring or persuading public and private entities to discontinue or degrade services that protect the privacy and anonymity of U.S. citizens.\" In a 2016 interview, Kilton Library IT Manager Chuck McAndrew stressed the importance of getting libraries involved with Tor: \"Librarians have always cared deeply about protecting privacy, intellectual freedom, and access to information (the freedom to read). Surveillance has a very well-documented chilling effect on intellectual freedom. It is the job of librarians to remove barriers to information.\" The second library to host a Tor node was the Las Naves Public Library in Valencia, Spain, implemented in the first months of 2016.In August 2015, an IBM security research group, called \"X-Force\", put out a quarterly report that advised companies to block Tor on security grounds, citing a \"steady increase\" in attacks from Tor exit nodes as well as botnet traffic.In September 2015, Luke Millanta created OnionView (now defunct), a web service that plots the location of active Tor relay nodes onto an interactive map of the world. The project's purpose was to detail the network's size and escalating growth rate.In December 2015, Daniel Ellsberg (of the Pentagon Papers), Cory Doctorow (of Boing Boing), Edward Snowden, and artist-activist Molly Crabapple, amongst others, announced their support of Tor.\n\n\n*** 2016 ***\nIn March 2016, New Hampshire state representative Keith Ammon introduced a bill allowing public libraries to run privacy software. The bill specifically referenced Tor. The text was crafted with extensive input from Alison Macrina, the director of the Library Freedom Project. The bill was passed by the House 268\u201362.Also in March 2016, the first Tor node, specifically a middle relay, was established at a library in Canada, the Graduate Resource Centre (GRC) in the Faculty of Information and Media Studies (FIMS) at the University of Western Ontario. Given that the running of a Tor exit node is an unsettled area of Canadian law, and that in general institutions are more capable than individuals to cope with legal pressures, Alison Macrina of the Library Freedom Project has opined that in some ways she would like to see intelligence agencies and law enforcement attempt to intervene in the event that an exit node were established.On 16 May 2016, CNN reported on the case of core Tor developer isis agora lovecruft, who had fled to Germany under the threat of a subpoena by the FBI during the Thanksgiving break of the previous year. The Electronic Frontier Foundation legally represented lovecruft.On 2 December 2016, The New Yorker reported on burgeoning digital privacy and security workshops in the San Francisco Bay Area, particularly at the hackerspace Noisebridge, in the wake of the 2016 United States presidential election; downloading the Tor browser was mentioned. Also, in December 2016, Turkey has blocked the usage of Tor, together with ten of the most used VPN services in Turkey, which were popular ways of accessing banned social media sites and services.Tor (and Bitcoin) was fundamental to the operation of the darkweb marketplace AlphaBay, which was taken down in an international law enforcement operation in July 2017. Despite federal claims that Tor would not shield a user, however, elementary operational security errors outside of the ambit of the Tor network led to the site's downfall.\n\n\n*** 2017 ***\nIn June 2017 the Democratic Socialists of America recommended intermittent Tor usage. And in August 2017, according to reportage cybersecurity firms which specialize in monitoring and researching the dark Web (which relies on Tor as its infrastructure) on behalf of banks and retailers routinely share their findings with the FBI and with other law enforcement agencies \"when possible and necessary\" regarding illegal content. The Russian-speaking underground offering a crime-as-a-service model is regarded as being particularly robust.\n\n\n*** 2018 ***\nIn June 2018, Venezuela blocked access to the Tor network. The block affected both direct connections to the network and connections being made via bridge relays.On 20 June 2018, Bavarian police raided the homes of the board members of the non-profit Zwiebelfreunde, a member of torservers.net, which handles the European financial transactions of riseup.net in connection with a blog post there which apparently promised violence against the upcoming Alternative for Germany convention. Tor came out strongly against the raid against its support organization, which provides legal and financial aid for the setting up and maintenance of high-speed relays and exit nodes. According to torservers.net, on 23 August 2018 the German court at Landgericht M\u00fcnchen ruled that the raid and seizures were illegal. The hardware and documentation seized had been kept under seal, and purportedly were neither analyzed nor evaluated by the Bavarian police.Since October 2018, Chinese online communities within Tor have begun to dwindle due to increased efforts to stop them by the Chinese government.\n\n\n*** 2019 ***\nIn November 2019, Edward Snowden called for a full, unabridged simplified Chinese translation of his autobiography, Permanent Record, as the Chinese publisher had violated their agreement by expurgating all mentions of Tor and other matters deemed politically sensitive by the Chinese Communist Party.\n\n\n*** 2021 ***\nOn 8 December 2021, the Russian government agency Roskomnadzor announced it has banned Tor and six VPN services for failing to abide by the Russian Internet blacklist. Russian ISPs unsuccessfully attempted to block Tor's main website as well as several bridges beginning on 1 December 2021. The Tor Project has appealed to Russian courts over this ban.\n\n\n*** 2022 ***\nIn response to Internet censorship during the Russian invasion of Ukraine, the BBC and VOA have directed Russian audiences to Tor. The Russian government increased efforts to block access to Tor through technical and political means, while the network reported an increase in traffic from Russia, and increased Russian use of its anti-censorship Snowflake tool.Russian courts temporarily lifted the blockade on Tor's website (but not connections to relays) on May 24, 2022 due to Russian law requiring that the Tor Project be involved in the case. However, the blockade was reinstated on July 21, 2022.Iran implemented rolling internet blackouts during the Mahsa Amini protests, and Tor and Snowflake were used to circumvent them.China, with its highly centralized control of its internet, had effectively blocked Tor.\n\n== Improved security ==\nTor responded to earlier vulnerabilities listed above by patching them and improving security. In one way or another, human (user) errors can lead to detection. The Tor Project website provides the best practices (instructions) on how to properly use the Tor browser. When improperly used, Tor is not secure. For example, Tor warns its users that not all traffic is protected; only the traffic routed through the Tor browser is protected. Users are also warned to use HTTPS versions of websites, not to torrent with Tor, not to enable browser plugins, not to open documents downloaded through Tor while online, and to use safe bridges. Users are also warned that they cannot provide their name or other revealing information in web forums over Tor and stay anonymous at the same time.Despite intelligence agencies' claims that 80% of Tor users would be de-anonymized within 6 months in the year 2013, that has still not happened. In fact, as late as September 2016, the FBI could not locate, de-anonymize and identify the Tor user who hacked into the email account of a staffer on Hillary Clinton's email server.The best tactic of law enforcement agencies to de-anonymize users appears to remain with Tor-relay adversaries running poisoned nodes, as well as counting on the users themselves using the Tor browser improperly. For example, downloading a video through the Tor browser and then opening the same file on an unprotected hard drive while online can make the users' real IP addresses available to authorities.\n\n\n*** Odds of detection ***\nWhen properly used, odds of being de-anonymized through Tor are said to be extremely low. Tor project's co-founder Nick Mathewson explained that the problem of \"Tor-relay adversaries\" running poisoned nodes means that a theoretical adversary of this kind is not the network's greatest threat:\n\n\"No adversary is truly global, but no adversary needs to be truly global,\" he says. \"Eavesdropping on the entire Internet is a several-billion-dollar problem. Running a few computers to eavesdrop on a lot of traffic, a selective denial of service attack to drive traffic to your computers, that's like a tens-of-thousands-of-dollars problem.\" At the most basic level, an attacker who runs two poisoned Tor nodes\u2014one entry, one exit\u2014is able to analyse traffic and thereby identify the tiny, unlucky percentage of users whose circuit happened to cross both of those nodes. In 2016 the Tor network offers a total of around 7,000 relays, around 2,000 guard (entry) nodes and around 1,000 exit nodes. So the odds of such an event happening are one in two million (1\u20442000 \u00d7 1\u20441000), give or take.\"\nTor does not provide protection against end-to-end timing attacks: if an attacker can watch the traffic coming out of the target computer, and also the traffic arriving at the target's chosen destination (e.g. a server hosting a .onion site), that attacker can use statistical analysis to discover that they are part of the same circuit.\n\n\n*** Levels of security ***\nDepending on individual user needs, Tor browser offers three levels of security located under the Security Level (the small gray shield at the top-right of the screen) icon > Advanced Security Settings. In addition to encrypting the data, including constantly changing an IP address through a virtual circuit comprising successive, randomly selected Tor relays, several other layers of security are at a user's disposal:\nStandard (default) \u2013 at this security level, all browser features are enabled.\nThis level provides the most usable experience, and the lowest level of security.\nSafer \u2013 at this security level, the following changes apply:\nJavaScript is disabled on non-HTTPS sites.\nOn sites where JavaScript is enabled, performance optimizations are disabled. Scripts on some sites may run slower.\nSome mechanisms of displaying math equations are disabled.\nAudio and video (HTML5 media), and WebGL are click-to-play.\nSafest \u2013 at this security level, these additional changes apply:\nJavaScript is disabled by default on all sites.\nSome fonts, icons, math symbols, and images are disabled.\nAudio and video (HTML5 media), and WebGL are click-to-play.\n\n== Citations ==\n\n== General and cited references =="
    }
  },
  {
    "instruction": "Write an answer to the following question: What are the four levels of security defined by FIPS 140-2, and what is the significance of each level?",
    "context": "",
    "output": "FIPS 140-2 defines four levels of security, named Level 1 to Level 4, which do not specify in detail what level of security is required by any particular application. Level 1 has the lowest requirements, while Level 4 has the most stringent physical security requirements and robustness against environmental attacks. Additionally, Section 4.1.1 of the specification describes other attacks that may require mitigation, such as differential power analysis, but protections are not required to achieve a given level.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are the four levels of security defined by FIPS 140-2, and what is the significance of each level?",
      "answer": "FIPS 140-2 defines four levels of security, named Level 1 to Level 4, which do not specify in detail what level of security is required by any particular application. Level 1 has the lowest requirements, while Level 4 has the most stringent physical security requirements and robustness against environmental attacks. Additionally, Section 4.1.1 of the specification describes other attacks that may require mitigation, such as differential power analysis, but protections are not required to achieve a given level."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the significance of TextSecure's use of the Signal Protocol (formerly known as the TextSecure Protocol)?",
    "context": "",
    "output": "TextSecure's use of the Signal Protocol (TextSecure Protocol) was significant because it has since been implemented into WhatsApp, Facebook Messenger, and Google Allo, encrypting the conversations of \"more than a billion people worldwide\".",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the significance of TextSecure's use of the Signal Protocol (formerly known as the TextSecure Protocol)?",
      "answer": "TextSecure's use of the Signal Protocol (TextSecure Protocol) was significant because it has since been implemented into WhatsApp, Facebook Messenger, and Google Allo, encrypting the conversations of \"more than a billion people worldwide\"."
    }
  },
  {
    "instruction": "Write an answer to the following question: How can files encrypted with a strong key by Rombertik be recovered?",
    "context": "",
    "output": "Files encrypted with a strong key by Rombertik can be nearly impossible to recover.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can files encrypted with a strong key by Rombertik be recovered?",
      "answer": "Files encrypted with a strong key by Rombertik can be nearly impossible to recover."
    }
  },
  {
    "instruction": "Context: Probabilistic signature scheme\n\n==Introduction==\nProbabilistic Signature Scheme (PSS) is a cryptographic signature scheme designed by Mihir Bellare and Phillip Rogaway.RSA-PSS is an adaptation of their work and is standardized as part of PKCS#1 v2.1. In general, RSA-PSS should be used as a replacement for RSA-PKCS#1 v1.5.\n\n\n\n== Design ==\nPSS was specifically developed to allow modern methods of security analysis to prove that its security directly relates to that of the RSA problem. There is no such proof for the traditional PKCS#1 v1.5 scheme.\n\n== Implementations ==\nOpenSSL\nwolfSSL\nGnuTLS\nAnswer this question: How does Probabilistic Signature Scheme (PSS) differ from other cryptographic signature schemes?",
    "context": "",
    "output": "Probabilistic Signature Scheme (PSS) differs from other cryptographic signature schemes as it allows modern methods of security analysis to prove that its security directly relates to that of the RSA problem.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does Probabilistic Signature Scheme (PSS) differ from other cryptographic signature schemes?",
      "answer": "Probabilistic Signature Scheme (PSS) differs from other cryptographic signature schemes as it allows modern methods of security analysis to prove that its security directly relates to that of the RSA problem.",
      "context": "Probabilistic signature scheme\n\n==Introduction==\nProbabilistic Signature Scheme (PSS) is a cryptographic signature scheme designed by Mihir Bellare and Phillip Rogaway.RSA-PSS is an adaptation of their work and is standardized as part of PKCS#1 v2.1. In general, RSA-PSS should be used as a replacement for RSA-PKCS#1 v1.5.\n\n\n\n== Design ==\nPSS was specifically developed to allow modern methods of security analysis to prove that its security directly relates to that of the RSA problem. There is no such proof for the traditional PKCS#1 v1.5 scheme.\n\n== Implementations ==\nOpenSSL\nwolfSSL\nGnuTLS"
    }
  },
  {
    "instruction": "Answer based on context:\n\nPrivate Disk\n\n==Introduction==\nPrivate Disk is a disk encryption application for the Microsoft Windows operating system, developed by Dekart SRL. It works by creating a virtual drive,  the contents of which is encrypted on-the-fly; other software can use the drive as if it were a usual one.\nOne of Private Disk's key selling points is in its ease of use, which is achieved by hiding complexity from the end user (e.g. data wiping is applied transparently when an encrypted image is deleted.) This simplicity does however reduce its flexibility in some respects (e.g. it only allows the use of AES-256 encryption.)\nAlthough Private Disk uses a NIST certified implementation of the AES and SHA-256/384/512 algorithms, this certification is restricted to a single component of Private Disk; the encryption/hash library used and not to Private Disk as a complete system.\n\n== Feature highlights ==\nNIST-certified implementation of AES-256-bit, and SHA-2. Private Disk complies with FIPS 197 and FIPS 180-2\nCBC mode with secret IVs is used to encrypt the sectors of the storage volume\nDisk Firewall, an application-level filter, which allows only trusted programs to access the virtual drive\nAbility to run directly from a removable drive, requiring no local installation\nOffers access to encrypted data on any system, even if administrative privileges are not available\nEncrypted images can be accessed on Windows Mobile and Windows CE handhelds; this is achieved by making the encrypted container format compatible with containers used by SecuBox (disk encryption software by Aiko Solutions)\nFile wiping is applied when deleting an encrypted image\nPD File Move, a file migration tool, which will locate the specified files on the system and securely move them to an encrypted disk\nCompatibility with Windows 9x and Windows NT operating systems\nAutorun and Autofinish automatically start a program or a script when a virtual disk is mounted or dismounted\nEncrypted backup of an encrypted image\nPassword quality meter\nAutomatic backup of a disk's encryption key\nBuilt-in password recovery tool\nCompatibility with 64-bit platformsExisting versions\nThere are multiple versions of Private Disk, which provide a different feature set:\n\nPrivate Disk -  hard disk encryption software that uses 256-bit AES encryption, is highly configurable, offers application-level protection, USB disk portability, etc.\nPrivate Disk Multifactor is a superset of Private Disk, providing the same functionality, adding support for biometric authentication, as well as smart-card or token-based authentication.\nPrivate Disk Light is a free version, it uses AES-128 and comes with a restricted set of features.\nPrivate Disk SDK is a software development kit that can be used to build a custom application which provides data encryption facilities.\n\nHow does Private Disk ensure secure file migration?",
    "context": "",
    "output": "Private Disk provides a file migration tool called PD File Move, which securely moves specified files to an encrypted disk, enhancing data protection.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does Private Disk ensure secure file migration?",
      "answer": "Private Disk provides a file migration tool called PD File Move, which securely moves specified files to an encrypted disk, enhancing data protection.",
      "context": "Private Disk\n\n==Introduction==\nPrivate Disk is a disk encryption application for the Microsoft Windows operating system, developed by Dekart SRL. It works by creating a virtual drive,  the contents of which is encrypted on-the-fly; other software can use the drive as if it were a usual one.\nOne of Private Disk's key selling points is in its ease of use, which is achieved by hiding complexity from the end user (e.g. data wiping is applied transparently when an encrypted image is deleted.) This simplicity does however reduce its flexibility in some respects (e.g. it only allows the use of AES-256 encryption.)\nAlthough Private Disk uses a NIST certified implementation of the AES and SHA-256/384/512 algorithms, this certification is restricted to a single component of Private Disk; the encryption/hash library used and not to Private Disk as a complete system.\n\n== Feature highlights ==\nNIST-certified implementation of AES-256-bit, and SHA-2. Private Disk complies with FIPS 197 and FIPS 180-2\nCBC mode with secret IVs is used to encrypt the sectors of the storage volume\nDisk Firewall, an application-level filter, which allows only trusted programs to access the virtual drive\nAbility to run directly from a removable drive, requiring no local installation\nOffers access to encrypted data on any system, even if administrative privileges are not available\nEncrypted images can be accessed on Windows Mobile and Windows CE handhelds; this is achieved by making the encrypted container format compatible with containers used by SecuBox (disk encryption software by Aiko Solutions)\nFile wiping is applied when deleting an encrypted image\nPD File Move, a file migration tool, which will locate the specified files on the system and securely move them to an encrypted disk\nCompatibility with Windows 9x and Windows NT operating systems\nAutorun and Autofinish automatically start a program or a script when a virtual disk is mounted or dismounted\nEncrypted backup of an encrypted image\nPassword quality meter\nAutomatic backup of a disk's encryption key\nBuilt-in password recovery tool\nCompatibility with 64-bit platformsExisting versions\nThere are multiple versions of Private Disk, which provide a different feature set:\n\nPrivate Disk -  hard disk encryption software that uses 256-bit AES encryption, is highly configurable, offers application-level protection, USB disk portability, etc.\nPrivate Disk Multifactor is a superset of Private Disk, providing the same functionality, adding support for biometric authentication, as well as smart-card or token-based authentication.\nPrivate Disk Light is a free version, it uses AES-128 and comes with a restricted set of features.\nPrivate Disk SDK is a software development kit that can be used to build a custom application which provides data encryption facilities."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the impact of Typosquatting on users' devices?",
    "context": "",
    "output": "Typosquatting can install drive-by malware or revenue generating adware onto the visitors' devices, potentially harming their computers and stealing sensitive information.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the impact of Typosquatting on users' devices?",
      "answer": "Typosquatting can install drive-by malware or revenue generating adware onto the visitors' devices, potentially harming their computers and stealing sensitive information."
    }
  },
  {
    "instruction": "Write an answer to the following question: How do virus hoaxes use the concept of authority to appear more credible and why is this a problem?",
    "context": "",
    "output": "Virus hoaxes often use the concept of authority to appear more credible by quoting fake announcements from reputable computer organizations and mainstream news media. This can make the hoax seem more legitimate and increase the likelihood of it being taken seriously. However, this is a problem because it can lead to users being deceived by the hoax and taking unnecessary action as a result.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do virus hoaxes use the concept of authority to appear more credible and why is this a problem?",
      "answer": "Virus hoaxes often use the concept of authority to appear more credible by quoting fake announcements from reputable computer organizations and mainstream news media. This can make the hoax seem more legitimate and increase the likelihood of it being taken seriously. However, this is a problem because it can lead to users being deceived by the hoax and taking unnecessary action as a result."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does blog spam impact the user experience on a website?",
    "context": "",
    "output": "Blog spam can negatively impact the user experience on a website by adding irrelevant or spammy content to the site. This can make it more difficult for users to find the information they are looking for and reduce the overall quality of the website.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does blog spam impact the user experience on a website?",
      "answer": "Blog spam can negatively impact the user experience on a website by adding irrelevant or spammy content to the site. This can make it more difficult for users to find the information they are looking for and reduce the overall quality of the website."
    }
  },
  {
    "instruction": "Context: MySecureCyberspace\n\n==Introduction==\nMySecureCyberspace began in 2003 as an initiative by Carnegie Mellon CyLab and the Information Networking Institute to educate the public about computer security, network security and Internet safety. Inspired by the National Strategy to Secure Cyberspace, the initiative empowers users to secure their part of cyberspace. \nThe initiative created a web portal at www.MySecureCyberspace.com that customized information to users about cybersecurity threats, in addition to tactical countermeasures and legal, ethical, and privacy issues. For example, using the Secure My Cyberspace tool on the web portal, a user could enter an online activity, such as email, and receive an explanation of common threats and issues associated with that activity, such as spam and phishing scams, and then receive advice on how to resolve those problems. As a web portal, MySecureCyberspace served people of all ages and roles, but certain areas of the web portal contained articles and resources specifically for parents, educators and children.\nFrom 2005 to 2012, MySecureCyberspace provided a Flash-based interactive game designed for elementary school children at www.CarnegieCyberAcademy.com called Carnegie Cadets that reinforced principles of safe and responsible computing. Enriched with content and classroom material that complied with the National Educational Technology Standards, the game could be integrated into fourth and fifth grade curricula. The Carnegie Cyber Academy website and supporting materials remain available, but the game is not compatible with current operating systems.\n\n== Recognition ==\nFinalist status for the 2009 Japan Prize\nSilver Awards of Distinction, Education and Children's Audience categories, 2009 Communicator Awards\nMerit Award, Online Communication, The Pittsburgh Chapter of the Society for Technical Communication, May 2007\nAnswer this question: What is the current status of the Carnegie Cadets game?",
    "context": "",
    "output": "The Carnegie Cadets game is not compatible with current operating systems.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the current status of the Carnegie Cadets game?",
      "answer": "The Carnegie Cadets game is not compatible with current operating systems.",
      "context": "MySecureCyberspace\n\n==Introduction==\nMySecureCyberspace began in 2003 as an initiative by Carnegie Mellon CyLab and the Information Networking Institute to educate the public about computer security, network security and Internet safety. Inspired by the National Strategy to Secure Cyberspace, the initiative empowers users to secure their part of cyberspace. \nThe initiative created a web portal at www.MySecureCyberspace.com that customized information to users about cybersecurity threats, in addition to tactical countermeasures and legal, ethical, and privacy issues. For example, using the Secure My Cyberspace tool on the web portal, a user could enter an online activity, such as email, and receive an explanation of common threats and issues associated with that activity, such as spam and phishing scams, and then receive advice on how to resolve those problems. As a web portal, MySecureCyberspace served people of all ages and roles, but certain areas of the web portal contained articles and resources specifically for parents, educators and children.\nFrom 2005 to 2012, MySecureCyberspace provided a Flash-based interactive game designed for elementary school children at www.CarnegieCyberAcademy.com called Carnegie Cadets that reinforced principles of safe and responsible computing. Enriched with content and classroom material that complied with the National Educational Technology Standards, the game could be integrated into fourth and fifth grade curricula. The Carnegie Cyber Academy website and supporting materials remain available, but the game is not compatible with current operating systems.\n\n== Recognition ==\nFinalist status for the 2009 Japan Prize\nSilver Awards of Distinction, Education and Children's Audience categories, 2009 Communicator Awards\nMerit Award, Online Communication, The Pittsburgh Chapter of the Society for Technical Communication, May 2007"
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the relationship between the NCF and other British intelligence agencies?",
    "context": "",
    "output": "The NCF is a joint initiative between the Ministry of Defence (MOD) and GCHQ, which is one of the British intelligence agencies. The NCF operates alongside the National Cyber Security Centre (NCSC), which is another British intelligence agency.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the relationship between the NCF and other British intelligence agencies?",
      "answer": "The NCF is a joint initiative between the Ministry of Defence (MOD) and GCHQ, which is one of the British intelligence agencies. The NCF operates alongside the National Cyber Security Centre (NCSC), which is another British intelligence agency."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are National Security Letters (NSLs) and how have their usage evolved over time?",
    "context": "",
    "output": "National Security Letters (NSLs) are a type of administrative subpoena that originated in the 1986 Electronic Communications Privacy Act. Initially, they targeted those suspected of being agents of a foreign power. However, the USA Patriot Act in 2001 expanded their usage to include those who may have information relevant to counterintelligence activities or terrorist activities directed against the United States.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are National Security Letters (NSLs) and how have their usage evolved over time?",
      "answer": "National Security Letters (NSLs) are a type of administrative subpoena that originated in the 1986 Electronic Communications Privacy Act. Initially, they targeted those suspected of being agents of a foreign power. However, the USA Patriot Act in 2001 expanded their usage to include those who may have information relevant to counterintelligence activities or terrorist activities directed against the United States."
    }
  },
  {
    "instruction": "Auth-Code\n\n==Introduction==\nAn Auth-Code, also known as an EPP code, authorization code, transfer code, or Auth-Info Code, is a generated passcode required to transfer an Internet domain name between domain registrars; the code is intended to indicate that the domain name owner has authorized the transfer.Auth-Codes are created by the current registrar of the domain. The registrar is required to provide the Auth-Code to the domain name owner within five calendar days of the owner's request, and ICANN accepts complaints about registrars that do not. Some registrars allow Auth-Codes to be generated by the domain owners through the registrar's website. All Generic top-level domains use an Auth-Code in their transfer process.The .nz domain registry used an eight-character Auth-Code called Unique Domain Authentication Identifier (UDAI) for domain transfers and name conflict procedures. The UDAI was provided to the domain owner by the domain's current registrar, and expired after 30 days. With the .nz registry update in 2022 the term UDAI was retired, and the passcode is now also referred to as an Auth-Code.\n\n\n\n== Alternative systems ==\nThe .uk and .co.uk domain registry, instead of using a passcode, has the domain owner specify the new registrar using the old registrar. The destination registrar is specified using the destination's registrar tag, also known as an Internet Provider Security (IPS) tag or Nominet Provider tag.Some registries use a document based approach either in conjunction with or instead of an Auth-Code. An example for that is .hu for which the registrant has to fill out a document and send it to the new registrar, who sends it to the registry to fulfill the domain transfer.The .is domain registry uses the domains admin NIC handle and the old registrar has to update it to the new registrars NIC handle.Some other registries use an email template (that may or may not be in part processed automatically) like .lr or .jm. In this case the technical contact is set to the registrar and can be updated by sending an updated template from the registrant or admin contacts email address.\n\nQ: How does the ICANN regulate the use of Auth-Codes in domain transfers?",
    "context": "",
    "output": "A: ICANN requires the registrar to provide the Auth-Code to the domain name owner within five calendar days of the owner's request and accepts complaints about registrars that do not comply.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the ICANN regulate the use of Auth-Codes in domain transfers?",
      "answer": "ICANN requires the registrar to provide the Auth-Code to the domain name owner within five calendar days of the owner's request and accepts complaints about registrars that do not comply.",
      "context": "Auth-Code\n\n==Introduction==\nAn Auth-Code, also known as an EPP code, authorization code, transfer code, or Auth-Info Code, is a generated passcode required to transfer an Internet domain name between domain registrars; the code is intended to indicate that the domain name owner has authorized the transfer.Auth-Codes are created by the current registrar of the domain. The registrar is required to provide the Auth-Code to the domain name owner within five calendar days of the owner's request, and ICANN accepts complaints about registrars that do not. Some registrars allow Auth-Codes to be generated by the domain owners through the registrar's website. All Generic top-level domains use an Auth-Code in their transfer process.The .nz domain registry used an eight-character Auth-Code called Unique Domain Authentication Identifier (UDAI) for domain transfers and name conflict procedures. The UDAI was provided to the domain owner by the domain's current registrar, and expired after 30 days. With the .nz registry update in 2022 the term UDAI was retired, and the passcode is now also referred to as an Auth-Code.\n\n\n\n== Alternative systems ==\nThe .uk and .co.uk domain registry, instead of using a passcode, has the domain owner specify the new registrar using the old registrar. The destination registrar is specified using the destination's registrar tag, also known as an Internet Provider Security (IPS) tag or Nominet Provider tag.Some registries use a document based approach either in conjunction with or instead of an Auth-Code. An example for that is .hu for which the registrant has to fill out a document and send it to the new registrar, who sends it to the registry to fulfill the domain transfer.The .is domain registry uses the domains admin NIC handle and the old registrar has to update it to the new registrars NIC handle.Some other registries use an email template (that may or may not be in part processed automatically) like .lr or .jm. In this case the technical contact is set to the registrar and can be updated by sending an updated template from the registrant or admin contacts email address."
    }
  },
  {
    "instruction": "Cohen's cryptosystem\n\n==Introduction==\nCohen's cryptosystem is a public-key cryptosystem proposed in 1998 by Bram Cohen.\n\n== Key generation ==\nIn Cohen's cryptosystem, private key is a positive integer \n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n  .\nThe algorithm uses \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n   public-keys \n  \n    \n      \n        \n          w\n          \n            0\n          \n        \n        ,\n        \u2026\n        ,\n        \n          w\n          \n            k\n            \u2212\n            1\n          \n        \n      \n    \n    {\\displaystyle w_{0},\\ldots ,w_{k-1}}\n   defined as follows:\nGenerate \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n   random integers \n  \n    \n      \n        \n          u\n          \n            0\n          \n        \n        ,\n        \u2026\n        ,\n        \n          u\n          \n            k\n            \u2212\n            1\n          \n        \n      \n    \n    {\\displaystyle u_{0},\\ldots ,u_{k-1}}\n   chosen randomly and uniformly between \n  \n    \n      \n        \u2212\n        B\n      \n    \n    {\\displaystyle -B}\n   and \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n  . Where \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n   is some bound.\nLet \n  \n    \n      \n        A\n\n== Encrypting a bit ==\nTo encrypt a bit \n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n   Alice randomly adds \n  \n    \n      \n        \n          \n            k\n            2\n          \n        \n      \n    \n    {\\displaystyle {\\frac {k}{2}}}\n   public keys and multiplies the result by either 1 (if she wishes to send a 0) or by \u22121 (if she wishes to send a 1) to obtain the ciphertext \n  \n    \n      \n        c\n\n== De-cryption ==\nTo de-crypt, Bob computes \n  \n    \n      \n        h\nQuestion: How does Bob decrypt the ciphertext in Cohen's cryptosystem?",
    "context": "",
    "output": "Answer: Bob computes h(c) to decrypt the ciphertext in Cohen's cryptosystem.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does Bob decrypt the ciphertext in Cohen's cryptosystem?",
      "answer": "Bob computes h(c) to decrypt the ciphertext in Cohen's cryptosystem.",
      "context": "Cohen's cryptosystem\n\n==Introduction==\nCohen's cryptosystem is a public-key cryptosystem proposed in 1998 by Bram Cohen.\n\n== Key generation ==\nIn Cohen's cryptosystem, private key is a positive integer \n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n  .\nThe algorithm uses \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n   public-keys \n  \n    \n      \n        \n          w\n          \n            0\n          \n        \n        ,\n        \u2026\n        ,\n        \n          w\n          \n            k\n            \u2212\n            1\n          \n        \n      \n    \n    {\\displaystyle w_{0},\\ldots ,w_{k-1}}\n   defined as follows:\nGenerate \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n   random integers \n  \n    \n      \n        \n          u\n          \n            0\n          \n        \n        ,\n        \u2026\n        ,\n        \n          u\n          \n            k\n            \u2212\n            1\n          \n        \n      \n    \n    {\\displaystyle u_{0},\\ldots ,u_{k-1}}\n   chosen randomly and uniformly between \n  \n    \n      \n        \u2212\n        B\n      \n    \n    {\\displaystyle -B}\n   and \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n  . Where \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n   is some bound.\nLet \n  \n    \n      \n        A\n\n== Encrypting a bit ==\nTo encrypt a bit \n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n   Alice randomly adds \n  \n    \n      \n        \n          \n            k\n            2\n          \n        \n      \n    \n    {\\displaystyle {\\frac {k}{2}}}\n   public keys and multiplies the result by either 1 (if she wishes to send a 0) or by \u22121 (if she wishes to send a 1) to obtain the ciphertext \n  \n    \n      \n        c\n\n== De-cryption ==\nTo de-crypt, Bob computes \n  \n    \n      \n        h"
    }
  },
  {
    "instruction": "Write an answer to the following question: Which country had the highest percentage of Code Shikara spam code in April 2017?",
    "context": "",
    "output": "Niger had the highest percentage of Code Shikara spam code in April 2017 with 77.51%.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Which country had the highest percentage of Code Shikara spam code in April 2017?",
      "answer": "Niger had the highest percentage of Code Shikara spam code in April 2017 with 77.51%."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is an Author Domain Signature in the context of email security?",
    "context": "",
    "output": "An Author Domain Signature is a valid DKIM signature where the domain name of the DKIM signing entity is the same as the domain name in the author address, indicating that the entity that controls the DNS zone for the author has relayed the author's message.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is an Author Domain Signature in the context of email security?",
      "answer": "An Author Domain Signature is a valid DKIM signature where the domain name of the DKIM signing entity is the same as the domain name in the author address, indicating that the entity that controls the DNS zone for the author has relayed the author's message."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does Coreflood collect information from the infected computers?",
    "context": "",
    "output": "Coreflood collects information by acting as a keylogger, which records sensitive user information.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does Coreflood collect information from the infected computers?",
      "answer": "Coreflood collects information by acting as a keylogger, which records sensitive user information."
    }
  },
  {
    "instruction": "Zero-day (computing)\n\n==Introduction==\nA zero-day (also known as a 0-day) is a computer-software vulnerability previously unknown to those who should be interested in its mitigation, like the vendor of the target software. Until the vulnerability is mitigated, hackers can exploit it to adversely affect programs, data, additional computers or a network. An exploit taking advantage of a zero-day is called a zero-day exploit, or zero-day attack.\nThe term \"zero-day\" originally referred to the number of days since a new piece of software was released to the public, so \"zero-day software\" was obtained by hacking into a developer's computer before release. Eventually the term was applied to the vulnerabilities that allowed this hacking, and to the number of days that the vendor has had to fix them. Once the vendors learn of the vulnerability, they will usually create patches or advise workarounds to mitigate it.\nThe more recently that the vendor has become aware of the vulnerability, the more likely it is that no fix or mitigation has been developed. Once a fix is developed, the chance of the exploit succeeding decreases as more users apply the fix over time. For zero-day exploits, unless the vulnerability is inadvertently fixed, such as by an unrelated update that happens to fix the vulnerability, the probability that a user has applied a vendor-supplied patch that fixes the problem is zero, so the exploit would remain available. Zero-day attacks are a severe threat.\n\n\n\n== Attack vectors ==\nPotential attack vectors for a zero-day vulnerability are identical to known vulnerabilities and those that have available patches. For example, when a user visits a rogue website, malicious code on the site can exploit unpatched vulnerabilities in a Web browser. Web browsers are a particular target for criminals because of their widespread distribution and usage. Cybercriminals, as well as international vendors of spyware such as Israel\u2019s NSO Group, can also send malicious e-mail attachments via SMTP, which exploit vulnerabilities in the application opening the attachment. Exploits that take advantage of common file types are numerous and frequent, as evidenced by their increasing appearances in databases such as US-CERT. Criminals can engineer malware to take advantage of these file type exploits to compromise attacked systems or steal confidential data.\n\n== Window of vulnerability ==\nThe time from when a software exploit first becomes active to the time when the number of vulnerable systems shrinks to insignificance is known as the window of vulnerability. The timeline for each software vulnerability is defined by the following main events: \n\nt0: The vulnerability is discovered (by anyone).\nt1a: A security patch is published (e.g., by the software vendor).\nt1b: An exploit becomes active.\nt2: Most vulnerable systems have applied the patch.Thus the formula for the length of the window of vulnerability is: t2 \u2212 t1b.\nIn this formulation, it is always true that t0 \u2264 t1a, and t0 \u2264 t1b. Note that t0 is not the same as day zero. For example, if a hacker is the first to discover (at t0) the vulnerability, the vendor might not learn of it until much later (on day zero).\nFor normal vulnerabilities, t1b > t1a. This implies that the software vendor was aware of the vulnerability and had time to publish a security patch (t1a) before any hacker could craft a workable exploit (t1b). For zero-day exploits, t1b \u2264 t1a, such that the exploit becomes active before a patch is made available.\nBy not disclosing known vulnerabilities, a software vendor hopes to reach t2 before t1b is reached, thus avoiding any exploits. However, the vendor has no guarantees that hackers will not find vulnerabilities on their own. Furthermore, hackers can analyze the security patches themselves, and thereby discover the underlying vulnerabilities and automatically generate working exploits. These exploits can be used effectively up until time t2.\nIn practice, the length of the window of vulnerability varies between systems, vendors, and individual vulnerabilities. It is often measured in days, with one report from 2006 estimating the average as 28 days.\n\n== Protection ==\nZero-day protection is the ability to provide protection against zero-day exploits. Since zero-day attacks are generally unknown to the public, it is often difficult to defend against them. Zero-day attacks are often effective against \"secure\" networks and can remain undetected even after they are launched. Thus, users of so-called secure systems must also exercise common sense and practice safe computing habits.Many techniques exist to limit the effectiveness of zero-day memory corruption vulnerabilities such as buffer overflows. These protection mechanisms exist in contemporary operating systems such as macOS, Windows Vista and beyond (see also: Security and safety features new to Windows Vista), Solaris, Linux, Unix, and Unix-like environments; Windows XP Service Pack 2 includes limited protection against generic memory corruption vulnerabilities and previous versions include even less. Desktop and server protection software also exist to mitigate zero-day buffer overflow vulnerabilities. Typically, these technologies involve heuristic termination analysis in order to stop attacks before they cause any harm.It has been suggested that a solution of this kind may be out of reach because it is algorithmically impossible in the general case to analyze any arbitrary code to determine if it is malicious, as such an analysis reduces to the halting problem over a linear bounded automaton, which is unsolvable. It is, however, unnecessary to address the general case (that is, to sort all programs into the categories of malicious or non-malicious) under most circumstances in order to eliminate a wide range of malicious behaviors. It suffices to recognize the safety of a limited set of programs (e.g., those that can access or modify only a given subset of machine resources) while rejecting both some safe and all unsafe programs. This does require the integrity of those safe programs to be maintained, which may prove difficult in the face of a kernel-level exploit.The Zeroday Emergency Response Team (ZERT) was a group of software engineers who worked to release non-vendor patches for zero-day exploits.\n\n== Worms ==\nZero-day worms take advantage of a surprise attack while they are still unknown to computer security professionals. Recent history shows an increasing rate of worm propagation. Well designed worms can spread very fast with devastating consequences to the Internet and other systems.\n\n== Ethics ==\nDiffering ideologies exist relating to the collection and use of zero-day vulnerability information. Many computer security vendors perform research on zero-day vulnerabilities in order to better understand the nature of vulnerabilities and their exploitation by individuals, computer worms and viruses. Alternatively, some vendors purchase vulnerabilities to augment their research capacity. An example of such a program is TippingPoint's Zero Day Initiative. While selling and buying these vulnerabilities is not technically illegal in most parts of the world, there is a lot of controversy over the method of disclosure. A 2006 German decision to include Article 6 of the Convention on Cybercrime and the EU Framework Decision on Attacks against Information Systems may make selling or even manufacturing vulnerabilities illegal.Most formal programs follow some form of Rain Forest Puppy's disclosure guidelines or the more recent OIS Guidelines for Security Vulnerability Reporting and Response. In general, these rules forbid the public disclosure of vulnerabilities without notification to the vendor and adequate time to produce a patch.\n\n== Viruses ==\nA zero-day virus (also known as zero-day malware or next-generation malware) is a previously unknown computer virus or other malware for which specific antivirus software signatures are not yet available.Traditionally, antivirus software relied upon signatures to identify malware. A virus signature is a unique pattern or code that can be used to detect and identify specific viruses. The antivirus scans file signatures and compares them to a database of known malicious codes. If they match, the file is flagged and treated as a threat. The major limitation of signature-based detection is that it is only capable of flagging already known malware, making it useless against zero-day attacks. Most modern antivirus software still uses signatures but also carries out other types of analysis.\n\n\n*** Code analysis ***\nIn code analysis, the machine code of the file is analysed to see if there is anything that looks suspicious. Typically, malware has characteristic behaviour; code analysis attempts to detect if this is present in the code.\nAlthough useful, code analysis has significant limitations. It is not always easy to determine what a section of code is intended to do, particularly if it is very complex and has been deliberately written with the intention of defeating analysis. Another limitation of code analysis is the time and resources available. In the competitive world of antivirus software, there is always a balance between the effectiveness of analysis and the time delay involved.\nOne approach to overcome the limitations of code analysis is for the antivirus software to run suspect sections of code in a safe sandbox and observe their behavior. This can be orders of magnitude faster than analyzing the same code, but must resist (and detect) attempts by the code to detect the sandbox.\n\n\n*** Generic signatures ***\nGeneric signatures are signatures that are specific to certain behaviour rather than a specific item of malware. Most new malware is not totally novel, but is a variation on earlier malware, or contains code from one or more earlier examples of malware. Thus, the results of previous analysis can be used against new malware.\n\n\n*** Competitiveness in the antivirus software industry ***\nIt is generally accepted in the antivirus industry that most vendors' signature-based protection is identically effective. If a signature is available for an item of malware, then every product (unless dysfunctional) should detect it. However, some vendors are significantly faster than others at becoming aware of new viruses and/or updating their customers' signature databases to detect them.There is a wide range of effectiveness in terms of zero-day virus protection. The German computer magazine c't found that detection rates for zero-day viruses varied from 20% to 68%. It is primarily in the area of zero-day virus performance that manufacturers now compete.\n\n== U.S. government involvement ==\n\n\n*** NSA's use of zero-day exploits (2017) ***\nIn mid-April 2017 the hackers known as The Shadow Brokers (TSB), who are allegedly linked to the Russian government, released files from the NSA (initially just regarded as alleged to be from the NSA, later confirmed through internal details and by American whistleblower Edward Snowden) which include a series of 'zero-day exploits' targeting Microsoft Windows software and a tool to penetrate the Society for Worldwide Interbank Financial Telecommunication (SWIFT)'s service provider. Ars Technica had reported Shadow Brokers' hacking claims in mid-January 2017, and in April the Shadow Brokers posted the exploits as proof.\n\n\n*** Vulnerabilities Equities Process ***\n\nThe Vulnerabilities Equities Process, first revealed publicly in 2016, is a process used by the U.S. federal government to determine on a case-by-case basis how it should treat zero-day computer security vulnerabilities: whether to disclose them to the public to help improve general computer security or to keep them secret for offensive use against the government's adversaries. The process has been criticized for a number of deficiencies, including restriction by non-disclosure agreements, lack of risk ratings, special treatment for the NSA, and a less than full commitment to disclosure as the default option.\n\nQ: What are the potential deficiencies of the Vulnerabilities Equities Process?",
    "context": "",
    "output": "A: The Vulnerabilities Equities Process has been criticized for a number of deficiencies, including restriction by non-disclosure agreements, lack of risk ratings, special treatment for the NSA, and a less than full commitment to disclosure as the default option.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are the potential deficiencies of the Vulnerabilities Equities Process?",
      "answer": "The Vulnerabilities Equities Process has been criticized for a number of deficiencies, including restriction by non-disclosure agreements, lack of risk ratings, special treatment for the NSA, and a less than full commitment to disclosure as the default option.",
      "context": "Zero-day (computing)\n\n==Introduction==\nA zero-day (also known as a 0-day) is a computer-software vulnerability previously unknown to those who should be interested in its mitigation, like the vendor of the target software. Until the vulnerability is mitigated, hackers can exploit it to adversely affect programs, data, additional computers or a network. An exploit taking advantage of a zero-day is called a zero-day exploit, or zero-day attack.\nThe term \"zero-day\" originally referred to the number of days since a new piece of software was released to the public, so \"zero-day software\" was obtained by hacking into a developer's computer before release. Eventually the term was applied to the vulnerabilities that allowed this hacking, and to the number of days that the vendor has had to fix them. Once the vendors learn of the vulnerability, they will usually create patches or advise workarounds to mitigate it.\nThe more recently that the vendor has become aware of the vulnerability, the more likely it is that no fix or mitigation has been developed. Once a fix is developed, the chance of the exploit succeeding decreases as more users apply the fix over time. For zero-day exploits, unless the vulnerability is inadvertently fixed, such as by an unrelated update that happens to fix the vulnerability, the probability that a user has applied a vendor-supplied patch that fixes the problem is zero, so the exploit would remain available. Zero-day attacks are a severe threat.\n\n\n\n== Attack vectors ==\nPotential attack vectors for a zero-day vulnerability are identical to known vulnerabilities and those that have available patches. For example, when a user visits a rogue website, malicious code on the site can exploit unpatched vulnerabilities in a Web browser. Web browsers are a particular target for criminals because of their widespread distribution and usage. Cybercriminals, as well as international vendors of spyware such as Israel\u2019s NSO Group, can also send malicious e-mail attachments via SMTP, which exploit vulnerabilities in the application opening the attachment. Exploits that take advantage of common file types are numerous and frequent, as evidenced by their increasing appearances in databases such as US-CERT. Criminals can engineer malware to take advantage of these file type exploits to compromise attacked systems or steal confidential data.\n\n== Window of vulnerability ==\nThe time from when a software exploit first becomes active to the time when the number of vulnerable systems shrinks to insignificance is known as the window of vulnerability. The timeline for each software vulnerability is defined by the following main events: \n\nt0: The vulnerability is discovered (by anyone).\nt1a: A security patch is published (e.g., by the software vendor).\nt1b: An exploit becomes active.\nt2: Most vulnerable systems have applied the patch.Thus the formula for the length of the window of vulnerability is: t2 \u2212 t1b.\nIn this formulation, it is always true that t0 \u2264 t1a, and t0 \u2264 t1b. Note that t0 is not the same as day zero. For example, if a hacker is the first to discover (at t0) the vulnerability, the vendor might not learn of it until much later (on day zero).\nFor normal vulnerabilities, t1b > t1a. This implies that the software vendor was aware of the vulnerability and had time to publish a security patch (t1a) before any hacker could craft a workable exploit (t1b). For zero-day exploits, t1b \u2264 t1a, such that the exploit becomes active before a patch is made available.\nBy not disclosing known vulnerabilities, a software vendor hopes to reach t2 before t1b is reached, thus avoiding any exploits. However, the vendor has no guarantees that hackers will not find vulnerabilities on their own. Furthermore, hackers can analyze the security patches themselves, and thereby discover the underlying vulnerabilities and automatically generate working exploits. These exploits can be used effectively up until time t2.\nIn practice, the length of the window of vulnerability varies between systems, vendors, and individual vulnerabilities. It is often measured in days, with one report from 2006 estimating the average as 28 days.\n\n== Protection ==\nZero-day protection is the ability to provide protection against zero-day exploits. Since zero-day attacks are generally unknown to the public, it is often difficult to defend against them. Zero-day attacks are often effective against \"secure\" networks and can remain undetected even after they are launched. Thus, users of so-called secure systems must also exercise common sense and practice safe computing habits.Many techniques exist to limit the effectiveness of zero-day memory corruption vulnerabilities such as buffer overflows. These protection mechanisms exist in contemporary operating systems such as macOS, Windows Vista and beyond (see also: Security and safety features new to Windows Vista), Solaris, Linux, Unix, and Unix-like environments; Windows XP Service Pack 2 includes limited protection against generic memory corruption vulnerabilities and previous versions include even less. Desktop and server protection software also exist to mitigate zero-day buffer overflow vulnerabilities. Typically, these technologies involve heuristic termination analysis in order to stop attacks before they cause any harm.It has been suggested that a solution of this kind may be out of reach because it is algorithmically impossible in the general case to analyze any arbitrary code to determine if it is malicious, as such an analysis reduces to the halting problem over a linear bounded automaton, which is unsolvable. It is, however, unnecessary to address the general case (that is, to sort all programs into the categories of malicious or non-malicious) under most circumstances in order to eliminate a wide range of malicious behaviors. It suffices to recognize the safety of a limited set of programs (e.g., those that can access or modify only a given subset of machine resources) while rejecting both some safe and all unsafe programs. This does require the integrity of those safe programs to be maintained, which may prove difficult in the face of a kernel-level exploit.The Zeroday Emergency Response Team (ZERT) was a group of software engineers who worked to release non-vendor patches for zero-day exploits.\n\n== Worms ==\nZero-day worms take advantage of a surprise attack while they are still unknown to computer security professionals. Recent history shows an increasing rate of worm propagation. Well designed worms can spread very fast with devastating consequences to the Internet and other systems.\n\n== Ethics ==\nDiffering ideologies exist relating to the collection and use of zero-day vulnerability information. Many computer security vendors perform research on zero-day vulnerabilities in order to better understand the nature of vulnerabilities and their exploitation by individuals, computer worms and viruses. Alternatively, some vendors purchase vulnerabilities to augment their research capacity. An example of such a program is TippingPoint's Zero Day Initiative. While selling and buying these vulnerabilities is not technically illegal in most parts of the world, there is a lot of controversy over the method of disclosure. A 2006 German decision to include Article 6 of the Convention on Cybercrime and the EU Framework Decision on Attacks against Information Systems may make selling or even manufacturing vulnerabilities illegal.Most formal programs follow some form of Rain Forest Puppy's disclosure guidelines or the more recent OIS Guidelines for Security Vulnerability Reporting and Response. In general, these rules forbid the public disclosure of vulnerabilities without notification to the vendor and adequate time to produce a patch.\n\n== Viruses ==\nA zero-day virus (also known as zero-day malware or next-generation malware) is a previously unknown computer virus or other malware for which specific antivirus software signatures are not yet available.Traditionally, antivirus software relied upon signatures to identify malware. A virus signature is a unique pattern or code that can be used to detect and identify specific viruses. The antivirus scans file signatures and compares them to a database of known malicious codes. If they match, the file is flagged and treated as a threat. The major limitation of signature-based detection is that it is only capable of flagging already known malware, making it useless against zero-day attacks. Most modern antivirus software still uses signatures but also carries out other types of analysis.\n\n\n*** Code analysis ***\nIn code analysis, the machine code of the file is analysed to see if there is anything that looks suspicious. Typically, malware has characteristic behaviour; code analysis attempts to detect if this is present in the code.\nAlthough useful, code analysis has significant limitations. It is not always easy to determine what a section of code is intended to do, particularly if it is very complex and has been deliberately written with the intention of defeating analysis. Another limitation of code analysis is the time and resources available. In the competitive world of antivirus software, there is always a balance between the effectiveness of analysis and the time delay involved.\nOne approach to overcome the limitations of code analysis is for the antivirus software to run suspect sections of code in a safe sandbox and observe their behavior. This can be orders of magnitude faster than analyzing the same code, but must resist (and detect) attempts by the code to detect the sandbox.\n\n\n*** Generic signatures ***\nGeneric signatures are signatures that are specific to certain behaviour rather than a specific item of malware. Most new malware is not totally novel, but is a variation on earlier malware, or contains code from one or more earlier examples of malware. Thus, the results of previous analysis can be used against new malware.\n\n\n*** Competitiveness in the antivirus software industry ***\nIt is generally accepted in the antivirus industry that most vendors' signature-based protection is identically effective. If a signature is available for an item of malware, then every product (unless dysfunctional) should detect it. However, some vendors are significantly faster than others at becoming aware of new viruses and/or updating their customers' signature databases to detect them.There is a wide range of effectiveness in terms of zero-day virus protection. The German computer magazine c't found that detection rates for zero-day viruses varied from 20% to 68%. It is primarily in the area of zero-day virus performance that manufacturers now compete.\n\n== U.S. government involvement ==\n\n\n*** NSA's use of zero-day exploits (2017) ***\nIn mid-April 2017 the hackers known as The Shadow Brokers (TSB), who are allegedly linked to the Russian government, released files from the NSA (initially just regarded as alleged to be from the NSA, later confirmed through internal details and by American whistleblower Edward Snowden) which include a series of 'zero-day exploits' targeting Microsoft Windows software and a tool to penetrate the Society for Worldwide Interbank Financial Telecommunication (SWIFT)'s service provider. Ars Technica had reported Shadow Brokers' hacking claims in mid-January 2017, and in April the Shadow Brokers posted the exploits as proof.\n\n\n*** Vulnerabilities Equities Process ***\n\nThe Vulnerabilities Equities Process, first revealed publicly in 2016, is a process used by the U.S. federal government to determine on a case-by-case basis how it should treat zero-day computer security vulnerabilities: whether to disclose them to the public to help improve general computer security or to keep them secret for offensive use against the government's adversaries. The process has been criticized for a number of deficiencies, including restriction by non-disclosure agreements, lack of risk ratings, special treatment for the NSA, and a less than full commitment to disclosure as the default option."
    }
  },
  {
    "instruction": "Full body scanner\n\n==Introduction==\nA full-body scanner is a device that detects objects on or inside a person's body for security screening purposes, without physically removing clothes or making physical contact. Unlike metal detectors, full-body scanners can detect non-metal objects, which became an increasing concern after various airliner bombing attempts in the 2000s and some scanners can also detect swallowed items or hidden in body cavities of a person. Starting in 2007, full-body scanners started supplementing metal detectors at airports and train stations in many countries.\nThree distinct technologies have been used in practice:\n\nMillimeter wave scanners use non-ionizing electromagnetic radiation similar to that used by wireless data transmitters, in the extremely high frequency (EHF) radio band (which is a lower frequency than visible light). The health risks posed by these machines are still being studied, and the evidence is mixed, though millimeter wave scanners do not generate ionizing radiation.\nX-ray-based scanners\nBackscatter X-ray scanners use low dose radiation for detecting suspicious metallic and non-metallic objects hidden under clothing or in shoes and in the cavities of the human body. The dosage of radiation received is usually between 0.05 and 0.1 \u03bcSv Considerable debate regarding the safety of this method sparked investigations, ultimately leading multiple countries to ban the usage of them.\nTransmission X-ray scanners use higher dosage penetrating radiation which passes through the human body and then is captured by a detector or array of detectors. This type of full body scanners allows to detect objects hidden not only under the clothes, but also inside the human body (for example, drugs carried by drug couriers in the stomach) or in natural cavities. The dosage received is usually not higher than 0.25 \u03bcSv and is mainly regulated by the American radiation safety standard for personal search systems using gamma or X-ray radiation\nInfra-red thermal conductivity scanners do not use electromagnetic radiation to penetrate the body or clothing, but instead use slight temperature differences on the surface of clothing to detect the presence of foreign objects. Thermal conductivity relies on the ability of contraband hidden under clothing to heat or cool the surface of the clothing faster than the skin surface. Warm air is used to heat up the surface of the clothing. How fast the clothing cools is dependent, in part, on what is beneath it. Items that cool the clothing faster or slower than the surface of the skin will be identified by a thermal image of the clothing. These scanners are less often used compared to X-ray-based and mmWave-based scanners.Passengers and advocates have objected to images of their naked bodies being displayed to screening agents or recorded by the government. Critics have called the imaging virtual strip searches without probable cause, and have suggested they are illegal and violate basic human rights. However, current technology is less intrusive and because of privacy issues most people are allowed to refuse this scan and opt for a traditional pat-down. Depending on the technology used, the operator may see an alternate-wavelength image of the person's naked body, merely a cartoon-like representation of the person with an indicator showing where any suspicious items were detected, or full X-ray image of the person. For privacy and security reasons, the display is generally not visible to other passengers, and in some cases is located in a separate room where the operator cannot see the face of the person being screened. Transmission X-ray scanners claim to be more privacy neutral as there is almost no way to distinguish a person but they also have a software able to hide privacy issues.\n\n== Usage ==\n\nSchiphol in the Netherlands was the first airport in the world to implement SafeView's millimeter-wave body scanner on a large scale after a test with flight personnel the previous year. On May 15, 2007, two of 17 purchased security scans were installed.\nThe Italian government had planned to install full-body scanners at all airport and train stations throughout the country, but announced in September 2010 plans to remove the scanners from airports, calling them \"slow and ineffective\".The European Union currently allows member states to decide whether to implement full body scanners in their countries:\nIt is for each member state to decide to authorise the use of scanners in national airports. That will not change ... But where this scanning technology is used it should be covered by EU-wide standards on detection capability as well as common safeguards to ensure compliance with EU health and fundamental rights provisions.\n\n\n*** Australia ***\nIn Australia the government has decided a no opt-out policy will be enforced in relation to screening at airports. Persons with medical or physical conditions that prevent them from undertaking a body scan will be offered alternative screening methods suitable to their circumstances. Infants and young children under 140 cm will not be selected to undergo a body scan. \nBody-scanners are being used at eight of Australia's international airports \u2013 Adelaide, Brisbane, Cairns, Darwin, Gold Coast, Melbourne, Perth and Sydney. So far only passengers exiting via international flights are affected. Domestic and international passengers departing Newcastle Port Stephens airport have been subject to body scanning since October 2019. Passengers who refuse a scan may be banned from flying. The scanners proposed to be used in Australia have shown a high rate of error in testing. Public outrage over the nude images created by the body scanners being collected by policy resulted in a lawsuit in 2010 to stop body scanning.\n\n\n*** Canada ***\nIn Canada, 24 airports currently have these scanners in use, using millimeter-wave technology.  Transport Canada notes that \"Passengers selected for a secondary search can choose between the full body scanner or a physical search.\"\n\n\n*** United States ***\nIn the U.S. full-body scanners have been installed at train stations, subways, penitentiaries and airports.After having previously used X-ray-based scanners the TSA currently uses Millimeter Wave AIT scanners exclusively, which show no identifying characteristics of the person being scanned. Instead, a generic outline of a person is used. As of December 2015, \"While passengers may generally decline AIT screening in favor of physical screening, TSA may direct mandatory AIT screening for some passengers as warranted by security considerations in order to safeguard transportation security.\"Regarding privacy concerns the Transportation Security Administration (TSA) has stated in 2010 they \"[have] not, will not and the machines cannot store images of passengers at airports\". However the TSA later disclosed, in a response to the house chair on homeland security, that its procurement of airport scanners requires manufacturers to include image storage and transmission features but that these features should be disabled before being placed in an airport. The TSA shows 45 individuals have the ability to turn these machines into 'test mode' which enables recording images, but states that they would never do this on a production system. The US Marshal Service did operate a backscatter machine in a courthouse which records images. However, in a statement they noted that only individuals involved in a test were recorded. A sample of these images was received and disseminated by Gizmodo in 2010, using a Freedom Of Information Request. It is not clear if the US Marshal service has put these new scanning machines, that have recording capabilities, into production. The analyst is in a different room and is not supposed to be able to see the person being scanned by the Backscatter X-ray AIT, but is in contact with other officials who can halt the scanned person if anything suspicious shows up on the scan.\nUS Penitentiary is also constantly purchasing X-ray full body scanners for contraband and weapons detection purposes. The scanners are generally Transmission X-ray scanners since these are the only devices capable of detecting metallic and non-metallic contraband hidden underneath clothing as well as contraband hidden inside body cavities.\n\n\n*** United Kingdom ***\nCivil rights groups in Britain in 2010 argued that the body scanning of children contravened the law relating to child pornography.Passive infra-red scanners have been developed for use in public spaces to collect and analyse natural heat radiation given off by the human body to detect both metallic and non-metallic \"threat objects\". No external radiation source is used and privacy is preserved as no body details are revealed. Police are conducting a trial of the equipment at London rail stations.\n\n\n*** Asia Pacific ***\nDuring the forecast period of 2020\u20132025, the Asia\u2013Pacific region is projected to grow at the highest market CAGR (Compound Annual Growth Rate). The growth of this region is possibly due to the high airport investments and improvements in prison systems. China and India are heavily investing in greenfield airport construction. In January 2020, the Indian government decided to equip 84 airports with full-body scanners, which has led the Indian market to grow at a higher rate.\n\n== Controversies ==\n\n\n*** Privacy ***\nSome argue that using a full-body scanner is equivalent to a strip search, and if used without probable cause violates basic human rights.Full-body scanning allows screeners to see the surface of the skin under clothing. Prosthetics including breast prostheses and prosthetic testicles may require a potentially embarrassing physical inspection once detected. The scanners can also detect other medical equipment normally hidden, such as colostomy bags and catheters. The transgender community also has privacy concerns that body scanners could lead to their harassment.\nIn the UK, in 2010, the Equality and Human Rights Commission argued that full-body scanners were a risk to human rights and might be breaking the law.A ruling of the European Council in 2013 required that persons analyzing the image shall be in a separate location and the image shall not be linked to the screened person.In 2010 the National Human Rights Commission of Korea opposed the use of full-body scanners and recommended that they not be deployed at airports.Opponents in the US argue that full body scanners and the new TSA patdowns are unconstitutional. A comprehensive student note came out in the Fall 2010 issue of the University of Denver Transportation Law Journal arguing that full-body scanners are unconstitutional in the United States because they are (1) too invasive and (2) not effective enough because the process is too inefficient.On July 2, 2010, the Electronic Privacy Information Center (EPIC) filed a lawsuit to suspend the deployment of full-body scanners at airports in the United States:\nEPIC argued that the federal agency has violated the Administrative Procedures Act, the Privacy Act, the Religious Freedom Restoration Act, and the Fourth Amendment. EPIC cited the invasive nature of the devices, the TSA's disregard of public opinion, and the impact on religious freedom.\nEPIC claimed at that time that full-body scanners violated the Fourth Amendment to the United States Constitution because they subject citizens to a virtual strip search without any evidence of wrongdoing.The American Civil Liberties Union, in 2006, called the machines an invasion of privacy: \"This doesn't only concern genitals but body size, body shape and other things like evidence of mastectomies, colostomy appliances or catheter tubes. These are very personal things that people have every right to keep private and personal, aside from the modesty consideration of not wanting to be naked.\"In Idaho a bill was introduced in 2011 to prevent the use of full-body scanners as a primary screening method and allow people to request an alternative.Travelers at U.S. airports have complained that when they opted not to be scanned, they were subjected to a new type of invasive pat-down that one traveler in 2010 described as \"probing and pushing ... in my genital area.\" Another traveler in the United States complained in 2010 that the TSA employee \"inserted four fingers of both hands inside my trousers and ran his fingers all the way around my waist, his fingers extending at least 2\u20133 inches below my waistline.\"As of December 15, 2015 the TSA published a new policy which required AIT to be \"mandatory\" for \"some\" passengers for \"security reasons\". However, most individuals in the US can still opt out of the scanner and choose a pat-down if they are uncomfortable going through the scanner. Individuals also have the right to be patted down in a private room and have it witnessed by a person of the individual's choice.In November 2010, a female traveler who opted out of a full body scan at Fort Lauderdale International Airport claimed that TSA agents handcuffed her to a chair and ripped up her plane ticket when she asked questions about the new type of invasive pat down she was about to receive. In response, the TSA posted parts of the security camera footage on their blog, though there is no sound in the video and the passenger is not directly in the camera during most of the incident.\n\nWholebody imaging technology may not be used as the sole or primary method of screening persons, nor may it be used to screen any person unless another method of screening, such as metal detection, demonstrates cause for preventing such person from boarding an aircraft or entering a public facility or government building.\nIn the United States, in 2010 the TSA required that their full-body scanners \"allow exporting of image data in real time\", and cases of the government's storing of images have been confirmed.In August 2010, it was reported that the United States Marshals Service saved thousands of images from a millimeter wave scanner. TSA \u2013 part of the Department of Homeland Security \u2013 reiterated that its own scanners do not save images and that the scanners do not have the capability to save images when they are installed in airports. However, these statements contradict the TSA's own Procurement Specs which specifically require that the machines have the ability to record and transmit images, even if those features might be initially turned off on delivery. Opponents have also expressed skepticism that if there were a successful terror attack that the machines could not save images for later inspection to find out what went wrong with the scans. On November 16, 2010, 100 of the stored 35,000 body scan images were leaked online and posted by Gizmodo.In February 2012 airport employees in Lagos were allegedly discovered wandering away from a cubicle located in a hidden corner on the right side of the screening area to where the 3D full-body scanner monitors are located.\nAt the Dallas Ft. Worth International Airport, TSA complaints have been reported to disproportionally stem from women who felt that they were singled out for repeated screening for the entertainment of male security officers.\n\n\n*** Treatment of minorities ***\nCurrent backscatter and millimeter wave scanners installed by the TSA are unable to screen adequately for security threats inside turbans, hijab, burqas, casts, prosthetics and loose clothing. This technology limitation of current scanners often requires these persons to undergo additional screening by hand or other methods and can cause additional delay or feelings of harassment.According to a manufacturer of the machines, the next generation of backscatter scanners will be able to screen all types of clothing. These improved scanners have been designed to equalize the screening process for religious minorities.Currently the transmission (penetrating) X-ray technology is the only way to detect hidden objects inside prosthetic devices and other hiding criteria of the same type.\n\n\n*** Treatment of transgender people ***\nCurrent machines installed by the TSA require agents in the US to designate each passenger as either male or female, after which the software compares the passenger's body against a normative body of that sex. Transgender passengers have reported that full body scanners at several U.S. airports have falsely raised alarms based on their anatomy.\n\n\n*** Health concerns ***\nHealth concerns relating to the use of full-body scanning technology are present, especially pertaining to the use of X-ray scanners. The issue is mainly regulated by ANSI 43.17.2009, which limits the dose on a per-person basis. However this 2010-era document is intended to apply primarily in the context of standard civilian-airport security. It is generally not considered applicable to unusual terrorism-threat detection concerns in high-security environments (prisons, special-purpose airports) or military institutions. Nor is ANSI 43.17.2009 considered to be the appropriate standard for highly concealed threats such liquid bombs inside body cavities or swallowed drugs.  Due to fundamental physical limitations of how each type of detection technology functions, these highly covert types of threats are impossible to detect by any means other than transmission X-rays.\nFrom the perspective of annual dosage, the ANSI 43.17.2009 standard stipulates that a transmission X-ray dosage of 0.25 \u03bcSv per scan, in conjunction with an annual total limit at 250 \u00b5Sv, equates to a per-person maximum of such 1000 scans per year for a civilian-aviation passenger.  However, counting all medical X-ray procedures (as a typical person might undergo in an average year), and if the total annual dose of 250 \u00b5Sv is taken to include all medical-related doses, then the number of flights/scans permitted for that person could be greatly reduced, assuming that transmission-type X-ray technology is used at each security screening that the civil-aviation passenger undergoes.  But because the medical X-ray dosages vary tremendously (over several orders of magnitude) depending on the diagnostic procedures that the patient is subjected to, the proportional contribution of airport-security X-raying to the person's total annual dosage cannot be calculated unless an accounting of the medical X-ray dosages is also present.\n\n\n**** Millimeter wave scanners ****\n\nCurrently adopted millimeter wave scanners operate in the millimeter or sub-terahertz band, using non-ionizing radiation, and have no proven adverse health effects, though no long-term studies have been done. Thomas S. Tenforde, president of the National Council on Radiation Protection and Measurements, said in 2010 that millimeter wave scanners are probably within bounds [of standards for safe operation], but there should be an effort to verify that they are safe for frequent use. WHO (World Health Organization) in 2011 categorized RF (radio frequency) radiation as a possible carcinogen.Numerical simulations of terahertz radiation, which active millimeter-wave scanners do not operate at, have produced mixed results. Researchers at the Center for Nonlinear Studies at Los Alamos National Laboratory in New Mexico have used simulations to show a way that terahertz radiation may affect DNA, However, this has not been verified.\n\n\n**** Backscatter X-ray scanners ****\nIn the United States, the FAA Modernization and Reform Act of 2012 required that all full-body scanners operated in airports by the Transportation Security Administration use \"Automated Target Recognition\" software, which replaces the picture of a nude body with the cartoon-like representation.  As a result of this law, all backscatter X-ray machines formerly in use by the Transportation Security Administration were removed from airports by May 2013, since the agency said the vendor (Rapiscan) did not meet their contractual deadline to implement the software.In the European Union, backscatter X-ray screening of airline passengers was banned in 2012 to protect passenger safety, and the deployment at Manchester Airport was removed.\n\nSeveral radiation safety authorities including the National Council on Radiation Protection and Measurements, The Health Physics Society, and the American College of Radiology, have stated that they are \"not aware of any evidence\" that full-body scans are unsafe. However, other radiation authorities, including the International Atomic Energy Agency and Nuclear Energy Agency recommend against using ionizing radiation on certain populations like pregnant women and children, and opponents of the devices say that no long-term studies have been done on the health effects of either backscatter X-ray or millimeter wave scanners: \"I don't think the right questions have been asked. We don't have enough information to make a decision on whether there's going to be a biological effect or not\". (Douglas Boreham, professor in Medical Physics and Applied Radiation Sciences at McMaster University in Hamilton, Ontario.)\nRichard Morin, a medical physicist at the Mayo Clinic has said that he is not concerned about health effects from backscatter X-ray scanners: \"From a radiation standpoint there has been no evidence that there is really any untoward effect from the use of this device [backscatter scanner], so I would not be concerned about it from a radiation dose standpoint \u2013 the issues of personal privacy are a different thing\". The health effects of the more common millimeter wave scanner are largely unknown, and at least one expert believes a safety study is warranted. \"I am very interested in performing a National Council on Radiation Protection and Measurements study on the use of millimeter-wave security screening systems\", said Thomas S. Tenforde, council president. However, no long-term studies have been done on the health effects of millimeter wave scanners.\nPerhaps the most notable and debated professional opinion in regard to the safety of scanners is the so-called \"Holdren Letter\" from a number of world-renowned biochemists and biophysics researchers from the University of California to the Assistant to the US President for Science and Technology, Dr. John P. Holdren. The opening paragraph of their letter of concern reads: \"We, a number of University of California, San Francisco faculty, are writing\u2014see attached memo\u2014to call your attention to our concerns about the potential serious health risks of the recently adopted whole body back scatter X-ray airport security scanners. This is an urgent situation as these X-ray scanners are rapidly being implemented as a primary screening step for all air travel passengers.\"Critics of backscatter X-ray scanners, including the head of the Center for Radiological Research at Columbia University, say that the radiation emitted by some full-body scanners is as much as 20 times stronger than officially reported and is not safe to use on large numbers of persons because of an increased risk of cancer to children and at-risk populations.\nResearchers at the University of California, San Francisco, (UCSF) have argued that the amount of radiation is higher than claimed by the TSA and body scanner manufacturers because the doses were calculated as if distributed throughout the whole body, but the radiation from backscatter X-ray scanners is focused on just the skin and surrounding tissues:\nThe majority of [the scanners'] energy is delivered to the skin and the underlying tissue. Thus, while the dose would be safe if it were distributed throughout the volume of the entire body, the dose to the skin may be dangerously high.\nThe X-ray dose from these devices has often been compared in the media to the cosmic ray exposure inherent to airplane travel or that of a chest X-ray. However, this comparison is very misleading: both the air travel cosmic ray exposure and chest X- rays have much higher X-ray energies and the health consequences are appropriately understood in terms of the whole body volume dose. In contrast, these new airport scanners are largely depositing their energy into the skin and immediately adjacent tissue, and since this is such a small fraction of body weight/vol, possibly by one to two orders of magnitude, the real dose to the skin is now high.\n\nIn addition, it appears that real independent safety data do not exist. A search, ultimately finding top FDA radiation physics staff, suggests that the relevant radiation quantity, the Flux [photons per unit area and time (because this is a scanning device)] has not been characterized. Instead an indirect test (Air Kerma) was made that emphasized the whole body exposure value, and thus it appears that the danger is low when compared to cosmic rays during airplane travel and a chest X-ray dose.\nHowever other professors in the UCSF radiology department disagree, saying that the radiation dose is low. \"The conclusions are wrong\", Ronald Arenson, professor of radiology, tells SF Weekly of his own institution's letter. \"People who are totally unrelated to radiation wrote it. ... It was senior faculty at UCSF. They're smart people and well-intended, but their conclusions, I think, were off-base. They don't understand how radiation translates to an actual dose in the human body\".\nDr. Steve Smith, inventor of the body scanner in 1991, and president of Tek84, one of the companies that produces the machines, has stated that the concerns of Dr. Brenner and UCSF Scientists regarding the skin dose of backscatter scanners are incorrect. He states the values used for X-ray penetration were incorrectly based on the description of the imaging depth which describes what the instrument sees and is a few mm into the skin and the dosage depth which is deeper. He describes experimental proof that the X-rays have the same properties as any other X-rays and the penetration is correct to be averaged over the whole body. Dr. Smith has provided measured data from an operating body scanner to explain his position.In October 2010, The TSA responded to the concerns of UCSF researchers via the White House science advisor.Scanners also concentrate the dose in time, because they deliver a high dose-rate at the moment of exposure. High dose-rate exposure has been shown to cause greater damage than the same radiation dose delivered at lower rates. This raises further questions about comparisons to background radiation.\nThe FDA report states:\n\nSince general-use x-ray systems emit ionizing radiation, the societal benefit of reliably detecting threats must be sufficient to outweigh the potential radiation risk, if any, to the individual screened. The dose from one screening with a general-use x-ray security screening system is so low that it presents an extremely small risk to any individual. To put the radiation dose received into perspective:\nNaturally occurring ionizing radiation is all around us. We are continuously exposed to this background radiation during ordinary living. In 42 minutes of ordinary living, a person receives more radiation from naturally occurring sources than from screening with any general-use x-ray security system.\nThe national radiation safety standard (see below) sets a dose per screening limit for the general-use category. To meet the requirements of the general-use category a full-body x-ray security system must deliver less than the dose a person receives during 4 minutes of airline flight. TSA has set their dose limit to ensure a person receives less radiation from one scan with a TSA general-use x-ray security system than from 2 minutes of airline flight.\nA person would have to be screened more than a thousand times in one year in order to exceed the annual radiation dose limit for people screening that has been set by expert radiation safety organizations (see below).\nMillimeter wave security systems which comply with the limits set in the applicable national non-ionizing radiation safety standard (see below) cause no known adverse health effects.\nThe U.S. TSA has also made public various independent safety assessments of the Secure 1000 Backscatter X-ray Scanner.Dr. David Brenner, head of Columbia University's center for radiological research, said although the danger posed to the individual passenger is \"very low\", he is urging researchers to carry out more tests on the device to look at the way it affects specific groups who could be more sensitive to radiation.\nDr. Andrew J. Einstein, director of cardiac CT research at Columbia University, has made the following statements in support of the safety of body scanners: \"A passenger would need to be scanned using a backscatter scanner, from both the front and the back, about 200,000 times to receive the amount of radiation equal to one typical CT scan ... Another way to look at this is that if you were scanned with a backscatter scanner every day of your life, you would still only receive a tenth of the dose of a typical CT scan ... By comparison, the amount of radiation from a backscatter scanner is equivalent to about 10 minutes of natural background radiation in the United States ... I believe that the general public has nothing to worry about in terms of the radiation from airline scanning ... For moms-to-be, no evidence supports an increased risk of miscarriage or fetal abnormalities from these scanners ... A pregnant woman will receive much more radiation from cosmic rays she is exposed to while flying than from passing through a scanner in the airport\".\nIn May 2010 the National Council on Radiation Protection and Measurements issued a press release in response to the health risk claims from UCSF and Columbia University (claims of excessive skin dose and risks to large populations vs. individuals). The NCRP claims that cancer risks cited by opponents are completely inaccurate, stating that:\n the summation of trivial average risks over very large populations or time periods into a single value produces a distorted image of risk, completely out of perspective with risks accepted every day, both voluntarily and involuntarily.\nand that\n\ngeneral-use systems should adhere to an effective dose of 0.1 microsievert (\u03bcSv) (0.01 millirem) or less per scan, and can be used mostly without regard to the number of individuals scanned or the number of scans per individual in a year. An effective dose of 0.1 \u03bcSv (0.01 mrem) per scan would allow 2,500 scans of an individual annually [i.e., if each scan required 0.1 \u03bcSv (0.01 mrem)] without exceeding the administrative control of 0.25 mSv (25 mrem) to a member of the general public for a single source or set of sources under one control. Assuming 250 workdays per year, this would correspond to an average of 10 scans each day, a frequency that is unlikely to be encountered.\nAll the same the Inter-Agency Committee on Radiation Safety which includes the International Atomic Energy Agency, Nuclear Energy Agency and the World Health Organization, reported that, \"Pregnant women and children should not be subject to scanning, even though the radiation dose from body scanners is 'extremely small'\".It has also been suggested that defects in the machines, damage from normal wear-and-tear, or software errors could focus an intense dose of radiation on just one spot of the body. The researchers write:\nMoreover, there are a number of 'red flags' related to the hardware itself. Because this device can scan a human in a few seconds, the X-ray beam is very intense. Any glitch in power at any point in the hardware (or more importantly in software) that stops the device could cause an intense radiation dose to a single spot on the skin. Who will oversee problems with overall dose after repair or software problems? The TSA is already complaining about resolution limitations; who will keep the manufacturers and/or TSA from just raising the dose, an easy way to improve signal-to-noise and get higher resolution? Lastly, given the recent incident (on December 25th), how do we know whether the manufacturer or TSA, seeking higher resolution, will scan the groin area more slowly leading to a much higher total dose?\nProponents of backscatter X-ray scanners argue that the ANSI N43.17 standard addresses safety requirements and engineering design of the systems to prevent the occurrence of accidental high radiation due to defects and errors in hardware and software. Safety requirements include \"fail-safe\" controls, multiple overlapping interlocks and engineering design to ensure that failure of any systems result in safe or non-operation of the system to reduce the chance of accidental exposures. Furthermore, TSA requires that certification to the ANSI N43.17 standard is performed by a third party and not by the manufacturer themselves. But there are cases where types of medical scanning machines, operated by trained medical personnel, have malfunctioned, causing serious injury to patients that were scanned. Critics of full-body scanners cite these incidents as examples of how radiation-based scanning machines can overdose people with radiation despite all safety precautions.In March 2011, it was found that some of the full body scanners in the US were emitting 10 times the normal level of radiation: Contractors charged with routinely examining the scanners submitted reports containing discrepancies, including mathematical miscalculations showing that some of the devices emitted radiation levels 10 times higher than normal:Peter Kant, executive vice president of Rapiscan Systems, said that \"In our review of the surveys we found instances where a technician incorrectly did his math and came up with results that showed the radiation readings were off by a factor of 10\".\nThe X-rays from backscatter scanners \"are a form of ionizing radiation, that is, radiation powerful enough to strip molecules in the body of their electrons, creating charged particles that cause cell damage and are thought to be the mechanism through which radiation causes cancer.\" Humans are exposed to background radiation every day, anywhere on earth, and proponents of backscatter X-ray scanners say that the devices expose subjects to levels of radiation equivalent to background radiation. Furthermore, when traveling on an airplane, passengers are exposed to much higher levels of radiation than on earth due to altitude. Proponents say that a backscatter X-ray scan is equivalent to the radiation received during two minutes of flying.The UK Health Protection Agency has also issued a statement that the radiation dose from backscatter scanners is very low and \"about the same as one hour of background radiation\".The European Commission issued a report stating that backscatter X-ray scanners pose no known health risk, but suggested that backscatter X-ray scanners, which expose people to ionizing radiation, should not be used when millimeter-wave scanners that \"have less effects on the human body\" are available.Assuming all other conditions equal, there is no reason to adopt X\u2010ray backscatters, which expose the subject to an additional \u2013 although negligible \u2013 source of ionizing radiations. Other WBI (Whole Body Imaging) technologies should be preferred for standard use. However, the European Commission's report provides no data substantiating the claim that \"all other conditions are equal\". One area where backscatter X-ray scanners can provide better performance than millimeter wave scanners, for example, is in the inspection of the shoes, groin and armpit regions of the body. The European Commission also recommended that alternate screening methods should be \"used on pregnant women, babies, children and people with disabilities\".In the United States, Senator Susan Collins, Ranking Member of the Senate Homeland Security Committee sent a letter on August 6, 2010, to the Secretary of Homeland Security and Administrator of the TSA, requesting that the TSA \"have the Department's Chief Medical Officer, working with independent experts, conduct a review of the health effects of their use for travelers, TSA employees, and airport and airline personnel.\" The TSA has completed this review.The U.S. government is also supplying higher-radiation through-body X-ray machines to at least two African countries \"for the purposes of airport security \u2013 the kind that can see through flesh, and which deliver real doses of radiation. The U.S.-supplied scanners have apparently been deployed at one airport in Ghana and four in Nigeria\". This has caused some to question how far the U.S. government intends to go with the technology.Unions for airline pilots working for American Airlines and US Airways have urged pilots to avoid the full body scanners.\n\n\n*** Child scanning ***\nThere is controversy over full-body scanners in some countries because the machines create images of virtual strip searches on persons under the age of 18 which may violate child pornography laws. In the UK, the scanners may be breaking the Protection of Children Act of 1978 by creating images or pseudo-images of nude children.Parents have complained that their young children are being virtually strip searched, sometimes without their parents present.\n\n\n*** Ineffectiveness ***\n\n\n**** Backscatter and millimeter ****\nSome critics suggest that full-body scanner technology is ineffective for multiple reasons, including that they can easily be bypassed and a study published in the November 2010 edition of the Journal of Transportation Security suggested terrorists might fool the Rapiscan machines and others like it employing the X-ray \"backscatter\" technique. A terrorist, the report found, could tape a thin film of explosives of about 15\u201320 centimeters in diameter to the stomach and walk through the machine undetected.Terrorists have already evolved their tactics with the use of surgically implanted bombs or bombs hidden in body cavities.In March 2012, scientist and blogger Jonathan Corbett demonstrated the ineffectiveness of the machines by publishing a viral video showing how he was able to get a metal box through backscatter X-ray and millimeter wave scanners in two US airports. In April 2012, Corbett released a second video interviewing a TSA screener, who described firearms and simulated explosives passing through the scanners during internal testing and training. In another test of the full-body scanners, the machines failed to detect bomb parts hidden around a person's body. And in a different test in 2011, an undercover TSA agent was able to carry a handgun through full body scanners multiple times without the weapon being detected. However, in this case, the TSA agent who was in charge of viewing the scanned images was simply not paying attention.Furthermore, an Israeli airport security expert, Rafi Sela, who helped design security at Ben Gurion International Airport, has said: \"I don't know why everybody is running to buy these expensive and useless machines. I can overcome the body scanners with enough explosives to bring down a Boeing 747... That's why we haven't put them in our airport.\"Again, despite the scanners, the TSA has been unable to stop weapons like box cutters and pistols from being carried onto airplanes.The Australia government has been challenged over the effectiveness and cost of full body scanners by public media to which Australian Transport Minister Anthony Albanese has said he \"makes no apologies\" for mandating the installation of full body scanners at Australian airports.Two alternatives that have been argued for by experts, such as Prof Chris Mayhew from Birmingham University, are chemical-based scanners and bomb-sniffing dogs. Others have argued that passenger profiling, as done by Israeli airport security, should replace full body scanners and patdowns.\n\n\n**** Transmission (penetrating) ****\n\nUnlike the above, transmission technology allows to detect objects swallowed or hidden inside the objects. This is the main reason it is commonly used in prisons and jails. However the current technology does not allow the dual-energy body scanning (and detecting the object by its atomic number like it is used in baggage or vehicle X-ray scanners) which could give the image the same detection effectiveness as regular black and white X-ray. This leads to the idea that human-held detection (finding threats by looking at the image and finding non-common to the human body items) is the most effective way to find a contraband. However counting a human factor (fatigue, decreased attention) threats still could be missed. Modern software based on Artificial Intelligence in full body scanners is designed to minimize human faults and rise the detection effectiveness of this method.\n\n\n*** US public opinion ***\nA Gallup poll given just after the 2009 Christmas Day bombing attempt suggested that 78% of American airline travelers approved of body scanners while 20% disapproved. 51% indicated that they would have some level of discomfort with full-body scans, while 48% said they would not be uncomfortable with the idea. The poll was given in the context of the 2009 Christmas Day bombing attempt, and some opponents of full body scanners say that the explosives used in that bombing attempt would not have been detected by full-body scanners.An ABC/Washington Post poll conducted by Langer Associates and released November 22, 2010, found that 64 percent of Americans favored the full-body X-ray scanners, but that 50 percent think the \"enhanced\" pat-downs go too far; 37 percent felt so strongly. In addition the poll states opposition is lowest amongst those who fly less than once a year.As of November 23, 2010 an online poll of 11,817 people on The Consumerist website, 59.41% said they would not fly as a result of the new scans. Additionally, as of November 23, 2010, a poll of MSNBC 8,500 online readers indicated 84.1% believe the new procedures would not increase travel safety. According to a CBS telephone poll of 1,137 people published in November 2010, 81% (+/- 5%) percent of those polled approved TSA's use of full-body scans.There has been some debate about the safety of the scanners, however, the TSA argue that mmw scanners used emit no ionizing radiation.\n\n\n*** Full-body scanner lobbyists ***\nFormer Homeland Security secretary Michael Chertoff has been criticized for heavily promoting full-body scanners while not always fully disclosing that he is a lobbyist for one of the companies that makes the machines. Other full-body scanner lobbyists with government connections include:\nformer TSA deputy administrator Tom Blank\nformer assistant administrator for policy at the TSA, Chad Wolf\nKevin Patrick Kelly, \"a former top staffer to Sen. Barbara Mikulski, D-Md., who sits on the Homeland Security Appropriations subcommittee\"\nFormer Senator Al D'Amato\n\n\n*** TSA's expansion of scanning program ***\nForbes magazine reported, in March 2011, that:\nNewly uncovered documents show that as early as 2008, the Department of Homeland Security has been planning pilot programs to deploy mobile scanning units that can be set up at public events and in train stations, along with mobile x-ray vans capable of scanning pedestrians on city streets.\nand that the TSA had research proposals to:\n\nbring full-body scanners to train stations, mass transit, and public events. Contracts included in the EPIC release showed plans to develop long-range scans that could assess what a subject carried from 30 feet away, along with studies that involved systems for x-ray scanners mounted in vans and \"covert\" scans of pedestrians.\n\n\n*** \"No nudity\" full-body scanner ***\nMillimeter-wave scanner software transitioned to featureless male or female 'cartoons' in 2011, in response to widescale privacy concerns. Opponents of full body scanners still consider this an unconstitutional strip search, because even though the operator sees only an edited version of the image, a naked image is still captured by the machine, and there is no guarantee the government or a private company will not store it in the case that a terrorist attack were successful.\nCurrently, the millimeter-wave scanner monitor shows a generic cookie-cutter-like outline of a person and highlights potential threats. It is the same image no matter the individual's gender, height, or body type. The scanner software recognizes metallic and non-metallic items hiding under clothing. The machine then processes an image using yellow boxes to point out any areas that may need additional screening.TSA Administrator John Pistole stated that \"Our top priority is the safety of the traveling public, and TSA constantly strives to explore and implement new technologies that enhance security and strengthen privacy protections for the traveling public ... This software upgrade enables us to continue providing a high level of security through advanced imaging technology screening, while improving the passenger experience at checkpoints.\"\n\nHow does the annual dosage limit for transmission X-ray scanners in airport security screening relate to medical X-ray procedures?",
    "context": "",
    "output": "A: The ANSI 43.17.2009 standard stipulates that a transmission X-ray dosage of 0.25 \u00b5Sv per scan, in conjunction with an annual total limit at 250 \u00b5Sv, equates to a per-person maximum of 1000 scans per year for a civilian-aviation passenger. However, if transmission-type X-ray technology is used at each security screening, the number of flights/scans permitted for that person could be greatly reduced, depending on the diagnostic procedures the passenger is subjected to, as medical X-ray dosages vary tremendously.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the annual dosage limit for transmission X-ray scanners in airport security screening relate to medical X-ray procedures?",
      "answer": "The ANSI 43.17.2009 standard stipulates that a transmission X-ray dosage of 0.25 \u00b5Sv per scan, in conjunction with an annual total limit at 250 \u00b5Sv, equates to a per-person maximum of 1000 scans per year for a civilian-aviation passenger. However, if transmission-type X-ray technology is used at each security screening, the number of flights/scans permitted for that person could be greatly reduced, depending on the diagnostic procedures the passenger is subjected to, as medical X-ray dosages vary tremendously.",
      "context": "Full body scanner\n\n==Introduction==\nA full-body scanner is a device that detects objects on or inside a person's body for security screening purposes, without physically removing clothes or making physical contact. Unlike metal detectors, full-body scanners can detect non-metal objects, which became an increasing concern after various airliner bombing attempts in the 2000s and some scanners can also detect swallowed items or hidden in body cavities of a person. Starting in 2007, full-body scanners started supplementing metal detectors at airports and train stations in many countries.\nThree distinct technologies have been used in practice:\n\nMillimeter wave scanners use non-ionizing electromagnetic radiation similar to that used by wireless data transmitters, in the extremely high frequency (EHF) radio band (which is a lower frequency than visible light). The health risks posed by these machines are still being studied, and the evidence is mixed, though millimeter wave scanners do not generate ionizing radiation.\nX-ray-based scanners\nBackscatter X-ray scanners use low dose radiation for detecting suspicious metallic and non-metallic objects hidden under clothing or in shoes and in the cavities of the human body. The dosage of radiation received is usually between 0.05 and 0.1 \u03bcSv Considerable debate regarding the safety of this method sparked investigations, ultimately leading multiple countries to ban the usage of them.\nTransmission X-ray scanners use higher dosage penetrating radiation which passes through the human body and then is captured by a detector or array of detectors. This type of full body scanners allows to detect objects hidden not only under the clothes, but also inside the human body (for example, drugs carried by drug couriers in the stomach) or in natural cavities. The dosage received is usually not higher than 0.25 \u03bcSv and is mainly regulated by the American radiation safety standard for personal search systems using gamma or X-ray radiation\nInfra-red thermal conductivity scanners do not use electromagnetic radiation to penetrate the body or clothing, but instead use slight temperature differences on the surface of clothing to detect the presence of foreign objects. Thermal conductivity relies on the ability of contraband hidden under clothing to heat or cool the surface of the clothing faster than the skin surface. Warm air is used to heat up the surface of the clothing. How fast the clothing cools is dependent, in part, on what is beneath it. Items that cool the clothing faster or slower than the surface of the skin will be identified by a thermal image of the clothing. These scanners are less often used compared to X-ray-based and mmWave-based scanners.Passengers and advocates have objected to images of their naked bodies being displayed to screening agents or recorded by the government. Critics have called the imaging virtual strip searches without probable cause, and have suggested they are illegal and violate basic human rights. However, current technology is less intrusive and because of privacy issues most people are allowed to refuse this scan and opt for a traditional pat-down. Depending on the technology used, the operator may see an alternate-wavelength image of the person's naked body, merely a cartoon-like representation of the person with an indicator showing where any suspicious items were detected, or full X-ray image of the person. For privacy and security reasons, the display is generally not visible to other passengers, and in some cases is located in a separate room where the operator cannot see the face of the person being screened. Transmission X-ray scanners claim to be more privacy neutral as there is almost no way to distinguish a person but they also have a software able to hide privacy issues.\n\n== Usage ==\n\nSchiphol in the Netherlands was the first airport in the world to implement SafeView's millimeter-wave body scanner on a large scale after a test with flight personnel the previous year. On May 15, 2007, two of 17 purchased security scans were installed.\nThe Italian government had planned to install full-body scanners at all airport and train stations throughout the country, but announced in September 2010 plans to remove the scanners from airports, calling them \"slow and ineffective\".The European Union currently allows member states to decide whether to implement full body scanners in their countries:\nIt is for each member state to decide to authorise the use of scanners in national airports. That will not change ... But where this scanning technology is used it should be covered by EU-wide standards on detection capability as well as common safeguards to ensure compliance with EU health and fundamental rights provisions.\n\n\n*** Australia ***\nIn Australia the government has decided a no opt-out policy will be enforced in relation to screening at airports. Persons with medical or physical conditions that prevent them from undertaking a body scan will be offered alternative screening methods suitable to their circumstances. Infants and young children under 140 cm will not be selected to undergo a body scan. \nBody-scanners are being used at eight of Australia's international airports \u2013 Adelaide, Brisbane, Cairns, Darwin, Gold Coast, Melbourne, Perth and Sydney. So far only passengers exiting via international flights are affected. Domestic and international passengers departing Newcastle Port Stephens airport have been subject to body scanning since October 2019. Passengers who refuse a scan may be banned from flying. The scanners proposed to be used in Australia have shown a high rate of error in testing. Public outrage over the nude images created by the body scanners being collected by policy resulted in a lawsuit in 2010 to stop body scanning.\n\n\n*** Canada ***\nIn Canada, 24 airports currently have these scanners in use, using millimeter-wave technology.  Transport Canada notes that \"Passengers selected for a secondary search can choose between the full body scanner or a physical search.\"\n\n\n*** United States ***\nIn the U.S. full-body scanners have been installed at train stations, subways, penitentiaries and airports.After having previously used X-ray-based scanners the TSA currently uses Millimeter Wave AIT scanners exclusively, which show no identifying characteristics of the person being scanned. Instead, a generic outline of a person is used. As of December 2015, \"While passengers may generally decline AIT screening in favor of physical screening, TSA may direct mandatory AIT screening for some passengers as warranted by security considerations in order to safeguard transportation security.\"Regarding privacy concerns the Transportation Security Administration (TSA) has stated in 2010 they \"[have] not, will not and the machines cannot store images of passengers at airports\". However the TSA later disclosed, in a response to the house chair on homeland security, that its procurement of airport scanners requires manufacturers to include image storage and transmission features but that these features should be disabled before being placed in an airport. The TSA shows 45 individuals have the ability to turn these machines into 'test mode' which enables recording images, but states that they would never do this on a production system. The US Marshal Service did operate a backscatter machine in a courthouse which records images. However, in a statement they noted that only individuals involved in a test were recorded. A sample of these images was received and disseminated by Gizmodo in 2010, using a Freedom Of Information Request. It is not clear if the US Marshal service has put these new scanning machines, that have recording capabilities, into production. The analyst is in a different room and is not supposed to be able to see the person being scanned by the Backscatter X-ray AIT, but is in contact with other officials who can halt the scanned person if anything suspicious shows up on the scan.\nUS Penitentiary is also constantly purchasing X-ray full body scanners for contraband and weapons detection purposes. The scanners are generally Transmission X-ray scanners since these are the only devices capable of detecting metallic and non-metallic contraband hidden underneath clothing as well as contraband hidden inside body cavities.\n\n\n*** United Kingdom ***\nCivil rights groups in Britain in 2010 argued that the body scanning of children contravened the law relating to child pornography.Passive infra-red scanners have been developed for use in public spaces to collect and analyse natural heat radiation given off by the human body to detect both metallic and non-metallic \"threat objects\". No external radiation source is used and privacy is preserved as no body details are revealed. Police are conducting a trial of the equipment at London rail stations.\n\n\n*** Asia Pacific ***\nDuring the forecast period of 2020\u20132025, the Asia\u2013Pacific region is projected to grow at the highest market CAGR (Compound Annual Growth Rate). The growth of this region is possibly due to the high airport investments and improvements in prison systems. China and India are heavily investing in greenfield airport construction. In January 2020, the Indian government decided to equip 84 airports with full-body scanners, which has led the Indian market to grow at a higher rate.\n\n== Controversies ==\n\n\n*** Privacy ***\nSome argue that using a full-body scanner is equivalent to a strip search, and if used without probable cause violates basic human rights.Full-body scanning allows screeners to see the surface of the skin under clothing. Prosthetics including breast prostheses and prosthetic testicles may require a potentially embarrassing physical inspection once detected. The scanners can also detect other medical equipment normally hidden, such as colostomy bags and catheters. The transgender community also has privacy concerns that body scanners could lead to their harassment.\nIn the UK, in 2010, the Equality and Human Rights Commission argued that full-body scanners were a risk to human rights and might be breaking the law.A ruling of the European Council in 2013 required that persons analyzing the image shall be in a separate location and the image shall not be linked to the screened person.In 2010 the National Human Rights Commission of Korea opposed the use of full-body scanners and recommended that they not be deployed at airports.Opponents in the US argue that full body scanners and the new TSA patdowns are unconstitutional. A comprehensive student note came out in the Fall 2010 issue of the University of Denver Transportation Law Journal arguing that full-body scanners are unconstitutional in the United States because they are (1) too invasive and (2) not effective enough because the process is too inefficient.On July 2, 2010, the Electronic Privacy Information Center (EPIC) filed a lawsuit to suspend the deployment of full-body scanners at airports in the United States:\nEPIC argued that the federal agency has violated the Administrative Procedures Act, the Privacy Act, the Religious Freedom Restoration Act, and the Fourth Amendment. EPIC cited the invasive nature of the devices, the TSA's disregard of public opinion, and the impact on religious freedom.\nEPIC claimed at that time that full-body scanners violated the Fourth Amendment to the United States Constitution because they subject citizens to a virtual strip search without any evidence of wrongdoing.The American Civil Liberties Union, in 2006, called the machines an invasion of privacy: \"This doesn't only concern genitals but body size, body shape and other things like evidence of mastectomies, colostomy appliances or catheter tubes. These are very personal things that people have every right to keep private and personal, aside from the modesty consideration of not wanting to be naked.\"In Idaho a bill was introduced in 2011 to prevent the use of full-body scanners as a primary screening method and allow people to request an alternative.Travelers at U.S. airports have complained that when they opted not to be scanned, they were subjected to a new type of invasive pat-down that one traveler in 2010 described as \"probing and pushing ... in my genital area.\" Another traveler in the United States complained in 2010 that the TSA employee \"inserted four fingers of both hands inside my trousers and ran his fingers all the way around my waist, his fingers extending at least 2\u20133 inches below my waistline.\"As of December 15, 2015 the TSA published a new policy which required AIT to be \"mandatory\" for \"some\" passengers for \"security reasons\". However, most individuals in the US can still opt out of the scanner and choose a pat-down if they are uncomfortable going through the scanner. Individuals also have the right to be patted down in a private room and have it witnessed by a person of the individual's choice.In November 2010, a female traveler who opted out of a full body scan at Fort Lauderdale International Airport claimed that TSA agents handcuffed her to a chair and ripped up her plane ticket when she asked questions about the new type of invasive pat down she was about to receive. In response, the TSA posted parts of the security camera footage on their blog, though there is no sound in the video and the passenger is not directly in the camera during most of the incident.\n\nWholebody imaging technology may not be used as the sole or primary method of screening persons, nor may it be used to screen any person unless another method of screening, such as metal detection, demonstrates cause for preventing such person from boarding an aircraft or entering a public facility or government building.\nIn the United States, in 2010 the TSA required that their full-body scanners \"allow exporting of image data in real time\", and cases of the government's storing of images have been confirmed.In August 2010, it was reported that the United States Marshals Service saved thousands of images from a millimeter wave scanner. TSA \u2013 part of the Department of Homeland Security \u2013 reiterated that its own scanners do not save images and that the scanners do not have the capability to save images when they are installed in airports. However, these statements contradict the TSA's own Procurement Specs which specifically require that the machines have the ability to record and transmit images, even if those features might be initially turned off on delivery. Opponents have also expressed skepticism that if there were a successful terror attack that the machines could not save images for later inspection to find out what went wrong with the scans. On November 16, 2010, 100 of the stored 35,000 body scan images were leaked online and posted by Gizmodo.In February 2012 airport employees in Lagos were allegedly discovered wandering away from a cubicle located in a hidden corner on the right side of the screening area to where the 3D full-body scanner monitors are located.\nAt the Dallas Ft. Worth International Airport, TSA complaints have been reported to disproportionally stem from women who felt that they were singled out for repeated screening for the entertainment of male security officers.\n\n\n*** Treatment of minorities ***\nCurrent backscatter and millimeter wave scanners installed by the TSA are unable to screen adequately for security threats inside turbans, hijab, burqas, casts, prosthetics and loose clothing. This technology limitation of current scanners often requires these persons to undergo additional screening by hand or other methods and can cause additional delay or feelings of harassment.According to a manufacturer of the machines, the next generation of backscatter scanners will be able to screen all types of clothing. These improved scanners have been designed to equalize the screening process for religious minorities.Currently the transmission (penetrating) X-ray technology is the only way to detect hidden objects inside prosthetic devices and other hiding criteria of the same type.\n\n\n*** Treatment of transgender people ***\nCurrent machines installed by the TSA require agents in the US to designate each passenger as either male or female, after which the software compares the passenger's body against a normative body of that sex. Transgender passengers have reported that full body scanners at several U.S. airports have falsely raised alarms based on their anatomy.\n\n\n*** Health concerns ***\nHealth concerns relating to the use of full-body scanning technology are present, especially pertaining to the use of X-ray scanners. The issue is mainly regulated by ANSI 43.17.2009, which limits the dose on a per-person basis. However this 2010-era document is intended to apply primarily in the context of standard civilian-airport security. It is generally not considered applicable to unusual terrorism-threat detection concerns in high-security environments (prisons, special-purpose airports) or military institutions. Nor is ANSI 43.17.2009 considered to be the appropriate standard for highly concealed threats such liquid bombs inside body cavities or swallowed drugs.  Due to fundamental physical limitations of how each type of detection technology functions, these highly covert types of threats are impossible to detect by any means other than transmission X-rays.\nFrom the perspective of annual dosage, the ANSI 43.17.2009 standard stipulates that a transmission X-ray dosage of 0.25 \u03bcSv per scan, in conjunction with an annual total limit at 250 \u00b5Sv, equates to a per-person maximum of such 1000 scans per year for a civilian-aviation passenger.  However, counting all medical X-ray procedures (as a typical person might undergo in an average year), and if the total annual dose of 250 \u00b5Sv is taken to include all medical-related doses, then the number of flights/scans permitted for that person could be greatly reduced, assuming that transmission-type X-ray technology is used at each security screening that the civil-aviation passenger undergoes.  But because the medical X-ray dosages vary tremendously (over several orders of magnitude) depending on the diagnostic procedures that the patient is subjected to, the proportional contribution of airport-security X-raying to the person's total annual dosage cannot be calculated unless an accounting of the medical X-ray dosages is also present.\n\n\n**** Millimeter wave scanners ****\n\nCurrently adopted millimeter wave scanners operate in the millimeter or sub-terahertz band, using non-ionizing radiation, and have no proven adverse health effects, though no long-term studies have been done. Thomas S. Tenforde, president of the National Council on Radiation Protection and Measurements, said in 2010 that millimeter wave scanners are probably within bounds [of standards for safe operation], but there should be an effort to verify that they are safe for frequent use. WHO (World Health Organization) in 2011 categorized RF (radio frequency) radiation as a possible carcinogen.Numerical simulations of terahertz radiation, which active millimeter-wave scanners do not operate at, have produced mixed results. Researchers at the Center for Nonlinear Studies at Los Alamos National Laboratory in New Mexico have used simulations to show a way that terahertz radiation may affect DNA, However, this has not been verified.\n\n\n**** Backscatter X-ray scanners ****\nIn the United States, the FAA Modernization and Reform Act of 2012 required that all full-body scanners operated in airports by the Transportation Security Administration use \"Automated Target Recognition\" software, which replaces the picture of a nude body with the cartoon-like representation.  As a result of this law, all backscatter X-ray machines formerly in use by the Transportation Security Administration were removed from airports by May 2013, since the agency said the vendor (Rapiscan) did not meet their contractual deadline to implement the software.In the European Union, backscatter X-ray screening of airline passengers was banned in 2012 to protect passenger safety, and the deployment at Manchester Airport was removed.\n\nSeveral radiation safety authorities including the National Council on Radiation Protection and Measurements, The Health Physics Society, and the American College of Radiology, have stated that they are \"not aware of any evidence\" that full-body scans are unsafe. However, other radiation authorities, including the International Atomic Energy Agency and Nuclear Energy Agency recommend against using ionizing radiation on certain populations like pregnant women and children, and opponents of the devices say that no long-term studies have been done on the health effects of either backscatter X-ray or millimeter wave scanners: \"I don't think the right questions have been asked. We don't have enough information to make a decision on whether there's going to be a biological effect or not\". (Douglas Boreham, professor in Medical Physics and Applied Radiation Sciences at McMaster University in Hamilton, Ontario.)\nRichard Morin, a medical physicist at the Mayo Clinic has said that he is not concerned about health effects from backscatter X-ray scanners: \"From a radiation standpoint there has been no evidence that there is really any untoward effect from the use of this device [backscatter scanner], so I would not be concerned about it from a radiation dose standpoint \u2013 the issues of personal privacy are a different thing\". The health effects of the more common millimeter wave scanner are largely unknown, and at least one expert believes a safety study is warranted. \"I am very interested in performing a National Council on Radiation Protection and Measurements study on the use of millimeter-wave security screening systems\", said Thomas S. Tenforde, council president. However, no long-term studies have been done on the health effects of millimeter wave scanners.\nPerhaps the most notable and debated professional opinion in regard to the safety of scanners is the so-called \"Holdren Letter\" from a number of world-renowned biochemists and biophysics researchers from the University of California to the Assistant to the US President for Science and Technology, Dr. John P. Holdren. The opening paragraph of their letter of concern reads: \"We, a number of University of California, San Francisco faculty, are writing\u2014see attached memo\u2014to call your attention to our concerns about the potential serious health risks of the recently adopted whole body back scatter X-ray airport security scanners. This is an urgent situation as these X-ray scanners are rapidly being implemented as a primary screening step for all air travel passengers.\"Critics of backscatter X-ray scanners, including the head of the Center for Radiological Research at Columbia University, say that the radiation emitted by some full-body scanners is as much as 20 times stronger than officially reported and is not safe to use on large numbers of persons because of an increased risk of cancer to children and at-risk populations.\nResearchers at the University of California, San Francisco, (UCSF) have argued that the amount of radiation is higher than claimed by the TSA and body scanner manufacturers because the doses were calculated as if distributed throughout the whole body, but the radiation from backscatter X-ray scanners is focused on just the skin and surrounding tissues:\nThe majority of [the scanners'] energy is delivered to the skin and the underlying tissue. Thus, while the dose would be safe if it were distributed throughout the volume of the entire body, the dose to the skin may be dangerously high.\nThe X-ray dose from these devices has often been compared in the media to the cosmic ray exposure inherent to airplane travel or that of a chest X-ray. However, this comparison is very misleading: both the air travel cosmic ray exposure and chest X- rays have much higher X-ray energies and the health consequences are appropriately understood in terms of the whole body volume dose. In contrast, these new airport scanners are largely depositing their energy into the skin and immediately adjacent tissue, and since this is such a small fraction of body weight/vol, possibly by one to two orders of magnitude, the real dose to the skin is now high.\n\nIn addition, it appears that real independent safety data do not exist. A search, ultimately finding top FDA radiation physics staff, suggests that the relevant radiation quantity, the Flux [photons per unit area and time (because this is a scanning device)] has not been characterized. Instead an indirect test (Air Kerma) was made that emphasized the whole body exposure value, and thus it appears that the danger is low when compared to cosmic rays during airplane travel and a chest X-ray dose.\nHowever other professors in the UCSF radiology department disagree, saying that the radiation dose is low. \"The conclusions are wrong\", Ronald Arenson, professor of radiology, tells SF Weekly of his own institution's letter. \"People who are totally unrelated to radiation wrote it. ... It was senior faculty at UCSF. They're smart people and well-intended, but their conclusions, I think, were off-base. They don't understand how radiation translates to an actual dose in the human body\".\nDr. Steve Smith, inventor of the body scanner in 1991, and president of Tek84, one of the companies that produces the machines, has stated that the concerns of Dr. Brenner and UCSF Scientists regarding the skin dose of backscatter scanners are incorrect. He states the values used for X-ray penetration were incorrectly based on the description of the imaging depth which describes what the instrument sees and is a few mm into the skin and the dosage depth which is deeper. He describes experimental proof that the X-rays have the same properties as any other X-rays and the penetration is correct to be averaged over the whole body. Dr. Smith has provided measured data from an operating body scanner to explain his position.In October 2010, The TSA responded to the concerns of UCSF researchers via the White House science advisor.Scanners also concentrate the dose in time, because they deliver a high dose-rate at the moment of exposure. High dose-rate exposure has been shown to cause greater damage than the same radiation dose delivered at lower rates. This raises further questions about comparisons to background radiation.\nThe FDA report states:\n\nSince general-use x-ray systems emit ionizing radiation, the societal benefit of reliably detecting threats must be sufficient to outweigh the potential radiation risk, if any, to the individual screened. The dose from one screening with a general-use x-ray security screening system is so low that it presents an extremely small risk to any individual. To put the radiation dose received into perspective:\nNaturally occurring ionizing radiation is all around us. We are continuously exposed to this background radiation during ordinary living. In 42 minutes of ordinary living, a person receives more radiation from naturally occurring sources than from screening with any general-use x-ray security system.\nThe national radiation safety standard (see below) sets a dose per screening limit for the general-use category. To meet the requirements of the general-use category a full-body x-ray security system must deliver less than the dose a person receives during 4 minutes of airline flight. TSA has set their dose limit to ensure a person receives less radiation from one scan with a TSA general-use x-ray security system than from 2 minutes of airline flight.\nA person would have to be screened more than a thousand times in one year in order to exceed the annual radiation dose limit for people screening that has been set by expert radiation safety organizations (see below).\nMillimeter wave security systems which comply with the limits set in the applicable national non-ionizing radiation safety standard (see below) cause no known adverse health effects.\nThe U.S. TSA has also made public various independent safety assessments of the Secure 1000 Backscatter X-ray Scanner.Dr. David Brenner, head of Columbia University's center for radiological research, said although the danger posed to the individual passenger is \"very low\", he is urging researchers to carry out more tests on the device to look at the way it affects specific groups who could be more sensitive to radiation.\nDr. Andrew J. Einstein, director of cardiac CT research at Columbia University, has made the following statements in support of the safety of body scanners: \"A passenger would need to be scanned using a backscatter scanner, from both the front and the back, about 200,000 times to receive the amount of radiation equal to one typical CT scan ... Another way to look at this is that if you were scanned with a backscatter scanner every day of your life, you would still only receive a tenth of the dose of a typical CT scan ... By comparison, the amount of radiation from a backscatter scanner is equivalent to about 10 minutes of natural background radiation in the United States ... I believe that the general public has nothing to worry about in terms of the radiation from airline scanning ... For moms-to-be, no evidence supports an increased risk of miscarriage or fetal abnormalities from these scanners ... A pregnant woman will receive much more radiation from cosmic rays she is exposed to while flying than from passing through a scanner in the airport\".\nIn May 2010 the National Council on Radiation Protection and Measurements issued a press release in response to the health risk claims from UCSF and Columbia University (claims of excessive skin dose and risks to large populations vs. individuals). The NCRP claims that cancer risks cited by opponents are completely inaccurate, stating that:\n the summation of trivial average risks over very large populations or time periods into a single value produces a distorted image of risk, completely out of perspective with risks accepted every day, both voluntarily and involuntarily.\nand that\n\ngeneral-use systems should adhere to an effective dose of 0.1 microsievert (\u03bcSv) (0.01 millirem) or less per scan, and can be used mostly without regard to the number of individuals scanned or the number of scans per individual in a year. An effective dose of 0.1 \u03bcSv (0.01 mrem) per scan would allow 2,500 scans of an individual annually [i.e., if each scan required 0.1 \u03bcSv (0.01 mrem)] without exceeding the administrative control of 0.25 mSv (25 mrem) to a member of the general public for a single source or set of sources under one control. Assuming 250 workdays per year, this would correspond to an average of 10 scans each day, a frequency that is unlikely to be encountered.\nAll the same the Inter-Agency Committee on Radiation Safety which includes the International Atomic Energy Agency, Nuclear Energy Agency and the World Health Organization, reported that, \"Pregnant women and children should not be subject to scanning, even though the radiation dose from body scanners is 'extremely small'\".It has also been suggested that defects in the machines, damage from normal wear-and-tear, or software errors could focus an intense dose of radiation on just one spot of the body. The researchers write:\nMoreover, there are a number of 'red flags' related to the hardware itself. Because this device can scan a human in a few seconds, the X-ray beam is very intense. Any glitch in power at any point in the hardware (or more importantly in software) that stops the device could cause an intense radiation dose to a single spot on the skin. Who will oversee problems with overall dose after repair or software problems? The TSA is already complaining about resolution limitations; who will keep the manufacturers and/or TSA from just raising the dose, an easy way to improve signal-to-noise and get higher resolution? Lastly, given the recent incident (on December 25th), how do we know whether the manufacturer or TSA, seeking higher resolution, will scan the groin area more slowly leading to a much higher total dose?\nProponents of backscatter X-ray scanners argue that the ANSI N43.17 standard addresses safety requirements and engineering design of the systems to prevent the occurrence of accidental high radiation due to defects and errors in hardware and software. Safety requirements include \"fail-safe\" controls, multiple overlapping interlocks and engineering design to ensure that failure of any systems result in safe or non-operation of the system to reduce the chance of accidental exposures. Furthermore, TSA requires that certification to the ANSI N43.17 standard is performed by a third party and not by the manufacturer themselves. But there are cases where types of medical scanning machines, operated by trained medical personnel, have malfunctioned, causing serious injury to patients that were scanned. Critics of full-body scanners cite these incidents as examples of how radiation-based scanning machines can overdose people with radiation despite all safety precautions.In March 2011, it was found that some of the full body scanners in the US were emitting 10 times the normal level of radiation: Contractors charged with routinely examining the scanners submitted reports containing discrepancies, including mathematical miscalculations showing that some of the devices emitted radiation levels 10 times higher than normal:Peter Kant, executive vice president of Rapiscan Systems, said that \"In our review of the surveys we found instances where a technician incorrectly did his math and came up with results that showed the radiation readings were off by a factor of 10\".\nThe X-rays from backscatter scanners \"are a form of ionizing radiation, that is, radiation powerful enough to strip molecules in the body of their electrons, creating charged particles that cause cell damage and are thought to be the mechanism through which radiation causes cancer.\" Humans are exposed to background radiation every day, anywhere on earth, and proponents of backscatter X-ray scanners say that the devices expose subjects to levels of radiation equivalent to background radiation. Furthermore, when traveling on an airplane, passengers are exposed to much higher levels of radiation than on earth due to altitude. Proponents say that a backscatter X-ray scan is equivalent to the radiation received during two minutes of flying.The UK Health Protection Agency has also issued a statement that the radiation dose from backscatter scanners is very low and \"about the same as one hour of background radiation\".The European Commission issued a report stating that backscatter X-ray scanners pose no known health risk, but suggested that backscatter X-ray scanners, which expose people to ionizing radiation, should not be used when millimeter-wave scanners that \"have less effects on the human body\" are available.Assuming all other conditions equal, there is no reason to adopt X\u2010ray backscatters, which expose the subject to an additional \u2013 although negligible \u2013 source of ionizing radiations. Other WBI (Whole Body Imaging) technologies should be preferred for standard use. However, the European Commission's report provides no data substantiating the claim that \"all other conditions are equal\". One area where backscatter X-ray scanners can provide better performance than millimeter wave scanners, for example, is in the inspection of the shoes, groin and armpit regions of the body. The European Commission also recommended that alternate screening methods should be \"used on pregnant women, babies, children and people with disabilities\".In the United States, Senator Susan Collins, Ranking Member of the Senate Homeland Security Committee sent a letter on August 6, 2010, to the Secretary of Homeland Security and Administrator of the TSA, requesting that the TSA \"have the Department's Chief Medical Officer, working with independent experts, conduct a review of the health effects of their use for travelers, TSA employees, and airport and airline personnel.\" The TSA has completed this review.The U.S. government is also supplying higher-radiation through-body X-ray machines to at least two African countries \"for the purposes of airport security \u2013 the kind that can see through flesh, and which deliver real doses of radiation. The U.S.-supplied scanners have apparently been deployed at one airport in Ghana and four in Nigeria\". This has caused some to question how far the U.S. government intends to go with the technology.Unions for airline pilots working for American Airlines and US Airways have urged pilots to avoid the full body scanners.\n\n\n*** Child scanning ***\nThere is controversy over full-body scanners in some countries because the machines create images of virtual strip searches on persons under the age of 18 which may violate child pornography laws. In the UK, the scanners may be breaking the Protection of Children Act of 1978 by creating images or pseudo-images of nude children.Parents have complained that their young children are being virtually strip searched, sometimes without their parents present.\n\n\n*** Ineffectiveness ***\n\n\n**** Backscatter and millimeter ****\nSome critics suggest that full-body scanner technology is ineffective for multiple reasons, including that they can easily be bypassed and a study published in the November 2010 edition of the Journal of Transportation Security suggested terrorists might fool the Rapiscan machines and others like it employing the X-ray \"backscatter\" technique. A terrorist, the report found, could tape a thin film of explosives of about 15\u201320 centimeters in diameter to the stomach and walk through the machine undetected.Terrorists have already evolved their tactics with the use of surgically implanted bombs or bombs hidden in body cavities.In March 2012, scientist and blogger Jonathan Corbett demonstrated the ineffectiveness of the machines by publishing a viral video showing how he was able to get a metal box through backscatter X-ray and millimeter wave scanners in two US airports. In April 2012, Corbett released a second video interviewing a TSA screener, who described firearms and simulated explosives passing through the scanners during internal testing and training. In another test of the full-body scanners, the machines failed to detect bomb parts hidden around a person's body. And in a different test in 2011, an undercover TSA agent was able to carry a handgun through full body scanners multiple times without the weapon being detected. However, in this case, the TSA agent who was in charge of viewing the scanned images was simply not paying attention.Furthermore, an Israeli airport security expert, Rafi Sela, who helped design security at Ben Gurion International Airport, has said: \"I don't know why everybody is running to buy these expensive and useless machines. I can overcome the body scanners with enough explosives to bring down a Boeing 747... That's why we haven't put them in our airport.\"Again, despite the scanners, the TSA has been unable to stop weapons like box cutters and pistols from being carried onto airplanes.The Australia government has been challenged over the effectiveness and cost of full body scanners by public media to which Australian Transport Minister Anthony Albanese has said he \"makes no apologies\" for mandating the installation of full body scanners at Australian airports.Two alternatives that have been argued for by experts, such as Prof Chris Mayhew from Birmingham University, are chemical-based scanners and bomb-sniffing dogs. Others have argued that passenger profiling, as done by Israeli airport security, should replace full body scanners and patdowns.\n\n\n**** Transmission (penetrating) ****\n\nUnlike the above, transmission technology allows to detect objects swallowed or hidden inside the objects. This is the main reason it is commonly used in prisons and jails. However the current technology does not allow the dual-energy body scanning (and detecting the object by its atomic number like it is used in baggage or vehicle X-ray scanners) which could give the image the same detection effectiveness as regular black and white X-ray. This leads to the idea that human-held detection (finding threats by looking at the image and finding non-common to the human body items) is the most effective way to find a contraband. However counting a human factor (fatigue, decreased attention) threats still could be missed. Modern software based on Artificial Intelligence in full body scanners is designed to minimize human faults and rise the detection effectiveness of this method.\n\n\n*** US public opinion ***\nA Gallup poll given just after the 2009 Christmas Day bombing attempt suggested that 78% of American airline travelers approved of body scanners while 20% disapproved. 51% indicated that they would have some level of discomfort with full-body scans, while 48% said they would not be uncomfortable with the idea. The poll was given in the context of the 2009 Christmas Day bombing attempt, and some opponents of full body scanners say that the explosives used in that bombing attempt would not have been detected by full-body scanners.An ABC/Washington Post poll conducted by Langer Associates and released November 22, 2010, found that 64 percent of Americans favored the full-body X-ray scanners, but that 50 percent think the \"enhanced\" pat-downs go too far; 37 percent felt so strongly. In addition the poll states opposition is lowest amongst those who fly less than once a year.As of November 23, 2010 an online poll of 11,817 people on The Consumerist website, 59.41% said they would not fly as a result of the new scans. Additionally, as of November 23, 2010, a poll of MSNBC 8,500 online readers indicated 84.1% believe the new procedures would not increase travel safety. According to a CBS telephone poll of 1,137 people published in November 2010, 81% (+/- 5%) percent of those polled approved TSA's use of full-body scans.There has been some debate about the safety of the scanners, however, the TSA argue that mmw scanners used emit no ionizing radiation.\n\n\n*** Full-body scanner lobbyists ***\nFormer Homeland Security secretary Michael Chertoff has been criticized for heavily promoting full-body scanners while not always fully disclosing that he is a lobbyist for one of the companies that makes the machines. Other full-body scanner lobbyists with government connections include:\nformer TSA deputy administrator Tom Blank\nformer assistant administrator for policy at the TSA, Chad Wolf\nKevin Patrick Kelly, \"a former top staffer to Sen. Barbara Mikulski, D-Md., who sits on the Homeland Security Appropriations subcommittee\"\nFormer Senator Al D'Amato\n\n\n*** TSA's expansion of scanning program ***\nForbes magazine reported, in March 2011, that:\nNewly uncovered documents show that as early as 2008, the Department of Homeland Security has been planning pilot programs to deploy mobile scanning units that can be set up at public events and in train stations, along with mobile x-ray vans capable of scanning pedestrians on city streets.\nand that the TSA had research proposals to:\n\nbring full-body scanners to train stations, mass transit, and public events. Contracts included in the EPIC release showed plans to develop long-range scans that could assess what a subject carried from 30 feet away, along with studies that involved systems for x-ray scanners mounted in vans and \"covert\" scans of pedestrians.\n\n\n*** \"No nudity\" full-body scanner ***\nMillimeter-wave scanner software transitioned to featureless male or female 'cartoons' in 2011, in response to widescale privacy concerns. Opponents of full body scanners still consider this an unconstitutional strip search, because even though the operator sees only an edited version of the image, a naked image is still captured by the machine, and there is no guarantee the government or a private company will not store it in the case that a terrorist attack were successful.\nCurrently, the millimeter-wave scanner monitor shows a generic cookie-cutter-like outline of a person and highlights potential threats. It is the same image no matter the individual's gender, height, or body type. The scanner software recognizes metallic and non-metallic items hiding under clothing. The machine then processes an image using yellow boxes to point out any areas that may need additional screening.TSA Administrator John Pistole stated that \"Our top priority is the safety of the traveling public, and TSA constantly strives to explore and implement new technologies that enhance security and strengthen privacy protections for the traveling public ... This software upgrade enables us to continue providing a high level of security through advanced imaging technology screening, while improving the passenger experience at checkpoints.\""
    }
  },
  {
    "instruction": "Write an answer to the following question: How prevalent is fleeceware on the Android Play Store, and how does this compare to other types of malware?",
    "context": "",
    "output": "According to a 2020 report, more than 600 million users have installed Android fleeceware apps from the Play Store. This makes it a significant issue for mobile security. However, it's important to note that other types of malware, such as ransomware or spyware, can also pose serious threats to users.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How prevalent is fleeceware on the Android Play Store, and how does this compare to other types of malware?",
      "answer": "According to a 2020 report, more than 600 million users have installed Android fleeceware apps from the Play Store. This makes it a significant issue for mobile security. However, it's important to note that other types of malware, such as ransomware or spyware, can also pose serious threats to users."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the requirement for CAs regarding OCSP checking for all certificates issued after Dec. 31, 2010?",
    "context": "",
    "output": "Section 26-A of the issuing criteria requires CAs to support OCSP checking for all certificates issued after Dec. 31, 2010. This requirement is in place to ensure a timely response to revocation checks by the browser.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the requirement for CAs regarding OCSP checking for all certificates issued after Dec. 31, 2010?",
      "answer": "Section 26-A of the issuing criteria requires CAs to support OCSP checking for all certificates issued after Dec. 31, 2010. This requirement is in place to ensure a timely response to revocation checks by the browser."
    }
  },
  {
    "instruction": "Claw-free permutation\n\n==Introduction==\nIn the mathematical and computer science field of cryptography, a group of three numbers (x,y,z) is said to be a claw of two permutations f0 and f1 if\n\nf0(x) = f1(y) = z.A pair of permutations f0 and f1 are said to be claw-free if there is no efficient algorithm for computing a claw.\nThe terminology claw free was introduced by Goldwasser, Micali, and Rivest in their 1984 paper, \"A Paradoxical Solution to the Signature Problem\" (and later in a more complete journal paper), where they showed that the existence of claw-free pairs of trapdoor permutations implies the existence of digital signature schemes secure against adaptive chosen-message attack. This construction was later superseded by the construction of digital signatures from any one-way trapdoor permutation.  The existence of trapdoor permutations does not by itself imply claw-free permutations exist; however, it has been shown that claw-free permutations do exist if factoring is hard.The general notion of claw-free permutation (not necessarily trapdoor) was further studied by Ivan Damg\u00e5rd in his PhD thesis The Application of Claw Free Functions in Cryptography (Aarhus University, 1988), where he showed how to construct \nCollision Resistant Hash Functions from claw-free permutations.  The notion of claw-freeness is closely related to that of collision resistance in hash functions.  The distinction is that claw-free permutations are pairs of functions in which it is hard to create a collision between them, while a collision-resistant hash function is a single function in which it's hard to find a collision, i.e. a function H is collision resistant if it's hard to find a pair of distinct values x,y such that\n\nH(x) = H(y).In the hash function literature, this is commonly termed a hash collision.  A hash function where collisions are difficult to find is said to have collision resistance.\n\n\n\n== Bit commitment ==\nGiven a pair of claw-free permutations f0 and f1 it is straightforward to create a commitment scheme.  To commit to a bit b the sender chooses a random x, and calculates fb(x).  Since both f0 and f1 share the same domain (and range), the bit b is statistically hidden from the receiver.  To open the commitment, the sender simply sends the randomness x to the receiver.  The sender is bound to his bit because opening a commitment to 1 \u2212 b is exactly equivalent to finding a claw.  Notice that like the construction of Collision Resistant Hash functions, this construction does not require that the claw-free functions have a trapdoor.\nQuestion: What is the significance of claw-free permutations in the context of bit commitment schemes?",
    "context": "",
    "output": "Answer: Claw-free permutations play a crucial role in the construction of bit commitment schemes. By utilizing a pair of claw-free permutations, a sender can create a commitment scheme where the bit is statistically hidden, and the sender is bound to their bit.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the significance of claw-free permutations in the context of bit commitment schemes?",
      "answer": "Claw-free permutations play a crucial role in the construction of bit commitment schemes. By utilizing a pair of claw-free permutations, a sender can create a commitment scheme where the bit is statistically hidden, and the sender is bound to their bit.",
      "context": "Claw-free permutation\n\n==Introduction==\nIn the mathematical and computer science field of cryptography, a group of three numbers (x,y,z) is said to be a claw of two permutations f0 and f1 if\n\nf0(x) = f1(y) = z.A pair of permutations f0 and f1 are said to be claw-free if there is no efficient algorithm for computing a claw.\nThe terminology claw free was introduced by Goldwasser, Micali, and Rivest in their 1984 paper, \"A Paradoxical Solution to the Signature Problem\" (and later in a more complete journal paper), where they showed that the existence of claw-free pairs of trapdoor permutations implies the existence of digital signature schemes secure against adaptive chosen-message attack. This construction was later superseded by the construction of digital signatures from any one-way trapdoor permutation.  The existence of trapdoor permutations does not by itself imply claw-free permutations exist; however, it has been shown that claw-free permutations do exist if factoring is hard.The general notion of claw-free permutation (not necessarily trapdoor) was further studied by Ivan Damg\u00e5rd in his PhD thesis The Application of Claw Free Functions in Cryptography (Aarhus University, 1988), where he showed how to construct \nCollision Resistant Hash Functions from claw-free permutations.  The notion of claw-freeness is closely related to that of collision resistance in hash functions.  The distinction is that claw-free permutations are pairs of functions in which it is hard to create a collision between them, while a collision-resistant hash function is a single function in which it's hard to find a collision, i.e. a function H is collision resistant if it's hard to find a pair of distinct values x,y such that\n\nH(x) = H(y).In the hash function literature, this is commonly termed a hash collision.  A hash function where collisions are difficult to find is said to have collision resistance.\n\n\n\n== Bit commitment ==\nGiven a pair of claw-free permutations f0 and f1 it is straightforward to create a commitment scheme.  To commit to a bit b the sender chooses a random x, and calculates fb(x).  Since both f0 and f1 share the same domain (and range), the bit b is statistically hidden from the receiver.  To open the commitment, the sender simply sends the randomness x to the receiver.  The sender is bound to his bit because opening a commitment to 1 \u2212 b is exactly equivalent to finding a claw.  Notice that like the construction of Collision Resistant Hash functions, this construction does not require that the claw-free functions have a trapdoor."
    }
  },
  {
    "instruction": "WikiLeaks\n\n==Introduction==\nWikiLeaks () is a publisher and media organisation founded in 2006. It operates as a non-profit and is funded by donations and media partnerships. It has published classified documents and other media provided by anonymous sources. It was founded by Julian Assange, an Australian editor, publisher, and activist, who is currently challenging extradition to the United States over his work with WikiLeaks. Since September 2018, Kristinn Hrafnsson has served as its editor-in-chief. Its website states that it has released more than ten million documents and associated analyses. WikiLeaks' most recent publication was in 2021 and its most recent publication of original documents was in 2019. Beginning in November 2022, many of the documents could not be accessed.WikiLeaks has released document caches and media that exposed serious violations of human rights and civil liberties. They released footage, that WikiLeaks entitled Collateral Murder, filmed during the 12 July 2007 Baghdad airstrike in which Iraqi Reuters journalists were among several civilians killed by a U.S. helicopter crew. WikiLeaks has also published leaks such as diplomatic cables from the United States and Saudi Arabia, emails from the governments of Syria and Turkey, corruption in Kenya and at Samherji. WikiLeaks has also published documents exposing surveillance by the Central Intelligence Agency, National Security Agency and private corporations. During the 2016 U.S. presidential election campaign, WikiLeaks released emails from the Democratic National Committee (DNC) and from Hillary Clinton's campaign manager, showing that the party's national committee favoured Clinton in the primaries. These releases resulted in the resignation of Debbie Wasserman Schultz as chairwoman of the DNC and caused significant harm to the Clinton campaign. During the campaign, WikiLeaks promoted false conspiracy theories about Hillary Clinton, the Democratic Party and the murder of Seth Rich.WikiLeaks has won a number of awards and has been commended for exposing state and corporate secrets, increasing transparency, assisting freedom of the press, and enhancing democratic discourse while challenging powerful institutions. WikiLeaks and some of its supporters say the organisation's publications have a perfect attribution record. The organisation has been the target of campaigns to discredit it, including aborted ones by Palantir and HBGary. WikiLeaks has also had its donation systems disrupted by problems with its payment processors. As a result, the Wau Holland Foundation helps process WikiLeaks' donations.\n\nThe organisation has been criticised for inadequately curating its content and violating the personal privacy of individuals. WikiLeaks has, for instance, revealed Social Security numbers, medical information, credit card numbers and details of suicide attempts. Various news organisations, activists, journalists and former members have also criticised the organisation over allegations of anti-semitism, an anti-Clinton and pro-Trump bias, various associations with the Russian government, a history of buying and selling leaks, and a lack of internal transparency. Journalists have also criticised the organisation for promoting false flag conspiracy theories, and its exaggerated and misleading descriptions of the contents of leaks. The CIA defined the organisation as a \"non-state hostile intelligence service\" after the release of Vault 7.\n\n== Administration ==\nWikiLeaks describes itself as \"an uncensorable system for untraceable mass document leaking\" and \"a project of the Sunshine Press,\" a non-profit organisation based in Iceland. In 2010, Julian Assange and Kristinn Hrafnsson registered Sunshine Press Productions ehf as a business without a headquarters in Iceland. Assange serves as the Director of Sunshine Press Productions ehf and is on the board of directors with Hrafnsson and Ingi Ragnar Ingason. Gavin MacFadyen was a deputy board member. According to a January 2010 interview, the WikiLeaks team then consisted of five people working full-time and about 800 people who worked occasionally, none of whom were compensated.In November 2022, many of WikiLeaks releases disappeared from the website, bringing the number of documents from around 10 million to around 3,000. Other reported issues with the site included the websites search ability not working and a broken submission page.\n\n\n*** Editorial policy ***\nWikiLeaks established an editorial policy that accepted only documents that were \"of political, diplomatic, historical or ethical interest\" (and excluded \"material that is already publicly available\"). This coincided with early criticism that having no editorial policy would drive out good material with spam and promote \"automated or indiscriminate publication of confidential records\". The original FAQ is no longer in effect, and no one can post or edit documents on WikiLeaks. Now, submissions to WikiLeaks are reviewed by anonymous WikiLeaks reviewers, and documents that do not meet the editorial criteria are rejected. By 2008, the revised FAQ stated: \"Anybody can post comments to it. [...] Users can publicly discuss documents and analyse their credibility and veracity.\" After the 2010 reorganisation, posting new comments on leaks was no longer possible.According to WikiLeaks, the goal of the organisation is \"to bring important news and information to the public \u2026 One of our most important activities is to publish original source material alongside our news stories so readers and historians alike can see evidence of the truth.\" It also seeks to ensure that journalists and whistleblowers are not prosecuted for emailing sensitive or classified documents. The online \"drop box\" is described by the WikiLeaks website as \"an innovative, secure and anonymous way for sources to leak information to [WikiLeaks] journalists\".An embargo agreement made by WikiLeaks in 2012 included a timeline for when emails could be written about, due in part to \"elections around the world and legal matters WikiLeaks and Julian are involved in.\" In 2017, WikiLeaks told Foreign Policy that they sometimes scheduled releases around high-profile events.In response to a question in 2010 about whether WikiLeaks would release information that he knew might get someone killed, Assange said that he had instituted a \"harm-minimization policy.\" This policy meant that people named in some documents might be contacted before publication to warn them, but that there were also times were members of WikiLeaks might have \"blood on our hands.\" One member of WikiLeaks told The New Yorker they were initially uncomfortable with Assange's editorial policy, but changed her mind because she thought no one had been unjustly harmed.In an August 2010 open letter, the non-governmental organisation Reporters Without Borders praised WikiLeaks' past usefulness in exposing \"serious violations of human rights and civil liberties\" but criticised the organisation over a perceived absence of editorial control, stating \"Journalistic work involves the selection of information. The argument with which you defend yourself, namely that WikiLeaks is not made up of journalists, is not convincing.\"In a 2013 resolution, the International Federation of Journalists, a trade union of journalists, called WikiLeaks a \"new breed of media organisation\" that \"offers important opportunities for media organisations\". Harvard professor Yochai Benkler praised WikiLeaks as a new form of journalistic enterprise, testifying at the court-martial of Chelsea Manning that \"WikiLeaks did serve a particular journalistic function,\" and that the \"range of the journalist's privilege\" is \"a hard line to draw\".Others do not consider WikiLeaks to be journalistic in nature. Media ethicist Kelly McBride of the Poynter Institute for Media Studies wrote in 2011: \"WikiLeaks might grow into a journalist endeavor. But it's not there yet.\" Bill Keller of The New York Times considers WikiLeaks to be a \"complicated source\" rather than a journalistic partner. Prominent First Amendment lawyer Floyd Abrams writes that WikiLeaks is not a journalistic organisation, but instead \"an organization of political activists; \u2026 a source for journalists; and \u2026 a conduit of leaked information to the press and the public\". In support of his opinion, referring to Assange's statements that WikiLeaks reads only a small fraction of information before deciding to publish it, Abrams wrote: \"No journalistic entity I have ever heard of\u2014none\u2014simply releases to the world an elephantine amount of material it has not read.\"\n\n\n*** Financing ***\nWikiLeaks is a self-described not-for-profit organisation, funded largely by volunteers, and is dependent on private donations, exclusivity contracts and concessions from their media partners. Its main financing methods include conventional bank transfers and online payment systems. According to Assange, WikiLeaks' lawyers often work pro bono. Assange has said that in some cases legal aid has been donated by media organisations such as the Associated Press, the Los Angeles Times, and the National Newspaper Publishers Association. Assange said in early 2010 that WikiLeaks' only revenue consists of donations, but it has considered other options including auctioning early access to documents. In September 2010, Assange said that WikiLeaks received millions of dollars in media partnerships, explaining they \"win concessions in relation to the number of journalists that will be put on it and how big they'll run with it.\"In 2010, Assange said the organisation was registered as a library in Australia, a foundation in France, and a newspaper in Sweden, and that it also used two United States-based non-profit 501c3 organisations for funding purposes.\n\n\n**** 2010-2013 ****\nIn January 2010, WikiLeaks temporarily shut down its website while management appealed for donations. Previously published material was no longer available, although some could still be accessed on unofficial mirror websites. WikiLeaks stated that it would resume full operation once the operational costs were paid. WikiLeaks saw this as a kind of work stoppage \"to ensure that everyone who is involved stops normal work and actually spends time raising revenue\". While the organisation initially planned for funds to be secured by 6 January 2010, it was not until 3 February 2010 that WikiLeaks announced that its minimum fundraising goal had been achieved.The Wau Holland Foundation, one of the WikiLeaks' main funding channels, stated that they received more than \u20ac900,000 in public donations between October 2009 and December 2010, of which \u20ac370,000 has been passed on to WikiLeaks. Hendrik Fulda, vice-president of the Wau Holland Foundation, said that every new WikiLeaks publication brought \"a wave of support\", and that donations were strongest in the weeks after WikiLeaks started publishing leaked diplomatic cables. According to Assange, WikiLeaks' media partnerships for the cables earned them almost $2 million three months after they started publishing. WikiLeaks was paid \u00a3150,000 by Al Jazeera and Channel 4 for two five-minute video clips about the Iraq War Logs. In December 2010, the Wau Holland Foundation stated that Julian Assange and three other permanent employees had begun to receive salaries.During 2010, WikiLeaks received over $1.9 million in donations. About $930,000 came through PayPal donations, with the rest coming through bank transfers. In 2011, donations dropped sharply and WikiLeaks received only around $180,000 in donations, while their expenses increased from $519,000 to $850,000. In 2011, Al Jazeera offered WikiLeaks $1.3 million for access to data. During September 2011, WikiLeaks began auctioning items on eBay to raise funds. Wikileaks started accepting bitcoin in 2011 as a currency which could not be blocked by financial intuitions or a government. In 2012, WikiLeaks raised only $68,000 through the Wau Holland Foundation and had expenses more than $507,000. In 2013, WikiLeaks and Wau Holland Foundation agreed on a new framework contract which Wau Holland Foundation would only cover direct costs such as server, ISP, project coordination and translation costs. Between January and May, Wau Holland Foundation was only able to cover $47,000 in essential infrastructure for WikiLeaks, but not an additional $400,000 that was submitted \"to cover publishing campaigns and logistics in 2012\".\n\n\n***** Financial blockade*****\n\nOn 22 January 2010, the Internet payment intermediary PayPal suspended WikiLeaks' donation account and froze its assets. WikiLeaks said that this had happened before, and was done for \"no obvious reason\". In August 2010, the internet payment company Moneybookers closed WikiLeaks' account and sent Assange a letter saying \"Following an audit of your account by our security department, we must advise that your account has been closed \u2026 to comply with money laundering or other investigations conducted by government authorities.\" After Assange asked what the problem was, Moneybookers sent another email saying that initially the \"account was suspended due to being accessed from a blacklisted IP address. However, following recent publicity and the subsequently addition of the WikiLeaks entity to blacklists in Australia and watchlists in the USA, we have terminated the business relationship.\" According to The Guardian, the apparent blacklisting came a few days after the Pentagon expressed anger at WikiLeaks for publishing the Afghan War logs.In December 2010, PayPal suspended WikiLeaks' account, thereby stopping donations through PayPal. PayPal said it had taken action after the US State Department sent a letter to Wikileaks stating that Wikileaks' activities were illegal in the US. Hendrik Fulda, vice-president of the Wau Holland Foundation, said that the Foundation had been receiving twice as many donations through PayPal as through normal banks before PayPal's decision to suspend WikiLeaks' account. Mastercard and Visa Europe also decided to stop accepting payments to WikiLeaks. Bank of America, Amazon and Swiss bank PostFinance had previously stopped dealing with WikiLeaks. Datacell, the IT company that enabled WikiLeaks to accept credit and debit card donations, threatened Mastercard and Visa with legal action to enforce the resumption of payments to WikiLeaks. Datacell said Visa's action was the result of political pressure.In October 2011, Assange said that the financial blockade by Bank of America, Visa, MasterCard, PayPal and Western Union, had cost WikiLeaks ninety-five per cent of its revenue. In 2012, an Icelandic district court ruled that Valitor, the Icelandic partner of Visa and MasterCard, was violating the law when it stopped accepting credit card donations to WikiLeaks. The court ruled that donations to WikiLeaks must resume within 14 days or Valitor would be fined US$6,000 a day. In November 2012, the European Union's European Commission said they wouldn't open a formal investigation into Mastercard and Visa and blocking donations for WikiLeaks because it was unlikely to have violated EU anti-trust rules.In response to the financial blockade of Wikileaks, Glenn Greenwald and others created the Freedom of the Press Foundation in order \"to block the US government from ever again being able to attack and suffocate an independent journalistic enterprise the way it did with WikiLeaks\".\n\n\n**** 2014-2018 ****\nIn 2014, Sunshine Press Productions ehf began receiving funds from Wau Holland Foundation for WikiLeaks. From 2014-2017 WikiLeaks was reimbursed for project coordination, technical preparation, removing metadata, reviewing information, communicating with media partners costs and a new submission platform and document search. The DNC emails and Podesta emails were not funded by the Wau Holland Foundation. By October 2017, WikiLeaks founder Julian Assange said the organisation had made a 50,000% return on Bitcoin. By that December, they had raised at least $25 million in Bitcoin.In 2018, the Wau Holland Foundation reimbursed Sunshine Press Productions for WikiLeaks' publications, as well as public relations and $50,000 for legal expenses in the Democratic National Committee v. Russian Federation lawsuit.\n\n\n*** Hosting ***\nIn 2010, the website was available on multiple servers, different domain names and had an official dark web version (available on the Tor Network) as a result of a number of denial-of-service attacks and its elimination from different Domain Name System (DNS) providers.Until August 2010, WikiLeaks was hosted by PRQ, a company based in Sweden providing \"highly secure, no-questions-asked hosting services\". PRQ was reported by The Register website to have \"almost no information about its clientele and maintains few if any of its own logs\". That month, WikiLeaks reached an agreement with the Swedish Pirate Party to host several of their servers. Later, WikiLeaks was hosted mainly by the Swedish Internet service provider Bahnhof in the Pionen facility, a former nuclear bunker in Sweden. Other servers were spread around the world with the main server located in Sweden.After the site became the target of a denial-of-service attack on its old servers, WikiLeaks moved its website to Amazon's servers. Amazon later removed the website from its servers. In a public statement, Amazon said that WikiLeaks was not following its terms of service. The company stated: \"There were several parts they were violating. For example, our terms of service state that 'you represent and warrant that you own or otherwise control all of the rights to the content ... that use of the content you supply does not violate this policy and will not cause injury to any person or entity.' It's clear that WikiLeaks doesn't own or otherwise control all the rights to this classified content.\" WikiLeaks was then moved to servers at OVH, a private web-hosting service in France. After criticism from the French government, a judge in Paris ruled that there was no need for OVH to cease hosting WikiLeaks without more information.WikiLeaks used EveryDNS, but was dropped by the company after distributed denial-of-service (DDoS) attacks against WikiLeaks hurt the quality of service for its other customers. Supporters of WikiLeaks waged verbal and DDoS attacks on EveryDNS. Because of a typographical error in blogs mistaking EveryDNS for competitor EasyDNS, the sizeable Internet backlash hit EasyDNS. Despite that, EasyDNS began providing WikiLeaks with DNS service on \"two 'battle hardened' servers\" to protect the quality of service for its other customers.\n\n\n*** Insurance files ***\nWikiLeaks has used heavily encrypted files to protect their publications against censorship, to pre-release publications, and as protection against arrest. The files have been described as \"insurance\", a \"dead man's switch\", \"a kind of doomsday option\", and a \"poison pill\". The insurance files sometimes come with pre-commitment hashes.WikiLeaks staff have said that \"insurance files are encrypted copies of unpublished documents submitted to us. We do this periodically, and especially at moments of high pressure on us, to ensure the documents can not be lost and history preserved. You will not be able to see the contents of any of our insurance files, until and unless the we are in a position where we must release the key. But you can download them and help spread them to ensure their safe keeping.\"On 29 July 2010 WikiLeaks added an \"Insurance file\" to the Afghan War Diary page. The file is AES encrypted. There has been speculation that it was intended to serve as insurance in case the WikiLeaks website or its spokesman Julian Assange are incapacitated, upon which the passphrase could be published. After the first few days' release of the US diplomatic cables starting 28 November 2010, the US television broadcasting company CBS predicted that \"If anything happens to Assange or the website, a key will go out to unlock the files. There would then be no way to stop the information from spreading like wildfire because so many people already have copies.\" CBS correspondent Declan McCullagh stated, \"What most folks are speculating is that the insurance file contains unreleased information that would be especially embarrassing to the US government if it were released.\"In August 2013, WikiLeaks posted three insurance files as torrents, totalling 400 gigabytes. WikiLeaks said they \"encrypted versions of upcoming publication data (\"insurance\") from time to time to nullify attempts at prior restraint.\"In June 2016, WikiLeaks posted an 88 gigabyte insurance file. On 16 October 2016, WikiLeaks tweeted an insurance file about Ecuador. In November, they posted insurance files for the US, the UK and Ecuador, and an unlabelled 90 gigabyte insurance file was posted.In January 2017, On 7 March 2017, WikiLeaks posted an encrypted file containing the Vault 7 Year Zero release. WikiLeaks had planned to release them later, but released them online later that day because of cyber attacks. The password, SplinterItIntoAThousandPiecesAndScatterItIntoTheWinds, was a reference to an alleged quote by President Kennedy.\n\n\n*** Staff ***\nIn June 2009, the website said it had more than 1,200 registered volunteers. According to Daniel Domscheit-Berg, WikiLeaks exaggerated the number of volunteers and Assange used many pseudonyms. Domscheit-Berg suggested that one may have been \"Jay Lim\", who identified online as an occasional WikiLeaks spokesperson and as its legal advisor.Daniel Domscheit-Berg, Sarah Harrison,  Kristinn Hrafnsson and Joseph Farrell are notable people who have been involved in the project. Harrison is also a member of Sunshine Press Productions along with Assange and Ingi Ragnar Ingason. Gavin MacFadyen was acknowledged by Assange as a \u2033beloved director of WikiLeaks\u2033 shortly after his death in 2016. Jacob Appelbaum is the only known American who is known to have been member of WikiLeaks, acting as a senior editor and spokesman. Gottfrid Svartholm had worked with WikiLeaks as a technical consultant and managed infrastructure critical to the organization. He was also listed as part of the \"decryption and transmission team\" on Collateral Murder and credited for \"networking\" and helped with several other unknown endeavors. Rop Gonggrijp, Birgitta J\u00f3nsd\u00f3ttir, Sm\u00e1ri McCarthy and Herbert Snorrason are WikiLeaks volunteers and members who the US government has tried to surveill with court orders. WikiLeaks was represented in Russia by Israel Shamir and in Sweden by his son Johannes Wahlstr\u00f6m.According to colleagues and former WikiLeaks insiders, the WikiLeaks dropbox architecture was rebuilt by a WikiLeaks programmer known to most insiders as \"The Architect\". He also instructed another WikiLeaks technician, and some of colleagues thought he was a computer genius. According to Andy Greenberg, insiders told him \"when The Architect joined WikiLeaks it was a mess. It was two creaking servers without all the flashy security that Assange had promised in interviews with the media. The Architect rebuilt it from scratch.\" According to Wired, \"WikiLeaks had been running on a single server with sensitive backend components like the submission and e-mail archives connected to the public-facing Wiki page. The Architect separated the platforms and set up a number of servers in various countries.\"In August 2011, WikiLeaks volunteer Sigurdur Thordarson, working in his home country Iceland, contacted the FBI and, after presenting a copy of Assange's passport at the American embassy, became the first informant to work for the FBI from inside WikiLeaks, and gave the FBI several hard drives he had copied from Assange and core WikiLeaks members. In November 2011, WikiLeaks dismissed Thordarson due to his embezzlement of $50,000, to which charge (along with several other offences) he later pleaded guilty in an Icelandic court. According to Thordarson, a few months after his dismissal by WikiLeaks the FBI agreed to pay him $5,000 as compensation for work missed while meeting with agents.Alexa O'Brien briefly worked for WikiLeaks in 2014, later saying she found working for the organization was not a good fit. On 26 September 2018, it was announced that Julian Assange had appointed Kristinn Hrafnsson as editor-in-chief of WikiLeaks with Assange continuing as its publisher.\n\n\n*** Submissions ***\nWikiLeaks restructured its process for contributions after its first document leaks did not gain much attention. Assange stated this was part of an attempt to take the voluntary effort typically seen in Wiki projects and \"redirect it to ... material that has real potential for change\". Before this, the Wikileaks FAQ, under \"How will Wikileaks operate?\", read as of February 2007:\nTo the user, Wikileaks will look very much like Wikipedia. Anybody can post to it, anybody can edit it. No technical knowledge is required. Leakers can post documents anonymously and untraceably. Users can publicly discuss documents and analyze their credibility and veracity. Users can discuss interpretations and context and collaboratively formulate collective publications. Users can read and write explanatory articles on leaks along with background material and context. The political relevance of documents and their verisimilitude will be revealed by a cast of thousands.\nWikiLeaks originally used a \"wiki\" communal publication method, which ended by May 2010.In 2010 Assange said WikiLeaks received some submissions through the postal mail. That year, Julian Assange said that the servers were located in Sweden and the other countries \"specifically because those nations offer legal protection to the disclosures made on the site\". He talks about the Swedish constitution, which he said gives the information\u2013providers total legal protection. According to Assange, under Swedish law, it is forbidden for any administrative authority to make inquiries about the sources of any type of newspaper. These laws were meant to make it difficult for any authority to target WikiLeaks by placing a burden of proof upon any complainant. Furthermore, \"WikiLeaks maintains its own servers at undisclosed locations, keeps no logs and uses military-grade encryption.\" Such arrangements have been called \"bulletproof hosting\". However according to the Columbia Journalism Review, \"a ariety of Swedish media law experts made it clear that Assange and WikiLeaks had repeatedly misrepresented not only the strength of the law, but its application to WikiLeaks. \"According to some, The Architect was the engineer who rebuilt the WikiLeaks submission system \"from scratch\" and instructed another WikiLeaks technician. According to Andy Greenberg and Wired, when The Architect joined WikiLeaks, it \"was a mess\" running on one or two servers \"without all the flashy security that Assange had promised in interviews with the media.\" The Architect rebuilt it from scratch and separated the sensitive platforms from the public-facing Wiki \"and set up a number of servers in various countries.\"During the 2010 reorganisation, The Architect left with Domscheit-Berg, taking the code behind the submission system with him. Assange said that the submission system was temporarily down because its backlog was too big. WikiLeaks later said it was down because of Domscheit-Berg's \"acts of sabotage\" when he left the organisation, which had forced WikiLeaks to \"overhaul the entire submission system\", and the staff lacked time to do so.WikiLeaks submissions stayed offline for four and a half years, until May 2015. While it was offline, WikiLeaks announced they were building a state-of-the-art secure submission system. The launch of the new system was delayed by security concerns in 2011. During this time, WikiLeaks continued to publish documents. These publications originated from material which had been directly shared with WikiLeaks by hackers, or were the result of Wikileaks organising and republishing already-public leaks. A former WikiLeaks associate said that Andy M\u00fcller-Maguhn and a colleague administered the submission server in 2016, though M\u00fcller-Maguhn denies this. That October, WikiLeaks suggested \"lawyer to lawyer\" as an alternate submission method, naming Margaret Ratner Kunstler.By October 2021, WikiLeaks' secure chat stopped working and by February 2022, WikiLeaks' submission system and email server were offline. In July 2022, a broken version of the submission system briefly relaunched with expired PGP keys and went offline after it was reported on by The Daily Dot.\n\n== Legal issues ==\nThere have been many legal issues in different countries and several investigations surrounding WikiLeaks since it was founded.\nIn August 2010, the internet payment company Moneybookers closed WikiLeaks' account due to publicity over its release of the Afghan war logs and because WikiLeaks had been added to the official US watchlist and an Australian government blacklist.\n\n\n*** Legal issues in Australia ***\nIn December 2010, the Australian Prime Minister Julia Gillard said that \"I absolutely condemn the placement of this information on the WikiLeaks website - it's a grossly irresponsible thing to do and an illegal thing to do\". After criticism and a revolt within her party, she said she was referring to \"the original theft of the material by a junior U.S. serviceman rather than any action by Mr Assange\".The Australian Federal Police later said that the release of the cables by WikiLeaks breached no Australian laws.On 2 September 2011, Australia's attorney general, Robert McClelland released a statement that the US diplomatic cables published by Wikileaks identified at least one ASIO officer, and that it was a crime in Australia to publish information which could identify an intelligence officer. McClelland said that \"On occasions before this week, WikiLeaks redacted identifying features where the safety of individuals or national security could be put at risk. It appears this hasn't occurred with documents that have been distributed across the internet this week.\" According to The Guardian and Al Jazeera, this meant \"Julian Assange could face prosecution in Australia.\"In 2014, WikiLeaks published information about political bribery allegations, violating a gag order in Australia. According to Peter Bartlett, a media lawyer in Australia, WikiLeaks was outside Australia's jurisdiction but \"if Assange ever comes back to Australia, you would expect that he would immediately be charged with breaking a suppression order.\"\n\n\n*** Legal issues in United States ***\n\nIn early February 2008, the Julius Baer Group sued WikiLeaks in California to have documents removed from their website. Judge Jeffrey White forced Dynadot, the domain registrar of wikileaks.org, to disassociate the site's domain name records with its servers, preventing use of the domain name to reach the site. Initially, the bank only wanted the documents to be removed (WikiLeaks had failed to name a contact person). After civil rights challenges, the judge lifted the injunction and the bank dropped the case on 5 March 2008.On 20 April 2018, the Democratic National Committee filed a multimillion-dollar lawsuit in federal district court in Manhattan against Russia, the Trump campaign, WikiLeaks and Julian Assange, alleging a conspiracy to disrupt the 2016 United States presidential election in Trump's favour. The suit was dismissed with prejudice on 30 July 2019. In his judgement, Judge John Koeltl said that WikiLeaks \"did not participate in any wrongdoing in obtaining the materials in the first place\" and therefore was within the law in publishing the information. The federal judge also wrote \"The DNC's interest in keeping 'donor lists' and 'fundraising strategies' secret is dwarfed by the newsworthiness of the documents as a whole...If WikiLeaks could be held liable for publishing documents concerning the DNC's political financial and voter-engagement strategies simply because the DNC labels them 'secret' and trade secrets, then so could any newspaper or other media outlet\".\n\n\n**** United States criminal investigations ****\nThe US Justice Department began a criminal investigation of WikiLeaks and Julian Assange soon after the leak of diplomatic cables in 2010 began. The Washington Post reported that the department was considering charges under the Espionage Act of 1917, an action which former prosecutors characterised as \"difficult\" because of First Amendment protections for the press. Several Supreme Court cases, while not conclusive, (e.g. Bartnicki v. Vopper) have established previously that the American Constitution protects the re-publication of illegally gained information provided the publishers did not themselves violate any laws in acquiring it. The question of criminal punishment or a civil injunction after publication, like in the WikiLeaks case, is less established.In 2010, the NSA added Assange to its Manhunting Timeline. In August 2010, the Pentagon had concluded that the Afghan War documents leak broke the law. A letter from the Department of Defence general counsel said that \"it is the view of the Department of Defence that WikiLeaks obtained this material in circumstances that constitute a violation of US law, and that as long as WikiLeaks holds this material, the violation of the law is ongoing.\" In November 2010, Harold Koh, the Legal Adviser of the Department of State, wrote that the United States diplomatic cables leak \"were provided in violation of US law and without regard for the grave consequences of this action\" and \"as long as WikiLeaks holds such material, the violation of the law is ongoing\".In 2011, a WikiLeaks volunteer became an FBI informant and Google was served with search warrants for the contents of two WikiLeaks volunteers' email accounts. The NSA discussed categorising WikiLeaks as a \"malicious foreign actor\" for surveillance purposes.On 14 December 2010 the United States Department of Justice issued a subpoena directing Twitter to provide information for accounts registered to or associated with WikiLeaks. Twitter decided to notify its users.By 2013,  J\u00e9r\u00e9mie Zimmermann, Sm\u00e1ri McCarthy, Jacob Appelbaum, David House and Jennifer Robinson had been detained and interrogated or approached when attempts were made to recruit them as informants, often using heavy handed tactics.In 2013, it was revealed that Google had been served with search warrants for the contents of email accounts belonging to WikiLeaks volunteers Herbert Snorrason and Smari McCarthy. In 2015, it was revealed that Google had been served with search warrants for the contents of email accounts belonging to WikiLeaks staff members Sarah Harrison, Joseph Farrell, and Kristinn Hrafnsson as part of a criminal investigation with alleged offences including espionage, conspiracy to commit espionage, the theft or conversion of property belonging to the United States government, violation of the Computer Fraud and Abuse Act, and criminal conspiracy. According to Daniel Domscheit-Berg in 2010, the WikiLeaks email accounts for Kristinn Hrafnsson and a young WikiLeaks staffer had automatically forwarded to their Google account, opening the organisation to surveillance risks.In April 2017, prosecutors began drafting a memo that considered charging members of WikiLeaks with conspiracy, theft of government property or violating the Espionage Act. That month, CIA director Mike Pompeo called WikiLeaks \"a non-state hostile intelligence service often abetted by state actors like Russia\". The official designation of Wikileaks and Julian Assange as a non-state hostile intelligence service was discussed in mid-2017 during preparation of the Intelligence Authorization Act for Fiscal Year 2018. It was eventually incorporated into the National Defense Authorization Act for Fiscal Year 2020 that became law in December 2019. The Act says \"It is the sense of Congress that WikiLeaks and the senior leadership of WikiLeaks resemble a non-state hostile intelligence service often abetted by state actors and should be treated as such a service by the United States.\" In the opinion of some former officials, the designation allowed the CIA to launch and plan operations that did not require presidential approval or congressional notice.In September 2021, Yahoo! News reported that in 2017 in the wake of the Vault 7 leaks, the CIA discussed plans to kidnap or assassinate Julian Assange. They also planned to spy on associates of WikiLeaks, sow discord among its members, and steal their electronic devices. \"[T]op intelligence officials lobbied the White House\" to designate Wikileaks as an \"information broker\" to allow for more investigative tools against it, \"potentially paving the way\" for its prosecution. Laura Poitras described attempts to classify herself and Assange as \"information brokers\" rather than journalists as \"bone-chilling and a threat to journalists worldwide\". Former CIA Director Mike Pompeo stated that the US officials who had spoken to Yahoo should be prosecuted for exposing CIA activities.In November 2018, an accidental filing with Assange's name was seen to indicate there were undisclosed charges against him. On 11 April 2019, Assange was charged in a computer hacking conspiracy. On 23 May, a superseding indictment was filed with charges of Conspiracy to Receive National Defense Information, Obtaining National Defense Information, Disclosure of National Defense Information, and Conspiracy to Commit Computer Intrusion. On 24 June 2020, another superseding indictment was filed which added to the allegations but not the charges.After the indictment against Assange was unsealed, the Department of Justice continued to investigate Wikileaks. The day after charging Assange, prosecutors contacted Domscheit-Berg. Prosecutors also spoke with David House for about 90 minutes, who had previously testified to the grand jury in exchange for immunity. House testified about helping run political operations for WikiLeaks and that Assange wanted him \"to help achieve favorable press for Chelsea Manning.\" According to House, the grand jury \"wanted full insight into WikiLeaks, what its goals were and why I was associated with it.  .\u2009.\u2009. It was all related to disclosures around the war logs.\" House said he had contact with Assange until 2013 and with WikiLeaks until 2015. Chelsea Manning and Jeremy Hammond refused to testify for the grand jury.In early 2019, the Mueller report wrote the Special Counsel's office considered charging WikiLeaks or Assange \"as conspirators in the computer-intrusion conspiracy and that there were \"factual uncertainties\" about the role that Assange may have played in the hacks or their distribution that were \"the subject of ongoing investigations\" by the US Attorney\u2019s Office.\n\n\n*** Use of leaked documents in court ***\nIn April 2011, the US Department of Justice warned military lawyers acting for Guantanamo Bay detainees against clicking of links on sites such as The New York Times that might lead to classified files published by WikiLeaks. In June 2011, the US Department of Justice ruled that attorneys acting for Guantanamo Bay detainees could cite documents published by WikiLeaks. The use of the documents was subject to restrictions.On 8 February 2018, the UK Supreme Court unanimously allowed a document that had been leaked through WikiLeaks to be admitted as evidence. The cable had been excluded from use in an earlier part of the case before the Administrative Court based on the fact that it was a diplomatic communication, which enjoy \"inviolable\" protections that prevent them from being used in court outside of exceptional circumstances. The Supreme Court ruled that since the document had already been widely disseminated, it had lost any protections it might have had. The hearing was considered an important test of the Vienna Convention in relation to WikiLeaks documents.\n\n== Publications ==\nThe initial tranche of WikiLeaks' documents came from a WikiLeaks' activist who owned a server that was a node in the Tor network. After they noticed that Chinese hackers used the network to gather information from foreign governments, the activist began recording the information. This let Assange show potential contributors that WikiLeaks was viable and say they had \"received over one million documents from thirteen countries\".\n\n\n*** 2006\u20132008 ***\nWikiLeaks posted its first document in December 2006, a decision to assassinate Somali government officials signed by rebel leader Sheikh Hassan Dahir Aweys. Assange and WikiLeaks were uncertain of its authenticity, and the document\u2019s authenticity was never determined.\nIn August 2007, the UK newspaper The Guardian published a story about corruption by the family of the former Kenyan leader Daniel arap Moi based on information provided via WikiLeaks.\nIn November 2007, a March 2003 copy of Standard Operating Procedures for Camp Delta detailing the protocol of the US Army at the Guantanamo Bay detention camp was released. The document revealed that some prisoners were off-limits to the International Committee of the Red Cross, something that the US military had in the past denied repeatedly. The Guant\u00e1namo Bay Manual included procedures for transferring prisoners and methods of evading protocols of the Geneva convention.\nIn February 2008, WikiLeaks released allegations of illegal activities at the Cayman Islands branch of the Swiss Bank Julius Baer, which resulted in the bank suing WikiLeaks and obtaining an injunction which temporarily suspended the operation of wikileaks.org. The California judge had Dynadot, the service provider of WikiLeaks block the site's domain (wikileaks.org) on 18 February 2008. The website was instantly mirrored, and later that month the judge overturned his previous decision citing First Amendment concerns and questions about legal jurisdiction.\nIn March 2008, WikiLeaks published what they referred to as \"the collected secret 'bibles' of Scientology\", and three days later received letters threatening to sue them for breach of copyright.\nIn September 2008, during the 2008 United States presidential election campaigns, the contents of a Yahoo account belonging to Sarah Palin (the running mate of Republican presidential nominee John McCain) were posted on WikiLeaks after being hacked by 4chan user David Kernell.\nIn November 2008, the membership list of the far-right British National Party was posted to WikiLeaks, after appearing briefly on a weblog. A year later, in October 2009, another list of BNP members was leaked, said by the BNP\u2019s leader, Nick Griffin, to be a \u2018malicious forgery\u2019.\n\n\n*** 2009 ***\nDuring 2008 and 2009, WikiLeaks published lists of forbidden or illegal web addresses for Australia, Denmark and Thailand. These were originally created to prevent access to child pornography and terrorism, but the leaks revealed that other sites featuring unrelated subjects were also listed.\nIn January 2009, WikiLeaks released 86 telephone intercept recordings of Peruvian politicians and businessmen involved in the 2008 Peru oil scandal.\nIn February, WikiLeaks cracked the encryption to and published NATO's Master Narrative for Afghanistan and three other classified or restricted NATO documents on the Pentagon Central Command (CENTCOM) site.\nDuring February, WikiLeaks released 6,780 Congressional Research Service reports followed in March by a set of documents belonging to Barclays Bank that had been ordered removed from the website of The Guardian.\nIn July, WikiLeaks released a report disclosing a \"serious nuclear accident\" at the Iranian Natanz nuclear facility. According to media reports, the accident may have been the direct result of a cyber-attack at Iran's nuclear program, carried out with the Stuxnet computer worm, a cyber-weapon allegedly built jointly by the United States and Israel.\nIn September, internal documents from Kaupthing Bank were leaked, from shortly before the collapse of Iceland's banking sector, which had caused the 2008\u20132012 Icelandic financial crisis. The document showed that suspiciously large sums of money were loaned to various owners of the bank, and large debts written off.\nIn October, Joint Services Protocol 440, a British document advising the security services on how to avoid documents being leaked, was published by WikiLeaks. Later that month, it announced that a super-injunction was being used by the commodities company Trafigura to stop The Guardian (London) from reporting on a leaked internal document regarding a toxic dumping incident in C\u00f4te d'Ivoire.\nIn November, released 570,000 intercepts of pager messages sent on the day of the 11 September attacks. These included messages sent from the Pentagon, the FBI, the Federal Emergency Management Agency and the NYPD, in response to the disaster.\n\n\n*** 2010 ***\n\nIn mid-February 2010, WikiLeaks received a leaked diplomatic cable from the United States Embassy in Reykjavik relating to the Icesave scandal, which they published on 18 February. The cable, known as Reykjavik 13, was the first of the classified documents WikiLeaks published among those allegedly provided to them by United States Army Private Chelsea Manning. In March 2010, WikiLeaks released a secret 32-page US Department of Defense Counterintelligence Analysis Report written in March 2008 discussing the leaking of material by WikiLeaks and how it could be deterred.In April, a classified video of the 12 July 2007 Baghdad airstrike was released, showing two Reuters employees being fired at, after the pilots mistakenly thought the men were carrying weapons, which were in fact cameras. After the men were killed, the video shows US forces firing on a family van that stopped to pick up the bodies. Press reports of the number killed in the attacks vary from 12 to \"over 18\". Among the dead were two journalists and two children were also wounded.In June 2010, Manning was arrested after alleged chat logs were given to United States authorities by former hacker Adrian Lamo, in whom she had confided. Manning reportedly told Lamo she had leaked the \"Collateral Murder\" video, in addition to a video of the Granai airstrike and about 260,000 diplomatic cables, to WikiLeaks. Manning later said that before WikiLeaks, she tried approaching The Washington Post, The New York Times and Politico.In July, WikiLeaks released 92,000 documents related to the war in Afghanistan between 2004 and the end of 2009 to the publications The Guardian, The New York Times and Der Spiegel. The documents detail individual incidents including \"friendly fire\" and civilian casualties. WikiLeaks asked the Pentagon and human-rights groups to help remove names from the documents to reduce the potential harm caused by their release, but did not receive assistance.After the Love Parade stampede in Duisburg, Germany, on 24 July 2010, a local resident published internal documents of the city administration regarding the planning of Love Parade. The city government reacted by securing a court order on 16 August forcing the removal of the documents from the website on which it was hosted. On 20 August 2010, WikiLeaks released a publication entitled Loveparade 2010 Duisburg planning documents, 2007\u20132010, which consisted of 43 internal documents regarding the Love Parade 2010.After the leak of information concerning the Afghan War, in October 2010, around 400,000 documents relating to the Iraq War were released. The BBC quoted the US Department of Defense referring to the Iraq War Logs as \"the largest leak of classified documents in its history\". Media coverage of the leaked documents emphasised claims that the US government had ignored reports of torture by the Iraqi authorities during the period after the 2003 war.\n\n\n*** Diplomatic cables release ***\n\nOn 28 November 2010, WikiLeaks and El Pa\u00eds, Le Monde, Der Spiegel, The Guardian, and The New York Times started simultaneously to publish the first 220 of 251,287 leaked documents labelled confidential \u2013 but not top-secret \u2013 and dated from 28 December 1966 to 28 February 2010.\n\nThe contents of the diplomatic cables include numerous unguarded comments and revelations regarding: US diplomats gathering personal information about Ban Ki-moon, Secretary-General of the United Nations, and other top UN officials; critiques and praises about the host countries of various United States embassies; political manoeuvring regarding climate change; discussion and resolutions towards ending ongoing tension in the Middle East; efforts and resistance towards nuclear disarmament; actions in the War on Terror; assessments of other threats around the world; dealings between various countries; United States intelligence and counterintelligence efforts; and other diplomatic actions. Reactions to the United States diplomatic cables leak varied. The overthrow of the presidency in Tunisia of 2011 has been attributed partly to reaction against the corruption revealed by leaked cables.According to the former US Ambassador to Cameroon from 2004 to 2007, Niels Marquardt, Marafa Hamidou Yaya was arrested on \"entirely unproven corruption charges\", subjected to a \"kangaroo court\", and given a 25-year prison sentence. Marquardt said Marafa's only real crime was having told him that he \"might be interested\" in the presidency one day. According to Marquardt, when Wikileaks released the cable in which this was mentioned, it became front-page news in Cameroon and led directly to Marafa's arrest. The U.S. ambassador at the time, Robert Jackson, said Marafa's trial did not specify the evidence against him.\n\n\n**** Unredacted cable release ****\n\n\n***** Background*****\nIn August 2010, Assange gave Guardian journalist David Leigh an encryption key and a URL where he could locate the file containing the U.S. diplomatic cables. In February 2011 David Leigh and Luke Harding of The Guardian published the book WikiLeaks: Inside Julian Assange's War on Secrecy containing the encryption key. Leigh said he believed the key was a temporary one that would expire within days. Wikileaks supporters disseminated the encrypted files to mirror sites in December 2010 after Wikileaks experienced cyber-attacks. When Wikileaks learned what had happened it notified the US State Department. On 25 August 2011, the German magazine Der Freitag published an article giving details which would enable people to piece the information together.\n\n\n***** Release*****\nIn January 2011, several unredacted cables were posted online by an associate of WikiLeaks, Israel Shamir. The cables incldued the names of people implied to be connected to bribery, and highly suggestive clues about the identity of an American informant.On 29 August, WikiLeaks published over 130,000 unredacted cables. On 31 August, WikiLeaks tweeted a link to a torrent of the encrypted data. On 1 September 2011, WikiLeaks announced that an encrypted version of the un-redacted US State Department cables had been available via BitTorrent for months and that the decryption key was available. WikiLeaks said that on 2 September it would publish the entire, unredacted archive in searchable form on its website. According to Assange, Wikileaks did this so that possible targets could be informed and better defend themselves, and also to provide a reliable source for the leaks.Glenn Greenwald wrote that \"WikiLeaks decided -- quite reasonably -- that the best and safest course was to release all the cables in full, so that not only the world's intelligence agencies but everyone had them, so that steps could be taken to protect the sources and so that the information in them was equally available\". The US cited the release in the opening of its request for extradition of Assange, saying his actions put lives at risk. The defence gave evidence it said would show that Assange was careful to protect lives. John Young, the owner and operator  of the website Cryptome testified at Assange's extradition hearing that the unredacted cables were published by Cryptome on 1 September, the day before Wikileaks, and they remain on the Cryptome site. Young testified that \"no US law enforcement authority has notified me that this publication of the cables is illegal, consists or contributes to a crime in any way, nor have they asked for them to be removed\".The Guardian wrote that the decision to publish the cables in a searchable form was made by Assange alone, a decision that it, and its four previous media partners, condemned. According to The Guardian, several thousand files in the archive were marked \"strictly protect\" which indicated officials thought sources could be endangered by their release. In a joint statement, The Guardian, El Pais, New York Times and Der Spiegel said they \"deplore the decision of WikiLeaks to publish the unredacted state department cables, which may put sources at risk\" and \"we cannot defend the needless publication of the complete data - indeed, we are united in condemning it.\" Le Monde told the Associated Press it would also sign the statement. In response, WikiLeaks accused The Guardian of false statements and nepotism. Out of concern for those involved, Reporters Without Borders temporarily suspended their WikiLeaks mirror.According to media reports, after WikiLeaks published the unredacted cables , Ethiopian journalist Argaw Ashine was interrogated several times about a reference to him in a cable talking to a government source. The source told him about plans to arrest the editors of the critical Ethiopian weekly Addis Neger, who fled the country a month after talking to Ashine. Ashine was subjected to government harassment and intimidation, and was forced to flee the country.The U.S. established an Information Review Task Force (IRTF) to investigate the impact of WikiLeaks' publications. In 2013, the task force's head, Brigadier General Robert Carr, testified at Chelsea Manning's sentencing hearing. Carr admitted under questioning from the defence counsel that, despite the resources at its disposal, the task force had found no specific examples of anyone who had lost their life due to WikiLeaks' publication of material provided by Manning. Ed Pilkington wrote in The Guardian that Carr's testimony significantly undermined the argument that WikiLeaks' publications put lives at risk.\n\n\n*** 2011\u20132015 ***\n\nIn late April 2011, files related to the Guantanamo prison were released. In December 2011, WikiLeaks started to release the Spy Files. On 27 February 2012, WikiLeaks began publishing more than five million emails from the Texas-headquartered \"global intelligence\" company Stratfor. On 5 July 2012, WikiLeaks began publishing the Syria Files (emails from Syrian political figures 2006\u20132012). On 25 October 2012, WikiLeaks began publishing The Detainee Policies, files covering the rules and procedures for detainees in US military custody. In April 2013 WikiLeaks published more than 1.7 million US diplomatic and intelligence documents from the 1970s, including the Kissinger cables.\nIn September 2013, WikiLeaks published \"Spy Files 3\", 250 documents from more than 90 surveillance companies. On 13 November 2013, a draft of the Trans-Pacific Partnership's Intellectual Property Rights chapter was published by WikiLeaks. On 10 June 2015, WikiLeaks published the draft on the Trans-Pacific Partnership's Transparency for Healthcare Annex, along with each country's negotiating position. On 19 June 2015 WikiLeaks began publishing The Saudi Cables: more than half a million cables and other documents from the Saudi Foreign Ministry that contain secret communications from various Saudi Embassies around the world.\nIn June and July 2015, WikiLeaks published a series of documents on NSA spying, which showed that NSA spied on the French, German, Brazilian and Japanese governments. The documents also detailed an economic espionage against French companies and associations and extensive monitoring of the Japanese economy and Japanese companies such as Mitsubishi and Mitsui.On 29 July 2015, WikiLeaks published a top secret letter from the Trans-Pacific Partnership Agreement (TPP) Ministerial Meeting in December 2013 which illustrated the position of negotiating countries on \"state-owned enterprises\" (SOEs). On 21 October 2015 WikiLeaks published some of John O. Brennan's emails, including a draft security clearance application which contained personal information.\n\n\n*** 2016 ***\n\nDuring the 2016 US Democratic Party presidential primaries, WikiLeaks hosted emails sent or received by presidential candidate Hillary Clinton from her personal mail server while she was Secretary of State. The emails had been released by the US State Department under a Freedom of information request in February 2016. WikiLeaks also created a search engine to allow the public to search through Clinton's emails. In July 2016, just prior to the publication of the UK government's Iraq Inquiry report, WikiLeaks published a selection of the emails referencing the Iraq War.On 19 July 2016, in response to the Turkish government's purges that followed the coup attempt, WikiLeaks released 294,548 emails from Turkey's ruling Justice and Development party (AKP). According to WikiLeaks, the material, which they claim to be the first batch from the \"AKP Emails\", was obtained a week before the attempted coup in the country and \"is not connected, in any way, to the elements behind the attempted coup, or to a rival political party or state\". After WikiLeaks announced that they would release the emails, the organisation was for over 24 hours under a \"sustained attack\". Following the leak, the Turkish government ordered the site to be blocked nationwide.Most experts and commentators agree that Phineas Fisher was behind the leak. Fisher said WikiLeaks had told her that the emails were \"all spam and crap.\" Fisher asked WikiLeaks not to publish the AKP emails as she was still accessing files on the AKP network. After WikiLeaks published the emails, the AKP shut down its internal network and Fisher lost access.On 22 July 2016, WikiLeaks released approximately 20,000 emails and 8,000 files sent from or received by Democratic National Committee (DNC) personnel. Some of the emails contained personal information of donors, including home addresses and Social Security numbers. Other emails appeared to criticise Bernie Sanders or showed favouritism towards Clinton during the primaries. Emails showed that the DNC shared debate questions with Clinton in advance. In July 2016, Debbie Wasserman Schultz resigned as chairwoman of the Democratic National Committee (DNC) because the emails released by WikiLeaks showed that the DNC was \"effectively an arm of Mrs. Clinton's campaign\" and had conspired to sabotage Bernie Sanders's campaign.On 7 October 2016, WikiLeaks started releasing series of emails and documents sent from or received by Hillary Clinton campaign manager, John Podesta, including Hillary Clinton's paid speeches to banks, including Goldman Sachs. The BBC reported that the release \"is unlikely to allay fears among liberal Democrats that she is too cosy with Wall Street\". According to a spokesman for the Clinton campaign, \"By dribbling these out every day WikiLeaks is proving they are nothing but a propaganda arm of the Kremlin with a political agenda doing Vladimir Putin's dirty work to help elect Donald Trump.\" The New York Times reported that when asked, President Vladimir Putin replied that Russia was being falsely accused. \"The hysteria is merely caused by the fact that somebody needs to divert the attention of the American people from the essence of what was exposed by the hackers.\"On 25 November 2016, WikiLeaks released emails and internal documents that provided details on the US military operations in Yemen from 2009 to March 2015. In a statement accompanying the release of the \"Yemen Files\", Assange said about the US involvement in the Yemen war: \"Although the United States government has provided most of the bombs and is deeply involved in the conduct of the war itself reportage on the war in English is conspicuously rare\".In December 2016, WikiLeaks published over 57,000 emails from Erdogan's son-in-law, Berat Albayrak, who was Turkey's Minister of Energy and Natural Resources. The emails show the inner workings of the Turkish government. According to WikiLeaks, the emails had been first released by Redhack.\n\n\n*** 2017 ***\nOn 16 February 2017, WikiLeaks released a purported report on CIA espionage orders (marked as NOFORN) for the 2012 French presidential election. The order called for details of party funding, internal rivalries and future attitudes toward the United States. The Associated Press noted that \"the orders seemed to represent standard intelligence-gathering.\"On 7 March 2017, WikiLeaks started publishing content code-named \"Vault 7\", describing it as containing CIA internal documentation of their \"massive arsenal\" of hacking tools including malware, viruses, weaponised \"zero day\" exploits and remote control systems. Leaked documents, dated from 2013 to 2016, detail the capabilities of the United States Central Intelligence Agency (CIA) to perform electronic surveillance and cyber warfare, such as the ability to compromise cars, smart TVs, web browsers (including Google Chrome, Microsoft Edge, Mozilla Firefox, and Opera Software ASA), and the operating systems of most smartphones (including Apple's iOS and Google's Android), as well as other operating systems such as Microsoft Windows, macOS, and Linux.In September 2017, WikiLeaks released \"Spy Files Russia,\" revealing \"how a St. Petersburg-based technology company called Peter-Service helped state entities gather detailed data on Russian cellphone users, part of a national system of online surveillance called System for Operative Investigative Activities (SORM).\"\n\n\n*** 2019 ***\nIn November 2019, WikiLeaks released an email from an unnamed investigator from the Organisation for the Prohibition of Chemical Weapons (OPCW) team investigating the 2018 chemical attack in Douma (Syria). The investigator accused the OPCW of covering up discrepancies. Robert Fisk said that documents released by WikiLeaks indicated that the OPCW \"suppressed or failed to publish, or simply preferred to ignore, the conclusions of up to 20 other members of its staff who became so upset at what they regarded as the misleading conclusions of the final report that they officially sought to have it changed in order to represent the truth\". The head of OPCW, Fernando Arias, described the leak as containing \"subjective views\" and stood by the original conclusions.In April 2018, WikiLeaks had offered a $100,000 reward for confidential information about \"the alleged chemical attack in Douma, Syria.\" In a November 2020 interview with BBC, WikiLeaks' alleged source declined to say if he took money from the organisation.On 12 November 2019, WikiLeaks began publishing what it called the Fishrot Files (Icelandic: Samherjaskj\u00f6lin), a collection of thousands of documents and email communication by employees of one of Iceland's largest fish industry companies, Samherji, that indicated that the company had paid hundreds of millions Icelandic kr\u00f3na to high ranking politicians and officials in Namibia with the objective of acquiring the country's coveted fishing quota.\n\n\n*** 2021 ***\nIn 2021, WikiLeaks made a searchable database of 17,000 publicly available documents, which it called The Intolerance Network, from the ultra-conservative Spanish Catholic organisation Hazte Oir and its international arm, CitizenGo. The documents reveal the internal workings of the organisations, their network of donors and their relationship with the Vatican. The release also includes documents from the secret Catholic organisation El Yunque. The editor of WikiLeaks, Kristinn Hrafnsson, said \"As ultra right-wing political groups have gained strength in recent years, with increasing attacks on women's and LGBT rights, it is valuable to have access to documents from those who have lobbied for those changes on a global basis\". According to WikiLeaks, the documents were first released in 2017.\n\n\n*** Authenticity and completeness ***\n\nAccording to The New Yorker, when WikiLeaks posted its first document in December 2006, \"Assange and the others were uncertain of its authenticity, but they thought that readers, using Wikipedia-like features of the site, would help analyse it. ... The document's authenticity was never determined, and news about WikiLeaks quickly superseded the leak itself.\" When someone said they were misidentified in a Julius Baer document as having a secret Swiss bank account Assange and Domscheit-Berg added a caveat to the document saying, \"according to three independent sources\" the information might be false or misleading. Domscheit-Berg says they made up the \"three independent sources\" and that the source had \"included some background information he had researched about the bank's clients\" that misidentified a Swiss account holder as a German man with a similar name.According to Wired in 2009, a \"whistleblower\" submitted fabricated documents to WikiLeaks. The documents were published and flagged by WikiLeaks as potential fakes. According to Daniel Domscheit-Berg, before WikiLeaks started working with media partners most verification of submissions was doing Google searches.WikiLeaks stated in 2010 that it has never released a misattributed document and that documents are assessed before release. In response to concerns about the possibility of misleading or fraudulent leaks, WikiLeaks has stated that misleading leaks \"are already well-placed in the mainstream media. WikiLeaks is of no additional assistance.\" The FAQ in 2010 stated that: \"The simplest and most effective countermeasure is a worldwide community of informed users and editors who can scrutinise and discuss leaked documents.\" According to statements by Assange in 2010, submitted documents were vetted by five reviewers with expertise in different topics such as language or programming, who also investigated the leaker's identity if known. Assange had the final say in document assessment.Columnist Eric Zorn wrote in 2016 \"So far, it's possible, even likely, that every stolen email WikiLeaks has posted has been authentic,\" but cautioned against assuming that future releases would be equally authentic. Writer Glenn Greenwald stated in 2016 that WikiLeaks has a \"perfect, long-standing record of only publishing authentic documents.\" Cybersecurity experts have said that it would be easy for a person to fabricate an email or alter it, as by changing headers and metadata.Some of the releases, including many of the Podesta emails, contain DKIM headers. This allows them to be verified as genuine to some degree of certainty.In July 2016, the Aspen Institute's Homeland Security Group, a bipartisan counterterrorism organisation, warned that hackers who stole authentic data might \"salt the files they release with plausible forgeries.\" According to Douglas Perry, Russian intelligence agencies have frequently used disinformation tactics. He wrote in 2016 that \"carefully faked emails might be included in the WikiLeaks dumps. After all, the best way to make false information believable is to mix it in with true information.\"In September 2016, The Daily Dot reported that WikiLeaks' Syria Files excluded \"records of a \u20ac2 billion transaction between the Syrian regime and a government-owned Russian bank,\" citing court documents.\n\n== Spin-offs ==\nRelease of United States diplomatic cables was followed by the creation of a number of other organisations based on the WikiLeaks model. According to Andy Greenberg there were more than 50 projects inspired by WikiLeaks in 2012, including GreenLeaks, BalkanLeaks, IndoLeaks, BrusselsLeaks and EnviroLeaks. WikiLeaks spokesman Kristinn Hrafnsson responded to the idea positively, saying that having more organisations like WikiLeaks was good.\nOpenLeaks was created by a former WikiLeaks spokesperson. Daniel Domscheit-Berg said the intention was to be more transparent than WikiLeaks. OpenLeaks was supposed to start public operations in early 2011 but despite much media coverage, as of April 2013 it is not operating.\nIn December 2011, WikiLeaks launched Friends of WikiLeaks, a social network for supporters and founders of the website.\nOn 9 September 2013 a number of major Dutch media outlets supported the launch of Publeaks, which provides a secure website for people to leak documents to the media using the GlobaLeaks whistleblowing software.\nRuLeaks was launched in December 2010 to translate and mirror publications by WikiLeaks. In January 2011, it started to publish its own content as well.\nLeakymails is a project designed to obtain and publish relevant documents exposing corruption of the political class and the powerful in Argentina.\nDistributed Denial of Secrets is a whistleblower site founded in 2018. Sometimes referred to as an alternative to WikiLeaks, it's best known for its publication of a large collection of internal police documents, known as BlueLeaks. The site has also published data on Russian oligarchs, fascist groups, shell companies, tax havens, banking in the Caymans and the Parler leak.\n\nQ: How does WikiLeaks' editorial policy differ from its original FAQ, and how have these changes affected the types of documents it publishes?",
    "context": "",
    "output": "A: WikiLeaks' editorial policy initially accepted documents of political, diplomatic, historical, or ethical interest, while the original FAQ allowed anyone to post or edit documents. However, the revised FAQ stated that only anonymous WikiLeaks reviewers could review submissions, and documents that did not meet the editorial criteria were rejected. This change in policy has resulted in a more curated selection of documents, focusing on those that are politically significant and have a higher level of credibility and veracity.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does WikiLeaks' editorial policy differ from its original FAQ, and how have these changes affected the types of documents it publishes?",
      "answer": "WikiLeaks' editorial policy initially accepted documents of political, diplomatic, historical, or ethical interest, while the original FAQ allowed anyone to post or edit documents. However, the revised FAQ stated that only anonymous WikiLeaks reviewers could review submissions, and documents that did not meet the editorial criteria were rejected. This change in policy has resulted in a more curated selection of documents, focusing on those that are politically significant and have a higher level of credibility and veracity.",
      "context": "WikiLeaks\n\n==Introduction==\nWikiLeaks () is a publisher and media organisation founded in 2006. It operates as a non-profit and is funded by donations and media partnerships. It has published classified documents and other media provided by anonymous sources. It was founded by Julian Assange, an Australian editor, publisher, and activist, who is currently challenging extradition to the United States over his work with WikiLeaks. Since September 2018, Kristinn Hrafnsson has served as its editor-in-chief. Its website states that it has released more than ten million documents and associated analyses. WikiLeaks' most recent publication was in 2021 and its most recent publication of original documents was in 2019. Beginning in November 2022, many of the documents could not be accessed.WikiLeaks has released document caches and media that exposed serious violations of human rights and civil liberties. They released footage, that WikiLeaks entitled Collateral Murder, filmed during the 12 July 2007 Baghdad airstrike in which Iraqi Reuters journalists were among several civilians killed by a U.S. helicopter crew. WikiLeaks has also published leaks such as diplomatic cables from the United States and Saudi Arabia, emails from the governments of Syria and Turkey, corruption in Kenya and at Samherji. WikiLeaks has also published documents exposing surveillance by the Central Intelligence Agency, National Security Agency and private corporations. During the 2016 U.S. presidential election campaign, WikiLeaks released emails from the Democratic National Committee (DNC) and from Hillary Clinton's campaign manager, showing that the party's national committee favoured Clinton in the primaries. These releases resulted in the resignation of Debbie Wasserman Schultz as chairwoman of the DNC and caused significant harm to the Clinton campaign. During the campaign, WikiLeaks promoted false conspiracy theories about Hillary Clinton, the Democratic Party and the murder of Seth Rich.WikiLeaks has won a number of awards and has been commended for exposing state and corporate secrets, increasing transparency, assisting freedom of the press, and enhancing democratic discourse while challenging powerful institutions. WikiLeaks and some of its supporters say the organisation's publications have a perfect attribution record. The organisation has been the target of campaigns to discredit it, including aborted ones by Palantir and HBGary. WikiLeaks has also had its donation systems disrupted by problems with its payment processors. As a result, the Wau Holland Foundation helps process WikiLeaks' donations.\n\nThe organisation has been criticised for inadequately curating its content and violating the personal privacy of individuals. WikiLeaks has, for instance, revealed Social Security numbers, medical information, credit card numbers and details of suicide attempts. Various news organisations, activists, journalists and former members have also criticised the organisation over allegations of anti-semitism, an anti-Clinton and pro-Trump bias, various associations with the Russian government, a history of buying and selling leaks, and a lack of internal transparency. Journalists have also criticised the organisation for promoting false flag conspiracy theories, and its exaggerated and misleading descriptions of the contents of leaks. The CIA defined the organisation as a \"non-state hostile intelligence service\" after the release of Vault 7.\n\n== Administration ==\nWikiLeaks describes itself as \"an uncensorable system for untraceable mass document leaking\" and \"a project of the Sunshine Press,\" a non-profit organisation based in Iceland. In 2010, Julian Assange and Kristinn Hrafnsson registered Sunshine Press Productions ehf as a business without a headquarters in Iceland. Assange serves as the Director of Sunshine Press Productions ehf and is on the board of directors with Hrafnsson and Ingi Ragnar Ingason. Gavin MacFadyen was a deputy board member. According to a January 2010 interview, the WikiLeaks team then consisted of five people working full-time and about 800 people who worked occasionally, none of whom were compensated.In November 2022, many of WikiLeaks releases disappeared from the website, bringing the number of documents from around 10 million to around 3,000. Other reported issues with the site included the websites search ability not working and a broken submission page.\n\n\n*** Editorial policy ***\nWikiLeaks established an editorial policy that accepted only documents that were \"of political, diplomatic, historical or ethical interest\" (and excluded \"material that is already publicly available\"). This coincided with early criticism that having no editorial policy would drive out good material with spam and promote \"automated or indiscriminate publication of confidential records\". The original FAQ is no longer in effect, and no one can post or edit documents on WikiLeaks. Now, submissions to WikiLeaks are reviewed by anonymous WikiLeaks reviewers, and documents that do not meet the editorial criteria are rejected. By 2008, the revised FAQ stated: \"Anybody can post comments to it. [...] Users can publicly discuss documents and analyse their credibility and veracity.\" After the 2010 reorganisation, posting new comments on leaks was no longer possible.According to WikiLeaks, the goal of the organisation is \"to bring important news and information to the public \u2026 One of our most important activities is to publish original source material alongside our news stories so readers and historians alike can see evidence of the truth.\" It also seeks to ensure that journalists and whistleblowers are not prosecuted for emailing sensitive or classified documents. The online \"drop box\" is described by the WikiLeaks website as \"an innovative, secure and anonymous way for sources to leak information to [WikiLeaks] journalists\".An embargo agreement made by WikiLeaks in 2012 included a timeline for when emails could be written about, due in part to \"elections around the world and legal matters WikiLeaks and Julian are involved in.\" In 2017, WikiLeaks told Foreign Policy that they sometimes scheduled releases around high-profile events.In response to a question in 2010 about whether WikiLeaks would release information that he knew might get someone killed, Assange said that he had instituted a \"harm-minimization policy.\" This policy meant that people named in some documents might be contacted before publication to warn them, but that there were also times were members of WikiLeaks might have \"blood on our hands.\" One member of WikiLeaks told The New Yorker they were initially uncomfortable with Assange's editorial policy, but changed her mind because she thought no one had been unjustly harmed.In an August 2010 open letter, the non-governmental organisation Reporters Without Borders praised WikiLeaks' past usefulness in exposing \"serious violations of human rights and civil liberties\" but criticised the organisation over a perceived absence of editorial control, stating \"Journalistic work involves the selection of information. The argument with which you defend yourself, namely that WikiLeaks is not made up of journalists, is not convincing.\"In a 2013 resolution, the International Federation of Journalists, a trade union of journalists, called WikiLeaks a \"new breed of media organisation\" that \"offers important opportunities for media organisations\". Harvard professor Yochai Benkler praised WikiLeaks as a new form of journalistic enterprise, testifying at the court-martial of Chelsea Manning that \"WikiLeaks did serve a particular journalistic function,\" and that the \"range of the journalist's privilege\" is \"a hard line to draw\".Others do not consider WikiLeaks to be journalistic in nature. Media ethicist Kelly McBride of the Poynter Institute for Media Studies wrote in 2011: \"WikiLeaks might grow into a journalist endeavor. But it's not there yet.\" Bill Keller of The New York Times considers WikiLeaks to be a \"complicated source\" rather than a journalistic partner. Prominent First Amendment lawyer Floyd Abrams writes that WikiLeaks is not a journalistic organisation, but instead \"an organization of political activists; \u2026 a source for journalists; and \u2026 a conduit of leaked information to the press and the public\". In support of his opinion, referring to Assange's statements that WikiLeaks reads only a small fraction of information before deciding to publish it, Abrams wrote: \"No journalistic entity I have ever heard of\u2014none\u2014simply releases to the world an elephantine amount of material it has not read.\"\n\n\n*** Financing ***\nWikiLeaks is a self-described not-for-profit organisation, funded largely by volunteers, and is dependent on private donations, exclusivity contracts and concessions from their media partners. Its main financing methods include conventional bank transfers and online payment systems. According to Assange, WikiLeaks' lawyers often work pro bono. Assange has said that in some cases legal aid has been donated by media organisations such as the Associated Press, the Los Angeles Times, and the National Newspaper Publishers Association. Assange said in early 2010 that WikiLeaks' only revenue consists of donations, but it has considered other options including auctioning early access to documents. In September 2010, Assange said that WikiLeaks received millions of dollars in media partnerships, explaining they \"win concessions in relation to the number of journalists that will be put on it and how big they'll run with it.\"In 2010, Assange said the organisation was registered as a library in Australia, a foundation in France, and a newspaper in Sweden, and that it also used two United States-based non-profit 501c3 organisations for funding purposes.\n\n\n**** 2010-2013 ****\nIn January 2010, WikiLeaks temporarily shut down its website while management appealed for donations. Previously published material was no longer available, although some could still be accessed on unofficial mirror websites. WikiLeaks stated that it would resume full operation once the operational costs were paid. WikiLeaks saw this as a kind of work stoppage \"to ensure that everyone who is involved stops normal work and actually spends time raising revenue\". While the organisation initially planned for funds to be secured by 6 January 2010, it was not until 3 February 2010 that WikiLeaks announced that its minimum fundraising goal had been achieved.The Wau Holland Foundation, one of the WikiLeaks' main funding channels, stated that they received more than \u20ac900,000 in public donations between October 2009 and December 2010, of which \u20ac370,000 has been passed on to WikiLeaks. Hendrik Fulda, vice-president of the Wau Holland Foundation, said that every new WikiLeaks publication brought \"a wave of support\", and that donations were strongest in the weeks after WikiLeaks started publishing leaked diplomatic cables. According to Assange, WikiLeaks' media partnerships for the cables earned them almost $2 million three months after they started publishing. WikiLeaks was paid \u00a3150,000 by Al Jazeera and Channel 4 for two five-minute video clips about the Iraq War Logs. In December 2010, the Wau Holland Foundation stated that Julian Assange and three other permanent employees had begun to receive salaries.During 2010, WikiLeaks received over $1.9 million in donations. About $930,000 came through PayPal donations, with the rest coming through bank transfers. In 2011, donations dropped sharply and WikiLeaks received only around $180,000 in donations, while their expenses increased from $519,000 to $850,000. In 2011, Al Jazeera offered WikiLeaks $1.3 million for access to data. During September 2011, WikiLeaks began auctioning items on eBay to raise funds. Wikileaks started accepting bitcoin in 2011 as a currency which could not be blocked by financial intuitions or a government. In 2012, WikiLeaks raised only $68,000 through the Wau Holland Foundation and had expenses more than $507,000. In 2013, WikiLeaks and Wau Holland Foundation agreed on a new framework contract which Wau Holland Foundation would only cover direct costs such as server, ISP, project coordination and translation costs. Between January and May, Wau Holland Foundation was only able to cover $47,000 in essential infrastructure for WikiLeaks, but not an additional $400,000 that was submitted \"to cover publishing campaigns and logistics in 2012\".\n\n\n***** Financial blockade*****\n\nOn 22 January 2010, the Internet payment intermediary PayPal suspended WikiLeaks' donation account and froze its assets. WikiLeaks said that this had happened before, and was done for \"no obvious reason\". In August 2010, the internet payment company Moneybookers closed WikiLeaks' account and sent Assange a letter saying \"Following an audit of your account by our security department, we must advise that your account has been closed \u2026 to comply with money laundering or other investigations conducted by government authorities.\" After Assange asked what the problem was, Moneybookers sent another email saying that initially the \"account was suspended due to being accessed from a blacklisted IP address. However, following recent publicity and the subsequently addition of the WikiLeaks entity to blacklists in Australia and watchlists in the USA, we have terminated the business relationship.\" According to The Guardian, the apparent blacklisting came a few days after the Pentagon expressed anger at WikiLeaks for publishing the Afghan War logs.In December 2010, PayPal suspended WikiLeaks' account, thereby stopping donations through PayPal. PayPal said it had taken action after the US State Department sent a letter to Wikileaks stating that Wikileaks' activities were illegal in the US. Hendrik Fulda, vice-president of the Wau Holland Foundation, said that the Foundation had been receiving twice as many donations through PayPal as through normal banks before PayPal's decision to suspend WikiLeaks' account. Mastercard and Visa Europe also decided to stop accepting payments to WikiLeaks. Bank of America, Amazon and Swiss bank PostFinance had previously stopped dealing with WikiLeaks. Datacell, the IT company that enabled WikiLeaks to accept credit and debit card donations, threatened Mastercard and Visa with legal action to enforce the resumption of payments to WikiLeaks. Datacell said Visa's action was the result of political pressure.In October 2011, Assange said that the financial blockade by Bank of America, Visa, MasterCard, PayPal and Western Union, had cost WikiLeaks ninety-five per cent of its revenue. In 2012, an Icelandic district court ruled that Valitor, the Icelandic partner of Visa and MasterCard, was violating the law when it stopped accepting credit card donations to WikiLeaks. The court ruled that donations to WikiLeaks must resume within 14 days or Valitor would be fined US$6,000 a day. In November 2012, the European Union's European Commission said they wouldn't open a formal investigation into Mastercard and Visa and blocking donations for WikiLeaks because it was unlikely to have violated EU anti-trust rules.In response to the financial blockade of Wikileaks, Glenn Greenwald and others created the Freedom of the Press Foundation in order \"to block the US government from ever again being able to attack and suffocate an independent journalistic enterprise the way it did with WikiLeaks\".\n\n\n**** 2014-2018 ****\nIn 2014, Sunshine Press Productions ehf began receiving funds from Wau Holland Foundation for WikiLeaks. From 2014-2017 WikiLeaks was reimbursed for project coordination, technical preparation, removing metadata, reviewing information, communicating with media partners costs and a new submission platform and document search. The DNC emails and Podesta emails were not funded by the Wau Holland Foundation. By October 2017, WikiLeaks founder Julian Assange said the organisation had made a 50,000% return on Bitcoin. By that December, they had raised at least $25 million in Bitcoin.In 2018, the Wau Holland Foundation reimbursed Sunshine Press Productions for WikiLeaks' publications, as well as public relations and $50,000 for legal expenses in the Democratic National Committee v. Russian Federation lawsuit.\n\n\n*** Hosting ***\nIn 2010, the website was available on multiple servers, different domain names and had an official dark web version (available on the Tor Network) as a result of a number of denial-of-service attacks and its elimination from different Domain Name System (DNS) providers.Until August 2010, WikiLeaks was hosted by PRQ, a company based in Sweden providing \"highly secure, no-questions-asked hosting services\". PRQ was reported by The Register website to have \"almost no information about its clientele and maintains few if any of its own logs\". That month, WikiLeaks reached an agreement with the Swedish Pirate Party to host several of their servers. Later, WikiLeaks was hosted mainly by the Swedish Internet service provider Bahnhof in the Pionen facility, a former nuclear bunker in Sweden. Other servers were spread around the world with the main server located in Sweden.After the site became the target of a denial-of-service attack on its old servers, WikiLeaks moved its website to Amazon's servers. Amazon later removed the website from its servers. In a public statement, Amazon said that WikiLeaks was not following its terms of service. The company stated: \"There were several parts they were violating. For example, our terms of service state that 'you represent and warrant that you own or otherwise control all of the rights to the content ... that use of the content you supply does not violate this policy and will not cause injury to any person or entity.' It's clear that WikiLeaks doesn't own or otherwise control all the rights to this classified content.\" WikiLeaks was then moved to servers at OVH, a private web-hosting service in France. After criticism from the French government, a judge in Paris ruled that there was no need for OVH to cease hosting WikiLeaks without more information.WikiLeaks used EveryDNS, but was dropped by the company after distributed denial-of-service (DDoS) attacks against WikiLeaks hurt the quality of service for its other customers. Supporters of WikiLeaks waged verbal and DDoS attacks on EveryDNS. Because of a typographical error in blogs mistaking EveryDNS for competitor EasyDNS, the sizeable Internet backlash hit EasyDNS. Despite that, EasyDNS began providing WikiLeaks with DNS service on \"two 'battle hardened' servers\" to protect the quality of service for its other customers.\n\n\n*** Insurance files ***\nWikiLeaks has used heavily encrypted files to protect their publications against censorship, to pre-release publications, and as protection against arrest. The files have been described as \"insurance\", a \"dead man's switch\", \"a kind of doomsday option\", and a \"poison pill\". The insurance files sometimes come with pre-commitment hashes.WikiLeaks staff have said that \"insurance files are encrypted copies of unpublished documents submitted to us. We do this periodically, and especially at moments of high pressure on us, to ensure the documents can not be lost and history preserved. You will not be able to see the contents of any of our insurance files, until and unless the we are in a position where we must release the key. But you can download them and help spread them to ensure their safe keeping.\"On 29 July 2010 WikiLeaks added an \"Insurance file\" to the Afghan War Diary page. The file is AES encrypted. There has been speculation that it was intended to serve as insurance in case the WikiLeaks website or its spokesman Julian Assange are incapacitated, upon which the passphrase could be published. After the first few days' release of the US diplomatic cables starting 28 November 2010, the US television broadcasting company CBS predicted that \"If anything happens to Assange or the website, a key will go out to unlock the files. There would then be no way to stop the information from spreading like wildfire because so many people already have copies.\" CBS correspondent Declan McCullagh stated, \"What most folks are speculating is that the insurance file contains unreleased information that would be especially embarrassing to the US government if it were released.\"In August 2013, WikiLeaks posted three insurance files as torrents, totalling 400 gigabytes. WikiLeaks said they \"encrypted versions of upcoming publication data (\"insurance\") from time to time to nullify attempts at prior restraint.\"In June 2016, WikiLeaks posted an 88 gigabyte insurance file. On 16 October 2016, WikiLeaks tweeted an insurance file about Ecuador. In November, they posted insurance files for the US, the UK and Ecuador, and an unlabelled 90 gigabyte insurance file was posted.In January 2017, On 7 March 2017, WikiLeaks posted an encrypted file containing the Vault 7 Year Zero release. WikiLeaks had planned to release them later, but released them online later that day because of cyber attacks. The password, SplinterItIntoAThousandPiecesAndScatterItIntoTheWinds, was a reference to an alleged quote by President Kennedy.\n\n\n*** Staff ***\nIn June 2009, the website said it had more than 1,200 registered volunteers. According to Daniel Domscheit-Berg, WikiLeaks exaggerated the number of volunteers and Assange used many pseudonyms. Domscheit-Berg suggested that one may have been \"Jay Lim\", who identified online as an occasional WikiLeaks spokesperson and as its legal advisor.Daniel Domscheit-Berg, Sarah Harrison,  Kristinn Hrafnsson and Joseph Farrell are notable people who have been involved in the project. Harrison is also a member of Sunshine Press Productions along with Assange and Ingi Ragnar Ingason. Gavin MacFadyen was acknowledged by Assange as a \u2033beloved director of WikiLeaks\u2033 shortly after his death in 2016. Jacob Appelbaum is the only known American who is known to have been member of WikiLeaks, acting as a senior editor and spokesman. Gottfrid Svartholm had worked with WikiLeaks as a technical consultant and managed infrastructure critical to the organization. He was also listed as part of the \"decryption and transmission team\" on Collateral Murder and credited for \"networking\" and helped with several other unknown endeavors. Rop Gonggrijp, Birgitta J\u00f3nsd\u00f3ttir, Sm\u00e1ri McCarthy and Herbert Snorrason are WikiLeaks volunteers and members who the US government has tried to surveill with court orders. WikiLeaks was represented in Russia by Israel Shamir and in Sweden by his son Johannes Wahlstr\u00f6m.According to colleagues and former WikiLeaks insiders, the WikiLeaks dropbox architecture was rebuilt by a WikiLeaks programmer known to most insiders as \"The Architect\". He also instructed another WikiLeaks technician, and some of colleagues thought he was a computer genius. According to Andy Greenberg, insiders told him \"when The Architect joined WikiLeaks it was a mess. It was two creaking servers without all the flashy security that Assange had promised in interviews with the media. The Architect rebuilt it from scratch.\" According to Wired, \"WikiLeaks had been running on a single server with sensitive backend components like the submission and e-mail archives connected to the public-facing Wiki page. The Architect separated the platforms and set up a number of servers in various countries.\"In August 2011, WikiLeaks volunteer Sigurdur Thordarson, working in his home country Iceland, contacted the FBI and, after presenting a copy of Assange's passport at the American embassy, became the first informant to work for the FBI from inside WikiLeaks, and gave the FBI several hard drives he had copied from Assange and core WikiLeaks members. In November 2011, WikiLeaks dismissed Thordarson due to his embezzlement of $50,000, to which charge (along with several other offences) he later pleaded guilty in an Icelandic court. According to Thordarson, a few months after his dismissal by WikiLeaks the FBI agreed to pay him $5,000 as compensation for work missed while meeting with agents.Alexa O'Brien briefly worked for WikiLeaks in 2014, later saying she found working for the organization was not a good fit. On 26 September 2018, it was announced that Julian Assange had appointed Kristinn Hrafnsson as editor-in-chief of WikiLeaks with Assange continuing as its publisher.\n\n\n*** Submissions ***\nWikiLeaks restructured its process for contributions after its first document leaks did not gain much attention. Assange stated this was part of an attempt to take the voluntary effort typically seen in Wiki projects and \"redirect it to ... material that has real potential for change\". Before this, the Wikileaks FAQ, under \"How will Wikileaks operate?\", read as of February 2007:\nTo the user, Wikileaks will look very much like Wikipedia. Anybody can post to it, anybody can edit it. No technical knowledge is required. Leakers can post documents anonymously and untraceably. Users can publicly discuss documents and analyze their credibility and veracity. Users can discuss interpretations and context and collaboratively formulate collective publications. Users can read and write explanatory articles on leaks along with background material and context. The political relevance of documents and their verisimilitude will be revealed by a cast of thousands.\nWikiLeaks originally used a \"wiki\" communal publication method, which ended by May 2010.In 2010 Assange said WikiLeaks received some submissions through the postal mail. That year, Julian Assange said that the servers were located in Sweden and the other countries \"specifically because those nations offer legal protection to the disclosures made on the site\". He talks about the Swedish constitution, which he said gives the information\u2013providers total legal protection. According to Assange, under Swedish law, it is forbidden for any administrative authority to make inquiries about the sources of any type of newspaper. These laws were meant to make it difficult for any authority to target WikiLeaks by placing a burden of proof upon any complainant. Furthermore, \"WikiLeaks maintains its own servers at undisclosed locations, keeps no logs and uses military-grade encryption.\" Such arrangements have been called \"bulletproof hosting\". However according to the Columbia Journalism Review, \"a ariety of Swedish media law experts made it clear that Assange and WikiLeaks had repeatedly misrepresented not only the strength of the law, but its application to WikiLeaks. \"According to some, The Architect was the engineer who rebuilt the WikiLeaks submission system \"from scratch\" and instructed another WikiLeaks technician. According to Andy Greenberg and Wired, when The Architect joined WikiLeaks, it \"was a mess\" running on one or two servers \"without all the flashy security that Assange had promised in interviews with the media.\" The Architect rebuilt it from scratch and separated the sensitive platforms from the public-facing Wiki \"and set up a number of servers in various countries.\"During the 2010 reorganisation, The Architect left with Domscheit-Berg, taking the code behind the submission system with him. Assange said that the submission system was temporarily down because its backlog was too big. WikiLeaks later said it was down because of Domscheit-Berg's \"acts of sabotage\" when he left the organisation, which had forced WikiLeaks to \"overhaul the entire submission system\", and the staff lacked time to do so.WikiLeaks submissions stayed offline for four and a half years, until May 2015. While it was offline, WikiLeaks announced they were building a state-of-the-art secure submission system. The launch of the new system was delayed by security concerns in 2011. During this time, WikiLeaks continued to publish documents. These publications originated from material which had been directly shared with WikiLeaks by hackers, or were the result of Wikileaks organising and republishing already-public leaks. A former WikiLeaks associate said that Andy M\u00fcller-Maguhn and a colleague administered the submission server in 2016, though M\u00fcller-Maguhn denies this. That October, WikiLeaks suggested \"lawyer to lawyer\" as an alternate submission method, naming Margaret Ratner Kunstler.By October 2021, WikiLeaks' secure chat stopped working and by February 2022, WikiLeaks' submission system and email server were offline. In July 2022, a broken version of the submission system briefly relaunched with expired PGP keys and went offline after it was reported on by The Daily Dot.\n\n== Legal issues ==\nThere have been many legal issues in different countries and several investigations surrounding WikiLeaks since it was founded.\nIn August 2010, the internet payment company Moneybookers closed WikiLeaks' account due to publicity over its release of the Afghan war logs and because WikiLeaks had been added to the official US watchlist and an Australian government blacklist.\n\n\n*** Legal issues in Australia ***\nIn December 2010, the Australian Prime Minister Julia Gillard said that \"I absolutely condemn the placement of this information on the WikiLeaks website - it's a grossly irresponsible thing to do and an illegal thing to do\". After criticism and a revolt within her party, she said she was referring to \"the original theft of the material by a junior U.S. serviceman rather than any action by Mr Assange\".The Australian Federal Police later said that the release of the cables by WikiLeaks breached no Australian laws.On 2 September 2011, Australia's attorney general, Robert McClelland released a statement that the US diplomatic cables published by Wikileaks identified at least one ASIO officer, and that it was a crime in Australia to publish information which could identify an intelligence officer. McClelland said that \"On occasions before this week, WikiLeaks redacted identifying features where the safety of individuals or national security could be put at risk. It appears this hasn't occurred with documents that have been distributed across the internet this week.\" According to The Guardian and Al Jazeera, this meant \"Julian Assange could face prosecution in Australia.\"In 2014, WikiLeaks published information about political bribery allegations, violating a gag order in Australia. According to Peter Bartlett, a media lawyer in Australia, WikiLeaks was outside Australia's jurisdiction but \"if Assange ever comes back to Australia, you would expect that he would immediately be charged with breaking a suppression order.\"\n\n\n*** Legal issues in United States ***\n\nIn early February 2008, the Julius Baer Group sued WikiLeaks in California to have documents removed from their website. Judge Jeffrey White forced Dynadot, the domain registrar of wikileaks.org, to disassociate the site's domain name records with its servers, preventing use of the domain name to reach the site. Initially, the bank only wanted the documents to be removed (WikiLeaks had failed to name a contact person). After civil rights challenges, the judge lifted the injunction and the bank dropped the case on 5 March 2008.On 20 April 2018, the Democratic National Committee filed a multimillion-dollar lawsuit in federal district court in Manhattan against Russia, the Trump campaign, WikiLeaks and Julian Assange, alleging a conspiracy to disrupt the 2016 United States presidential election in Trump's favour. The suit was dismissed with prejudice on 30 July 2019. In his judgement, Judge John Koeltl said that WikiLeaks \"did not participate in any wrongdoing in obtaining the materials in the first place\" and therefore was within the law in publishing the information. The federal judge also wrote \"The DNC's interest in keeping 'donor lists' and 'fundraising strategies' secret is dwarfed by the newsworthiness of the documents as a whole...If WikiLeaks could be held liable for publishing documents concerning the DNC's political financial and voter-engagement strategies simply because the DNC labels them 'secret' and trade secrets, then so could any newspaper or other media outlet\".\n\n\n**** United States criminal investigations ****\nThe US Justice Department began a criminal investigation of WikiLeaks and Julian Assange soon after the leak of diplomatic cables in 2010 began. The Washington Post reported that the department was considering charges under the Espionage Act of 1917, an action which former prosecutors characterised as \"difficult\" because of First Amendment protections for the press. Several Supreme Court cases, while not conclusive, (e.g. Bartnicki v. Vopper) have established previously that the American Constitution protects the re-publication of illegally gained information provided the publishers did not themselves violate any laws in acquiring it. The question of criminal punishment or a civil injunction after publication, like in the WikiLeaks case, is less established.In 2010, the NSA added Assange to its Manhunting Timeline. In August 2010, the Pentagon had concluded that the Afghan War documents leak broke the law. A letter from the Department of Defence general counsel said that \"it is the view of the Department of Defence that WikiLeaks obtained this material in circumstances that constitute a violation of US law, and that as long as WikiLeaks holds this material, the violation of the law is ongoing.\" In November 2010, Harold Koh, the Legal Adviser of the Department of State, wrote that the United States diplomatic cables leak \"were provided in violation of US law and without regard for the grave consequences of this action\" and \"as long as WikiLeaks holds such material, the violation of the law is ongoing\".In 2011, a WikiLeaks volunteer became an FBI informant and Google was served with search warrants for the contents of two WikiLeaks volunteers' email accounts. The NSA discussed categorising WikiLeaks as a \"malicious foreign actor\" for surveillance purposes.On 14 December 2010 the United States Department of Justice issued a subpoena directing Twitter to provide information for accounts registered to or associated with WikiLeaks. Twitter decided to notify its users.By 2013,  J\u00e9r\u00e9mie Zimmermann, Sm\u00e1ri McCarthy, Jacob Appelbaum, David House and Jennifer Robinson had been detained and interrogated or approached when attempts were made to recruit them as informants, often using heavy handed tactics.In 2013, it was revealed that Google had been served with search warrants for the contents of email accounts belonging to WikiLeaks volunteers Herbert Snorrason and Smari McCarthy. In 2015, it was revealed that Google had been served with search warrants for the contents of email accounts belonging to WikiLeaks staff members Sarah Harrison, Joseph Farrell, and Kristinn Hrafnsson as part of a criminal investigation with alleged offences including espionage, conspiracy to commit espionage, the theft or conversion of property belonging to the United States government, violation of the Computer Fraud and Abuse Act, and criminal conspiracy. According to Daniel Domscheit-Berg in 2010, the WikiLeaks email accounts for Kristinn Hrafnsson and a young WikiLeaks staffer had automatically forwarded to their Google account, opening the organisation to surveillance risks.In April 2017, prosecutors began drafting a memo that considered charging members of WikiLeaks with conspiracy, theft of government property or violating the Espionage Act. That month, CIA director Mike Pompeo called WikiLeaks \"a non-state hostile intelligence service often abetted by state actors like Russia\". The official designation of Wikileaks and Julian Assange as a non-state hostile intelligence service was discussed in mid-2017 during preparation of the Intelligence Authorization Act for Fiscal Year 2018. It was eventually incorporated into the National Defense Authorization Act for Fiscal Year 2020 that became law in December 2019. The Act says \"It is the sense of Congress that WikiLeaks and the senior leadership of WikiLeaks resemble a non-state hostile intelligence service often abetted by state actors and should be treated as such a service by the United States.\" In the opinion of some former officials, the designation allowed the CIA to launch and plan operations that did not require presidential approval or congressional notice.In September 2021, Yahoo! News reported that in 2017 in the wake of the Vault 7 leaks, the CIA discussed plans to kidnap or assassinate Julian Assange. They also planned to spy on associates of WikiLeaks, sow discord among its members, and steal their electronic devices. \"[T]op intelligence officials lobbied the White House\" to designate Wikileaks as an \"information broker\" to allow for more investigative tools against it, \"potentially paving the way\" for its prosecution. Laura Poitras described attempts to classify herself and Assange as \"information brokers\" rather than journalists as \"bone-chilling and a threat to journalists worldwide\". Former CIA Director Mike Pompeo stated that the US officials who had spoken to Yahoo should be prosecuted for exposing CIA activities.In November 2018, an accidental filing with Assange's name was seen to indicate there were undisclosed charges against him. On 11 April 2019, Assange was charged in a computer hacking conspiracy. On 23 May, a superseding indictment was filed with charges of Conspiracy to Receive National Defense Information, Obtaining National Defense Information, Disclosure of National Defense Information, and Conspiracy to Commit Computer Intrusion. On 24 June 2020, another superseding indictment was filed which added to the allegations but not the charges.After the indictment against Assange was unsealed, the Department of Justice continued to investigate Wikileaks. The day after charging Assange, prosecutors contacted Domscheit-Berg. Prosecutors also spoke with David House for about 90 minutes, who had previously testified to the grand jury in exchange for immunity. House testified about helping run political operations for WikiLeaks and that Assange wanted him \"to help achieve favorable press for Chelsea Manning.\" According to House, the grand jury \"wanted full insight into WikiLeaks, what its goals were and why I was associated with it.  .\u2009.\u2009. It was all related to disclosures around the war logs.\" House said he had contact with Assange until 2013 and with WikiLeaks until 2015. Chelsea Manning and Jeremy Hammond refused to testify for the grand jury.In early 2019, the Mueller report wrote the Special Counsel's office considered charging WikiLeaks or Assange \"as conspirators in the computer-intrusion conspiracy and that there were \"factual uncertainties\" about the role that Assange may have played in the hacks or their distribution that were \"the subject of ongoing investigations\" by the US Attorney\u2019s Office.\n\n\n*** Use of leaked documents in court ***\nIn April 2011, the US Department of Justice warned military lawyers acting for Guantanamo Bay detainees against clicking of links on sites such as The New York Times that might lead to classified files published by WikiLeaks. In June 2011, the US Department of Justice ruled that attorneys acting for Guantanamo Bay detainees could cite documents published by WikiLeaks. The use of the documents was subject to restrictions.On 8 February 2018, the UK Supreme Court unanimously allowed a document that had been leaked through WikiLeaks to be admitted as evidence. The cable had been excluded from use in an earlier part of the case before the Administrative Court based on the fact that it was a diplomatic communication, which enjoy \"inviolable\" protections that prevent them from being used in court outside of exceptional circumstances. The Supreme Court ruled that since the document had already been widely disseminated, it had lost any protections it might have had. The hearing was considered an important test of the Vienna Convention in relation to WikiLeaks documents.\n\n== Publications ==\nThe initial tranche of WikiLeaks' documents came from a WikiLeaks' activist who owned a server that was a node in the Tor network. After they noticed that Chinese hackers used the network to gather information from foreign governments, the activist began recording the information. This let Assange show potential contributors that WikiLeaks was viable and say they had \"received over one million documents from thirteen countries\".\n\n\n*** 2006\u20132008 ***\nWikiLeaks posted its first document in December 2006, a decision to assassinate Somali government officials signed by rebel leader Sheikh Hassan Dahir Aweys. Assange and WikiLeaks were uncertain of its authenticity, and the document\u2019s authenticity was never determined.\nIn August 2007, the UK newspaper The Guardian published a story about corruption by the family of the former Kenyan leader Daniel arap Moi based on information provided via WikiLeaks.\nIn November 2007, a March 2003 copy of Standard Operating Procedures for Camp Delta detailing the protocol of the US Army at the Guantanamo Bay detention camp was released. The document revealed that some prisoners were off-limits to the International Committee of the Red Cross, something that the US military had in the past denied repeatedly. The Guant\u00e1namo Bay Manual included procedures for transferring prisoners and methods of evading protocols of the Geneva convention.\nIn February 2008, WikiLeaks released allegations of illegal activities at the Cayman Islands branch of the Swiss Bank Julius Baer, which resulted in the bank suing WikiLeaks and obtaining an injunction which temporarily suspended the operation of wikileaks.org. The California judge had Dynadot, the service provider of WikiLeaks block the site's domain (wikileaks.org) on 18 February 2008. The website was instantly mirrored, and later that month the judge overturned his previous decision citing First Amendment concerns and questions about legal jurisdiction.\nIn March 2008, WikiLeaks published what they referred to as \"the collected secret 'bibles' of Scientology\", and three days later received letters threatening to sue them for breach of copyright.\nIn September 2008, during the 2008 United States presidential election campaigns, the contents of a Yahoo account belonging to Sarah Palin (the running mate of Republican presidential nominee John McCain) were posted on WikiLeaks after being hacked by 4chan user David Kernell.\nIn November 2008, the membership list of the far-right British National Party was posted to WikiLeaks, after appearing briefly on a weblog. A year later, in October 2009, another list of BNP members was leaked, said by the BNP\u2019s leader, Nick Griffin, to be a \u2018malicious forgery\u2019.\n\n\n*** 2009 ***\nDuring 2008 and 2009, WikiLeaks published lists of forbidden or illegal web addresses for Australia, Denmark and Thailand. These were originally created to prevent access to child pornography and terrorism, but the leaks revealed that other sites featuring unrelated subjects were also listed.\nIn January 2009, WikiLeaks released 86 telephone intercept recordings of Peruvian politicians and businessmen involved in the 2008 Peru oil scandal.\nIn February, WikiLeaks cracked the encryption to and published NATO's Master Narrative for Afghanistan and three other classified or restricted NATO documents on the Pentagon Central Command (CENTCOM) site.\nDuring February, WikiLeaks released 6,780 Congressional Research Service reports followed in March by a set of documents belonging to Barclays Bank that had been ordered removed from the website of The Guardian.\nIn July, WikiLeaks released a report disclosing a \"serious nuclear accident\" at the Iranian Natanz nuclear facility. According to media reports, the accident may have been the direct result of a cyber-attack at Iran's nuclear program, carried out with the Stuxnet computer worm, a cyber-weapon allegedly built jointly by the United States and Israel.\nIn September, internal documents from Kaupthing Bank were leaked, from shortly before the collapse of Iceland's banking sector, which had caused the 2008\u20132012 Icelandic financial crisis. The document showed that suspiciously large sums of money were loaned to various owners of the bank, and large debts written off.\nIn October, Joint Services Protocol 440, a British document advising the security services on how to avoid documents being leaked, was published by WikiLeaks. Later that month, it announced that a super-injunction was being used by the commodities company Trafigura to stop The Guardian (London) from reporting on a leaked internal document regarding a toxic dumping incident in C\u00f4te d'Ivoire.\nIn November, released 570,000 intercepts of pager messages sent on the day of the 11 September attacks. These included messages sent from the Pentagon, the FBI, the Federal Emergency Management Agency and the NYPD, in response to the disaster.\n\n\n*** 2010 ***\n\nIn mid-February 2010, WikiLeaks received a leaked diplomatic cable from the United States Embassy in Reykjavik relating to the Icesave scandal, which they published on 18 February. The cable, known as Reykjavik 13, was the first of the classified documents WikiLeaks published among those allegedly provided to them by United States Army Private Chelsea Manning. In March 2010, WikiLeaks released a secret 32-page US Department of Defense Counterintelligence Analysis Report written in March 2008 discussing the leaking of material by WikiLeaks and how it could be deterred.In April, a classified video of the 12 July 2007 Baghdad airstrike was released, showing two Reuters employees being fired at, after the pilots mistakenly thought the men were carrying weapons, which were in fact cameras. After the men were killed, the video shows US forces firing on a family van that stopped to pick up the bodies. Press reports of the number killed in the attacks vary from 12 to \"over 18\". Among the dead were two journalists and two children were also wounded.In June 2010, Manning was arrested after alleged chat logs were given to United States authorities by former hacker Adrian Lamo, in whom she had confided. Manning reportedly told Lamo she had leaked the \"Collateral Murder\" video, in addition to a video of the Granai airstrike and about 260,000 diplomatic cables, to WikiLeaks. Manning later said that before WikiLeaks, she tried approaching The Washington Post, The New York Times and Politico.In July, WikiLeaks released 92,000 documents related to the war in Afghanistan between 2004 and the end of 2009 to the publications The Guardian, The New York Times and Der Spiegel. The documents detail individual incidents including \"friendly fire\" and civilian casualties. WikiLeaks asked the Pentagon and human-rights groups to help remove names from the documents to reduce the potential harm caused by their release, but did not receive assistance.After the Love Parade stampede in Duisburg, Germany, on 24 July 2010, a local resident published internal documents of the city administration regarding the planning of Love Parade. The city government reacted by securing a court order on 16 August forcing the removal of the documents from the website on which it was hosted. On 20 August 2010, WikiLeaks released a publication entitled Loveparade 2010 Duisburg planning documents, 2007\u20132010, which consisted of 43 internal documents regarding the Love Parade 2010.After the leak of information concerning the Afghan War, in October 2010, around 400,000 documents relating to the Iraq War were released. The BBC quoted the US Department of Defense referring to the Iraq War Logs as \"the largest leak of classified documents in its history\". Media coverage of the leaked documents emphasised claims that the US government had ignored reports of torture by the Iraqi authorities during the period after the 2003 war.\n\n\n*** Diplomatic cables release ***\n\nOn 28 November 2010, WikiLeaks and El Pa\u00eds, Le Monde, Der Spiegel, The Guardian, and The New York Times started simultaneously to publish the first 220 of 251,287 leaked documents labelled confidential \u2013 but not top-secret \u2013 and dated from 28 December 1966 to 28 February 2010.\n\nThe contents of the diplomatic cables include numerous unguarded comments and revelations regarding: US diplomats gathering personal information about Ban Ki-moon, Secretary-General of the United Nations, and other top UN officials; critiques and praises about the host countries of various United States embassies; political manoeuvring regarding climate change; discussion and resolutions towards ending ongoing tension in the Middle East; efforts and resistance towards nuclear disarmament; actions in the War on Terror; assessments of other threats around the world; dealings between various countries; United States intelligence and counterintelligence efforts; and other diplomatic actions. Reactions to the United States diplomatic cables leak varied. The overthrow of the presidency in Tunisia of 2011 has been attributed partly to reaction against the corruption revealed by leaked cables.According to the former US Ambassador to Cameroon from 2004 to 2007, Niels Marquardt, Marafa Hamidou Yaya was arrested on \"entirely unproven corruption charges\", subjected to a \"kangaroo court\", and given a 25-year prison sentence. Marquardt said Marafa's only real crime was having told him that he \"might be interested\" in the presidency one day. According to Marquardt, when Wikileaks released the cable in which this was mentioned, it became front-page news in Cameroon and led directly to Marafa's arrest. The U.S. ambassador at the time, Robert Jackson, said Marafa's trial did not specify the evidence against him.\n\n\n**** Unredacted cable release ****\n\n\n***** Background*****\nIn August 2010, Assange gave Guardian journalist David Leigh an encryption key and a URL where he could locate the file containing the U.S. diplomatic cables. In February 2011 David Leigh and Luke Harding of The Guardian published the book WikiLeaks: Inside Julian Assange's War on Secrecy containing the encryption key. Leigh said he believed the key was a temporary one that would expire within days. Wikileaks supporters disseminated the encrypted files to mirror sites in December 2010 after Wikileaks experienced cyber-attacks. When Wikileaks learned what had happened it notified the US State Department. On 25 August 2011, the German magazine Der Freitag published an article giving details which would enable people to piece the information together.\n\n\n***** Release*****\nIn January 2011, several unredacted cables were posted online by an associate of WikiLeaks, Israel Shamir. The cables incldued the names of people implied to be connected to bribery, and highly suggestive clues about the identity of an American informant.On 29 August, WikiLeaks published over 130,000 unredacted cables. On 31 August, WikiLeaks tweeted a link to a torrent of the encrypted data. On 1 September 2011, WikiLeaks announced that an encrypted version of the un-redacted US State Department cables had been available via BitTorrent for months and that the decryption key was available. WikiLeaks said that on 2 September it would publish the entire, unredacted archive in searchable form on its website. According to Assange, Wikileaks did this so that possible targets could be informed and better defend themselves, and also to provide a reliable source for the leaks.Glenn Greenwald wrote that \"WikiLeaks decided -- quite reasonably -- that the best and safest course was to release all the cables in full, so that not only the world's intelligence agencies but everyone had them, so that steps could be taken to protect the sources and so that the information in them was equally available\". The US cited the release in the opening of its request for extradition of Assange, saying his actions put lives at risk. The defence gave evidence it said would show that Assange was careful to protect lives. John Young, the owner and operator  of the website Cryptome testified at Assange's extradition hearing that the unredacted cables were published by Cryptome on 1 September, the day before Wikileaks, and they remain on the Cryptome site. Young testified that \"no US law enforcement authority has notified me that this publication of the cables is illegal, consists or contributes to a crime in any way, nor have they asked for them to be removed\".The Guardian wrote that the decision to publish the cables in a searchable form was made by Assange alone, a decision that it, and its four previous media partners, condemned. According to The Guardian, several thousand files in the archive were marked \"strictly protect\" which indicated officials thought sources could be endangered by their release. In a joint statement, The Guardian, El Pais, New York Times and Der Spiegel said they \"deplore the decision of WikiLeaks to publish the unredacted state department cables, which may put sources at risk\" and \"we cannot defend the needless publication of the complete data - indeed, we are united in condemning it.\" Le Monde told the Associated Press it would also sign the statement. In response, WikiLeaks accused The Guardian of false statements and nepotism. Out of concern for those involved, Reporters Without Borders temporarily suspended their WikiLeaks mirror.According to media reports, after WikiLeaks published the unredacted cables , Ethiopian journalist Argaw Ashine was interrogated several times about a reference to him in a cable talking to a government source. The source told him about plans to arrest the editors of the critical Ethiopian weekly Addis Neger, who fled the country a month after talking to Ashine. Ashine was subjected to government harassment and intimidation, and was forced to flee the country.The U.S. established an Information Review Task Force (IRTF) to investigate the impact of WikiLeaks' publications. In 2013, the task force's head, Brigadier General Robert Carr, testified at Chelsea Manning's sentencing hearing. Carr admitted under questioning from the defence counsel that, despite the resources at its disposal, the task force had found no specific examples of anyone who had lost their life due to WikiLeaks' publication of material provided by Manning. Ed Pilkington wrote in The Guardian that Carr's testimony significantly undermined the argument that WikiLeaks' publications put lives at risk.\n\n\n*** 2011\u20132015 ***\n\nIn late April 2011, files related to the Guantanamo prison were released. In December 2011, WikiLeaks started to release the Spy Files. On 27 February 2012, WikiLeaks began publishing more than five million emails from the Texas-headquartered \"global intelligence\" company Stratfor. On 5 July 2012, WikiLeaks began publishing the Syria Files (emails from Syrian political figures 2006\u20132012). On 25 October 2012, WikiLeaks began publishing The Detainee Policies, files covering the rules and procedures for detainees in US military custody. In April 2013 WikiLeaks published more than 1.7 million US diplomatic and intelligence documents from the 1970s, including the Kissinger cables.\nIn September 2013, WikiLeaks published \"Spy Files 3\", 250 documents from more than 90 surveillance companies. On 13 November 2013, a draft of the Trans-Pacific Partnership's Intellectual Property Rights chapter was published by WikiLeaks. On 10 June 2015, WikiLeaks published the draft on the Trans-Pacific Partnership's Transparency for Healthcare Annex, along with each country's negotiating position. On 19 June 2015 WikiLeaks began publishing The Saudi Cables: more than half a million cables and other documents from the Saudi Foreign Ministry that contain secret communications from various Saudi Embassies around the world.\nIn June and July 2015, WikiLeaks published a series of documents on NSA spying, which showed that NSA spied on the French, German, Brazilian and Japanese governments. The documents also detailed an economic espionage against French companies and associations and extensive monitoring of the Japanese economy and Japanese companies such as Mitsubishi and Mitsui.On 29 July 2015, WikiLeaks published a top secret letter from the Trans-Pacific Partnership Agreement (TPP) Ministerial Meeting in December 2013 which illustrated the position of negotiating countries on \"state-owned enterprises\" (SOEs). On 21 October 2015 WikiLeaks published some of John O. Brennan's emails, including a draft security clearance application which contained personal information.\n\n\n*** 2016 ***\n\nDuring the 2016 US Democratic Party presidential primaries, WikiLeaks hosted emails sent or received by presidential candidate Hillary Clinton from her personal mail server while she was Secretary of State. The emails had been released by the US State Department under a Freedom of information request in February 2016. WikiLeaks also created a search engine to allow the public to search through Clinton's emails. In July 2016, just prior to the publication of the UK government's Iraq Inquiry report, WikiLeaks published a selection of the emails referencing the Iraq War.On 19 July 2016, in response to the Turkish government's purges that followed the coup attempt, WikiLeaks released 294,548 emails from Turkey's ruling Justice and Development party (AKP). According to WikiLeaks, the material, which they claim to be the first batch from the \"AKP Emails\", was obtained a week before the attempted coup in the country and \"is not connected, in any way, to the elements behind the attempted coup, or to a rival political party or state\". After WikiLeaks announced that they would release the emails, the organisation was for over 24 hours under a \"sustained attack\". Following the leak, the Turkish government ordered the site to be blocked nationwide.Most experts and commentators agree that Phineas Fisher was behind the leak. Fisher said WikiLeaks had told her that the emails were \"all spam and crap.\" Fisher asked WikiLeaks not to publish the AKP emails as she was still accessing files on the AKP network. After WikiLeaks published the emails, the AKP shut down its internal network and Fisher lost access.On 22 July 2016, WikiLeaks released approximately 20,000 emails and 8,000 files sent from or received by Democratic National Committee (DNC) personnel. Some of the emails contained personal information of donors, including home addresses and Social Security numbers. Other emails appeared to criticise Bernie Sanders or showed favouritism towards Clinton during the primaries. Emails showed that the DNC shared debate questions with Clinton in advance. In July 2016, Debbie Wasserman Schultz resigned as chairwoman of the Democratic National Committee (DNC) because the emails released by WikiLeaks showed that the DNC was \"effectively an arm of Mrs. Clinton's campaign\" and had conspired to sabotage Bernie Sanders's campaign.On 7 October 2016, WikiLeaks started releasing series of emails and documents sent from or received by Hillary Clinton campaign manager, John Podesta, including Hillary Clinton's paid speeches to banks, including Goldman Sachs. The BBC reported that the release \"is unlikely to allay fears among liberal Democrats that she is too cosy with Wall Street\". According to a spokesman for the Clinton campaign, \"By dribbling these out every day WikiLeaks is proving they are nothing but a propaganda arm of the Kremlin with a political agenda doing Vladimir Putin's dirty work to help elect Donald Trump.\" The New York Times reported that when asked, President Vladimir Putin replied that Russia was being falsely accused. \"The hysteria is merely caused by the fact that somebody needs to divert the attention of the American people from the essence of what was exposed by the hackers.\"On 25 November 2016, WikiLeaks released emails and internal documents that provided details on the US military operations in Yemen from 2009 to March 2015. In a statement accompanying the release of the \"Yemen Files\", Assange said about the US involvement in the Yemen war: \"Although the United States government has provided most of the bombs and is deeply involved in the conduct of the war itself reportage on the war in English is conspicuously rare\".In December 2016, WikiLeaks published over 57,000 emails from Erdogan's son-in-law, Berat Albayrak, who was Turkey's Minister of Energy and Natural Resources. The emails show the inner workings of the Turkish government. According to WikiLeaks, the emails had been first released by Redhack.\n\n\n*** 2017 ***\nOn 16 February 2017, WikiLeaks released a purported report on CIA espionage orders (marked as NOFORN) for the 2012 French presidential election. The order called for details of party funding, internal rivalries and future attitudes toward the United States. The Associated Press noted that \"the orders seemed to represent standard intelligence-gathering.\"On 7 March 2017, WikiLeaks started publishing content code-named \"Vault 7\", describing it as containing CIA internal documentation of their \"massive arsenal\" of hacking tools including malware, viruses, weaponised \"zero day\" exploits and remote control systems. Leaked documents, dated from 2013 to 2016, detail the capabilities of the United States Central Intelligence Agency (CIA) to perform electronic surveillance and cyber warfare, such as the ability to compromise cars, smart TVs, web browsers (including Google Chrome, Microsoft Edge, Mozilla Firefox, and Opera Software ASA), and the operating systems of most smartphones (including Apple's iOS and Google's Android), as well as other operating systems such as Microsoft Windows, macOS, and Linux.In September 2017, WikiLeaks released \"Spy Files Russia,\" revealing \"how a St. Petersburg-based technology company called Peter-Service helped state entities gather detailed data on Russian cellphone users, part of a national system of online surveillance called System for Operative Investigative Activities (SORM).\"\n\n\n*** 2019 ***\nIn November 2019, WikiLeaks released an email from an unnamed investigator from the Organisation for the Prohibition of Chemical Weapons (OPCW) team investigating the 2018 chemical attack in Douma (Syria). The investigator accused the OPCW of covering up discrepancies. Robert Fisk said that documents released by WikiLeaks indicated that the OPCW \"suppressed or failed to publish, or simply preferred to ignore, the conclusions of up to 20 other members of its staff who became so upset at what they regarded as the misleading conclusions of the final report that they officially sought to have it changed in order to represent the truth\". The head of OPCW, Fernando Arias, described the leak as containing \"subjective views\" and stood by the original conclusions.In April 2018, WikiLeaks had offered a $100,000 reward for confidential information about \"the alleged chemical attack in Douma, Syria.\" In a November 2020 interview with BBC, WikiLeaks' alleged source declined to say if he took money from the organisation.On 12 November 2019, WikiLeaks began publishing what it called the Fishrot Files (Icelandic: Samherjaskj\u00f6lin), a collection of thousands of documents and email communication by employees of one of Iceland's largest fish industry companies, Samherji, that indicated that the company had paid hundreds of millions Icelandic kr\u00f3na to high ranking politicians and officials in Namibia with the objective of acquiring the country's coveted fishing quota.\n\n\n*** 2021 ***\nIn 2021, WikiLeaks made a searchable database of 17,000 publicly available documents, which it called The Intolerance Network, from the ultra-conservative Spanish Catholic organisation Hazte Oir and its international arm, CitizenGo. The documents reveal the internal workings of the organisations, their network of donors and their relationship with the Vatican. The release also includes documents from the secret Catholic organisation El Yunque. The editor of WikiLeaks, Kristinn Hrafnsson, said \"As ultra right-wing political groups have gained strength in recent years, with increasing attacks on women's and LGBT rights, it is valuable to have access to documents from those who have lobbied for those changes on a global basis\". According to WikiLeaks, the documents were first released in 2017.\n\n\n*** Authenticity and completeness ***\n\nAccording to The New Yorker, when WikiLeaks posted its first document in December 2006, \"Assange and the others were uncertain of its authenticity, but they thought that readers, using Wikipedia-like features of the site, would help analyse it. ... The document's authenticity was never determined, and news about WikiLeaks quickly superseded the leak itself.\" When someone said they were misidentified in a Julius Baer document as having a secret Swiss bank account Assange and Domscheit-Berg added a caveat to the document saying, \"according to three independent sources\" the information might be false or misleading. Domscheit-Berg says they made up the \"three independent sources\" and that the source had \"included some background information he had researched about the bank's clients\" that misidentified a Swiss account holder as a German man with a similar name.According to Wired in 2009, a \"whistleblower\" submitted fabricated documents to WikiLeaks. The documents were published and flagged by WikiLeaks as potential fakes. According to Daniel Domscheit-Berg, before WikiLeaks started working with media partners most verification of submissions was doing Google searches.WikiLeaks stated in 2010 that it has never released a misattributed document and that documents are assessed before release. In response to concerns about the possibility of misleading or fraudulent leaks, WikiLeaks has stated that misleading leaks \"are already well-placed in the mainstream media. WikiLeaks is of no additional assistance.\" The FAQ in 2010 stated that: \"The simplest and most effective countermeasure is a worldwide community of informed users and editors who can scrutinise and discuss leaked documents.\" According to statements by Assange in 2010, submitted documents were vetted by five reviewers with expertise in different topics such as language or programming, who also investigated the leaker's identity if known. Assange had the final say in document assessment.Columnist Eric Zorn wrote in 2016 \"So far, it's possible, even likely, that every stolen email WikiLeaks has posted has been authentic,\" but cautioned against assuming that future releases would be equally authentic. Writer Glenn Greenwald stated in 2016 that WikiLeaks has a \"perfect, long-standing record of only publishing authentic documents.\" Cybersecurity experts have said that it would be easy for a person to fabricate an email or alter it, as by changing headers and metadata.Some of the releases, including many of the Podesta emails, contain DKIM headers. This allows them to be verified as genuine to some degree of certainty.In July 2016, the Aspen Institute's Homeland Security Group, a bipartisan counterterrorism organisation, warned that hackers who stole authentic data might \"salt the files they release with plausible forgeries.\" According to Douglas Perry, Russian intelligence agencies have frequently used disinformation tactics. He wrote in 2016 that \"carefully faked emails might be included in the WikiLeaks dumps. After all, the best way to make false information believable is to mix it in with true information.\"In September 2016, The Daily Dot reported that WikiLeaks' Syria Files excluded \"records of a \u20ac2 billion transaction between the Syrian regime and a government-owned Russian bank,\" citing court documents.\n\n== Spin-offs ==\nRelease of United States diplomatic cables was followed by the creation of a number of other organisations based on the WikiLeaks model. According to Andy Greenberg there were more than 50 projects inspired by WikiLeaks in 2012, including GreenLeaks, BalkanLeaks, IndoLeaks, BrusselsLeaks and EnviroLeaks. WikiLeaks spokesman Kristinn Hrafnsson responded to the idea positively, saying that having more organisations like WikiLeaks was good.\nOpenLeaks was created by a former WikiLeaks spokesperson. Daniel Domscheit-Berg said the intention was to be more transparent than WikiLeaks. OpenLeaks was supposed to start public operations in early 2011 but despite much media coverage, as of April 2013 it is not operating.\nIn December 2011, WikiLeaks launched Friends of WikiLeaks, a social network for supporters and founders of the website.\nOn 9 September 2013 a number of major Dutch media outlets supported the launch of Publeaks, which provides a secure website for people to leak documents to the media using the GlobaLeaks whistleblowing software.\nRuLeaks was launched in December 2010 to translate and mirror publications by WikiLeaks. In January 2011, it started to publish its own content as well.\nLeakymails is a project designed to obtain and publish relevant documents exposing corruption of the political class and the powerful in Argentina.\nDistributed Denial of Secrets is a whistleblower site founded in 2018. Sometimes referred to as an alternative to WikiLeaks, it's best known for its publication of a large collection of internal police documents, known as BlueLeaks. The site has also published data on Russian oligarchs, fascist groups, shell companies, tax havens, banking in the Caymans and the Parler leak."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is risk acceptance and when is it appropriate to use?",
    "context": "",
    "output": "Risk acceptance is the assumption of all remaining risks by the business as a part of doing business. It is appropriate to use when all other risk options have been considered and found to be unfeasible or too costly.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is risk acceptance and when is it appropriate to use?",
      "answer": "Risk acceptance is the assumption of all remaining risks by the business as a part of doing business. It is appropriate to use when all other risk options have been considered and found to be unfeasible or too costly."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are the legal implications of port scanning activities?",
    "context": "",
    "output": "The legal process for port scanning activities involves proving that an intent to commit a break-in or unauthorized access existed, rather than just the performance of a port scan. Laws regarding port scanning activities vary by country and are subject to criticism by security experts.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are the legal implications of port scanning activities?",
      "answer": "The legal process for port scanning activities involves proving that an intent to commit a break-in or unauthorized access existed, rather than just the performance of a port scan. Laws regarding port scanning activities vary by country and are subject to criticism by security experts."
    }
  },
  {
    "instruction": "Index of cryptography articles\n\n==Introduction==\nArticles related to cryptography include:\n\n\n\n== A ==\nA5/1   \u2022\nA5/2   \u2022\nABA digital signature guidelines   \u2022\nABC (stream cipher)   \u2022\nAbraham Sinkov   \u2022\nAcoustic cryptanalysis   \u2022\nAdaptive chosen-ciphertext attack   \u2022\nAdaptive chosen plaintext and chosen ciphertext attack   \u2022\nAdvantage (cryptography)   \u2022\nADFGVX cipher   \u2022\nAdi Shamir   \u2022\nAdvanced Access Content System   \u2022\nAdvanced Encryption Standard   \u2022\nAdvanced Encryption Standard process   \u2022\nAdversary   \u2022\nAEAD block cipher modes of operation   \u2022\nAffine cipher   \u2022\nAgnes Meyer Driscoll   \u2022\nAKA (security)   \u2022\nAkelarre (cipher)   \u2022\nAlan Turing   \u2022\nAlastair Denniston   \u2022\nAl Bhed language   \u2022\nAlex Biryukov   \u2022\nAlfred Menezes   \u2022\nAlgebraic Eraser   \u2022\nAlgorithmically random sequence   \u2022\nAlice and Bob   \u2022\nAll-or-nothing transform   \u2022\nAlphabetum Kaldeorum   \u2022\nAlternating step generator   \u2022\nAmerican Cryptogram Association   \u2022\nAN/CYZ-10   \u2022\nAnonymous publication   \u2022\nAnonymous remailer   \u2022\nAntoni Palluth   \u2022\nAnubis (cipher)   \u2022\nArgon2   \u2022\nARIA (cipher)   \u2022\nArlington Hall   \u2022\nArne Beurling   \u2022\nArnold Cipher   \u2022\nArray controller based encryption   \u2022\nArthur Scherbius   \u2022\nArvid Gerhard Damm   \u2022\nAsiacrypt   \u2022\nAtbash   \u2022\nAttribute-based encryption   \u2022\nAttack model   \u2022\nAuguste Kerckhoffs   \u2022\nAuthenticated encryption   \u2022\nAuthentication   \u2022\nAuthorization certificate   \u2022\nAutokey cipher   \u2022\nAvalanche effect\n\n== B ==\nB-Dienst   \u2022\nBabington Plot   \u2022\nBaby-step giant-step   \u2022\nBacon's cipher   \u2022\nBanburismus   \u2022\nBart Preneel   \u2022\nBaseKing   \u2022\nBassOmatic   \u2022\nBATON   \u2022\nBB84   \u2022\nBeale ciphers   \u2022\nBEAR and LION ciphers   \u2022\nBeaufort cipher   \u2022\nBeaumanor Hall   \u2022\nBent function   \u2022\nBerlekamp\u2013Massey algorithm   \u2022\nBernstein v. United States   \u2022\nBestCrypt   \u2022\nBiclique attack   \u2022\nBID/60   \u2022\nBID 770   \u2022\nBifid cipher   \u2022\nBill Weisband   \u2022\nBinary Goppa code   \u2022\nBiometric word list   \u2022\nBirthday attack   \u2022\nBit-flipping attack   \u2022\nBitTorrent protocol encryption   \u2022\nBiuro Szyfr\u00f3w   \u2022\nBlack Chamber   \u2022\nBlaise de Vigen\u00e8re   \u2022\nBletchley Park   \u2022\nBlind credential   \u2022\nBlinding (cryptography)   \u2022\nBlind signature   \u2022\nBlock cipher   \u2022\nBlock cipher mode of operation   \u2022\nBlock size (cryptography)   \u2022\nBlowfish (cipher)   \u2022\nBlum Blum Shub   \u2022\nBlum\u2013Goldwasser cryptosystem   \u2022\nBomba (cryptography)   \u2022\nBombe   \u2022\nBook cipher   \u2022\nBooks on cryptography   \u2022\nBoomerang attack   \u2022\nBoris Hagelin   \u2022\nBouncy Castle (cryptography)   \u2022\nBroadcast encryption   \u2022\nBruce Schneier   \u2022\nBrute-force attack   \u2022\nBrute Force: Cracking the Data Encryption Standard   \u2022\nBurrows\u2013Abadi\u2013Needham logic   \u2022\nBurt Kaliski\n\n== C ==\nC2Net   \u2022\nC-36 (cipher machine)   \u2022\nC-52 (cipher machine)   \u2022\nCaesar cipher   \u2022\nCamellia (cipher)   \u2022\nCAPICOM   \u2022\nCapstone (cryptography)   \u2022\nCardan grille   \u2022\nCard catalog (cryptology)   \u2022\nCarlisle Adams   \u2022\nCAST-128   \u2022\nCAST-256   \u2022\nCayley\u2013Purser algorithm   \u2022\nCBC-MAC   \u2022\nCCM mode   \u2022\nCCMP   \u2022\nCD-57   \u2022\nCDMF   \u2022\nCellular Message Encryption Algorithm   \u2022\nCentiban   \u2022\nCentral Security Service   \u2022\nCentre for Applied Cryptographic Research   \u2022\nCentral Bureau   \u2022\nCerticom   \u2022\nCertificate authority   \u2022\nCertificate-based encryption   \u2022\nCertificateless cryptography   \u2022\nCertificate revocation list   \u2022\nCertificate signing request   \u2022\nCertification path validation algorithm   \u2022\nChaffing and winnowing   \u2022\nChallenge-Handshake Authentication Protocol   \u2022\nChallenge\u2013response authentication   \u2022\nChosen-ciphertext attack   \u2022\nChosen-plaintext attack   \u2022\nCIKS-1   \u2022\nCipher disk   \u2022\nCipher runes   \u2022\nCipher security summary   \u2022\nCipherSaber   \u2022\nCiphertext expansion   \u2022\nCiphertext indistinguishability   \u2022\nCiphertext-only attack   \u2022\nCiphertext stealing   \u2022\nCIPHERUNICORN-A   \u2022\nCIPHERUNICORN-E   \u2022\nClassical cipher   \u2022\nClaude Shannon   \u2022\nClaw-free permutation   \u2022\nCleartext   \u2022\nCLEFIA   \u2022\nClifford Cocks   \u2022\nClipper chip   \u2022\nClock (cryptography)   \u2022\nClock drift   \u2022\nCMVP   \u2022\nCOCONUT98   \u2022\nCodebook   \u2022\nCode (cryptography)   \u2022\nCode talker   \u2022\nCodress message   \u2022\nCold boot attack   \u2022\nCollision attack   \u2022\nCollision resistance   \u2022\nColossus computer   \u2022\nCombined Cipher Machine   \u2022\nCommitment scheme   \u2022\nCommon Scrambling Algorithm   \u2022\nCommunications security   \u2022\nCommunications Security Establishment   \u2022\nCommunication Theory of Secrecy Systems   \u2022\nComparison of disk encryption software   \u2022\nComparison of SSH clients   \u2022\nCompleteness (cryptography)   \u2022\nComplexity trap   \u2022\nComputational Diffie\u2013Hellman assumption   \u2022\nComputational hardness assumption   \u2022\nComputer insecurity   \u2022\nComputer and network surveillance   \u2022\nCOMSEC equipment   \u2022\nConch (SSH)   \u2022\nConcrete security   \u2022\nConel Hugh O'Donel Alexander   \u2022\nConfidentiality   \u2022\nConfusion and diffusion   \u2022\nContent-scrambling system   \u2022\nControlled Cryptographic Item   \u2022\nCorkscrew (program)   \u2022\nCorrelation immunity   \u2022\nCOSIC   \u2022\nCovert channel   \u2022\nCover (telecommunications)   \u2022\nCrab (cipher)   \u2022\nCramer\u2013Shoup cryptosystem   \u2022\nCRAM-MD5   \u2022\nCRHF   \u2022\nCrib (cryptanalysis)   \u2022\nCrossCrypt   \u2022\nCrowds (anonymity network)   \u2022\nCrypt (C)   \u2022\nCryptanalysis   \u2022\nCryptanalysis of the Enigma   \u2022\nCryptanalysis of the Lorenz cipher   \u2022\nCryptanalytic computer   \u2022\nCryptex   \u2022\nCryptico   \u2022\nCrypto AG   \u2022\nCrypto-anarchism   \u2022\nCrypto API (Linux)   \u2022\nMicrosoft CryptoAPI   \u2022\nCryptoBuddy   \u2022\nCryptochannel   \u2022\nCRYPTO (conference)   \u2022\nCryptogram   \u2022\nCryptographically Generated Address   \u2022\nCryptographically secure pseudorandom number generator   \u2022\nCryptographically strong   \u2022\nCryptographic Application Programming Interface   \u2022\nCryptographic hash function   \u2022\nCryptographic key types   \u2022\nCryptographic Message Syntax   \u2022\nCryptographic primitive   \u2022\nCryptographic protocol   \u2022\nCryptographic Service Provider   \u2022\nCryptographie ind\u00e9chiffrable   \u2022\nCryptography   \u2022\nCryptography in Japan   \u2022\nCryptography newsgroups   \u2022\nCryptography standards   \u2022\nCrypto: How the Code Rebels Beat the Government\u2014Saving Privacy in the Digital Age   \u2022\nCryptologia   \u2022\nCryptology ePrint Archive   \u2022\nCryptology Research Society of India   \u2022\nCryptomathic   \u2022\nCryptome   \u2022\nCryptomeria cipher   \u2022\nCryptonomicon   \u2022\nCrypTool   \u2022\nCrypto phone   \u2022\nCrypto-society   \u2022\nCryptosystem   \u2022\nCryptovirology   \u2022\nCRYPTREC   \u2022\nCS-Cipher   \u2022\nCurve25519   \u2022 Curve448   \u2022 Custom hardware attack   \u2022\nCycles per byte   \u2022\nCyclometer   \u2022\nCypherpunk   \u2022\nCyrillic Projector\n\n== D ==\nD'Agapeyeff cipher   \u2022\nDaniel J. Bernstein   \u2022\nData Authentication Algorithm   \u2022\nData Encryption Standard   \u2022\nDatagram Transport Layer Security   \u2022\nDavid Chaum   \u2022\nDavid Kahn   \u2022\nDavid Naccache   \u2022\nDavid Wagner   \u2022\nDavid Wheeler (computer scientist)   \u2022\nDavies attack   \u2022\nDavies\u2013Meyer hash   \u2022\nDEAL   \u2022\nDecipherment   \u2022\nDecisional Diffie\u2013Hellman assumption   \u2022\nDecorrelation theory   \u2022\nDecrypt   \u2022\nDeCSS   \u2022\nDefence Signals Directorate   \u2022\nDegree of anonymity   \u2022\nDelegated Path Discovery   \u2022\nDelegated Path Validation   \u2022\nDeniable encryption   \u2022\nDerek Taunt   \u2022\nDerived unique key per transaction   \u2022\nDES Challenges   \u2022\nDES supplementary material   \u2022\nDES-X   \u2022\nDeterministic encryption   \u2022\nDFC (cipher)   \u2022\nDictionary attack   \u2022\nDifferential cryptanalysis   \u2022\nDifferential-linear attack   \u2022\nDifferential power analysis   \u2022\nDiffie\u2013Hellman key exchange   \u2022\nDiffie\u2013Hellman problem   \u2022\nDigiCipher 2   \u2022\nDigital Fortress   \u2022\nDigital rights management   \u2022\nDigital signature   \u2022\nDigital Signature Algorithm   \u2022\nDigital signature forgery   \u2022\nDigital timestamping   \u2022\nDigital watermarking   \u2022\nDilly Knox   \u2022\nDining cryptographers problem   \u2022\nDiplomatic bag   \u2022\nDirect Anonymous Attestation   \u2022\nDiscrete logarithm   \u2022\nDisk encryption   \u2022\nDisk encryption hardware   \u2022\nDisk encryption software   \u2022\nDistance-bounding protocol   \u2022\nDistinguishing attack   \u2022\nDistributed.net   \u2022\nDMA attack   \u2022\ndm-crypt   \u2022\nDmitry Sklyarov   \u2022\nDomainKeys   \u2022\nDon Coppersmith   \u2022\nDorabella Cipher   \u2022\nDouble Ratchet Algorithm   \u2022\nDoug Stinson   \u2022\nDragon (cipher)   \u2022\nDRYAD   \u2022\nDual_EC_DRBG   \u2022\n\n== E ==\nE0 (cipher)   \u2022\nE2 (cipher)   \u2022\nE4M   \u2022\nEAP-AKA   \u2022\nEAP-SIM   \u2022\nEAX mode   \u2022\nECC patents   \u2022\nECHELON   \u2022\nECRYPT   \u2022\nEdouard Fleissner von Wostrowitz   \u2022\nEdward Hebern   \u2022\nEdward Scheidt   \u2022\nEdward Travis   \u2022\nEFF DES cracker   \u2022\nEfficient Probabilistic Public-Key Encryption Scheme   \u2022\nEKMS   \u2022\nElectronic Communications Act 2000   \u2022\nElectronic money   \u2022\nElectronic signature   \u2022\nElectronic voting   \u2022\nElGamal encryption   \u2022\nElGamal signature scheme   \u2022\nEli Biham   \u2022\nElizebeth Friedman   \u2022\nElliptic-curve cryptography   \u2022\nElliptic-curve Diffie\u2013Hellman   \u2022\nElliptic Curve DSA   \u2022 EdDSA   \u2022 Elliptic curve only hash   \u2022\nElonka Dunin   \u2022\nEncrypted function   \u2022\nEncrypted key exchange   \u2022\nEncrypting File System   \u2022\nEncryption   \u2022\nEncryption software   \u2022\nEnigmail   \u2022\nEnigma machine   \u2022\nEnigma rotor details   \u2022\nEntrust   \u2022\nErnst Fetterlein   \u2022\neSTREAM   \u2022\n\u00c9tienne Bazeries   \u2022\nEurocrypt   \u2022\nEuroCrypt   \u2022\nExport of cryptography   \u2022\nExtensible Authentication Protocol\n\n== F ==\nFast Software Encryption   \u2022\nFast syndrome-based hash   \u2022\nFEA-M   \u2022\nFEAL   \u2022\nFeige\u2013Fiat\u2013Shamir identification scheme   \u2022\nFeistel cipher   \u2022\nF\u00e9lix Delastelle   \u2022\nFialka   \u2022\nFilesystem-level encryption   \u2022\nFileVault   \u2022\nFill device   \u2022\nFinancial cryptography   \u2022\nFIPS 140   \u2022\nFIPS 140-2   \u2022\nFirefly (key exchange protocol)   \u2022\nFISH (cipher)   \u2022\nFish (cryptography)   \u2022\nFloradora   \u2022\nFluhrer, Mantin and Shamir attack   \u2022\nFormat-preserving encryption   \u2022\nFortezza   \u2022\nFort George G. Meade   \u2022\nFortuna (PRNG)   \u2022\nFour-square cipher   \u2022\nFranciszek Pokorny   \u2022\nFrank A. Stevenson   \u2022\nFrank Rowlett   \u2022\nFreenet   \u2022\nFreeOTFE   \u2022\nFreeS/WAN   \u2022\nFrequency analysis   \u2022\nFriedrich Kasiski   \u2022\nFritz-chip   \u2022\nFROG   \u2022\nFROSTBURG   \u2022\nFTP over SSH   \u2022\nFull disk encryption   \u2022\nFull Domain Hash   \u2022\nF. W. Winterbotham\n\n== G ==\nGalois/Counter Mode   \u2022\nGardening (cryptanalysis)   \u2022\nGCHQ Bude   \u2022\nGCHQ CSO Morwenstow   \u2022\nGDES   \u2022\nGeneric Security Services Application Program Interface   \u2022\nGeorge Blakley   \u2022\nGeorge Scovell   \u2022\nGGH encryption scheme   \u2022\nGGH signature scheme   \u2022\nGilbert Vernam   \u2022\nGMR (cryptography)   \u2022\nGNU Privacy Guard   \u2022\nGnuTLS   \u2022\nGoldwasser\u2013Micali cryptosystem   \u2022\nGordon Welchman   \u2022\nGOST (block cipher)   \u2022\nGOST (hash function)   \u2022\nGovernment Communications Headquarters   \u2022\nGovernment Communications Security Bureau   \u2022\nGrain (cipher)   \u2022\nGrand Cru (cipher)   \u2022\nGreat Cipher   \u2022\nGrill (cryptology)   \u2022\nGrille (cryptography)   \u2022\nGroup-based cryptography   \u2022\nGroup signature   \u2022\nGrover's algorithm   \u2022\nGustave Bertrand   \u2022\nGwido Langer\n\n== H ==\nH.235   \u2022\nHAIFA construction   \u2022\nHAIPE   \u2022\nHans Dobbertin   \u2022\nHans-Thilo Schmidt   \u2022\nHard-core predicate   \u2022\nHardware random number generator   \u2022\nHardware security module   \u2022\nHarold Keen   \u2022\nHarry Hinsley   \u2022\nHarvest (computer)   \u2022\nHAS-160   \u2022\nHash-based cryptography   \u2022\nHashcash   \u2022\nHash chain   \u2022\nHash function security summary   \u2022\nHash list   \u2022\nHasty Pudding cipher   \u2022\nHAVAL   \u2022\nHC-256   \u2022\nHC-9   \u2022\nHeath Robinson (codebreaking machine)   \u2022\nHebern rotor machine   \u2022\nHenri Braqueni\u00e9   \u2022\nHenryk Zygalski   \u2022\nHerbert Yardley   \u2022\nHidden Field Equations   \u2022\nHideki Imai   \u2022\nHierocrypt   \u2022\nHigh-bandwidth Digital Content Protection   \u2022\nHigher-order differential cryptanalysis   \u2022\nHill cipher   \u2022\nHistory of cryptography   \u2022\nHMAC   \u2022\nHMAC-based One-time Password algorithm   (HOTP) \u2022\nHorst Feistel   \u2022\nHoward Heys   \u2022\nHttps   \u2022\nHugo Hadwiger   \u2022\nHugo Koch   \u2022\nHushmail   \u2022\nHut 6   \u2022\nHut 8   \u2022\nHX-63   \u2022\nHybrid cryptosystem   \u2022\nHyperelliptic curve cryptography   \u2022\nHyper-encryption\n\n== I ==\nIan Goldberg   \u2022\nIBM 4758   \u2022\nICE (cipher)   \u2022\nID-based cryptography   \u2022\nIDEA NXT   \u2022\nIdentification friend or foe   \u2022\nIEEE 802.11i   \u2022\nIEEE P1363   \u2022\nI. J. Good   \u2022\nIllegal prime   \u2022\nImpossible differential cryptanalysis   \u2022\nIndex of coincidence   \u2022\nIndifferent chosen-ciphertext attack   \u2022\nIndistinguishability obfuscation   \u2022\nIndocrypt   \u2022\nInformation leakage   \u2022\nInformation Security Group   \u2022\nInformation-theoretic security   \u2022\nInitialization vector   \u2022\nInteger factorization   \u2022\nIntegral cryptanalysis   \u2022\nIntegrated Encryption Scheme   \u2022\nIntegrated Windows Authentication   \u2022\nInterlock protocol   \u2022\nIntermediate certificate authorities   \u2022\nInternational Association for Cryptologic Research   \u2022\nInternational Data Encryption Algorithm   \u2022\nInternet Key Exchange   \u2022\nInternet Security Association and Key Management Protocol   \u2022\nInterpolation attack   \u2022\nInvisible ink   \u2022\nIPsec   \u2022\nIraqi block cipher   \u2022\nISAAC (cipher)   \u2022\nISO 19092-2   \u2022\nISO/IEC 9797   \u2022\nIvan Damg\u00e5rd\n\n== J ==\nJacques Stern   \u2022\nJADE (cypher machine)   \u2022\nJames Gillogly   \u2022\nJames H. Ellis   \u2022\nJames Massey   \u2022\nJan Grali\u0144ski   \u2022\nJan Kowalewski   \u2022\nJapanese naval codes   \u2022\nJava Cryptography Architecture   \u2022\nJefferson disk   \u2022\nJennifer Seberry   \u2022\nJerzy R\u00f3\u017cycki   \u2022\nJoan Daemen   \u2022\nJohannes Trithemius   \u2022\nJohn Herivel   \u2022\nJohn Kelsey (cryptanalyst)   \u2022\nJohn R. F. Jeffreys   \u2022\nJohn Tiltman   \u2022\nJon Lech Johansen   \u2022\nJosef Pieprzyk   \u2022\nJoseph Desch   \u2022\nJoseph Finnegan (cryptographer)   \u2022\nJoseph Mauborgne   \u2022\nJoseph Rochefort   \u2022\nJournal of Cryptology   \u2022\nJunger v. Daley\n\n== K ==\nKaisa Nyberg   \u2022\nKalyna (cipher)   \u2022\nKasiski examination   \u2022\nKASUMI   \u2022\nKCDSA   \u2022\nKeePass   \u2022\nKerberos (protocol)   \u2022\nKerckhoffs's principle   \u2022\nKevin McCurley (cryptographer)   \u2022\nKey-agreement protocol   \u2022\nKey authentication   \u2022\nKey clustering   \u2022\nKey (cryptography)   \u2022\nKey derivation function   \u2022\nKey distribution center   \u2022\nKey escrow   \u2022\nKey exchange   \u2022\nKeyfile   \u2022\nKey generation   \u2022\nKey generator   \u2022\nKey management   \u2022\nKey-recovery attack   \u2022\nKey schedule   \u2022\nKey server (cryptographic)   \u2022\nKey signature (cryptography)   \u2022\nKeysigning   \u2022\nKey signing party   \u2022\nKey size   \u2022\nKey space (cryptography)   \u2022\nKeystream   \u2022\nKey stretching   \u2022\nKey whitening   \u2022\nKG-84   \u2022\nKHAZAD   \u2022\nKhufu and Khafre   \u2022\nKiss (cryptanalysis)   \u2022\nKL-43   \u2022\nKL-51   \u2022\nKL-7   \u2022\nKleptography   \u2022\nKN-Cipher   \u2022\nKnapsack problem   \u2022\nKnown-key distinguishing attack   \u2022\nKnown-plaintext attack   \u2022\nKnownSafe   \u2022\nKOI-18   \u2022\nKOV-14   \u2022\nKryha   \u2022\nKryptos   \u2022\nKSD-64   \u2022\nKupyna   \u2022\nKuznyechik   \u2022\nKW-26   \u2022\nKW-37   \u2022\nKY-3   \u2022\nKY-57   \u2022\nKY-58   \u2022\nKY-68   \u2022\nKYK-13\n\n== L ==\nLacida   \u2022\nLadder-DES   \u2022\nLamport signature   \u2022\nLars Knudsen   \u2022\nLattice-based cryptography   \u2022\nLaurance Safford   \u2022\nLawrie Brown   \u2022\nLCS35   \u2022\nLeo Marks   \u2022\nLeonard Adleman   \u2022\nLeon Battista Alberti   \u2022\nLeo Rosen   \u2022\nLeslie Yoxall   \u2022\nLEVIATHAN (cipher)   \u2022\nLEX (cipher)   \u2022\nLibelle (cipher)   \u2022\nLinear cryptanalysis   \u2022\nLinear-feedback shift register   \u2022\nLink encryption   \u2022\nList of ciphertexts   \u2022\nList of cryptographers   \u2022\nList of cryptographic file systems   \u2022\nList of cryptographic key types   \u2022\nList of cryptology conferences   \u2022\nList of telecommunications encryption terms   \u2022 List of people associated with Bletchley Park \u2022 \n  List of SFTP clients   \u2022\nList of SFTP server software   \u2022\nLOKI   \u2022\nLOKI97   \u2022\nLorenz cipher   \u2022\nLouis W. Tordella   \u2022\nLsh   \u2022\nLucifer (cipher)   \u2022\nLyra2\n\n== M ==\nM6 (cipher)   \u2022\nM8 (cipher)   \u2022\nM-209   \u2022\nM-325   \u2022\nM-94   \u2022\nMacGuffin (cipher)   \u2022\nMadryga   \u2022\nMAGENTA   \u2022\nMagic (cryptography)   \u2022\nMaksymilian Ci\u0119\u017cki   \u2022\nMalcolm J. Williamson   \u2022\nMalleability (cryptography)   \u2022\nMan-in-the-middle attack   \u2022\nMarian Rejewski   \u2022\nMARS (cryptography)   \u2022\nMartin Hellman   \u2022\nMaruTukku   \u2022\nMassey\u2013Omura cryptosystem   \u2022\nMatt Blaze   \u2022\nMatt Robshaw   \u2022\nMax Newman   \u2022\nMcEliece cryptosystem   \u2022\nmcrypt   \u2022\nMD2 (cryptography)   \u2022\nMD4   \u2022\nMD5   \u2022\nMD5CRK   \u2022\nMDC-2   \u2022\nMDS matrix   \u2022\nMean shortest distance   \u2022\nMeet-in-the-middle attack   \u2022\nMental poker   \u2022\nMercury (cipher machine)   \u2022\nMercy (cipher)   \u2022\nMeredith Gardner   \u2022\nMerkle signature scheme   \u2022\nMerkle\u2013Damg\u00e5rd construction   \u2022\nMerkle\u2013Hellman knapsack cryptosystem   \u2022\nMerkle's Puzzles   \u2022\nMerkle tree   \u2022\nMESH (cipher)   \u2022\nMessage authentication   \u2022\nMessage authentication code   \u2022\nMessage forgery   \u2022\nMI8   \u2022\nMichael Luby   \u2022\nMICKEY   \u2022\nMicrodot   \u2022\nMilitary Cryptanalysis (book) (William F. Friedman)   \u2022\nMilitary Cryptanalytics   \u2022\nMimic function   \u2022\nMirror writing   \u2022\nMISTY1   \u2022\nMitsuru Matsui   \u2022\nMMB (cipher)   \u2022\nMod n cryptanalysis   \u2022\nMQV   \u2022\nMS-CHAP   \u2022\nMUGI   \u2022\nMULTI-S01   \u2022\nMultiSwap   \u2022\nMultivariate cryptography\n\n== N ==\nNational Communications Centre   \u2022\nNational Cryptologic Museum   \u2022\nNational Security Agency   \u2022\nNational Cipher Challenge   \u2022\nNavajo I   \u2022\nNeal Koblitz   \u2022\nNeedham\u2013Schroeder protocol   \u2022\nNegligible function   \u2022\nNEMA (machine)   \u2022\nNESSIE   \u2022\nNetwork Security Services   \u2022\nNeural cryptography   \u2022\nNew Data Seal   \u2022\nNewDES   \u2022\nN-Hash   \u2022\nNicolas Courtois   \u2022\nNiederreiter cryptosystem   \u2022\nNiels Ferguson   \u2022\nNigel de Grey   \u2022\nNihilist cipher   \u2022\nNikita Borisov   \u2022\nNimbus (cipher)   \u2022\nNIST hash function competition   \u2022\nNonlinear-feedback shift register   \u2022\nNOEKEON   \u2022\nNon-malleable codes   \u2022\nNoreen   \u2022\nNothing up my sleeve number   \u2022\nNSA cryptography   \u2022\nNSA encryption systems   \u2022\nNSA in fiction   \u2022\nNSAKEY   \u2022\nNSA Suite A Cryptography   \u2022\nNSA Suite B Cryptography   \u2022\nNT LAN Manager   \u2022\nNTLMSSP   \u2022\nNTRUEncrypt   \u2022\nNTRUSign   \u2022\nNull cipher   \u2022\nNumbers station   \u2022\nNUSH   \u2022\nNTRU\n\n== O ==\nOblivious transfer   \u2022\nOCB mode   \u2022\nOded Goldreich   \u2022\nOff-the-Record Messaging   \u2022\nOkamoto\u2013Uchiyama cryptosystem   \u2022\nOMI cryptograph   \u2022\nOMNI (SCIP)   \u2022\nOne-key MAC   \u2022\nOne-time pad   \u2022\nOne-time password   \u2022\nOne-way compression function   \u2022\nOne-way function   \u2022\nOnion routing   \u2022\nOnline Certificate Status Protocol   \u2022\nOP-20-G   \u2022\nOpenPGP card   \u2022\nOpenSSH   \u2022\nOpenSSL   \u2022\nOpenswan   \u2022\nOpenVPN   \u2022\nOperation Ruthless   \u2022\nOptimal asymmetric encryption padding   \u2022\nOver the Air Rekeying   (OTAR) \u2022\nOTFE   \u2022\nOtway\u2013Rees protocol\n\n== P ==\nPadding (cryptography)   \u2022\nPadding oracle attack    \u2022\nPaillier cryptosystem   \u2022\nPairing-based cryptography   \u2022\nPanama (cryptography)   \u2022\nPartitioning cryptanalysis   \u2022\nPassive attack   \u2022\nPassphrase   \u2022\nPassword   \u2022\nPassword-authenticated key agreement   \u2022\nPassword cracking   \u2022\nPassword Hashing Competition   \u2022\nPaul Kocher   \u2022\nPaulo Pancatuccio   \u2022\nPaulo S. L. M. Barreto   \u2022\nPaul van Oorschot   \u2022\nPBKDF2   \u2022\nPC Bruno   \u2022\nPepper (cryptography)   \u2022\nPerfect forward secrecy   \u2022\nPerforated sheets   \u2022\nPermutation cipher   \u2022\nPeter Gutmann (computer scientist)   \u2022\nPeter Junger   \u2022\nPeter Twinn   \u2022\nPGP Corporation   \u2022\nPGPDisk   \u2022\nPGPfone   \u2022\nPhelix   \u2022\nPhil Zimmermann   \u2022\nPhoturis (protocol)   \u2022\nPhysical security   \u2022\nPhysical unclonable function   \u2022\nPig Latin   \u2022\nPigpen cipher   \u2022\nPike (cipher)   \u2022\nPiling-up lemma   \u2022\nPinwheel (cryptography)   \u2022\nPiotr Smole\u0144ski   \u2022\nPirate decryption   \u2022\nPKC (conference)   \u2022\nPKCS   \u2022\nPKCS 11   \u2022\nPKCS 12   \u2022\nPKIX   \u2022\nPlaintext   \u2022\nPlaintext-aware encryption   \u2022\nPlayfair cipher   \u2022\nPlugboard   \u2022\nPMAC (cryptography)   \u2022\nPoem code   \u2022\nPohlig\u2013Hellman algorithm   \u2022\nPoint-to-Point Tunneling Protocol   \u2022\nPointcheval\u2013Stern signature algorithm   \u2022\nPoly1305   \u2022\nPolyalphabetic cipher   \u2022\nPolybius square   \u2022\nPortex   \u2022\nPost-quantum cryptography   \u2022\nPost-Quantum Cryptography Standardization   \u2022\nPower analysis   \u2022\nPreimage attack   \u2022\nPre-shared key   \u2022\nPretty Good Privacy   \u2022\nPrinter steganography   \u2022\nPrivacy-enhanced Electronic Mail   \u2022\nPrivate Communications Technology   \u2022\nPrivate information retrieval   \u2022\nProbabilistic encryption   \u2022\nProduct cipher   \u2022\nProof-of-work system   \u2022\nProtected Extensible Authentication Protocol   \u2022\nProvable security   \u2022\nProvably secure cryptographic hash function   \u2022\nProxy re-encryption   \u2022\nPseudo-Hadamard transform   \u2022\nPseudonymity   \u2022\nPseudorandom function   \u2022\nPseudorandom number generator   \u2022\nPseudorandom permutation   \u2022\nPublic key certificate   \u2022\nPublic-key cryptography   \u2022\nPublic key fingerprint   \u2022\nPublic key infrastructure   \u2022\nPURPLE   \u2022\nPuTTY   \u2022\nPy (cipher)\n\n== Q ==\nQ (cipher)   \u2022\nQrpff   \u2022\nQUAD (cipher)   \u2022\nQuadratic sieve   \u2022\nQuantum coin flipping   \u2022\nQuantum cryptography   \u2022\nQuantum digital signature   \u2022\nQuantum fingerprinting   \u2022\nQuantum key distribution\n\n== R ==\nRabbit (cipher)   \u2022\nRabin cryptosystem   \u2022\nRabin\u2013Williams encryption   \u2022\nRadioGat\u00fan   \u2022\nRail fence cipher   \u2022\nRainbow table   \u2022\nRalph Merkle   \u2022\nRambutan (cryptography)   \u2022\nRandom function   \u2022\nRandomness tests   \u2022\nRandom number generator attack   \u2022\nRandom oracle   \u2022\nRC2   \u2022\nRC4   \u2022\nRC5   \u2022\nRC6   \u2022\nRebound attack   \u2022\nReciprocal cipher   \u2022\nRed/black concept   \u2022\nREDOC   \u2022\nRed Pike (cipher)   \u2022\nReflector (cipher machine)   \u2022\nRegulation of Investigatory Powers Act 2000   \u2022\nReihenschieber   \u2022\nRekeying (cryptography)   \u2022\nRelated-key attack   \u2022\nReplay attack   \u2022\nReservehandverfahren   \u2022\nResidual block termination   \u2022\nRijndael key schedule   \u2022\nRijndael S-box   \u2022\nRing signature   \u2022\nRIPEMD   \u2022\nRip van Winkle cipher   \u2022\nRobert Morris (cryptographer)   \u2022\nRobot certificate authority   \u2022\nRockex   \u2022\nRolf Noskwith   \u2022\nRon Rivest   \u2022\nRoom 40   \u2022\nRoot certificate   \u2022\nRoss J. Anderson   \u2022\nRossignols   \u2022\nROT13   \u2022\nRotor machine   \u2022\nRSA RSA \u2022\nRSA-100   \u2022\nRSA-1024   \u2022\nRSA-110   \u2022\nRSA-120   \u2022\nRSA-129   \u2022\nRSA-130   \u2022\nRSA-140   \u2022\nRSA-150   \u2022\nRSA-1536   \u2022\nRSA-155   \u2022\nRSA-160   \u2022\nRSA-170   \u2022\nRSA-180   \u2022\nRSA-190   \u2022\nRSA-200   \u2022\nRSA-2048   \u2022\nRSA-210   \u2022\nRSA-220   \u2022\nRSA-230   \u2022\nRSA-232   \u2022\nRSA-240   \u2022\nRSA-250   \u2022\nRSA-260   \u2022\nRSA-270   \u2022\nRSA-280   \u2022\nRSA-290   \u2022\nRSA-300   \u2022\nRSA-309   \u2022\nRSA-310   \u2022\nRSA-320   \u2022\nRSA-330   \u2022\nRSA-340   \u2022\nRSA-350   \u2022\nRSA-360   \u2022\nRSA-370   \u2022\nRSA-380   \u2022\nRSA-390   \u2022\nRSA-400   \u2022\nRSA-410   \u2022\nRSA-420   \u2022\nRSA-430   \u2022\nRSA-440   \u2022\nRSA-450   \u2022\nRSA-460   \u2022\nRSA-470   \u2022\nRSA-480   \u2022\nRSA-490   \u2022\nRSA-500   \u2022\nRSA-576   \u2022\nRSA-617   \u2022\nRSA-640   \u2022\nRSA-704   \u2022\nRSA-768   \u2022\nRSA-896   \u2022\nRSA-PSS   \u2022\nRSA Factoring Challenge   \u2022\nRSA problem   \u2022\nRSA Secret-Key Challenge   \u2022\nRSA Security   \u2022\nRubber-hose cryptanalysis   \u2022\nRunning key cipher   \u2022\nRussian copulation\n\n== S ==\nS-1 block cipher   \u2022\nSAFER   \u2022\nSalsa20   \u2022\nSalt (cryptography)   \u2022\nSAM card   \u2022\nSecurity Support Provider Interface   \u2022\nSAML   \u2022\nSAVILLE   \u2022\nSC2000   \u2022\nSchnorr group   \u2022\nSchnorr signature   \u2022\nSchoof\u2013Elkies\u2013Atkin algorithm   \u2022\nSCIP   \u2022\nScott Vanstone   \u2022\nScrambler   \u2022\nScramdisk   \u2022\nScream (cipher)   \u2022\nScrypt   \u2022\nScytale   \u2022\nSeahorse (software)   \u2022\nSEAL (cipher)   \u2022\nSean Murphy (cryptographer)   \u2022\nSECG   \u2022\nSecret broadcast   \u2022\nSecret decoder ring   \u2022\nSecrets and Lies (Schneier)   \u2022\nSecret sharing   \u2022\nSect\u00e9ra Secure Module   \u2022\nSecure access module   \u2022\nSecure channel   \u2022\nSecure Communication based on Quantum Cryptography   \u2022\nSecure copy   \u2022\nSecure cryptoprocessor   \u2022\nSecure Electronic Transaction   \u2022\nSecure Hash Algorithms   \u2022\nSecure Hypertext Transfer Protocol   \u2022\nSecure key issuing cryptography   \u2022\nSecure multi-party computation   \u2022\nSecure Neighbor Discovery   \u2022\nSecure Real-time Transport Protocol   \u2022\nSecure remote password protocol   \u2022\nSecure Shell   \u2022\nSecure telephone   \u2022\nSecure Terminal Equipment   \u2022\nSecure voice   \u2022\nSecurID   \u2022\nSecurity association   \u2022\nSecurity engineering   \u2022\nSecurity level   \u2022\nSecurity parameter   \u2022\nSecurity protocol notation   \u2022\nSecurity through obscurity   \u2022\nSecurity token   \u2022\nSEED   \u2022\nSelected Areas in Cryptography   \u2022\nSelf-certifying File System   \u2022\nSelf-shrinking generator   \u2022\nSelf-signed certificate   \u2022\nSemantic security   \u2022\nSerge Vaudenay   \u2022\nSerpent (cipher)   \u2022\nSession key   \u2022\nSHACAL   \u2022\nShafi Goldwasser   \u2022\nSHA-1   \u2022\nSHA-2   \u2022\nSHA-3   \u2022\nShared secret   \u2022\nSHARK   \u2022\nShaun Wylie   \u2022\nShor's algorithm   \u2022\nShrinking generator   \u2022\nShugborough inscription   \u2022\nSide-channel attack   \u2022\nSiemens and Halske T52   \u2022\nSIGABA   \u2022\nSIGCUM   \u2022\nSIGINT   \u2022\nSignal Protocol   \u2022\nSignal Intelligence Service   \u2022\nSigncryption   \u2022\nSIGSALY   \u2022\nSILC (protocol)   \u2022\nSilvio Micali   \u2022\nSimple Authentication and Security Layer   \u2022\nSimple public-key infrastructure   \u2022\nSimple XOR cipher   \u2022\nS/KEY   \u2022\nSkein (hash function)   \u2022\nSkipjack (cipher)   \u2022\nSlide attack   \u2022\nSlidex   \u2022\nSmall subgroup confinement attack   \u2022\nS/MIME   \u2022\nSM4 algorithm   (formerly SMS4) \u2022\nSnake oil (cryptography)   \u2022\nSnefru   \u2022\nSNOW   \u2022\nSnuffle   \u2022\nSOBER-128   \u2022\nSolitaire (cipher)   \u2022\nSolomon Kullback   \u2022\nSOSEMANUK   \u2022\nSpecial Collection Service   \u2022\nSpectr-H64   \u2022\nSPEKE (cryptography)   \u2022\nSponge function   \u2022\nSPNEGO   \u2022\nSquare (cipher)   \u2022\nSsh-agent   \u2022 Ssh-keygen   \u2022 SSH File Transfer Protocol   \u2022\nSSLeay   \u2022\nStafford Tavares   \u2022\nStandard model (cryptography)   \u2022\nStation CAST   \u2022\nStation HYPO   \u2022\nStation-to-Station protocol   \u2022\nStatistical cryptanalysis   \u2022\nStefan Lucks   \u2022\nSteganalysis   \u2022\nSteganography   \u2022\nStraddling checkerboard   \u2022\nStream cipher   \u2022\nStream cipher attacks   \u2022\nStrong cryptography   \u2022\nStrong RSA assumption   \u2022\nStuart Milner-Barry   \u2022\nSTU-II   \u2022\nSTU-III   \u2022\nStunnel   \u2022\nSubstitution box   \u2022\nSubstitution cipher   \u2022\nSubstitution\u2013permutation network   \u2022\nSuperencryption   \u2022\nSupersingular isogeny key exchange   \u2022\nSwedish National Defence Radio Establishment   \u2022\nSWIFFT   \u2022\nSXAL/MBAL   \u2022\nSymmetric-key algorithm   \u2022\nSYSKEY\n\n== T ==\nTabula recta   \u2022\nTaher Elgamal   \u2022\nTamper resistance   \u2022\nTcpcrypt   \u2022\nTelevision encryption   \u2022\nTEMPEST   \u2022\nTemplate:Cryptographic software   \u2022\nTemporal Key Integrity Protocol   \u2022\nTestery   \u2022\nThawte   \u2022\nThe Alphabet Cipher   \u2022\nThe Code Book   \u2022\nThe Codebreakers   \u2022\nThe Gold-Bug   \u2022\nThe Magic Words are Squeamish Ossifrage   \u2022\nTheory of Cryptography Conference   \u2022\nThe world wonders   \u2022\nThomas Jakobsen   \u2022\nThree-pass protocol   \u2022\nThreshold shadow scheme   \u2022\nTICOM   \u2022\nTiger (cryptography)   \u2022\nTimeline of cryptography   \u2022\nTime/memory/data tradeoff attack   \u2022\nTime-based One-time Password algorithm   (TOTP) \u2022\nTiming attack   \u2022\nTiny Encryption Algorithm   \u2022\nTom Berson   \u2022\nTommy Flowers   \u2022\nTopics in cryptography   \u2022\nTor (anonymity network)   \u2022\nTorus-based cryptography   \u2022\nTraffic analysis   \u2022\nTraffic-flow security   \u2022\nTraitor tracing   \u2022\nTransmission security   \u2022\nTransport Layer Security   \u2022\nTransposition cipher   \u2022\nTrapdoor function   \u2022\nTrench code   \u2022\nTreyfer   \u2022\nTrifid cipher   \u2022\nTriple DES   \u2022\nTrivium (cipher)   \u2022\nTrueCrypt   \u2022\nTruncated differential cryptanalysis   \u2022\nTrusted third party   \u2022\nTuring (cipher)   \u2022\nTWINKLE   \u2022\nTWIRL   \u2022\nTwofish   \u2022\nTwo-square cipher   \u2022\nType 1 encryption   \u2022\nType 2 encryption   \u2022\nType 3 encryption   \u2022\nType 4 encryption   \u2022\nTypex\n\n== U ==\nUES (cipher)   \u2022\nUltra   \u2022\nUMAC   \u2022\nUnbalanced Oil and Vinegar   \u2022\nUndeniable signature   \u2022\nUnicity distance   \u2022\nUniversal composability   \u2022\nUniversal one-way hash function   (UOWHF)\n\n== V ==\nVenona project   \u2022\nVerifiable secret sharing   \u2022\nVerisign   \u2022\nVery smooth hash   \u2022\nVEST   \u2022\nVIC cipher   \u2022\nVideoCrypt   \u2022\nVigen\u00e8re cipher   \u2022\nVincent Rijmen   \u2022\nVINSON   \u2022\nVirtual private network   \u2022\nVisual cryptography   \u2022\nVoynich manuscript\n\n== W ==\nWadsworth's cipher   \u2022\nWAKE   \u2022\nWLAN Authentication and Privacy Infrastructure   \u2022\nWatermark (data file)   \u2022\nWatermarking attack   \u2022\nWeak key   \u2022\nWeb of trust   \u2022\nWhirlpool (hash function)   \u2022\nWhitfield Diffie   \u2022\nWide Mouth Frog protocol   \u2022\nWi-Fi Protected Access   \u2022\nWilliam F. Friedman   \u2022\nWilliam Montgomery (cryptographer)   \u2022\nWinSCP   \u2022\nWired Equivalent Privacy   \u2022\nWireless Transport Layer Security   \u2022\nWitness-indistinguishable proof   \u2022\nWorkshop on Cryptographic Hardware and Embedded Systems   \u2022\nWorld War I cryptography   \u2022\nWorld War II cryptography   \u2022\nW. T. Tutte\n\n== X ==\nX.509   \u2022\nXDH assumption   \u2022\nXiaoyun Wang   \u2022\nXML Encryption   \u2022\nXML Signature   \u2022\nxmx   \u2022\nXSL attack   \u2022\nXTEA   \u2022\nXTR   \u2022\nXuejia Lai   \u2022\nXXTEA  \n10-00-00-00-00\n\n== Y ==\nYarrow algorithm   \u2022\nY-stations   \u2022\nYuliang Zheng\n\n== Z ==\nZeroisation   \u2022\nZero-knowledge password proof   \u2022\nZero-knowledge proof   \u2022\nZfone   \u2022\nZodiac (cipher)   \u2022\nZRTP   \u2022\nZimmermann\u2013Sassaman key-signing protocol   \u2022\nZimmermann Telegram\n\nAnswer this question based on the above context: Which encryption algorithm was broken in 1977 by a team led by Don Coppersmith at IBM using a special-purpose machine called the DES Cracker?",
    "context": "",
    "output": "The Data Encryption Standard (DES) was broken in 1977 by a team led by Don Coppersmith at IBM using a special-purpose machine called the DES Cracker.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Which encryption algorithm was broken in 1977 by a team led by Don Coppersmith at IBM using a special-purpose machine called the DES Cracker?",
      "answer": "The Data Encryption Standard (DES) was broken in 1977 by a team led by Don Coppersmith at IBM using a special-purpose machine called the DES Cracker.",
      "context": "Index of cryptography articles\n\n==Introduction==\nArticles related to cryptography include:\n\n\n\n== A ==\nA5/1   \u2022\nA5/2   \u2022\nABA digital signature guidelines   \u2022\nABC (stream cipher)   \u2022\nAbraham Sinkov   \u2022\nAcoustic cryptanalysis   \u2022\nAdaptive chosen-ciphertext attack   \u2022\nAdaptive chosen plaintext and chosen ciphertext attack   \u2022\nAdvantage (cryptography)   \u2022\nADFGVX cipher   \u2022\nAdi Shamir   \u2022\nAdvanced Access Content System   \u2022\nAdvanced Encryption Standard   \u2022\nAdvanced Encryption Standard process   \u2022\nAdversary   \u2022\nAEAD block cipher modes of operation   \u2022\nAffine cipher   \u2022\nAgnes Meyer Driscoll   \u2022\nAKA (security)   \u2022\nAkelarre (cipher)   \u2022\nAlan Turing   \u2022\nAlastair Denniston   \u2022\nAl Bhed language   \u2022\nAlex Biryukov   \u2022\nAlfred Menezes   \u2022\nAlgebraic Eraser   \u2022\nAlgorithmically random sequence   \u2022\nAlice and Bob   \u2022\nAll-or-nothing transform   \u2022\nAlphabetum Kaldeorum   \u2022\nAlternating step generator   \u2022\nAmerican Cryptogram Association   \u2022\nAN/CYZ-10   \u2022\nAnonymous publication   \u2022\nAnonymous remailer   \u2022\nAntoni Palluth   \u2022\nAnubis (cipher)   \u2022\nArgon2   \u2022\nARIA (cipher)   \u2022\nArlington Hall   \u2022\nArne Beurling   \u2022\nArnold Cipher   \u2022\nArray controller based encryption   \u2022\nArthur Scherbius   \u2022\nArvid Gerhard Damm   \u2022\nAsiacrypt   \u2022\nAtbash   \u2022\nAttribute-based encryption   \u2022\nAttack model   \u2022\nAuguste Kerckhoffs   \u2022\nAuthenticated encryption   \u2022\nAuthentication   \u2022\nAuthorization certificate   \u2022\nAutokey cipher   \u2022\nAvalanche effect\n\n== B ==\nB-Dienst   \u2022\nBabington Plot   \u2022\nBaby-step giant-step   \u2022\nBacon's cipher   \u2022\nBanburismus   \u2022\nBart Preneel   \u2022\nBaseKing   \u2022\nBassOmatic   \u2022\nBATON   \u2022\nBB84   \u2022\nBeale ciphers   \u2022\nBEAR and LION ciphers   \u2022\nBeaufort cipher   \u2022\nBeaumanor Hall   \u2022\nBent function   \u2022\nBerlekamp\u2013Massey algorithm   \u2022\nBernstein v. United States   \u2022\nBestCrypt   \u2022\nBiclique attack   \u2022\nBID/60   \u2022\nBID 770   \u2022\nBifid cipher   \u2022\nBill Weisband   \u2022\nBinary Goppa code   \u2022\nBiometric word list   \u2022\nBirthday attack   \u2022\nBit-flipping attack   \u2022\nBitTorrent protocol encryption   \u2022\nBiuro Szyfr\u00f3w   \u2022\nBlack Chamber   \u2022\nBlaise de Vigen\u00e8re   \u2022\nBletchley Park   \u2022\nBlind credential   \u2022\nBlinding (cryptography)   \u2022\nBlind signature   \u2022\nBlock cipher   \u2022\nBlock cipher mode of operation   \u2022\nBlock size (cryptography)   \u2022\nBlowfish (cipher)   \u2022\nBlum Blum Shub   \u2022\nBlum\u2013Goldwasser cryptosystem   \u2022\nBomba (cryptography)   \u2022\nBombe   \u2022\nBook cipher   \u2022\nBooks on cryptography   \u2022\nBoomerang attack   \u2022\nBoris Hagelin   \u2022\nBouncy Castle (cryptography)   \u2022\nBroadcast encryption   \u2022\nBruce Schneier   \u2022\nBrute-force attack   \u2022\nBrute Force: Cracking the Data Encryption Standard   \u2022\nBurrows\u2013Abadi\u2013Needham logic   \u2022\nBurt Kaliski\n\n== C ==\nC2Net   \u2022\nC-36 (cipher machine)   \u2022\nC-52 (cipher machine)   \u2022\nCaesar cipher   \u2022\nCamellia (cipher)   \u2022\nCAPICOM   \u2022\nCapstone (cryptography)   \u2022\nCardan grille   \u2022\nCard catalog (cryptology)   \u2022\nCarlisle Adams   \u2022\nCAST-128   \u2022\nCAST-256   \u2022\nCayley\u2013Purser algorithm   \u2022\nCBC-MAC   \u2022\nCCM mode   \u2022\nCCMP   \u2022\nCD-57   \u2022\nCDMF   \u2022\nCellular Message Encryption Algorithm   \u2022\nCentiban   \u2022\nCentral Security Service   \u2022\nCentre for Applied Cryptographic Research   \u2022\nCentral Bureau   \u2022\nCerticom   \u2022\nCertificate authority   \u2022\nCertificate-based encryption   \u2022\nCertificateless cryptography   \u2022\nCertificate revocation list   \u2022\nCertificate signing request   \u2022\nCertification path validation algorithm   \u2022\nChaffing and winnowing   \u2022\nChallenge-Handshake Authentication Protocol   \u2022\nChallenge\u2013response authentication   \u2022\nChosen-ciphertext attack   \u2022\nChosen-plaintext attack   \u2022\nCIKS-1   \u2022\nCipher disk   \u2022\nCipher runes   \u2022\nCipher security summary   \u2022\nCipherSaber   \u2022\nCiphertext expansion   \u2022\nCiphertext indistinguishability   \u2022\nCiphertext-only attack   \u2022\nCiphertext stealing   \u2022\nCIPHERUNICORN-A   \u2022\nCIPHERUNICORN-E   \u2022\nClassical cipher   \u2022\nClaude Shannon   \u2022\nClaw-free permutation   \u2022\nCleartext   \u2022\nCLEFIA   \u2022\nClifford Cocks   \u2022\nClipper chip   \u2022\nClock (cryptography)   \u2022\nClock drift   \u2022\nCMVP   \u2022\nCOCONUT98   \u2022\nCodebook   \u2022\nCode (cryptography)   \u2022\nCode talker   \u2022\nCodress message   \u2022\nCold boot attack   \u2022\nCollision attack   \u2022\nCollision resistance   \u2022\nColossus computer   \u2022\nCombined Cipher Machine   \u2022\nCommitment scheme   \u2022\nCommon Scrambling Algorithm   \u2022\nCommunications security   \u2022\nCommunications Security Establishment   \u2022\nCommunication Theory of Secrecy Systems   \u2022\nComparison of disk encryption software   \u2022\nComparison of SSH clients   \u2022\nCompleteness (cryptography)   \u2022\nComplexity trap   \u2022\nComputational Diffie\u2013Hellman assumption   \u2022\nComputational hardness assumption   \u2022\nComputer insecurity   \u2022\nComputer and network surveillance   \u2022\nCOMSEC equipment   \u2022\nConch (SSH)   \u2022\nConcrete security   \u2022\nConel Hugh O'Donel Alexander   \u2022\nConfidentiality   \u2022\nConfusion and diffusion   \u2022\nContent-scrambling system   \u2022\nControlled Cryptographic Item   \u2022\nCorkscrew (program)   \u2022\nCorrelation immunity   \u2022\nCOSIC   \u2022\nCovert channel   \u2022\nCover (telecommunications)   \u2022\nCrab (cipher)   \u2022\nCramer\u2013Shoup cryptosystem   \u2022\nCRAM-MD5   \u2022\nCRHF   \u2022\nCrib (cryptanalysis)   \u2022\nCrossCrypt   \u2022\nCrowds (anonymity network)   \u2022\nCrypt (C)   \u2022\nCryptanalysis   \u2022\nCryptanalysis of the Enigma   \u2022\nCryptanalysis of the Lorenz cipher   \u2022\nCryptanalytic computer   \u2022\nCryptex   \u2022\nCryptico   \u2022\nCrypto AG   \u2022\nCrypto-anarchism   \u2022\nCrypto API (Linux)   \u2022\nMicrosoft CryptoAPI   \u2022\nCryptoBuddy   \u2022\nCryptochannel   \u2022\nCRYPTO (conference)   \u2022\nCryptogram   \u2022\nCryptographically Generated Address   \u2022\nCryptographically secure pseudorandom number generator   \u2022\nCryptographically strong   \u2022\nCryptographic Application Programming Interface   \u2022\nCryptographic hash function   \u2022\nCryptographic key types   \u2022\nCryptographic Message Syntax   \u2022\nCryptographic primitive   \u2022\nCryptographic protocol   \u2022\nCryptographic Service Provider   \u2022\nCryptographie ind\u00e9chiffrable   \u2022\nCryptography   \u2022\nCryptography in Japan   \u2022\nCryptography newsgroups   \u2022\nCryptography standards   \u2022\nCrypto: How the Code Rebels Beat the Government\u2014Saving Privacy in the Digital Age   \u2022\nCryptologia   \u2022\nCryptology ePrint Archive   \u2022\nCryptology Research Society of India   \u2022\nCryptomathic   \u2022\nCryptome   \u2022\nCryptomeria cipher   \u2022\nCryptonomicon   \u2022\nCrypTool   \u2022\nCrypto phone   \u2022\nCrypto-society   \u2022\nCryptosystem   \u2022\nCryptovirology   \u2022\nCRYPTREC   \u2022\nCS-Cipher   \u2022\nCurve25519   \u2022 Curve448   \u2022 Custom hardware attack   \u2022\nCycles per byte   \u2022\nCyclometer   \u2022\nCypherpunk   \u2022\nCyrillic Projector\n\n== D ==\nD'Agapeyeff cipher   \u2022\nDaniel J. Bernstein   \u2022\nData Authentication Algorithm   \u2022\nData Encryption Standard   \u2022\nDatagram Transport Layer Security   \u2022\nDavid Chaum   \u2022\nDavid Kahn   \u2022\nDavid Naccache   \u2022\nDavid Wagner   \u2022\nDavid Wheeler (computer scientist)   \u2022\nDavies attack   \u2022\nDavies\u2013Meyer hash   \u2022\nDEAL   \u2022\nDecipherment   \u2022\nDecisional Diffie\u2013Hellman assumption   \u2022\nDecorrelation theory   \u2022\nDecrypt   \u2022\nDeCSS   \u2022\nDefence Signals Directorate   \u2022\nDegree of anonymity   \u2022\nDelegated Path Discovery   \u2022\nDelegated Path Validation   \u2022\nDeniable encryption   \u2022\nDerek Taunt   \u2022\nDerived unique key per transaction   \u2022\nDES Challenges   \u2022\nDES supplementary material   \u2022\nDES-X   \u2022\nDeterministic encryption   \u2022\nDFC (cipher)   \u2022\nDictionary attack   \u2022\nDifferential cryptanalysis   \u2022\nDifferential-linear attack   \u2022\nDifferential power analysis   \u2022\nDiffie\u2013Hellman key exchange   \u2022\nDiffie\u2013Hellman problem   \u2022\nDigiCipher 2   \u2022\nDigital Fortress   \u2022\nDigital rights management   \u2022\nDigital signature   \u2022\nDigital Signature Algorithm   \u2022\nDigital signature forgery   \u2022\nDigital timestamping   \u2022\nDigital watermarking   \u2022\nDilly Knox   \u2022\nDining cryptographers problem   \u2022\nDiplomatic bag   \u2022\nDirect Anonymous Attestation   \u2022\nDiscrete logarithm   \u2022\nDisk encryption   \u2022\nDisk encryption hardware   \u2022\nDisk encryption software   \u2022\nDistance-bounding protocol   \u2022\nDistinguishing attack   \u2022\nDistributed.net   \u2022\nDMA attack   \u2022\ndm-crypt   \u2022\nDmitry Sklyarov   \u2022\nDomainKeys   \u2022\nDon Coppersmith   \u2022\nDorabella Cipher   \u2022\nDouble Ratchet Algorithm   \u2022\nDoug Stinson   \u2022\nDragon (cipher)   \u2022\nDRYAD   \u2022\nDual_EC_DRBG   \u2022\n\n== E ==\nE0 (cipher)   \u2022\nE2 (cipher)   \u2022\nE4M   \u2022\nEAP-AKA   \u2022\nEAP-SIM   \u2022\nEAX mode   \u2022\nECC patents   \u2022\nECHELON   \u2022\nECRYPT   \u2022\nEdouard Fleissner von Wostrowitz   \u2022\nEdward Hebern   \u2022\nEdward Scheidt   \u2022\nEdward Travis   \u2022\nEFF DES cracker   \u2022\nEfficient Probabilistic Public-Key Encryption Scheme   \u2022\nEKMS   \u2022\nElectronic Communications Act 2000   \u2022\nElectronic money   \u2022\nElectronic signature   \u2022\nElectronic voting   \u2022\nElGamal encryption   \u2022\nElGamal signature scheme   \u2022\nEli Biham   \u2022\nElizebeth Friedman   \u2022\nElliptic-curve cryptography   \u2022\nElliptic-curve Diffie\u2013Hellman   \u2022\nElliptic Curve DSA   \u2022 EdDSA   \u2022 Elliptic curve only hash   \u2022\nElonka Dunin   \u2022\nEncrypted function   \u2022\nEncrypted key exchange   \u2022\nEncrypting File System   \u2022\nEncryption   \u2022\nEncryption software   \u2022\nEnigmail   \u2022\nEnigma machine   \u2022\nEnigma rotor details   \u2022\nEntrust   \u2022\nErnst Fetterlein   \u2022\neSTREAM   \u2022\n\u00c9tienne Bazeries   \u2022\nEurocrypt   \u2022\nEuroCrypt   \u2022\nExport of cryptography   \u2022\nExtensible Authentication Protocol\n\n== F ==\nFast Software Encryption   \u2022\nFast syndrome-based hash   \u2022\nFEA-M   \u2022\nFEAL   \u2022\nFeige\u2013Fiat\u2013Shamir identification scheme   \u2022\nFeistel cipher   \u2022\nF\u00e9lix Delastelle   \u2022\nFialka   \u2022\nFilesystem-level encryption   \u2022\nFileVault   \u2022\nFill device   \u2022\nFinancial cryptography   \u2022\nFIPS 140   \u2022\nFIPS 140-2   \u2022\nFirefly (key exchange protocol)   \u2022\nFISH (cipher)   \u2022\nFish (cryptography)   \u2022\nFloradora   \u2022\nFluhrer, Mantin and Shamir attack   \u2022\nFormat-preserving encryption   \u2022\nFortezza   \u2022\nFort George G. Meade   \u2022\nFortuna (PRNG)   \u2022\nFour-square cipher   \u2022\nFranciszek Pokorny   \u2022\nFrank A. Stevenson   \u2022\nFrank Rowlett   \u2022\nFreenet   \u2022\nFreeOTFE   \u2022\nFreeS/WAN   \u2022\nFrequency analysis   \u2022\nFriedrich Kasiski   \u2022\nFritz-chip   \u2022\nFROG   \u2022\nFROSTBURG   \u2022\nFTP over SSH   \u2022\nFull disk encryption   \u2022\nFull Domain Hash   \u2022\nF. W. Winterbotham\n\n== G ==\nGalois/Counter Mode   \u2022\nGardening (cryptanalysis)   \u2022\nGCHQ Bude   \u2022\nGCHQ CSO Morwenstow   \u2022\nGDES   \u2022\nGeneric Security Services Application Program Interface   \u2022\nGeorge Blakley   \u2022\nGeorge Scovell   \u2022\nGGH encryption scheme   \u2022\nGGH signature scheme   \u2022\nGilbert Vernam   \u2022\nGMR (cryptography)   \u2022\nGNU Privacy Guard   \u2022\nGnuTLS   \u2022\nGoldwasser\u2013Micali cryptosystem   \u2022\nGordon Welchman   \u2022\nGOST (block cipher)   \u2022\nGOST (hash function)   \u2022\nGovernment Communications Headquarters   \u2022\nGovernment Communications Security Bureau   \u2022\nGrain (cipher)   \u2022\nGrand Cru (cipher)   \u2022\nGreat Cipher   \u2022\nGrill (cryptology)   \u2022\nGrille (cryptography)   \u2022\nGroup-based cryptography   \u2022\nGroup signature   \u2022\nGrover's algorithm   \u2022\nGustave Bertrand   \u2022\nGwido Langer\n\n== H ==\nH.235   \u2022\nHAIFA construction   \u2022\nHAIPE   \u2022\nHans Dobbertin   \u2022\nHans-Thilo Schmidt   \u2022\nHard-core predicate   \u2022\nHardware random number generator   \u2022\nHardware security module   \u2022\nHarold Keen   \u2022\nHarry Hinsley   \u2022\nHarvest (computer)   \u2022\nHAS-160   \u2022\nHash-based cryptography   \u2022\nHashcash   \u2022\nHash chain   \u2022\nHash function security summary   \u2022\nHash list   \u2022\nHasty Pudding cipher   \u2022\nHAVAL   \u2022\nHC-256   \u2022\nHC-9   \u2022\nHeath Robinson (codebreaking machine)   \u2022\nHebern rotor machine   \u2022\nHenri Braqueni\u00e9   \u2022\nHenryk Zygalski   \u2022\nHerbert Yardley   \u2022\nHidden Field Equations   \u2022\nHideki Imai   \u2022\nHierocrypt   \u2022\nHigh-bandwidth Digital Content Protection   \u2022\nHigher-order differential cryptanalysis   \u2022\nHill cipher   \u2022\nHistory of cryptography   \u2022\nHMAC   \u2022\nHMAC-based One-time Password algorithm   (HOTP) \u2022\nHorst Feistel   \u2022\nHoward Heys   \u2022\nHttps   \u2022\nHugo Hadwiger   \u2022\nHugo Koch   \u2022\nHushmail   \u2022\nHut 6   \u2022\nHut 8   \u2022\nHX-63   \u2022\nHybrid cryptosystem   \u2022\nHyperelliptic curve cryptography   \u2022\nHyper-encryption\n\n== I ==\nIan Goldberg   \u2022\nIBM 4758   \u2022\nICE (cipher)   \u2022\nID-based cryptography   \u2022\nIDEA NXT   \u2022\nIdentification friend or foe   \u2022\nIEEE 802.11i   \u2022\nIEEE P1363   \u2022\nI. J. Good   \u2022\nIllegal prime   \u2022\nImpossible differential cryptanalysis   \u2022\nIndex of coincidence   \u2022\nIndifferent chosen-ciphertext attack   \u2022\nIndistinguishability obfuscation   \u2022\nIndocrypt   \u2022\nInformation leakage   \u2022\nInformation Security Group   \u2022\nInformation-theoretic security   \u2022\nInitialization vector   \u2022\nInteger factorization   \u2022\nIntegral cryptanalysis   \u2022\nIntegrated Encryption Scheme   \u2022\nIntegrated Windows Authentication   \u2022\nInterlock protocol   \u2022\nIntermediate certificate authorities   \u2022\nInternational Association for Cryptologic Research   \u2022\nInternational Data Encryption Algorithm   \u2022\nInternet Key Exchange   \u2022\nInternet Security Association and Key Management Protocol   \u2022\nInterpolation attack   \u2022\nInvisible ink   \u2022\nIPsec   \u2022\nIraqi block cipher   \u2022\nISAAC (cipher)   \u2022\nISO 19092-2   \u2022\nISO/IEC 9797   \u2022\nIvan Damg\u00e5rd\n\n== J ==\nJacques Stern   \u2022\nJADE (cypher machine)   \u2022\nJames Gillogly   \u2022\nJames H. Ellis   \u2022\nJames Massey   \u2022\nJan Grali\u0144ski   \u2022\nJan Kowalewski   \u2022\nJapanese naval codes   \u2022\nJava Cryptography Architecture   \u2022\nJefferson disk   \u2022\nJennifer Seberry   \u2022\nJerzy R\u00f3\u017cycki   \u2022\nJoan Daemen   \u2022\nJohannes Trithemius   \u2022\nJohn Herivel   \u2022\nJohn Kelsey (cryptanalyst)   \u2022\nJohn R. F. Jeffreys   \u2022\nJohn Tiltman   \u2022\nJon Lech Johansen   \u2022\nJosef Pieprzyk   \u2022\nJoseph Desch   \u2022\nJoseph Finnegan (cryptographer)   \u2022\nJoseph Mauborgne   \u2022\nJoseph Rochefort   \u2022\nJournal of Cryptology   \u2022\nJunger v. Daley\n\n== K ==\nKaisa Nyberg   \u2022\nKalyna (cipher)   \u2022\nKasiski examination   \u2022\nKASUMI   \u2022\nKCDSA   \u2022\nKeePass   \u2022\nKerberos (protocol)   \u2022\nKerckhoffs's principle   \u2022\nKevin McCurley (cryptographer)   \u2022\nKey-agreement protocol   \u2022\nKey authentication   \u2022\nKey clustering   \u2022\nKey (cryptography)   \u2022\nKey derivation function   \u2022\nKey distribution center   \u2022\nKey escrow   \u2022\nKey exchange   \u2022\nKeyfile   \u2022\nKey generation   \u2022\nKey generator   \u2022\nKey management   \u2022\nKey-recovery attack   \u2022\nKey schedule   \u2022\nKey server (cryptographic)   \u2022\nKey signature (cryptography)   \u2022\nKeysigning   \u2022\nKey signing party   \u2022\nKey size   \u2022\nKey space (cryptography)   \u2022\nKeystream   \u2022\nKey stretching   \u2022\nKey whitening   \u2022\nKG-84   \u2022\nKHAZAD   \u2022\nKhufu and Khafre   \u2022\nKiss (cryptanalysis)   \u2022\nKL-43   \u2022\nKL-51   \u2022\nKL-7   \u2022\nKleptography   \u2022\nKN-Cipher   \u2022\nKnapsack problem   \u2022\nKnown-key distinguishing attack   \u2022\nKnown-plaintext attack   \u2022\nKnownSafe   \u2022\nKOI-18   \u2022\nKOV-14   \u2022\nKryha   \u2022\nKryptos   \u2022\nKSD-64   \u2022\nKupyna   \u2022\nKuznyechik   \u2022\nKW-26   \u2022\nKW-37   \u2022\nKY-3   \u2022\nKY-57   \u2022\nKY-58   \u2022\nKY-68   \u2022\nKYK-13\n\n== L ==\nLacida   \u2022\nLadder-DES   \u2022\nLamport signature   \u2022\nLars Knudsen   \u2022\nLattice-based cryptography   \u2022\nLaurance Safford   \u2022\nLawrie Brown   \u2022\nLCS35   \u2022\nLeo Marks   \u2022\nLeonard Adleman   \u2022\nLeon Battista Alberti   \u2022\nLeo Rosen   \u2022\nLeslie Yoxall   \u2022\nLEVIATHAN (cipher)   \u2022\nLEX (cipher)   \u2022\nLibelle (cipher)   \u2022\nLinear cryptanalysis   \u2022\nLinear-feedback shift register   \u2022\nLink encryption   \u2022\nList of ciphertexts   \u2022\nList of cryptographers   \u2022\nList of cryptographic file systems   \u2022\nList of cryptographic key types   \u2022\nList of cryptology conferences   \u2022\nList of telecommunications encryption terms   \u2022 List of people associated with Bletchley Park \u2022 \n  List of SFTP clients   \u2022\nList of SFTP server software   \u2022\nLOKI   \u2022\nLOKI97   \u2022\nLorenz cipher   \u2022\nLouis W. Tordella   \u2022\nLsh   \u2022\nLucifer (cipher)   \u2022\nLyra2\n\n== M ==\nM6 (cipher)   \u2022\nM8 (cipher)   \u2022\nM-209   \u2022\nM-325   \u2022\nM-94   \u2022\nMacGuffin (cipher)   \u2022\nMadryga   \u2022\nMAGENTA   \u2022\nMagic (cryptography)   \u2022\nMaksymilian Ci\u0119\u017cki   \u2022\nMalcolm J. Williamson   \u2022\nMalleability (cryptography)   \u2022\nMan-in-the-middle attack   \u2022\nMarian Rejewski   \u2022\nMARS (cryptography)   \u2022\nMartin Hellman   \u2022\nMaruTukku   \u2022\nMassey\u2013Omura cryptosystem   \u2022\nMatt Blaze   \u2022\nMatt Robshaw   \u2022\nMax Newman   \u2022\nMcEliece cryptosystem   \u2022\nmcrypt   \u2022\nMD2 (cryptography)   \u2022\nMD4   \u2022\nMD5   \u2022\nMD5CRK   \u2022\nMDC-2   \u2022\nMDS matrix   \u2022\nMean shortest distance   \u2022\nMeet-in-the-middle attack   \u2022\nMental poker   \u2022\nMercury (cipher machine)   \u2022\nMercy (cipher)   \u2022\nMeredith Gardner   \u2022\nMerkle signature scheme   \u2022\nMerkle\u2013Damg\u00e5rd construction   \u2022\nMerkle\u2013Hellman knapsack cryptosystem   \u2022\nMerkle's Puzzles   \u2022\nMerkle tree   \u2022\nMESH (cipher)   \u2022\nMessage authentication   \u2022\nMessage authentication code   \u2022\nMessage forgery   \u2022\nMI8   \u2022\nMichael Luby   \u2022\nMICKEY   \u2022\nMicrodot   \u2022\nMilitary Cryptanalysis (book) (William F. Friedman)   \u2022\nMilitary Cryptanalytics   \u2022\nMimic function   \u2022\nMirror writing   \u2022\nMISTY1   \u2022\nMitsuru Matsui   \u2022\nMMB (cipher)   \u2022\nMod n cryptanalysis   \u2022\nMQV   \u2022\nMS-CHAP   \u2022\nMUGI   \u2022\nMULTI-S01   \u2022\nMultiSwap   \u2022\nMultivariate cryptography\n\n== N ==\nNational Communications Centre   \u2022\nNational Cryptologic Museum   \u2022\nNational Security Agency   \u2022\nNational Cipher Challenge   \u2022\nNavajo I   \u2022\nNeal Koblitz   \u2022\nNeedham\u2013Schroeder protocol   \u2022\nNegligible function   \u2022\nNEMA (machine)   \u2022\nNESSIE   \u2022\nNetwork Security Services   \u2022\nNeural cryptography   \u2022\nNew Data Seal   \u2022\nNewDES   \u2022\nN-Hash   \u2022\nNicolas Courtois   \u2022\nNiederreiter cryptosystem   \u2022\nNiels Ferguson   \u2022\nNigel de Grey   \u2022\nNihilist cipher   \u2022\nNikita Borisov   \u2022\nNimbus (cipher)   \u2022\nNIST hash function competition   \u2022\nNonlinear-feedback shift register   \u2022\nNOEKEON   \u2022\nNon-malleable codes   \u2022\nNoreen   \u2022\nNothing up my sleeve number   \u2022\nNSA cryptography   \u2022\nNSA encryption systems   \u2022\nNSA in fiction   \u2022\nNSAKEY   \u2022\nNSA Suite A Cryptography   \u2022\nNSA Suite B Cryptography   \u2022\nNT LAN Manager   \u2022\nNTLMSSP   \u2022\nNTRUEncrypt   \u2022\nNTRUSign   \u2022\nNull cipher   \u2022\nNumbers station   \u2022\nNUSH   \u2022\nNTRU\n\n== O ==\nOblivious transfer   \u2022\nOCB mode   \u2022\nOded Goldreich   \u2022\nOff-the-Record Messaging   \u2022\nOkamoto\u2013Uchiyama cryptosystem   \u2022\nOMI cryptograph   \u2022\nOMNI (SCIP)   \u2022\nOne-key MAC   \u2022\nOne-time pad   \u2022\nOne-time password   \u2022\nOne-way compression function   \u2022\nOne-way function   \u2022\nOnion routing   \u2022\nOnline Certificate Status Protocol   \u2022\nOP-20-G   \u2022\nOpenPGP card   \u2022\nOpenSSH   \u2022\nOpenSSL   \u2022\nOpenswan   \u2022\nOpenVPN   \u2022\nOperation Ruthless   \u2022\nOptimal asymmetric encryption padding   \u2022\nOver the Air Rekeying   (OTAR) \u2022\nOTFE   \u2022\nOtway\u2013Rees protocol\n\n== P ==\nPadding (cryptography)   \u2022\nPadding oracle attack    \u2022\nPaillier cryptosystem   \u2022\nPairing-based cryptography   \u2022\nPanama (cryptography)   \u2022\nPartitioning cryptanalysis   \u2022\nPassive attack   \u2022\nPassphrase   \u2022\nPassword   \u2022\nPassword-authenticated key agreement   \u2022\nPassword cracking   \u2022\nPassword Hashing Competition   \u2022\nPaul Kocher   \u2022\nPaulo Pancatuccio   \u2022\nPaulo S. L. M. Barreto   \u2022\nPaul van Oorschot   \u2022\nPBKDF2   \u2022\nPC Bruno   \u2022\nPepper (cryptography)   \u2022\nPerfect forward secrecy   \u2022\nPerforated sheets   \u2022\nPermutation cipher   \u2022\nPeter Gutmann (computer scientist)   \u2022\nPeter Junger   \u2022\nPeter Twinn   \u2022\nPGP Corporation   \u2022\nPGPDisk   \u2022\nPGPfone   \u2022\nPhelix   \u2022\nPhil Zimmermann   \u2022\nPhoturis (protocol)   \u2022\nPhysical security   \u2022\nPhysical unclonable function   \u2022\nPig Latin   \u2022\nPigpen cipher   \u2022\nPike (cipher)   \u2022\nPiling-up lemma   \u2022\nPinwheel (cryptography)   \u2022\nPiotr Smole\u0144ski   \u2022\nPirate decryption   \u2022\nPKC (conference)   \u2022\nPKCS   \u2022\nPKCS 11   \u2022\nPKCS 12   \u2022\nPKIX   \u2022\nPlaintext   \u2022\nPlaintext-aware encryption   \u2022\nPlayfair cipher   \u2022\nPlugboard   \u2022\nPMAC (cryptography)   \u2022\nPoem code   \u2022\nPohlig\u2013Hellman algorithm   \u2022\nPoint-to-Point Tunneling Protocol   \u2022\nPointcheval\u2013Stern signature algorithm   \u2022\nPoly1305   \u2022\nPolyalphabetic cipher   \u2022\nPolybius square   \u2022\nPortex   \u2022\nPost-quantum cryptography   \u2022\nPost-Quantum Cryptography Standardization   \u2022\nPower analysis   \u2022\nPreimage attack   \u2022\nPre-shared key   \u2022\nPretty Good Privacy   \u2022\nPrinter steganography   \u2022\nPrivacy-enhanced Electronic Mail   \u2022\nPrivate Communications Technology   \u2022\nPrivate information retrieval   \u2022\nProbabilistic encryption   \u2022\nProduct cipher   \u2022\nProof-of-work system   \u2022\nProtected Extensible Authentication Protocol   \u2022\nProvable security   \u2022\nProvably secure cryptographic hash function   \u2022\nProxy re-encryption   \u2022\nPseudo-Hadamard transform   \u2022\nPseudonymity   \u2022\nPseudorandom function   \u2022\nPseudorandom number generator   \u2022\nPseudorandom permutation   \u2022\nPublic key certificate   \u2022\nPublic-key cryptography   \u2022\nPublic key fingerprint   \u2022\nPublic key infrastructure   \u2022\nPURPLE   \u2022\nPuTTY   \u2022\nPy (cipher)\n\n== Q ==\nQ (cipher)   \u2022\nQrpff   \u2022\nQUAD (cipher)   \u2022\nQuadratic sieve   \u2022\nQuantum coin flipping   \u2022\nQuantum cryptography   \u2022\nQuantum digital signature   \u2022\nQuantum fingerprinting   \u2022\nQuantum key distribution\n\n== R ==\nRabbit (cipher)   \u2022\nRabin cryptosystem   \u2022\nRabin\u2013Williams encryption   \u2022\nRadioGat\u00fan   \u2022\nRail fence cipher   \u2022\nRainbow table   \u2022\nRalph Merkle   \u2022\nRambutan (cryptography)   \u2022\nRandom function   \u2022\nRandomness tests   \u2022\nRandom number generator attack   \u2022\nRandom oracle   \u2022\nRC2   \u2022\nRC4   \u2022\nRC5   \u2022\nRC6   \u2022\nRebound attack   \u2022\nReciprocal cipher   \u2022\nRed/black concept   \u2022\nREDOC   \u2022\nRed Pike (cipher)   \u2022\nReflector (cipher machine)   \u2022\nRegulation of Investigatory Powers Act 2000   \u2022\nReihenschieber   \u2022\nRekeying (cryptography)   \u2022\nRelated-key attack   \u2022\nReplay attack   \u2022\nReservehandverfahren   \u2022\nResidual block termination   \u2022\nRijndael key schedule   \u2022\nRijndael S-box   \u2022\nRing signature   \u2022\nRIPEMD   \u2022\nRip van Winkle cipher   \u2022\nRobert Morris (cryptographer)   \u2022\nRobot certificate authority   \u2022\nRockex   \u2022\nRolf Noskwith   \u2022\nRon Rivest   \u2022\nRoom 40   \u2022\nRoot certificate   \u2022\nRoss J. Anderson   \u2022\nRossignols   \u2022\nROT13   \u2022\nRotor machine   \u2022\nRSA RSA \u2022\nRSA-100   \u2022\nRSA-1024   \u2022\nRSA-110   \u2022\nRSA-120   \u2022\nRSA-129   \u2022\nRSA-130   \u2022\nRSA-140   \u2022\nRSA-150   \u2022\nRSA-1536   \u2022\nRSA-155   \u2022\nRSA-160   \u2022\nRSA-170   \u2022\nRSA-180   \u2022\nRSA-190   \u2022\nRSA-200   \u2022\nRSA-2048   \u2022\nRSA-210   \u2022\nRSA-220   \u2022\nRSA-230   \u2022\nRSA-232   \u2022\nRSA-240   \u2022\nRSA-250   \u2022\nRSA-260   \u2022\nRSA-270   \u2022\nRSA-280   \u2022\nRSA-290   \u2022\nRSA-300   \u2022\nRSA-309   \u2022\nRSA-310   \u2022\nRSA-320   \u2022\nRSA-330   \u2022\nRSA-340   \u2022\nRSA-350   \u2022\nRSA-360   \u2022\nRSA-370   \u2022\nRSA-380   \u2022\nRSA-390   \u2022\nRSA-400   \u2022\nRSA-410   \u2022\nRSA-420   \u2022\nRSA-430   \u2022\nRSA-440   \u2022\nRSA-450   \u2022\nRSA-460   \u2022\nRSA-470   \u2022\nRSA-480   \u2022\nRSA-490   \u2022\nRSA-500   \u2022\nRSA-576   \u2022\nRSA-617   \u2022\nRSA-640   \u2022\nRSA-704   \u2022\nRSA-768   \u2022\nRSA-896   \u2022\nRSA-PSS   \u2022\nRSA Factoring Challenge   \u2022\nRSA problem   \u2022\nRSA Secret-Key Challenge   \u2022\nRSA Security   \u2022\nRubber-hose cryptanalysis   \u2022\nRunning key cipher   \u2022\nRussian copulation\n\n== S ==\nS-1 block cipher   \u2022\nSAFER   \u2022\nSalsa20   \u2022\nSalt (cryptography)   \u2022\nSAM card   \u2022\nSecurity Support Provider Interface   \u2022\nSAML   \u2022\nSAVILLE   \u2022\nSC2000   \u2022\nSchnorr group   \u2022\nSchnorr signature   \u2022\nSchoof\u2013Elkies\u2013Atkin algorithm   \u2022\nSCIP   \u2022\nScott Vanstone   \u2022\nScrambler   \u2022\nScramdisk   \u2022\nScream (cipher)   \u2022\nScrypt   \u2022\nScytale   \u2022\nSeahorse (software)   \u2022\nSEAL (cipher)   \u2022\nSean Murphy (cryptographer)   \u2022\nSECG   \u2022\nSecret broadcast   \u2022\nSecret decoder ring   \u2022\nSecrets and Lies (Schneier)   \u2022\nSecret sharing   \u2022\nSect\u00e9ra Secure Module   \u2022\nSecure access module   \u2022\nSecure channel   \u2022\nSecure Communication based on Quantum Cryptography   \u2022\nSecure copy   \u2022\nSecure cryptoprocessor   \u2022\nSecure Electronic Transaction   \u2022\nSecure Hash Algorithms   \u2022\nSecure Hypertext Transfer Protocol   \u2022\nSecure key issuing cryptography   \u2022\nSecure multi-party computation   \u2022\nSecure Neighbor Discovery   \u2022\nSecure Real-time Transport Protocol   \u2022\nSecure remote password protocol   \u2022\nSecure Shell   \u2022\nSecure telephone   \u2022\nSecure Terminal Equipment   \u2022\nSecure voice   \u2022\nSecurID   \u2022\nSecurity association   \u2022\nSecurity engineering   \u2022\nSecurity level   \u2022\nSecurity parameter   \u2022\nSecurity protocol notation   \u2022\nSecurity through obscurity   \u2022\nSecurity token   \u2022\nSEED   \u2022\nSelected Areas in Cryptography   \u2022\nSelf-certifying File System   \u2022\nSelf-shrinking generator   \u2022\nSelf-signed certificate   \u2022\nSemantic security   \u2022\nSerge Vaudenay   \u2022\nSerpent (cipher)   \u2022\nSession key   \u2022\nSHACAL   \u2022\nShafi Goldwasser   \u2022\nSHA-1   \u2022\nSHA-2   \u2022\nSHA-3   \u2022\nShared secret   \u2022\nSHARK   \u2022\nShaun Wylie   \u2022\nShor's algorithm   \u2022\nShrinking generator   \u2022\nShugborough inscription   \u2022\nSide-channel attack   \u2022\nSiemens and Halske T52   \u2022\nSIGABA   \u2022\nSIGCUM   \u2022\nSIGINT   \u2022\nSignal Protocol   \u2022\nSignal Intelligence Service   \u2022\nSigncryption   \u2022\nSIGSALY   \u2022\nSILC (protocol)   \u2022\nSilvio Micali   \u2022\nSimple Authentication and Security Layer   \u2022\nSimple public-key infrastructure   \u2022\nSimple XOR cipher   \u2022\nS/KEY   \u2022\nSkein (hash function)   \u2022\nSkipjack (cipher)   \u2022\nSlide attack   \u2022\nSlidex   \u2022\nSmall subgroup confinement attack   \u2022\nS/MIME   \u2022\nSM4 algorithm   (formerly SMS4) \u2022\nSnake oil (cryptography)   \u2022\nSnefru   \u2022\nSNOW   \u2022\nSnuffle   \u2022\nSOBER-128   \u2022\nSolitaire (cipher)   \u2022\nSolomon Kullback   \u2022\nSOSEMANUK   \u2022\nSpecial Collection Service   \u2022\nSpectr-H64   \u2022\nSPEKE (cryptography)   \u2022\nSponge function   \u2022\nSPNEGO   \u2022\nSquare (cipher)   \u2022\nSsh-agent   \u2022 Ssh-keygen   \u2022 SSH File Transfer Protocol   \u2022\nSSLeay   \u2022\nStafford Tavares   \u2022\nStandard model (cryptography)   \u2022\nStation CAST   \u2022\nStation HYPO   \u2022\nStation-to-Station protocol   \u2022\nStatistical cryptanalysis   \u2022\nStefan Lucks   \u2022\nSteganalysis   \u2022\nSteganography   \u2022\nStraddling checkerboard   \u2022\nStream cipher   \u2022\nStream cipher attacks   \u2022\nStrong cryptography   \u2022\nStrong RSA assumption   \u2022\nStuart Milner-Barry   \u2022\nSTU-II   \u2022\nSTU-III   \u2022\nStunnel   \u2022\nSubstitution box   \u2022\nSubstitution cipher   \u2022\nSubstitution\u2013permutation network   \u2022\nSuperencryption   \u2022\nSupersingular isogeny key exchange   \u2022\nSwedish National Defence Radio Establishment   \u2022\nSWIFFT   \u2022\nSXAL/MBAL   \u2022\nSymmetric-key algorithm   \u2022\nSYSKEY\n\n== T ==\nTabula recta   \u2022\nTaher Elgamal   \u2022\nTamper resistance   \u2022\nTcpcrypt   \u2022\nTelevision encryption   \u2022\nTEMPEST   \u2022\nTemplate:Cryptographic software   \u2022\nTemporal Key Integrity Protocol   \u2022\nTestery   \u2022\nThawte   \u2022\nThe Alphabet Cipher   \u2022\nThe Code Book   \u2022\nThe Codebreakers   \u2022\nThe Gold-Bug   \u2022\nThe Magic Words are Squeamish Ossifrage   \u2022\nTheory of Cryptography Conference   \u2022\nThe world wonders   \u2022\nThomas Jakobsen   \u2022\nThree-pass protocol   \u2022\nThreshold shadow scheme   \u2022\nTICOM   \u2022\nTiger (cryptography)   \u2022\nTimeline of cryptography   \u2022\nTime/memory/data tradeoff attack   \u2022\nTime-based One-time Password algorithm   (TOTP) \u2022\nTiming attack   \u2022\nTiny Encryption Algorithm   \u2022\nTom Berson   \u2022\nTommy Flowers   \u2022\nTopics in cryptography   \u2022\nTor (anonymity network)   \u2022\nTorus-based cryptography   \u2022\nTraffic analysis   \u2022\nTraffic-flow security   \u2022\nTraitor tracing   \u2022\nTransmission security   \u2022\nTransport Layer Security   \u2022\nTransposition cipher   \u2022\nTrapdoor function   \u2022\nTrench code   \u2022\nTreyfer   \u2022\nTrifid cipher   \u2022\nTriple DES   \u2022\nTrivium (cipher)   \u2022\nTrueCrypt   \u2022\nTruncated differential cryptanalysis   \u2022\nTrusted third party   \u2022\nTuring (cipher)   \u2022\nTWINKLE   \u2022\nTWIRL   \u2022\nTwofish   \u2022\nTwo-square cipher   \u2022\nType 1 encryption   \u2022\nType 2 encryption   \u2022\nType 3 encryption   \u2022\nType 4 encryption   \u2022\nTypex\n\n== U ==\nUES (cipher)   \u2022\nUltra   \u2022\nUMAC   \u2022\nUnbalanced Oil and Vinegar   \u2022\nUndeniable signature   \u2022\nUnicity distance   \u2022\nUniversal composability   \u2022\nUniversal one-way hash function   (UOWHF)\n\n== V ==\nVenona project   \u2022\nVerifiable secret sharing   \u2022\nVerisign   \u2022\nVery smooth hash   \u2022\nVEST   \u2022\nVIC cipher   \u2022\nVideoCrypt   \u2022\nVigen\u00e8re cipher   \u2022\nVincent Rijmen   \u2022\nVINSON   \u2022\nVirtual private network   \u2022\nVisual cryptography   \u2022\nVoynich manuscript\n\n== W ==\nWadsworth's cipher   \u2022\nWAKE   \u2022\nWLAN Authentication and Privacy Infrastructure   \u2022\nWatermark (data file)   \u2022\nWatermarking attack   \u2022\nWeak key   \u2022\nWeb of trust   \u2022\nWhirlpool (hash function)   \u2022\nWhitfield Diffie   \u2022\nWide Mouth Frog protocol   \u2022\nWi-Fi Protected Access   \u2022\nWilliam F. Friedman   \u2022\nWilliam Montgomery (cryptographer)   \u2022\nWinSCP   \u2022\nWired Equivalent Privacy   \u2022\nWireless Transport Layer Security   \u2022\nWitness-indistinguishable proof   \u2022\nWorkshop on Cryptographic Hardware and Embedded Systems   \u2022\nWorld War I cryptography   \u2022\nWorld War II cryptography   \u2022\nW. T. Tutte\n\n== X ==\nX.509   \u2022\nXDH assumption   \u2022\nXiaoyun Wang   \u2022\nXML Encryption   \u2022\nXML Signature   \u2022\nxmx   \u2022\nXSL attack   \u2022\nXTEA   \u2022\nXTR   \u2022\nXuejia Lai   \u2022\nXXTEA  \n10-00-00-00-00\n\n== Y ==\nYarrow algorithm   \u2022\nY-stations   \u2022\nYuliang Zheng\n\n== Z ==\nZeroisation   \u2022\nZero-knowledge password proof   \u2022\nZero-knowledge proof   \u2022\nZfone   \u2022\nZodiac (cipher)   \u2022\nZRTP   \u2022\nZimmermann\u2013Sassaman key-signing protocol   \u2022\nZimmermann Telegram"
    }
  },
  {
    "instruction": "Write an answer to the following question: How does Alice generate a symmetric key in DLIES?",
    "context": "",
    "output": "In DLIES, Alice generates a symmetric key by computing the hash value of the concatenation of her ephemeral public value and Bob's public key using a key derivation function.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does Alice generate a symmetric key in DLIES?",
      "answer": "In DLIES, Alice generates a symmetric key by computing the hash value of the concatenation of her ephemeral public value and Bob's public key using a key derivation function."
    }
  },
  {
    "instruction": "Random oracle\n\n==Introduction==\nIn cryptography, a random oracle is an oracle (a theoretical black box) that responds to every unique query with a (truly) random response chosen uniformly from its output domain. If a query is repeated, it responds the same way every time that query is submitted.\nStated differently, a random oracle is a mathematical function chosen uniformly at random, that is, a function mapping each possible query to a (fixed) random response from its output domain.\nRandom oracles as a mathematical abstraction were first used in rigorous cryptographic proofs in the 1993 publication by Mihir Bellare and Phillip Rogaway (1993). They are typically used when the proof cannot be carried out using weaker assumptions on the cryptographic hash function. A system that is proven secure when every hash function is replaced by a random oracle is described as being secure in the random oracle model, as opposed to secure in the standard model of cryptography.\n\n== Applications ==\nRandom oracles are typically used as an idealised replacement for cryptographic hash functions in schemes where strong randomness assumptions are needed of the hash function's output. Such a proof often shows that a system or a protocol is secure by showing that an attacker must require impossible behavior from the oracle, or solve some mathematical problem believed hard in order to break it. However, it only proves such properties in the random oracle model, making sure no major design flaws are present. It is in general not true that such a proof implies the same properties in the standard model. Still, a proof in the random oracle model is considered better than no formal security proof at all.Not all uses of cryptographic hash functions require random oracles: schemes that require only one or more properties having a definition in the standard model (such as collision resistance, preimage resistance, second preimage resistance, etc.) can often be proven secure in the standard model (e.g., the Cramer\u2013Shoup cryptosystem).\nRandom oracles have long been considered in computational complexity theory, and many schemes have been proven secure in the random oracle model, for example Optimal Asymmetric Encryption Padding, RSA-FDH and Probabilistic Signature Scheme. In 1986, Amos Fiat and Adi Shamir showed a major application of random oracles \u2013 the removal of interaction from protocols for the creation of signatures.\nIn 1989, Russell Impagliazzo and Steven Rudich showed the limitation of random oracles \u2013 namely that their existence alone is not sufficient for secret-key exchange.\nIn 1993, Mihir Bellare and Phillip Rogaway were the first to advocate their use in cryptographic constructions. In their definition, the random oracle produces a bit-string of infinite length which can be truncated to the length desired.\nWhen a random oracle is used within a security proof, it is made available to all players, including the adversary or adversaries. A single oracle may be treated as multiple oracles by pre-pending a fixed bit-string to the beginning of each query (e.g., queries formatted as \"1|x\" or \"0|x\" can be considered as calls to two separate random oracles, similarly \"00|x\", \"01|x\", \"10|x\" and \"11|x\" can be used to represent calls to four separate random oracles).\n\n== Limitations ==\nAccording to the Church\u2013Turing thesis, no function computable by a finite algorithm can implement a true random oracle (which by definition requires an infinite description because it has infinitely many possible inputs, and its outputs are all independent from each other and need to be individually specified by any description).\nIn fact, certain artificial signature and encryption schemes are known which are proven secure in the random oracle model, but which are trivially insecure when any real function is substituted for the random oracle. Nonetheless, for any more natural protocol a proof of security in the random oracle model gives very strong evidence of the practical security of the protocol.In general, if a protocol is proven secure, attacks to that protocol must either be outside what was proven, or break one of the assumptions in the proof; for instance if the proof relies on the hardness of integer factorization, to break this assumption one must discover a fast integer factorization algorithm. Instead, to break the random oracle assumption, one must discover some unknown and undesirable property of the actual hash function; for good hash functions where such properties are believed unlikely, the considered protocol can be considered secure.\n\n== Random Oracle Hypothesis ==\nAlthough the Baker\u2013Gill\u2013Solovay theorem showed that there exists an oracle A such that PA\n\n== Ideal Cipher ==\nAn ideal cipher is a random permutation oracle that is used to model an idealized block cipher. A random permutation decrypts each ciphertext block into one and only one plaintext block and vice versa, so there is a one-to-one correspondence. Some cryptographic proofs make not only the \"forward\" permutation available to all players, but also the \"reverse\" permutation.\nRecent works showed that an ideal cipher can be constructed from a random oracle using 10-round or even 8-round Feistel networks.\n\n== Ideal Permutation ==\nAn ideal permutation is an idealized object sometimes used in cryptography to model the behaviour of a permutation whose outputs are indistinguishable from those of a random permutation. In the ideal permutation model, an additional oracle access is given to the ideal permutation and its inverse. The ideal permutation model can be seen as a special case of the ideal cipher model where access is given to only a single permutation, instead of a family of permutations as in the case of the ideal cipher model.\n\n== Quantum-accessible Random Oracles ==\nPost-quantum cryptography studies quantum attacks on classical cryptographic schemes. As a random oracle is an abstraction of a hash function, it makes sense to assume that a quantum attacker can access the random oracle in quantum superposition. Many of the classical security proofs break down in that quantum random oracle model and need to be revised.\n\nBased on the above text, answer a question. What is the Random Oracle Hypothesis in cryptography?",
    "context": "",
    "output": "The Random Oracle Hypothesis is a conjecture that states that for every probabilistic polynomial-time algorithm A, the probability that A distinguishes the output of a random function from the output of a random oracle is negligible.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the Random Oracle Hypothesis in cryptography?",
      "answer": "The Random Oracle Hypothesis is a conjecture that states that for every probabilistic polynomial-time algorithm A, the probability that A distinguishes the output of a random function from the output of a random oracle is negligible.",
      "context": "Random oracle\n\n==Introduction==\nIn cryptography, a random oracle is an oracle (a theoretical black box) that responds to every unique query with a (truly) random response chosen uniformly from its output domain. If a query is repeated, it responds the same way every time that query is submitted.\nStated differently, a random oracle is a mathematical function chosen uniformly at random, that is, a function mapping each possible query to a (fixed) random response from its output domain.\nRandom oracles as a mathematical abstraction were first used in rigorous cryptographic proofs in the 1993 publication by Mihir Bellare and Phillip Rogaway (1993). They are typically used when the proof cannot be carried out using weaker assumptions on the cryptographic hash function. A system that is proven secure when every hash function is replaced by a random oracle is described as being secure in the random oracle model, as opposed to secure in the standard model of cryptography.\n\n== Applications ==\nRandom oracles are typically used as an idealised replacement for cryptographic hash functions in schemes where strong randomness assumptions are needed of the hash function's output. Such a proof often shows that a system or a protocol is secure by showing that an attacker must require impossible behavior from the oracle, or solve some mathematical problem believed hard in order to break it. However, it only proves such properties in the random oracle model, making sure no major design flaws are present. It is in general not true that such a proof implies the same properties in the standard model. Still, a proof in the random oracle model is considered better than no formal security proof at all.Not all uses of cryptographic hash functions require random oracles: schemes that require only one or more properties having a definition in the standard model (such as collision resistance, preimage resistance, second preimage resistance, etc.) can often be proven secure in the standard model (e.g., the Cramer\u2013Shoup cryptosystem).\nRandom oracles have long been considered in computational complexity theory, and many schemes have been proven secure in the random oracle model, for example Optimal Asymmetric Encryption Padding, RSA-FDH and Probabilistic Signature Scheme. In 1986, Amos Fiat and Adi Shamir showed a major application of random oracles \u2013 the removal of interaction from protocols for the creation of signatures.\nIn 1989, Russell Impagliazzo and Steven Rudich showed the limitation of random oracles \u2013 namely that their existence alone is not sufficient for secret-key exchange.\nIn 1993, Mihir Bellare and Phillip Rogaway were the first to advocate their use in cryptographic constructions. In their definition, the random oracle produces a bit-string of infinite length which can be truncated to the length desired.\nWhen a random oracle is used within a security proof, it is made available to all players, including the adversary or adversaries. A single oracle may be treated as multiple oracles by pre-pending a fixed bit-string to the beginning of each query (e.g., queries formatted as \"1|x\" or \"0|x\" can be considered as calls to two separate random oracles, similarly \"00|x\", \"01|x\", \"10|x\" and \"11|x\" can be used to represent calls to four separate random oracles).\n\n== Limitations ==\nAccording to the Church\u2013Turing thesis, no function computable by a finite algorithm can implement a true random oracle (which by definition requires an infinite description because it has infinitely many possible inputs, and its outputs are all independent from each other and need to be individually specified by any description).\nIn fact, certain artificial signature and encryption schemes are known which are proven secure in the random oracle model, but which are trivially insecure when any real function is substituted for the random oracle. Nonetheless, for any more natural protocol a proof of security in the random oracle model gives very strong evidence of the practical security of the protocol.In general, if a protocol is proven secure, attacks to that protocol must either be outside what was proven, or break one of the assumptions in the proof; for instance if the proof relies on the hardness of integer factorization, to break this assumption one must discover a fast integer factorization algorithm. Instead, to break the random oracle assumption, one must discover some unknown and undesirable property of the actual hash function; for good hash functions where such properties are believed unlikely, the considered protocol can be considered secure.\n\n== Random Oracle Hypothesis ==\nAlthough the Baker\u2013Gill\u2013Solovay theorem showed that there exists an oracle A such that PA\n\n== Ideal Cipher ==\nAn ideal cipher is a random permutation oracle that is used to model an idealized block cipher. A random permutation decrypts each ciphertext block into one and only one plaintext block and vice versa, so there is a one-to-one correspondence. Some cryptographic proofs make not only the \"forward\" permutation available to all players, but also the \"reverse\" permutation.\nRecent works showed that an ideal cipher can be constructed from a random oracle using 10-round or even 8-round Feistel networks.\n\n== Ideal Permutation ==\nAn ideal permutation is an idealized object sometimes used in cryptography to model the behaviour of a permutation whose outputs are indistinguishable from those of a random permutation. In the ideal permutation model, an additional oracle access is given to the ideal permutation and its inverse. The ideal permutation model can be seen as a special case of the ideal cipher model where access is given to only a single permutation, instead of a family of permutations as in the case of the ideal cipher model.\n\n== Quantum-accessible Random Oracles ==\nPost-quantum cryptography studies quantum attacks on classical cryptographic schemes. As a random oracle is an abstraction of a hash function, it makes sense to assume that a quantum attacker can access the random oracle in quantum superposition. Many of the classical security proofs break down in that quantum random oracle model and need to be revised."
    }
  },
  {
    "instruction": "Write an answer to the following question: How do spam emails use Typosquatting?",
    "context": "",
    "output": "Spam emails sometimes use Typosquatting URLs to trick users into visiting malicious sites that look like a given bank's site, for instance.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do spam emails use Typosquatting?",
      "answer": "Spam emails sometimes use Typosquatting URLs to trick users into visiting malicious sites that look like a given bank's site, for instance."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the role of independent key-bits between subciphers in a MITM attack?",
    "context": "",
    "output": "Independent key-bits between subciphers are crucial for a MITM attack to work, as they need to be bruteforced independently. The more rounds attacked, the larger the subciphers, which in turn reduces the number of independent key-bits between the subciphers.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of independent key-bits between subciphers in a MITM attack?",
      "answer": "Independent key-bits between subciphers are crucial for a MITM attack to work, as they need to be bruteforced independently. The more rounds attacked, the larger the subciphers, which in turn reduces the number of independent key-bits between the subciphers."
    }
  },
  {
    "instruction": "Context: Hash function security summary\n\n==Introduction==\nThis article summarizes publicly known attacks against cryptographic hash functions. Note that not all entries may be up to date. For a summary of other hash function parameters, see comparison of cryptographic hash functions.\n\n\n\n== Table color key ==\n\n== Common hash functions ==\n\n\n*** Collision resistance ***\n\n\n*** Chosen prefix collision attack ***\n\n\n*** Preimage resistance ***\n\n\n*** Length extension ***\n\nVulnerable: MD5, SHA1, SHA256, SHA512\nNot vulnerable: SHA384, SHA-3, BLAKE2\n\n== Less-common hash functions ==\n\n\n*** Collision resistance ***\n\n\n*** Preimage resistance ***\n\n== Attacks on hashed passwords ==\n\nHashes described here are designed for fast computation and have roughly similar speeds.  Because most users typically choose short passwords formed in predictable ways, passwords can often be recovered from their hashed value if a fast hash is used. Searches on the order of 100 billion tests per second are possible with high-end graphics processors.  \nSpecial hashes called key derivation functions have been created to slow brute force searches. These include pbkdf2, bcrypt, scrypt, argon2, and balloon.\n\nQuestion: What is the purpose of key derivation functions in cryptography?\n\nAnswer:",
    "context": "",
    "output": "The purpose of key derivation functions in cryptography is to slow down brute force searches by making it computationally expensive to compute the hash value.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the purpose of key derivation functions in cryptography?",
      "answer": "The purpose of key derivation functions in cryptography is to slow down brute force searches by making it computationally expensive to compute the hash value.",
      "context": "Hash function security summary\n\n==Introduction==\nThis article summarizes publicly known attacks against cryptographic hash functions. Note that not all entries may be up to date. For a summary of other hash function parameters, see comparison of cryptographic hash functions.\n\n\n\n== Table color key ==\n\n== Common hash functions ==\n\n\n*** Collision resistance ***\n\n\n*** Chosen prefix collision attack ***\n\n\n*** Preimage resistance ***\n\n\n*** Length extension ***\n\nVulnerable: MD5, SHA1, SHA256, SHA512\nNot vulnerable: SHA384, SHA-3, BLAKE2\n\n== Less-common hash functions ==\n\n\n*** Collision resistance ***\n\n\n*** Preimage resistance ***\n\n== Attacks on hashed passwords ==\n\nHashes described here are designed for fast computation and have roughly similar speeds.  Because most users typically choose short passwords formed in predictable ways, passwords can often be recovered from their hashed value if a fast hash is used. Searches on the order of 100 billion tests per second are possible with high-end graphics processors.  \nSpecial hashes called key derivation functions have been created to slow brute force searches. These include pbkdf2, bcrypt, scrypt, argon2, and balloon."
    }
  },
  {
    "instruction": "Write an answer to the following question: How do the UK ACPO guidelines address the audit trail of digital evidence?",
    "context": "",
    "output": "The UK ACPO guidelines address the audit trail of digital evidence by requiring that an audit trail or other record of all processes applied to digital evidence should be created and preserved. This allows an independent third party to examine those processes and achieve the same result.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do the UK ACPO guidelines address the audit trail of digital evidence?",
      "answer": "The UK ACPO guidelines address the audit trail of digital evidence by requiring that an audit trail or other record of all processes applied to digital evidence should be created and preserved. This allows an independent third party to examine those processes and achieve the same result."
    }
  },
  {
    "instruction": "Context: Pass the hash\n\n==Introduction==\nIn computer security, pass the hash is a hacking technique that allows an attacker to authenticate to a remote server or service by using the underlying NTLM or LanMan hash of a user's password, instead of requiring the associated plaintext password as is normally the case. It replaces the need for stealing the plaintext password to gain access with stealing the hash. \nThe attack exploits an implementation weakness in the authentication protocol, where password hashes remain static from session to session until the password is next changed.\nThis technique can be performed against any server or service accepting LM or NTLM authentication, whether it runs on a machine with Windows, Unix, or any other operating system.\n\n== Description ==\nOn systems or services using NTLM authentication, users' passwords are never sent in cleartext over the wire. Instead, they are provided to the requesting system, like a domain controller, as a hash in a response to a challenge\u2013response authentication scheme.Native Windows applications ask users for the cleartext password, then call APIs like LsaLogonUser that convert that password to one or two hash values (the LM or NT hashes) and then send that to the remote server during NTLM authentication.If an attacker has the hashes of a user's password, they do not need the cleartext password; they can simply use the hash to authenticate with a server and impersonate that user. In other words, from an attacker's perspective, hashes are functionally equivalent to the original passwords that they were generated from.\n\n== Hash harvesting ==\nBefore an attacker can carry out a pass-the-hash attack, they must obtain the password hashes of the target user accounts. To this end, penetration testers and attackers can harvest password hashes using a number of different methods:\n\nCached hashes or credentials of users who have previously logged onto a machine (for example at the console or via RDP) can be read from the SAM by anyone who has Administrator-level privileges. The default behavior of caching hashes or credentials for offline use can be disabled by administrators, so this technique may not always work if a machine has been sufficiently hardened.\nDumping the local user's account database (SAM). This database only contains user accounts local to the particular machine that was compromised. For example, in a domain environment, the SAM database of a machine will not contain domain users, only users local to that machine that more likely will not be very useful to authenticate to other services on the domain. However, if the same local administrative account passwords are used across multiple systems the attacker can remotely access those systems using the local user account hashes.\nSniffing LM and NTLM challenge\u2013response dialogues between client and servers, and later brute-forcing captured encrypted hashes (since the hashes obtained in this way are encrypted, it is necessary to perform a brute-force attack to obtain the actual hashes).\nDumping authenticated users' credentials stored by Windows in the memory of the lsass.exe process. The credentials dumped in this way may include those of domain users or administrators, such as those logged in via RDP. This technique may therefore be used to obtain credentials of user accounts that are not local to the compromised computer, but rather originate from the security domain that the machine is a member of.\n\n== Mitigations ==\nAny system using LM or NTLM authentication in combination with any communication protocol (SMB, FTP, RPC, HTTP etc.) is at risk from this attack. The exploit is very difficult to defend against, due to possible exploits in Windows and applications running on Windows that can be used by an attacker to elevate their privileges and then carry out the hash harvesting that facilitates the attack. Furthermore, it may only require one machine in a Windows domain to not be configured correctly or be missing a security patch for an attacker to find a way in. A wide range of penetration testing tools are furthermore available to automate the process of discovering a weakness on a machine.\nThere is no single defense against the technique, thus standard defense in depth practices apply \u2013 for example use of firewalls, intrusion prevention systems, 802.1x authentication, IPsec, antivirus software, reducing the number of people with elevated privileges, pro-active security patching etc.  Preventing Windows from storing cached credentials may limit attackers to obtaining hashes from memory, which usually means that the target account must be logged into the machine when the attack is executed. Allowing domain administrators to log into systems that may be compromised or untrusted will create a scenario where the administrators' hashes become the targets of attackers; limiting domain administrator logons to trusted domain controllers can therefore limit the opportunities for an attacker. The principle of least privilege suggests that a least user access (LUA) approach should be taken, in that users should not use accounts with more privileges than necessary to complete the task at hand. Configuring systems not to use LM or NTLM can also strengthen security, but newer exploits are able to forward Kerberos tickets in a similar way. Limiting the scope of debug privileges on system may frustrate some attacks that inject code or steal hashes from the memory of sensitive processes.Restricted Admin Mode is a new Windows operating system feature introduced in 2014 via security bulletin 2871997, which is designed to reduce the effectiveness of the attack.\n\nQuestion: How can an attacker obtain the password hashes of the target user accounts in order to carry out a pass the hash attack?\n\nAnswer:",
    "context": "",
    "output": "An attacker can harvest password hashes using methods such as reading cached hashes from the SAM, dumping the local user's account database, sniffing LM and NTLM challenge-response dialogues, and dumping authenticated users' credentials stored in the memory of the lsass.exe process.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can an attacker obtain the password hashes of the target user accounts in order to carry out a pass the hash attack?",
      "answer": "An attacker can harvest password hashes using methods such as reading cached hashes from the SAM, dumping the local user's account database, sniffing LM and NTLM challenge-response dialogues, and dumping authenticated users' credentials stored in the memory of the lsass.exe process.",
      "context": "Pass the hash\n\n==Introduction==\nIn computer security, pass the hash is a hacking technique that allows an attacker to authenticate to a remote server or service by using the underlying NTLM or LanMan hash of a user's password, instead of requiring the associated plaintext password as is normally the case. It replaces the need for stealing the plaintext password to gain access with stealing the hash. \nThe attack exploits an implementation weakness in the authentication protocol, where password hashes remain static from session to session until the password is next changed.\nThis technique can be performed against any server or service accepting LM or NTLM authentication, whether it runs on a machine with Windows, Unix, or any other operating system.\n\n== Description ==\nOn systems or services using NTLM authentication, users' passwords are never sent in cleartext over the wire. Instead, they are provided to the requesting system, like a domain controller, as a hash in a response to a challenge\u2013response authentication scheme.Native Windows applications ask users for the cleartext password, then call APIs like LsaLogonUser that convert that password to one or two hash values (the LM or NT hashes) and then send that to the remote server during NTLM authentication.If an attacker has the hashes of a user's password, they do not need the cleartext password; they can simply use the hash to authenticate with a server and impersonate that user. In other words, from an attacker's perspective, hashes are functionally equivalent to the original passwords that they were generated from.\n\n== Hash harvesting ==\nBefore an attacker can carry out a pass-the-hash attack, they must obtain the password hashes of the target user accounts. To this end, penetration testers and attackers can harvest password hashes using a number of different methods:\n\nCached hashes or credentials of users who have previously logged onto a machine (for example at the console or via RDP) can be read from the SAM by anyone who has Administrator-level privileges. The default behavior of caching hashes or credentials for offline use can be disabled by administrators, so this technique may not always work if a machine has been sufficiently hardened.\nDumping the local user's account database (SAM). This database only contains user accounts local to the particular machine that was compromised. For example, in a domain environment, the SAM database of a machine will not contain domain users, only users local to that machine that more likely will not be very useful to authenticate to other services on the domain. However, if the same local administrative account passwords are used across multiple systems the attacker can remotely access those systems using the local user account hashes.\nSniffing LM and NTLM challenge\u2013response dialogues between client and servers, and later brute-forcing captured encrypted hashes (since the hashes obtained in this way are encrypted, it is necessary to perform a brute-force attack to obtain the actual hashes).\nDumping authenticated users' credentials stored by Windows in the memory of the lsass.exe process. The credentials dumped in this way may include those of domain users or administrators, such as those logged in via RDP. This technique may therefore be used to obtain credentials of user accounts that are not local to the compromised computer, but rather originate from the security domain that the machine is a member of.\n\n== Mitigations ==\nAny system using LM or NTLM authentication in combination with any communication protocol (SMB, FTP, RPC, HTTP etc.) is at risk from this attack. The exploit is very difficult to defend against, due to possible exploits in Windows and applications running on Windows that can be used by an attacker to elevate their privileges and then carry out the hash harvesting that facilitates the attack. Furthermore, it may only require one machine in a Windows domain to not be configured correctly or be missing a security patch for an attacker to find a way in. A wide range of penetration testing tools are furthermore available to automate the process of discovering a weakness on a machine.\nThere is no single defense against the technique, thus standard defense in depth practices apply \u2013 for example use of firewalls, intrusion prevention systems, 802.1x authentication, IPsec, antivirus software, reducing the number of people with elevated privileges, pro-active security patching etc.  Preventing Windows from storing cached credentials may limit attackers to obtaining hashes from memory, which usually means that the target account must be logged into the machine when the attack is executed. Allowing domain administrators to log into systems that may be compromised or untrusted will create a scenario where the administrators' hashes become the targets of attackers; limiting domain administrator logons to trusted domain controllers can therefore limit the opportunities for an attacker. The principle of least privilege suggests that a least user access (LUA) approach should be taken, in that users should not use accounts with more privileges than necessary to complete the task at hand. Configuring systems not to use LM or NTLM can also strengthen security, but newer exploits are able to forward Kerberos tickets in a similar way. Limiting the scope of debug privileges on system may frustrate some attacks that inject code or steal hashes from the memory of sensitive processes.Restricted Admin Mode is a new Windows operating system feature introduced in 2014 via security bulletin 2871997, which is designed to reduce the effectiveness of the attack."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are the main components of reactionary detection techniques for DGA domain names?",
    "context": "",
    "output": "Reactionary detection relies on non-supervised clustering techniques and contextual information like network NXDOMAIN responses, WHOIS information, and passive DNS to make an assessment of domain name legitimacy.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are the main components of reactionary detection techniques for DGA domain names?",
      "answer": "Reactionary detection relies on non-supervised clustering techniques and contextual information like network NXDOMAIN responses, WHOIS information, and passive DNS to make an assessment of domain name legitimacy."
    }
  },
  {
    "instruction": "Write an answer to the following question: How can cross-domain resources be accessed using a proxy server and what are some benefits of this approach?",
    "context": "",
    "output": "Cross-domain resources can be accessed using a proxy server by making web requests to externally hosted resources when cross-domain restrictions prohibit the web site from linking directly to the outside domains. This allows web sites to make web requests to externally hosted resources without violating cross-domain restrictions and potentially exposing sensitive information.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can cross-domain resources be accessed using a proxy server and what are some benefits of this approach?",
      "answer": "Cross-domain resources can be accessed using a proxy server by making web requests to externally hosted resources when cross-domain restrictions prohibit the web site from linking directly to the outside domains. This allows web sites to make web requests to externally hosted resources without violating cross-domain restrictions and potentially exposing sensitive information."
    }
  },
  {
    "instruction": "Write an answer to the following question: Will F-Secure detect programs that might be used for terrorist activity or to benefit organized crime?",
    "context": "",
    "output": "Yes, F-Secure will detect any program they see that might be used for terrorist activity or to benefit organized crime, as stated in the Controversies section.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Will F-Secure detect programs that might be used for terrorist activity or to benefit organized crime?",
      "answer": "Yes, F-Secure will detect any program they see that might be used for terrorist activity or to benefit organized crime, as stated in the Controversies section."
    }
  },
  {
    "instruction": "NIST Special Publication 800-53\n\n==Introduction==\nNIST Special Publication 800-53 provides a catalog of security and privacy controls for all U.S. federal information systems except those related to national security. It is published by the National Institute of Standards and Technology, which is a non-regulatory agency of the United States Department of Commerce. NIST develops and issues standards, guidelines, and other publications to assist federal agencies in implementing the Federal Information Security Modernization Act of 2014 (FISMA) and to help with managing cost effective programs to protect their information and information systems.Two related documents are 800-53A and 800-53B which provide guidance, and baselines based on 800-53.\n\n\n\n== Purpose ==\nNIST Special Publication 800-53 is part of the Special Publication 800-series that reports on the Information Technology Laboratory's (ITL) research, guidelines, and outreach efforts in information system security, and on ITL's activity with industry, government, and academic organizations.Specifically, NIST Special Publication 800-53 covers the steps in the Risk Management Framework that address security control selection for federal information systems in accordance with the security requirements in Federal Information Processing Standard (FIPS) 200.  This includes selecting an initial set of baseline security controls based on a FIPS 199 worst-case impact analysis, tailoring the baseline security controls, and supplementing the security controls based on an organizational assessment of risk. The security rules cover 20 areas including access control, incident response, business continuity, and disaster recovery.A key part of the assessment and authorization (formerly certification and accreditation) process for federal information systems is selecting and implementing a subset of the controls (safeguards) from the Security Control Catalog (NIST 800-53, Appendix F) . These controls are the management, operational, and technical safeguards (or countermeasures) prescribed for an information system to protect the confidentiality, integrity, and availability of the system and its information.  To implement the needed safeguards or controls, agencies must first determine the security category of their information systems in accordance with the provisions of FIPS 199, \u201cStandards for Security Categorization of Federal Information and Information Systems.\u201d  The security categorization of the information system (low, moderate or high) determines the baseline collection of controls that must be implemented and monitored. Agencies have the ability to adjust these controls and tailor them to fit more closely with their organizational goals or environments.\n\n== Compliance ==\nAlthough any private organization can adopt the use of NIST 800-53 as a guiding framework for their security practice, all U.S. federal government agencies and contractors are required to comply with the framework in order to protect their critical data.\nAgencies are expected to be compliant with NIST security standards and guidelines within one year of the publication date (February 2005) unless otherwise directed.  Information systems that are under development are expected to be compliant upon deployment.\n\n== Revisions ==\n\n\n*** Initial release ***\nNIST Special Publication 800-53 was initially released in February 2005 as \"Recommended Security Controls for Federal Information Systems.\"\n\n\n*** First revision ***\nNIST Special Publication 800-53 Revision 1 was initially released in December 2006 as \"Recommended Security Controls for Federal Information Systems.\"\n\n\n*** Second revision ***\nNIST Special Publication 800-53 Revision 2 was initially released in December 2007 as \"Recommended Security Controls for Federal Information Systems.\"\n\n\n*** Third revision ***\nThe third version of NIST's Special Publication 800-53, \"Recommended Security Controls for Federal Information Systems and Organizations,\" incorporates several recommendations from people who commented on previously published versions, who recommended a reduction in the number of security controls for low-impact systems, a new set of application-level controls and greater discretionary powers for organizations to downgrade controls.  Also included in the final draft is language that allows federal agencies to keep their existing security measures if they can demonstrate that the level of security is equivalent to the standards being proposed by NIST. The third version also represents an effort to harmonize security requirements across government communities and between government and non-government systems. In the past, NIST guidance has not applied to government information systems identified as national security systems.  The management, operational, and technical controls in SP 800-53 Revision 3 provide a common information security language for all government information systems. The revised security control catalog also includes state-of-the-practice safeguards and countermeasures to address advanced cyber threats and exploits. Significant changes in this revision of the document include\n\nA simplified, six-step risk management framework;\nAdditional security controls and enhancements for advanced cyber threats;\nRecommendations for prioritizing security controls during implementation or deployment;\nRevised security control structure with a new references section;\nElimination of security requirements from supplemental guidance sections;\nGuidance on using the risk management framework for legacy information systems and for external information system services providers;\nUpdates to security control baselines based on current threat information and cyber attacks;\nOrganization-level security controls for managing information security programs;\nGuidance on the management of common controls within organizations; and\nStrategy for harmonizing FISMA security standards and guidelines with international security standard ISO/IEC 27001.\n\n\n*** Fourth revision ***\nAs part of the ongoing cyber security partnership among the United States Department of Defense, the intelligence community, and the federal civil agencies, NIST has launched its biennial update to Special Publication 800\u201053, \"Security and Privacy Controls for Federal Information Systems and Organizations,\" with an initial public draft released on February 28, 2012. The 2011\u201312 initiative will include an update of current security controls, control enhancements, supplemental guidance and an update on tailoring and supplementation guidance that form key elements of the control selection process. Key focus areas include, but are not limited to:\n\nInsider threats;\nSoftware application security (including web applications);\nSocial networking, mobiles devices, and cloud computing;\nCross domain solutions;\nAdvanced persistent threats;\nSupply chain security;\nPrivacy.Revision 4 is broken up into 18 control families, including:\n\nAC - Access Control\nAU - Audit and Accountability\nAT - Awareness and Training\nCM - Configuration Management\nCP - Contingency Planning\nIA - Identification and Authentication\nIR - Incident Response\nMA - Maintenance\nMP - Media Protection\nPS - Personnel Security\nPE - Physical and Environmental Protection\nPL - Planning\nPM - Program Management\nRA - Risk Assessment\nCA - Security Assessment and Authorization\nSC - System and Communications Protection\nSI - System and Information Integrity\nSA - System and Services AcquisitionInformation on these control families and the controls contained within can be found on the NIST website at the following link: https://nvd.nist.gov/800-53/Rev4\n\n\n*** Fifth revision ***\nNIST SP 800-53 Revision 5 removes the word \"federal\" to indicate that these regulations may be applied to all organizations, not just federal organizations. The first public draft was published on August 15, 2017. A final draft release was set for publication in December 2018, with the final publication date set for March 2019.\" Per the NIST Computer Security Resource Center (CSRC), major changes to the publication include:\n\nMaking the security and privacy controls more outcome-based by changing the structure of the controls;\nFully integrating the privacy controls into the security control catalog creating a consolidated and unified set of controls for systems and organizations;\nSeparating the control selection process from the actual controls, thus allowing the controls to be used by different communities of interest including systems engineers, software developers, enterprise architects; and mission/business owners;\nEliminating the term information system and replacing it with the term system so the controls can be applied to any type of system including, for example, general-purpose systems, cyber-physical systems, industrial/process control systems, and IoT devices;\nDe-emphasizing the federal focus of the publication to encourage greater use by nonfederal organizations;\nPromoting integration with different risk management and cyber security approaches and lexicons, including the Cybersecurity Framework;\nClarifying the relationship between security and privacy to improve the selection of controls necessary to address the full scope of security and privacy risks; and\nIncorporating new, state of the practice controls based on threat intelligence and empirical attack data, including controls to strengthen cybersecurity and privacy governance and accountability.As of September 2019, Revision 5 was delayed due to a potential disagreement among the Office of Information and Regulatory Affairs (OIRA) and other U.S. agencies.The final version of Revision 5 was released on September 23, 2020 and is available on the NIST website at the following link: https://csrc.nist.gov/publications/detail/sp/800-53/rev-5/final\n\n== 800-53A ==\nNIST Special Publication 800-53A provides a set of procedures for conducting assessments of security controls and privacy controls employed within federal information systems and organizations. The procedures are customizable and can be easily tailored to provide organizations with the needed flexibility to conduct security control assessments and privacy control assessments that support organizational risk management processes and that are aligned with the stated risk tolerance of the organization. Information on building effective security assessment plans and privacy assessment plans is also provided along with guidance on analyzing assessment results.\n\n\n*** Revision 1 ***\nNIST Special Publication 800-53A is titled \u201cGuide for Assessing Security Controls in Federal Information Systems and Organizations.\"  This version will describe testing and evaluation procedures for the 17 required control families.  These assessment guidelines are designed to enable periodic testing and are used by federal agencies to determine what security controls are necessary to protect organizational operations and assets, individuals, other organizations, and the nation.\nAccording to Ron Ross, senior computer scientist and information security researcher at NIST, these guidelines will also allow federal agencies to assess \"if mandated controls have been implemented correctly, are operating as intended, and are... meeting the organization's security requirements.\"\nTo do this, version A describes assessment methods and procedures for each of the security controls mandated in Special Publication 800-53. These methods and procedures are to be used as guidelines for federal agencies.  These guidelines are meant to limit confusion and ensure that agencies interpret and implement the security controls in the same way.\n\n\n*** Revision 4 ***\nNIST SP 800-53A Revision 4 is Assessing Security and Privacy Controls in Federal Information Systems and Organizations. The Revision number went from Revision 1 to Revision 4 in order to better reflect the NIST Special Publication 800-53 it is meant to be used with.\n\n== 800-53B ==\nNIST Special Publication 800-53B provides a set of baseline security controls and privacy controls for information systems and organizations. The baselines establish default controls based on FISMA rates (Privacy, Low, Moderate, and High) and can be easily tailored to organizational risk management processes.\nInformation on building effective security assessment plans and privacy assessment plans is also provided along with guidance on analyzing assessment results.\n\n\n*** Initial release ***\nNIST Special Publication 800-53B was initially released in September 2020 as \"Control Baselines for Information Systems and Organizations.\"\n\nQ: How does NIST Special Publication 800-53 Revision 5 promote integration with different risk management and cyber security approaches and lexicons, including the Cybersecurity Framework?",
    "context": "",
    "output": "A: NIST Special Publication 800-53 Revision 5 promotes integration with different risk management and cyber security approaches and lexicons, including the Cybersecurity Framework by making the security and privacy controls more outcome-based by changing the structure of the controls, fully integrating the privacy controls into the security control catalog creating a consolidated and unified set of controls for systems and organizations, separating the control selection process from the actual controls, thus allowing the controls to be used by different communities of interest including systems engineers, software developers, enterprise architects, and mission/business owners, eliminating the term information system and replacing it with the term system so the controls can be applied to any type of system, de-emphasizing the federal focus of the publication to encourage greater use by nonfederal organizations, clarifying the relationship between security and privacy to improve the selection of controls necessary to address the full scope of security and privacy risks, and incorporating new, state of the practice controls based on threat intelligence and empirical attack data, including controls to strengthen cybersecurity and privacy governance and accountability.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does NIST Special Publication 800-53 Revision 5 promote integration with different risk management and cyber security approaches and lexicons, including the Cybersecurity Framework?",
      "answer": "NIST Special Publication 800-53 Revision 5 promotes integration with different risk management and cyber security approaches and lexicons, including the Cybersecurity Framework by making the security and privacy controls more outcome-based by changing the structure of the controls, fully integrating the privacy controls into the security control catalog creating a consolidated and unified set of controls for systems and organizations, separating the control selection process from the actual controls, thus allowing the controls to be used by different communities of interest including systems engineers, software developers, enterprise architects, and mission/business owners, eliminating the term information system and replacing it with the term system so the controls can be applied to any type of system, de-emphasizing the federal focus of the publication to encourage greater use by nonfederal organizations, clarifying the relationship between security and privacy to improve the selection of controls necessary to address the full scope of security and privacy risks, and incorporating new, state of the practice controls based on threat intelligence and empirical attack data, including controls to strengthen cybersecurity and privacy governance and accountability.",
      "context": "NIST Special Publication 800-53\n\n==Introduction==\nNIST Special Publication 800-53 provides a catalog of security and privacy controls for all U.S. federal information systems except those related to national security. It is published by the National Institute of Standards and Technology, which is a non-regulatory agency of the United States Department of Commerce. NIST develops and issues standards, guidelines, and other publications to assist federal agencies in implementing the Federal Information Security Modernization Act of 2014 (FISMA) and to help with managing cost effective programs to protect their information and information systems.Two related documents are 800-53A and 800-53B which provide guidance, and baselines based on 800-53.\n\n\n\n== Purpose ==\nNIST Special Publication 800-53 is part of the Special Publication 800-series that reports on the Information Technology Laboratory's (ITL) research, guidelines, and outreach efforts in information system security, and on ITL's activity with industry, government, and academic organizations.Specifically, NIST Special Publication 800-53 covers the steps in the Risk Management Framework that address security control selection for federal information systems in accordance with the security requirements in Federal Information Processing Standard (FIPS) 200.  This includes selecting an initial set of baseline security controls based on a FIPS 199 worst-case impact analysis, tailoring the baseline security controls, and supplementing the security controls based on an organizational assessment of risk. The security rules cover 20 areas including access control, incident response, business continuity, and disaster recovery.A key part of the assessment and authorization (formerly certification and accreditation) process for federal information systems is selecting and implementing a subset of the controls (safeguards) from the Security Control Catalog (NIST 800-53, Appendix F) . These controls are the management, operational, and technical safeguards (or countermeasures) prescribed for an information system to protect the confidentiality, integrity, and availability of the system and its information.  To implement the needed safeguards or controls, agencies must first determine the security category of their information systems in accordance with the provisions of FIPS 199, \u201cStandards for Security Categorization of Federal Information and Information Systems.\u201d  The security categorization of the information system (low, moderate or high) determines the baseline collection of controls that must be implemented and monitored. Agencies have the ability to adjust these controls and tailor them to fit more closely with their organizational goals or environments.\n\n== Compliance ==\nAlthough any private organization can adopt the use of NIST 800-53 as a guiding framework for their security practice, all U.S. federal government agencies and contractors are required to comply with the framework in order to protect their critical data.\nAgencies are expected to be compliant with NIST security standards and guidelines within one year of the publication date (February 2005) unless otherwise directed.  Information systems that are under development are expected to be compliant upon deployment.\n\n== Revisions ==\n\n\n*** Initial release ***\nNIST Special Publication 800-53 was initially released in February 2005 as \"Recommended Security Controls for Federal Information Systems.\"\n\n\n*** First revision ***\nNIST Special Publication 800-53 Revision 1 was initially released in December 2006 as \"Recommended Security Controls for Federal Information Systems.\"\n\n\n*** Second revision ***\nNIST Special Publication 800-53 Revision 2 was initially released in December 2007 as \"Recommended Security Controls for Federal Information Systems.\"\n\n\n*** Third revision ***\nThe third version of NIST's Special Publication 800-53, \"Recommended Security Controls for Federal Information Systems and Organizations,\" incorporates several recommendations from people who commented on previously published versions, who recommended a reduction in the number of security controls for low-impact systems, a new set of application-level controls and greater discretionary powers for organizations to downgrade controls.  Also included in the final draft is language that allows federal agencies to keep their existing security measures if they can demonstrate that the level of security is equivalent to the standards being proposed by NIST. The third version also represents an effort to harmonize security requirements across government communities and between government and non-government systems. In the past, NIST guidance has not applied to government information systems identified as national security systems.  The management, operational, and technical controls in SP 800-53 Revision 3 provide a common information security language for all government information systems. The revised security control catalog also includes state-of-the-practice safeguards and countermeasures to address advanced cyber threats and exploits. Significant changes in this revision of the document include\n\nA simplified, six-step risk management framework;\nAdditional security controls and enhancements for advanced cyber threats;\nRecommendations for prioritizing security controls during implementation or deployment;\nRevised security control structure with a new references section;\nElimination of security requirements from supplemental guidance sections;\nGuidance on using the risk management framework for legacy information systems and for external information system services providers;\nUpdates to security control baselines based on current threat information and cyber attacks;\nOrganization-level security controls for managing information security programs;\nGuidance on the management of common controls within organizations; and\nStrategy for harmonizing FISMA security standards and guidelines with international security standard ISO/IEC 27001.\n\n\n*** Fourth revision ***\nAs part of the ongoing cyber security partnership among the United States Department of Defense, the intelligence community, and the federal civil agencies, NIST has launched its biennial update to Special Publication 800\u201053, \"Security and Privacy Controls for Federal Information Systems and Organizations,\" with an initial public draft released on February 28, 2012. The 2011\u201312 initiative will include an update of current security controls, control enhancements, supplemental guidance and an update on tailoring and supplementation guidance that form key elements of the control selection process. Key focus areas include, but are not limited to:\n\nInsider threats;\nSoftware application security (including web applications);\nSocial networking, mobiles devices, and cloud computing;\nCross domain solutions;\nAdvanced persistent threats;\nSupply chain security;\nPrivacy.Revision 4 is broken up into 18 control families, including:\n\nAC - Access Control\nAU - Audit and Accountability\nAT - Awareness and Training\nCM - Configuration Management\nCP - Contingency Planning\nIA - Identification and Authentication\nIR - Incident Response\nMA - Maintenance\nMP - Media Protection\nPS - Personnel Security\nPE - Physical and Environmental Protection\nPL - Planning\nPM - Program Management\nRA - Risk Assessment\nCA - Security Assessment and Authorization\nSC - System and Communications Protection\nSI - System and Information Integrity\nSA - System and Services AcquisitionInformation on these control families and the controls contained within can be found on the NIST website at the following link: https://nvd.nist.gov/800-53/Rev4\n\n\n*** Fifth revision ***\nNIST SP 800-53 Revision 5 removes the word \"federal\" to indicate that these regulations may be applied to all organizations, not just federal organizations. The first public draft was published on August 15, 2017. A final draft release was set for publication in December 2018, with the final publication date set for March 2019.\" Per the NIST Computer Security Resource Center (CSRC), major changes to the publication include:\n\nMaking the security and privacy controls more outcome-based by changing the structure of the controls;\nFully integrating the privacy controls into the security control catalog creating a consolidated and unified set of controls for systems and organizations;\nSeparating the control selection process from the actual controls, thus allowing the controls to be used by different communities of interest including systems engineers, software developers, enterprise architects; and mission/business owners;\nEliminating the term information system and replacing it with the term system so the controls can be applied to any type of system including, for example, general-purpose systems, cyber-physical systems, industrial/process control systems, and IoT devices;\nDe-emphasizing the federal focus of the publication to encourage greater use by nonfederal organizations;\nPromoting integration with different risk management and cyber security approaches and lexicons, including the Cybersecurity Framework;\nClarifying the relationship between security and privacy to improve the selection of controls necessary to address the full scope of security and privacy risks; and\nIncorporating new, state of the practice controls based on threat intelligence and empirical attack data, including controls to strengthen cybersecurity and privacy governance and accountability.As of September 2019, Revision 5 was delayed due to a potential disagreement among the Office of Information and Regulatory Affairs (OIRA) and other U.S. agencies.The final version of Revision 5 was released on September 23, 2020 and is available on the NIST website at the following link: https://csrc.nist.gov/publications/detail/sp/800-53/rev-5/final\n\n== 800-53A ==\nNIST Special Publication 800-53A provides a set of procedures for conducting assessments of security controls and privacy controls employed within federal information systems and organizations. The procedures are customizable and can be easily tailored to provide organizations with the needed flexibility to conduct security control assessments and privacy control assessments that support organizational risk management processes and that are aligned with the stated risk tolerance of the organization. Information on building effective security assessment plans and privacy assessment plans is also provided along with guidance on analyzing assessment results.\n\n\n*** Revision 1 ***\nNIST Special Publication 800-53A is titled \u201cGuide for Assessing Security Controls in Federal Information Systems and Organizations.\"  This version will describe testing and evaluation procedures for the 17 required control families.  These assessment guidelines are designed to enable periodic testing and are used by federal agencies to determine what security controls are necessary to protect organizational operations and assets, individuals, other organizations, and the nation.\nAccording to Ron Ross, senior computer scientist and information security researcher at NIST, these guidelines will also allow federal agencies to assess \"if mandated controls have been implemented correctly, are operating as intended, and are... meeting the organization's security requirements.\"\nTo do this, version A describes assessment methods and procedures for each of the security controls mandated in Special Publication 800-53. These methods and procedures are to be used as guidelines for federal agencies.  These guidelines are meant to limit confusion and ensure that agencies interpret and implement the security controls in the same way.\n\n\n*** Revision 4 ***\nNIST SP 800-53A Revision 4 is Assessing Security and Privacy Controls in Federal Information Systems and Organizations. The Revision number went from Revision 1 to Revision 4 in order to better reflect the NIST Special Publication 800-53 it is meant to be used with.\n\n== 800-53B ==\nNIST Special Publication 800-53B provides a set of baseline security controls and privacy controls for information systems and organizations. The baselines establish default controls based on FISMA rates (Privacy, Low, Moderate, and High) and can be easily tailored to organizational risk management processes.\nInformation on building effective security assessment plans and privacy assessment plans is also provided along with guidance on analyzing assessment results.\n\n\n*** Initial release ***\nNIST Special Publication 800-53B was initially released in September 2020 as \"Control Baselines for Information Systems and Organizations.\""
    }
  },
  {
    "instruction": "Write an answer to the following question: What are the primary concerns of a key management system (KMS)?",
    "context": "",
    "output": "A KMS is responsible for generating, establishing, storing, using, and replacing cryptographic keys, ensuring their security throughout their lifecycle.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are the primary concerns of a key management system (KMS)?",
      "answer": "A KMS is responsible for generating, establishing, storing, using, and replacing cryptographic keys, ensuring their security throughout their lifecycle."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does SoftEther VPN optimize performance?",
    "context": "",
    "output": "SoftEther VPN optimizes performance by using full Ethernet frame utilization, reducing memory copy operations, parallel transmission, and clustering. These features reduce latency and increase throughput, making VPN connections faster.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does SoftEther VPN optimize performance?",
      "answer": "SoftEther VPN optimizes performance by using full Ethernet frame utilization, reducing memory copy operations, parallel transmission, and clustering. These features reduce latency and increase throughput, making VPN connections faster."
    }
  },
  {
    "instruction": "Write an answer to the following question: What did the M-94 consist of?",
    "context": "",
    "output": "The M-94 consisted of 25 aluminum discs attached to a four-and-a-half inch long rod, with each disc containing the 26 letters of the Roman alphabet in scrambled order around its circumference.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What did the M-94 consist of?",
      "answer": "The M-94 consisted of 25 aluminum discs attached to a four-and-a-half inch long rod, with each disc containing the 26 letters of the Roman alphabet in scrambled order around its circumference."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the Cameron MegaHAL speech bot and what is its significance to Telecomix?",
    "context": "",
    "output": "The Cameron MegaHAL speech bot is a computer generated representation of all Telecomix activists and has become a core symbol for the organization. Its function in governing the actions of the activists remains obscure.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the Cameron MegaHAL speech bot and what is its significance to Telecomix?",
      "answer": "The Cameron MegaHAL speech bot is a computer generated representation of all Telecomix activists and has become a core symbol for the organization. Its function in governing the actions of the activists remains obscure."
    }
  },
  {
    "instruction": "Answer based on context:\n\nNetwork enumeration\n\n==Introduction==\nNetwork enumeration is a computing activity in which usernames and info on groups, shares, and services of networked computers are retrieved. It should not be confused with network mapping, which only retrieves information about which servers are connected to a specific network and what operating system runs on them.\nNetwork enumeration is the discovery of hosts or devices on a network. Network enumeration tends to use overt discovery protocols such as ICMP and SNMP to gather information. It may also scan various ports on remote hosts for looking for well known services in an attempt to further identify the function of a remote host. The next stage of enumeration is to fingerprint the operating system of the remote host.\n\n== Software ==\nA network enumerator or network scanner is a computer program used to retrieve usernames and info on groups, shares, and services of networked computers. This type of program scans networks for vulnerabilities in the security of that network. If there is a vulnerability with the security of the network, it will send a report back to a hacker who may use this info to exploit that network glitch to gain entry to the network or for other malicious activities. Ethical hackers often also use the information to remove the glitches and strengthen their network.\nMalicious (or \"black-hat\") hackers can, on entry of the network, get to security-sensitive information or corrupt the network making it useless. If this network belonged to a company which used this network on a regular basis, the company would lose the function to send information internally to other departments.\nNetwork enumerators are often used by script kiddies for ease of use, as well as by more experienced hackers in cooperation with other programs/manual lookups. Also, whois queries, zone transfers, ping sweeps, and traceroute can be performed.\n\n== List of network enumerators ==\nMetasploit Project\nNmap\nNessus\nOpenVAS\nSAINT (software)\nSecurity Administrator Tool for Analyzing Networks\nZMap (software)\n\nWhat information does a network enumerator or scanner look for in a network?",
    "context": "",
    "output": "Network enumerators scan networks for vulnerabilities in the security of that network, retrieving usernames, group, shares, and service information.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What information does a network enumerator or scanner look for in a network?",
      "answer": "Network enumerators scan networks for vulnerabilities in the security of that network, retrieving usernames, group, shares, and service information.",
      "context": "Network enumeration\n\n==Introduction==\nNetwork enumeration is a computing activity in which usernames and info on groups, shares, and services of networked computers are retrieved. It should not be confused with network mapping, which only retrieves information about which servers are connected to a specific network and what operating system runs on them.\nNetwork enumeration is the discovery of hosts or devices on a network. Network enumeration tends to use overt discovery protocols such as ICMP and SNMP to gather information. It may also scan various ports on remote hosts for looking for well known services in an attempt to further identify the function of a remote host. The next stage of enumeration is to fingerprint the operating system of the remote host.\n\n== Software ==\nA network enumerator or network scanner is a computer program used to retrieve usernames and info on groups, shares, and services of networked computers. This type of program scans networks for vulnerabilities in the security of that network. If there is a vulnerability with the security of the network, it will send a report back to a hacker who may use this info to exploit that network glitch to gain entry to the network or for other malicious activities. Ethical hackers often also use the information to remove the glitches and strengthen their network.\nMalicious (or \"black-hat\") hackers can, on entry of the network, get to security-sensitive information or corrupt the network making it useless. If this network belonged to a company which used this network on a regular basis, the company would lose the function to send information internally to other departments.\nNetwork enumerators are often used by script kiddies for ease of use, as well as by more experienced hackers in cooperation with other programs/manual lookups. Also, whois queries, zone transfers, ping sweeps, and traceroute can be performed.\n\n== List of network enumerators ==\nMetasploit Project\nNmap\nNessus\nOpenVAS\nSAINT (software)\nSecurity Administrator Tool for Analyzing Networks\nZMap (software)"
    }
  },
  {
    "instruction": "Key schedule\n\n==Introduction==\nIn cryptography, the so-called product ciphers are a certain kind of cipher, where the (de-)ciphering of data is typically done as an iteration of rounds.  The setup for each round is generally the same, except for round-specific fixed values called a round constant, and round-specific data derived from the cipher key called a round key.  A key schedule is an algorithm that calculates all the round keys from the key.\n\n== Some types of key schedules ==\nSome ciphers have simple key schedules. For example, the block cipher TEA splits the 128-bit key into four 32-bit pieces and uses them repeatedly in successive rounds.\nDES has a key schedule in which the 56-bit key is divided into two 28-bit halves; each half is thereafter treated separately. In successive rounds, both halves are rotated left by one or two bits (specified for each round), and then 48 round key bits are selected by Permuted Choice 2 (PC-2) \u2013 24 bits from the left half and 24 from the right. The rotations have the effect that a different set of bits is used in each round key; each bit is used in approximately 14 out of the 16 round keys.\nTo avoid simple relationships between the cipher key and the round keys, in order to resist such forms of cryptanalysis as related-key attacks and slide attacks, many modern ciphers use more elaborate key schedules to generate an \"expanded key\" from which round keys are drawn. Some ciphers, such as Rijndael (AES) and Blowfish, use the same operations as those used in the data path of the cipher algorithm for their key expansion, sometimes initialized with some \"nothing-up-my-sleeve numbers\". Other ciphers, such as RC5, expand keys with functions that are somewhat or completely different from the encryption functions.\n\nHow does RC5 expand keys in its key schedule differently from the encryption functions?",
    "context": "",
    "output": "A: RC5 expands keys with functions that are different from the encryption functions, making it more difficult for attackers to exploit possible relationships between the cipher key and round keys.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does RC5 expand keys in its key schedule differently from the encryption functions?",
      "answer": "RC5 expands keys with functions that are different from the encryption functions, making it more difficult for attackers to exploit possible relationships between the cipher key and round keys.",
      "context": "Key schedule\n\n==Introduction==\nIn cryptography, the so-called product ciphers are a certain kind of cipher, where the (de-)ciphering of data is typically done as an iteration of rounds.  The setup for each round is generally the same, except for round-specific fixed values called a round constant, and round-specific data derived from the cipher key called a round key.  A key schedule is an algorithm that calculates all the round keys from the key.\n\n== Some types of key schedules ==\nSome ciphers have simple key schedules. For example, the block cipher TEA splits the 128-bit key into four 32-bit pieces and uses them repeatedly in successive rounds.\nDES has a key schedule in which the 56-bit key is divided into two 28-bit halves; each half is thereafter treated separately. In successive rounds, both halves are rotated left by one or two bits (specified for each round), and then 48 round key bits are selected by Permuted Choice 2 (PC-2) \u2013 24 bits from the left half and 24 from the right. The rotations have the effect that a different set of bits is used in each round key; each bit is used in approximately 14 out of the 16 round keys.\nTo avoid simple relationships between the cipher key and the round keys, in order to resist such forms of cryptanalysis as related-key attacks and slide attacks, many modern ciphers use more elaborate key schedules to generate an \"expanded key\" from which round keys are drawn. Some ciphers, such as Rijndael (AES) and Blowfish, use the same operations as those used in the data path of the cipher algorithm for their key expansion, sometimes initialized with some \"nothing-up-my-sleeve numbers\". Other ciphers, such as RC5, expand keys with functions that are somewhat or completely different from the encryption functions."
    }
  },
  {
    "instruction": "Online identity management\n\n==Introduction==\nOnline identity management (OIM), also known as online image management, online personal branding, or personal reputation management (PRM),  is a set of methods for generating a distinguished Web presence of a person on the Internet. Online identity management also refers to identity exposure and identity disclosure, and has particularly developed in the management on online identity in social network services or online dating services.\n\n== Aspects ==\nOne aspect of the online identity management process has to do with improving the quantity and quality of traffic to sites that have content related to a person. In that aspect, OIM is a part of another discipline called search engine optimization with the difference that the only keyword is the person's name, and the optimization object is not necessary a single web site; it can consider a set of completely different sites that contain positive online references. The objective in this case is to get high rankings for as many sites as possible when someone search for a person's name. If the search engine used is Google, this action is called \"to google someone\".Another aspect has to do with impression management, i.e. \"the process through which people try to control the impressions other people form of them\". One of the objectives, in particular, is to increase the online reputation of the person.\nPseudonyms are sometimes used to protect the true online identity of individuals from harm. This can be the case when presenting unpopular views or dissenting opinion online in a way that will not affect the true identity of the author. Facebook estimates that up to 11.2% of accounts are fake. Many of these profiles are used as logins to protect the true identity of online authors.An individual's presence could be reflected in any kind of content that refers to that person, including news, participation in blogs and forums, personal web sites, social media presence, pictures, video, etc. Because of that, online identity management often involves participation in social media sites like Facebook, Google+, LinkedIn, Flickr, YouTube, Twitter, Last.fm, Myspace, Quora, Tumblr, Pinterest and other online communities and community websites, and is related to blogging, blog social networks like MyBlogLog and blog search engines like Technorati.\nOIM can serve specific purposes such as a professional networking platform. OSN platforms represent who the user is and what attributes they bring to the world. The information a user can plug into their profile is usually not verified, which can lead to specifics forms of false identity. OIM can also consist in more questionable practices such as the case of buying \"likes\", \"friends\", or \"subscribers\".\n\n== Objective ==\nThe Objective of Online Identity Management is to:\n\nMaximize the appearances of positive online references about a specific person, targeting not only to users that actively search for that person on any search engine, but also to those that eventually can reach a person's reference while browsing the web.\nBuild an online identity in case the person's web presence is minimal or nonexistent.\nSolve online reputation problems. In this case, the process can also be named online reputation management.\nTo express opinions that may be unheard, if the person's reputation wasn't previously favored.Online Identity management can be utilized on a personal and professional level. Online identity management utilizes web presence to gain attention from potential huge clients to followers. A person managing online identity will use social media sites like Twitter, Facebook, Instagram Youtube, Snapchat, and networking sites to increase their online activity. They also use other tools like search engine optimization and advertisements to boost their audience and gain insights on their audience. Online Identity Management is most effective with the use of all social networking sites and posting frequently. This technique is used to target their audience and to make sure their audience does not miss any content. Additionally, Online Identity Management can be used to manipulate followers, viewers, and clients by using misleading or over-exaggerated information.\n\n== Motivation ==\nThe reason why someone would be interested in doing online identity management is closely related to the increasing number of constituencies that use the internet as a tool to find information about people. A survey by CareerBuilder.com found that one in four hiring managers used search engines to screen candidates. One in 10 also checked candidates' profiles on social networking sites such as Facebook, Instagram, Twitter, Youtube and other communicative networks. According to a December 2007 survey by the Ponemon Institute, a privacy research organization, roughly half of U.S. hiring officials use the Internet in vetting job applications. Online identity management may also be used to increase an individual's professional online presence. When practicing online identity management, employers receive a satisfied notion regarding their candidate's professional attitudes and personality. This may result in a candidate receiving the job based on their professional online presence. Online Identity management is key to having a successful business and relationship with the public. An online presence is vital to the digital world we live in today. Many employers check the social network account of their candidate to grasp the kind of person they are. Even after being hired companies will continuously check account to ensure professionalism and company privacy is being maintained.The concept of manipulating search results to show positive results is intriguing for both individuals and businesses. Individuals that want to hide from their past can use OIM to repair their online image and suppress content that damages their credibility, employability and reputation. By changing what people see when searching for an individual, they are able to create a completely new and positive identity in its place. In 2014, the EU ruled that people have \"The right to be forgotten\", and that in some circumstances content can be removed from Google's search index.\nIn 1988, the European Union passed the Safe Harbor Act which prohibited the sharing unauthorized personal information. Many companies to this day voluntarily comply to this law; however, it is the job of the user to fully ensure the safety of their online identity. The European Union later passed the a landmark ruling back in 2014, that stated that all individuals have the \"right to be forgotten\". This granted user's the removal of all irrelevant data that could harm one's online identityOnline identity management is also a factor and important when a person is seeking a need or good. Depending on companies online viewers and content can encourage or discourage a sale. Online identity management is important because decisions can be made depending on online activity. Depending on the motives of the goods, company, and person their online identity should serve the purpose of heightening their likeness, attractiveness, and exposure.\nQ: What is the objective of OIM in terms of search engine optimization?",
    "context": "",
    "output": "The objective of OIM in terms of search engine optimization is to maximize the appearances of positive online references about a specific person, targeting not only users who actively search for that person on any search engine, but also those who can eventually reach the person's reference while browsing the web.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the objective of OIM in terms of search engine optimization?",
      "answer": "The objective of OIM in terms of search engine optimization is to maximize the appearances of positive online references about a specific person, targeting not only users who actively search for that person on any search engine, but also those who can eventually reach the person's reference while browsing the web.",
      "context": "Online identity management\n\n==Introduction==\nOnline identity management (OIM), also known as online image management, online personal branding, or personal reputation management (PRM),  is a set of methods for generating a distinguished Web presence of a person on the Internet. Online identity management also refers to identity exposure and identity disclosure, and has particularly developed in the management on online identity in social network services or online dating services.\n\n== Aspects ==\nOne aspect of the online identity management process has to do with improving the quantity and quality of traffic to sites that have content related to a person. In that aspect, OIM is a part of another discipline called search engine optimization with the difference that the only keyword is the person's name, and the optimization object is not necessary a single web site; it can consider a set of completely different sites that contain positive online references. The objective in this case is to get high rankings for as many sites as possible when someone search for a person's name. If the search engine used is Google, this action is called \"to google someone\".Another aspect has to do with impression management, i.e. \"the process through which people try to control the impressions other people form of them\". One of the objectives, in particular, is to increase the online reputation of the person.\nPseudonyms are sometimes used to protect the true online identity of individuals from harm. This can be the case when presenting unpopular views or dissenting opinion online in a way that will not affect the true identity of the author. Facebook estimates that up to 11.2% of accounts are fake. Many of these profiles are used as logins to protect the true identity of online authors.An individual's presence could be reflected in any kind of content that refers to that person, including news, participation in blogs and forums, personal web sites, social media presence, pictures, video, etc. Because of that, online identity management often involves participation in social media sites like Facebook, Google+, LinkedIn, Flickr, YouTube, Twitter, Last.fm, Myspace, Quora, Tumblr, Pinterest and other online communities and community websites, and is related to blogging, blog social networks like MyBlogLog and blog search engines like Technorati.\nOIM can serve specific purposes such as a professional networking platform. OSN platforms represent who the user is and what attributes they bring to the world. The information a user can plug into their profile is usually not verified, which can lead to specifics forms of false identity. OIM can also consist in more questionable practices such as the case of buying \"likes\", \"friends\", or \"subscribers\".\n\n== Objective ==\nThe Objective of Online Identity Management is to:\n\nMaximize the appearances of positive online references about a specific person, targeting not only to users that actively search for that person on any search engine, but also to those that eventually can reach a person's reference while browsing the web.\nBuild an online identity in case the person's web presence is minimal or nonexistent.\nSolve online reputation problems. In this case, the process can also be named online reputation management.\nTo express opinions that may be unheard, if the person's reputation wasn't previously favored.Online Identity management can be utilized on a personal and professional level. Online identity management utilizes web presence to gain attention from potential huge clients to followers. A person managing online identity will use social media sites like Twitter, Facebook, Instagram Youtube, Snapchat, and networking sites to increase their online activity. They also use other tools like search engine optimization and advertisements to boost their audience and gain insights on their audience. Online Identity Management is most effective with the use of all social networking sites and posting frequently. This technique is used to target their audience and to make sure their audience does not miss any content. Additionally, Online Identity Management can be used to manipulate followers, viewers, and clients by using misleading or over-exaggerated information.\n\n== Motivation ==\nThe reason why someone would be interested in doing online identity management is closely related to the increasing number of constituencies that use the internet as a tool to find information about people. A survey by CareerBuilder.com found that one in four hiring managers used search engines to screen candidates. One in 10 also checked candidates' profiles on social networking sites such as Facebook, Instagram, Twitter, Youtube and other communicative networks. According to a December 2007 survey by the Ponemon Institute, a privacy research organization, roughly half of U.S. hiring officials use the Internet in vetting job applications. Online identity management may also be used to increase an individual's professional online presence. When practicing online identity management, employers receive a satisfied notion regarding their candidate's professional attitudes and personality. This may result in a candidate receiving the job based on their professional online presence. Online Identity management is key to having a successful business and relationship with the public. An online presence is vital to the digital world we live in today. Many employers check the social network account of their candidate to grasp the kind of person they are. Even after being hired companies will continuously check account to ensure professionalism and company privacy is being maintained.The concept of manipulating search results to show positive results is intriguing for both individuals and businesses. Individuals that want to hide from their past can use OIM to repair their online image and suppress content that damages their credibility, employability and reputation. By changing what people see when searching for an individual, they are able to create a completely new and positive identity in its place. In 2014, the EU ruled that people have \"The right to be forgotten\", and that in some circumstances content can be removed from Google's search index.\nIn 1988, the European Union passed the Safe Harbor Act which prohibited the sharing unauthorized personal information. Many companies to this day voluntarily comply to this law; however, it is the job of the user to fully ensure the safety of their online identity. The European Union later passed the a landmark ruling back in 2014, that stated that all individuals have the \"right to be forgotten\". This granted user's the removal of all irrelevant data that could harm one's online identityOnline identity management is also a factor and important when a person is seeking a need or good. Depending on companies online viewers and content can encourage or discourage a sale. Online identity management is important because decisions can be made depending on online activity. Depending on the motives of the goods, company, and person their online identity should serve the purpose of heightening their likeness, attractiveness, and exposure."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are the challenges of using mobile data for authorities during investigations?",
    "context": "",
    "output": "The challenges of using mobile data for authorities during investigations include potential privacy infringements and potential surveillance. In the United States, several cases have reached the Supreme Court regarding these issues, such as authorities using GPS data to track down suspects' locations and monitor data over long periods of time.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are the challenges of using mobile data for authorities during investigations?",
      "answer": "The challenges of using mobile data for authorities during investigations include potential privacy infringements and potential surveillance. In the United States, several cases have reached the Supreme Court regarding these issues, such as authorities using GPS data to track down suspects' locations and monitor data over long periods of time."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is Dual_EC_DRBG and why was it favored by the National Security Agency (NSA)?",
    "context": "",
    "output": "Dual_EC_DRBG is a deterministic random bit generator published by the U.S. National Institute of Standards and Technology and favored by the NSA. It uses elliptic curve technology and includes a set of recommended constants. However, it was later discovered that the constants could be constructed to create a kleptographic backdoor in the algorithm.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is Dual_EC_DRBG and why was it favored by the National Security Agency (NSA)?",
      "answer": "Dual_EC_DRBG is a deterministic random bit generator published by the U.S. National Institute of Standards and Technology and favored by the NSA. It uses elliptic curve technology and includes a set of recommended constants. However, it was later discovered that the constants could be constructed to create a kleptographic backdoor in the algorithm."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the role of centralized data centers in the context of storage security?",
    "context": "",
    "output": "Centralized data centers continue to be dependent on due to needs for data integration, data consistency, and data quality. With the enormous growth of critical data volumes, many organizations have adopted storage-centric architectures for their ICT infrastructure, making storage security an important role in securing this data, and in many instances, it serves as the last line of defense from both internal and external adversaries.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of centralized data centers in the context of storage security?",
      "answer": "Centralized data centers continue to be dependent on due to needs for data integration, data consistency, and data quality. With the enormous growth of critical data volumes, many organizations have adopted storage-centric architectures for their ICT infrastructure, making storage security an important role in securing this data, and in many instances, it serves as the last line of defense from both internal and external adversaries."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does Microsoft Autofill ensure that only the user can access their stored passwords in the Microsoft Authenticator app?",
    "context": "",
    "output": "Microsoft Authenticator app requires multi-factor authentication to sign in, which provides an additional layer of security and ensures that only the user can access their stored passwords.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does Microsoft Autofill ensure that only the user can access their stored passwords in the Microsoft Authenticator app?",
      "answer": "Microsoft Authenticator app requires multi-factor authentication to sign in, which provides an additional layer of security and ensures that only the user can access their stored passwords."
    }
  },
  {
    "instruction": "YARA\n\n==Introduction==\nYARA is the name of a tool primarily used in malware research and detection.\nIt provides a rule-based approach to create descriptions of malware families based on regular expression, textual or binary patterns. A description is essentially a YARA rule name, where these rules consist of sets of strings and a boolean expression.\n\n== Design ==\nYARA by default comes with modules to process PE, ELF analysis, as well as support for the open-source Cuckoo sandbox.\n\nWhat is the primary use case for YARA and what approach does it use for malware detection?",
    "context": "",
    "output": "A: YARA is primarily used in malware research and detection, and it follows a rule-based approach for this purpose. It creates descriptions of malware families based on regular expressions, textual, or binary patterns. These descriptions are in the form of YARA rules, which consist of sets of strings and a boolean expression.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the primary use case for YARA and what approach does it use for malware detection?",
      "answer": "YARA is primarily used in malware research and detection, and it follows a rule-based approach for this purpose. It creates descriptions of malware families based on regular expressions, textual, or binary patterns. These descriptions are in the form of YARA rules, which consist of sets of strings and a boolean expression.",
      "context": "YARA\n\n==Introduction==\nYARA is the name of a tool primarily used in malware research and detection.\nIt provides a rule-based approach to create descriptions of malware families based on regular expression, textual or binary patterns. A description is essentially a YARA rule name, where these rules consist of sets of strings and a boolean expression.\n\n== Design ==\nYARA by default comes with modules to process PE, ELF analysis, as well as support for the open-source Cuckoo sandbox."
    }
  },
  {
    "instruction": "Private information retrieval\n\n==Introduction==\nIn cryptography, a private information retrieval (PIR) protocol is a protocol that allows a user to retrieve an item from a server in possession of a database without revealing which item is retrieved. PIR is a weaker version of 1-out-of-n oblivious transfer, where it is also required that the user should not get information about other database items.\nOne trivial, but very inefficient way to achieve PIR is for the server to send an entire copy of the database to the user. In fact, this is the only possible protocol (in the classical or the quantum setting) that gives the user information theoretic privacy for their query in a single-server setting. There are two ways to address this problem: make the server computationally bounded or assume that there are multiple non-cooperating servers, each having a copy of the database.\nThe problem was introduced in 1995 by Chor, Goldreich, Kushilevitz and Sudan in the information-theoretic setting and in 1997 by Kushilevitz and Ostrovsky in the computational setting. Since then, very efficient solutions have been discovered. Single database (computationally private) PIR can be achieved with constant (amortized) communication and k-database (information theoretic) PIR can be done with \n  \n    \n      \n        \n          n\n          \n            O\n            \n              (\n              \n                \n                  \n                    log\n                    \u2061\n                    log\n                    \u2061\n                    k\n                  \n                  \n                    k\n                    log\n                    \u2061\n                    k\n                  \n                \n              \n              )\n            \n          \n        \n      \n    \n    {\\displaystyle n^{O\\left({\\frac {\\log \\log k}{k\\log k}}\\right)}}\n   communication.\n\n\n\n== Advances in computational PIR ==\nThe first single-database computational PIR scheme to achieve communication complexity less than \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n   was created in 1997 by Kushilevitz and Ostrovsky  and achieved communication complexity of \n  \n    \n      \n        \n          n\n          \n            \u03f5\n          \n        \n      \n    \n    {\\displaystyle n^{\\epsilon }}\n   for any \n  \n    \n      \n        \u03f5\n      \n    \n    {\\displaystyle \\epsilon }\n  , where \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n   is the number of bits in the database. The security of their scheme was based on the well-studied Quadratic residuosity problem. In 1999, Christian Cachin, Silvio Micali and Markus Stadler achieved poly-logarithmic communication complexity. The security of their system is based on the Phi-hiding assumption. In 2004, Helger Lipmaa achieved log-squared communication complexity \n  \n    \n      \n        O\n        (\n        \u2113\n        log\n        \u2061\n        n\n        +\n        k\n        \n          log\n          \n            2\n          \n        \n        \u2061\n        n\n        )\n      \n    \n    {\\displaystyle O(\\ell \\log n+k\\log ^{2}n)}\n  , where \n  \n    \n      \n        \u2113\n      \n    \n    {\\displaystyle \\ell }\n   is the length of the strings and \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n   is the security parameter. The security of his system reduces to the semantic security of a length-flexible additively homomorphic cryptosystem like the Damg\u00e5rd\u2013Jurik cryptosystem. In 2005 Craig Gentry and Zulfikar Ramzan achieved log-squared communication complexity which retrieves log-square (consecutive) bits of the database. The security of their scheme is also based on a variant of the Phi-hiding assumption. The communication rate was finally brought down to \n  \n    \n      \n        1\n      \n    \n    {\\displaystyle 1}\n   by Aggelos Kiayias, Nikos Leonardos, Helger Lipmaa, Kateryna Pavlyk, Qiang Tang, in 2015.All previous sublinear-communication computational PIR protocol required linear computational complexity of \n  \n    \n      \n        \u03a9\n        (\n        n\n        )\n      \n    \n    {\\displaystyle \\Omega (n)}\n   public-key operations. In 2009, Helger Lipmaa designed a computational PIR protocol with communication complexity \n  \n    \n      \n        O\n        (\n        \u2113\n        log\n        \u2061\n        n\n        +\n        k\n        \n          log\n          \n            2\n          \n        \n        \u2061\n        n\n        )\n      \n    \n    {\\displaystyle O(\\ell \\log n+k\\log ^{2}n)}\n   and worst-case computation of \n  \n    \n      \n        O\n        (\n        n\n        \n          /\n        \n        log\n        \u2061\n        n\n        )\n      \n    \n    {\\displaystyle O(n/\\log n)}\n   public-key operations. Amortization techniques that retrieve non-consecutive bits have been considered by Yuval Ishai, Eyal Kushilevitz, Rafail Ostrovsky and Amit Sahai.As shown by Ostrovsky and Skeith, the schemes by Kushilevitz and Ostrovsky  and Lipmaa  use similar ideas based on homomorphic encryption. The Kushilevitz and Ostrovsky protocol is based on the Goldwasser\u2013Micali cryptosystem while the protocol by Lipmaa is based on the Damg\u00e5rd\u2013Jurik cryptosystem.\n\n== Advances in information theoretic PIR ==\nAchieving information theoretic security requires the assumption that there are multiple non-cooperating servers, each having a copy of the database. Without this assumption, any information-theoretically secure PIR protocol requires an amount of communication that is at least the size of the database n.  Multi-server PIR protocols tolerant of non-responsive or malicious/colluding servers are called robust or Byzantine robust respectively.  These issues were first considered by Beimel and Stahl (2002).  An \u2113-server system that can operate where only k of the servers respond, \u03bd of the servers respond incorrectly, and which can withstand up to t colluding servers without revealing the client's query is called \"t-private \u03bd-Byzantine robust k-out-of-\u2113 PIR\" [DGH 2012].  In 2012, C. Devet, I. Goldberg, and N. Heninger (DGH 2012) proposed an optimally robust scheme that is Byzantine-robust to \n  \n    \n      \n        \u03bd\n        <\n        k\n        \u2212\n        t\n        \u2212\n        1\n      \n    \n    {\\displaystyle \\nu <k-t-1}\n   which is the theoretical maximum value.  It is based on an earlier protocol of Goldberg that uses Shamir's Secret Sharing to hide the query.  Goldberg has released a C++ implementation on SourceForge.\n\n== Relation to other cryptographic primitives ==\nOne-way functions are necessary, but not known to be sufficient, for nontrivial (i.e., with sublinear communication) single database computationally private information retrieval. In fact, such a protocol was proved by Giovanni Di Crescenzo, Tal Malkin and Rafail Ostrovsky to imply oblivious transfer (see below).Oblivious transfer, also called symmetric PIR, is PIR with the additional restriction that the user may not learn any item other than the one she requested. It is termed symmetric because both the user and the database have a privacy requirement.\nCollision-resistant cryptographic hash functions are implied by any one-round computational PIR scheme, as shown by Ishai, Kushilevitz and Ostrovsky.\n\n== PIR variations ==\nThe basic motivation for Private Information Retrieval is a family of two-party protocols in which one of the parties (the sender) owns a database, and the other part (the receiver) wants to query it with certain privacy restrictions and warranties. So, as a result of the protocol, if the receiver wants the i-th value in the database he  must learn the i-th entry, but the sender must learn nothing about i. In a general PIR protocol, a computationally unbounded sender can learn nothing about i so privacy is theoretically preserved. Since the PIR problem was posed, different approaches to its solution have been pursued and some variations were proposed.\nA CPIR (Computationally Private Information Retrieval) protocol is similar to a PIR protocol: the receiver retrieves an element chosen by him from the sender's database, so that the sender obtains no knowledge about which element was transferred. The only difference is that privacy is safeguarded against a polynomially bounded sender.A CSPIR (Computationally Symmetric Private Information Retrieval) protocol is used in a similar scenario in which a CPIR protocol is used. If the sender owns a database, and the receiver wants to get the i-th value in this database, at the end of the execution of a SPIR protocol, the receiver should have learned nothing about values in the database other than the i-th one.\n\n== PIR implementations ==\nNumerous Computational PIR and Information theoretic PIR schemes in the literature have been implemented. Here is an incomplete list:\n\nMuchPIR is a CPIR implementation as a Postgres C/C++ Extension [GitHub, 2021].\nSealPIR is a fast CPIR implementation [ACLS 2018].\nPopcorn is a PIR implementation tailored for media [GCMSAW 2016].\nPercy++ includes implementations of [AG 2007, DGH 2012, CGKS 1998, Goldberg 2007, HOG 2011, LG 2015].\nRAID-PIR is an implementation of the ITPIR scheme of [DHS 2014].\nXPIR is a fast CPIR implementation [ABFK 2014].\nupPIR is an ITPIR implementation [Cappos 2013].\n\n\n*** Notes ***\n\nWhat limitation does the trivial, yet inefficient way of achieving PIR have in terms of privacy and communication complexity?",
    "context": "",
    "output": "A: The trivial way of achieving PIR is for the server to send an entire copy of the database to the user, which gives the user information-theoretic privacy for their query in a single-server setting. However, this approach has high communication complexity, which is proportional to the size of the entire database.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What limitation does the trivial, yet inefficient way of achieving PIR have in terms of privacy and communication complexity?",
      "answer": "The trivial way of achieving PIR is for the server to send an entire copy of the database to the user, which gives the user information-theoretic privacy for their query in a single-server setting. However, this approach has high communication complexity, which is proportional to the size of the entire database.",
      "context": "Private information retrieval\n\n==Introduction==\nIn cryptography, a private information retrieval (PIR) protocol is a protocol that allows a user to retrieve an item from a server in possession of a database without revealing which item is retrieved. PIR is a weaker version of 1-out-of-n oblivious transfer, where it is also required that the user should not get information about other database items.\nOne trivial, but very inefficient way to achieve PIR is for the server to send an entire copy of the database to the user. In fact, this is the only possible protocol (in the classical or the quantum setting) that gives the user information theoretic privacy for their query in a single-server setting. There are two ways to address this problem: make the server computationally bounded or assume that there are multiple non-cooperating servers, each having a copy of the database.\nThe problem was introduced in 1995 by Chor, Goldreich, Kushilevitz and Sudan in the information-theoretic setting and in 1997 by Kushilevitz and Ostrovsky in the computational setting. Since then, very efficient solutions have been discovered. Single database (computationally private) PIR can be achieved with constant (amortized) communication and k-database (information theoretic) PIR can be done with \n  \n    \n      \n        \n          n\n          \n            O\n            \n              (\n              \n                \n                  \n                    log\n                    \u2061\n                    log\n                    \u2061\n                    k\n                  \n                  \n                    k\n                    log\n                    \u2061\n                    k\n                  \n                \n              \n              )\n            \n          \n        \n      \n    \n    {\\displaystyle n^{O\\left({\\frac {\\log \\log k}{k\\log k}}\\right)}}\n   communication.\n\n\n\n== Advances in computational PIR ==\nThe first single-database computational PIR scheme to achieve communication complexity less than \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n   was created in 1997 by Kushilevitz and Ostrovsky  and achieved communication complexity of \n  \n    \n      \n        \n          n\n          \n            \u03f5\n          \n        \n      \n    \n    {\\displaystyle n^{\\epsilon }}\n   for any \n  \n    \n      \n        \u03f5\n      \n    \n    {\\displaystyle \\epsilon }\n  , where \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n   is the number of bits in the database. The security of their scheme was based on the well-studied Quadratic residuosity problem. In 1999, Christian Cachin, Silvio Micali and Markus Stadler achieved poly-logarithmic communication complexity. The security of their system is based on the Phi-hiding assumption. In 2004, Helger Lipmaa achieved log-squared communication complexity \n  \n    \n      \n        O\n        (\n        \u2113\n        log\n        \u2061\n        n\n        +\n        k\n        \n          log\n          \n            2\n          \n        \n        \u2061\n        n\n        )\n      \n    \n    {\\displaystyle O(\\ell \\log n+k\\log ^{2}n)}\n  , where \n  \n    \n      \n        \u2113\n      \n    \n    {\\displaystyle \\ell }\n   is the length of the strings and \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n   is the security parameter. The security of his system reduces to the semantic security of a length-flexible additively homomorphic cryptosystem like the Damg\u00e5rd\u2013Jurik cryptosystem. In 2005 Craig Gentry and Zulfikar Ramzan achieved log-squared communication complexity which retrieves log-square (consecutive) bits of the database. The security of their scheme is also based on a variant of the Phi-hiding assumption. The communication rate was finally brought down to \n  \n    \n      \n        1\n      \n    \n    {\\displaystyle 1}\n   by Aggelos Kiayias, Nikos Leonardos, Helger Lipmaa, Kateryna Pavlyk, Qiang Tang, in 2015.All previous sublinear-communication computational PIR protocol required linear computational complexity of \n  \n    \n      \n        \u03a9\n        (\n        n\n        )\n      \n    \n    {\\displaystyle \\Omega (n)}\n   public-key operations. In 2009, Helger Lipmaa designed a computational PIR protocol with communication complexity \n  \n    \n      \n        O\n        (\n        \u2113\n        log\n        \u2061\n        n\n        +\n        k\n        \n          log\n          \n            2\n          \n        \n        \u2061\n        n\n        )\n      \n    \n    {\\displaystyle O(\\ell \\log n+k\\log ^{2}n)}\n   and worst-case computation of \n  \n    \n      \n        O\n        (\n        n\n        \n          /\n        \n        log\n        \u2061\n        n\n        )\n      \n    \n    {\\displaystyle O(n/\\log n)}\n   public-key operations. Amortization techniques that retrieve non-consecutive bits have been considered by Yuval Ishai, Eyal Kushilevitz, Rafail Ostrovsky and Amit Sahai.As shown by Ostrovsky and Skeith, the schemes by Kushilevitz and Ostrovsky  and Lipmaa  use similar ideas based on homomorphic encryption. The Kushilevitz and Ostrovsky protocol is based on the Goldwasser\u2013Micali cryptosystem while the protocol by Lipmaa is based on the Damg\u00e5rd\u2013Jurik cryptosystem.\n\n== Advances in information theoretic PIR ==\nAchieving information theoretic security requires the assumption that there are multiple non-cooperating servers, each having a copy of the database. Without this assumption, any information-theoretically secure PIR protocol requires an amount of communication that is at least the size of the database n.  Multi-server PIR protocols tolerant of non-responsive or malicious/colluding servers are called robust or Byzantine robust respectively.  These issues were first considered by Beimel and Stahl (2002).  An \u2113-server system that can operate where only k of the servers respond, \u03bd of the servers respond incorrectly, and which can withstand up to t colluding servers without revealing the client's query is called \"t-private \u03bd-Byzantine robust k-out-of-\u2113 PIR\" [DGH 2012].  In 2012, C. Devet, I. Goldberg, and N. Heninger (DGH 2012) proposed an optimally robust scheme that is Byzantine-robust to \n  \n    \n      \n        \u03bd\n        <\n        k\n        \u2212\n        t\n        \u2212\n        1\n      \n    \n    {\\displaystyle \\nu <k-t-1}\n   which is the theoretical maximum value.  It is based on an earlier protocol of Goldberg that uses Shamir's Secret Sharing to hide the query.  Goldberg has released a C++ implementation on SourceForge.\n\n== Relation to other cryptographic primitives ==\nOne-way functions are necessary, but not known to be sufficient, for nontrivial (i.e., with sublinear communication) single database computationally private information retrieval. In fact, such a protocol was proved by Giovanni Di Crescenzo, Tal Malkin and Rafail Ostrovsky to imply oblivious transfer (see below).Oblivious transfer, also called symmetric PIR, is PIR with the additional restriction that the user may not learn any item other than the one she requested. It is termed symmetric because both the user and the database have a privacy requirement.\nCollision-resistant cryptographic hash functions are implied by any one-round computational PIR scheme, as shown by Ishai, Kushilevitz and Ostrovsky.\n\n== PIR variations ==\nThe basic motivation for Private Information Retrieval is a family of two-party protocols in which one of the parties (the sender) owns a database, and the other part (the receiver) wants to query it with certain privacy restrictions and warranties. So, as a result of the protocol, if the receiver wants the i-th value in the database he  must learn the i-th entry, but the sender must learn nothing about i. In a general PIR protocol, a computationally unbounded sender can learn nothing about i so privacy is theoretically preserved. Since the PIR problem was posed, different approaches to its solution have been pursued and some variations were proposed.\nA CPIR (Computationally Private Information Retrieval) protocol is similar to a PIR protocol: the receiver retrieves an element chosen by him from the sender's database, so that the sender obtains no knowledge about which element was transferred. The only difference is that privacy is safeguarded against a polynomially bounded sender.A CSPIR (Computationally Symmetric Private Information Retrieval) protocol is used in a similar scenario in which a CPIR protocol is used. If the sender owns a database, and the receiver wants to get the i-th value in this database, at the end of the execution of a SPIR protocol, the receiver should have learned nothing about values in the database other than the i-th one.\n\n== PIR implementations ==\nNumerous Computational PIR and Information theoretic PIR schemes in the literature have been implemented. Here is an incomplete list:\n\nMuchPIR is a CPIR implementation as a Postgres C/C++ Extension [GitHub, 2021].\nSealPIR is a fast CPIR implementation [ACLS 2018].\nPopcorn is a PIR implementation tailored for media [GCMSAW 2016].\nPercy++ includes implementations of [AG 2007, DGH 2012, CGKS 1998, Goldberg 2007, HOG 2011, LG 2015].\nRAID-PIR is an implementation of the ITPIR scheme of [DHS 2014].\nXPIR is a fast CPIR implementation [ABFK 2014].\nupPIR is an ITPIR implementation [Cappos 2013].\n\n\n*** Notes ***"
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the Evaluation Assurance Level (EAL) reflect added assurance requirements for IT product or system certification?",
    "context": "",
    "output": "The Evaluation Assurance Level (EAL) is a numerical grade assigned following the completion of a Common Criteria security evaluation. It reflects added assurance requirements that must be met to achieve Common Criteria certification, with higher levels providing higher confidence that the system's principal security features are reliably implemented.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the Evaluation Assurance Level (EAL) reflect added assurance requirements for IT product or system certification?",
      "answer": "The Evaluation Assurance Level (EAL) is a numerical grade assigned following the completion of a Common Criteria security evaluation. It reflects added assurance requirements that must be met to achieve Common Criteria certification, with higher levels providing higher confidence that the system's principal security features are reliably implemented."
    }
  },
  {
    "instruction": "Write an answer to the following question: How can improper use case handling lead to security bugs?",
    "context": "",
    "output": "Improper use case handling can lead to security bugs if the software does not properly handle all possible scenarios and inputs. This can result in the software behaving in unexpected and insecure ways when it encounters certain inputs or situations.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can improper use case handling lead to security bugs?",
      "answer": "Improper use case handling can lead to security bugs if the software does not properly handle all possible scenarios and inputs. This can result in the software behaving in unexpected and insecure ways when it encounters certain inputs or situations."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the role of Access Now in Torservers.net?",
    "context": "",
    "output": "Access Now is a member of Torservers.net, which is a network of non-profit organizations that provide nodes to the Tor anonymity network.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of Access Now in Torservers.net?",
      "answer": "Access Now is a member of Torservers.net, which is a network of non-profit organizations that provide nodes to the Tor anonymity network."
    }
  },
  {
    "instruction": "Noname057(16)\n\n==Introduction==\nNoName057(16) is a pro-Russian hacker group that first declared itself in March 2022 and claimed responsibility for cyber-attacks on Ukrainian, American, and European websites of government agencies, media, and private companies. It is regarded as an unorganized and free pro-Russian activist group seeking to attract attention in Western countries.\n\n\n\n== Activity ==\nInformation about the attacks carried out by NoName057(16) is published in the Telegram messenger channel of the same name. According to Ukrainian media, their employees received threatening letters from the NoName057(16) group. This was also stated by the Ukrainian ex-Ombudsman Lyudmila Denisova. OSINT researcher Cyberknow20 has included NoName057(16) in his summary table of hacker groups, which he periodically updates.\n\n== Known DDOS attacks ==\n\n\n*** Ukrainian sites ***\nStarting from March 2022, the NoName057(16) group has carried out a number of cyberattacks on Ukrainian media websites and Ukrainian media portals. For example, such as: the portal \"Detector Media\", the site \"Odessa Online\", the information agency \"Competitor\".\n\n\n*** Baltic sites ***\n\n\n**** Latvia ****\nThe DDOS attack claimed by the NoName057(16) group disrupted the online train ticket sales system on the website and in the mobile application of the Latvian company Passenger Train (Pasa\u017eieru vilciens). The company representatives stated in their Twitter account they had to stop selling tickets on the site and in the application because of the incident.\n\n\n**** Lithuania ****\nOn June 21, representatives of the hacker group NoName 057(16) announced on their Telegram channel that they were joining the attacks on the websites of the Republic of Lithuania. In their appeal, they called on other communities of pro-Russian hackers, as well as individual hacktivists, to do the same. The hackers called their actions \"revenge for Kaliningrad\". \nAs a result, in about a month, the group carried out more than 200 attacks on Lithuanian Internet infrastructure resources. \nThe Lithuanian Ministry of Defense stated that the participants in the attacks were pro-Russian \"volunteer activists\". \nIn particular, the group attacked the website of the Lithuanian company Ingstad, the websites of Lithuanian airports and other Internet resources. \nIn addition to DDOS attacks on Lithuanian sites, hackers from NoName057(16) managed to perform a so-called deface on one of them. As a result, a message from hackers appeared on the main page of the resource of the logistics company ExpressTrip.\n\n\n*** Estonia ***\nOn June 7, 2022, NoName057(16) carried out a cyberattack on the website of the Central Bank of Estonia[source?]. Bank representatives confirmed the fact of the attack and emphasized that as a result of the incident, \u201cthe external website and the statistics module of the Bank of Estonia were not working due to technical reasons\u201d.[27]\n\n\n*** United States ***\nAlso, hackers from NoName057(16) carried out attacks on the websites of American companies from various fields of activity. \nAs a result of one of these attacks the website of the ITT company ceased to be available to users for a long time.\n\n\n*** Denmark ***\nThe group claimed responsibility for DDOS attacks on the sites of a number of businesses in the financial sector, along with the Ministry of Finance in January 2023, due to the Danish support to Ukraine.\n\n\n*** Norway ***\nAs a kind of protest against the decision of the Norwegian authorities to ban the delivery of goods to Russian citizens in the Svalbard archipelago, the NoName057(16) group organized attacks on a number of sites in Norway. The attacks were noticed by the local media.\n\n\n*** Poland ***\nThe group also carried out DDOS attacks against Poland's Internet infrastructure in different periods of time.\n\n\n*** Finland ***\nA cyber attack on the website of the Finnish Parliament occurred after Finland joined NATO on April 4, 2023. Finnish journalists ranked the group as pro-Russian.As a result of the incident, the Finnish criminal police launched a preliminary investigation.\n\n\n*** Czech Republic ***\nDuring the 2023 presidential elections on January 13, 2023, the website of presidential candidate General Petr Pavel has been under a strong hacker attack since Friday morning. That's why it was not loading for some users, his election team said. It is said that the website faced a similarly strong attack throughout Wednesday. According to the operator, the attack was conducted from various IP addresses across Europe.\nOn March 24, 2023, there was a DDoS attack on the site of Prague Integrated Transport website about public transportation in Prague. The website for unavailable for several hours. The Noname057(16) claimed responsibility for the attack. Also, the website of Florenc Central Bus Station was also affected by this attack.\n\n\n*** Italy ***\nFollowing the visit of Prime Minister Giorgia Meloni to Kiev, in support of Ukraine's efforts in the ongoing conflict with Russia, a series of Italian companies' and institutions' were attacked in February and March 2023.\n\n\n*** Iceland ***\nDuring the Summit of the Heads of State and Government of the Council of Europe in Reykjavik, Iceland, May 16 2023, the NoName057(16) group claimed responsibility for several attacks on Icelandic governmental websites.\nRead the text above and answer this question: What was the response of the Norwegian authorities to NoName057(16)'s attacks on a number of sites in Norway?",
    "context": "",
    "output": "The Norwegian authorities did not specifically respond to the attacks in the text, but it is mentioned that the attacks were organized as a protest against the decision to ban the delivery of goods to Russian citizens in the Svalbard archipelago.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was the response of the Norwegian authorities to NoName057(16)'s attacks on a number of sites in Norway?",
      "answer": "The Norwegian authorities did not specifically respond to the attacks in the text, but it is mentioned that the attacks were organized as a protest against the decision to ban the delivery of goods to Russian citizens in the Svalbard archipelago.",
      "context": "Noname057(16)\n\n==Introduction==\nNoName057(16) is a pro-Russian hacker group that first declared itself in March 2022 and claimed responsibility for cyber-attacks on Ukrainian, American, and European websites of government agencies, media, and private companies. It is regarded as an unorganized and free pro-Russian activist group seeking to attract attention in Western countries.\n\n\n\n== Activity ==\nInformation about the attacks carried out by NoName057(16) is published in the Telegram messenger channel of the same name. According to Ukrainian media, their employees received threatening letters from the NoName057(16) group. This was also stated by the Ukrainian ex-Ombudsman Lyudmila Denisova. OSINT researcher Cyberknow20 has included NoName057(16) in his summary table of hacker groups, which he periodically updates.\n\n== Known DDOS attacks ==\n\n\n*** Ukrainian sites ***\nStarting from March 2022, the NoName057(16) group has carried out a number of cyberattacks on Ukrainian media websites and Ukrainian media portals. For example, such as: the portal \"Detector Media\", the site \"Odessa Online\", the information agency \"Competitor\".\n\n\n*** Baltic sites ***\n\n\n**** Latvia ****\nThe DDOS attack claimed by the NoName057(16) group disrupted the online train ticket sales system on the website and in the mobile application of the Latvian company Passenger Train (Pasa\u017eieru vilciens). The company representatives stated in their Twitter account they had to stop selling tickets on the site and in the application because of the incident.\n\n\n**** Lithuania ****\nOn June 21, representatives of the hacker group NoName 057(16) announced on their Telegram channel that they were joining the attacks on the websites of the Republic of Lithuania. In their appeal, they called on other communities of pro-Russian hackers, as well as individual hacktivists, to do the same. The hackers called their actions \"revenge for Kaliningrad\". \nAs a result, in about a month, the group carried out more than 200 attacks on Lithuanian Internet infrastructure resources. \nThe Lithuanian Ministry of Defense stated that the participants in the attacks were pro-Russian \"volunteer activists\". \nIn particular, the group attacked the website of the Lithuanian company Ingstad, the websites of Lithuanian airports and other Internet resources. \nIn addition to DDOS attacks on Lithuanian sites, hackers from NoName057(16) managed to perform a so-called deface on one of them. As a result, a message from hackers appeared on the main page of the resource of the logistics company ExpressTrip.\n\n\n*** Estonia ***\nOn June 7, 2022, NoName057(16) carried out a cyberattack on the website of the Central Bank of Estonia[source?]. Bank representatives confirmed the fact of the attack and emphasized that as a result of the incident, \u201cthe external website and the statistics module of the Bank of Estonia were not working due to technical reasons\u201d.[27]\n\n\n*** United States ***\nAlso, hackers from NoName057(16) carried out attacks on the websites of American companies from various fields of activity. \nAs a result of one of these attacks the website of the ITT company ceased to be available to users for a long time.\n\n\n*** Denmark ***\nThe group claimed responsibility for DDOS attacks on the sites of a number of businesses in the financial sector, along with the Ministry of Finance in January 2023, due to the Danish support to Ukraine.\n\n\n*** Norway ***\nAs a kind of protest against the decision of the Norwegian authorities to ban the delivery of goods to Russian citizens in the Svalbard archipelago, the NoName057(16) group organized attacks on a number of sites in Norway. The attacks were noticed by the local media.\n\n\n*** Poland ***\nThe group also carried out DDOS attacks against Poland's Internet infrastructure in different periods of time.\n\n\n*** Finland ***\nA cyber attack on the website of the Finnish Parliament occurred after Finland joined NATO on April 4, 2023. Finnish journalists ranked the group as pro-Russian.As a result of the incident, the Finnish criminal police launched a preliminary investigation.\n\n\n*** Czech Republic ***\nDuring the 2023 presidential elections on January 13, 2023, the website of presidential candidate General Petr Pavel has been under a strong hacker attack since Friday morning. That's why it was not loading for some users, his election team said. It is said that the website faced a similarly strong attack throughout Wednesday. According to the operator, the attack was conducted from various IP addresses across Europe.\nOn March 24, 2023, there was a DDoS attack on the site of Prague Integrated Transport website about public transportation in Prague. The website for unavailable for several hours. The Noname057(16) claimed responsibility for the attack. Also, the website of Florenc Central Bus Station was also affected by this attack.\n\n\n*** Italy ***\nFollowing the visit of Prime Minister Giorgia Meloni to Kiev, in support of Ukraine's efforts in the ongoing conflict with Russia, a series of Italian companies' and institutions' were attacked in February and March 2023.\n\n\n*** Iceland ***\nDuring the Summit of the Heads of State and Government of the Council of Europe in Reykjavik, Iceland, May 16 2023, the NoName057(16) group claimed responsibility for several attacks on Icelandic governmental websites."
    }
  },
  {
    "instruction": "Data diddling\n\n==Introduction==\nData diddling is a type of cybercrime in which data is altered as it is entered into a computer system, most often by a data entry clerk or a computer virus. Computerized processing of the altered data results in a fraudulent benefit. In some cases, the altered data is changed back after processing to conceal the activity. The results can be huge. They might include adjusting financial figures up or down marginally, or it could be more complex and make an entire system unusable.\n\n\n\nQ: What measures can be taken to prevent data diddling, and how can it be detected after it has occurred?",
    "context": "",
    "output": "A: Preventing data diddling requires a multi-layered approach, including: (1) implementing strict access controls to prevent unauthorized access to data entry systems, (2) conducting regular data audits to detect any discrepancies or anomalies, (3) using data encryption and digital signatures to ensure the integrity and authenticity of data, and (4) providing regular training and awareness programs to employees to help them understand the risks associated with data diddling. To detect data diddling after it has occurred, it is important to conduct regular data audits, use data analytics tools to detect anomalies, and implement a robust incident response plan to minimize the impact of the attack.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What measures can be taken to prevent data diddling, and how can it be detected after it has occurred?",
      "answer": "Preventing data diddling requires a multi-layered approach, including: (1) implementing strict access controls to prevent unauthorized access to data entry systems, (2) conducting regular data audits to detect any discrepancies or anomalies, (3) using data encryption and digital signatures to ensure the integrity and authenticity of data, and (4) providing regular training and awareness programs to employees to help them understand the risks associated with data diddling. To detect data diddling after it has occurred, it is important to conduct regular data audits, use data analytics tools to detect anomalies, and implement a robust incident response plan to minimize the impact of the attack.",
      "context": "Data diddling\n\n==Introduction==\nData diddling is a type of cybercrime in which data is altered as it is entered into a computer system, most often by a data entry clerk or a computer virus. Computerized processing of the altered data results in a fraudulent benefit. In some cases, the altered data is changed back after processing to conceal the activity. The results can be huge. They might include adjusting financial figures up or down marginally, or it could be more complex and make an entire system unusable.\n\n"
    }
  },
  {
    "instruction": "Write an answer to the following question: How do endpoint security systems maintain corporate network security?",
    "context": "",
    "output": "Endpoint security systems maintain corporate network security by identifying and managing users' computer and data access, restricting sensitive data and website access, and provisioning limited access to non-compliant devices.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do endpoint security systems maintain corporate network security?",
      "answer": "Endpoint security systems maintain corporate network security by identifying and managing users' computer and data access, restricting sensitive data and website access, and provisioning limited access to non-compliant devices."
    }
  },
  {
    "instruction": "Write an answer to the following question: How did Qihoo 360 respond to the reprimand from the Chinese Ministry of Industry and Information?",
    "context": "",
    "output": "Qihoo 360 and Tencent were ordered to come to an accord by the Chinese Ministry of Industry and Information following their dispute in 2010. It is not clear how Qihoo 360 responded to the reprimand specifically.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How did Qihoo 360 respond to the reprimand from the Chinese Ministry of Industry and Information?",
      "answer": "Qihoo 360 and Tencent were ordered to come to an accord by the Chinese Ministry of Industry and Information following their dispute in 2010. It is not clear how Qihoo 360 responded to the reprimand specifically."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the use of data exhaust affect revenue for companies?",
    "context": "",
    "output": "The use of data exhaust can help companies improve quality control, performance, and revenue by providing insights into user behavior and preferences.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the use of data exhaust affect revenue for companies?",
      "answer": "The use of data exhaust can help companies improve quality control, performance, and revenue by providing insights into user behavior and preferences."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is a trapdoor one-way function or trapdoor permutation?",
    "context": "",
    "output": "A trapdoor one-way function or trapdoor permutation is a special kind of one-way function that is hard to invert unless some secret information, called the trapdoor, is known.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is a trapdoor one-way function or trapdoor permutation?",
      "answer": "A trapdoor one-way function or trapdoor permutation is a special kind of one-way function that is hard to invert unless some secret information, called the trapdoor, is known."
    }
  },
  {
    "instruction": "Kelihos botnet\n\n==Introduction==\nThe Kelihos botnet, also known as Hlux, is a botnet mainly involved in spamming and the theft of bitcoins.\n\n== Structure, operations and spread ==\nThe Kelihos botnet is a so-called peer-to-peer botnet, where individual botnet nodes are capable of acting as command-and-control servers for the entire botnet. In traditional non-peer-to-peer botnets, all the nodes receive their instructions and \"work\" from a limited set of servers \u2013 if these servers are removed or taken down, the botnet will no longer receive instructions and will therefore effectively shut down. Peer-to-peer botnets seek to mitigate that risk by allowing every peer to send instructions to the entire botnet, thus making it more difficult to shut down.The first version of the botnet was mainly involved in denial-of-service attacks and email spam, while version two of the botnet added the ability to steal Bitcoin wallets, as well as a program used to mine bitcoins itself. Its spam capacity allows the botnet to spread itself by sending malware links to users in order to infect them with a Trojan horse, though later versions mostly propagate over social network sites, in particular through Facebook. A more comprehensive list of the Kelihos spam can be found in the following research paper.\n\n== Arrest and extradition ==\nOn 2 February 2018, the United States Department of Justice announced that a Russian national has been extradited from Spain and will be arraigned in Connecticut on charges stemming from his alleged operation of the Kelihos botnet. Peter Yuryevich Levashov, 37, also known as Pyotr Levashov, Petr Levashov, Peter Severa, Petr Severa and Sergey Astakhov, of St. Petersburg, was detained on 7 April 2017 in Barcelona, when he was arrested by Spanish authorities based upon a criminal complaint and arrest warrant issued in the United States District of Connecticut. On 3 February 2018, he pleaded not guilty to the charges of wire and email fraud, hacking, identity theft and conspiracy after appearing before a federal judge in the U.S. state of Connecticut. He remains in detention. In September 2018, Levashov pleaded guilty.\nQ: How does the Kelihos botnet differ from traditional botnets in terms of its structure and operations?",
    "context": "",
    "output": "Unlike traditional botnets that have a centralized command-and-control server, the Kelihos botnet operates on a peer-to-peer basis. This means that each node in the botnet is capable of sending instructions to the entire network, making it more resilient to takedowns. Additionally, while earlier versions of the botnet focused on denial-of-service attacks and email spam, later versions also included capabilities for stealing Bitcoin wallets and mining bitcoins.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the Kelihos botnet differ from traditional botnets in terms of its structure and operations?",
      "answer": "Unlike traditional botnets that have a centralized command-and-control server, the Kelihos botnet operates on a peer-to-peer basis. This means that each node in the botnet is capable of sending instructions to the entire network, making it more resilient to takedowns. Additionally, while earlier versions of the botnet focused on denial-of-service attacks and email spam, later versions also included capabilities for stealing Bitcoin wallets and mining bitcoins.",
      "context": "Kelihos botnet\n\n==Introduction==\nThe Kelihos botnet, also known as Hlux, is a botnet mainly involved in spamming and the theft of bitcoins.\n\n== Structure, operations and spread ==\nThe Kelihos botnet is a so-called peer-to-peer botnet, where individual botnet nodes are capable of acting as command-and-control servers for the entire botnet. In traditional non-peer-to-peer botnets, all the nodes receive their instructions and \"work\" from a limited set of servers \u2013 if these servers are removed or taken down, the botnet will no longer receive instructions and will therefore effectively shut down. Peer-to-peer botnets seek to mitigate that risk by allowing every peer to send instructions to the entire botnet, thus making it more difficult to shut down.The first version of the botnet was mainly involved in denial-of-service attacks and email spam, while version two of the botnet added the ability to steal Bitcoin wallets, as well as a program used to mine bitcoins itself. Its spam capacity allows the botnet to spread itself by sending malware links to users in order to infect them with a Trojan horse, though later versions mostly propagate over social network sites, in particular through Facebook. A more comprehensive list of the Kelihos spam can be found in the following research paper.\n\n== Arrest and extradition ==\nOn 2 February 2018, the United States Department of Justice announced that a Russian national has been extradited from Spain and will be arraigned in Connecticut on charges stemming from his alleged operation of the Kelihos botnet. Peter Yuryevich Levashov, 37, also known as Pyotr Levashov, Petr Levashov, Peter Severa, Petr Severa and Sergey Astakhov, of St. Petersburg, was detained on 7 April 2017 in Barcelona, when he was arrested by Spanish authorities based upon a criminal complaint and arrest warrant issued in the United States District of Connecticut. On 3 February 2018, he pleaded not guilty to the charges of wire and email fraud, hacking, identity theft and conspiracy after appearing before a federal judge in the U.S. state of Connecticut. He remains in detention. In September 2018, Levashov pleaded guilty."
    }
  },
  {
    "instruction": "Write an answer to the following question: What organization manages the Homeland Open Security Technology (HOST) project?",
    "context": "",
    "output": "The Homeland Open Security Technology (HOST) project is contracted to the Open Technology Research Consortium.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What organization manages the Homeland Open Security Technology (HOST) project?",
      "answer": "The Homeland Open Security Technology (HOST) project is contracted to the Open Technology Research Consortium."
    }
  },
  {
    "instruction": "Kenzero\n\n==Introduction==\nKenzero is a computer trojan that is spread across peer-to-peer networks and is programmed to monitor the browsing history of victims. \n\n\n\n== Operations ==\nKenzero attacks computers that download files through peer-to-peer networks (P2P). Once the file is opened, the virus locates the victim's browsing history and publishes it online. People can then view the file(s).\n\nHow does Kenzero make the victim's browsing history public?",
    "context": "",
    "output": "A: Kenzero makes the victim's browsing history public by publishing it online, where it can be viewed by anyone with access to the internet.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does Kenzero make the victim's browsing history public?",
      "answer": "Kenzero makes the victim's browsing history public by publishing it online, where it can be viewed by anyone with access to the internet.",
      "context": "Kenzero\n\n==Introduction==\nKenzero is a computer trojan that is spread across peer-to-peer networks and is programmed to monitor the browsing history of victims. \n\n\n\n== Operations ==\nKenzero attacks computers that download files through peer-to-peer networks (P2P). Once the file is opened, the virus locates the victim's browsing history and publishes it online. People can then view the file(s)."
    }
  },
  {
    "instruction": "Write an answer to the following question: Who were some of the notable members of the President's Commission on Enhancing National Cybersecurity?",
    "context": "",
    "output": "Some of the notable members of the President's Commission on Enhancing National Cybersecurity included Tom Donilon, former Assistant to the President and National Security Advisor, Sam Palmisano, former CEO of IBM, General Keith Alexander, CEO of IronNet Cybersecurity, and Heather Murren, former member of the Financial Crisis Inquiry Commission and co-founder of the Nevada Cancer Institute.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Who were some of the notable members of the President's Commission on Enhancing National Cybersecurity?",
      "answer": "Some of the notable members of the President's Commission on Enhancing National Cybersecurity included Tom Donilon, former Assistant to the President and National Security Advisor, Sam Palmisano, former CEO of IBM, General Keith Alexander, CEO of IronNet Cybersecurity, and Heather Murren, former member of the Financial Crisis Inquiry Commission and co-founder of the Nevada Cancer Institute."
    }
  },
  {
    "instruction": "Zombie Zero\n\n==Introduction==\nZombie Zero is an attack vector where a cyber attacker utilized malware that was clandestinely embedded in new barcode readers which were manufactured overseas.  \nIt remains unknown if this attack was promulgated by organized crime or a nation state. Clearly there was significant planning and investment in order to design the malware, and then embed it into the hardware within the barcode scanner. Internet of things (IoT) devices may be similarly preinstalled with malware that can capture the network passwords and then open a backdoor to attackers. Given the high volume of these devices manufactured overseas high caution is to be exercised before placing these devices on corporate or government networks.\n\n\n\n== Detailed data on the attack ==\nA malware embedded scanner was installed on a wireless network.  An attack against the internal network initiated automatically using a server message block protocol. \nThe stolen data which was scanned included every piece of information about the item, destination address, source and more.  This was sent clandestinely to a command and control connection back to a botnet in China.  This botnet connected to the Lanxiang Vocational School located in the China Unicom network for Shandong province. This school in China has been connected to previous attacks, including Google and the Operation Aurora attack. The manufacturer of the scanner was located just a few blocks away from the school.\nThe botnet then downloaded a second payload that broadened the command and control which now extended to the target company's corporate servers in finance. The attackers were looking for logistics data on all shipping on a worldwide basis, and the attackers had succeeded in obtaining detailed financial data on all customers and shipments.\n\n== Detection ==\nZombie Zero can be detected using deception technology.\n\nQ: What type of data was stolen in the Zombie Zero attack?",
    "context": "",
    "output": "A: Every piece of information about the scanned items, destination address, source, and more was stolen in the Zombie Zero attack.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What type of data was stolen in the Zombie Zero attack?",
      "answer": "Every piece of information about the scanned items, destination address, source, and more was stolen in the Zombie Zero attack.",
      "context": "Zombie Zero\n\n==Introduction==\nZombie Zero is an attack vector where a cyber attacker utilized malware that was clandestinely embedded in new barcode readers which were manufactured overseas.  \nIt remains unknown if this attack was promulgated by organized crime or a nation state. Clearly there was significant planning and investment in order to design the malware, and then embed it into the hardware within the barcode scanner. Internet of things (IoT) devices may be similarly preinstalled with malware that can capture the network passwords and then open a backdoor to attackers. Given the high volume of these devices manufactured overseas high caution is to be exercised before placing these devices on corporate or government networks.\n\n\n\n== Detailed data on the attack ==\nA malware embedded scanner was installed on a wireless network.  An attack against the internal network initiated automatically using a server message block protocol. \nThe stolen data which was scanned included every piece of information about the item, destination address, source and more.  This was sent clandestinely to a command and control connection back to a botnet in China.  This botnet connected to the Lanxiang Vocational School located in the China Unicom network for Shandong province. This school in China has been connected to previous attacks, including Google and the Operation Aurora attack. The manufacturer of the scanner was located just a few blocks away from the school.\nThe botnet then downloaded a second payload that broadened the command and control which now extended to the target company's corporate servers in finance. The attackers were looking for logistics data on all shipping on a worldwide basis, and the attackers had succeeded in obtaining detailed financial data on all customers and shipments.\n\n== Detection ==\nZombie Zero can be detected using deception technology."
    }
  },
  {
    "instruction": "Anti-phishing software\n\n==Introduction==\nAnti-phishing software consists of computer programs that attempt to identify phishing content contained in websites, e-mail, or other forms used to accessing data (usually from the internet) and block the content, usually with a warning to the user (and often an option to view the content regardless). It is often integrated with web browsers and email clients as a toolbar that displays the real domain name for the website the viewer is visiting, in an attempt to prevent fraudulent websites from masquerading as other legitimate websites.\nMost popular web browsers comes with built-in anti-phishing and anti-malware protection services, but almost none of the alternate web browsers have such protections.Password managers can also be used to help defend against phishing, as can some mutual authentication techniques.\n\n== Notable client-based anti-phishing programs ==\navast!\nAvira Premium Security Suite\nEarthlink ScamBlocker (discontinued)\neBay Toolbar\nEgress Defend \nESET Smart Security\nG Data Software G DATA Antivirus\nGeoTrust TrustWatch\nGoogle Safe Browsing (used in Mozilla Firefox, Google Chrome, Opera, Safari, and Vivaldi)\nKaspersky Internet Security\nMcAfee SiteAdvisor\nMicrosoft SmartScreen (used in Microsoft Edge, Internet Explorer, and Microsoft Outlook)\nMozilla Thunderbird\nNetcraft Toolbar\nNetscape\nNorton 360\nNorton Internet Security\nPhishTank SiteChecker\nQuick Heal\nWindows Mail - default Windows Vista e-mail client\nWOT (Web Of Trust) - browser extension\nZoneAlarm\n\n== Service-based anti-phishing ==\nGoogle Safe Browsing\nOpenDNS\nPhishTank\n\n== Anti-phishing effectiveness ==\nAn independent study conducted by Carnegie Mellon University CyLab titled \"Phinding Phish: An Evaluation of Anti-Phishing Toolbars\" and released November 13, 2006 tested the ability of ten anti-phishing solutions to block or warn about known phishing sites and not block or warn about legitimate sites (not exhibit false-positives), as well as the usability of each solution. Of the solutions tested, Netcraft Toolbar, EarthLink ScamBlocker and SpoofGuard were able to correctly identify over 75% of the sites tested, with Netcraft Toolbar receiving the highest score without incorrectly identifying legitimate sites as phishing. Severe problems were however discovered using SpoofGuard, and it incorrectly identified 38% of the tested legitimate sites as phishing, leading to the conclusion that \"such inaccuracies might nullify the benefits SpoofGuard offers in identifying phishing sites.\" Google Safe Browsing (which has since been built into Firefox) and Internet Explorer both performed well, but when testing ability to detect fresh phishes Netcraft Toolbar scored as high as 96%, while Google Safe Browsing scored as low as 0%, possibly due to technical problems with Google Safe Browsing. The testing was performed using phishing data obtained from Anti-Phishing Working Group, PhishTank, and an unnamed email filtering vendor.Another study, conducted by SmartWare for Mozilla and released November 14, 2006, concluded that the anti-phishing filter in Firefox was more effective than Internet Explorer by over 10%. The results of this study have been questioned by critics, noting that the testing data was sourced exclusively from PhishTank, which itself is an anti-phishing provider. The study only compared Internet Explorer and Firefox, leaving out (among others) Netcraft Toolbar and the Opera browser, both of which use data from PhishTank in their anti-phishing solutions. This has led to speculations that, with the limited testing data, both Opera and Netcraft Toolbar would have gotten a perfect score had they been part of the study.While the two directly aforementioned reports were released only one day apart, Asa Dotzler, Director of Community Development at Mozilla, has responded to the criticism of the Mozilla-commissioned report by saying, \"so you're agreeing that the most recent legitimate data puts Firefox ahead. Good enough for me.\"Since these studies were conducted, both Microsoft and Opera Software have started licensing Netcraft's anti-phishing data, bringing the effectiveness of their browser's built-in anti-phishing on par with Netcraft Toolbar and beyond.\n\nHow did the anti-phishing filter in Firefox compare to Internet Explorer in a study conducted by SmartWare for Mozilla?",
    "context": "",
    "output": "A: The anti-phishing filter in Firefox was more effective than Internet Explorer by over 10% in a study conducted by SmartWare for Mozilla.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How did the anti-phishing filter in Firefox compare to Internet Explorer in a study conducted by SmartWare for Mozilla?",
      "answer": "The anti-phishing filter in Firefox was more effective than Internet Explorer by over 10% in a study conducted by SmartWare for Mozilla.",
      "context": "Anti-phishing software\n\n==Introduction==\nAnti-phishing software consists of computer programs that attempt to identify phishing content contained in websites, e-mail, or other forms used to accessing data (usually from the internet) and block the content, usually with a warning to the user (and often an option to view the content regardless). It is often integrated with web browsers and email clients as a toolbar that displays the real domain name for the website the viewer is visiting, in an attempt to prevent fraudulent websites from masquerading as other legitimate websites.\nMost popular web browsers comes with built-in anti-phishing and anti-malware protection services, but almost none of the alternate web browsers have such protections.Password managers can also be used to help defend against phishing, as can some mutual authentication techniques.\n\n== Notable client-based anti-phishing programs ==\navast!\nAvira Premium Security Suite\nEarthlink ScamBlocker (discontinued)\neBay Toolbar\nEgress Defend \nESET Smart Security\nG Data Software G DATA Antivirus\nGeoTrust TrustWatch\nGoogle Safe Browsing (used in Mozilla Firefox, Google Chrome, Opera, Safari, and Vivaldi)\nKaspersky Internet Security\nMcAfee SiteAdvisor\nMicrosoft SmartScreen (used in Microsoft Edge, Internet Explorer, and Microsoft Outlook)\nMozilla Thunderbird\nNetcraft Toolbar\nNetscape\nNorton 360\nNorton Internet Security\nPhishTank SiteChecker\nQuick Heal\nWindows Mail - default Windows Vista e-mail client\nWOT (Web Of Trust) - browser extension\nZoneAlarm\n\n== Service-based anti-phishing ==\nGoogle Safe Browsing\nOpenDNS\nPhishTank\n\n== Anti-phishing effectiveness ==\nAn independent study conducted by Carnegie Mellon University CyLab titled \"Phinding Phish: An Evaluation of Anti-Phishing Toolbars\" and released November 13, 2006 tested the ability of ten anti-phishing solutions to block or warn about known phishing sites and not block or warn about legitimate sites (not exhibit false-positives), as well as the usability of each solution. Of the solutions tested, Netcraft Toolbar, EarthLink ScamBlocker and SpoofGuard were able to correctly identify over 75% of the sites tested, with Netcraft Toolbar receiving the highest score without incorrectly identifying legitimate sites as phishing. Severe problems were however discovered using SpoofGuard, and it incorrectly identified 38% of the tested legitimate sites as phishing, leading to the conclusion that \"such inaccuracies might nullify the benefits SpoofGuard offers in identifying phishing sites.\" Google Safe Browsing (which has since been built into Firefox) and Internet Explorer both performed well, but when testing ability to detect fresh phishes Netcraft Toolbar scored as high as 96%, while Google Safe Browsing scored as low as 0%, possibly due to technical problems with Google Safe Browsing. The testing was performed using phishing data obtained from Anti-Phishing Working Group, PhishTank, and an unnamed email filtering vendor.Another study, conducted by SmartWare for Mozilla and released November 14, 2006, concluded that the anti-phishing filter in Firefox was more effective than Internet Explorer by over 10%. The results of this study have been questioned by critics, noting that the testing data was sourced exclusively from PhishTank, which itself is an anti-phishing provider. The study only compared Internet Explorer and Firefox, leaving out (among others) Netcraft Toolbar and the Opera browser, both of which use data from PhishTank in their anti-phishing solutions. This has led to speculations that, with the limited testing data, both Opera and Netcraft Toolbar would have gotten a perfect score had they been part of the study.While the two directly aforementioned reports were released only one day apart, Asa Dotzler, Director of Community Development at Mozilla, has responded to the criticism of the Mozilla-commissioned report by saying, \"so you're agreeing that the most recent legitimate data puts Firefox ahead. Good enough for me.\"Since these studies were conducted, both Microsoft and Opera Software have started licensing Netcraft's anti-phishing data, bringing the effectiveness of their browser's built-in anti-phishing on par with Netcraft Toolbar and beyond."
    }
  },
  {
    "instruction": "Polygraphic substitution\n\n==Introduction==\nPolygraphic substitution is a cipher in which a uniform substitution is performed on blocks of letters.  When the length of the block is specifically known, more precise terms are used: for instance, a cipher in which pairs of letters are substituted is bigraphic.\nAs a concept, polygraphic substitution contrasts with monoalphabetic (or simple) substitutions in which individual letters are uniformly substituted, or polyalphabetic substitutions in which individual letters are substituted in different ways depending on their position in the text.  In theory, there is some overlap in these definitions; one could conceivably consider a Vigen\u00e8re cipher with an eight-letter key to be an octographic substitution. In practice, this is not a useful observation since it is far more fruitful to consider it to be a polyalphabetic substitution cipher.\n\n\n\n== Specific ciphers ==\nIn 1563, Giambattista della Porta devised the first bigraphic substitution.  However, it was nothing more than a matrix of symbols.  In practice, it would have been all but impossible to memorize, and carrying around the table would lead to risks of falling into enemy hands.\nIn 1854, Charles Wheatstone came up with the Playfair cipher, a keyword-based system that could be performed on paper in the field.  This was followed up over the next fifty years with the closely related four-square and two-square ciphers, which are slightly more cumbersome but offer slightly better security.In 1929, Lester S. Hill developed the Hill cipher, which uses matrix algebra to encrypt blocks of any desired length.  However, encryption is very difficult to perform by hand for any sufficiently large block size, although it has been implemented by machine or computer.   This is therefore on the frontier between classical and modern cryptography.\n\n== Cryptanalysis of general polygraphic substitutions ==\nPolygraphic systems do provide a significant improvement in security over monoalphabetic substitutions.  Given an individual letter 'E' in a message, it could be encrypted using any of 52 instructions depending on its location and neighbors, which can be used to great advantage to mask the frequency of individual letters.  However, the security boost is limited; while it generally requires a larger sample of text to crack, it can still be done by hand.\nOne can identify a polygraphically-encrypted text by performing a frequency chart of polygrams and not merely of individual letters.  These can be compared to the frequency of plaintext English.  The distribution of digrams is even more stark than individual letters.  For example, the six most common letters in English (23%) represent approximately half of English plaintext, but it takes only the most frequent 8% of the 676 digrams to achieve the same potency.  In addition, even in a plaintext many thousands of characters long, one would expect that nearly half of the digrams would not occur, or only barely.  In addition, looking over the text one would expect to see a fairly regular scattering of repeated text in multiples of the block length and relatively few that are not multiples.\nCracking a code identified as polygraphic is similar to cracking a general monoalphabetic substitution except with a larger 'alphabet'.  One identifies the most frequent polygrams, experiments with replacing them with common plaintext polygrams, and attempts to build up common words, phrases, and finally meaning.  Naturally, if the investigation led the cryptanalyst to suspect that a code was of a specific type, like a Playfair or order-2 Hill cipher, then they could use a more specific attack.\n\nHow does polygraphic substitution differ from monoalphabetic and polyalphabetic substitutions in terms of the units being substituted?",
    "context": "",
    "output": "A: Polygraphic substitution involves uniform substitution of blocks of letters, while monoalphabetic substitution deals with individual letters and polyalphabetic substitution substitutes individual letters based on their position in the text.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does polygraphic substitution differ from monoalphabetic and polyalphabetic substitutions in terms of the units being substituted?",
      "answer": "Polygraphic substitution involves uniform substitution of blocks of letters, while monoalphabetic substitution deals with individual letters and polyalphabetic substitution substitutes individual letters based on their position in the text.",
      "context": "Polygraphic substitution\n\n==Introduction==\nPolygraphic substitution is a cipher in which a uniform substitution is performed on blocks of letters.  When the length of the block is specifically known, more precise terms are used: for instance, a cipher in which pairs of letters are substituted is bigraphic.\nAs a concept, polygraphic substitution contrasts with monoalphabetic (or simple) substitutions in which individual letters are uniformly substituted, or polyalphabetic substitutions in which individual letters are substituted in different ways depending on their position in the text.  In theory, there is some overlap in these definitions; one could conceivably consider a Vigen\u00e8re cipher with an eight-letter key to be an octographic substitution. In practice, this is not a useful observation since it is far more fruitful to consider it to be a polyalphabetic substitution cipher.\n\n\n\n== Specific ciphers ==\nIn 1563, Giambattista della Porta devised the first bigraphic substitution.  However, it was nothing more than a matrix of symbols.  In practice, it would have been all but impossible to memorize, and carrying around the table would lead to risks of falling into enemy hands.\nIn 1854, Charles Wheatstone came up with the Playfair cipher, a keyword-based system that could be performed on paper in the field.  This was followed up over the next fifty years with the closely related four-square and two-square ciphers, which are slightly more cumbersome but offer slightly better security.In 1929, Lester S. Hill developed the Hill cipher, which uses matrix algebra to encrypt blocks of any desired length.  However, encryption is very difficult to perform by hand for any sufficiently large block size, although it has been implemented by machine or computer.   This is therefore on the frontier between classical and modern cryptography.\n\n== Cryptanalysis of general polygraphic substitutions ==\nPolygraphic systems do provide a significant improvement in security over monoalphabetic substitutions.  Given an individual letter 'E' in a message, it could be encrypted using any of 52 instructions depending on its location and neighbors, which can be used to great advantage to mask the frequency of individual letters.  However, the security boost is limited; while it generally requires a larger sample of text to crack, it can still be done by hand.\nOne can identify a polygraphically-encrypted text by performing a frequency chart of polygrams and not merely of individual letters.  These can be compared to the frequency of plaintext English.  The distribution of digrams is even more stark than individual letters.  For example, the six most common letters in English (23%) represent approximately half of English plaintext, but it takes only the most frequent 8% of the 676 digrams to achieve the same potency.  In addition, even in a plaintext many thousands of characters long, one would expect that nearly half of the digrams would not occur, or only barely.  In addition, looking over the text one would expect to see a fairly regular scattering of repeated text in multiples of the block length and relatively few that are not multiples.\nCracking a code identified as polygraphic is similar to cracking a general monoalphabetic substitution except with a larger 'alphabet'.  One identifies the most frequent polygrams, experiments with replacing them with common plaintext polygrams, and attempts to build up common words, phrases, and finally meaning.  Naturally, if the investigation led the cryptanalyst to suspect that a code was of a specific type, like a Playfair or order-2 Hill cipher, then they could use a more specific attack."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are the potential vulnerabilities of certificate-based encryption systems due to regular communication between users and the certificate authority?",
    "context": "",
    "output": "Regular communication between users and the certificate authority exposes the system to potential electronic attacks, such as denial-of-service attacks. Additionally, such attacks could effectively halt the system's functionality.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are the potential vulnerabilities of certificate-based encryption systems due to regular communication between users and the certificate authority?",
      "answer": "Regular communication between users and the certificate authority exposes the system to potential electronic attacks, such as denial-of-service attacks. Additionally, such attacks could effectively halt the system's functionality."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the protected access level extend permissions in computer programming?",
    "context": "",
    "output": "The protected access level extends permissions to all subclasses of the corresponding class.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the protected access level extend permissions in computer programming?",
      "answer": "The protected access level extends permissions to all subclasses of the corresponding class."
    }
  },
  {
    "instruction": "Write an answer to the following question: How can data protection and privacy be improved through cyber security awareness training?",
    "context": "",
    "output": "Cyber security awareness training can enhance data protection and privacy by teaching end users about data classification, encryption, data anonymization, and data masking or obfuscation. Users will also learn about permissions and access controls for data, including email attachments, as well as backup strategies to restore data if it becomes unavailable.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can data protection and privacy be improved through cyber security awareness training?",
      "answer": "Cyber security awareness training can enhance data protection and privacy by teaching end users about data classification, encryption, data anonymization, and data masking or obfuscation. Users will also learn about permissions and access controls for data, including email attachments, as well as backup strategies to restore data if it becomes unavailable."
    }
  },
  {
    "instruction": "Context: Suricata (software)\n\n==Introduction==\nSuricata is an open-source based intrusion detection system (IDS) and intrusion prevention system (IPS). It was developed by the Open Information Security Foundation (OISF). A beta version was released in December 2009, with the first standard release following in July 2010.\n\n== Free intrusion detection systems ==\nOSSEC HIDS\nPrelude Hybrid IDS\nSagan\nSnort\nZeek NIDS\nAnswer this question: How does Suricata differ from other free intrusion detection systems like OSSEC HIDS, Prelude Hybrid IDS, Sagan, Snort, and Zeek NIDS?",
    "context": "",
    "output": "Suricata is an open-source based intrusion detection system (IDS) and intrusion prevention system (IPS), while OSSEC HIDS is a host-based IDS, Prelude Hybrid IDS is a hybrid IDS that combines both network and host-based sensors, Sagan is a high-speed IDS that uses a rule-based system, Snort is a popular open-source IDS and IPS that uses a rule-based system, and Zeek NIDS (formerly known as Bro NIDS) is a powerful open-source network IDS that focuses on providing high-level protocol analysis and anomaly detection. Suricata is unique in its ability to function as both an IDS and an IPS, as well as its support for multiple protocols and advanced features such as application-layer protocol decoding and file extraction.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does Suricata differ from other free intrusion detection systems like OSSEC HIDS, Prelude Hybrid IDS, Sagan, Snort, and Zeek NIDS?",
      "answer": "Suricata is an open-source based intrusion detection system (IDS) and intrusion prevention system (IPS), while OSSEC HIDS is a host-based IDS, Prelude Hybrid IDS is a hybrid IDS that combines both network and host-based sensors, Sagan is a high-speed IDS that uses a rule-based system, Snort is a popular open-source IDS and IPS that uses a rule-based system, and Zeek NIDS (formerly known as Bro NIDS) is a powerful open-source network IDS that focuses on providing high-level protocol analysis and anomaly detection. Suricata is unique in its ability to function as both an IDS and an IPS, as well as its support for multiple protocols and advanced features such as application-layer protocol decoding and file extraction.",
      "context": "Suricata (software)\n\n==Introduction==\nSuricata is an open-source based intrusion detection system (IDS) and intrusion prevention system (IPS). It was developed by the Open Information Security Foundation (OISF). A beta version was released in December 2009, with the first standard release following in July 2010.\n\n== Free intrusion detection systems ==\nOSSEC HIDS\nPrelude Hybrid IDS\nSagan\nSnort\nZeek NIDS"
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the core technology of Vidoop's products?",
    "context": "",
    "output": "The core technology of Vidoop's products is the Vidoop Dynamic Image Grid, a login tool that powers Vidoop Secure and myVidoop.com.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the core technology of Vidoop's products?",
      "answer": "The core technology of Vidoop's products is the Vidoop Dynamic Image Grid, a login tool that powers Vidoop Secure and myVidoop.com."
    }
  },
  {
    "instruction": "Content Security Policy\n\n==Introduction==\nContent Security Policy (CSP) is a computer security standard introduced to prevent cross-site scripting (XSS), clickjacking and other code injection  attacks resulting from execution of malicious content in the trusted web page context. It is a Candidate Recommendation of the W3C working group on Web Application Security, widely supported by modern web browsers. CSP provides a standard method for website owners to declare approved origins of content that browsers should be allowed to load on that website\u2014covered types are JavaScript, CSS, HTML frames, web workers, fonts, images, embeddable objects such as Java applets, ActiveX, audio and video files, and other HTML5 features.\n\n== Status ==\nThe standard, originally named Content Restrictions, was proposed by Robert Hansen in 2004, first implemented in Firefox 4 and quickly picked up by other browsers. Version 1 of the standard was published in 2012 as W3C candidate recommendation and quickly with further versions (Level 2) published in 2014. As of 2023, the draft of Level 3 is being developed with the new features being quickly adopted by the web browsers.The following header names are in use as part of experimental CSP implementations:\nContent-Security-Policy \u2013 standard header name proposed by the W3C document. Google Chrome supports this as of version 25. Firefox supports this as of version 23, released on 6 August 2013. WebKit supports this as of version 528 (nightly build). Chromium-based Microsoft Edge support is similar to Chrome's.\nX-WebKit-CSP \u2013 deprecated, experimental header introduced into Google Chrome, Safari and other WebKit-based web browsers in 2011.\nX-Content-Security-Policy \u2013 deprecated, experimental header introduced in Gecko 2 based browsers (Firefox 4 to Firefox 22,  Thunderbird 3.3,  SeaMonkey 2.1).A website can declare multiple CSP headers, also mixing enforcement and report-only ones. Each header will be processed separately by the browser.\nCSP can also be delivered within the HTML code using a HTML META tag, although in this case its effectiveness will be limited.Internet Explorer 10 and Internet Explorer 11 also support CSP, but only sandbox directive, using the experimental X-Content-Security-Policy header.A number of web application frameworks support CSP, for example AngularJS (natively) and Django (middleware). Instructions for Ruby on Rails have been posted by GitHub. Web framework support is however only required if the CSP contents somehow depend on the web application's state\u2014such as usage of the nonce origin. Otherwise, the CSP is rather static and can be delivered from web application tiers above the application, for example on load balancer or web server.\n\n\n*** Bypasses ***\nIn December 2015  and December 2016, a few methods of bypassing 'nonce' allowlisting origins were published. In January 2016, another method was published, which leverages server-wide CSP allowlisting to exploit old and vulnerable versions of JavaScript libraries hosted at the same server (frequent case with CDN servers). In May 2017 one more method was published to bypass CSP using web application frameworks code.\n\n== Mode of operation ==\n\nIf the Content-Security-Policy header is present in the server response, a compliant client enforces the declarative allowlist policy. One example goal of a policy is a stricter execution mode for JavaScript in order to prevent certain cross-site scripting attacks. In practice this means that a number of features are disabled by default:\n\nInline JavaScript code<script> blocks,\nDOM event handlers as HTML attributes (e.g. onclick)\nThe javascript: links\nInline CSS statements\n<style> block\nstyle attributed to HTML elements\nDynamic JavaScript code evaluationeval()\nstring arguments for setTimeout and setInterval functions\nnew Function() constructor\nDynamic CSS statements\nCSSStyleSheet.insertRule() methodWhile using CSP in a new application may be quite straightforward, especially with CSP-compatible JavaScript framework, existing applications may require some refactoring\u2014or relaxing the policy. Recommended coding practice for CSP-compatible web applications is to load code from external source files (<script src>), parse JSON instead of evaluating it and use EventTarget.addEventListener() to set event handlers.\n\n\n*** Notes ***\n\n== Reporting ==\nAny time a requested resource or script execution violates the policy, the browser will fire a POST request to the value specified in report-uri or  report-to containing details of the violation.\nCSP reports are standard JSON structures and can be captured either by application's own API or public CSP report receivers.In 2018 security researchers showed how to send false positive reports to the designated receiver specified in report-uri . This allows potential attackers to arbitrarily trigger those alarms and might render them less useful in case of a real attack. This behaviour is intended and cannot be fixed, as the browser (client) is sending the reports.\n\n== Browser add-ons and extensions exemption ==\nAccording to the original CSP (1.0) Processing Model (2012\u20132013), CSP should not interfere with the operation of browser add-ons or extensions installed by the user. This feature of CSP would have effectively allowed any add-on, extension, or Bookmarklet to inject script into web sites, regardless of the origin of that script, and thus be exempt from CSP policies.\n\nHowever, this policy has since been modified (as of CSP 1.1) with the following wording. Note the use of the word \"may\" instead of the prior absolute \"should (not)\" wording:Note: User agents may allow users to modify or bypass policy enforcement through user preferences, bookmarklets, third-party additions to the user agent, and other such mechanisms.The absolute \"should\" wording was being used by browser users to request/demand adherence to the policy and have changes installed in popular browsers (Firefox, Chrome, Safari) to support it. This was particularly contentious when sites like Twitter and GitHub started using strong CSP policies, which 'broke' the use of Bookmarklets.The W3C Web Application Security Working Group considers such script to be part of the Trusted Computing Base implemented by the browser; however, it has been argued to the working group by a representative of Cox Communications that this exemption is a potential security hole that could be exploited by malicious or compromised add-ons or extensions.\n\n== Complementary measures ==\nAs of 2015 a number of new browser security standards are being proposed by W3C, most of them complementary to CSP:\nSubresource Integrity (SRI), to ensure only known, trusted resource files (typically JavaScript, CSS) are loaded from third-party servers (typically CDNs)\nMixed Content, to clarify the intended browser's policy on pages loaded over HTTPS and linking content over plaintext HTTP\nUpgrade Insecure Requests, hinting browsers on how to handle legacy links on pages migrated to HTTPS\nCredential Management, a unified JavaScript API to access user's credentials to facilitate complex login schemes,\nReferrer Policy, CSP extension to hint the browser on generation of the Referer headers.\n\nHow can a website declare multiple CSP headers and how are they processed by the browser?",
    "context": "",
    "output": "A: A website can declare multiple CSP headers, which will be processed separately by the browser. Each header can be either an enforcement or report-only one.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can a website declare multiple CSP headers and how are they processed by the browser?",
      "answer": "A website can declare multiple CSP headers, which will be processed separately by the browser. Each header can be either an enforcement or report-only one.",
      "context": "Content Security Policy\n\n==Introduction==\nContent Security Policy (CSP) is a computer security standard introduced to prevent cross-site scripting (XSS), clickjacking and other code injection  attacks resulting from execution of malicious content in the trusted web page context. It is a Candidate Recommendation of the W3C working group on Web Application Security, widely supported by modern web browsers. CSP provides a standard method for website owners to declare approved origins of content that browsers should be allowed to load on that website\u2014covered types are JavaScript, CSS, HTML frames, web workers, fonts, images, embeddable objects such as Java applets, ActiveX, audio and video files, and other HTML5 features.\n\n== Status ==\nThe standard, originally named Content Restrictions, was proposed by Robert Hansen in 2004, first implemented in Firefox 4 and quickly picked up by other browsers. Version 1 of the standard was published in 2012 as W3C candidate recommendation and quickly with further versions (Level 2) published in 2014. As of 2023, the draft of Level 3 is being developed with the new features being quickly adopted by the web browsers.The following header names are in use as part of experimental CSP implementations:\nContent-Security-Policy \u2013 standard header name proposed by the W3C document. Google Chrome supports this as of version 25. Firefox supports this as of version 23, released on 6 August 2013. WebKit supports this as of version 528 (nightly build). Chromium-based Microsoft Edge support is similar to Chrome's.\nX-WebKit-CSP \u2013 deprecated, experimental header introduced into Google Chrome, Safari and other WebKit-based web browsers in 2011.\nX-Content-Security-Policy \u2013 deprecated, experimental header introduced in Gecko 2 based browsers (Firefox 4 to Firefox 22,  Thunderbird 3.3,  SeaMonkey 2.1).A website can declare multiple CSP headers, also mixing enforcement and report-only ones. Each header will be processed separately by the browser.\nCSP can also be delivered within the HTML code using a HTML META tag, although in this case its effectiveness will be limited.Internet Explorer 10 and Internet Explorer 11 also support CSP, but only sandbox directive, using the experimental X-Content-Security-Policy header.A number of web application frameworks support CSP, for example AngularJS (natively) and Django (middleware). Instructions for Ruby on Rails have been posted by GitHub. Web framework support is however only required if the CSP contents somehow depend on the web application's state\u2014such as usage of the nonce origin. Otherwise, the CSP is rather static and can be delivered from web application tiers above the application, for example on load balancer or web server.\n\n\n*** Bypasses ***\nIn December 2015  and December 2016, a few methods of bypassing 'nonce' allowlisting origins were published. In January 2016, another method was published, which leverages server-wide CSP allowlisting to exploit old and vulnerable versions of JavaScript libraries hosted at the same server (frequent case with CDN servers). In May 2017 one more method was published to bypass CSP using web application frameworks code.\n\n== Mode of operation ==\n\nIf the Content-Security-Policy header is present in the server response, a compliant client enforces the declarative allowlist policy. One example goal of a policy is a stricter execution mode for JavaScript in order to prevent certain cross-site scripting attacks. In practice this means that a number of features are disabled by default:\n\nInline JavaScript code<script> blocks,\nDOM event handlers as HTML attributes (e.g. onclick)\nThe javascript: links\nInline CSS statements\n<style> block\nstyle attributed to HTML elements\nDynamic JavaScript code evaluationeval()\nstring arguments for setTimeout and setInterval functions\nnew Function() constructor\nDynamic CSS statements\nCSSStyleSheet.insertRule() methodWhile using CSP in a new application may be quite straightforward, especially with CSP-compatible JavaScript framework, existing applications may require some refactoring\u2014or relaxing the policy. Recommended coding practice for CSP-compatible web applications is to load code from external source files (<script src>), parse JSON instead of evaluating it and use EventTarget.addEventListener() to set event handlers.\n\n\n*** Notes ***\n\n== Reporting ==\nAny time a requested resource or script execution violates the policy, the browser will fire a POST request to the value specified in report-uri or  report-to containing details of the violation.\nCSP reports are standard JSON structures and can be captured either by application's own API or public CSP report receivers.In 2018 security researchers showed how to send false positive reports to the designated receiver specified in report-uri . This allows potential attackers to arbitrarily trigger those alarms and might render them less useful in case of a real attack. This behaviour is intended and cannot be fixed, as the browser (client) is sending the reports.\n\n== Browser add-ons and extensions exemption ==\nAccording to the original CSP (1.0) Processing Model (2012\u20132013), CSP should not interfere with the operation of browser add-ons or extensions installed by the user. This feature of CSP would have effectively allowed any add-on, extension, or Bookmarklet to inject script into web sites, regardless of the origin of that script, and thus be exempt from CSP policies.\n\nHowever, this policy has since been modified (as of CSP 1.1) with the following wording. Note the use of the word \"may\" instead of the prior absolute \"should (not)\" wording:Note: User agents may allow users to modify or bypass policy enforcement through user preferences, bookmarklets, third-party additions to the user agent, and other such mechanisms.The absolute \"should\" wording was being used by browser users to request/demand adherence to the policy and have changes installed in popular browsers (Firefox, Chrome, Safari) to support it. This was particularly contentious when sites like Twitter and GitHub started using strong CSP policies, which 'broke' the use of Bookmarklets.The W3C Web Application Security Working Group considers such script to be part of the Trusted Computing Base implemented by the browser; however, it has been argued to the working group by a representative of Cox Communications that this exemption is a potential security hole that could be exploited by malicious or compromised add-ons or extensions.\n\n== Complementary measures ==\nAs of 2015 a number of new browser security standards are being proposed by W3C, most of them complementary to CSP:\nSubresource Integrity (SRI), to ensure only known, trusted resource files (typically JavaScript, CSS) are loaded from third-party servers (typically CDNs)\nMixed Content, to clarify the intended browser's policy on pages loaded over HTTPS and linking content over plaintext HTTP\nUpgrade Insecure Requests, hinting browsers on how to handle legacy links on pages migrated to HTTPS\nCredential Management, a unified JavaScript API to access user's credentials to facilitate complex login schemes,\nReferrer Policy, CSP extension to hint the browser on generation of the Referer headers."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the size of the BDU reflect on the state of data security threats management in the Russian Federation compared to the United States?",
    "context": "",
    "output": "The smaller size of the BDU compared to the U.S. National Vulnerability Database could suggest that the Russian Federation may have fewer resources dedicated to managing data security threats or a lower number of reported threats. However, it's important to note that this is only one metric and there could be other factors at play.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the size of the BDU reflect on the state of data security threats management in the Russian Federation compared to the United States?",
      "answer": "The smaller size of the BDU compared to the U.S. National Vulnerability Database could suggest that the Russian Federation may have fewer resources dedicated to managing data security threats or a lower number of reported threats. However, it's important to note that this is only one metric and there could be other factors at play."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the role of PCH's board of directors, and who are its members?",
    "context": "",
    "output": "PCH's board of directors consists of Steve Feldman (chairman), Dorian Kim, and Bill Woodcock (executive director). They provide strategic direction and oversight for the organization.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of PCH's board of directors, and who are its members?",
      "answer": "PCH's board of directors consists of Steve Feldman (chairman), Dorian Kim, and Bill Woodcock (executive director). They provide strategic direction and oversight for the organization."
    }
  },
  {
    "instruction": "Spyware\n\n==Introduction==\nSpyware (a portmanteau for spying software) is software with malicious behaviour that aims to gather information about a person or organization and send it to another entity in a way that harms the user\u2014for example, by violating their privacy or endangering their device's security. This behaviour may be present in malware as well as in legitimate software. Websites may engage in spyware behaviours like web tracking. Hardware devices may also be affected. Spyware is frequently associated with advertising and involves many of the same issues. Because these behaviors are so common, and can have non-harmful uses, providing a precise definition of spyware is a difficult task.\n\n== Overview ==\nSpyware is mostly classified into four types: adware, system monitors, tracking including web tracking, and trojans; examples of other notorious types include digital rights management capabilities that \"phone home\", keyloggers, rootkits, and web beacons. These four categories are not mutually exclusive and they have similar tactics in attacking networks and devices. The main goal is to install, hack into the network, avoid being detected, and safely remove themselves from the network.Spyware is mostly used for the stealing information and storing Internet users' movements on the Web and serving up pop-up ads to Internet users. Whenever spyware is used for malicious purposes, its presence is typically hidden from the user and can be difficult to detect. Some spyware, such as keyloggers, may be installed by the owner of a shared, corporate, or public computer intentionally in order to monitor users.\nWhile the term spyware suggests software that monitors a user's computer, the functions of spyware can extend beyond simple monitoring. Spyware can collect almost any type of data, including personal information like internet surfing habits, user logins, and bank or credit account information. Spyware can also interfere with a user's control of a computer by installing additional software or redirecting web browsers. Some spyware can change computer settings, which can result in slow Internet connection speeds, un-authorized changes in browser settings, or changes to software settings.\nSometimes, spyware is included along with genuine software, and may come from a malicious website or may have been added to the intentional functionality of genuine software (see the paragraph about Facebook, below). In response to the emergence of spyware, a small industry has sprung up dealing in anti-spyware software. Running anti-spyware software has become a widely recognized element of computer security practices, especially for computers running Microsoft Windows. A number of jurisdictions have passed anti-spyware laws, which usually target any software that is surreptitiously installed to control a user's computer.\nIn German-speaking countries, spyware used or made by the government is called govware by computer experts (in common parlance: Regierungstrojaner, literally \"Government Trojan\"). Govware is typically a trojan horse software used to intercept communications from the target computer. Some countries, like Switzerland and Germany, have a legal framework governing the use of such software. In the US, the term \"policeware\" has been used for similar purposes.Use of the term \"spyware\" has eventually declined as the practice of tracking users has been pushed ever further into the mainstream by major websites and data mining companies; these generally break no known laws and compel users to be tracked, not by fraudulent practices per se, but by the default settings created for users and the language of terms-of-service agreements. In one documented example, on CBS/CNet News reported, on March 7, 2011, on a Wall Street Journal analysis revealing the practice of Facebook and other websites of tracking users' browsing activity, linked to their identity, far beyond users' visits and activity within the Facebook site itself. The report stated: \"Here's how it works. You go to Facebook, you log in, you spend some time there, and then ... you move on without logging out. Let's say the next site you go to is New York Times. Those buttons, without you clicking on them, have just reported back to Facebook and Twitter that you went there and also your identity within those accounts. Let's say you moved on to something like a site about depression. This one also has a tweet button, a Google widget, and those, too, can report back who you are and that you went there.\" The WSJ analysis was researched by Brian Kennish, founder of Disconnect, Inc.\n\n== Routes of infection ==\nSpyware does not necessarily spread in the same way as a virus or worm because infected systems generally do not attempt to transmit or copy the software to other computers. Instead, spyware installs itself on a system by deceiving the user or by exploiting software vulnerabilities.\nMost spyware is installed without  knowledge, or by using deceptive tactics. Spyware may try to deceive users by bundling itself with desirable software. Other common tactics are using a Trojan horse, spy gadgets that look like normal devices but turn out to be something else, such as a USB Keylogger. These devices actually are connected to the device as memory units but are capable of recording each stroke made on the keyboard. Some spyware authors infect a system through security holes in the Web browser or in other software. When the user navigates to a Web page controlled by the spyware author, the page contains code which attacks the browser and forces the download and installation of spyware.\nThe installation of spyware frequently involves Internet Explorer. Its popularity and history of security issues have made it a frequent target. Its deep integration with the Windows environment make it susceptible to attack into the Windows operating system. Internet Explorer also serves as a point of attachment for spyware in the form of Browser Helper Objects, which modify the browser's behaviour.\n\n== Effects and behaviors ==\nA spyware rarely operates alone on a computer; an affected machine usually has multiple infections. Users frequently notice unwanted behavior and degradation of system performance. A spyware infestation can create significant unwanted CPU activity, disk usage, and network traffic. Stability issues, such as applications freezing, failure to boot, and system-wide crashes are also common. Usually, this effect is intentional, but may be caused from the malware simply requiring large amounts of computing power, disk space, or network usage. Spyware, which interferes with networking software commonly causes difficulty connecting to the Internet.\nIn some infections, the spyware is not even evident. Users assume in those situations that the performance issues relate to faulty hardware, Windows installation problems, or another malware infection. Some owners of badly infected systems resort to contacting technical support experts, or even buying a new computer because the existing system \"has become too slow\". Badly infected systems may require a clean reinstallation of all their software in order to return to full functionality.\nMoreover, some types of spyware disable software firewalls and antivirus software, and/or reduce browser security settings, which opens the system to further opportunistic infections. Some spyware disables or even removes competing spyware programs, on the grounds that more spyware-related annoyances increase the likelihood that users will take action to remove the programs.Keyloggers are sometimes part of malware packages downloaded onto computers without the owners' knowledge. Some keylogger software is freely available on the internet, while others are commercial or private applications. Most keyloggers allow not only keyboard keystrokes to be captured, they also are often capable of collecting screen captures from the computer.\nA typical Windows user has administrative privileges, mostly for convenience. Because of this, any program the user runs has unrestricted access to the system. As with other operating systems, Windows users are able to follow the principle of least privilege and use non-administrator accounts. Alternatively, they can reduce the privileges of specific vulnerable Internet-facing processes, such as Internet Explorer.\nSince Windows Vista is, by default, a computer administrator that runs everything under limited user privileges, when a program requires administrative privileges, a User Account Control pop-up will prompt the user to allow or deny the action. This improves on the design used by previous versions of Windows.\nSpyware is also known as tracking software.\n\n== Remedies and prevention ==\n\nAs the spyware threat has evolved, a number of techniques have emerged to counteract it. These include programs designed to remove or block spyware, as well as various user practices which reduce the chance of getting spyware on a system.\nNonetheless, spyware remains a costly problem. When a large number of pieces of spyware have infected a Windows computer, the only remedy may involve backing up user data, and fully reinstalling the operating system. For instance, some spyware cannot be completely removed by Symantec, Microsoft, PC Tools.\n\n\n*** Anti-spyware programs ***\n\nMany programmers and some commercial firms have released products designed to remove or block spyware. Programs such as PC Tools' Spyware Doctor, Lavasoft's Ad-Aware SE and Patrick Kolla's Spybot - Search & Destroy rapidly gained popularity as tools to remove, and in some cases intercept, spyware programs.  On December, 2004, Microsoft acquired the GIANT AntiSpyware software, re\u2011branding it as Microsoft AntiSpyware (Beta 1) and releasing it as a free download for Genuine Windows XP and Windows 2003 users. In November, 2005, it was renamed Windows Defender.Major anti-virus firms such as Symantec, PC Tools, McAfee and Sophos have also added anti-spyware features to their existing anti-virus products. Early on, anti-virus firms expressed reluctance to add anti-spyware functions, citing lawsuits brought by spyware authors against the authors of web sites and programs which described their products as \"spyware\". However, recent versions of these major firms home and business anti-virus products do include anti-spyware functions, albeit treated differently from viruses. Symantec Anti-Virus, for instance, categorizes spyware programs as \"extended threats\" and now offers real-time protection against these threats.\n\n\n*** How anti-spyware software works ***\nAnti-spyware programs can combat spyware in two ways:\n\nThey can provide real-time protection in a manner similar to that of anti-virus protection: all incoming network data is scanned for spyware, and any detected threats are blocked.\nAnti-spyware software programs can be used solely for detection and removal of spyware software that has already been installed into the computer. This kind of anti-spyware can often be set to scan on a regular schedule.Such programs inspect the contents of the Windows registry, operating system files, and installed programs, and remove files and entries which match a list of known spyware. Real-time protection from spyware works identically to real-time anti-virus protection: the software scans disk files at download time, and blocks the activity of components known to represent spyware.\nIn some cases, it may also intercept attempts to install start-up items or to modify browser settings. Earlier versions of anti-spyware programs focused chiefly on detection and removal. Javacool Software's SpywareBlaster, one of the first to offer real-time protection, blocked the installation of ActiveX-based spyware.\nLike most anti-virus software, many anti-spyware/adware tools require a frequently updated database of threats. As new spyware programs are released, anti-spyware developers discover and evaluate them, adding to the list of known spyware, which allows the software to detect and remove new spyware. As a result, anti-spyware software is of limited usefulness without regular updates. Updates may be installed automatically or manually.\nA popular generic spyware removal tool used by those that requires a certain degree of expertise is HijackThis, which scans certain areas of the Windows OS where spyware often resides and presents a list with items to delete manually. As most of the items are legitimate windows files/registry entries it is advised for those who are less knowledgeable on this subject to post a HijackThis log on the numerous antispyware sites and let the experts decide what to delete.\nIf a spyware program is not blocked and manages to get itself installed, it may resist attempts to terminate or uninstall it. Some programs work in pairs: when an anti-spyware scanner (or the user) terminates one running process, the other one respawns the killed program. Likewise, some spyware will detect attempts to remove registry keys and immediately add them again. Usually, booting the infected computer in safe mode allows an anti-spyware program a better chance of removing persistent spyware. Killing the process tree may also work.\n\n\n*** Security practices ***\nTo detect spyware, computer users have found several practices useful in addition to installing anti-spyware programs.  Many users have installed a web browser other than Internet Explorer, such as Mozilla Firefox or Google Chrome. Though no browser is completely safe, Internet Explorer was once at a greater risk for spyware infection due to its large user base as well as vulnerabilities such as ActiveX but these three major browsers are now close to equivalent when it comes to security.Some ISPs\u2014particularly colleges and universities\u2014have taken a different approach to blocking spyware: they use their network firewalls and web proxies to block access to Web sites known to install spyware. On March 31, 2005, Cornell University's Information Technology department released a report detailing the behavior of one particular piece of proxy-based spyware, Marketscore, and the steps the university took to intercept it. Many other educational institutions have taken similar steps.\nIndividual users can also install firewalls from a variety of companies.  These monitor the flow of information going to and from a networked computer and provide protection against spyware and malware.  Some users install a large hosts file which prevents the user's computer from connecting to known spyware-related web addresses.  Spyware may get installed via certain shareware programs offered for download. Downloading programs only from reputable sources can provide some protection from this source of attack.Individual users can use cellphone / computer with physical (electric) switch, or isolated electronic switch that disconnects microphone, camera without bypass and keep it in disconnected position where not in use, that limits information that spyware can collect. (Policy recommended by NIST Guidelines for Managing the Security of Mobile Devices, 2013).\n\n== Applications ==\n\n\n*** \"Stealware\" and affiliate fraud ***\nA few spyware vendors, notably 180 Solutions, have written what the New York Times has dubbed \"stealware\", and what spyware researcher Ben Edelman terms affiliate fraud, a form of click fraud. Stealware diverts the payment of affiliate marketing revenues from the legitimate affiliate to the spyware vendor.\nSpyware which attacks affiliate networks places the spyware operator's affiliate tag on the user's activity \u2013 replacing any other tag, if there is one. The spyware operator is the only party that gains from this. The user has their choices thwarted, a legitimate affiliate loses revenue, networks' reputations are injured, and vendors are harmed by having to pay out affiliate revenues to an \"affiliate\" who is not party to a contract. Affiliate fraud is a violation of the terms of service of most affiliate marketing networks. Mobile devices can also be vulnerable to chargeware, which manipulates users into illegitimate mobile charges.\n\n\n*** Identity theft and fraud ***\nIn one case, spyware has been closely associated with identity theft. In August 2005, researchers from security software firm Sunbelt Software suspected the creators of the common CoolWebSearch spyware had used it to transmit \"chat sessions, user names, passwords, bank information, etc.\"; however it turned out that \"it actually (was) its own sophisticated criminal little trojan that's independent of CWS.\" This case is currently under investigation by the FBI.\nThe Federal Trade Commission estimates that 27.3 million Americans have been victims of identity theft, and that financial losses from identity theft totaled nearly $48 billion for businesses and financial institutions and at least $5 billion in out-of-pocket expenses for individuals.\n\n\n*** Digital rights management ***\nSome copy-protection technologies have borrowed from spyware. In 2005, Sony BMG Music Entertainment was found to be using rootkits in its XCP digital rights management technology Like spyware, not only was it difficult to detect and uninstall, it was so poorly written that most efforts to remove it could have rendered computers unable to function.\nTexas Attorney General Greg Abbott filed suit, and three separate class-action suits were filed. Sony BMG later provided a workaround on its website to help users remove it.Beginning on April 25, 2006, Microsoft's Windows Genuine Advantage Notifications application was installed on most Windows PCs as a \"critical security update\". While the main purpose of this deliberately uninstallable application is to ensure the copy of Windows on the machine was lawfully purchased and installed, it also installs software that has been accused of \"phoning home\" on a daily basis, like spyware. It can be removed with the RemoveWGA tool.\n\n\n*** Personal relationships ***\nStalkerware is spyware that has been used to monitor electronic activities of partners in intimate relationships. At least one software package, Loverspy, was specifically marketed for this purpose. Depending on local laws regarding communal/marital property, observing a partner's online activity without their consent may be illegal; the author of Loverspy and several users of the product were indicted in California in 2005 on charges of wiretapping and various computer crimes.\n\n\n*** Browser cookies ***\nAnti-spyware programs often report Web advertisers' HTTP cookies, the small text files that track browsing activity, as spyware. While they are not always inherently malicious, many users object to third parties using space on their personal computers for their business purposes, and many anti-spyware programs offer to remove them.\n\n\n*** Shameware ***\nShameware or \"accountability software\" is a type of spyware that is not hidden from the user, but operates with their knowledge, if not necessarily their consent. Parents, religious leaders or other authority figures may require their children or congregation members to install such software, which is intended to detect the viewing of pornography or other content deemed inappropriate, and to report it to the authority figure, who may then confront the user about it.\n\n== Spyware programs ==\n\nThese common spyware programs illustrate the diversity of behaviors found in these attacks. Note that as with computer viruses, researchers give names to spyware programs which may not be used by their creators. Programs may be grouped into \"families\" based not on shared program code, but on common behaviors, or by \"following the money\" of apparent financial or business connections. For instance, a number of the spyware programs distributed by Claria are collectively known as \"Gator\". Likewise, programs that are frequently installed together may be described as parts of the same spyware package, even if they function separately.\n\n== Spyware vendors ==\nSpyware vendors include NSO Group, which in the 2010s sold spyware to governments for spying on human rights activists and journalists. NSO Group was investigated by Citizen Lab.\n\n== Rogue anti-spyware programs ==\n\nMalicious programmers have released a large number of  rogue (fake) anti-spyware programs, and widely distributed Web banner ads can warn users that their computers have been infected with spyware, directing them to purchase programs which do not actually remove spyware\u2014or else, may add more spyware of their own.The recent proliferation of fake or spoofed antivirus products that bill themselves as antispyware can be troublesome.  Users may receive popups prompting them to install them to protect their computer, when it will in fact add spyware. It is recommended that users do not install any freeware claiming to be anti-spyware unless it is verified to be legitimate. Some known offenders include:\n\n \nFake antivirus products constitute 15 percent of all malware.On January 26, 2006, Microsoft and the Washington state attorney general filed suit against Secure Computer for its Spyware Cleaner product.\n\n== Legal issues ==\n\n\n*** Criminal law ***\nUnauthorized access to a computer is illegal under computer crime laws, such as the U.S. Computer Fraud and Abuse Act, the U.K.'s Computer Misuse Act, and similar laws in other countries. Since owners of computers infected with spyware generally claim that they never authorized the installation, a prima facie reading would suggest that the promulgation of spyware would count as a criminal act. Law enforcement has often pursued the authors of other malware, particularly viruses. However, few spyware developers have been prosecuted, and many operate openly as strictly legitimate businesses, though some have faced lawsuits.Spyware producers argue that, contrary to the users' claims, users do in fact give consent to installations. Spyware that comes bundled with shareware applications may be described in the legalese text of an end-user license agreement (EULA). Many users habitually ignore these purported contracts, but spyware companies such as Claria say these demonstrate that users have consented.\nDespite the ubiquity of EULAs agreements, under which a single click can be taken as consent to the entire text, relatively little caselaw has resulted from their use. It has been established in most common law jurisdictions that this type of agreement can be a binding contract in certain circumstances. This does not, however, mean that every such agreement is a contract, or that every term in one is enforceable.\nSome jurisdictions, including the U.S. states of Iowa and Washington, have passed laws criminalizing some forms of spyware. Such laws make it illegal for anyone other than the owner or operator of a computer to install software that alters Web-browser settings, monitors keystrokes, or disables computer-security software.\nIn the United States, lawmakers introduced a bill in 2005 entitled the Internet Spyware Prevention Act, which would imprison creators of spyware.\n\n\n*** Administrative sanctions ***\n\n\n**** US FTC actions ****\nThe US Federal Trade Commission has sued Internet marketing organizations under the \"unfairness doctrine\" to make them stop infecting consumers' PCs with spyware. In one case, that against Seismic Entertainment Productions, the FTC accused the defendants of developing a program that seized control of PCs nationwide, infected them with spyware and other malicious software, bombarded them with a barrage of pop-up advertising for Seismic's clients, exposed the PCs to security risks, and caused them to malfunction. Seismic then offered to sell the victims an \"antispyware\" program to fix the computers, and stop the popups and other problems that Seismic had caused. On November 21, 2006, a settlement was entered in federal court under which a $1.75 million judgment was imposed in one case and $1.86 million in another, but the defendants were insolventIn a second case, brought against CyberSpy Software LLC, the FTC charged that CyberSpy marketed and sold \"RemoteSpy\" keylogger spyware to clients who would then secretly monitor unsuspecting consumers' computers. According to the FTC, Cyberspy touted RemoteSpy as a \"100% undetectable\" way to \"Spy on Anyone. From Anywhere.\" The FTC has obtained a temporary order prohibiting the defendants from selling the software and disconnecting from the Internet any of their servers that collect, store, or provide access to information that this software has gathered. The case is still in its preliminary stages.  A complaint filed by the Electronic Privacy Information Center (EPIC) brought the RemoteSpy software to the FTC's attention.\n\n\n**** Netherlands OPTA ****\nAn administrative fine, the first of its kind in Europe, has been issued by the Independent Authority of Posts and Telecommunications (OPTA) from the Netherlands. It applied fines in total value of Euro 1,000,000 for infecting 22 million computers. The spyware concerned is called DollarRevenue. The law articles that have been violated are art. 4.1 of the Decision on universal service providers and on the interests of end users; the fines have been issued based on art. 15.4 taken together with art. 15.10 of the Dutch telecommunications law.\n\n\n*** Civil law ***\nFormer New York State Attorney General and former Governor of New York Eliot Spitzer has pursued spyware companies for fraudulent installation of software. In a suit brought in 2005 by Spitzer, the California firm Intermix Media, Inc. ended up settling, by agreeing to pay US$7.5 million and to stop distributing spyware.The hijacking of Web advertisements has also led to litigation. In June 2002, a number of large Web publishers sued Claria for replacing advertisements, but settled out of court.\nCourts have not yet had to decide whether advertisers can be held liable for spyware that displays their ads. In many cases, the companies whose advertisements appear in spyware pop-ups do not directly do business with the spyware firm. Rather, they have contracted with an advertising agency, which in turn contracts with an online subcontractor who gets paid by the number of \"impressions\" or appearances of the advertisement. Some major firms such as Dell Computer and Mercedes-Benz have sacked advertising agencies that have run their ads in spyware.\n\n\n*** Libel suits by spyware developers ***\nLitigation has gone both ways. Since \"spyware\" has become a common pejorative, some makers have filed libel and defamation actions when their products have been so described. In 2003, Gator (now known as Claria) filed suit against the website PC Pitstop for describing its program as \"spyware\". PC Pitstop settled, agreeing not to use the word \"spyware\", but continues to describe harm caused by the Gator/Claria software. As a result, other anti-spyware and anti-virus companies have also used other terms such as \"potentially unwanted programs\" or greyware to denote these products.\n\n\n*** WebcamGate ***\n\nIn the 2010 WebcamGate case, plaintiffs charged two suburban Philadelphia high schools secretly spied on students by surreptitiously and remotely activating webcams embedded in school-issued laptops the students were using at home, and therefore infringed on their privacy rights.  The school loaded each student's computer with LANrev's remote activation tracking software.  This included the now-discontinued \"TheftTrack\".  While TheftTrack was not enabled by default on the software, the program allowed the school district to elect to activate it, and to choose which of the TheftTrack surveillance options the school wanted to enable.TheftTrack allowed school district employees to secretly remotely activate the webcam embedded in the student's laptop, above the laptop's screen. That allowed school officials to secretly take photos through the webcam, of whatever was in front of it and in its line of sight, and send the photos to the school's server. The LANrev software disabled the webcams for all other uses (e.g., students were unable to use Photo Booth or video chat), so most students mistakenly believed their webcams did not work at all. On top of the webcam surveillance, TheftTrack allowed school officials to take screenshots and send them to the school's server. School officials were also granted the ability to take snapshots of instant messages, web browsing, music playlists, and written compositions. The schools admitted to secretly snapping over 66,000 webshots and screenshots, including webcam shots of students in their bedrooms.\nQuestion: How do spyware vendors justify their actions?",
    "context": "",
    "output": "Answer: Spyware vendors argue that users consent to installations by agreeing to end-user license agreements (EULAs) when they install shareware applications. However, this argument is disputed, as many users do not read or understand these agreements. Additionally, some jurisdictions have passed laws criminalizing certain forms of spyware.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do spyware vendors justify their actions?",
      "answer": "Spyware vendors argue that users consent to installations by agreeing to end-user license agreements (EULAs) when they install shareware applications. However, this argument is disputed, as many users do not read or understand these agreements. Additionally, some jurisdictions have passed laws criminalizing certain forms of spyware.",
      "context": "Spyware\n\n==Introduction==\nSpyware (a portmanteau for spying software) is software with malicious behaviour that aims to gather information about a person or organization and send it to another entity in a way that harms the user\u2014for example, by violating their privacy or endangering their device's security. This behaviour may be present in malware as well as in legitimate software. Websites may engage in spyware behaviours like web tracking. Hardware devices may also be affected. Spyware is frequently associated with advertising and involves many of the same issues. Because these behaviors are so common, and can have non-harmful uses, providing a precise definition of spyware is a difficult task.\n\n== Overview ==\nSpyware is mostly classified into four types: adware, system monitors, tracking including web tracking, and trojans; examples of other notorious types include digital rights management capabilities that \"phone home\", keyloggers, rootkits, and web beacons. These four categories are not mutually exclusive and they have similar tactics in attacking networks and devices. The main goal is to install, hack into the network, avoid being detected, and safely remove themselves from the network.Spyware is mostly used for the stealing information and storing Internet users' movements on the Web and serving up pop-up ads to Internet users. Whenever spyware is used for malicious purposes, its presence is typically hidden from the user and can be difficult to detect. Some spyware, such as keyloggers, may be installed by the owner of a shared, corporate, or public computer intentionally in order to monitor users.\nWhile the term spyware suggests software that monitors a user's computer, the functions of spyware can extend beyond simple monitoring. Spyware can collect almost any type of data, including personal information like internet surfing habits, user logins, and bank or credit account information. Spyware can also interfere with a user's control of a computer by installing additional software or redirecting web browsers. Some spyware can change computer settings, which can result in slow Internet connection speeds, un-authorized changes in browser settings, or changes to software settings.\nSometimes, spyware is included along with genuine software, and may come from a malicious website or may have been added to the intentional functionality of genuine software (see the paragraph about Facebook, below). In response to the emergence of spyware, a small industry has sprung up dealing in anti-spyware software. Running anti-spyware software has become a widely recognized element of computer security practices, especially for computers running Microsoft Windows. A number of jurisdictions have passed anti-spyware laws, which usually target any software that is surreptitiously installed to control a user's computer.\nIn German-speaking countries, spyware used or made by the government is called govware by computer experts (in common parlance: Regierungstrojaner, literally \"Government Trojan\"). Govware is typically a trojan horse software used to intercept communications from the target computer. Some countries, like Switzerland and Germany, have a legal framework governing the use of such software. In the US, the term \"policeware\" has been used for similar purposes.Use of the term \"spyware\" has eventually declined as the practice of tracking users has been pushed ever further into the mainstream by major websites and data mining companies; these generally break no known laws and compel users to be tracked, not by fraudulent practices per se, but by the default settings created for users and the language of terms-of-service agreements. In one documented example, on CBS/CNet News reported, on March 7, 2011, on a Wall Street Journal analysis revealing the practice of Facebook and other websites of tracking users' browsing activity, linked to their identity, far beyond users' visits and activity within the Facebook site itself. The report stated: \"Here's how it works. You go to Facebook, you log in, you spend some time there, and then ... you move on without logging out. Let's say the next site you go to is New York Times. Those buttons, without you clicking on them, have just reported back to Facebook and Twitter that you went there and also your identity within those accounts. Let's say you moved on to something like a site about depression. This one also has a tweet button, a Google widget, and those, too, can report back who you are and that you went there.\" The WSJ analysis was researched by Brian Kennish, founder of Disconnect, Inc.\n\n== Routes of infection ==\nSpyware does not necessarily spread in the same way as a virus or worm because infected systems generally do not attempt to transmit or copy the software to other computers. Instead, spyware installs itself on a system by deceiving the user or by exploiting software vulnerabilities.\nMost spyware is installed without  knowledge, or by using deceptive tactics. Spyware may try to deceive users by bundling itself with desirable software. Other common tactics are using a Trojan horse, spy gadgets that look like normal devices but turn out to be something else, such as a USB Keylogger. These devices actually are connected to the device as memory units but are capable of recording each stroke made on the keyboard. Some spyware authors infect a system through security holes in the Web browser or in other software. When the user navigates to a Web page controlled by the spyware author, the page contains code which attacks the browser and forces the download and installation of spyware.\nThe installation of spyware frequently involves Internet Explorer. Its popularity and history of security issues have made it a frequent target. Its deep integration with the Windows environment make it susceptible to attack into the Windows operating system. Internet Explorer also serves as a point of attachment for spyware in the form of Browser Helper Objects, which modify the browser's behaviour.\n\n== Effects and behaviors ==\nA spyware rarely operates alone on a computer; an affected machine usually has multiple infections. Users frequently notice unwanted behavior and degradation of system performance. A spyware infestation can create significant unwanted CPU activity, disk usage, and network traffic. Stability issues, such as applications freezing, failure to boot, and system-wide crashes are also common. Usually, this effect is intentional, but may be caused from the malware simply requiring large amounts of computing power, disk space, or network usage. Spyware, which interferes with networking software commonly causes difficulty connecting to the Internet.\nIn some infections, the spyware is not even evident. Users assume in those situations that the performance issues relate to faulty hardware, Windows installation problems, or another malware infection. Some owners of badly infected systems resort to contacting technical support experts, or even buying a new computer because the existing system \"has become too slow\". Badly infected systems may require a clean reinstallation of all their software in order to return to full functionality.\nMoreover, some types of spyware disable software firewalls and antivirus software, and/or reduce browser security settings, which opens the system to further opportunistic infections. Some spyware disables or even removes competing spyware programs, on the grounds that more spyware-related annoyances increase the likelihood that users will take action to remove the programs.Keyloggers are sometimes part of malware packages downloaded onto computers without the owners' knowledge. Some keylogger software is freely available on the internet, while others are commercial or private applications. Most keyloggers allow not only keyboard keystrokes to be captured, they also are often capable of collecting screen captures from the computer.\nA typical Windows user has administrative privileges, mostly for convenience. Because of this, any program the user runs has unrestricted access to the system. As with other operating systems, Windows users are able to follow the principle of least privilege and use non-administrator accounts. Alternatively, they can reduce the privileges of specific vulnerable Internet-facing processes, such as Internet Explorer.\nSince Windows Vista is, by default, a computer administrator that runs everything under limited user privileges, when a program requires administrative privileges, a User Account Control pop-up will prompt the user to allow or deny the action. This improves on the design used by previous versions of Windows.\nSpyware is also known as tracking software.\n\n== Remedies and prevention ==\n\nAs the spyware threat has evolved, a number of techniques have emerged to counteract it. These include programs designed to remove or block spyware, as well as various user practices which reduce the chance of getting spyware on a system.\nNonetheless, spyware remains a costly problem. When a large number of pieces of spyware have infected a Windows computer, the only remedy may involve backing up user data, and fully reinstalling the operating system. For instance, some spyware cannot be completely removed by Symantec, Microsoft, PC Tools.\n\n\n*** Anti-spyware programs ***\n\nMany programmers and some commercial firms have released products designed to remove or block spyware. Programs such as PC Tools' Spyware Doctor, Lavasoft's Ad-Aware SE and Patrick Kolla's Spybot - Search & Destroy rapidly gained popularity as tools to remove, and in some cases intercept, spyware programs.  On December, 2004, Microsoft acquired the GIANT AntiSpyware software, re\u2011branding it as Microsoft AntiSpyware (Beta 1) and releasing it as a free download for Genuine Windows XP and Windows 2003 users. In November, 2005, it was renamed Windows Defender.Major anti-virus firms such as Symantec, PC Tools, McAfee and Sophos have also added anti-spyware features to their existing anti-virus products. Early on, anti-virus firms expressed reluctance to add anti-spyware functions, citing lawsuits brought by spyware authors against the authors of web sites and programs which described their products as \"spyware\". However, recent versions of these major firms home and business anti-virus products do include anti-spyware functions, albeit treated differently from viruses. Symantec Anti-Virus, for instance, categorizes spyware programs as \"extended threats\" and now offers real-time protection against these threats.\n\n\n*** How anti-spyware software works ***\nAnti-spyware programs can combat spyware in two ways:\n\nThey can provide real-time protection in a manner similar to that of anti-virus protection: all incoming network data is scanned for spyware, and any detected threats are blocked.\nAnti-spyware software programs can be used solely for detection and removal of spyware software that has already been installed into the computer. This kind of anti-spyware can often be set to scan on a regular schedule.Such programs inspect the contents of the Windows registry, operating system files, and installed programs, and remove files and entries which match a list of known spyware. Real-time protection from spyware works identically to real-time anti-virus protection: the software scans disk files at download time, and blocks the activity of components known to represent spyware.\nIn some cases, it may also intercept attempts to install start-up items or to modify browser settings. Earlier versions of anti-spyware programs focused chiefly on detection and removal. Javacool Software's SpywareBlaster, one of the first to offer real-time protection, blocked the installation of ActiveX-based spyware.\nLike most anti-virus software, many anti-spyware/adware tools require a frequently updated database of threats. As new spyware programs are released, anti-spyware developers discover and evaluate them, adding to the list of known spyware, which allows the software to detect and remove new spyware. As a result, anti-spyware software is of limited usefulness without regular updates. Updates may be installed automatically or manually.\nA popular generic spyware removal tool used by those that requires a certain degree of expertise is HijackThis, which scans certain areas of the Windows OS where spyware often resides and presents a list with items to delete manually. As most of the items are legitimate windows files/registry entries it is advised for those who are less knowledgeable on this subject to post a HijackThis log on the numerous antispyware sites and let the experts decide what to delete.\nIf a spyware program is not blocked and manages to get itself installed, it may resist attempts to terminate or uninstall it. Some programs work in pairs: when an anti-spyware scanner (or the user) terminates one running process, the other one respawns the killed program. Likewise, some spyware will detect attempts to remove registry keys and immediately add them again. Usually, booting the infected computer in safe mode allows an anti-spyware program a better chance of removing persistent spyware. Killing the process tree may also work.\n\n\n*** Security practices ***\nTo detect spyware, computer users have found several practices useful in addition to installing anti-spyware programs.  Many users have installed a web browser other than Internet Explorer, such as Mozilla Firefox or Google Chrome. Though no browser is completely safe, Internet Explorer was once at a greater risk for spyware infection due to its large user base as well as vulnerabilities such as ActiveX but these three major browsers are now close to equivalent when it comes to security.Some ISPs\u2014particularly colleges and universities\u2014have taken a different approach to blocking spyware: they use their network firewalls and web proxies to block access to Web sites known to install spyware. On March 31, 2005, Cornell University's Information Technology department released a report detailing the behavior of one particular piece of proxy-based spyware, Marketscore, and the steps the university took to intercept it. Many other educational institutions have taken similar steps.\nIndividual users can also install firewalls from a variety of companies.  These monitor the flow of information going to and from a networked computer and provide protection against spyware and malware.  Some users install a large hosts file which prevents the user's computer from connecting to known spyware-related web addresses.  Spyware may get installed via certain shareware programs offered for download. Downloading programs only from reputable sources can provide some protection from this source of attack.Individual users can use cellphone / computer with physical (electric) switch, or isolated electronic switch that disconnects microphone, camera without bypass and keep it in disconnected position where not in use, that limits information that spyware can collect. (Policy recommended by NIST Guidelines for Managing the Security of Mobile Devices, 2013).\n\n== Applications ==\n\n\n*** \"Stealware\" and affiliate fraud ***\nA few spyware vendors, notably 180 Solutions, have written what the New York Times has dubbed \"stealware\", and what spyware researcher Ben Edelman terms affiliate fraud, a form of click fraud. Stealware diverts the payment of affiliate marketing revenues from the legitimate affiliate to the spyware vendor.\nSpyware which attacks affiliate networks places the spyware operator's affiliate tag on the user's activity \u2013 replacing any other tag, if there is one. The spyware operator is the only party that gains from this. The user has their choices thwarted, a legitimate affiliate loses revenue, networks' reputations are injured, and vendors are harmed by having to pay out affiliate revenues to an \"affiliate\" who is not party to a contract. Affiliate fraud is a violation of the terms of service of most affiliate marketing networks. Mobile devices can also be vulnerable to chargeware, which manipulates users into illegitimate mobile charges.\n\n\n*** Identity theft and fraud ***\nIn one case, spyware has been closely associated with identity theft. In August 2005, researchers from security software firm Sunbelt Software suspected the creators of the common CoolWebSearch spyware had used it to transmit \"chat sessions, user names, passwords, bank information, etc.\"; however it turned out that \"it actually (was) its own sophisticated criminal little trojan that's independent of CWS.\" This case is currently under investigation by the FBI.\nThe Federal Trade Commission estimates that 27.3 million Americans have been victims of identity theft, and that financial losses from identity theft totaled nearly $48 billion for businesses and financial institutions and at least $5 billion in out-of-pocket expenses for individuals.\n\n\n*** Digital rights management ***\nSome copy-protection technologies have borrowed from spyware. In 2005, Sony BMG Music Entertainment was found to be using rootkits in its XCP digital rights management technology Like spyware, not only was it difficult to detect and uninstall, it was so poorly written that most efforts to remove it could have rendered computers unable to function.\nTexas Attorney General Greg Abbott filed suit, and three separate class-action suits were filed. Sony BMG later provided a workaround on its website to help users remove it.Beginning on April 25, 2006, Microsoft's Windows Genuine Advantage Notifications application was installed on most Windows PCs as a \"critical security update\". While the main purpose of this deliberately uninstallable application is to ensure the copy of Windows on the machine was lawfully purchased and installed, it also installs software that has been accused of \"phoning home\" on a daily basis, like spyware. It can be removed with the RemoveWGA tool.\n\n\n*** Personal relationships ***\nStalkerware is spyware that has been used to monitor electronic activities of partners in intimate relationships. At least one software package, Loverspy, was specifically marketed for this purpose. Depending on local laws regarding communal/marital property, observing a partner's online activity without their consent may be illegal; the author of Loverspy and several users of the product were indicted in California in 2005 on charges of wiretapping and various computer crimes.\n\n\n*** Browser cookies ***\nAnti-spyware programs often report Web advertisers' HTTP cookies, the small text files that track browsing activity, as spyware. While they are not always inherently malicious, many users object to third parties using space on their personal computers for their business purposes, and many anti-spyware programs offer to remove them.\n\n\n*** Shameware ***\nShameware or \"accountability software\" is a type of spyware that is not hidden from the user, but operates with their knowledge, if not necessarily their consent. Parents, religious leaders or other authority figures may require their children or congregation members to install such software, which is intended to detect the viewing of pornography or other content deemed inappropriate, and to report it to the authority figure, who may then confront the user about it.\n\n== Spyware programs ==\n\nThese common spyware programs illustrate the diversity of behaviors found in these attacks. Note that as with computer viruses, researchers give names to spyware programs which may not be used by their creators. Programs may be grouped into \"families\" based not on shared program code, but on common behaviors, or by \"following the money\" of apparent financial or business connections. For instance, a number of the spyware programs distributed by Claria are collectively known as \"Gator\". Likewise, programs that are frequently installed together may be described as parts of the same spyware package, even if they function separately.\n\n== Spyware vendors ==\nSpyware vendors include NSO Group, which in the 2010s sold spyware to governments for spying on human rights activists and journalists. NSO Group was investigated by Citizen Lab.\n\n== Rogue anti-spyware programs ==\n\nMalicious programmers have released a large number of  rogue (fake) anti-spyware programs, and widely distributed Web banner ads can warn users that their computers have been infected with spyware, directing them to purchase programs which do not actually remove spyware\u2014or else, may add more spyware of their own.The recent proliferation of fake or spoofed antivirus products that bill themselves as antispyware can be troublesome.  Users may receive popups prompting them to install them to protect their computer, when it will in fact add spyware. It is recommended that users do not install any freeware claiming to be anti-spyware unless it is verified to be legitimate. Some known offenders include:\n\n \nFake antivirus products constitute 15 percent of all malware.On January 26, 2006, Microsoft and the Washington state attorney general filed suit against Secure Computer for its Spyware Cleaner product.\n\n== Legal issues ==\n\n\n*** Criminal law ***\nUnauthorized access to a computer is illegal under computer crime laws, such as the U.S. Computer Fraud and Abuse Act, the U.K.'s Computer Misuse Act, and similar laws in other countries. Since owners of computers infected with spyware generally claim that they never authorized the installation, a prima facie reading would suggest that the promulgation of spyware would count as a criminal act. Law enforcement has often pursued the authors of other malware, particularly viruses. However, few spyware developers have been prosecuted, and many operate openly as strictly legitimate businesses, though some have faced lawsuits.Spyware producers argue that, contrary to the users' claims, users do in fact give consent to installations. Spyware that comes bundled with shareware applications may be described in the legalese text of an end-user license agreement (EULA). Many users habitually ignore these purported contracts, but spyware companies such as Claria say these demonstrate that users have consented.\nDespite the ubiquity of EULAs agreements, under which a single click can be taken as consent to the entire text, relatively little caselaw has resulted from their use. It has been established in most common law jurisdictions that this type of agreement can be a binding contract in certain circumstances. This does not, however, mean that every such agreement is a contract, or that every term in one is enforceable.\nSome jurisdictions, including the U.S. states of Iowa and Washington, have passed laws criminalizing some forms of spyware. Such laws make it illegal for anyone other than the owner or operator of a computer to install software that alters Web-browser settings, monitors keystrokes, or disables computer-security software.\nIn the United States, lawmakers introduced a bill in 2005 entitled the Internet Spyware Prevention Act, which would imprison creators of spyware.\n\n\n*** Administrative sanctions ***\n\n\n**** US FTC actions ****\nThe US Federal Trade Commission has sued Internet marketing organizations under the \"unfairness doctrine\" to make them stop infecting consumers' PCs with spyware. In one case, that against Seismic Entertainment Productions, the FTC accused the defendants of developing a program that seized control of PCs nationwide, infected them with spyware and other malicious software, bombarded them with a barrage of pop-up advertising for Seismic's clients, exposed the PCs to security risks, and caused them to malfunction. Seismic then offered to sell the victims an \"antispyware\" program to fix the computers, and stop the popups and other problems that Seismic had caused. On November 21, 2006, a settlement was entered in federal court under which a $1.75 million judgment was imposed in one case and $1.86 million in another, but the defendants were insolventIn a second case, brought against CyberSpy Software LLC, the FTC charged that CyberSpy marketed and sold \"RemoteSpy\" keylogger spyware to clients who would then secretly monitor unsuspecting consumers' computers. According to the FTC, Cyberspy touted RemoteSpy as a \"100% undetectable\" way to \"Spy on Anyone. From Anywhere.\" The FTC has obtained a temporary order prohibiting the defendants from selling the software and disconnecting from the Internet any of their servers that collect, store, or provide access to information that this software has gathered. The case is still in its preliminary stages.  A complaint filed by the Electronic Privacy Information Center (EPIC) brought the RemoteSpy software to the FTC's attention.\n\n\n**** Netherlands OPTA ****\nAn administrative fine, the first of its kind in Europe, has been issued by the Independent Authority of Posts and Telecommunications (OPTA) from the Netherlands. It applied fines in total value of Euro 1,000,000 for infecting 22 million computers. The spyware concerned is called DollarRevenue. The law articles that have been violated are art. 4.1 of the Decision on universal service providers and on the interests of end users; the fines have been issued based on art. 15.4 taken together with art. 15.10 of the Dutch telecommunications law.\n\n\n*** Civil law ***\nFormer New York State Attorney General and former Governor of New York Eliot Spitzer has pursued spyware companies for fraudulent installation of software. In a suit brought in 2005 by Spitzer, the California firm Intermix Media, Inc. ended up settling, by agreeing to pay US$7.5 million and to stop distributing spyware.The hijacking of Web advertisements has also led to litigation. In June 2002, a number of large Web publishers sued Claria for replacing advertisements, but settled out of court.\nCourts have not yet had to decide whether advertisers can be held liable for spyware that displays their ads. In many cases, the companies whose advertisements appear in spyware pop-ups do not directly do business with the spyware firm. Rather, they have contracted with an advertising agency, which in turn contracts with an online subcontractor who gets paid by the number of \"impressions\" or appearances of the advertisement. Some major firms such as Dell Computer and Mercedes-Benz have sacked advertising agencies that have run their ads in spyware.\n\n\n*** Libel suits by spyware developers ***\nLitigation has gone both ways. Since \"spyware\" has become a common pejorative, some makers have filed libel and defamation actions when their products have been so described. In 2003, Gator (now known as Claria) filed suit against the website PC Pitstop for describing its program as \"spyware\". PC Pitstop settled, agreeing not to use the word \"spyware\", but continues to describe harm caused by the Gator/Claria software. As a result, other anti-spyware and anti-virus companies have also used other terms such as \"potentially unwanted programs\" or greyware to denote these products.\n\n\n*** WebcamGate ***\n\nIn the 2010 WebcamGate case, plaintiffs charged two suburban Philadelphia high schools secretly spied on students by surreptitiously and remotely activating webcams embedded in school-issued laptops the students were using at home, and therefore infringed on their privacy rights.  The school loaded each student's computer with LANrev's remote activation tracking software.  This included the now-discontinued \"TheftTrack\".  While TheftTrack was not enabled by default on the software, the program allowed the school district to elect to activate it, and to choose which of the TheftTrack surveillance options the school wanted to enable.TheftTrack allowed school district employees to secretly remotely activate the webcam embedded in the student's laptop, above the laptop's screen. That allowed school officials to secretly take photos through the webcam, of whatever was in front of it and in its line of sight, and send the photos to the school's server. The LANrev software disabled the webcams for all other uses (e.g., students were unable to use Photo Booth or video chat), so most students mistakenly believed their webcams did not work at all. On top of the webcam surveillance, TheftTrack allowed school officials to take screenshots and send them to the school's server. School officials were also granted the ability to take snapshots of instant messages, web browsing, music playlists, and written compositions. The schools admitted to secretly snapping over 66,000 webshots and screenshots, including webcam shots of students in their bedrooms."
    }
  },
  {
    "instruction": "Clario Tech\n\n==Introduction==\nClario is a security software development company that offers consumer-facing digital security and privacy applications for use on a range of operating systems including iOS, Android, macOS.Clario Tech allegedly has more than 800 team members in various worldwide locations, the majority appear to be operating from Ukraine. The workforce consists of software developers, marketing specialists, security researchers and customer support agents. In 2019, the company announced it would invest $30 million during 2020 to develop its cybersecurity products and make them accessible for all.\n\n\n\n== Products ==\n\n\n*** Clario ***\nClario security application was officially launched at the Consumer Electronic Awards in January 2020 in Las Vegas. Clario announced its aim was to offer a new online security product via a user-friendly dashboard, integrating cybersecurity technology with 24/7 human support against digital threats.The cybersecurity application has been reviewed in various publications including the Evening Standard who called it the \u201cUber of cybersecurity\u201d.In response to the COVID-19 pandemic, Clario launched a 24/7 IT support hotline for anyone to call if they experienced technology issues while in lockdown. The company\u2019s 600+ team were on hand to respond to any reported issues.\nClario received the AV-TEST certification in December 2020 and was featured in the honorable mentions list in the Privacy Focused tool nomination as part of the Product Hunt\u2019s 2020 Golden Kitty Award Winners in 2020.\n\n\n*** MacUpdate ***\nMacUpdate is a Macintosh software download website founded in 1997 by Joel Mueller. In 2017, the site was sold to Zeobit, and subsequently was acquired by Clario Tech in 2020.\n\n\n*** MacKeeper ***\nMacKeeper is utility software that offers system cleaning, privacy features and antivirus for macOS. Clario Tech has become the owner of the MacKeeper software since 2019 with aim to accelerate the transformation of MacKeeper.\n\n== Clario cybersecurity research ==\nClario Tech has undertaken numerous pieces of research into cybersecurity trends in 2020 and 2021. These include \"Which Company Uses the Most of Your Data?\", \"The State of Cybercrime in US and UK\", \"Cybercrime Hotspots\".\nRead the text above and answer this question: Who is the current owner of MacKeeper?",
    "context": "",
    "output": "Clario Tech has become the owner of the MacKeeper software since 2019.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Who is the current owner of MacKeeper?",
      "answer": "Clario Tech has become the owner of the MacKeeper software since 2019.",
      "context": "Clario Tech\n\n==Introduction==\nClario is a security software development company that offers consumer-facing digital security and privacy applications for use on a range of operating systems including iOS, Android, macOS.Clario Tech allegedly has more than 800 team members in various worldwide locations, the majority appear to be operating from Ukraine. The workforce consists of software developers, marketing specialists, security researchers and customer support agents. In 2019, the company announced it would invest $30 million during 2020 to develop its cybersecurity products and make them accessible for all.\n\n\n\n== Products ==\n\n\n*** Clario ***\nClario security application was officially launched at the Consumer Electronic Awards in January 2020 in Las Vegas. Clario announced its aim was to offer a new online security product via a user-friendly dashboard, integrating cybersecurity technology with 24/7 human support against digital threats.The cybersecurity application has been reviewed in various publications including the Evening Standard who called it the \u201cUber of cybersecurity\u201d.In response to the COVID-19 pandemic, Clario launched a 24/7 IT support hotline for anyone to call if they experienced technology issues while in lockdown. The company\u2019s 600+ team were on hand to respond to any reported issues.\nClario received the AV-TEST certification in December 2020 and was featured in the honorable mentions list in the Privacy Focused tool nomination as part of the Product Hunt\u2019s 2020 Golden Kitty Award Winners in 2020.\n\n\n*** MacUpdate ***\nMacUpdate is a Macintosh software download website founded in 1997 by Joel Mueller. In 2017, the site was sold to Zeobit, and subsequently was acquired by Clario Tech in 2020.\n\n\n*** MacKeeper ***\nMacKeeper is utility software that offers system cleaning, privacy features and antivirus for macOS. Clario Tech has become the owner of the MacKeeper software since 2019 with aim to accelerate the transformation of MacKeeper.\n\n== Clario cybersecurity research ==\nClario Tech has undertaken numerous pieces of research into cybersecurity trends in 2020 and 2021. These include \"Which Company Uses the Most of Your Data?\", \"The State of Cybercrime in US and UK\", \"Cybercrime Hotspots\"."
    }
  },
  {
    "instruction": "Context: Tera Term\n\n==Introduction==\nTera Term (alternatively TeraTerm) is an open-source, free, software implemented, terminal emulator (communications) program. It emulates different types of computer terminals, from DEC VT100 to DEC VT382. It supports telnet, SSH 1 & 2 and serial port connections. It also has a built-in macro scripting language (supporting Oniguruma regular expressions) and a few other useful plugins.\n\n== Features ==\nTera term supports:\nSerial port connections over UART.\nTCP/IP (telnet, SSH1, SSH2) connections.\nLog replaying.\nNamed pipe connection.\nIPv6 communication.\nVT100 emulation and selected VT200/VT300 emulation.\nTek4010 emulation.\nFile transfer protocols (Kermit, XMODEM, YMODEM, ZMODEM, B-PLUS and Quick-VAN).\nScripts using the \"Tera Term Language\".\n\n== Common versions ==\n1.4 Last version supporting Win16; source available in Pascal\n2.3 Last version released by T. Teranishi\n3.1.3 Last version released by Ayera. Has issues with scroll window boundaries. Title bar identifies it as version 3.1\n4.xx Latest OSDN release\n\n== Sample images ==\n\nQuestion: What is the purpose of named pipe connection support in Tera Term?\n\nAnswer:",
    "context": "",
    "output": "Named pipe connection support in Tera Term allows users to create a virtual communication channel between applications or services on the same computer. This can be useful for inter-process communication or for connecting to specialized devices or systems.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the purpose of named pipe connection support in Tera Term?",
      "answer": "Named pipe connection support in Tera Term allows users to create a virtual communication channel between applications or services on the same computer. This can be useful for inter-process communication or for connecting to specialized devices or systems.",
      "context": "Tera Term\n\n==Introduction==\nTera Term (alternatively TeraTerm) is an open-source, free, software implemented, terminal emulator (communications) program. It emulates different types of computer terminals, from DEC VT100 to DEC VT382. It supports telnet, SSH 1 & 2 and serial port connections. It also has a built-in macro scripting language (supporting Oniguruma regular expressions) and a few other useful plugins.\n\n== Features ==\nTera term supports:\nSerial port connections over UART.\nTCP/IP (telnet, SSH1, SSH2) connections.\nLog replaying.\nNamed pipe connection.\nIPv6 communication.\nVT100 emulation and selected VT200/VT300 emulation.\nTek4010 emulation.\nFile transfer protocols (Kermit, XMODEM, YMODEM, ZMODEM, B-PLUS and Quick-VAN).\nScripts using the \"Tera Term Language\".\n\n== Common versions ==\n1.4 Last version supporting Win16; source available in Pascal\n2.3 Last version released by T. Teranishi\n3.1.3 Last version released by Ayera. Has issues with scroll window boundaries. Title bar identifies it as version 3.1\n4.xx Latest OSDN release\n\n== Sample images =="
    }
  },
  {
    "instruction": "Cipher security summary\n\n==Introduction==\nThis article summarizes publicly known attacks against block ciphers and stream ciphers. Note that there are perhaps attacks that are not publicly known, and not all entries may be up to date.\n\n== Table color key ==\n\n== Best attack ==\nThis column lists the complexity of the attack:\n\nIf the attack doesn't break the full cipher, \"rounds\" refers to how many rounds were broken\n\"time\"  \u2014 time complexity, number of cipher evaluations for the attacker\n\"data\" \u2014 required known plaintext-ciphertext pairs (if applicable)\n\"memory\" \u2014 how many blocks worth of data needs to be stored (if applicable)\n\"related keys\" \u2014 for related-key attacks, how many related key queries are needed\n\n== Common ciphers ==\n\n\n*** Key or plaintext recovery attacks ***\nAttacks that lead to disclosure of the key or plaintext.\n\n\n*** Distinguishing attacks ***\n\nAttacks that allow distinguishing ciphertext from random data.\n\n== Less common ciphers ==\n\n\n*** Key recovery attacks ***\nAttacks that lead to disclosure of the key.\n\n\n*** Distinguishing attacks ***\n\nAttacks that allow distinguishing ciphertext from random data.\n\nAnswer this question based on the above context: What are some potential consequences of a successful distinguishing attack against a stream cipher?",
    "context": "",
    "output": "A successful distinguishing attack against a stream cipher could allow an attacker to distinguish ciphertext generated by the stream cipher from random data. This type of attack can be particularly effective against stream ciphers that use weak keystream generators.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are some potential consequences of a successful distinguishing attack against a stream cipher?",
      "answer": "A successful distinguishing attack against a stream cipher could allow an attacker to distinguish ciphertext generated by the stream cipher from random data. This type of attack can be particularly effective against stream ciphers that use weak keystream generators.",
      "context": "Cipher security summary\n\n==Introduction==\nThis article summarizes publicly known attacks against block ciphers and stream ciphers. Note that there are perhaps attacks that are not publicly known, and not all entries may be up to date.\n\n== Table color key ==\n\n== Best attack ==\nThis column lists the complexity of the attack:\n\nIf the attack doesn't break the full cipher, \"rounds\" refers to how many rounds were broken\n\"time\"  \u2014 time complexity, number of cipher evaluations for the attacker\n\"data\" \u2014 required known plaintext-ciphertext pairs (if applicable)\n\"memory\" \u2014 how many blocks worth of data needs to be stored (if applicable)\n\"related keys\" \u2014 for related-key attacks, how many related key queries are needed\n\n== Common ciphers ==\n\n\n*** Key or plaintext recovery attacks ***\nAttacks that lead to disclosure of the key or plaintext.\n\n\n*** Distinguishing attacks ***\n\nAttacks that allow distinguishing ciphertext from random data.\n\n== Less common ciphers ==\n\n\n*** Key recovery attacks ***\nAttacks that lead to disclosure of the key.\n\n\n*** Distinguishing attacks ***\n\nAttacks that allow distinguishing ciphertext from random data."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are some common alternatives to traditional text-based passwords?",
    "context": "",
    "output": "Some common alternatives to traditional text-based passwords include single use passwords, non-text based, Biometric, 2D key, multi-factor authentication, or Cognitive Passwords that are question based.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are some common alternatives to traditional text-based passwords?",
      "answer": "Some common alternatives to traditional text-based passwords include single use passwords, non-text based, Biometric, 2D key, multi-factor authentication, or Cognitive Passwords that are question based."
    }
  },
  {
    "instruction": "Write an answer to the following question: How do memory safety vulnerabilities occur in software?",
    "context": "",
    "output": "Memory safety vulnerabilities, such as buffer overflows, can occur due to programming errors, inadequate input validation, or insecure coding practices.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do memory safety vulnerabilities occur in software?",
      "answer": "Memory safety vulnerabilities, such as buffer overflows, can occur due to programming errors, inadequate input validation, or insecure coding practices."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are the potential benefits of using Apache's virtual hosting facility to provide HTTP and HTTPS on a single server machine?",
    "context": "",
    "output": "Potential benefits of using Apache's virtual hosting facility to provide HTTP and HTTPS on a single server machine include reduced resource usage, simplified configuration, and reduced complexity in managing the two virtual servers.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are the potential benefits of using Apache's virtual hosting facility to provide HTTP and HTTPS on a single server machine?",
      "answer": "Potential benefits of using Apache's virtual hosting facility to provide HTTP and HTTPS on a single server machine include reduced resource usage, simplified configuration, and reduced complexity in managing the two virtual servers."
    }
  },
  {
    "instruction": "Nftables\n\n==Introduction==\nnftables is a subsystem of the Linux kernel providing filtering and classification of network packets/datagrams/frames. It has been available since Linux kernel 3.13 released on 19 January 2014.nftables replaces the legacy iptables portions of Netfilter. Among the advantages of nftables over iptables is less code duplication and easier extension to new protocols. nftables is configured via the user-space utility nft, while legacy tools are configured via the utilities iptables, ip6tables, arptables and ebtables frameworks.\nnftables utilizes the building blocks of the Netfilter infrastructure, such as the existing hooks into the networking stack, connection tracking system, userspace queueing component, and logging subsystem.\n\n\n\n== nft ==\n\n\n*** Command-line syntax ***\nA command to drop any packets with destination IP address 1.2.3.4:\n\nnft add rule ip filter output ip daddr 1.2.3.4 drop\n\nNote that the new syntax differs significantly from that of iptables, in which the same rule would be written:\n\niptables -A OUTPUT -d 1.2.3.4 -j DROP\n\nThe new syntax can appear more verbose, but it is also far more flexible. nftables incorporates advanced data structures such as dictionaries, maps and concatenations that do not exist with iptables. Making use of these can significantly reduce the number of chains and rules needed to express a given packet filtering design.\nThe iptables-translate tool can be used to translate many existing iptables rules to equivalent nftables rules. Debian 10 (Buster), among other Linux distributions, uses nftables along with iptables-translate as the default packet filtering backend.\n\n== Overview ==\nThe nftables kernel engine adds a simple virtual machine into the Linux kernel, which is able to execute bytecode to inspect a network packet and make decisions on how that packet should be handled. The operations implemented by this virtual machine are intentionally made basic. It can get data from the packet itself, have a look at the associated metadata (inbound interface, for example), and manage connection-tracking data. Arithmetic, bitwise and comparison operators can be used for making decisions based on that data. The virtual machine is also capable of manipulating sets of data (typically, IP addresses), allowing multiple comparison operations to be replaced with a single set lookup.The above-described organization is contrary to the iptables firewalling code, which has protocol awareness built-in so deeply into the logic that the code has had to be replicated four times\u2014for IPv4, IPv6, ARP, and Ethernet bridging\u2014as the firewall engines are too protocol-specific to be used in a generic manner.The main advantages of nftables over iptables are the simplification of the Linux kernel ABI, reduction of code duplication, improved error reporting, and more efficient execution, storage and incremental changes of filtering rules. Traditionally used iptables(8), ip6tables(8), arptables(8) and ebtables(8) (for IPv4, IPv6, ARP and Ethernet bridging, respectively) are intended to be replaced with nft(8) as a single unified implementation, providing firewall configuration on top of the in-kernel virtual machine.\nnftables also offers an improved userspace API that allows atomic replacements of one or more firewall rules within a single Netlink transaction. This speeds up firewall configuration changes for setups having large rulesets; it can also help in avoiding race conditions while the rule changes are being executed. nftables also includes compatibility features to ease transition from previous firewalls, command-line utilities to convert rules in the iptables format, and syntax-compatible versions of iptables commands that use the nftables backend.\n\nWhat is the main goal of the nftables kernel engine?",
    "context": "",
    "output": "The main goal of the nftables kernel engine is to add a simple virtual machine into the Linux kernel that is able to execute bytecode to inspect a network packet and make decisions on how that packet should be handled.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the main goal of the nftables kernel engine?",
      "answer": "The main goal of the nftables kernel engine is to add a simple virtual machine into the Linux kernel that is able to execute bytecode to inspect a network packet and make decisions on how that packet should be handled.",
      "context": "Nftables\n\n==Introduction==\nnftables is a subsystem of the Linux kernel providing filtering and classification of network packets/datagrams/frames. It has been available since Linux kernel 3.13 released on 19 January 2014.nftables replaces the legacy iptables portions of Netfilter. Among the advantages of nftables over iptables is less code duplication and easier extension to new protocols. nftables is configured via the user-space utility nft, while legacy tools are configured via the utilities iptables, ip6tables, arptables and ebtables frameworks.\nnftables utilizes the building blocks of the Netfilter infrastructure, such as the existing hooks into the networking stack, connection tracking system, userspace queueing component, and logging subsystem.\n\n\n\n== nft ==\n\n\n*** Command-line syntax ***\nA command to drop any packets with destination IP address 1.2.3.4:\n\nnft add rule ip filter output ip daddr 1.2.3.4 drop\n\nNote that the new syntax differs significantly from that of iptables, in which the same rule would be written:\n\niptables -A OUTPUT -d 1.2.3.4 -j DROP\n\nThe new syntax can appear more verbose, but it is also far more flexible. nftables incorporates advanced data structures such as dictionaries, maps and concatenations that do not exist with iptables. Making use of these can significantly reduce the number of chains and rules needed to express a given packet filtering design.\nThe iptables-translate tool can be used to translate many existing iptables rules to equivalent nftables rules. Debian 10 (Buster), among other Linux distributions, uses nftables along with iptables-translate as the default packet filtering backend.\n\n== Overview ==\nThe nftables kernel engine adds a simple virtual machine into the Linux kernel, which is able to execute bytecode to inspect a network packet and make decisions on how that packet should be handled. The operations implemented by this virtual machine are intentionally made basic. It can get data from the packet itself, have a look at the associated metadata (inbound interface, for example), and manage connection-tracking data. Arithmetic, bitwise and comparison operators can be used for making decisions based on that data. The virtual machine is also capable of manipulating sets of data (typically, IP addresses), allowing multiple comparison operations to be replaced with a single set lookup.The above-described organization is contrary to the iptables firewalling code, which has protocol awareness built-in so deeply into the logic that the code has had to be replicated four times\u2014for IPv4, IPv6, ARP, and Ethernet bridging\u2014as the firewall engines are too protocol-specific to be used in a generic manner.The main advantages of nftables over iptables are the simplification of the Linux kernel ABI, reduction of code duplication, improved error reporting, and more efficient execution, storage and incremental changes of filtering rules. Traditionally used iptables(8), ip6tables(8), arptables(8) and ebtables(8) (for IPv4, IPv6, ARP and Ethernet bridging, respectively) are intended to be replaced with nft(8) as a single unified implementation, providing firewall configuration on top of the in-kernel virtual machine.\nnftables also offers an improved userspace API that allows atomic replacements of one or more firewall rules within a single Netlink transaction. This speeds up firewall configuration changes for setups having large rulesets; it can also help in avoiding race conditions while the rule changes are being executed. nftables also includes compatibility features to ease transition from previous firewalls, command-line utilities to convert rules in the iptables format, and syntax-compatible versions of iptables commands that use the nftables backend."
    }
  },
  {
    "instruction": "Write an answer to the following question: What action did LinkedIn take after discovering the additional compromised email addresses and passwords in May 2016?",
    "context": "",
    "output": "LinkedIn discovered an additional 100 million email addresses and passwords that had been compromised from the same 2012 breach. However, the text does not provide information on any specific actions LinkedIn took after this discovery.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What action did LinkedIn take after discovering the additional compromised email addresses and passwords in May 2016?",
      "answer": "LinkedIn discovered an additional 100 million email addresses and passwords that had been compromised from the same 2012 breach. However, the text does not provide information on any specific actions LinkedIn took after this discovery."
    }
  }
]