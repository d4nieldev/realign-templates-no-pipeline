[
  {
    "instruction": "Write an answer to the following question: How does Network Intelligence enhance the effectiveness of applications for Database Security, Database Auditing, and Network Protection?",
    "context": "",
    "output": "Network Intelligence combines real-time network monitoring with IP metadata extraction, enhancing the effectiveness of applications for Database Security, Database Auditing, and Network Protection. The network visibility afforded by NI can also be used to build enhancements and next-generation solutions for Network Performance Management, WAN Optimization, Customer Experience Management, Content Filtering, and internal billing of networked applications.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does Network Intelligence enhance the effectiveness of applications for Database Security, Database Auditing, and Network Protection?",
      "answer": "Network Intelligence combines real-time network monitoring with IP metadata extraction, enhancing the effectiveness of applications for Database Security, Database Auditing, and Network Protection. The network visibility afforded by NI can also be used to build enhancements and next-generation solutions for Network Performance Management, WAN Optimization, Customer Experience Management, Content Filtering, and internal billing of networked applications."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the Matyas\u2013Meyer\u2013Oseas single-block-length one-way compression function differ from Davies\u2013Meyer?",
    "context": "",
    "output": "The Matyas\u2013Meyer\u2013Oseas compression function feeds each block of the message as the plaintext to be encrypted and the previous hash value as the key to the block cipher. The output ciphertext is then XORed with the same message block to produce the next hash value.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the Matyas\u2013Meyer\u2013Oseas single-block-length one-way compression function differ from Davies\u2013Meyer?",
      "answer": "The Matyas\u2013Meyer\u2013Oseas compression function feeds each block of the message as the plaintext to be encrypted and the previous hash value as the key to the block cipher. The output ciphertext is then XORed with the same message block to produce the next hash value."
    }
  },
  {
    "instruction": "IPFire\n\n==Introduction==\nIPFire is a hardened open source Linux distribution that primarily performs as a router and a firewall; a standalone firewall system with a web-based management console for configuration.\nIPFire originally started as a fork of IPCop and has been rewritten on basis of Linux From Scratch since version 2. It supports installation of add-ons to add server services, which can be extended into a SOHO server.\nIn April 2015, the project became a member of the Open Invention Network.\n\n\n\n== System Requirements ==\nThe basic requirements are at least a 1 GHz CPU, 1GB of RAM, and a 4GB hard drive. Two network cards are needed to connect to an Ethernet network. DSL, LTE and Wi-Fi (WLAN) are supported, too, with corresponding hardware.The required computing power to run IPFire depends on the area of application. Most commonly, x86 systems are being used, but ARM devices, such as Raspberry Pi or Banana Pi, are supported, too.\nIPFire can be used in virtual environments (such as KVM, VMWare, XEN, Qemu, etc.).\nThe basic setup of IPFire happens over a guided dialogue on the console, and the further administration takes place on the web-based management interface, such as add-ons and additional features.\n\n== System Details ==\nThe project is regularly updated by the development team to maintain the security. Developed as a stateful packet inspection (SPI) firewall.IPFire separates the network into different segments based on their security risk which are organised in colours. Normal clients connected to the LAN are represented as green, the Internet is represented as red, an optional DMZ is represented as orange and an optional Wireless network is represented as blue. No traffic can flow between segments unless specifically permitted through a firewall rule.IPFire's package management system, called Pakfire allows to install system updates, which keep security up to date, and additional software packages for customisation to different usage scenarios and needs. The Linux system is customised for the concrete purpose of a firewall.The design is modular, making its functionalities extensible through plugins, but the base comes with the following features\nStateful packet-inspection firewall based on Linux Netfilter\nProxy server with content filter and catching-updates functions (e.g. Microsoft Windows updates, virus scanners, etc.)\nIntrusion detection system (Snort) with the option to install the Intrusion Prevention System guardian via Pakfire\nSince Core Update 131 it features the intrusion prevention system \"Suricata\" instead of snort\nVirtual private network (VPN) with IPsec and OpenVPN\nDynamic Host Configuration Protocol (DHCP) server\nCaching name-server (supports DNSSEC)\nTime server\nWake-on-LAN (WOL)\nDynamic DNS\nQuality of service (QoS)\nSystem monitoring functions and log analysis\nGeoIP filtering\nCaptive Portal\n\n== IPFire Location ==\nThe IPFire Project built a free Internet geolocation database published under the Creative Commons license. It is being used by The Tor Project to identify the location of Tor nodes and relays.\n\nBased on the above text, answer a question. How does IPFire help in system monitoring and log analysis?",
    "context": "",
    "output": "IPFire comes with system monitoring functions and log analysis, which helps in identifying and resolving system issues.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does IPFire help in system monitoring and log analysis?",
      "answer": "IPFire comes with system monitoring functions and log analysis, which helps in identifying and resolving system issues.",
      "context": "IPFire\n\n==Introduction==\nIPFire is a hardened open source Linux distribution that primarily performs as a router and a firewall; a standalone firewall system with a web-based management console for configuration.\nIPFire originally started as a fork of IPCop and has been rewritten on basis of Linux From Scratch since version 2. It supports installation of add-ons to add server services, which can be extended into a SOHO server.\nIn April 2015, the project became a member of the Open Invention Network.\n\n\n\n== System Requirements ==\nThe basic requirements are at least a 1 GHz CPU, 1GB of RAM, and a 4GB hard drive. Two network cards are needed to connect to an Ethernet network. DSL, LTE and Wi-Fi (WLAN) are supported, too, with corresponding hardware.The required computing power to run IPFire depends on the area of application. Most commonly, x86 systems are being used, but ARM devices, such as Raspberry Pi or Banana Pi, are supported, too.\nIPFire can be used in virtual environments (such as KVM, VMWare, XEN, Qemu, etc.).\nThe basic setup of IPFire happens over a guided dialogue on the console, and the further administration takes place on the web-based management interface, such as add-ons and additional features.\n\n== System Details ==\nThe project is regularly updated by the development team to maintain the security. Developed as a stateful packet inspection (SPI) firewall.IPFire separates the network into different segments based on their security risk which are organised in colours. Normal clients connected to the LAN are represented as green, the Internet is represented as red, an optional DMZ is represented as orange and an optional Wireless network is represented as blue. No traffic can flow between segments unless specifically permitted through a firewall rule.IPFire's package management system, called Pakfire allows to install system updates, which keep security up to date, and additional software packages for customisation to different usage scenarios and needs. The Linux system is customised for the concrete purpose of a firewall.The design is modular, making its functionalities extensible through plugins, but the base comes with the following features\nStateful packet-inspection firewall based on Linux Netfilter\nProxy server with content filter and catching-updates functions (e.g. Microsoft Windows updates, virus scanners, etc.)\nIntrusion detection system (Snort) with the option to install the Intrusion Prevention System guardian via Pakfire\nSince Core Update 131 it features the intrusion prevention system \"Suricata\" instead of snort\nVirtual private network (VPN) with IPsec and OpenVPN\nDynamic Host Configuration Protocol (DHCP) server\nCaching name-server (supports DNSSEC)\nTime server\nWake-on-LAN (WOL)\nDynamic DNS\nQuality of service (QoS)\nSystem monitoring functions and log analysis\nGeoIP filtering\nCaptive Portal\n\n== IPFire Location ==\nThe IPFire Project built a free Internet geolocation database published under the Creative Commons license. It is being used by The Tor Project to identify the location of Tor nodes and relays."
    }
  },
  {
    "instruction": "Write an answer to the following question: What was Johannes Trithemius's career before he became an abbot?",
    "context": "",
    "output": "Before becoming an abbot, Johannes Trithemius traveled to various universities, including the University of Heidelberg, to find good teachers. He also wandered around looking for teachers in Trier, Cologne, the Netherlands, and Heidelberg.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was Johannes Trithemius's career before he became an abbot?",
      "answer": "Before becoming an abbot, Johannes Trithemius traveled to various universities, including the University of Heidelberg, to find good teachers. He also wandered around looking for teachers in Trier, Cologne, the Netherlands, and Heidelberg."
    }
  },
  {
    "instruction": "Write an answer to the following question: How has Sophos' partnership with ActiveState contributed to its business?",
    "context": "",
    "output": "Sophos' partnership with ActiveState, which lasted from 2003 to 2006, allowed Sophos to serve as the parent company of ActiveState, a developer of programming tools for dynamic programming languages. This partnership gave Sophos access to ActiveState's expertise in programming tools, which may have been useful in developing its own security software. However, the partnership ended when ActiveState was sold to Pender Financial in 2006.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How has Sophos' partnership with ActiveState contributed to its business?",
      "answer": "Sophos' partnership with ActiveState, which lasted from 2003 to 2006, allowed Sophos to serve as the parent company of ActiveState, a developer of programming tools for dynamic programming languages. This partnership gave Sophos access to ActiveState's expertise in programming tools, which may have been useful in developing its own security software. However, the partnership ended when ActiveState was sold to Pender Financial in 2006."
    }
  },
  {
    "instruction": "Write an answer to the following question: Which Linux distribution first enabled AppArmor by default in SLES 10 and in openSUSE 10.1?",
    "context": "",
    "output": "Novell's SLES and openSUSE were the first Linux distributions to enable AppArmor by default in SLES 10 and openSUSE 10.1.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Which Linux distribution first enabled AppArmor by default in SLES 10 and in openSUSE 10.1?",
      "answer": "Novell's SLES and openSUSE were the first Linux distributions to enable AppArmor by default in SLES 10 and openSUSE 10.1."
    }
  },
  {
    "instruction": "Apache SpamAssassin\n\n==Introduction==\nApache SpamAssassin is a computer program used for e-mail spam filtering. It uses a variety of spam-detection techniques, including DNS and fuzzy checksum techniques, Bayesian filtering, external programs, blacklists and online databases. It is released under the Apache License 2.0 and is a part of the Apache Foundation since 2004.\nThe program can be integrated with the mail server to automatically filter all mail for a site. It can also be run by individual users on their own mailbox and integrates with several mail programs. Apache SpamAssassin is highly configurable; if used as a system-wide filter it can still be configured to support per-user preferences.\n\n== Methods of usage ==\nApache SpamAssassin is a Perl-based application (Mail::SpamAssassin in CPAN) which is usually used to filter all incoming mail for one or several users. It can be run as a standalone application or as a subprogram of another application (such as a Milter, SA-Exim, Exiscan, MailScanner, MIMEDefang, Amavis) or as a client (spamc) that communicates with a daemon (spamd). The client/server or embedded mode of operation has performance benefits, but under certain circumstances may introduce additional security risks.\nTypically either variant of the application is set up in a generic mail filter program, or it is called directly from a mail user agent that supports this, whenever new mail arrives. Mail filter programs such as procmail can be made to pipe all incoming mail through Apache SpamAssassin with an adjustment to a user's procmailrc file.\n\n== Operation ==\nApache SpamAssassin comes with a large set of rules which are applied to determine whether an email is spam or not. Most rules are based on regular expressions that are matched against the body or header fields of the message, but Apache SpamAssassin also employs a number of other spam-fighting techniques. The rules are called \"tests\" in the SpamAssassin documentation.\nEach test has a score value that will be assigned to a message if it matches the test's criteria. The scores can be positive or negative, with positive values indicating \"spam\" and negative \"ham\" (non-spam messages). A message is matched against all tests and Apache SpamAssassin combines the results into a global score which is assigned to the message. The higher the score, the higher the probability that the message is spam.\nApache SpamAssassin has an internal (configurable) score threshold to classify a message as spam. Usually a message will only be considered as spam if it matches multiple criteria; matching just a single test will not usually be enough to reach the threshold.\nIf Apache SpamAssassin considers a message to be spam, it can be further rewritten. In the default configuration, the content of the mail is appended as a MIME attachment, with a brief excerpt in the message body, and a description of the tests which resulted in the mail being classified as spam. If the score is lower than the defined settings, by default the information about the tests passed and total score is still added to the email headers and can be used in post-processing for less severe actions, such as tagging the mail as suspicious.\nApache SpamAssassin allows for a per-user configuration of its behavior, even if installed as system-wide service; the configuration can be read from a file or a database.  In their configuration users can specify individuals whose emails are never considered spam, or change the scores for certain rules. The user can also define a list of languages which they want to receive mail in, and Apache SpamAssassin then assigns a higher score to all mails that appear to be written in another language.\nApache SpamAssassin is based on heuristics (pattern recognition), and such software exhibits false positives and false negatives.\n\n== Network-based filtering methods ==\nApache SpamAssassin also supports:\n\nDNS-based blacklists and DNS-based whitelists\nFuzzy-checksum-based spam detection filters such as the Distributed Checksum Clearinghouse, Vipul's Razor and the Cloudmark Authority plugins (commercial)\nHashcash email stamps based on proof-of-work\nSender Policy Framework and DomainKeys Identified Mail\nURI blacklists such as SURBL or URIBL which track spam websitesMore methods can be added reasonably easily by writing a Perl plug-in for Apache SpamAssassin.\n\n== Bayesian filtering ==\nApache SpamAssassin reinforces its rules through Bayesian filtering where a user or administrator \"feeds\" examples of good (ham) and bad (spam) into the filter in order to learn the difference between the two. For this purpose, Apache SpamAssassin provides the command-line tool sa-learn, which can be instructed to learn a single mail or an entire mailbox as either ham or spam.\nTypically, the user will move unrecognized spam to a separate folder, and then run sa-learn on the folder of non-spam and on the folder of spam separately. Alternatively, if the mail user agent supports it, sa-learn can be called for individual emails. Regardless of the method used to perform the learning, SpamAssassin's Bayesian test will help score future e-mails based on this learning to improve the accuracy.\n\n== Licensing ==\nApache SpamAssassin is free/open source software, licensed under the Apache License 2.0. Versions prior to 3.0 are dual-licensed under the Artistic License and the GNU General Public License.\n\n== sa-compile ==\nsa-compile is a utility distributed with Apache SpamAssassin that compiles a SpamAssassin ruleset into a deterministic finite automaton that allows Apache SpamAssassin to use processor power more efficiently.\n\n== Testing Apache SpamAssassin ==\nApache SpamAssassin is designed to trigger on the GTUBE, a 68-byte string similar to the antivirus EICAR test file. If this string is inserted in an RFC 5322 formatted message and passed through the Apache SpamAssassin engine, Apache SpamAssassin will trigger with a weight of 1000.\n\nBased on the above text, answer a question. How can Apache SpamAssassin be integrated with a mail server?",
    "context": "",
    "output": "Apache SpamAssassin can be integrated with the mail server to automatically filter all mail for a site.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can Apache SpamAssassin be integrated with a mail server?",
      "answer": "Apache SpamAssassin can be integrated with the mail server to automatically filter all mail for a site.",
      "context": "Apache SpamAssassin\n\n==Introduction==\nApache SpamAssassin is a computer program used for e-mail spam filtering. It uses a variety of spam-detection techniques, including DNS and fuzzy checksum techniques, Bayesian filtering, external programs, blacklists and online databases. It is released under the Apache License 2.0 and is a part of the Apache Foundation since 2004.\nThe program can be integrated with the mail server to automatically filter all mail for a site. It can also be run by individual users on their own mailbox and integrates with several mail programs. Apache SpamAssassin is highly configurable; if used as a system-wide filter it can still be configured to support per-user preferences.\n\n== Methods of usage ==\nApache SpamAssassin is a Perl-based application (Mail::SpamAssassin in CPAN) which is usually used to filter all incoming mail for one or several users. It can be run as a standalone application or as a subprogram of another application (such as a Milter, SA-Exim, Exiscan, MailScanner, MIMEDefang, Amavis) or as a client (spamc) that communicates with a daemon (spamd). The client/server or embedded mode of operation has performance benefits, but under certain circumstances may introduce additional security risks.\nTypically either variant of the application is set up in a generic mail filter program, or it is called directly from a mail user agent that supports this, whenever new mail arrives. Mail filter programs such as procmail can be made to pipe all incoming mail through Apache SpamAssassin with an adjustment to a user's procmailrc file.\n\n== Operation ==\nApache SpamAssassin comes with a large set of rules which are applied to determine whether an email is spam or not. Most rules are based on regular expressions that are matched against the body or header fields of the message, but Apache SpamAssassin also employs a number of other spam-fighting techniques. The rules are called \"tests\" in the SpamAssassin documentation.\nEach test has a score value that will be assigned to a message if it matches the test's criteria. The scores can be positive or negative, with positive values indicating \"spam\" and negative \"ham\" (non-spam messages). A message is matched against all tests and Apache SpamAssassin combines the results into a global score which is assigned to the message. The higher the score, the higher the probability that the message is spam.\nApache SpamAssassin has an internal (configurable) score threshold to classify a message as spam. Usually a message will only be considered as spam if it matches multiple criteria; matching just a single test will not usually be enough to reach the threshold.\nIf Apache SpamAssassin considers a message to be spam, it can be further rewritten. In the default configuration, the content of the mail is appended as a MIME attachment, with a brief excerpt in the message body, and a description of the tests which resulted in the mail being classified as spam. If the score is lower than the defined settings, by default the information about the tests passed and total score is still added to the email headers and can be used in post-processing for less severe actions, such as tagging the mail as suspicious.\nApache SpamAssassin allows for a per-user configuration of its behavior, even if installed as system-wide service; the configuration can be read from a file or a database.  In their configuration users can specify individuals whose emails are never considered spam, or change the scores for certain rules. The user can also define a list of languages which they want to receive mail in, and Apache SpamAssassin then assigns a higher score to all mails that appear to be written in another language.\nApache SpamAssassin is based on heuristics (pattern recognition), and such software exhibits false positives and false negatives.\n\n== Network-based filtering methods ==\nApache SpamAssassin also supports:\n\nDNS-based blacklists and DNS-based whitelists\nFuzzy-checksum-based spam detection filters such as the Distributed Checksum Clearinghouse, Vipul's Razor and the Cloudmark Authority plugins (commercial)\nHashcash email stamps based on proof-of-work\nSender Policy Framework and DomainKeys Identified Mail\nURI blacklists such as SURBL or URIBL which track spam websitesMore methods can be added reasonably easily by writing a Perl plug-in for Apache SpamAssassin.\n\n== Bayesian filtering ==\nApache SpamAssassin reinforces its rules through Bayesian filtering where a user or administrator \"feeds\" examples of good (ham) and bad (spam) into the filter in order to learn the difference between the two. For this purpose, Apache SpamAssassin provides the command-line tool sa-learn, which can be instructed to learn a single mail or an entire mailbox as either ham or spam.\nTypically, the user will move unrecognized spam to a separate folder, and then run sa-learn on the folder of non-spam and on the folder of spam separately. Alternatively, if the mail user agent supports it, sa-learn can be called for individual emails. Regardless of the method used to perform the learning, SpamAssassin's Bayesian test will help score future e-mails based on this learning to improve the accuracy.\n\n== Licensing ==\nApache SpamAssassin is free/open source software, licensed under the Apache License 2.0. Versions prior to 3.0 are dual-licensed under the Artistic License and the GNU General Public License.\n\n== sa-compile ==\nsa-compile is a utility distributed with Apache SpamAssassin that compiles a SpamAssassin ruleset into a deterministic finite automaton that allows Apache SpamAssassin to use processor power more efficiently.\n\n== Testing Apache SpamAssassin ==\nApache SpamAssassin is designed to trigger on the GTUBE, a 68-byte string similar to the antivirus EICAR test file. If this string is inserted in an RFC 5322 formatted message and passed through the Apache SpamAssassin engine, Apache SpamAssassin will trigger with a weight of 1000."
    }
  },
  {
    "instruction": "Write an answer to the following question: How do hardware security bugs differ from other types of security vulnerabilities?",
    "context": "",
    "output": "Hardware security bugs are unique in that they are hardware flaws or bugs that create vulnerabilities in CPUs or other devices with programmable processors or logic and direct memory access, rather than software-based vulnerabilities.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do hardware security bugs differ from other types of security vulnerabilities?",
      "answer": "Hardware security bugs are unique in that they are hardware flaws or bugs that create vulnerabilities in CPUs or other devices with programmable processors or logic and direct memory access, rather than software-based vulnerabilities."
    }
  },
  {
    "instruction": "Write an answer to the following question: How is Tallinn 2.0 different from its predecessor?",
    "context": "",
    "output": "Tallinn 2.0 expands the scope of the original Tallinn Manual to include a broader range of cyber operations and examines the international legal framework that applies to such operations.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How is Tallinn 2.0 different from its predecessor?",
      "answer": "Tallinn 2.0 expands the scope of the original Tallinn Manual to include a broader range of cyber operations and examines the international legal framework that applies to such operations."
    }
  },
  {
    "instruction": "Context: End-to-end encryption\n\n==Introduction==\nEnd-to-end encryption (E2EE)  is a system of communication where only the users communicating can read the messages. In principle, it prevents potential eavesdroppers \u2013 including telecom providers, Internet providers, malicious actors, and even the provider of the communication service \u2013 from being able to access the cryptographic keys needed to decrypt the conversation.End-to-end encryption is intended to prevent  data being read or secretly modified, other than by the true sender and recipient(s). The messages are encrypted by the sender but the third party does not have a means to decrypt them, and stores them encrypted. The recipients retrieve the encrypted data and decrypt it themselves.\nBecause no third parties can decipher the data being communicated or stored, for example, companies that provide end-to-end encryption are unable to hand over texts of their customers' messages to the authorities.In 2022, the UK's Information Commissioner's Office, the government body responsible for enforcing online data standards, stated that opposition to E2EE was misinformed and the debate too unbalanced, with too little focus on benefits, since E2EE \"helped keep children safe online\" and law enforcement access to stored data on servers was \"not the only way\" to find abusers.\n\n\n\n== E2EE and privacy ==\nIn many messaging systems, including email and many chat networks, messages pass through intermediaries and are stored by a third party, from which they are retrieved by the recipient. Even if the messages are encrypted, they are only encrypted 'in transit', and are thus accessible by the service provider, regardless of whether server-side disk encryption is used. Server-side disk encryption simply prevents unauthorized users from viewing this information. It does not prevent the company itself from viewing the information, as they have the key and can simply decrypt this data. \nThis allows the third party to provide search and other features, or to scan for illegal and unacceptable content, but also means they can be read and misused by anyone who has access to the stored messages on the third-party system, whether this is by design or via a backdoor. This can be seen as a concern in many cases where privacy is very important, such as businesses whose reputation depends on their ability to protect third party data, negotiations and communications that are important enough to have a risk of targeted 'hacking' or surveillance, and where sensitive subjects such as health, and information about minors are involved.\nIt is important to note that E2EE alone does not guarantee privacy or security. For example, data may be held unencrypted on the user's own device, or be accessible via their own app, if their login is compromised.\n\n== Etymology of the term ==\nThe term \"end-to-end encryption\" originally only meant that the communication is never decrypted during its transport from the sender to the receiver.\nFor example, around 2003, E2EE has been proposed as an additional layer of encryption for GSM or TETRA, in addition to the existing radio encryption protecting the communication between the mobile device and the network infrastructure. This has been standardized by SFPG for TETRA. Note that in TETRA E2EE, the keys are generated by a Key Management Centre (KMC) or a Key Management Facility (KMF), not by the communicating users.Later, around 2014, the meaning of \"end-to-end encryption\" started to evolve when WhatsApp encrypted a portion of its network, requiring that not only the communication stays encrypted during transport, but also that the provider of the communication service is not able to decrypt the communications either by having access to the private key, or by having the capability to undetectably inject an adversarial public key as part of a man-in-the-middle attack. This new meaning is now the widely accepted one.\n\n== Modern usage ==\nAs of 2016, typical server-based communications systems do not include end-to-end encryption. These systems can only guarantee the protection of communications between clients and servers, meaning that users have to trust the third parties who are running the servers with the sensitive content. End-to-end encryption is regarded as safer because it reduces the number of parties who might be able to interfere or break the encryption. In the case of instant messaging, users may use a third-party client or plugin to implement an end-to-end encryption scheme over an otherwise non-E2EE protocol.Some non-E2EE systems, such as Lavabit and Hushmail, have described themselves as offering \"end-to-end\" encryption when they did not. Other systems, such as Telegram and Google Allo, have been criticized for not enabling end-to-end encryption by default. Telegram did not enable end-to-end encryption by default on VoIP calls while users were using desktop software version, but that problem was fixed quickly. However, as of 2020, Telegram still features no end-to-end encryption by default, no end-to-end encryption for group chats, and no end-to-end encryption for its desktop clients.\nSome encrypted backup and file sharing services provide client-side encryption. The encryption they offer is here not referred to as end-to-end encryption, because the services are not meant for sharing messages between users. However, the term \"end-to-end encryption\" is sometimes incorrectly used to describe client-side encryption.\n\n== Challenges ==\n\n\n*** Man-in-the-middle attacks ***\nEnd-to-end encryption ensures that data is transferred securely between endpoints. But, rather than try to break the encryption, an eavesdropper may impersonate a message recipient (during key exchange or by substituting their public key for the recipient's), so that messages are encrypted with a key known to the attacker. After decrypting the message, the snoop can then encrypt it with a key that they share with the actual recipient, or their public key in case of asymmetric systems, and send the message on again to avoid detection. This is known as a man-in-the-middle attack (MITM).\n\n\n**** Authentication ****\nMost end-to-end encryption protocols include some form of endpoint authentication specifically to prevent MITM attacks. For example, one could rely on certification authorities or a web of trust. An alternative technique is to generate cryptographic hashes (fingerprints) based on the communicating users\u2019 public keys or shared secret keys. The parties compare their fingerprints using an outside (out-of-band) communication channel that guarantees integrity and authenticity of communication (but not necessarily secrecy), before starting their conversation. If the fingerprints match, there is in theory, no man in the middle.When displayed for human inspection, fingerprints usually use some form of Binary-to-text encoding. These strings are then formatted into groups of characters for readability. Some clients instead display a natural language representation of the fingerprint. As the approach consists of a one-to-one mapping between fingerprint blocks and words, there is no loss in entropy. The protocol may choose to display words in the user's native (system) language. This can, however, make cross-language comparisons prone to errors.In order to improve localization, some protocols have chosen to display fingerprints as base 10 strings instead of more error prone hexadecimal or natural language strings. An example of the base 10 fingerprint (called safety number in Signal and security code in WhatsApp) would be:\n\n 37345  35585  86758  07668\n 05805  48714  98975  19432\n 47272  72741  60915  64451\n\nOther applications such as Telegram, instead, encode fingerprints using emojis.\nModern messaging applications can also display fingerprints as QR codes that users can scan off each other's devices.\n\n\n*** Endpoint security ***\nThe end-to-end encryption paradigm does not directly address risks at the communications endpoints themselves. Each user's computer can still be hacked to steal his or her cryptographic key (to create a MITM attack) or simply read the recipients\u2019 decrypted messages both in real time and from log files. Even the most perfectly encrypted communication pipe is only as secure as the mailbox on the other end. Major attempts to increase endpoint security have been to isolate key generation, storage and cryptographic operations to a smart card such as Google's Project Vault. However, since plaintext input and output are still visible to the host system, malware can monitor conversations in real time. A more robust approach is to isolate all sensitive data to a fully air gapped computer. PGP has been recommended by experts for this purpose. However, as Bruce Schneier points out, Stuxnet developed by US and Israel successfully jumped air gap and reached Natanz nuclear plant's network in Iran. To deal with key exfiltration with malware, one approach is to split the Trusted Computing Base behind two unidirectionally connected computers that prevent either insertion of malware, or exfiltration of sensitive data with inserted malware.\n\n\n*** Backdoors ***\nA backdoor is usually a secret method of bypassing normal authentication or encryption in a computer system, a product, or an embedded device, etc. Companies may also willingly or unwillingly introduce backdoors to their software that help subvert key negotiation or bypass encryption altogether. In 2013, information leaked by Edward Snowden showed that Skype had a backdoor which allowed Microsoft to hand over their users' messages to the NSA despite the fact that those messages were officially end-to-end encrypted.Following terrorist attacks in San Bernardino in 2015 and Pensacola in 2019, the FBI requested backdoors to Apple's iPhone software. The company, however, refused to create a backdoor for the government, citing concern that such a tool could pose risk for its consumers\u2019 privacy.\n\n\n*** Compliance and regulatory requirements for content inspection ***\nWhile E2EE can offer privacy benefits that make it desirable in consumer-grade services, many businesses have to balance these benefits with their regulatory requirements. For example, many organizations are subject to mandates that require them to be able to decrypt any communication between their employees or between their employees and third parties.\nThis might be needed for archival purposes, for inspection by Data Loss Prevention (DLP) systems, for litigation-related eDiscovery or for detection of malware and other threats in the data streams. For this reason, some enterprise-focused communications and information protection systems might implement encryption in a way that ensures all transmissions are encrypted with the encryption being terminated at their internal systems (on-premises or cloud-based) so can have access to the information for inspection and processing.\nAnswer this question: What is the role of the service provider in E2EE?",
    "context": "",
    "output": "In E2EE, the service provider does not have the means to decrypt the messages, and stores them encrypted. The recipients retrieve the encrypted data and decrypt it themselves.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of the service provider in E2EE?",
      "answer": "In E2EE, the service provider does not have the means to decrypt the messages, and stores them encrypted. The recipients retrieve the encrypted data and decrypt it themselves.",
      "context": "End-to-end encryption\n\n==Introduction==\nEnd-to-end encryption (E2EE)  is a system of communication where only the users communicating can read the messages. In principle, it prevents potential eavesdroppers \u2013 including telecom providers, Internet providers, malicious actors, and even the provider of the communication service \u2013 from being able to access the cryptographic keys needed to decrypt the conversation.End-to-end encryption is intended to prevent  data being read or secretly modified, other than by the true sender and recipient(s). The messages are encrypted by the sender but the third party does not have a means to decrypt them, and stores them encrypted. The recipients retrieve the encrypted data and decrypt it themselves.\nBecause no third parties can decipher the data being communicated or stored, for example, companies that provide end-to-end encryption are unable to hand over texts of their customers' messages to the authorities.In 2022, the UK's Information Commissioner's Office, the government body responsible for enforcing online data standards, stated that opposition to E2EE was misinformed and the debate too unbalanced, with too little focus on benefits, since E2EE \"helped keep children safe online\" and law enforcement access to stored data on servers was \"not the only way\" to find abusers.\n\n\n\n== E2EE and privacy ==\nIn many messaging systems, including email and many chat networks, messages pass through intermediaries and are stored by a third party, from which they are retrieved by the recipient. Even if the messages are encrypted, they are only encrypted 'in transit', and are thus accessible by the service provider, regardless of whether server-side disk encryption is used. Server-side disk encryption simply prevents unauthorized users from viewing this information. It does not prevent the company itself from viewing the information, as they have the key and can simply decrypt this data. \nThis allows the third party to provide search and other features, or to scan for illegal and unacceptable content, but also means they can be read and misused by anyone who has access to the stored messages on the third-party system, whether this is by design or via a backdoor. This can be seen as a concern in many cases where privacy is very important, such as businesses whose reputation depends on their ability to protect third party data, negotiations and communications that are important enough to have a risk of targeted 'hacking' or surveillance, and where sensitive subjects such as health, and information about minors are involved.\nIt is important to note that E2EE alone does not guarantee privacy or security. For example, data may be held unencrypted on the user's own device, or be accessible via their own app, if their login is compromised.\n\n== Etymology of the term ==\nThe term \"end-to-end encryption\" originally only meant that the communication is never decrypted during its transport from the sender to the receiver.\nFor example, around 2003, E2EE has been proposed as an additional layer of encryption for GSM or TETRA, in addition to the existing radio encryption protecting the communication between the mobile device and the network infrastructure. This has been standardized by SFPG for TETRA. Note that in TETRA E2EE, the keys are generated by a Key Management Centre (KMC) or a Key Management Facility (KMF), not by the communicating users.Later, around 2014, the meaning of \"end-to-end encryption\" started to evolve when WhatsApp encrypted a portion of its network, requiring that not only the communication stays encrypted during transport, but also that the provider of the communication service is not able to decrypt the communications either by having access to the private key, or by having the capability to undetectably inject an adversarial public key as part of a man-in-the-middle attack. This new meaning is now the widely accepted one.\n\n== Modern usage ==\nAs of 2016, typical server-based communications systems do not include end-to-end encryption. These systems can only guarantee the protection of communications between clients and servers, meaning that users have to trust the third parties who are running the servers with the sensitive content. End-to-end encryption is regarded as safer because it reduces the number of parties who might be able to interfere or break the encryption. In the case of instant messaging, users may use a third-party client or plugin to implement an end-to-end encryption scheme over an otherwise non-E2EE protocol.Some non-E2EE systems, such as Lavabit and Hushmail, have described themselves as offering \"end-to-end\" encryption when they did not. Other systems, such as Telegram and Google Allo, have been criticized for not enabling end-to-end encryption by default. Telegram did not enable end-to-end encryption by default on VoIP calls while users were using desktop software version, but that problem was fixed quickly. However, as of 2020, Telegram still features no end-to-end encryption by default, no end-to-end encryption for group chats, and no end-to-end encryption for its desktop clients.\nSome encrypted backup and file sharing services provide client-side encryption. The encryption they offer is here not referred to as end-to-end encryption, because the services are not meant for sharing messages between users. However, the term \"end-to-end encryption\" is sometimes incorrectly used to describe client-side encryption.\n\n== Challenges ==\n\n\n*** Man-in-the-middle attacks ***\nEnd-to-end encryption ensures that data is transferred securely between endpoints. But, rather than try to break the encryption, an eavesdropper may impersonate a message recipient (during key exchange or by substituting their public key for the recipient's), so that messages are encrypted with a key known to the attacker. After decrypting the message, the snoop can then encrypt it with a key that they share with the actual recipient, or their public key in case of asymmetric systems, and send the message on again to avoid detection. This is known as a man-in-the-middle attack (MITM).\n\n\n**** Authentication ****\nMost end-to-end encryption protocols include some form of endpoint authentication specifically to prevent MITM attacks. For example, one could rely on certification authorities or a web of trust. An alternative technique is to generate cryptographic hashes (fingerprints) based on the communicating users\u2019 public keys or shared secret keys. The parties compare their fingerprints using an outside (out-of-band) communication channel that guarantees integrity and authenticity of communication (but not necessarily secrecy), before starting their conversation. If the fingerprints match, there is in theory, no man in the middle.When displayed for human inspection, fingerprints usually use some form of Binary-to-text encoding. These strings are then formatted into groups of characters for readability. Some clients instead display a natural language representation of the fingerprint. As the approach consists of a one-to-one mapping between fingerprint blocks and words, there is no loss in entropy. The protocol may choose to display words in the user's native (system) language. This can, however, make cross-language comparisons prone to errors.In order to improve localization, some protocols have chosen to display fingerprints as base 10 strings instead of more error prone hexadecimal or natural language strings. An example of the base 10 fingerprint (called safety number in Signal and security code in WhatsApp) would be:\n\n 37345  35585  86758  07668\n 05805  48714  98975  19432\n 47272  72741  60915  64451\n\nOther applications such as Telegram, instead, encode fingerprints using emojis.\nModern messaging applications can also display fingerprints as QR codes that users can scan off each other's devices.\n\n\n*** Endpoint security ***\nThe end-to-end encryption paradigm does not directly address risks at the communications endpoints themselves. Each user's computer can still be hacked to steal his or her cryptographic key (to create a MITM attack) or simply read the recipients\u2019 decrypted messages both in real time and from log files. Even the most perfectly encrypted communication pipe is only as secure as the mailbox on the other end. Major attempts to increase endpoint security have been to isolate key generation, storage and cryptographic operations to a smart card such as Google's Project Vault. However, since plaintext input and output are still visible to the host system, malware can monitor conversations in real time. A more robust approach is to isolate all sensitive data to a fully air gapped computer. PGP has been recommended by experts for this purpose. However, as Bruce Schneier points out, Stuxnet developed by US and Israel successfully jumped air gap and reached Natanz nuclear plant's network in Iran. To deal with key exfiltration with malware, one approach is to split the Trusted Computing Base behind two unidirectionally connected computers that prevent either insertion of malware, or exfiltration of sensitive data with inserted malware.\n\n\n*** Backdoors ***\nA backdoor is usually a secret method of bypassing normal authentication or encryption in a computer system, a product, or an embedded device, etc. Companies may also willingly or unwillingly introduce backdoors to their software that help subvert key negotiation or bypass encryption altogether. In 2013, information leaked by Edward Snowden showed that Skype had a backdoor which allowed Microsoft to hand over their users' messages to the NSA despite the fact that those messages were officially end-to-end encrypted.Following terrorist attacks in San Bernardino in 2015 and Pensacola in 2019, the FBI requested backdoors to Apple's iPhone software. The company, however, refused to create a backdoor for the government, citing concern that such a tool could pose risk for its consumers\u2019 privacy.\n\n\n*** Compliance and regulatory requirements for content inspection ***\nWhile E2EE can offer privacy benefits that make it desirable in consumer-grade services, many businesses have to balance these benefits with their regulatory requirements. For example, many organizations are subject to mandates that require them to be able to decrypt any communication between their employees or between their employees and third parties.\nThis might be needed for archival purposes, for inspection by Data Loss Prevention (DLP) systems, for litigation-related eDiscovery or for detection of malware and other threats in the data streams. For this reason, some enterprise-focused communications and information protection systems might implement encryption in a way that ensures all transmissions are encrypted with the encryption being terminated at their internal systems (on-premises or cloud-based) so can have access to the information for inspection and processing."
    }
  },
  {
    "instruction": "Write an answer to the following question: Which third-party platform did Keeper partner with to launch a public vulnerability disclosure program?",
    "context": "",
    "output": "Keeper launched a public vulnerability disclosure program in partnership with Bugcrowd.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Which third-party platform did Keeper partner with to launch a public vulnerability disclosure program?",
      "answer": "Keeper launched a public vulnerability disclosure program in partnership with Bugcrowd."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the role of the NICE 2.0 Framework in the CEH certification?",
    "context": "",
    "output": "The NICE 2.0 Framework ensures a systematic job role mapping in the CEH certification.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of the NICE 2.0 Framework in the CEH certification?",
      "answer": "The NICE 2.0 Framework ensures a systematic job role mapping in the CEH certification."
    }
  },
  {
    "instruction": "SpamBayes\n\n==Introduction==\nSpamBayes is a Bayesian spam filter written in Python which uses techniques laid out by Paul Graham in his essay \"A Plan for Spam\". It has subsequently been improved by Gary Robinson and Tim Peters, among others.\nThe most notable difference between a conventional Bayesian filter and the filter used by SpamBayes is that there are three classifications rather than two: spam, non-spam (called ham in SpamBayes), and unsure. The user trains a message as being either ham or spam; when filtering a message, the spam filters generate one score for ham and another for spam.\nIf the spam score is high and the ham score is low, the message will be classified as spam.\nIf the spam score is low and the ham score is high, the message will be classified as ham.\nIf the scores are both high or both low, the message will be classified as unsure.\nThis approach leads to a low number of false positives and false negatives, but it may result in a number of unsures which need a human decision.\n\n== Web filtering ==\nSome work has gone into applying SpamBayes to filter internet content via a proxy web server.\n\nQ: What is the role of the proxy web server in applying SpamBayes as a web filter?",
    "context": "",
    "output": "A: The proxy web server acts as an intermediary between the client and the internet content, filtering internet content using SpamBayes based on the predefined rules or policies.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of the proxy web server in applying SpamBayes as a web filter?",
      "answer": "The proxy web server acts as an intermediary between the client and the internet content, filtering internet content using SpamBayes based on the predefined rules or policies.",
      "context": "SpamBayes\n\n==Introduction==\nSpamBayes is a Bayesian spam filter written in Python which uses techniques laid out by Paul Graham in his essay \"A Plan for Spam\". It has subsequently been improved by Gary Robinson and Tim Peters, among others.\nThe most notable difference between a conventional Bayesian filter and the filter used by SpamBayes is that there are three classifications rather than two: spam, non-spam (called ham in SpamBayes), and unsure. The user trains a message as being either ham or spam; when filtering a message, the spam filters generate one score for ham and another for spam.\nIf the spam score is high and the ham score is low, the message will be classified as spam.\nIf the spam score is low and the ham score is high, the message will be classified as ham.\nIf the scores are both high or both low, the message will be classified as unsure.\nThis approach leads to a low number of false positives and false negatives, but it may result in a number of unsures which need a human decision.\n\n== Web filtering ==\nSome work has gone into applying SpamBayes to filter internet content via a proxy web server."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does JASBUG allow hackers to remotely take control of Windows devices?",
    "context": "",
    "output": "JASBUG allows hackers to remotely take control of Windows devices that connect to an Active Directory domain.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does JASBUG allow hackers to remotely take control of Windows devices?",
      "answer": "JASBUG allows hackers to remotely take control of Windows devices that connect to an Active Directory domain."
    }
  },
  {
    "instruction": "Write an answer to the following question: How can file processing and uploading vulnerabilities facilitate the delivery of web shells?",
    "context": "",
    "output": "File processing and uploading vulnerabilities can enable attackers to bypass intended file type restrictions, allowing them to upload malicious files (including web shells) to the web server. By exploiting these vulnerabilities, attackers can upload web shells disguised as legitimate files, which can then be executed on the server to grant the attacker remote access.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can file processing and uploading vulnerabilities facilitate the delivery of web shells?",
      "answer": "File processing and uploading vulnerabilities can enable attackers to bypass intended file type restrictions, allowing them to upload malicious files (including web shells) to the web server. By exploiting these vulnerabilities, attackers can upload web shells disguised as legitimate files, which can then be executed on the server to grant the attacker remote access."
    }
  },
  {
    "instruction": "Write an answer to the following question: How has WireGuard been extended by third-party programs and scripts?",
    "context": "",
    "output": "WireGuard has been extended by third-party programs and scripts to include features such as user-friendly management interfaces, logging, dynamic firewall updates, dynamic IP assignment, and LDAP integration.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How has WireGuard been extended by third-party programs and scripts?",
      "answer": "WireGuard has been extended by third-party programs and scripts to include features such as user-friendly management interfaces, logging, dynamic firewall updates, dynamic IP assignment, and LDAP integration."
    }
  },
  {
    "instruction": "Security information and event management\n\n==Introduction==\nSecurity information and event management (SIEM) is a field within the field of computer security, where software products and services combine security information management (SIM) and security event management (SEM). They provide real-time analysis of security alerts generated by applications and network hardware. Vendors sell SIEM as software, as appliances, or as managed services; these products are also used to log security data and generate reports for compliance purposes. The term and the initialism SIEM was coined by Mark Nicolett and Amrit Williams of Gartner in 2005.\n\n\n\n== Information assurance ==\nPublished in September 2006, NIST SP 800-92 Guide to Computer Security Log Management is the primary document used in the NIST Risk Management Framework for what should be auditable. While not definitive or exhaustive as there have been significant changes in technology since 2006, this guidance anticipated industry growth as the document is still relevant. This document pre-dates many modern SIEM technologies that are well known today, as evident by no reference to the term \"SIEM. NIST is not the only guidance for a regulatory mechanism for auditing and monitoring that are encouraged to use SIEM solutions instead of de-centralized individual host-based checks. NIST identifies several public and private entities with their logging guidance that may enforce its requirements; Federal Information Security Management Act of 2002 (FISMA), Gramm-Leach-Bliley Act (GLBA), Health Insurance Portability and Accountability Act of 1996 (HIPAA), Sarbanes-Oxley Act (SOX) of 2002, Payment Card Industry Data Security Standard (PCI DSS), and International Organization for Standardization (ISO) 27001. It is not uncommon for NIST documents to be referenced in public and private organizations.\n\nNIST SP 800-53 AU-2 Event Monitoring is a core security control for enabling logging functionality to support the information assurance process for all auditing throughout a system. AU-2 Event Monitoring also serves as a critical basis for continuous monitoring for information assurance and cybersecurity engineering efforts throughout a network. It is expected that the SIEM solution is used as a core tool or suite of tools to support this effort. Depending on the system categorization concerning the impact on the Confidentiality, Integrity, and Availability (CIA) of a system are generally five specific requirements needed to satisfy the base logging requirements of a federal system (AU-2, a-e). It is essential to understand the security control requirements about the SIEM infrastructure and operation. Below are the security control requirements for AU-2.The [Assignment: organization-defined...] is left blank to determine what is appropriate for its enterprise. Executive Order 14028 seeks to unify the inputs across all federal agencies.a.\u2003Identify the types of events that the system is capable of logging in support of the audit function: [Assignment: organization-defined event types that the system is capable of logging];\nb.\u2003Coordinate the event logging function with other organizational entities requiring audit-related information to guide and inform the selection criteria for events to be logged;\nc.\u2003Specify the following event types for logging within the system: [Assignment: organization-defined event types (subset of the event types defined in AU-2a.) along with the frequency of (or situation requiring) logging for each identified event type];\nd.\u2003Provide a rationale for why the event types selected for logging are deemed to be adequate to support after-the-fact investigations of incidents; and\n\ne.\u2003Review and update the event types selected for logging [Assignment: organization-defined frequency].Events on a system could include and are not limited to credential changes, failed access attempts, role base or attribute changes to accounts, token-based use, access attempts, and failures, etc. While logging every system action to the system is possible, it is often not advised based on the volume of logs and actionable security-relevant data. Organizations can use AU-2 a through e, as the basis to build from while adhering to other controls that may require or call out specific security auditing requirements in more granular detail.\nNIST SP 800-53 SI-4 System Monitoring is the security control that specifies the monitoring of the system. This monitoring is focused on monitoring systems that monitor the system. This can include hardware and software in unison to detect events and anomalies, malware, connections, and any other pertinent mechanism that is used to detect attacks or indicators of potential attacks.a.\u2003Monitor the system to detect:\n1.\u2003Attacks and indicators of potential attacks in accordance with the following monitoring objectives: [Assignment: organization-defined monitoring objectives]; and\n2.\u2003Unauthorized local, network, and remote connections;b.\u2003Identify unauthorized use of the system through the following techniques and methods: [Assignment: organization-defined techniques and methods];\nc.\u2003Invoke internal monitoring capabilities or deploy monitoring devices:\n\n1.\u2003Strategically within the system to collect organization-determined essential information; and\n2.\u2003At ad hoc locations within the system to track specific types of transactions of interest to the organization;d.\u2003Analyze detected events and anomalies;\ne.\u2003Adjust the level of system monitoring activity when there is a change in risk to organizational operations and assets, individuals, other organizations, or the Nation;\nf.\u2003Obtain legal opinion regarding system monitoring activities; and\n\ng.\u2003Provide [Assignment: organization-defined system monitoring information] to [Assignment: organization-defined personnel or roles] [Selection (one or more): as needed; [Assignment: organization-defined frequency]].NIST SP 800-53 RA-10 Threat Hunting is a new base security control added to NIST 800-53 with the latest Revision 5 edit and publication. Threat hunting is the proactive defense of a network by combining all security information and actively looking for threats. To execute the operation, the analysts and engineers need a repository of information, and a SIEM solution is often used as a hub because all system logs would typically be sent to this centralized location. A threat hunting team is not limited to this approach. However, the SIEM solution should provide significant amounts of security-relevant data.a.\u2003Establish and maintain a cyber threat hunting capability to:\n1.\u2003Search for indicators of compromise in organizational systems; and\n2.\u2003Detect, track, and disrupt threats that evade existing controls; and\nb.\u2003Employ the threat hunting capability [Assignment: organization-defined frequency].NIST SP 800-53 R5 and the brief descriptions of AU-2, SI-4, and RA-10 depict how individual controls are all used as critical elements of the event, alerting and monitoring via a SIEM. These controls, combined with other technical security controls provided by NIST, weave together an in-depth defense system. The assurance of the system security is enforced with various risk assessments and continuous monitoring - often enhanced or streamlined with a SIEM product used across entire cybersecurity teams. There are many more technical controls that outline specific items that must be monitored. The controls identified are a cursory overlook of controls directly related to the event and audit gathering functionality and use in a SIEM tool.\n\n== Terminology ==\nThe acronyms SEM, SIM and SIEM have sometimes been used interchangeably, but generally refer to the different primary focus of products:\n\nLog management: Focus on simple collection and storage of log messages and audit trails\nSecurity information management (SIM): Long-term storage as well as analysis and reporting of log data.\nSecurity event manager (SEM): Real-time monitoring, correlation of events, notifications and console views.\nSecurity information and event management (SIEM): Combines SIM and SEM and provides real-time analysis of security alerts generated by network hardware and applications.\nManaged Security Service: (MSS) or Managed Security Service Provider: (MSSP): The most common managed services appear to evolve around connectivity and bandwidth, network monitoring, security, virtualization, and disaster recovery.\nSecurity as a service (SECaaS): These security services often include authentication, anti-virus, anti-malware/spyware, intrusion detection, penetration testing and security event management, among others.In practice many products in this area will have a mix of these functions, so there will often be some overlap \u2013 and many commercial vendors also promote their own terminology. Oftentimes commercial vendors provide different combinations of these functionalities which tend to improve SIEM overall. Log management alone doesn't provide real-time insights on network security, SEM on its own won't provide complete data for deep threat analysis. When SEM and log management are combined, more information is available for SIEM to monitor.\nA key focus is to monitor and help manage user and service privileges, directory services and other system-configuration changes; as well as providing log auditing and review and incident response.\n\n== Capabilities ==\nData aggregation: Log management aggregates data from many sources, including networks, security, servers, databases, applications, providing the ability to consolidate monitored data to help avoid missing crucial events.\nCorrelation: Looks for common attributes and links events together into meaningful bundles. This technology provides the ability to perform a variety of correlation techniques to integrate different sources, in order to turn data into useful information. Correlation is typically a function of the Security Event Management portion of a full SIEM solution\nAlerting: The automated analysis of correlated events\nDashboards: Tools can take event data and turn it into informational charts to assist in seeing patterns, or identifying activity that is not forming a standard pattern.\nCompliance: Applications can be employed to automate the gathering of compliance data, producing reports that adapt to existing security, governance and auditing processes.\nRetention: Employing long-term storage of historical data to facilitate correlation of data over time, and to provide the retention necessary for compliance requirements. The Long term log data retention is critical in forensic investigations as it is unlikely that the discovery of a network breach will be at the time of the breach occurring.\nForensic analysis: The ability to search across logs on different nodes and time periods based on specific criteria. This mitigates having to aggregate log information in your head or having to search through thousands and thousands of logs.\n\n== Components ==\n\nSIEM architectures may vary by vendor; however, generally, essential components comprise the SIEM engine. The essential components of a SIEM are as follows:\nA data collector forwards selected audit logs from a host (agent based or host based log streaming into index and aggregation point) \nAn ingest and indexing point aggregation point for parsing, correlation, and data normalization \nA search node that is used for visualization, queries, reports, and alerts (analysis take place on a search node) A basic SIEM infrastructure is depicted in the image to the right.\n\n== Use cases ==\nComputer security researcher Chris Kubecka identified the following SIEM use cases, presented at the hacking conference 28C3 (Chaos Communication Congress).\nSIEM visibility and anomaly detection could help detect zero-days or polymorphic code. Primarily due to low rates of anti-virus detection against this type of rapidly changing malware.\nParsing, log normalization and categorization can occur automatically, regardless of the type of computer or network device, as long as it can send a log.\nVisualization with a SIEM using security events and log failures can aid in pattern detection.\nProtocol anomalies that can indicate a misconfiguration or a security issue can be identified with a SIEM using pattern detection, alerting, baseline and dashboards.\nSIEMS can detect covert, malicious communications and encrypted channels.\nCyberwarfare can be detected by SIEMs with accuracy, discovering both attackers and victims.\n\n== Correlation rules examples ==\nSIEM systems can have hundreds and thousands of correlation rules. Some of these are simple, and some are more complex. Once a correlation rule is triggered the system can take appropriate steps to mitigate a cyber attack. Usually, this includes sending a notification to a user and then possibly limiting or even shutting down the system. According to UTMStack, these are some of the most important ones.\n\n\n*** Brute Force Detection ***\nBrute force detection is relatively straightforward. Brute forcing relates to continually trying to guess a variable. It most commonly refers to someone trying to constantly guess your password - either manually or with a tool. However, it can refer to trying to guess URLs or important file locations on your system.\nAn automated brute force is easy to detect as someone trying to enter their password 60 times in a minute is impossible.\n\n\n*** Impossible Travel ***\nWhen a user logs in to a system, generally speaking, it creates a timestamp of the event. Alongside the time, the system may often record other useful information such as the device used, physical location, IP address, incorrect login attempts, etc. The more data is collected the more use can be gathered from it. For impossible travel, the system looks at the current and last login date/time and the difference between the recorded distances. If it deems it's not possible for this to happen, for example traveling hundreds of miles within a minute, then it will set off a warning.\nMany employees and users are now using VPN services which may obscure physical location. This should be taken into consideration when setting up such a rule.\n\n\n*** Excessive File Copying ***\nThe average user does not typically copy or move files on the system repeatedly. Thus, any excessive file copying on a system could be attributed to an attacker wanting to cause harm to an organization. Unfortunately, it's not as simple as stating someone has gained access to your network illegally and wants to steal confidential information. It could also be an employee looking to sell company information, or they could just want to take home some files for the weekend.\n\n\n*** DDoS Attack ***\nA DDoS (Distributed Denial of Service) Attack could cause significant damage to a company or organization. A DDoS attack can not only take a website offline, it can also make a system weaker. With suitable correlation rules in place, a SIEM should trigger an alert at the start of the attack so that the company can take the necessary precautionary measures to protect vital systems.\n\n\n*** File Integrity Change ***\nFile Integrity and Change Monitoring (FIM) is the process of monitoring the files on your system. Unexpected changes in your system files will trigger an alert as it's a likely indication of a cyber attack.\n\n== Models ==\nAlongside correlation rules, it's also possible for SIEM to have models. Models differ somewhat from correlation rules but if implemented correctly can be just as useful.  Instead of using a one-to-one correlation, a model requires a number of steps to happen in order to trigger an alert. This usually means a first-time rule followed by an anomalous behavior. This can be as simple as a user logging in from a different location than usual and then carrying out a large file transfer.\nThis can be extremely useful as a single event does not necessarily mean a compromise of an organization's servers or network, it could just be a team member working from a caf\u00e9 for a change in scenery.\n\n== Handling False Positives ==\nUnfortunately, false positives appear in all walks of life, and this holds true for SIEM.  All tools and systems have the possibility to produce a false-positive result. For example, too many failed login attempts can just be an employee forgetting their password and not someone trying to break into the system. It's important that for any triggered events the steps taken are justifiable and of an appropriate measure as you wouldn't want employees getting locked out for hours in such scenarios.\n\n== Alerting examples ==\nSome examples of customized rules to alert on event conditions involve user authentication rules, attacks detected and infections detected.\n\nWhat is the purpose of the ingest and indexing point in a SIEM system?",
    "context": "",
    "output": "The ingest and indexing point in a SIEM system is responsible for parsing, correlation, and data normalization of the collected logs. It aggregates log data from various sources and performs initial processing to make it easier to analyze and correlate events.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the purpose of the ingest and indexing point in a SIEM system?",
      "answer": "The ingest and indexing point in a SIEM system is responsible for parsing, correlation, and data normalization of the collected logs. It aggregates log data from various sources and performs initial processing to make it easier to analyze and correlate events.",
      "context": "Security information and event management\n\n==Introduction==\nSecurity information and event management (SIEM) is a field within the field of computer security, where software products and services combine security information management (SIM) and security event management (SEM). They provide real-time analysis of security alerts generated by applications and network hardware. Vendors sell SIEM as software, as appliances, or as managed services; these products are also used to log security data and generate reports for compliance purposes. The term and the initialism SIEM was coined by Mark Nicolett and Amrit Williams of Gartner in 2005.\n\n\n\n== Information assurance ==\nPublished in September 2006, NIST SP 800-92 Guide to Computer Security Log Management is the primary document used in the NIST Risk Management Framework for what should be auditable. While not definitive or exhaustive as there have been significant changes in technology since 2006, this guidance anticipated industry growth as the document is still relevant. This document pre-dates many modern SIEM technologies that are well known today, as evident by no reference to the term \"SIEM. NIST is not the only guidance for a regulatory mechanism for auditing and monitoring that are encouraged to use SIEM solutions instead of de-centralized individual host-based checks. NIST identifies several public and private entities with their logging guidance that may enforce its requirements; Federal Information Security Management Act of 2002 (FISMA), Gramm-Leach-Bliley Act (GLBA), Health Insurance Portability and Accountability Act of 1996 (HIPAA), Sarbanes-Oxley Act (SOX) of 2002, Payment Card Industry Data Security Standard (PCI DSS), and International Organization for Standardization (ISO) 27001. It is not uncommon for NIST documents to be referenced in public and private organizations.\n\nNIST SP 800-53 AU-2 Event Monitoring is a core security control for enabling logging functionality to support the information assurance process for all auditing throughout a system. AU-2 Event Monitoring also serves as a critical basis for continuous monitoring for information assurance and cybersecurity engineering efforts throughout a network. It is expected that the SIEM solution is used as a core tool or suite of tools to support this effort. Depending on the system categorization concerning the impact on the Confidentiality, Integrity, and Availability (CIA) of a system are generally five specific requirements needed to satisfy the base logging requirements of a federal system (AU-2, a-e). It is essential to understand the security control requirements about the SIEM infrastructure and operation. Below are the security control requirements for AU-2.The [Assignment: organization-defined...] is left blank to determine what is appropriate for its enterprise. Executive Order 14028 seeks to unify the inputs across all federal agencies.a.\u2003Identify the types of events that the system is capable of logging in support of the audit function: [Assignment: organization-defined event types that the system is capable of logging];\nb.\u2003Coordinate the event logging function with other organizational entities requiring audit-related information to guide and inform the selection criteria for events to be logged;\nc.\u2003Specify the following event types for logging within the system: [Assignment: organization-defined event types (subset of the event types defined in AU-2a.) along with the frequency of (or situation requiring) logging for each identified event type];\nd.\u2003Provide a rationale for why the event types selected for logging are deemed to be adequate to support after-the-fact investigations of incidents; and\n\ne.\u2003Review and update the event types selected for logging [Assignment: organization-defined frequency].Events on a system could include and are not limited to credential changes, failed access attempts, role base or attribute changes to accounts, token-based use, access attempts, and failures, etc. While logging every system action to the system is possible, it is often not advised based on the volume of logs and actionable security-relevant data. Organizations can use AU-2 a through e, as the basis to build from while adhering to other controls that may require or call out specific security auditing requirements in more granular detail.\nNIST SP 800-53 SI-4 System Monitoring is the security control that specifies the monitoring of the system. This monitoring is focused on monitoring systems that monitor the system. This can include hardware and software in unison to detect events and anomalies, malware, connections, and any other pertinent mechanism that is used to detect attacks or indicators of potential attacks.a.\u2003Monitor the system to detect:\n1.\u2003Attacks and indicators of potential attacks in accordance with the following monitoring objectives: [Assignment: organization-defined monitoring objectives]; and\n2.\u2003Unauthorized local, network, and remote connections;b.\u2003Identify unauthorized use of the system through the following techniques and methods: [Assignment: organization-defined techniques and methods];\nc.\u2003Invoke internal monitoring capabilities or deploy monitoring devices:\n\n1.\u2003Strategically within the system to collect organization-determined essential information; and\n2.\u2003At ad hoc locations within the system to track specific types of transactions of interest to the organization;d.\u2003Analyze detected events and anomalies;\ne.\u2003Adjust the level of system monitoring activity when there is a change in risk to organizational operations and assets, individuals, other organizations, or the Nation;\nf.\u2003Obtain legal opinion regarding system monitoring activities; and\n\ng.\u2003Provide [Assignment: organization-defined system monitoring information] to [Assignment: organization-defined personnel or roles] [Selection (one or more): as needed; [Assignment: organization-defined frequency]].NIST SP 800-53 RA-10 Threat Hunting is a new base security control added to NIST 800-53 with the latest Revision 5 edit and publication. Threat hunting is the proactive defense of a network by combining all security information and actively looking for threats. To execute the operation, the analysts and engineers need a repository of information, and a SIEM solution is often used as a hub because all system logs would typically be sent to this centralized location. A threat hunting team is not limited to this approach. However, the SIEM solution should provide significant amounts of security-relevant data.a.\u2003Establish and maintain a cyber threat hunting capability to:\n1.\u2003Search for indicators of compromise in organizational systems; and\n2.\u2003Detect, track, and disrupt threats that evade existing controls; and\nb.\u2003Employ the threat hunting capability [Assignment: organization-defined frequency].NIST SP 800-53 R5 and the brief descriptions of AU-2, SI-4, and RA-10 depict how individual controls are all used as critical elements of the event, alerting and monitoring via a SIEM. These controls, combined with other technical security controls provided by NIST, weave together an in-depth defense system. The assurance of the system security is enforced with various risk assessments and continuous monitoring - often enhanced or streamlined with a SIEM product used across entire cybersecurity teams. There are many more technical controls that outline specific items that must be monitored. The controls identified are a cursory overlook of controls directly related to the event and audit gathering functionality and use in a SIEM tool.\n\n== Terminology ==\nThe acronyms SEM, SIM and SIEM have sometimes been used interchangeably, but generally refer to the different primary focus of products:\n\nLog management: Focus on simple collection and storage of log messages and audit trails\nSecurity information management (SIM): Long-term storage as well as analysis and reporting of log data.\nSecurity event manager (SEM): Real-time monitoring, correlation of events, notifications and console views.\nSecurity information and event management (SIEM): Combines SIM and SEM and provides real-time analysis of security alerts generated by network hardware and applications.\nManaged Security Service: (MSS) or Managed Security Service Provider: (MSSP): The most common managed services appear to evolve around connectivity and bandwidth, network monitoring, security, virtualization, and disaster recovery.\nSecurity as a service (SECaaS): These security services often include authentication, anti-virus, anti-malware/spyware, intrusion detection, penetration testing and security event management, among others.In practice many products in this area will have a mix of these functions, so there will often be some overlap \u2013 and many commercial vendors also promote their own terminology. Oftentimes commercial vendors provide different combinations of these functionalities which tend to improve SIEM overall. Log management alone doesn't provide real-time insights on network security, SEM on its own won't provide complete data for deep threat analysis. When SEM and log management are combined, more information is available for SIEM to monitor.\nA key focus is to monitor and help manage user and service privileges, directory services and other system-configuration changes; as well as providing log auditing and review and incident response.\n\n== Capabilities ==\nData aggregation: Log management aggregates data from many sources, including networks, security, servers, databases, applications, providing the ability to consolidate monitored data to help avoid missing crucial events.\nCorrelation: Looks for common attributes and links events together into meaningful bundles. This technology provides the ability to perform a variety of correlation techniques to integrate different sources, in order to turn data into useful information. Correlation is typically a function of the Security Event Management portion of a full SIEM solution\nAlerting: The automated analysis of correlated events\nDashboards: Tools can take event data and turn it into informational charts to assist in seeing patterns, or identifying activity that is not forming a standard pattern.\nCompliance: Applications can be employed to automate the gathering of compliance data, producing reports that adapt to existing security, governance and auditing processes.\nRetention: Employing long-term storage of historical data to facilitate correlation of data over time, and to provide the retention necessary for compliance requirements. The Long term log data retention is critical in forensic investigations as it is unlikely that the discovery of a network breach will be at the time of the breach occurring.\nForensic analysis: The ability to search across logs on different nodes and time periods based on specific criteria. This mitigates having to aggregate log information in your head or having to search through thousands and thousands of logs.\n\n== Components ==\n\nSIEM architectures may vary by vendor; however, generally, essential components comprise the SIEM engine. The essential components of a SIEM are as follows:\nA data collector forwards selected audit logs from a host (agent based or host based log streaming into index and aggregation point) \nAn ingest and indexing point aggregation point for parsing, correlation, and data normalization \nA search node that is used for visualization, queries, reports, and alerts (analysis take place on a search node) A basic SIEM infrastructure is depicted in the image to the right.\n\n== Use cases ==\nComputer security researcher Chris Kubecka identified the following SIEM use cases, presented at the hacking conference 28C3 (Chaos Communication Congress).\nSIEM visibility and anomaly detection could help detect zero-days or polymorphic code. Primarily due to low rates of anti-virus detection against this type of rapidly changing malware.\nParsing, log normalization and categorization can occur automatically, regardless of the type of computer or network device, as long as it can send a log.\nVisualization with a SIEM using security events and log failures can aid in pattern detection.\nProtocol anomalies that can indicate a misconfiguration or a security issue can be identified with a SIEM using pattern detection, alerting, baseline and dashboards.\nSIEMS can detect covert, malicious communications and encrypted channels.\nCyberwarfare can be detected by SIEMs with accuracy, discovering both attackers and victims.\n\n== Correlation rules examples ==\nSIEM systems can have hundreds and thousands of correlation rules. Some of these are simple, and some are more complex. Once a correlation rule is triggered the system can take appropriate steps to mitigate a cyber attack. Usually, this includes sending a notification to a user and then possibly limiting or even shutting down the system. According to UTMStack, these are some of the most important ones.\n\n\n*** Brute Force Detection ***\nBrute force detection is relatively straightforward. Brute forcing relates to continually trying to guess a variable. It most commonly refers to someone trying to constantly guess your password - either manually or with a tool. However, it can refer to trying to guess URLs or important file locations on your system.\nAn automated brute force is easy to detect as someone trying to enter their password 60 times in a minute is impossible.\n\n\n*** Impossible Travel ***\nWhen a user logs in to a system, generally speaking, it creates a timestamp of the event. Alongside the time, the system may often record other useful information such as the device used, physical location, IP address, incorrect login attempts, etc. The more data is collected the more use can be gathered from it. For impossible travel, the system looks at the current and last login date/time and the difference between the recorded distances. If it deems it's not possible for this to happen, for example traveling hundreds of miles within a minute, then it will set off a warning.\nMany employees and users are now using VPN services which may obscure physical location. This should be taken into consideration when setting up such a rule.\n\n\n*** Excessive File Copying ***\nThe average user does not typically copy or move files on the system repeatedly. Thus, any excessive file copying on a system could be attributed to an attacker wanting to cause harm to an organization. Unfortunately, it's not as simple as stating someone has gained access to your network illegally and wants to steal confidential information. It could also be an employee looking to sell company information, or they could just want to take home some files for the weekend.\n\n\n*** DDoS Attack ***\nA DDoS (Distributed Denial of Service) Attack could cause significant damage to a company or organization. A DDoS attack can not only take a website offline, it can also make a system weaker. With suitable correlation rules in place, a SIEM should trigger an alert at the start of the attack so that the company can take the necessary precautionary measures to protect vital systems.\n\n\n*** File Integrity Change ***\nFile Integrity and Change Monitoring (FIM) is the process of monitoring the files on your system. Unexpected changes in your system files will trigger an alert as it's a likely indication of a cyber attack.\n\n== Models ==\nAlongside correlation rules, it's also possible for SIEM to have models. Models differ somewhat from correlation rules but if implemented correctly can be just as useful.  Instead of using a one-to-one correlation, a model requires a number of steps to happen in order to trigger an alert. This usually means a first-time rule followed by an anomalous behavior. This can be as simple as a user logging in from a different location than usual and then carrying out a large file transfer.\nThis can be extremely useful as a single event does not necessarily mean a compromise of an organization's servers or network, it could just be a team member working from a caf\u00e9 for a change in scenery.\n\n== Handling False Positives ==\nUnfortunately, false positives appear in all walks of life, and this holds true for SIEM.  All tools and systems have the possibility to produce a false-positive result. For example, too many failed login attempts can just be an employee forgetting their password and not someone trying to break into the system. It's important that for any triggered events the steps taken are justifiable and of an appropriate measure as you wouldn't want employees getting locked out for hours in such scenarios.\n\n== Alerting examples ==\nSome examples of customized rules to alert on event conditions involve user authentication rules, attacks detected and infections detected."
    }
  },
  {
    "instruction": "SQL Slammer\n\n==Introduction==\nSQL Slammer is a 2003 computer worm that caused a denial of service on some Internet hosts and dramatically slowed general Internet traffic and crashing routers all around the world. It spread rapidly, infecting most of its 75,000 victims within 10 minutes.\nThe program exploited a buffer overflow bug in Microsoft's SQL Server and Desktop Engine database products. Although the MS02-039 patch had been released six months earlier, many organizations had not yet applied it.\nThe most infected regions were Europe, North America, and Asia (including East Asia and southern Asia (India) etc. ).\n\n\n\n== Technical details ==\nThe worm was based on proof of concept code demonstrated at the Black Hat Briefings by David Litchfield, who had initially discovered the buffer overflow vulnerability that the worm exploited. It is a small piece of code that does little other than generate random IP addresses and send itself out to those addresses. If a selected address happens to belong to a host that is running an unpatched copy of Microsoft SQL Server Resolution Service listening on UDP port 1434, the host immediately becomes infected and begins spraying the Internet with more copies of the worm program.\nHome PCs are generally not vulnerable to this worm unless they have MSDE installed. The worm is so small that it does not contain code to write itself to disk, so it only stays in memory, and it is easy to remove. For example, Symantec provides a free of charge removal utility, or it can even be removed by restarting SQL Server (although the machine would likely be reinfected immediately).\nThe worm was made possible by a software security vulnerability in SQL Server first reported by Microsoft on 24 July 2002. A patch had been available from Microsoft for six months prior to the worm's launch, but many installations had not been patched \u2013 including many at Microsoft.The worm began to be noticed early on 25 January 2003 as it slowed systems worldwide. The slowdown was caused by the collapse of numerous routers under the burden of extremely high bombardment traffic from infected servers. Normally, when traffic is too high for routers to handle, the routers are supposed to delay or temporarily stop network traffic. Instead, some routers crashed (became unusable), and the \"neighbour\" routers would notice that these routers had stopped and should not be contacted (aka \"removed from the routing table\"). Routers started sending notices to this effect to other routers they knew about. The flood of routing table update notices caused some additional routers to fail, compounding the problem. Eventually the crashed routers' maintainers restarted them, causing them to announce their status, leading to another wave of routing table updates. Soon a significant portion of Internet bandwidth was consumed by routers communicating with each other to update their routing tables, and ordinary data traffic slowed or in some cases stopped altogether. Because the SQL Slammer worm was so small in size, sometimes it was able to get through when legitimate traffic was not.\nTwo key aspects contributed to SQL Slammer's rapid propagation. The worm infected new hosts over the sessionless UDP protocol, and the entire worm (only 376 bytes) fits inside a single packet. As a result, each infected host could simply \"fire and forget\" packets as rapidly as possible.\n\nWhat was the role of unpatched copies of Microsoft SQL Server Resolution Service in the spread of the SQL Slammer worm?",
    "context": "",
    "output": "Unpatched copies of Microsoft SQL Server Resolution Service listening on UDP port 1434 were vulnerable to the SQL Slammer worm. If a selected IP address belonged to a host with this service, the host would become infected and begin spraying the Internet with more copies of the worm program.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was the role of unpatched copies of Microsoft SQL Server Resolution Service in the spread of the SQL Slammer worm?",
      "answer": "Unpatched copies of Microsoft SQL Server Resolution Service listening on UDP port 1434 were vulnerable to the SQL Slammer worm. If a selected IP address belonged to a host with this service, the host would become infected and begin spraying the Internet with more copies of the worm program.",
      "context": "SQL Slammer\n\n==Introduction==\nSQL Slammer is a 2003 computer worm that caused a denial of service on some Internet hosts and dramatically slowed general Internet traffic and crashing routers all around the world. It spread rapidly, infecting most of its 75,000 victims within 10 minutes.\nThe program exploited a buffer overflow bug in Microsoft's SQL Server and Desktop Engine database products. Although the MS02-039 patch had been released six months earlier, many organizations had not yet applied it.\nThe most infected regions were Europe, North America, and Asia (including East Asia and southern Asia (India) etc. ).\n\n\n\n== Technical details ==\nThe worm was based on proof of concept code demonstrated at the Black Hat Briefings by David Litchfield, who had initially discovered the buffer overflow vulnerability that the worm exploited. It is a small piece of code that does little other than generate random IP addresses and send itself out to those addresses. If a selected address happens to belong to a host that is running an unpatched copy of Microsoft SQL Server Resolution Service listening on UDP port 1434, the host immediately becomes infected and begins spraying the Internet with more copies of the worm program.\nHome PCs are generally not vulnerable to this worm unless they have MSDE installed. The worm is so small that it does not contain code to write itself to disk, so it only stays in memory, and it is easy to remove. For example, Symantec provides a free of charge removal utility, or it can even be removed by restarting SQL Server (although the machine would likely be reinfected immediately).\nThe worm was made possible by a software security vulnerability in SQL Server first reported by Microsoft on 24 July 2002. A patch had been available from Microsoft for six months prior to the worm's launch, but many installations had not been patched \u2013 including many at Microsoft.The worm began to be noticed early on 25 January 2003 as it slowed systems worldwide. The slowdown was caused by the collapse of numerous routers under the burden of extremely high bombardment traffic from infected servers. Normally, when traffic is too high for routers to handle, the routers are supposed to delay or temporarily stop network traffic. Instead, some routers crashed (became unusable), and the \"neighbour\" routers would notice that these routers had stopped and should not be contacted (aka \"removed from the routing table\"). Routers started sending notices to this effect to other routers they knew about. The flood of routing table update notices caused some additional routers to fail, compounding the problem. Eventually the crashed routers' maintainers restarted them, causing them to announce their status, leading to another wave of routing table updates. Soon a significant portion of Internet bandwidth was consumed by routers communicating with each other to update their routing tables, and ordinary data traffic slowed or in some cases stopped altogether. Because the SQL Slammer worm was so small in size, sometimes it was able to get through when legitimate traffic was not.\nTwo key aspects contributed to SQL Slammer's rapid propagation. The worm infected new hosts over the sessionless UDP protocol, and the entire worm (only 376 bytes) fits inside a single packet. As a result, each infected host could simply \"fire and forget\" packets as rapidly as possible."
    }
  },
  {
    "instruction": "Chaotic cryptology\n\n==Introduction==\nChaotic cryptology is the application of the mathematical chaos theory to the practice of the cryptography, the study or techniques used to privately and securely transmit information with the presence of a third-party or adversary. Since first being investigated by Robert Matthews in 1989, the use of chaos in cryptography has attracted much interest. However, long-standing concerns about its security and implementation speed continue to limit its implementation.Chaotic cryptology consists of two opposite processes: Chaotic cryptography and Chaotic cryptanalysis. Cryptography refers to encrypting information for secure transmission, whereas cryptanalysis refers to decrypting and deciphering encoded encrypted messages.\nIn order to use chaos theory efficiently in cryptography, the chaotic maps are implemented such that the entropy generated by the map can produce required Confusion and diffusion. Properties in chaotic systems and cryptographic primitives share unique characteristics that allow for the chaotic systems to be applied to cryptography. If chaotic parameters, as well as cryptographic keys, can be mapped symmetrically or mapped to produce acceptable and functional outputs, it will make it next to impossible for an adversary to find the outputs without any knowledge of the initial values. Since chaotic maps in a real life scenario require a set of numbers that are limited, they may, in fact, have no real purpose in a cryptosystem if the chaotic behavior can be predicted. \nOne of the most important issues for any cryptographic primitive is the security of the system. However, in numerous cases, chaos-based cryptography algorithms are proved insecure. The main issue in many of the cryptanalyzed algorithms is the inadequacy of the chaotic maps implemented in the system.\n\n\n\n== Types ==\nChaos-based cryptography has been divided into two major groups: \n\nSymmetric chaos cryptography, where the same secret key is used by sender and receiver.\nAsymmetric chaos cryptography, where one key of the cryptosystem is public. Some of the few proposed systems  have been broken.The majority of chaos-based cryptographic algorithms are symmetric. Many use discrete chaotic maps in their process.\n\n== Applications ==\n\n\n*** Image encryption ***\nBourbakis and Alexopoulos in 1991 proposed supposedly the earliest fully intended digital image encryption scheme which was based on SCAN language. Later on, with the emergence of chaos-based cryptography hundreds of new image encryption algorithms, all with the aim of improving the security of digital images were proposed. However, there were three main aspects of the design of an image encryption that was usually modified in different algorithms (chaotic map, application of the map and structure of algorithm). The initial and perhaps most crucial point was the chaotic map applied in the design of the algorithms. The speed of the cryptosystem is always an important parameter in the evaluation of the efficiency of a cryptography algorithm, therefore, the designers were initially interested in using simple chaotic maps such as tent map, and the logistic map. However, in 2006 and 2007, the new image encryption algorithms based on more sophisticated chaotic maps proved that application of chaotic map with higher dimension could improve the quality and security of the cryptosystems.\n\n\n*** Hash function ***\nChaotic behavior can generate hash functions.\n\n\n*** Random number generation ***\nThe unpredictable behavior of the chaotic maps can be used in the generation of random numbers. Some of the earliest chaos-based random number generators tried to directly generate random numbers from the logistic map.\n\nAnswer this question based on the above context: How can chaotic behavior be used in random number generation?",
    "context": "",
    "output": "Chaotic behavior can be used in random number generation by exploiting the unpredictable and complex properties of chaotic systems.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can chaotic behavior be used in random number generation?",
      "answer": "Chaotic behavior can be used in random number generation by exploiting the unpredictable and complex properties of chaotic systems.",
      "context": "Chaotic cryptology\n\n==Introduction==\nChaotic cryptology is the application of the mathematical chaos theory to the practice of the cryptography, the study or techniques used to privately and securely transmit information with the presence of a third-party or adversary. Since first being investigated by Robert Matthews in 1989, the use of chaos in cryptography has attracted much interest. However, long-standing concerns about its security and implementation speed continue to limit its implementation.Chaotic cryptology consists of two opposite processes: Chaotic cryptography and Chaotic cryptanalysis. Cryptography refers to encrypting information for secure transmission, whereas cryptanalysis refers to decrypting and deciphering encoded encrypted messages.\nIn order to use chaos theory efficiently in cryptography, the chaotic maps are implemented such that the entropy generated by the map can produce required Confusion and diffusion. Properties in chaotic systems and cryptographic primitives share unique characteristics that allow for the chaotic systems to be applied to cryptography. If chaotic parameters, as well as cryptographic keys, can be mapped symmetrically or mapped to produce acceptable and functional outputs, it will make it next to impossible for an adversary to find the outputs without any knowledge of the initial values. Since chaotic maps in a real life scenario require a set of numbers that are limited, they may, in fact, have no real purpose in a cryptosystem if the chaotic behavior can be predicted. \nOne of the most important issues for any cryptographic primitive is the security of the system. However, in numerous cases, chaos-based cryptography algorithms are proved insecure. The main issue in many of the cryptanalyzed algorithms is the inadequacy of the chaotic maps implemented in the system.\n\n\n\n== Types ==\nChaos-based cryptography has been divided into two major groups: \n\nSymmetric chaos cryptography, where the same secret key is used by sender and receiver.\nAsymmetric chaos cryptography, where one key of the cryptosystem is public. Some of the few proposed systems  have been broken.The majority of chaos-based cryptographic algorithms are symmetric. Many use discrete chaotic maps in their process.\n\n== Applications ==\n\n\n*** Image encryption ***\nBourbakis and Alexopoulos in 1991 proposed supposedly the earliest fully intended digital image encryption scheme which was based on SCAN language. Later on, with the emergence of chaos-based cryptography hundreds of new image encryption algorithms, all with the aim of improving the security of digital images were proposed. However, there were three main aspects of the design of an image encryption that was usually modified in different algorithms (chaotic map, application of the map and structure of algorithm). The initial and perhaps most crucial point was the chaotic map applied in the design of the algorithms. The speed of the cryptosystem is always an important parameter in the evaluation of the efficiency of a cryptography algorithm, therefore, the designers were initially interested in using simple chaotic maps such as tent map, and the logistic map. However, in 2006 and 2007, the new image encryption algorithms based on more sophisticated chaotic maps proved that application of chaotic map with higher dimension could improve the quality and security of the cryptosystems.\n\n\n*** Hash function ***\nChaotic behavior can generate hash functions.\n\n\n*** Random number generation ***\nThe unpredictable behavior of the chaotic maps can be used in the generation of random numbers. Some of the earliest chaos-based random number generators tried to directly generate random numbers from the logistic map."
    }
  },
  {
    "instruction": "Context: Computer security model\n\n==Introduction==\nA computer security model is a scheme for specifying and enforcing security policies. A security model may be founded upon a formal model of access rights, a model of computation, a model of distributed computing, or no particular theoretical grounding at all. A computer security model is implemented through a computer security policy.\nFor a more complete list of available articles on specific security models, see Category:Computer security models.\n\n\n\n== Selected topics ==\nAccess control list (ACL)\nAttribute-based access control (ABAC)\nBell\u2013LaPadula model\nBiba model\nBrewer and Nash model\nCapability-based security\nClark-Wilson model\nContext-based access control (CBAC)\nGraham-Denning model\nHarrison-Ruzzo-Ullman (HRU)\nHigh-water mark (computer security)\nLattice-based access control (LBAC)\nMandatory access control (MAC)\nMulti-level security (MLS)\nNon-interference (security)\nObject-capability model\nProtection ring\nRole-based access control (RBAC)\nTake-grant protection model\nDiscretionary access control (DAC)\n\nQuestion: What is the Brewer and Nash model and how does it address security concerns in a distributed system?\n\nAnswer:",
    "context": "",
    "output": "The Brewer and Nash model, also known as the Chinese Wall model, is a security model designed to prevent conflicts of interest in a distributed system. It achieves this by ensuring that users who have access to sensitive information in one part of the system cannot access related information in another part, thus preventing any potential conflicts of interest.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the Brewer and Nash model and how does it address security concerns in a distributed system?",
      "answer": "The Brewer and Nash model, also known as the Chinese Wall model, is a security model designed to prevent conflicts of interest in a distributed system. It achieves this by ensuring that users who have access to sensitive information in one part of the system cannot access related information in another part, thus preventing any potential conflicts of interest.",
      "context": "Computer security model\n\n==Introduction==\nA computer security model is a scheme for specifying and enforcing security policies. A security model may be founded upon a formal model of access rights, a model of computation, a model of distributed computing, or no particular theoretical grounding at all. A computer security model is implemented through a computer security policy.\nFor a more complete list of available articles on specific security models, see Category:Computer security models.\n\n\n\n== Selected topics ==\nAccess control list (ACL)\nAttribute-based access control (ABAC)\nBell\u2013LaPadula model\nBiba model\nBrewer and Nash model\nCapability-based security\nClark-Wilson model\nContext-based access control (CBAC)\nGraham-Denning model\nHarrison-Ruzzo-Ullman (HRU)\nHigh-water mark (computer security)\nLattice-based access control (LBAC)\nMandatory access control (MAC)\nMulti-level security (MLS)\nNon-interference (security)\nObject-capability model\nProtection ring\nRole-based access control (RBAC)\nTake-grant protection model\nDiscretionary access control (DAC)"
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the language in which the Mbed TLS core SSL library is written?",
    "context": "",
    "output": "The Mbed TLS core SSL library is written in the C programming language.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the language in which the Mbed TLS core SSL library is written?",
      "answer": "The Mbed TLS core SSL library is written in the C programming language."
    }
  },
  {
    "instruction": "Write an answer to the following question: When was the Cutwail botnet founded?",
    "context": "",
    "output": "The Cutwail botnet was founded around 2007.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "When was the Cutwail botnet founded?",
      "answer": "The Cutwail botnet was founded around 2007."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the difference between a block cipher and a stream cipher in symmetric-key cryptography?",
    "context": "",
    "output": "A block cipher enciphers input in blocks of plaintext, as opposed to individual characters which is the input form used by a stream cipher.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the difference between a block cipher and a stream cipher in symmetric-key cryptography?",
      "answer": "A block cipher enciphers input in blocks of plaintext, as opposed to individual characters which is the input form used by a stream cipher."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are some of the firewall rule-set appliance-UTM filtering features, and how do they differ from advanced features?",
    "context": "",
    "output": "Firewall rule-set appliance-UTM filtering features refer to the basic firewall capabilities provided by firewall appliances, such as packet filtering, stateful inspection, and application-level gateway. Advanced features, on the other hand, include more sophisticated functionalities such as intrusion prevention, content filtering, and anti-malware protection.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are some of the firewall rule-set appliance-UTM filtering features, and how do they differ from advanced features?",
      "answer": "Firewall rule-set appliance-UTM filtering features refer to the basic firewall capabilities provided by firewall appliances, such as packet filtering, stateful inspection, and application-level gateway. Advanced features, on the other hand, include more sophisticated functionalities such as intrusion prevention, content filtering, and anti-malware protection."
    }
  },
  {
    "instruction": "Write an answer to the following question: How can the use of fixed-sized ICMP packets prevent ICMP tunneling?",
    "context": "",
    "output": "Limiting the size of ICMP packets can impede or eliminate ICMP tunneling behavior, as the standard defined by RFC 792 allows for an arbitrary data length for any type 0 (echo reply) or 8 (echo message) ICMP packets.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can the use of fixed-sized ICMP packets prevent ICMP tunneling?",
      "answer": "Limiting the size of ICMP packets can impede or eliminate ICMP tunneling behavior, as the standard defined by RFC 792 allows for an arbitrary data length for any type 0 (echo reply) or 8 (echo message) ICMP packets."
    }
  },
  {
    "instruction": "Write an answer to the following question: What was the response of the Telecommunications Regulatory Commission of Sri Lanka to the first cyberattack in February 2021?",
    "context": "",
    "output": "The Telecommunications Regulatory Commission of Sri Lanka tweeted regarding the first cyberattack in February 2021 as a public alert.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was the response of the Telecommunications Regulatory Commission of Sri Lanka to the first cyberattack in February 2021?",
      "answer": "The Telecommunications Regulatory Commission of Sri Lanka tweeted regarding the first cyberattack in February 2021 as a public alert."
    }
  },
  {
    "instruction": "Write an answer to the following question: How is the value of m decoded from the 3-bit encoding in the SYN cookie?",
    "context": "",
    "output": "The value of m is decoded from the 3-bit encoding in the SYN cookie by performing a decoding operation on the 3-bit value.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How is the value of m decoded from the 3-bit encoding in the SYN cookie?",
      "answer": "The value of m is decoded from the 3-bit encoding in the SYN cookie by performing a decoding operation on the 3-bit value."
    }
  },
  {
    "instruction": "Write an answer to the following question: How do DAST tools perform automated reviews of web applications?",
    "context": "",
    "output": "DAST tools facilitate the automated review of a web application by looking for a wide variety of vulnerabilities, such as input/output validation, specific application problems, and server configuration mistakes. They can detect vulnerabilities of the finalized release candidate versions prior to shipping, simulate a malicious user by attacking and probing, and scan year-round to be constantly searching for vulnerabilities.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do DAST tools perform automated reviews of web applications?",
      "answer": "DAST tools facilitate the automated review of a web application by looking for a wide variety of vulnerabilities, such as input/output validation, specific application problems, and server configuration mistakes. They can detect vulnerabilities of the finalized release candidate versions prior to shipping, simulate a malicious user by attacking and probing, and scan year-round to be constantly searching for vulnerabilities."
    }
  },
  {
    "instruction": "Context: Oracle Identity Management\n\n==Introduction==\nOracle Identity Management, a software suite marketed by Oracle Corporation, provides identity and access management (IAM) technologies.\nThe name of the software suite closely resembles the name of one of its components, Oracle Identity Manager.\n\n\n\n== Components ==\n\n== Sun rebranding ==\nAfter Oracle acquired Sun Microsystems, they re-branded a number of products that overlapped in function. (See table below.)  The re-branding, and Oracle's commitment to ongoing support and maintenance of these products were revealed by Hasan Rizvi, Senior Vice President of Oracle Fusion Middleware in an Oracle and Sun Identity Management Strategy webcast in 2010.\n\n== Other information ==\nOriginally, in the 10g and earlier versions, the Java-based portions of the suite ran mainly on OC4J, although some components (e.g. OIM) supported other J2EE appservers. For the 11g version, Oracle Corporation ported the OC4J-based components to WebLogic.\nAs of November  2008 the software was undergoing Common Criteria evaluation process.In March 2005 Oracle acquired Oblix and incorporated their web access control software into Oracle Identity Management.\nAnswer this question: When did the Oracle Identity Management software begin the Common Criteria evaluation process?",
    "context": "",
    "output": "As of November 2008, the Oracle Identity Management software was undergoing Common Criteria evaluation process.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "When did the Oracle Identity Management software begin the Common Criteria evaluation process?",
      "answer": "As of November 2008, the Oracle Identity Management software was undergoing Common Criteria evaluation process.",
      "context": "Oracle Identity Management\n\n==Introduction==\nOracle Identity Management, a software suite marketed by Oracle Corporation, provides identity and access management (IAM) technologies.\nThe name of the software suite closely resembles the name of one of its components, Oracle Identity Manager.\n\n\n\n== Components ==\n\n== Sun rebranding ==\nAfter Oracle acquired Sun Microsystems, they re-branded a number of products that overlapped in function. (See table below.)  The re-branding, and Oracle's commitment to ongoing support and maintenance of these products were revealed by Hasan Rizvi, Senior Vice President of Oracle Fusion Middleware in an Oracle and Sun Identity Management Strategy webcast in 2010.\n\n== Other information ==\nOriginally, in the 10g and earlier versions, the Java-based portions of the suite ran mainly on OC4J, although some components (e.g. OIM) supported other J2EE appservers. For the 11g version, Oracle Corporation ported the OC4J-based components to WebLogic.\nAs of November  2008 the software was undergoing Common Criteria evaluation process.In March 2005 Oracle acquired Oblix and incorporated their web access control software into Oracle Identity Management."
    }
  },
  {
    "instruction": "Write an answer to the following question: Which IT Security firm made a statement about the passwords containing a number of email addresses from Gmail, AOL, Yahoo, and more such websites?",
    "context": "",
    "output": "TrustedSec.net made a statement about the passwords containing a number of email addresses from Gmail, AOL, Yahoo, and more such websites.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Which IT Security firm made a statement about the passwords containing a number of email addresses from Gmail, AOL, Yahoo, and more such websites?",
      "answer": "TrustedSec.net made a statement about the passwords containing a number of email addresses from Gmail, AOL, Yahoo, and more such websites."
    }
  },
  {
    "instruction": "Answer based on context:\n\nPhone hacking\n\n==Introduction==\nPhone hacking is the practice of exploring a mobile device often using computer exploits to analyze everything from the lowest memory and central processing unit levels up to the highest file system and process levels. Modern open source tooling has become fairly sophisticated as to be able to \"hook\" into individual functions within any running App on an unlocked device and allow deep inspection and modification of their functions.\nPhone hacking is a large branch of computer security that includes studying various situations exactly how attackers use security exploits to gain some level of access to a mobile device in a variety of situations and presumed access levels.\nThe term came to prominence during the News International phone hacking scandal, in which it was alleged (and in some cases proved in court) that the British tabloid newspaper the News of the World had been involved in the interception of voicemail messages of the British Royal Family, other public figures, and a murdered schoolgirl named Milly Dowler.\n\n\n\n== Victims of phone hacking ==\nAlthough any mobile phone users may be targeted, \"for those who are famous, rich or powerful or whose prize is important enough (for whatever reason) to devote time and resources to make a concerted attack, it is usually more common, there are real risks to face.\"\n\n== Techniques ==\n\n\n*** Voicemail hacking ***\n\nThe unauthorized remote access to voicemail systems, such as exposed by the News International phone hacking scandal, is possible because of weaknesses in the implementations of these systems by telcos.Mobile phone voicemail messages may be accessed on a landline telephone with the entry of a personal identification number (PIN). Reporters for News International would call the number of an individual's mobile phone, wait to be moved to voicemail, and then guess the PIN, which was often set at a simple default such as 0000 or 1234.Even where the default PIN is not known, social engineering can be used to reset the voicemail PIN code to the default by impersonating the owner of the phone with a call to a call centre. During the mid-2000s, calls originating from the handset registered to a voicemail account would be put straight through to voicemail without the need of a PIN.  A hacker could use caller ID spoofing to impersonate a target's handset caller ID and thereby gain access to the associated voicemail without a PIN.Following controversies over phone hacking and criticism of mobile service providers who allowed access to voicemail without a PIN, many mobile phone companies have strengthened the default security of their systems so that remote access to voicemail messages and other phone settings can no longer be achieved even via a default PIN. For example, AT&T announced in August 2011 that all new wireless subscribers would be required to enter a PIN when checking their voicemail, even when checking it from their own phones. To encourage password strength, some companies now disallow the use of consecutive or repeat digits in voicemail PINs.\n\n\n*** Handsets ***\nAn analysis of user-selected PIN codes suggested that ten numbers represent 15% of all iPhone passcodes, with \"1234\" and \"0000\" being the most common, with years of birth and graduation also being common choices.  Even if a four-digit PIN is randomly selected, the key space is very small (\n  \n    \n      \n        \n          10\n          \n            4\n          \n        \n      \n    \n    {\\displaystyle 10^{4}}\n   or 10,000 possibilities), making PINs significantly easier to brute force than most passwords; someone with physical access to a handset secured with a PIN can therefore feasibly determine the PIN in a short time.Mobile phone microphones can be activated remotely by security agencies or telcos, without any need for physical access, as long as the battery has not been removed. This \"roving bug\" feature has been used by law enforcement agencies and intelligence services to listen in on nearby conversations.Other techniques for phone hacking include tricking a mobile phone user into downloading malware which monitors activity on the phone. Bluesnarfing is an unauthorized access to a phone via Bluetooth.\n\n\n*** Other ***\nThere are flaws in the implementation of the GSM encryption algorithm that allow passive interception.  The equipment needed is available to government agencies or can be built from freely available parts.In December 2011, German researcher Karsten Nohl revealed that it was possible to hack into mobile phone voice and text messages on many networks with free decryption software available on the Internet. He blamed the mobile phone companies for relying on outdated encryption techniques in the 2G system, and said that the problem could be fixed very easily.\n\n== Legality ==\nPhone hacking, [2] being a form of surveillance, is illegal in many countries unless it is carried out as lawful interception by a government agency. In the News International phone hacking scandal, private investigator Glenn Mulcaire was found to have violated the Regulation of Investigatory Powers Act 2000. He was sentenced to six months in prison in January 2007. Renewed controversy over the phone-hacking claims led to the closure of the News of the World in July 2011.In December 2010, the Truth in Caller ID Act was signed into United States law, making it illegal \"to cause any caller identification service to knowingly transmit misleading or inaccurate caller identification information with the intent to defraud, cause harm, or wrongfully obtain anything of value.\"\n\nWhat are some steps mobile phone companies have taken to strengthen the default security of their voicemail systems?",
    "context": "",
    "output": "In response to controversies over phone hacking, many mobile phone companies have strengthened the default security of their voicemail systems. This includes requiring a PIN for remote access, disallowing the use of consecutive or repeat digits in voicemail PINs, and implementing stronger encryption algorithms.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are some steps mobile phone companies have taken to strengthen the default security of their voicemail systems?",
      "answer": "In response to controversies over phone hacking, many mobile phone companies have strengthened the default security of their voicemail systems. This includes requiring a PIN for remote access, disallowing the use of consecutive or repeat digits in voicemail PINs, and implementing stronger encryption algorithms.",
      "context": "Phone hacking\n\n==Introduction==\nPhone hacking is the practice of exploring a mobile device often using computer exploits to analyze everything from the lowest memory and central processing unit levels up to the highest file system and process levels. Modern open source tooling has become fairly sophisticated as to be able to \"hook\" into individual functions within any running App on an unlocked device and allow deep inspection and modification of their functions.\nPhone hacking is a large branch of computer security that includes studying various situations exactly how attackers use security exploits to gain some level of access to a mobile device in a variety of situations and presumed access levels.\nThe term came to prominence during the News International phone hacking scandal, in which it was alleged (and in some cases proved in court) that the British tabloid newspaper the News of the World had been involved in the interception of voicemail messages of the British Royal Family, other public figures, and a murdered schoolgirl named Milly Dowler.\n\n\n\n== Victims of phone hacking ==\nAlthough any mobile phone users may be targeted, \"for those who are famous, rich or powerful or whose prize is important enough (for whatever reason) to devote time and resources to make a concerted attack, it is usually more common, there are real risks to face.\"\n\n== Techniques ==\n\n\n*** Voicemail hacking ***\n\nThe unauthorized remote access to voicemail systems, such as exposed by the News International phone hacking scandal, is possible because of weaknesses in the implementations of these systems by telcos.Mobile phone voicemail messages may be accessed on a landline telephone with the entry of a personal identification number (PIN). Reporters for News International would call the number of an individual's mobile phone, wait to be moved to voicemail, and then guess the PIN, which was often set at a simple default such as 0000 or 1234.Even where the default PIN is not known, social engineering can be used to reset the voicemail PIN code to the default by impersonating the owner of the phone with a call to a call centre. During the mid-2000s, calls originating from the handset registered to a voicemail account would be put straight through to voicemail without the need of a PIN.  A hacker could use caller ID spoofing to impersonate a target's handset caller ID and thereby gain access to the associated voicemail without a PIN.Following controversies over phone hacking and criticism of mobile service providers who allowed access to voicemail without a PIN, many mobile phone companies have strengthened the default security of their systems so that remote access to voicemail messages and other phone settings can no longer be achieved even via a default PIN. For example, AT&T announced in August 2011 that all new wireless subscribers would be required to enter a PIN when checking their voicemail, even when checking it from their own phones. To encourage password strength, some companies now disallow the use of consecutive or repeat digits in voicemail PINs.\n\n\n*** Handsets ***\nAn analysis of user-selected PIN codes suggested that ten numbers represent 15% of all iPhone passcodes, with \"1234\" and \"0000\" being the most common, with years of birth and graduation also being common choices.  Even if a four-digit PIN is randomly selected, the key space is very small (\n  \n    \n      \n        \n          10\n          \n            4\n          \n        \n      \n    \n    {\\displaystyle 10^{4}}\n   or 10,000 possibilities), making PINs significantly easier to brute force than most passwords; someone with physical access to a handset secured with a PIN can therefore feasibly determine the PIN in a short time.Mobile phone microphones can be activated remotely by security agencies or telcos, without any need for physical access, as long as the battery has not been removed. This \"roving bug\" feature has been used by law enforcement agencies and intelligence services to listen in on nearby conversations.Other techniques for phone hacking include tricking a mobile phone user into downloading malware which monitors activity on the phone. Bluesnarfing is an unauthorized access to a phone via Bluetooth.\n\n\n*** Other ***\nThere are flaws in the implementation of the GSM encryption algorithm that allow passive interception.  The equipment needed is available to government agencies or can be built from freely available parts.In December 2011, German researcher Karsten Nohl revealed that it was possible to hack into mobile phone voice and text messages on many networks with free decryption software available on the Internet. He blamed the mobile phone companies for relying on outdated encryption techniques in the 2G system, and said that the problem could be fixed very easily.\n\n== Legality ==\nPhone hacking, [2] being a form of surveillance, is illegal in many countries unless it is carried out as lawful interception by a government agency. In the News International phone hacking scandal, private investigator Glenn Mulcaire was found to have violated the Regulation of Investigatory Powers Act 2000. He was sentenced to six months in prison in January 2007. Renewed controversy over the phone-hacking claims led to the closure of the News of the World in July 2011.In December 2010, the Truth in Caller ID Act was signed into United States law, making it illegal \"to cause any caller identification service to knowingly transmit misleading or inaccurate caller identification information with the intent to defraud, cause harm, or wrongfully obtain anything of value.\""
    }
  },
  {
    "instruction": "Write an answer to the following question: How does Amazon VPC allow users to connect to other users' VPCs?",
    "context": "",
    "output": "Amazon VPC allows users to connect to other users' VPCs by routing traffic from one VPC to another VPC using private IP addresses. This enables users to communicate as if they were on the same network.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does Amazon VPC allow users to connect to other users' VPCs?",
      "answer": "Amazon VPC allows users to connect to other users' VPCs by routing traffic from one VPC to another VPC using private IP addresses. This enables users to communicate as if they were on the same network."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is MEDJACK.3 and why is it considered to have additional sophistication?",
    "context": "",
    "output": "MEDJACK.3 is a variant of medical device hijacking that is considered to have additional sophistication. It is designed to search for older, more vulnerable operating systems only found embedded within medical devices. Furthermore, it has the ability to hide from sandboxes and other defense tools until it is in a safe (non-VM) environment.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is MEDJACK.3 and why is it considered to have additional sophistication?",
      "answer": "MEDJACK.3 is a variant of medical device hijacking that is considered to have additional sophistication. It is designed to search for older, more vulnerable operating systems only found embedded within medical devices. Furthermore, it has the ability to hide from sandboxes and other defense tools until it is in a safe (non-VM) environment."
    }
  },
  {
    "instruction": "Write an answer to the following question: How can organizations detect a Turla infection?",
    "context": "",
    "output": "Organizations can detect a Turla infection by monitoring their networks and systems for unusual activity, such as unexpected network connections, unusual login attempts, or the presence of unknown or suspicious files. They can also use intrusion detection and prevention systems, antivirus and anti-malware software, and other security tools to detect and block Turla and other threats.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can organizations detect a Turla infection?",
      "answer": "Organizations can detect a Turla infection by monitoring their networks and systems for unusual activity, such as unexpected network connections, unusual login attempts, or the presence of unknown or suspicious files. They can also use intrusion detection and prevention systems, antivirus and anti-malware software, and other security tools to detect and block Turla and other threats."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the concept of a trusted path or trusted channel prevent interception or tampering of sensitive data during electronic signatures?",
    "context": "",
    "output": "A trusted path protects data from the user and a security component, while a trusted channel protects data between security component and other information resources. In the context of electronic signatures, the trusted path is used to secure the communication of sensitive data, such as a PIN, between the user and a smart card. The trusted channel, on the other hand, is used to secure the communication of data between the smart card and other information resources, such as a file being read and sent for signature.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the concept of a trusted path or trusted channel prevent interception or tampering of sensitive data during electronic signatures?",
      "answer": "A trusted path protects data from the user and a security component, while a trusted channel protects data between security component and other information resources. In the context of electronic signatures, the trusted path is used to secure the communication of sensitive data, such as a PIN, between the user and a smart card. The trusted channel, on the other hand, is used to secure the communication of data between the smart card and other information resources, such as a file being read and sent for signature."
    }
  },
  {
    "instruction": "Army Signal Command Cybernetic Security Unit\n\n==Introduction==\nThe Army Signal Command Cybernetic Security Unit (Italian: Reparto Sicurezza Cibernetica del Comando Trasmissioni dell\u2019Esercito) is a cyber warfare unit of the Italian Army.\n\n\n\n== Mission ==\nThe Cybernetic Security Unit performs:\nCyber defence, together with the Task Force C4 of Theater;\nInformation research, in support of G2/J2 cells;\nCyber command staff and forensic operations in support of personnel, future operations and logistics cells, for planning cybernetic military operations and traditional military operations with effects in cyberspace;\nOther Cyber operations, according to the assigned tasks and missions.The Cybernetic Security Unit is tasked with performing cyber operations related to the defence of IT networks and Command-and-Control systems, Operational Technology, for the protection of critical infrastructures and platforms and weapon systems and Disruptive Technology.The Cybernetic Security Unit operates under the Network Operations Command (a joint command) alongside the Joint Telecommunications School. The Cybernetic Security Unit personnel also operates within both the cyber-deployed operational units and the staff of the supported Command.\n\n== Organisation ==\nAccording to Defence Undersecretary Angelo Tofalo, the Army Signal Command Cybernetic Security Unit is framed under the command of the Signals Commander. The Unit, at the battalion level, consists of two Cybernetic Security Companies and one Training and Innovation Section.\n\n== Emblem ==\nThe coat of arms of the Army Signal Command Cybernetic Security Unit depicts Janus Bifrons.The badge is in enameled metal, in the shape of a Samnite shield, with a silver-blue edge. In the middle, on a light blue background, Janus (parted per pale) is charged: in the first partition, there is the human forehead in cornflower blue colour, and in the second, the cybernetic forehead is covered by dark blue electronic circuit tracks. The 5-pointed gold star appears at the base of Janus.All the elements of the badge are placed on a light blue background, a symbol of communication and an emblem of loyalty. The other elements that make up the badge are represented through shades of the same blue, while the score that represents the cybernetic front of the Janus is covered with veins similar to traces of an electronic printed circuit, a symbol of the high technological level of the Unit.\n\nQ: What does the coat of arms of the Cybernetic Security Unit depict?",
    "context": "",
    "output": "A: The coat of arms of the Cybernetic Security Unit depicts Janus Bifrons, a symbol of communication and loyalty.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What does the coat of arms of the Cybernetic Security Unit depict?",
      "answer": "The coat of arms of the Cybernetic Security Unit depicts Janus Bifrons, a symbol of communication and loyalty.",
      "context": "Army Signal Command Cybernetic Security Unit\n\n==Introduction==\nThe Army Signal Command Cybernetic Security Unit (Italian: Reparto Sicurezza Cibernetica del Comando Trasmissioni dell\u2019Esercito) is a cyber warfare unit of the Italian Army.\n\n\n\n== Mission ==\nThe Cybernetic Security Unit performs:\nCyber defence, together with the Task Force C4 of Theater;\nInformation research, in support of G2/J2 cells;\nCyber command staff and forensic operations in support of personnel, future operations and logistics cells, for planning cybernetic military operations and traditional military operations with effects in cyberspace;\nOther Cyber operations, according to the assigned tasks and missions.The Cybernetic Security Unit is tasked with performing cyber operations related to the defence of IT networks and Command-and-Control systems, Operational Technology, for the protection of critical infrastructures and platforms and weapon systems and Disruptive Technology.The Cybernetic Security Unit operates under the Network Operations Command (a joint command) alongside the Joint Telecommunications School. The Cybernetic Security Unit personnel also operates within both the cyber-deployed operational units and the staff of the supported Command.\n\n== Organisation ==\nAccording to Defence Undersecretary Angelo Tofalo, the Army Signal Command Cybernetic Security Unit is framed under the command of the Signals Commander. The Unit, at the battalion level, consists of two Cybernetic Security Companies and one Training and Innovation Section.\n\n== Emblem ==\nThe coat of arms of the Army Signal Command Cybernetic Security Unit depicts Janus Bifrons.The badge is in enameled metal, in the shape of a Samnite shield, with a silver-blue edge. In the middle, on a light blue background, Janus (parted per pale) is charged: in the first partition, there is the human forehead in cornflower blue colour, and in the second, the cybernetic forehead is covered by dark blue electronic circuit tracks. The 5-pointed gold star appears at the base of Janus.All the elements of the badge are placed on a light blue background, a symbol of communication and an emblem of loyalty. The other elements that make up the badge are represented through shades of the same blue, while the score that represents the cybernetic front of the Janus is covered with veins similar to traces of an electronic printed circuit, a symbol of the high technological level of the Unit."
    }
  },
  {
    "instruction": "Write an answer to the following question: How was code signing invented and by whom?",
    "context": "",
    "output": "Code signing was invented in 1995 by Michael Doyle as part of the Eolas WebWish browser plug-in, which enabled the use of public-key cryptography to sign downloadable Web app program code using a secret key.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How was code signing invented and by whom?",
      "answer": "Code signing was invented in 1995 by Michael Doyle as part of the Eolas WebWish browser plug-in, which enabled the use of public-key cryptography to sign downloadable Web app program code using a secret key."
    }
  },
  {
    "instruction": "National Industrial Security Program\n\n==Introduction==\nThe National Industrial Security Program, or NISP, is the nominal authority in the United States for managing the needs of private industry to access classified information.The NISP was established in 1993 by Executive Order 12829.  The National Security Council nominally sets policy for the NISP, while the Director of the Information Security Oversight Office is nominally the authority for implementation.  Under the ISOO, the Secretary of Defense is nominally the Executive Agent, but the NISP recognizes four different Cognizant Security Agencies, all of which have equal authority: the Department of Defense, the Department of Energy, the Central Intelligence Agency, and the Nuclear Regulatory Commission.Defense Counterintelligence and Security Agency administers the NISP on behalf of the Department of Defense and 34 other federal agencies.\n\n== NISP Operating Manual (DoD 5220.22-M) ==\nA major component of the NISP is the NISP Operating Manual, also called NISPOM, or DoD  5220.22-M. The NISPOM establishes the standard procedures and requirements for all government contractors, with regards to classified information. As of 2017, the current NISPOM edition is dated 28 Feb 2006.  Chapters and selected sections of this edition are:\nChapter 1 \u2013 General Provisions and Requirements\nChapter 2 \u2013 Security Clearances\nSection 1 \u2013 Facility Clearances\nSection 2 \u2013 Personnel Security Clearances\nSection 3 \u2013 Foreign Ownership, Control, or Influence (FOCI)\nChapter 3 \u2013 Security Training and Briefings\nChapter 4 \u2013 Classification and Marking\nChapter 5 \u2013 Safeguarding Classified Information\nChapter 6 \u2013 Visits and Meetings\nChapter 7 \u2013 Subcontracting\nChapter 8 \u2013 Information System Security\nChapter 9 \u2013 Special Requirements\nSection 1 \u2013 RD and FRD\nSection 2 \u2013 DoD Critical Nuclear Weapon Design Information (CNWDI)\nSection 3 \u2013 Intelligence Information\nSection 4 \u2013 Communication Security (COMSEC)\nChapter 10 \u2013 International Security Requirements\nChapter 11 \u2013 Miscellaneous Information\nSection 1 \u2013 TEMPEST\nSection 2 \u2013 Defense Technical Information Center (DTIC)\nSection 3 \u2013 Independent Research and Development (IR&D) Efforts\nAppendices\n\n\n*** Data sanitization ***\nDoD 5220.22-M is sometimes cited as a standard for sanitization to counter data remanence.  The NISPOM actually covers the entire field of government\u2013industrial security, of which data sanitization is a very small part (about two paragraphs in a 141-page document). Furthermore, the NISPOM does not actually specify any particular method.  Standards for sanitization are left up to the Cognizant Security Authority.  The Defense Security Service provides a Clearing and Sanitization Matrix (C&SM) which does specify methods.  As of the June 2007 edition of the DSS C&SM, overwriting is no longer acceptable for sanitization of magnetic media; only degaussing or physical destruction is acceptable.\n\nWhat year is the current NISPOM edition dated?",
    "context": "",
    "output": "The current NISPOM edition is dated February 28, 2006.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What year is the current NISPOM edition dated?",
      "answer": "The current NISPOM edition is dated February 28, 2006.",
      "context": "National Industrial Security Program\n\n==Introduction==\nThe National Industrial Security Program, or NISP, is the nominal authority in the United States for managing the needs of private industry to access classified information.The NISP was established in 1993 by Executive Order 12829.  The National Security Council nominally sets policy for the NISP, while the Director of the Information Security Oversight Office is nominally the authority for implementation.  Under the ISOO, the Secretary of Defense is nominally the Executive Agent, but the NISP recognizes four different Cognizant Security Agencies, all of which have equal authority: the Department of Defense, the Department of Energy, the Central Intelligence Agency, and the Nuclear Regulatory Commission.Defense Counterintelligence and Security Agency administers the NISP on behalf of the Department of Defense and 34 other federal agencies.\n\n== NISP Operating Manual (DoD 5220.22-M) ==\nA major component of the NISP is the NISP Operating Manual, also called NISPOM, or DoD  5220.22-M. The NISPOM establishes the standard procedures and requirements for all government contractors, with regards to classified information. As of 2017, the current NISPOM edition is dated 28 Feb 2006.  Chapters and selected sections of this edition are:\nChapter 1 \u2013 General Provisions and Requirements\nChapter 2 \u2013 Security Clearances\nSection 1 \u2013 Facility Clearances\nSection 2 \u2013 Personnel Security Clearances\nSection 3 \u2013 Foreign Ownership, Control, or Influence (FOCI)\nChapter 3 \u2013 Security Training and Briefings\nChapter 4 \u2013 Classification and Marking\nChapter 5 \u2013 Safeguarding Classified Information\nChapter 6 \u2013 Visits and Meetings\nChapter 7 \u2013 Subcontracting\nChapter 8 \u2013 Information System Security\nChapter 9 \u2013 Special Requirements\nSection 1 \u2013 RD and FRD\nSection 2 \u2013 DoD Critical Nuclear Weapon Design Information (CNWDI)\nSection 3 \u2013 Intelligence Information\nSection 4 \u2013 Communication Security (COMSEC)\nChapter 10 \u2013 International Security Requirements\nChapter 11 \u2013 Miscellaneous Information\nSection 1 \u2013 TEMPEST\nSection 2 \u2013 Defense Technical Information Center (DTIC)\nSection 3 \u2013 Independent Research and Development (IR&D) Efforts\nAppendices\n\n\n*** Data sanitization ***\nDoD 5220.22-M is sometimes cited as a standard for sanitization to counter data remanence.  The NISPOM actually covers the entire field of government\u2013industrial security, of which data sanitization is a very small part (about two paragraphs in a 141-page document). Furthermore, the NISPOM does not actually specify any particular method.  Standards for sanitization are left up to the Cognizant Security Authority.  The Defense Security Service provides a Clearing and Sanitization Matrix (C&SM) which does specify methods.  As of the June 2007 edition of the DSS C&SM, overwriting is no longer acceptable for sanitization of magnetic media; only degaussing or physical destruction is acceptable."
    }
  },
  {
    "instruction": "Write an answer to the following question: Who was the source of the emails leaked by Wikileaks?",
    "context": "",
    "output": "The emails leaked by Wikileaks were stolen by one or more hackers operating under the pseudonym \"Guccifer 2.0\" who are alleged to be Russian intelligence agency hackers.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Who was the source of the emails leaked by Wikileaks?",
      "answer": "The emails leaked by Wikileaks were stolen by one or more hackers operating under the pseudonym \"Guccifer 2.0\" who are alleged to be Russian intelligence agency hackers."
    }
  },
  {
    "instruction": "Passwordless authentication\n\n==Introduction==\nPasswordless authentication is an authentication method in which a user can log in to a computer system without the entering (and having to remember) a password or any other knowledge-based secret. In most common implementations users are asked to enter their public identifier (username, phone number, email address etc.) and then complete the authentication process by providing a secure proof of identity through a registered device or token.\nPasswordless authentication methods typically rely on public-key cryptography infrastructure where the public key is provided during registration to the authenticating service (remote server, application or website) while the private key is kept on a user\u2019s device (PC, smartphone or an external security token) and can be accessed only by providing a biometric signature or another authentication factor which is not knowledge-based. \nThese factors classically fall into two categories: \n\nOwnership factors (\u201cSomething the user has\u201d) such as a cellular phone, OTP token, smart card or a hardware token.\nInherence factors (\u201cSomething the user is\u201d) like fingerprints, retinal scans, face or voice recognition and other biometric identifiers.Some designs might also accept a combination of other factors such as geo-location, network address, behavioral patterns and gestures, as long as no memorized passwords are involved.\nPasswordless authentication is sometimes confused with multi-factor authentication (MFA), since both use a wide variety of authentication factors, but while MFA is often used as an added layer of security on top of password-based authentication, passwordless authentication does not require a memorized secret and usually uses just one highly secure factor to authenticate identity, making it faster and simpler for users.\n\"Passwordless MFA\" is the term used when both approaches are employed, and the authentication flow is both passwordless and uses multiple factors, providing the highest security level when implemented correctly.\n\n\n\n== Mechanism ==\nA user must first register with a system before their identity can be verified. A passwordless registration flow may include the following steps:\nRegistration request: When a user attempts to register with a website, the server sends a registration request to the user's device.\nAuthentication factor selection: When the user's device receives the registration request, it sets up a method for authenticating the user.  For example, the device may use biometrics like a fingerprint scanner or facial recognition for user identification.\nKey generation: The user's device generates a public/private key pair and sends the public key to the server for future verification.Once they have registered, a user can log in to the system via the following process:\n\nAuthentication challenge: The server sends an authentication to the user's device when the user attempts to log into the site.\nUser authentication: The user proves their identity to their device using the biometric scanner, unlocking their private key.\nChallenge response: The user's device digitally signs a response to the authentication challenge with the user's private key.\nResponse validation: The server uses the device's public key to verify the digital signature and provides access to the user's account.\n\n== Benefits and drawbacks ==\nProponents point out several unique benefits over other authentication methods:\n\nGreater security \u2013 passwords are known to be a weak point in computer systems (due to reuse, sharing, cracking, spraying etc.) and are regarded a top attack vector responsible for a huge percentage of security breaches.\nBetter user experience \u2013 Not only users aren\u2019t required to remember complicated password and comply with different security policies, they are also not required to periodically renew passwords.\nReduced IT costs \u2013 since no password storage and management is needed IT teams are no longer burdened by setting password policies, detecting leaks, resetting forgotten passwords, and complying with password storage regulation.\nBetter visibility of credential use \u2013 since credentials are tied to a specific device or inherent user attribute, they can't be massively used and access management becomes more tight.\nScalability \u2013 managing multiple logins without additional password fatigue or complicated registration.While others point out operational and cost-related disadvantages:\n\nImplementation costs \u2013 Although it is accepted that passwordless authentication leads to savings in the long term, deployment costs are currently a hindering factor for many potential users. Cost is associated with the need to deploy an authentication mechanism on an existing user directory and sometimes the additional hardware deployed to users (e.g. OTPs or security keys).\nTraining and expertise needed \u2013 while most password management systems are built similarly and have been used for many years, passwordless authentication requires adaptation from both IT teams and end users.\nSingle point of failure \u2013 particularly implementations using OTP or push notifications to cellular device applications can create a challenge for the end user if a device is broken, lost, stolen or simply upgraded.\n\nQ: How does passwordless authentication improve user experience?",
    "context": "",
    "output": "A: Passwordless authentication improves the user experience by eliminating the need for users to remember complicated passwords and comply with different security policies. Additionally, users do not have to periodically renew their passwords.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does passwordless authentication improve user experience?",
      "answer": "Passwordless authentication improves the user experience by eliminating the need for users to remember complicated passwords and comply with different security policies. Additionally, users do not have to periodically renew their passwords.",
      "context": "Passwordless authentication\n\n==Introduction==\nPasswordless authentication is an authentication method in which a user can log in to a computer system without the entering (and having to remember) a password or any other knowledge-based secret. In most common implementations users are asked to enter their public identifier (username, phone number, email address etc.) and then complete the authentication process by providing a secure proof of identity through a registered device or token.\nPasswordless authentication methods typically rely on public-key cryptography infrastructure where the public key is provided during registration to the authenticating service (remote server, application or website) while the private key is kept on a user\u2019s device (PC, smartphone or an external security token) and can be accessed only by providing a biometric signature or another authentication factor which is not knowledge-based. \nThese factors classically fall into two categories: \n\nOwnership factors (\u201cSomething the user has\u201d) such as a cellular phone, OTP token, smart card or a hardware token.\nInherence factors (\u201cSomething the user is\u201d) like fingerprints, retinal scans, face or voice recognition and other biometric identifiers.Some designs might also accept a combination of other factors such as geo-location, network address, behavioral patterns and gestures, as long as no memorized passwords are involved.\nPasswordless authentication is sometimes confused with multi-factor authentication (MFA), since both use a wide variety of authentication factors, but while MFA is often used as an added layer of security on top of password-based authentication, passwordless authentication does not require a memorized secret and usually uses just one highly secure factor to authenticate identity, making it faster and simpler for users.\n\"Passwordless MFA\" is the term used when both approaches are employed, and the authentication flow is both passwordless and uses multiple factors, providing the highest security level when implemented correctly.\n\n\n\n== Mechanism ==\nA user must first register with a system before their identity can be verified. A passwordless registration flow may include the following steps:\nRegistration request: When a user attempts to register with a website, the server sends a registration request to the user's device.\nAuthentication factor selection: When the user's device receives the registration request, it sets up a method for authenticating the user.  For example, the device may use biometrics like a fingerprint scanner or facial recognition for user identification.\nKey generation: The user's device generates a public/private key pair and sends the public key to the server for future verification.Once they have registered, a user can log in to the system via the following process:\n\nAuthentication challenge: The server sends an authentication to the user's device when the user attempts to log into the site.\nUser authentication: The user proves their identity to their device using the biometric scanner, unlocking their private key.\nChallenge response: The user's device digitally signs a response to the authentication challenge with the user's private key.\nResponse validation: The server uses the device's public key to verify the digital signature and provides access to the user's account.\n\n== Benefits and drawbacks ==\nProponents point out several unique benefits over other authentication methods:\n\nGreater security \u2013 passwords are known to be a weak point in computer systems (due to reuse, sharing, cracking, spraying etc.) and are regarded a top attack vector responsible for a huge percentage of security breaches.\nBetter user experience \u2013 Not only users aren\u2019t required to remember complicated password and comply with different security policies, they are also not required to periodically renew passwords.\nReduced IT costs \u2013 since no password storage and management is needed IT teams are no longer burdened by setting password policies, detecting leaks, resetting forgotten passwords, and complying with password storage regulation.\nBetter visibility of credential use \u2013 since credentials are tied to a specific device or inherent user attribute, they can't be massively used and access management becomes more tight.\nScalability \u2013 managing multiple logins without additional password fatigue or complicated registration.While others point out operational and cost-related disadvantages:\n\nImplementation costs \u2013 Although it is accepted that passwordless authentication leads to savings in the long term, deployment costs are currently a hindering factor for many potential users. Cost is associated with the need to deploy an authentication mechanism on an existing user directory and sometimes the additional hardware deployed to users (e.g. OTPs or security keys).\nTraining and expertise needed \u2013 while most password management systems are built similarly and have been used for many years, passwordless authentication requires adaptation from both IT teams and end users.\nSingle point of failure \u2013 particularly implementations using OTP or push notifications to cellular device applications can create a challenge for the end user if a device is broken, lost, stolen or simply upgraded."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the effect of the message that the BadBunny worm displays if the macro is opened from the affected document?",
    "context": "",
    "output": "The message that the BadBunny worm displays if the macro is opened from the affected document has no direct effects on the user's system, but it is a social engineering tactic used by the worm to trick the user into opening the document and activating the macro.\n```",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the effect of the message that the BadBunny worm displays if the macro is opened from the affected document?",
      "answer": "The message that the BadBunny worm displays if the macro is opened from the affected document has no direct effects on the user's system, but it is a social engineering tactic used by the worm to trick the user into opening the document and activating the macro.\n```"
    }
  },
  {
    "instruction": "Write an answer to the following question: In what ways can automated source code auditing tools help developers?",
    "context": "",
    "output": "Automated source code auditing tools can help developers by automatically checking for common vulnerabilities, saving time and resources compared to manual auditing processes. These tools can also provide continuous feedback, encouraging secure coding practices and improving overall software security.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "In what ways can automated source code auditing tools help developers?",
      "answer": "Automated source code auditing tools can help developers by automatically checking for common vulnerabilities, saving time and resources compared to manual auditing processes. These tools can also provide continuous feedback, encouraging secure coding practices and improving overall software security."
    }
  },
  {
    "instruction": "Hebern rotor machine\n\n==Introduction==\nThe Hebern Rotor Machine was an electro-mechanical encryption machine built by combining the mechanical parts of a standard typewriter with the electrical parts of an electric typewriter, connecting the two through a scrambler. It is the first example (though just barely) of a class of machines known as rotor machines that would become the primary form of encryption during World War II and for some time after, and which included such famous examples as the German Enigma.\n\n\n\n== Description ==\n\nThe key to the Hebern design was a disk with electrical contacts on either side, known today as a rotor. Linking the contacts on either side of the rotor were wires, with each letter on one side being wired to another on the far side in a random fashion. The wiring encoded a single substitution alphabet.\nWhen the user pressed a key on the typewriter keyboard, a small amount of current from a battery flowed through the key into one of the contacts on the input side of the disk, through the wiring, and back out a different contact. The power then operated the mechanicals of an electric typewriter to type the encrypted letter, or alternately simply lit a bulb or paper tape punch from a teletype machine.\nNormally such a system would be no better than the single-alphabet systems of the 16th century. However the rotor in the Hebern machine was geared to the keyboard on the typewriter, so that after every keypress, the rotor turned and the substitution alphabet thus changed slightly. This turns the basic substitution into a polyalphabetic one similar to the well known Vigen\u00e8re cipher, with the exception that it required no manual lookup of the keys or cyphertext. Operators simply turned the rotor to a pre-chosen starting position and started typing. To decrypt the message, they turned the rotor around in its socket so it was \"backwards\", thus reversing all the substitutions. They then typed in the ciphertext and out came the plaintext.\nBetter yet, several rotors can be placed such that the output of the first is connected to the input of the next. In this case the first rotor operates as before, turning once with each keypress. Additional rotors are then spun with a cam on the one beside it, each one being turned one position after the one beside it rotates a full turn. In this way the number of such alphabets increases dramatically. For a rotor with 26 letters in its alphabet, five such rotors \"stacked\" in this fashion allows for 265\nQuestion: How did the Hebern Rotor Machine make use of multiple rotors in series?",
    "context": "",
    "output": "Answer: The Hebern Rotor Machine made use of multiple rotors in series by connecting the output of the first rotor to the input of the next rotor, allowing for the use of multiple substitution alphabets and increasing the security of the encryption.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How did the Hebern Rotor Machine make use of multiple rotors in series?",
      "answer": "The Hebern Rotor Machine made use of multiple rotors in series by connecting the output of the first rotor to the input of the next rotor, allowing for the use of multiple substitution alphabets and increasing the security of the encryption.",
      "context": "Hebern rotor machine\n\n==Introduction==\nThe Hebern Rotor Machine was an electro-mechanical encryption machine built by combining the mechanical parts of a standard typewriter with the electrical parts of an electric typewriter, connecting the two through a scrambler. It is the first example (though just barely) of a class of machines known as rotor machines that would become the primary form of encryption during World War II and for some time after, and which included such famous examples as the German Enigma.\n\n\n\n== Description ==\n\nThe key to the Hebern design was a disk with electrical contacts on either side, known today as a rotor. Linking the contacts on either side of the rotor were wires, with each letter on one side being wired to another on the far side in a random fashion. The wiring encoded a single substitution alphabet.\nWhen the user pressed a key on the typewriter keyboard, a small amount of current from a battery flowed through the key into one of the contacts on the input side of the disk, through the wiring, and back out a different contact. The power then operated the mechanicals of an electric typewriter to type the encrypted letter, or alternately simply lit a bulb or paper tape punch from a teletype machine.\nNormally such a system would be no better than the single-alphabet systems of the 16th century. However the rotor in the Hebern machine was geared to the keyboard on the typewriter, so that after every keypress, the rotor turned and the substitution alphabet thus changed slightly. This turns the basic substitution into a polyalphabetic one similar to the well known Vigen\u00e8re cipher, with the exception that it required no manual lookup of the keys or cyphertext. Operators simply turned the rotor to a pre-chosen starting position and started typing. To decrypt the message, they turned the rotor around in its socket so it was \"backwards\", thus reversing all the substitutions. They then typed in the ciphertext and out came the plaintext.\nBetter yet, several rotors can be placed such that the output of the first is connected to the input of the next. In this case the first rotor operates as before, turning once with each keypress. Additional rotors are then spun with a cam on the one beside it, each one being turned one position after the one beside it rotates a full turn. In this way the number of such alphabets increases dramatically. For a rotor with 26 letters in its alphabet, five such rotors \"stacked\" in this fashion allows for 265"
    }
  },
  {
    "instruction": "Zero-day (computing)\n\n==Introduction==\nA zero-day (also known as a 0-day) is a computer-software vulnerability previously unknown to those who should be interested in its mitigation, like the vendor of the target software. Until the vulnerability is mitigated, hackers can exploit it to adversely affect programs, data, additional computers or a network. An exploit taking advantage of a zero-day is called a zero-day exploit, or zero-day attack.\nThe term \"zero-day\" originally referred to the number of days since a new piece of software was released to the public, so \"zero-day software\" was obtained by hacking into a developer's computer before release. Eventually the term was applied to the vulnerabilities that allowed this hacking, and to the number of days that the vendor has had to fix them. Once the vendors learn of the vulnerability, they will usually create patches or advise workarounds to mitigate it.\nThe more recently that the vendor has become aware of the vulnerability, the more likely it is that no fix or mitigation has been developed. Once a fix is developed, the chance of the exploit succeeding decreases as more users apply the fix over time. For zero-day exploits, unless the vulnerability is inadvertently fixed, such as by an unrelated update that happens to fix the vulnerability, the probability that a user has applied a vendor-supplied patch that fixes the problem is zero, so the exploit would remain available. Zero-day attacks are a severe threat.\n\n\n\n== Attack vectors ==\nPotential attack vectors for a zero-day vulnerability are identical to known vulnerabilities and those that have available patches. For example, when a user visits a rogue website, malicious code on the site can exploit unpatched vulnerabilities in a Web browser. Web browsers are a particular target for criminals because of their widespread distribution and usage. Cybercriminals, as well as international vendors of spyware such as Israel\u2019s NSO Group, can also send malicious e-mail attachments via SMTP, which exploit vulnerabilities in the application opening the attachment. Exploits that take advantage of common file types are numerous and frequent, as evidenced by their increasing appearances in databases such as US-CERT. Criminals can engineer malware to take advantage of these file type exploits to compromise attacked systems or steal confidential data.\n\n== Window of vulnerability ==\nThe time from when a software exploit first becomes active to the time when the number of vulnerable systems shrinks to insignificance is known as the window of vulnerability. The timeline for each software vulnerability is defined by the following main events: \n\nt0: The vulnerability is discovered (by anyone).\nt1a: A security patch is published (e.g., by the software vendor).\nt1b: An exploit becomes active.\nt2: Most vulnerable systems have applied the patch.Thus the formula for the length of the window of vulnerability is: t2 \u2212 t1b.\nIn this formulation, it is always true that t0 \u2264 t1a, and t0 \u2264 t1b. Note that t0 is not the same as day zero. For example, if a hacker is the first to discover (at t0) the vulnerability, the vendor might not learn of it until much later (on day zero).\nFor normal vulnerabilities, t1b > t1a. This implies that the software vendor was aware of the vulnerability and had time to publish a security patch (t1a) before any hacker could craft a workable exploit (t1b). For zero-day exploits, t1b \u2264 t1a, such that the exploit becomes active before a patch is made available.\nBy not disclosing known vulnerabilities, a software vendor hopes to reach t2 before t1b is reached, thus avoiding any exploits. However, the vendor has no guarantees that hackers will not find vulnerabilities on their own. Furthermore, hackers can analyze the security patches themselves, and thereby discover the underlying vulnerabilities and automatically generate working exploits. These exploits can be used effectively up until time t2.\nIn practice, the length of the window of vulnerability varies between systems, vendors, and individual vulnerabilities. It is often measured in days, with one report from 2006 estimating the average as 28 days.\n\n== Protection ==\nZero-day protection is the ability to provide protection against zero-day exploits. Since zero-day attacks are generally unknown to the public, it is often difficult to defend against them. Zero-day attacks are often effective against \"secure\" networks and can remain undetected even after they are launched. Thus, users of so-called secure systems must also exercise common sense and practice safe computing habits.Many techniques exist to limit the effectiveness of zero-day memory corruption vulnerabilities such as buffer overflows. These protection mechanisms exist in contemporary operating systems such as macOS, Windows Vista and beyond (see also: Security and safety features new to Windows Vista), Solaris, Linux, Unix, and Unix-like environments; Windows XP Service Pack 2 includes limited protection against generic memory corruption vulnerabilities and previous versions include even less. Desktop and server protection software also exist to mitigate zero-day buffer overflow vulnerabilities. Typically, these technologies involve heuristic termination analysis in order to stop attacks before they cause any harm.It has been suggested that a solution of this kind may be out of reach because it is algorithmically impossible in the general case to analyze any arbitrary code to determine if it is malicious, as such an analysis reduces to the halting problem over a linear bounded automaton, which is unsolvable. It is, however, unnecessary to address the general case (that is, to sort all programs into the categories of malicious or non-malicious) under most circumstances in order to eliminate a wide range of malicious behaviors. It suffices to recognize the safety of a limited set of programs (e.g., those that can access or modify only a given subset of machine resources) while rejecting both some safe and all unsafe programs. This does require the integrity of those safe programs to be maintained, which may prove difficult in the face of a kernel-level exploit.The Zeroday Emergency Response Team (ZERT) was a group of software engineers who worked to release non-vendor patches for zero-day exploits.\n\n== Worms ==\nZero-day worms take advantage of a surprise attack while they are still unknown to computer security professionals. Recent history shows an increasing rate of worm propagation. Well designed worms can spread very fast with devastating consequences to the Internet and other systems.\n\n== Ethics ==\nDiffering ideologies exist relating to the collection and use of zero-day vulnerability information. Many computer security vendors perform research on zero-day vulnerabilities in order to better understand the nature of vulnerabilities and their exploitation by individuals, computer worms and viruses. Alternatively, some vendors purchase vulnerabilities to augment their research capacity. An example of such a program is TippingPoint's Zero Day Initiative. While selling and buying these vulnerabilities is not technically illegal in most parts of the world, there is a lot of controversy over the method of disclosure. A 2006 German decision to include Article 6 of the Convention on Cybercrime and the EU Framework Decision on Attacks against Information Systems may make selling or even manufacturing vulnerabilities illegal.Most formal programs follow some form of Rain Forest Puppy's disclosure guidelines or the more recent OIS Guidelines for Security Vulnerability Reporting and Response. In general, these rules forbid the public disclosure of vulnerabilities without notification to the vendor and adequate time to produce a patch.\n\n== Viruses ==\nA zero-day virus (also known as zero-day malware or next-generation malware) is a previously unknown computer virus or other malware for which specific antivirus software signatures are not yet available.Traditionally, antivirus software relied upon signatures to identify malware. A virus signature is a unique pattern or code that can be used to detect and identify specific viruses. The antivirus scans file signatures and compares them to a database of known malicious codes. If they match, the file is flagged and treated as a threat. The major limitation of signature-based detection is that it is only capable of flagging already known malware, making it useless against zero-day attacks. Most modern antivirus software still uses signatures but also carries out other types of analysis.\n\n\n*** Code analysis ***\nIn code analysis, the machine code of the file is analysed to see if there is anything that looks suspicious. Typically, malware has characteristic behaviour; code analysis attempts to detect if this is present in the code.\nAlthough useful, code analysis has significant limitations. It is not always easy to determine what a section of code is intended to do, particularly if it is very complex and has been deliberately written with the intention of defeating analysis. Another limitation of code analysis is the time and resources available. In the competitive world of antivirus software, there is always a balance between the effectiveness of analysis and the time delay involved.\nOne approach to overcome the limitations of code analysis is for the antivirus software to run suspect sections of code in a safe sandbox and observe their behavior. This can be orders of magnitude faster than analyzing the same code, but must resist (and detect) attempts by the code to detect the sandbox.\n\n\n*** Generic signatures ***\nGeneric signatures are signatures that are specific to certain behaviour rather than a specific item of malware. Most new malware is not totally novel, but is a variation on earlier malware, or contains code from one or more earlier examples of malware. Thus, the results of previous analysis can be used against new malware.\n\n\n*** Competitiveness in the antivirus software industry ***\nIt is generally accepted in the antivirus industry that most vendors' signature-based protection is identically effective. If a signature is available for an item of malware, then every product (unless dysfunctional) should detect it. However, some vendors are significantly faster than others at becoming aware of new viruses and/or updating their customers' signature databases to detect them.There is a wide range of effectiveness in terms of zero-day virus protection. The German computer magazine c't found that detection rates for zero-day viruses varied from 20% to 68%. It is primarily in the area of zero-day virus performance that manufacturers now compete.\n\n== U.S. government involvement ==\n\n\n*** NSA's use of zero-day exploits (2017) ***\nIn mid-April 2017 the hackers known as The Shadow Brokers (TSB), who are allegedly linked to the Russian government, released files from the NSA (initially just regarded as alleged to be from the NSA, later confirmed through internal details and by American whistleblower Edward Snowden) which include a series of 'zero-day exploits' targeting Microsoft Windows software and a tool to penetrate the Society for Worldwide Interbank Financial Telecommunication (SWIFT)'s service provider. Ars Technica had reported Shadow Brokers' hacking claims in mid-January 2017, and in April the Shadow Brokers posted the exploits as proof.\n\n\n*** Vulnerabilities Equities Process ***\n\nThe Vulnerabilities Equities Process, first revealed publicly in 2016, is a process used by the U.S. federal government to determine on a case-by-case basis how it should treat zero-day computer security vulnerabilities: whether to disclose them to the public to help improve general computer security or to keep them secret for offensive use against the government's adversaries. The process has been criticized for a number of deficiencies, including restriction by non-disclosure agreements, lack of risk ratings, special treatment for the NSA, and a less than full commitment to disclosure as the default option.\nRead the text above and answer this question: How did the term \"zero-day\" come about and what does it originally refer to?",
    "context": "",
    "output": "The term \"zero-day\" originally referred to the number of days since a new piece of software was released to the public. It was used to describe software that was obtained by hacking into a developer's computer before release. Later, the term was applied to the vulnerabilities that allowed this hacking and to the number of days that the vendor has had to fix them.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How did the term \"zero-day\" come about and what does it originally refer to?",
      "answer": "The term \"zero-day\" originally referred to the number of days since a new piece of software was released to the public. It was used to describe software that was obtained by hacking into a developer's computer before release. Later, the term was applied to the vulnerabilities that allowed this hacking and to the number of days that the vendor has had to fix them.",
      "context": "Zero-day (computing)\n\n==Introduction==\nA zero-day (also known as a 0-day) is a computer-software vulnerability previously unknown to those who should be interested in its mitigation, like the vendor of the target software. Until the vulnerability is mitigated, hackers can exploit it to adversely affect programs, data, additional computers or a network. An exploit taking advantage of a zero-day is called a zero-day exploit, or zero-day attack.\nThe term \"zero-day\" originally referred to the number of days since a new piece of software was released to the public, so \"zero-day software\" was obtained by hacking into a developer's computer before release. Eventually the term was applied to the vulnerabilities that allowed this hacking, and to the number of days that the vendor has had to fix them. Once the vendors learn of the vulnerability, they will usually create patches or advise workarounds to mitigate it.\nThe more recently that the vendor has become aware of the vulnerability, the more likely it is that no fix or mitigation has been developed. Once a fix is developed, the chance of the exploit succeeding decreases as more users apply the fix over time. For zero-day exploits, unless the vulnerability is inadvertently fixed, such as by an unrelated update that happens to fix the vulnerability, the probability that a user has applied a vendor-supplied patch that fixes the problem is zero, so the exploit would remain available. Zero-day attacks are a severe threat.\n\n\n\n== Attack vectors ==\nPotential attack vectors for a zero-day vulnerability are identical to known vulnerabilities and those that have available patches. For example, when a user visits a rogue website, malicious code on the site can exploit unpatched vulnerabilities in a Web browser. Web browsers are a particular target for criminals because of their widespread distribution and usage. Cybercriminals, as well as international vendors of spyware such as Israel\u2019s NSO Group, can also send malicious e-mail attachments via SMTP, which exploit vulnerabilities in the application opening the attachment. Exploits that take advantage of common file types are numerous and frequent, as evidenced by their increasing appearances in databases such as US-CERT. Criminals can engineer malware to take advantage of these file type exploits to compromise attacked systems or steal confidential data.\n\n== Window of vulnerability ==\nThe time from when a software exploit first becomes active to the time when the number of vulnerable systems shrinks to insignificance is known as the window of vulnerability. The timeline for each software vulnerability is defined by the following main events: \n\nt0: The vulnerability is discovered (by anyone).\nt1a: A security patch is published (e.g., by the software vendor).\nt1b: An exploit becomes active.\nt2: Most vulnerable systems have applied the patch.Thus the formula for the length of the window of vulnerability is: t2 \u2212 t1b.\nIn this formulation, it is always true that t0 \u2264 t1a, and t0 \u2264 t1b. Note that t0 is not the same as day zero. For example, if a hacker is the first to discover (at t0) the vulnerability, the vendor might not learn of it until much later (on day zero).\nFor normal vulnerabilities, t1b > t1a. This implies that the software vendor was aware of the vulnerability and had time to publish a security patch (t1a) before any hacker could craft a workable exploit (t1b). For zero-day exploits, t1b \u2264 t1a, such that the exploit becomes active before a patch is made available.\nBy not disclosing known vulnerabilities, a software vendor hopes to reach t2 before t1b is reached, thus avoiding any exploits. However, the vendor has no guarantees that hackers will not find vulnerabilities on their own. Furthermore, hackers can analyze the security patches themselves, and thereby discover the underlying vulnerabilities and automatically generate working exploits. These exploits can be used effectively up until time t2.\nIn practice, the length of the window of vulnerability varies between systems, vendors, and individual vulnerabilities. It is often measured in days, with one report from 2006 estimating the average as 28 days.\n\n== Protection ==\nZero-day protection is the ability to provide protection against zero-day exploits. Since zero-day attacks are generally unknown to the public, it is often difficult to defend against them. Zero-day attacks are often effective against \"secure\" networks and can remain undetected even after they are launched. Thus, users of so-called secure systems must also exercise common sense and practice safe computing habits.Many techniques exist to limit the effectiveness of zero-day memory corruption vulnerabilities such as buffer overflows. These protection mechanisms exist in contemporary operating systems such as macOS, Windows Vista and beyond (see also: Security and safety features new to Windows Vista), Solaris, Linux, Unix, and Unix-like environments; Windows XP Service Pack 2 includes limited protection against generic memory corruption vulnerabilities and previous versions include even less. Desktop and server protection software also exist to mitigate zero-day buffer overflow vulnerabilities. Typically, these technologies involve heuristic termination analysis in order to stop attacks before they cause any harm.It has been suggested that a solution of this kind may be out of reach because it is algorithmically impossible in the general case to analyze any arbitrary code to determine if it is malicious, as such an analysis reduces to the halting problem over a linear bounded automaton, which is unsolvable. It is, however, unnecessary to address the general case (that is, to sort all programs into the categories of malicious or non-malicious) under most circumstances in order to eliminate a wide range of malicious behaviors. It suffices to recognize the safety of a limited set of programs (e.g., those that can access or modify only a given subset of machine resources) while rejecting both some safe and all unsafe programs. This does require the integrity of those safe programs to be maintained, which may prove difficult in the face of a kernel-level exploit.The Zeroday Emergency Response Team (ZERT) was a group of software engineers who worked to release non-vendor patches for zero-day exploits.\n\n== Worms ==\nZero-day worms take advantage of a surprise attack while they are still unknown to computer security professionals. Recent history shows an increasing rate of worm propagation. Well designed worms can spread very fast with devastating consequences to the Internet and other systems.\n\n== Ethics ==\nDiffering ideologies exist relating to the collection and use of zero-day vulnerability information. Many computer security vendors perform research on zero-day vulnerabilities in order to better understand the nature of vulnerabilities and their exploitation by individuals, computer worms and viruses. Alternatively, some vendors purchase vulnerabilities to augment their research capacity. An example of such a program is TippingPoint's Zero Day Initiative. While selling and buying these vulnerabilities is not technically illegal in most parts of the world, there is a lot of controversy over the method of disclosure. A 2006 German decision to include Article 6 of the Convention on Cybercrime and the EU Framework Decision on Attacks against Information Systems may make selling or even manufacturing vulnerabilities illegal.Most formal programs follow some form of Rain Forest Puppy's disclosure guidelines or the more recent OIS Guidelines for Security Vulnerability Reporting and Response. In general, these rules forbid the public disclosure of vulnerabilities without notification to the vendor and adequate time to produce a patch.\n\n== Viruses ==\nA zero-day virus (also known as zero-day malware or next-generation malware) is a previously unknown computer virus or other malware for which specific antivirus software signatures are not yet available.Traditionally, antivirus software relied upon signatures to identify malware. A virus signature is a unique pattern or code that can be used to detect and identify specific viruses. The antivirus scans file signatures and compares them to a database of known malicious codes. If they match, the file is flagged and treated as a threat. The major limitation of signature-based detection is that it is only capable of flagging already known malware, making it useless against zero-day attacks. Most modern antivirus software still uses signatures but also carries out other types of analysis.\n\n\n*** Code analysis ***\nIn code analysis, the machine code of the file is analysed to see if there is anything that looks suspicious. Typically, malware has characteristic behaviour; code analysis attempts to detect if this is present in the code.\nAlthough useful, code analysis has significant limitations. It is not always easy to determine what a section of code is intended to do, particularly if it is very complex and has been deliberately written with the intention of defeating analysis. Another limitation of code analysis is the time and resources available. In the competitive world of antivirus software, there is always a balance between the effectiveness of analysis and the time delay involved.\nOne approach to overcome the limitations of code analysis is for the antivirus software to run suspect sections of code in a safe sandbox and observe their behavior. This can be orders of magnitude faster than analyzing the same code, but must resist (and detect) attempts by the code to detect the sandbox.\n\n\n*** Generic signatures ***\nGeneric signatures are signatures that are specific to certain behaviour rather than a specific item of malware. Most new malware is not totally novel, but is a variation on earlier malware, or contains code from one or more earlier examples of malware. Thus, the results of previous analysis can be used against new malware.\n\n\n*** Competitiveness in the antivirus software industry ***\nIt is generally accepted in the antivirus industry that most vendors' signature-based protection is identically effective. If a signature is available for an item of malware, then every product (unless dysfunctional) should detect it. However, some vendors are significantly faster than others at becoming aware of new viruses and/or updating their customers' signature databases to detect them.There is a wide range of effectiveness in terms of zero-day virus protection. The German computer magazine c't found that detection rates for zero-day viruses varied from 20% to 68%. It is primarily in the area of zero-day virus performance that manufacturers now compete.\n\n== U.S. government involvement ==\n\n\n*** NSA's use of zero-day exploits (2017) ***\nIn mid-April 2017 the hackers known as The Shadow Brokers (TSB), who are allegedly linked to the Russian government, released files from the NSA (initially just regarded as alleged to be from the NSA, later confirmed through internal details and by American whistleblower Edward Snowden) which include a series of 'zero-day exploits' targeting Microsoft Windows software and a tool to penetrate the Society for Worldwide Interbank Financial Telecommunication (SWIFT)'s service provider. Ars Technica had reported Shadow Brokers' hacking claims in mid-January 2017, and in April the Shadow Brokers posted the exploits as proof.\n\n\n*** Vulnerabilities Equities Process ***\n\nThe Vulnerabilities Equities Process, first revealed publicly in 2016, is a process used by the U.S. federal government to determine on a case-by-case basis how it should treat zero-day computer security vulnerabilities: whether to disclose them to the public to help improve general computer security or to keep them secret for offensive use against the government's adversaries. The process has been criticized for a number of deficiencies, including restriction by non-disclosure agreements, lack of risk ratings, special treatment for the NSA, and a less than full commitment to disclosure as the default option."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does PKIoverheid, the public key infrastructure (PKI) from the Dutch government, ensure the authenticity and integrity of digital certificates?",
    "context": "",
    "output": "PKIoverheid uses a combination of public key cryptography and digital certificates to ensure the authenticity and integrity of digital certificates. Public key cryptography involves the use of two keys, a public key and a private key, to encrypt and decrypt data. Digital certificates, which are issued and managed by PKIoverheid, bind a public key to the identity of an individual, organization, or device. This allows users to verify the identity of the certificate holder and encrypt data using the certificate holder's public key, knowing that only the certificate holder's private key can be used to decrypt it.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does PKIoverheid, the public key infrastructure (PKI) from the Dutch government, ensure the authenticity and integrity of digital certificates?",
      "answer": "PKIoverheid uses a combination of public key cryptography and digital certificates to ensure the authenticity and integrity of digital certificates. Public key cryptography involves the use of two keys, a public key and a private key, to encrypt and decrypt data. Digital certificates, which are issued and managed by PKIoverheid, bind a public key to the identity of an individual, organization, or device. This allows users to verify the identity of the certificate holder and encrypt data using the certificate holder's public key, knowing that only the certificate holder's private key can be used to decrypt it."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the role of automation in cyberbiosecurity threats?",
    "context": "",
    "output": "Automation is one of the fields where cyberbiosecurity threats are becoming increasingly important. The integration of automation with other fields such as artificial intelligence and synthetic biology is generating new security vulnerabilities.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of automation in cyberbiosecurity threats?",
      "answer": "Automation is one of the fields where cyberbiosecurity threats are becoming increasingly important. The integration of automation with other fields such as artificial intelligence and synthetic biology is generating new security vulnerabilities."
    }
  },
  {
    "instruction": "2021 Iranian fuel cyberattack\n\n==Introduction==\nThe Iranian fuel 2021 cyberstrike was an attack on the Iranian fuel system, government-issued cards used for buying subsidized fuel, and digital road billboards. The attack took place on 26 October 2021. The government announced that people had to buy gas without their ration card. According to the Supreme Council of Cyberspace, the attacks were similar to the attack on the Iranian rail road transit system in July. Iranian President Ebrahim Raisi stated, \"this cyberattack is neither the first time nor will it be the last.\"Network infrastructure is a semi-isolated system not connected to the Internet but instead uses the National Internet (National Information Network).Gholamreza Jalali, the head of Iranian civil defense, accused the United States and Israel of being behind the attack in an interview with state TV.\n\n\n\n== Scale and Details ==\nIran's 4300 gas stations were unable to process payments. Initially, the Ministry of Petroleum blamed a technical error, though it was later revealed to be a cyberattack. Users trying to purchase fuel at affected gas stations received a display reading \"cyberattack 64411\" which is associated with a hotline to the Ayatollah's office which responds to questions about Islamic law, though a possible connection was not commented on by official Iranian agencies. Cybersecurity industry firms noted the similarity to a 2020 rail attack in which a similar message was displayed, prompting speculation of a possible connection between the two attacks. The previous attack was attributed by security researchers at Check Point to the hacking group INDRA, which claims to be an anti-government partisan resistance group.Digital billboards in Iranian cities were seen displaying messages such as \"Khameini! Where is our fuel?\" as news about the attack spread. A group called Predatory Sparrow claimed credit for the attack along with a previous cyberattacks against Iranian rail assets earlier in 2021, although Iranian officials simply attributed it to an unnamed state actor.\n\nAnswer this question based on the above context: How did digital billboards in Iranian cities respond to the 2021 Iranian fuel cyberattack?",
    "context": "",
    "output": "Digital billboards in Iranian cities displayed messages such as \"Khameini! Where is our fuel?\" as news about the attack spread.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How did digital billboards in Iranian cities respond to the 2021 Iranian fuel cyberattack?",
      "answer": "Digital billboards in Iranian cities displayed messages such as \"Khameini! Where is our fuel?\" as news about the attack spread.",
      "context": "2021 Iranian fuel cyberattack\n\n==Introduction==\nThe Iranian fuel 2021 cyberstrike was an attack on the Iranian fuel system, government-issued cards used for buying subsidized fuel, and digital road billboards. The attack took place on 26 October 2021. The government announced that people had to buy gas without their ration card. According to the Supreme Council of Cyberspace, the attacks were similar to the attack on the Iranian rail road transit system in July. Iranian President Ebrahim Raisi stated, \"this cyberattack is neither the first time nor will it be the last.\"Network infrastructure is a semi-isolated system not connected to the Internet but instead uses the National Internet (National Information Network).Gholamreza Jalali, the head of Iranian civil defense, accused the United States and Israel of being behind the attack in an interview with state TV.\n\n\n\n== Scale and Details ==\nIran's 4300 gas stations were unable to process payments. Initially, the Ministry of Petroleum blamed a technical error, though it was later revealed to be a cyberattack. Users trying to purchase fuel at affected gas stations received a display reading \"cyberattack 64411\" which is associated with a hotline to the Ayatollah's office which responds to questions about Islamic law, though a possible connection was not commented on by official Iranian agencies. Cybersecurity industry firms noted the similarity to a 2020 rail attack in which a similar message was displayed, prompting speculation of a possible connection between the two attacks. The previous attack was attributed by security researchers at Check Point to the hacking group INDRA, which claims to be an anti-government partisan resistance group.Digital billboards in Iranian cities were seen displaying messages such as \"Khameini! Where is our fuel?\" as news about the attack spread. A group called Predatory Sparrow claimed credit for the attack along with a previous cyberattacks against Iranian rail assets earlier in 2021, although Iranian officials simply attributed it to an unnamed state actor."
    }
  },
  {
    "instruction": "Simjacker\n\n==Introduction==\nSimjacker is a cellular software exploit for SIM Cards discovered by AdaptiveMobile Security. 29 countries are vulnerable according to ZDNet. The vulnerability has been exploited primarily in Mexico, but also Colombia and Peru, according to the Wall Street Journal, where it was used to track the location of mobile phone users without their knowledge. \n\n\n\n== Technical information ==\nThe attack works by exploiting a vulnerability in a UICC/SIM Card library called the S@T Browser. A specially formatted binary text message is sent to the victim handset, which contains a set of commands to be executed by the S@T Browser environment in the UICC. As the S@T Browser environment has access to a subset of SIM Toolkit commands, the attackers used this vulnerability to instruct the UICC to request IMEI and location information from the handset via SIM Toolkit commands. Once this was obtained the UICC then instructs the handset to exfiltrate this information to the attackers within another text message. Other types of attacks are also possible using the S@T Browser, such as forcing a mobile device to open a webpage or to make a phone call.The attack differed from previously reported SIM Card attacks as those required the SIM key to be obtained. The Simjacker attack does not require a SIM key, only that the SIM Card has the S@T Browser library installed on it, and that the binary messages containing the S@T Browser commands can be sent to the victim. \nSimjacker was registered in the Common Vulnerabilities and Exposures database as CVE-2019-16256 and CVE-2019-16257, and by the GSM Association in its Coordinated Vulnerability Disclosure process as CVD-2019-0026\n\n== Impact ==\nThe vulnerability was estimated to affect UICCs in at least 61 mobile operators in 29 countries, with estimates between a few hundred million to over a billion SIM cards affected. The researcher reported that the most probable, conservative estimate is that mid to high hundreds of millions of SIM Cards globally are affected.The vulnerability was being actively exploited primarily in Mexico, with thousands of mobile phone users being tracked by a surveillance company over the previous 2 years using this exploit.\n\n== Mitigation ==\nMobile phone users can use a tool from SRLabs to see if their SIM Card is vulnerable.\n\nCan Simjacker be used to force a mobile phone to make a call?",
    "context": "",
    "output": "Yes, Simjacker can be used to force a mobile phone to make a call, which can be used for various malicious purposes such as social engineering or fraud.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Can Simjacker be used to force a mobile phone to make a call?",
      "answer": "Yes, Simjacker can be used to force a mobile phone to make a call, which can be used for various malicious purposes such as social engineering or fraud.",
      "context": "Simjacker\n\n==Introduction==\nSimjacker is a cellular software exploit for SIM Cards discovered by AdaptiveMobile Security. 29 countries are vulnerable according to ZDNet. The vulnerability has been exploited primarily in Mexico, but also Colombia and Peru, according to the Wall Street Journal, where it was used to track the location of mobile phone users without their knowledge. \n\n\n\n== Technical information ==\nThe attack works by exploiting a vulnerability in a UICC/SIM Card library called the S@T Browser. A specially formatted binary text message is sent to the victim handset, which contains a set of commands to be executed by the S@T Browser environment in the UICC. As the S@T Browser environment has access to a subset of SIM Toolkit commands, the attackers used this vulnerability to instruct the UICC to request IMEI and location information from the handset via SIM Toolkit commands. Once this was obtained the UICC then instructs the handset to exfiltrate this information to the attackers within another text message. Other types of attacks are also possible using the S@T Browser, such as forcing a mobile device to open a webpage or to make a phone call.The attack differed from previously reported SIM Card attacks as those required the SIM key to be obtained. The Simjacker attack does not require a SIM key, only that the SIM Card has the S@T Browser library installed on it, and that the binary messages containing the S@T Browser commands can be sent to the victim. \nSimjacker was registered in the Common Vulnerabilities and Exposures database as CVE-2019-16256 and CVE-2019-16257, and by the GSM Association in its Coordinated Vulnerability Disclosure process as CVD-2019-0026\n\n== Impact ==\nThe vulnerability was estimated to affect UICCs in at least 61 mobile operators in 29 countries, with estimates between a few hundred million to over a billion SIM cards affected. The researcher reported that the most probable, conservative estimate is that mid to high hundreds of millions of SIM Cards globally are affected.The vulnerability was being actively exploited primarily in Mexico, with thousands of mobile phone users being tracked by a surveillance company over the previous 2 years using this exploit.\n\n== Mitigation ==\nMobile phone users can use a tool from SRLabs to see if their SIM Card is vulnerable."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the significance of the CJCSG algorithm's submission to the eSTREAM Project of the eCRYPT network, given its archival classification?",
    "context": "",
    "output": "The CJCSG algorithm's submission to the eSTREAM Project of the eCRYPT network indicates that it was initially considered as a potential candidate for cryptographic applications. However, its archival classification suggests that it did not meet the necessary requirements or standards for further development and implementation. Despite its archival status, the algorithm may still provide insights and knowledge for the development of future stream cypher algorithms.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the significance of the CJCSG algorithm's submission to the eSTREAM Project of the eCRYPT network, given its archival classification?",
      "answer": "The CJCSG algorithm's submission to the eSTREAM Project of the eCRYPT network indicates that it was initially considered as a potential candidate for cryptographic applications. However, its archival classification suggests that it did not meet the necessary requirements or standards for further development and implementation. Despite its archival status, the algorithm may still provide insights and knowledge for the development of future stream cypher algorithms."
    }
  },
  {
    "instruction": "Write an answer to the following question: What did F-Secure say regarding detecting tools made by a known violent mafia or terrorist organization?",
    "context": "",
    "output": "F-Secure said that they would detect such tools for terrorist activity or to benefit organized crime.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What did F-Secure say regarding detecting tools made by a known violent mafia or terrorist organization?",
      "answer": "F-Secure said that they would detect such tools for terrorist activity or to benefit organized crime."
    }
  },
  {
    "instruction": "Disposable email address\n\n==Introduction==\nDisposable email addressing, also known as DEA or dark mail or \"masked\" email, refers to an approach which involves a unique email address being used for every contact, entity, or for a limited number of times or uses. The benefit is that if anyone compromises the address or utilizes it in connection with email abuse, the address owner can easily cancel (or \"dispose\" of) it without affecting any of their other contacts.\n\n\n\n== Uses ==\nDisposable email addressing sets up a different, unique email address for every sender/recipient combination. It operates most usefully in scenarios where someone may sell or release an email address to spam lists or to other unscrupulous entities. The most common situations of this type involve online registration for sites offering discussion groups, bulletin boards, chat rooms, online shopping, and file hosting services. At a time when email spam has become an everyday nuisance, and when identity theft threatens, DEAs can serve as a convenient tool for protecting Internet users.Disposable email addresses can be cancelled if someone starts to use the address in a manner that was not intended by the creator. Examples are the accidental release of an email to a spam list, or if the address was procured by spammers. Alternatively, the user may simply decide not to receive further correspondence from the sender. Whatever the cause, DEA allows the address owner to take unilateral action by simply cancelling the address in question. Later, the owner can determine whether to update the recipient or not.\nDisposable email addresses typically forward to one or more real email mailboxes in which the owner receives and reads messages. The contact with whom a DEA is shared never learns the real email address of the user. If a database manages the DEA, it can also quickly identify the expected sender of each message by retrieving the associated contact name of each unique DEA. Used properly, DEA can also help identify which recipients handle email addresses in a careless or illegitimate manner. Moreover, it can serve as a tool for spotting fake messages or phishers.\n\n== Advantages over traditional email ==\nIdeally, owners share a DEA once with each contact/entity. Thus, if the DEA should ever change, only one entity needs to be updated. By comparison, the traditional practice of giving the same email address to multiple recipients means that if that address subsequently changes, many legitimate recipients will need to receive notification of the change and to update their records \u2014 a potentially tedious process.\nAdditionally, because access has been narrowed down to one contact, that entity then becomes the most likely point of compromise for any spam that account receives (see \"filtering\" below for exceptions). This allows users to determine firsthand the trustworthiness of the people with whom they share their DEAs. \"Safe\" DEAs that have not been abused can be forwarded to a real email account, while messages sent to \"compromised\" DEAs can be routed to a special folder, sent to the trash, held for spam filtering, or returned as undeliverable if the DEA is deleted outright.\nFurther, because DEAs serve as a layer of indirection between the sender and recipient, if the DEA user's actual email address changes, for instance because of moving from a university address to a local ISP, then the user need only update the DEA service provider about the change, and all outstanding DEAs will continue to function without updating.\n\n== Using \"sub-addressing\" ==\nA number of email systems support \"sub-addressing\" (also known as \"plus\" or \"tagged\" addressing) where a tag can be appended to the \"local part\" of an email address \u2014 the part to the left of the \"@\" \u2014 but with the modified address being an alias to the unmodified address. For example, the address joeuser+tag@example.com denotes the same delivery address as joeuser@example.com. The text of the tag may be used to apply filtering, or to create single-use addresses.\nIf available, this feature can allow users to create their own disposable addresses.\n\n== Multiple email aliases ==\nAnother approach is to register one main email address and many auxiliary email addresses, which will forward all mail to the main address, i.e., the auxiliaries are used as aliases of the main address. The advantage of this approach is that the user can easily detect which auxiliary email is 'leaking' with spam and block or dispose it.\nSome services require additional time to set up forwarding, but others allow to create new addresses \"on the fly\" without registering them with the service in advance. However, this method allows storage and access of all emails from a single main account, although to manage forwarding for some services the user has to remember the password for each alias.\nA variation is to use a catch-all address, then forward to the real mailbox using wildcards. Many mail servers allow the use of an asterisk (*), meaning \"any number of characters\". This makes the whitelist automatic and only requires the administrator to update the blacklist occasionally. In effect, the user has one address, but it contains wild cards, e.g., \"me.*@my.domain'\", which will match any incoming address that starts with \"me.\" and ends with \"@my.domain\". This is very similar to the \"+\" notation, but it may be even less obvious, since the address appears to be completely normal.\n\n== Concerns ==\n\n\n*** Restrictions by site administrators ***\nSome forum and wiki administrators dislike DEAs because they obfuscate the identity of the members and make maintaining member control difficult. As an example, Internet trolls, vandals and other users that may have been banned may use throwaway email addresses to get around the ban. Using a DEA provider only makes this easier; the same convenience with which a person may create a DEA to filter spam also applies to trolls. Website operators expecting to generate revenue by selling the user email addresses they gather may choose to ban DEAs as well, due to the low market value of such addresses. There are several free lists available to help detect DEA domains, as well as managed services.\nBanning DEAs might not be as effective at deterring undesirable users. More effective techniques for controlling undesirables without inconveniences to legitimate DEA users might include: recognizing legitimate DEAs for what they are (they usually have a proper domain and a fixed prefix or suffix), distinguishing them from short-lived, random throwaway address patterns or domains used by undesirables, wildcard banning.\nAs with any kind of threat and defense measures, no attempts to use or thwart DEAs are foolproof \u2014 any filtering method is bound to result in some false positives (legitimate users getting banned), and some false negatives (undesirables getting through, and legitimate users managing to come up with a DEA pattern getting around limitations imposed by site administrators). This is because the email address may be partly or fully defined by the user, made to appear as \"permanent\"-looking as needed, or made to avoid a particular pattern, defeating any filtering because for all intents and purposes it is not different from a permanent one, despite being limited to one purpose.\nCaught in the crossfire between Internet undesirables and administrative and user attempts to deal with them, DEA providers have trouble presenting a total solution. A user may find it necessary to come up with a conventional-looking email address (or create a separate mailbox in the worst case) to a public/commercial entity if required. There is always uncertainty about the trustworthiness and reputation of the site administrators, the availability of options to hide email addresses, the existence/enforcement of an acceptable privacy policy and the chance that the site may one day be compromised or transferred to new owners. Even the largest and otherwise reputable companies have been compromised or resorted to sending spam or giving away emails to third parties. A human correspondent's computer or mailbox may be compromised by malware and their address book can be stolen and sold to spammers.\n\nAnswer this question based on the above context: How can DEAs help users protect their personal information from being compromised or sold to spammers?",
    "context": "",
    "output": "DEAs help users protect their personal information by providing a unique email address for every sender/recipient combination. This approach ensures that if an email address is compromised or sold to spam lists, the user can easily cancel it without affecting their other contacts. DEAs can also help identify which recipients handle email addresses in a careless or illegitimate manner and serve as a tool for spotting fake messages or phishers.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can DEAs help users protect their personal information from being compromised or sold to spammers?",
      "answer": "DEAs help users protect their personal information by providing a unique email address for every sender/recipient combination. This approach ensures that if an email address is compromised or sold to spam lists, the user can easily cancel it without affecting their other contacts. DEAs can also help identify which recipients handle email addresses in a careless or illegitimate manner and serve as a tool for spotting fake messages or phishers.",
      "context": "Disposable email address\n\n==Introduction==\nDisposable email addressing, also known as DEA or dark mail or \"masked\" email, refers to an approach which involves a unique email address being used for every contact, entity, or for a limited number of times or uses. The benefit is that if anyone compromises the address or utilizes it in connection with email abuse, the address owner can easily cancel (or \"dispose\" of) it without affecting any of their other contacts.\n\n\n\n== Uses ==\nDisposable email addressing sets up a different, unique email address for every sender/recipient combination. It operates most usefully in scenarios where someone may sell or release an email address to spam lists or to other unscrupulous entities. The most common situations of this type involve online registration for sites offering discussion groups, bulletin boards, chat rooms, online shopping, and file hosting services. At a time when email spam has become an everyday nuisance, and when identity theft threatens, DEAs can serve as a convenient tool for protecting Internet users.Disposable email addresses can be cancelled if someone starts to use the address in a manner that was not intended by the creator. Examples are the accidental release of an email to a spam list, or if the address was procured by spammers. Alternatively, the user may simply decide not to receive further correspondence from the sender. Whatever the cause, DEA allows the address owner to take unilateral action by simply cancelling the address in question. Later, the owner can determine whether to update the recipient or not.\nDisposable email addresses typically forward to one or more real email mailboxes in which the owner receives and reads messages. The contact with whom a DEA is shared never learns the real email address of the user. If a database manages the DEA, it can also quickly identify the expected sender of each message by retrieving the associated contact name of each unique DEA. Used properly, DEA can also help identify which recipients handle email addresses in a careless or illegitimate manner. Moreover, it can serve as a tool for spotting fake messages or phishers.\n\n== Advantages over traditional email ==\nIdeally, owners share a DEA once with each contact/entity. Thus, if the DEA should ever change, only one entity needs to be updated. By comparison, the traditional practice of giving the same email address to multiple recipients means that if that address subsequently changes, many legitimate recipients will need to receive notification of the change and to update their records \u2014 a potentially tedious process.\nAdditionally, because access has been narrowed down to one contact, that entity then becomes the most likely point of compromise for any spam that account receives (see \"filtering\" below for exceptions). This allows users to determine firsthand the trustworthiness of the people with whom they share their DEAs. \"Safe\" DEAs that have not been abused can be forwarded to a real email account, while messages sent to \"compromised\" DEAs can be routed to a special folder, sent to the trash, held for spam filtering, or returned as undeliverable if the DEA is deleted outright.\nFurther, because DEAs serve as a layer of indirection between the sender and recipient, if the DEA user's actual email address changes, for instance because of moving from a university address to a local ISP, then the user need only update the DEA service provider about the change, and all outstanding DEAs will continue to function without updating.\n\n== Using \"sub-addressing\" ==\nA number of email systems support \"sub-addressing\" (also known as \"plus\" or \"tagged\" addressing) where a tag can be appended to the \"local part\" of an email address \u2014 the part to the left of the \"@\" \u2014 but with the modified address being an alias to the unmodified address. For example, the address joeuser+tag@example.com denotes the same delivery address as joeuser@example.com. The text of the tag may be used to apply filtering, or to create single-use addresses.\nIf available, this feature can allow users to create their own disposable addresses.\n\n== Multiple email aliases ==\nAnother approach is to register one main email address and many auxiliary email addresses, which will forward all mail to the main address, i.e., the auxiliaries are used as aliases of the main address. The advantage of this approach is that the user can easily detect which auxiliary email is 'leaking' with spam and block or dispose it.\nSome services require additional time to set up forwarding, but others allow to create new addresses \"on the fly\" without registering them with the service in advance. However, this method allows storage and access of all emails from a single main account, although to manage forwarding for some services the user has to remember the password for each alias.\nA variation is to use a catch-all address, then forward to the real mailbox using wildcards. Many mail servers allow the use of an asterisk (*), meaning \"any number of characters\". This makes the whitelist automatic and only requires the administrator to update the blacklist occasionally. In effect, the user has one address, but it contains wild cards, e.g., \"me.*@my.domain'\", which will match any incoming address that starts with \"me.\" and ends with \"@my.domain\". This is very similar to the \"+\" notation, but it may be even less obvious, since the address appears to be completely normal.\n\n== Concerns ==\n\n\n*** Restrictions by site administrators ***\nSome forum and wiki administrators dislike DEAs because they obfuscate the identity of the members and make maintaining member control difficult. As an example, Internet trolls, vandals and other users that may have been banned may use throwaway email addresses to get around the ban. Using a DEA provider only makes this easier; the same convenience with which a person may create a DEA to filter spam also applies to trolls. Website operators expecting to generate revenue by selling the user email addresses they gather may choose to ban DEAs as well, due to the low market value of such addresses. There are several free lists available to help detect DEA domains, as well as managed services.\nBanning DEAs might not be as effective at deterring undesirable users. More effective techniques for controlling undesirables without inconveniences to legitimate DEA users might include: recognizing legitimate DEAs for what they are (they usually have a proper domain and a fixed prefix or suffix), distinguishing them from short-lived, random throwaway address patterns or domains used by undesirables, wildcard banning.\nAs with any kind of threat and defense measures, no attempts to use or thwart DEAs are foolproof \u2014 any filtering method is bound to result in some false positives (legitimate users getting banned), and some false negatives (undesirables getting through, and legitimate users managing to come up with a DEA pattern getting around limitations imposed by site administrators). This is because the email address may be partly or fully defined by the user, made to appear as \"permanent\"-looking as needed, or made to avoid a particular pattern, defeating any filtering because for all intents and purposes it is not different from a permanent one, despite being limited to one purpose.\nCaught in the crossfire between Internet undesirables and administrative and user attempts to deal with them, DEA providers have trouble presenting a total solution. A user may find it necessary to come up with a conventional-looking email address (or create a separate mailbox in the worst case) to a public/commercial entity if required. There is always uncertainty about the trustworthiness and reputation of the site administrators, the availability of options to hide email addresses, the existence/enforcement of an acceptable privacy policy and the chance that the site may one day be compromised or transferred to new owners. Even the largest and otherwise reputable companies have been compromised or resorted to sending spam or giving away emails to third parties. A human correspondent's computer or mailbox may be compromised by malware and their address book can be stolen and sold to spammers."
    }
  },
  {
    "instruction": "Answer based on context:\n\nHare (computer virus)\n\n==Introduction==\nThe Hare Virus was a destructive computer virus which infected DOS and Windows 95 machines in August 1996.  It was also known as Hare.7610, Krsna and HD Euthanasia.\n\n\n\n== Description ==\nThe virus was capable of infecting .COM and .EXE executable files, as well as the master boot record of hard disks and the boot sector on floppy disks.  The virus was set to read the system date of the computer and activate on August 22 and September 22, at which time it would erase the hard disk in the computer and display the following message:\n\nHDEuthanasia by Demon Emperor: Hare Krsna, hare, hare\n\n== Timing ==\nThe date of the virus is controversial, even there is consensus that it started spreading at the end of the spring or at the beginning of the summer of 1996 in New Zealand, experts seem to disagree about the precise timing of the start of the spread. After a little while, its effects started to show up in South Africa and Canada. The United States saw the arrival of Hare in May 1996 and then continued spreading globally to Western and Eastern Europe.\n\nWhat kind of computer systems did the Hare Virus target and what file types did it infect?",
    "context": "",
    "output": "The Hare Virus targeted DOS and Windows 95 machines and was capable of infecting .COM and .EXE executable files, as well as the master boot record of hard disks and the boot sector on floppy disks.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What kind of computer systems did the Hare Virus target and what file types did it infect?",
      "answer": "The Hare Virus targeted DOS and Windows 95 machines and was capable of infecting .COM and .EXE executable files, as well as the master boot record of hard disks and the boot sector on floppy disks.",
      "context": "Hare (computer virus)\n\n==Introduction==\nThe Hare Virus was a destructive computer virus which infected DOS and Windows 95 machines in August 1996.  It was also known as Hare.7610, Krsna and HD Euthanasia.\n\n\n\n== Description ==\nThe virus was capable of infecting .COM and .EXE executable files, as well as the master boot record of hard disks and the boot sector on floppy disks.  The virus was set to read the system date of the computer and activate on August 22 and September 22, at which time it would erase the hard disk in the computer and display the following message:\n\nHDEuthanasia by Demon Emperor: Hare Krsna, hare, hare\n\n== Timing ==\nThe date of the virus is controversial, even there is consensus that it started spreading at the end of the spring or at the beginning of the summer of 1996 in New Zealand, experts seem to disagree about the precise timing of the start of the spread. After a little while, its effects started to show up in South Africa and Canada. The United States saw the arrival of Hare in May 1996 and then continued spreading globally to Western and Eastern Europe."
    }
  },
  {
    "instruction": "Armitage (computing)\n\n==Introduction==\nArmitage is a graphical cyber attack management tool for the Metasploit Project that visualizes targets and recommends exploits. It is a free and open source network security tool notable for its contributions to red team collaboration allowing for: shared sessions, data, and communication through a single Metasploit instance. Armitage is written and supported by Raphael Mudge.\n\n== Features ==\nArmitage is a scriptable red team collaboration tool built on top of the Metasploit Framework. Through Armitage, a user may launch scans and exploits, get exploit recommendations, and use the advanced features of the Metasploit Framework's meterpreter.\nRead the text above and answer this question: What is the meterpreter in the context of Armitage and the Metasploit Framework?",
    "context": "",
    "output": "The meterpreter is an advanced payload in the Metasploit Framework that is accessible through Armitage. It provides post-exploitation capabilities such as command execution, file system interaction, and more.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the meterpreter in the context of Armitage and the Metasploit Framework?",
      "answer": "The meterpreter is an advanced payload in the Metasploit Framework that is accessible through Armitage. It provides post-exploitation capabilities such as command execution, file system interaction, and more.",
      "context": "Armitage (computing)\n\n==Introduction==\nArmitage is a graphical cyber attack management tool for the Metasploit Project that visualizes targets and recommends exploits. It is a free and open source network security tool notable for its contributions to red team collaboration allowing for: shared sessions, data, and communication through a single Metasploit instance. Armitage is written and supported by Raphael Mudge.\n\n== Features ==\nArmitage is a scriptable red team collaboration tool built on top of the Metasploit Framework. Through Armitage, a user may launch scans and exploits, get exploit recommendations, and use the advanced features of the Metasploit Framework's meterpreter."
    }
  },
  {
    "instruction": "LinOTP\n\n==Introduction==\nLinOTP is Linux-based software to manage authentication devices for two-factor authentication with one time passwords. \nIt is implemented as a web service based on the python framework Pylons. Thus it requires a web server to \nrun in.\nLinOTP is mainly developed by the German company KeyIdentity GmbH. Its core components are licensed under the Affero General Public License.\nIt is an open source authentication server certified\nby the OATH initiative for open authentication for its 2.4 version.\n\n\n\n== Overview ==\nAs a web service LinOTP provides a REST-like web API. All functions can be accessed via Pylons controllers. \nResponses are returned as a JSON object.\nLinOTP is designed in a modular way enabling user store modules and token modules. Thus it is capable of supporting a wide range of different tokens.\n\n== Features ==\nSupported tokens:SafeNet eToken Pass\nSafeNet Safeword Alpine\nmOTP\nLost token\nPaper token\nFeitian C-100 (HOTP)\nFeitian]] C-200 (TOTP)\nFeitian C-300 (OCRA)\nFeitian c601 (optical OCRA)\nAuthenex A-Key V 3.6\nYubico Yubikey\nGemalto Ezio Token\nSmartdisplayer\nNagraID 106/103\nNagraID 306 (OCRA)\nBR Token SafeSIGNATURE\nLSE Simple Pass token\nLSE Remote Token\nLSE Radius Token\nLSE Tagespasswort Token\nApps for iPhone and Android like the Google Authenticator\nAny HOTP/ TOTP and OCRA TokenYubikey mass enrollment via CLI\nsupport for token databases like sqlite, mysql, postgresql, oracle, db2\nmanagement via web interface or command line client\nUsers stored in flat files\nPAM module\nSAML\nOpenID\nFreeRADIUS connection via rlm_perl\nSelfservice\nImport of XML Token files\nManagement functions:enroll/assign tokens\nsynchronize, resynchronize, automatic resychronization\nactivate/deactivate/delete tokens\nautoassignment\nlost token scenario\nfind token by OTP value\nget OTP valueDetailed Policies Definitions\nSophisticated Audit API\nMultitenancy\n\n== Source Code ==\nBeing written in Python the program itself comes as the source code.\n\n== Project web site ==\n[1]\nQuestion: How does LinOTP support a wide range of different tokens and what are some of the tokens it supports?",
    "context": "",
    "output": "Answer: LinOTP is designed in a modular way, enabling user store modules and token modules, and it supports a wide range of tokens, including SafeNet eToken Pass, Feitian C-100 (HOTP), Yubico Yubikey, and Authenex A-Key V 3.6, among others.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does LinOTP support a wide range of different tokens and what are some of the tokens it supports?",
      "answer": "LinOTP is designed in a modular way, enabling user store modules and token modules, and it supports a wide range of tokens, including SafeNet eToken Pass, Feitian C-100 (HOTP), Yubico Yubikey, and Authenex A-Key V 3.6, among others.",
      "context": "LinOTP\n\n==Introduction==\nLinOTP is Linux-based software to manage authentication devices for two-factor authentication with one time passwords. \nIt is implemented as a web service based on the python framework Pylons. Thus it requires a web server to \nrun in.\nLinOTP is mainly developed by the German company KeyIdentity GmbH. Its core components are licensed under the Affero General Public License.\nIt is an open source authentication server certified\nby the OATH initiative for open authentication for its 2.4 version.\n\n\n\n== Overview ==\nAs a web service LinOTP provides a REST-like web API. All functions can be accessed via Pylons controllers. \nResponses are returned as a JSON object.\nLinOTP is designed in a modular way enabling user store modules and token modules. Thus it is capable of supporting a wide range of different tokens.\n\n== Features ==\nSupported tokens:SafeNet eToken Pass\nSafeNet Safeword Alpine\nmOTP\nLost token\nPaper token\nFeitian C-100 (HOTP)\nFeitian]] C-200 (TOTP)\nFeitian C-300 (OCRA)\nFeitian c601 (optical OCRA)\nAuthenex A-Key V 3.6\nYubico Yubikey\nGemalto Ezio Token\nSmartdisplayer\nNagraID 106/103\nNagraID 306 (OCRA)\nBR Token SafeSIGNATURE\nLSE Simple Pass token\nLSE Remote Token\nLSE Radius Token\nLSE Tagespasswort Token\nApps for iPhone and Android like the Google Authenticator\nAny HOTP/ TOTP and OCRA TokenYubikey mass enrollment via CLI\nsupport for token databases like sqlite, mysql, postgresql, oracle, db2\nmanagement via web interface or command line client\nUsers stored in flat files\nPAM module\nSAML\nOpenID\nFreeRADIUS connection via rlm_perl\nSelfservice\nImport of XML Token files\nManagement functions:enroll/assign tokens\nsynchronize, resynchronize, automatic resychronization\nactivate/deactivate/delete tokens\nautoassignment\nlost token scenario\nfind token by OTP value\nget OTP valueDetailed Policies Definitions\nSophisticated Audit API\nMultitenancy\n\n== Source Code ==\nBeing written in Python the program itself comes as the source code.\n\n== Project web site ==\n[1]"
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the role of the Central Management System (CMS) in managing security operations at FireEye?",
    "context": "",
    "output": "The Central Management System (CMS) consolidates the management, reporting, and data sharing of Web MPS, Email MPS, File MPS, and Malware Analysis System (MAS) into a single network-based appliance, acting as a distribution hub for malware security intelligence.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of the Central Management System (CMS) in managing security operations at FireEye?",
      "answer": "The Central Management System (CMS) consolidates the management, reporting, and data sharing of Web MPS, Email MPS, File MPS, and Malware Analysis System (MAS) into a single network-based appliance, acting as a distribution hub for malware security intelligence."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is WebScarab's role in the context of web security, and what are its key features?",
    "context": "",
    "output": "WebScarab is an open-source web security testing tool that functions as a proxy, intercepting and modifying web browser requests and server responses. It is capable of recording traffic for later analysis. The tool was developed by The Open Web Application Security Project (OWASP) using Java, making it compatible with multiple operating systems.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is WebScarab's role in the context of web security, and what are its key features?",
      "answer": "WebScarab is an open-source web security testing tool that functions as a proxy, intercepting and modifying web browser requests and server responses. It is capable of recording traffic for later analysis. The tool was developed by The Open Web Application Security Project (OWASP) using Java, making it compatible with multiple operating systems."
    }
  },
  {
    "instruction": "Write an answer to the following question: Which authentication protocols are vulnerable to the pass the hash attack?",
    "context": "",
    "output": "The pass the hash attack can be performed against any server or service that accepts LM or NTLM authentication, regardless of the operating system.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Which authentication protocols are vulnerable to the pass the hash attack?",
      "answer": "The pass the hash attack can be performed against any server or service that accepts LM or NTLM authentication, regardless of the operating system."
    }
  },
  {
    "instruction": "Answer based on context:\n\nKali NetHunter\n\n==Introduction==\nKali NetHunter is a free and open-source mobile penetration testing platform for Android devices, based on Kali Linux. Kali NetHunter is available for un-rooted devices (NetHunter Rootless), for rooted devices that have a standard recovery (NetHunter Lite), and for rooted devices with custom recovery for which a NetHunter specific kernel is available (NetHunter). Official images are published by Offensive Security on their download page and are updated every quarter. NetHunter images with custom kernels are published for the most popular supported devices, such as Google Nexus, Samsung Galaxy and OnePlus. Many more models are supported, and images not published by Offensive Security can be generated using NetHunter build scripts. Kali NetHunter is maintained by a community of volunteers, and is funded by Offensive Security.\n\n== Background and history ==\nVersion 1.1 was released in January 2015 and added support for Oneplus devices & non-English keyboard layouts for HID attacks.Version 1.2 was released in May 2015 and added support for Nexus 9 Android tablets.Version 3.0 was released in January 2016 after a major rewrite of the application, installer, and kernel building framework. This version also introduced support for devices running Android Marshmallow.Version 2019.2 was released in May 2019 and switched to kali-rolling as its Kali Linux container. It adopted the Kali Linux versioning and release cycle to reflect that change. With this release, the number of supported Android devices grew to over 50.Version 2019.3 was released in September 2019 and introduced the NetHunter App Store as the default mechanism for deploying and updating apps.Version 2019.4 was released in December 2019 and premiered the \"Kali NetHunter Desktop Experience.\"Before December 2019, Kali NetHunter was only available for selected Android devices. Installing Kali NetHunter required a device that:\n\nis rooted\nhas a custom recovery\nhad a kernel built especially for Kali NetHunterIn December 2019, \"Kali NetHunter Lite\" and \"Kali NetHunter Rootless\" editions were released to allow users of devices for which no NetHunter specific kernels were available, and users of devices that are not rooted, to install Kali NetHunter with a reduced set of functionality.Version 2020.1 was released on 28 January 2020 and partitioned 3 NetHunter images; NetHunter Rootless, NetHunter Lite, NetHunter Full.Version 2020.2 was released on 12 May 2020 and supported over 160 kernels and 64 devices.Version 2020.3 was released on 18 August 2020 and added Bluetooth Arsenal (It combines a set of bluetooth tools in the Kali NetHunter app with some pre-configured workflows and exciting use cases. You can use your external adapter for reconnaissance, spoofing, listening to and injecting audio into various devices, including speakers, headsets, watches, or even cars.) and supported Nokia 3.1 and Nokia 6.1 phones.Version 2020.4 was released on 18 November 2020 and edited new NetHunter settings menu, added select from different boot animations, and persistent Magisk.\n\n== Features ==\nIn addition to the penetration testing tools included with desktop Kali Linux, NetHunter also enables Wireless 802.11 frame injection, one-click MANA Evil Access Points, HID keyboard functionality (for Teensy-like attacks), as well as BadUSB man-in-the-middle /(MitM) attacks.\n\n== NetHunter App Store ==\nKali Nethunter has an applications store based on a fork of F-Droid with telemetry completely removed. The store has about 42 applications (2021).\n\nHow many kernels are supported by Kali NetHunter as of 2020.2?",
    "context": "",
    "output": "Kali NetHunter supports over 160 kernels as of 2020.2.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How many kernels are supported by Kali NetHunter as of 2020.2?",
      "answer": "Kali NetHunter supports over 160 kernels as of 2020.2.",
      "context": "Kali NetHunter\n\n==Introduction==\nKali NetHunter is a free and open-source mobile penetration testing platform for Android devices, based on Kali Linux. Kali NetHunter is available for un-rooted devices (NetHunter Rootless), for rooted devices that have a standard recovery (NetHunter Lite), and for rooted devices with custom recovery for which a NetHunter specific kernel is available (NetHunter). Official images are published by Offensive Security on their download page and are updated every quarter. NetHunter images with custom kernels are published for the most popular supported devices, such as Google Nexus, Samsung Galaxy and OnePlus. Many more models are supported, and images not published by Offensive Security can be generated using NetHunter build scripts. Kali NetHunter is maintained by a community of volunteers, and is funded by Offensive Security.\n\n== Background and history ==\nVersion 1.1 was released in January 2015 and added support for Oneplus devices & non-English keyboard layouts for HID attacks.Version 1.2 was released in May 2015 and added support for Nexus 9 Android tablets.Version 3.0 was released in January 2016 after a major rewrite of the application, installer, and kernel building framework. This version also introduced support for devices running Android Marshmallow.Version 2019.2 was released in May 2019 and switched to kali-rolling as its Kali Linux container. It adopted the Kali Linux versioning and release cycle to reflect that change. With this release, the number of supported Android devices grew to over 50.Version 2019.3 was released in September 2019 and introduced the NetHunter App Store as the default mechanism for deploying and updating apps.Version 2019.4 was released in December 2019 and premiered the \"Kali NetHunter Desktop Experience.\"Before December 2019, Kali NetHunter was only available for selected Android devices. Installing Kali NetHunter required a device that:\n\nis rooted\nhas a custom recovery\nhad a kernel built especially for Kali NetHunterIn December 2019, \"Kali NetHunter Lite\" and \"Kali NetHunter Rootless\" editions were released to allow users of devices for which no NetHunter specific kernels were available, and users of devices that are not rooted, to install Kali NetHunter with a reduced set of functionality.Version 2020.1 was released on 28 January 2020 and partitioned 3 NetHunter images; NetHunter Rootless, NetHunter Lite, NetHunter Full.Version 2020.2 was released on 12 May 2020 and supported over 160 kernels and 64 devices.Version 2020.3 was released on 18 August 2020 and added Bluetooth Arsenal (It combines a set of bluetooth tools in the Kali NetHunter app with some pre-configured workflows and exciting use cases. You can use your external adapter for reconnaissance, spoofing, listening to and injecting audio into various devices, including speakers, headsets, watches, or even cars.) and supported Nokia 3.1 and Nokia 6.1 phones.Version 2020.4 was released on 18 November 2020 and edited new NetHunter settings menu, added select from different boot animations, and persistent Magisk.\n\n== Features ==\nIn addition to the penetration testing tools included with desktop Kali Linux, NetHunter also enables Wireless 802.11 frame injection, one-click MANA Evil Access Points, HID keyboard functionality (for Teensy-like attacks), as well as BadUSB man-in-the-middle /(MitM) attacks.\n\n== NetHunter App Store ==\nKali Nethunter has an applications store based on a fork of F-Droid with telemetry completely removed. The store has about 42 applications (2021)."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the BS 7799 standard align with other quality standards, and what model does it use for implementation?",
    "context": "",
    "output": "BS 7799-2, which focuses on the implementation of an Information Security Management System (ISMS), aligns with quality standards such as ISO 9000 by adopting the Plan-Do-Check-Act (PDCA) model in its 2002 version. This model, also known as the Deming quality assurance model, is a systematic approach to managing processes and improving product or service quality.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the BS 7799 standard align with other quality standards, and what model does it use for implementation?",
      "answer": "BS 7799-2, which focuses on the implementation of an Information Security Management System (ISMS), aligns with quality standards such as ISO 9000 by adopting the Plan-Do-Check-Act (PDCA) model in its 2002 version. This model, also known as the Deming quality assurance model, is a systematic approach to managing processes and improving product or service quality."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the difference between FIPS 140-2 and FIPS 140-3?",
    "context": "",
    "output": "FIPS 140-3 is the successor to FIPS 140-2, it is a U.S. government computer security standard used to approve cryptographic modules, the main difference is that FIPS 140-3 testing began on September 22, 2020 and FIPS 140-2 testing will be available until September 21, 2021, creating an overlapping transition period of one year.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the difference between FIPS 140-2 and FIPS 140-3?",
      "answer": "FIPS 140-3 is the successor to FIPS 140-2, it is a U.S. government computer security standard used to approve cryptographic modules, the main difference is that FIPS 140-3 testing began on September 22, 2020 and FIPS 140-2 testing will be available until September 21, 2021, creating an overlapping transition period of one year."
    }
  },
  {
    "instruction": "Content sniffing\n\n==Introduction==\nContent sniffing, also known as media type sniffing or MIME sniffing, is the practice of inspecting the content of a byte stream to attempt to deduce the file format of the data within it. Content sniffing is generally used to compensate for a lack of accurate metadata that would otherwise be required to enable the file to be interpreted correctly. Content sniffing techniques tend to use a mixture of techniques that rely on the redundancy found in most file formats: looking for file signatures and magic numbers, and heuristics including searching for well-known representative substrings, the use of byte frequency and n-gram tables, and Bayesian inference.\nMultipurpose Internet Mail Extensions (MIME) sniffing was, and still is, used by some web browsers, including notably Microsoft's Internet Explorer, in an attempt to help web sites which do not correctly signal the MIME type of web content display. However, doing this opens up a serious security vulnerability, in which, by confusing the MIME sniffing algorithm, the browser can be manipulated into interpreting data in a way that allows an attacker to carry out operations that are not expected by either the site operator or user, such as cross-site scripting. Moreover, by making sites which do not correctly assign MIME types to content appear to work correctly in those browsers, it fails to encourage the correct labeling of material, which in turn makes content sniffing necessary for these sites to work, creating a vicious circle of incompatibility with web standards and security best practices.\nA specification exists for media type sniffing in HTML5, which attempts to balance the requirements of security with the need for reverse compatibility with web content with missing or incorrect MIME-type data. It attempts to provide a precise specification that can be used across implementations to implement a single well-defined and deterministic set of behaviors.The UNIX file command can be viewed as a content sniffing application.\n\n\n\n== Charset sniffing ==\n\nNumerous web browsers use a more limited form of content sniffing to attempt to determine the character encoding of text files for which the MIME type is already known. This technique is known as charset sniffing or codepage sniffing and, for certain encodings, may be used to bypass security restrictions too. For instance, Internet Explorer 7 may be tricked to run JScript in circumvention of its policy by allowing the browser to guess that an HTML-file was encoded in UTF-7.\nThis bug is worsened by the feature of the UTF-7 encoding which permits multiple encodings of the same text and, specifically, alternative representations of ASCII characters.\nMost encodings do not allow evasive presentations of ASCII characters, so charset sniffing is less dangerous in general because, due to the historical accident of the ASCII-centric nature of scripting and markup languages, characters outside the ASCII repertoire are more difficult to use to circumvent security boundaries, and mis-interpretations of character sets tend to produce results no worse than the display of mojibake.\n\nWhat is the significance of the ASCII-centric nature of scripting and markup languages in the context of charset sniffing?",
    "context": "",
    "output": "A: The ASCII-centric nature of scripting and markup languages means that characters outside the ASCII repertoire are generally more difficult to use to circumvent security boundaries. Misinterpretations of character sets tend to result in the display of mojibake, which is less dangerous compared to the potential security risks associated with ASCII characters.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the significance of the ASCII-centric nature of scripting and markup languages in the context of charset sniffing?",
      "answer": "The ASCII-centric nature of scripting and markup languages means that characters outside the ASCII repertoire are generally more difficult to use to circumvent security boundaries. Misinterpretations of character sets tend to result in the display of mojibake, which is less dangerous compared to the potential security risks associated with ASCII characters.",
      "context": "Content sniffing\n\n==Introduction==\nContent sniffing, also known as media type sniffing or MIME sniffing, is the practice of inspecting the content of a byte stream to attempt to deduce the file format of the data within it. Content sniffing is generally used to compensate for a lack of accurate metadata that would otherwise be required to enable the file to be interpreted correctly. Content sniffing techniques tend to use a mixture of techniques that rely on the redundancy found in most file formats: looking for file signatures and magic numbers, and heuristics including searching for well-known representative substrings, the use of byte frequency and n-gram tables, and Bayesian inference.\nMultipurpose Internet Mail Extensions (MIME) sniffing was, and still is, used by some web browsers, including notably Microsoft's Internet Explorer, in an attempt to help web sites which do not correctly signal the MIME type of web content display. However, doing this opens up a serious security vulnerability, in which, by confusing the MIME sniffing algorithm, the browser can be manipulated into interpreting data in a way that allows an attacker to carry out operations that are not expected by either the site operator or user, such as cross-site scripting. Moreover, by making sites which do not correctly assign MIME types to content appear to work correctly in those browsers, it fails to encourage the correct labeling of material, which in turn makes content sniffing necessary for these sites to work, creating a vicious circle of incompatibility with web standards and security best practices.\nA specification exists for media type sniffing in HTML5, which attempts to balance the requirements of security with the need for reverse compatibility with web content with missing or incorrect MIME-type data. It attempts to provide a precise specification that can be used across implementations to implement a single well-defined and deterministic set of behaviors.The UNIX file command can be viewed as a content sniffing application.\n\n\n\n== Charset sniffing ==\n\nNumerous web browsers use a more limited form of content sniffing to attempt to determine the character encoding of text files for which the MIME type is already known. This technique is known as charset sniffing or codepage sniffing and, for certain encodings, may be used to bypass security restrictions too. For instance, Internet Explorer 7 may be tricked to run JScript in circumvention of its policy by allowing the browser to guess that an HTML-file was encoded in UTF-7.\nThis bug is worsened by the feature of the UTF-7 encoding which permits multiple encodings of the same text and, specifically, alternative representations of ASCII characters.\nMost encodings do not allow evasive presentations of ASCII characters, so charset sniffing is less dangerous in general because, due to the historical accident of the ASCII-centric nature of scripting and markup languages, characters outside the ASCII repertoire are more difficult to use to circumvent security boundaries, and mis-interpretations of character sets tend to produce results no worse than the display of mojibake."
    }
  },
  {
    "instruction": "Context: Directory traversal attack\n\n==Introduction==\nA directory traversal (or path traversal) is a form of insecure direct object reference where insufficient security validation or sanitization of user-supplied file names can be exploited, such that characters representing \"traverse to parent directory\" are passed through to the operating system's file system API. An affected application can be exploited to gain unauthorized access to the file system.\n\n\n\n== Example ==\nA typical example of a vulnerable application in PHP code is:\n\nAn attack against this system could be to send the following HTTP request:\n\nThe server would then generate a response such as:\n\nThe repeated ../ characters after /home/users/phpguru/templates/ have caused \ninclude() to traverse to the root directory, and then include the Unix password file /etc/passwd.\nUnix /etc/passwd is a common file used to demonstrate directory traversal, as it is often used by crackers to try cracking the passwords. However, in more recent Unix systems, the /etc/passwd file does not contain the hashed passwords, and they are instead located in the /etc/shadow file, which cannot be read by unprivileged users on the machine. Even in that case, though, reading /etc/passwd does still show a list of user accounts.\n\n== Variations ==\nDirectory traversal in its simplest form uses the ../ pattern. Some common variations are listed below:\n\n\n*** Microsoft Windows ***\nMicrosoft Windows and DOS directory traversal uses the ..\\ or ../ patterns.Each partition has a separate root directory (labeled C:\\ where C could be any partition), and there is no common root directory above that. This means that for most directory vulnerabilities on Windows, attacks are limited to a single partition.\nDirectory traversal has been the cause of numerous Microsoft vulnerabilities.\n\n\n*** Percent encoding in URIs ***\nSome web applications attempt to prevent directory traversal by scanning the path of a request URI for patterns such as ../. This check is sometimes mistakenly performed before percent-decoding, causing URIs containing patterns like %2e%2e/ to be accepted despite being decoded into ../ before actual use.\n\n\n**** Double encoding ****\nPercent decoding may accidentally be performed multiple times; once before validation, but again afterwards, making the application vulnerable to Double percent-encoding attacks in which illegal characters are replaced by their double-percent-encoded form in order to bypass security countermeasures. For example, in a double percent-encoding attack, ../ may be replaced by its double-percent-encoded form %252E%252E%252F. This kind of vulnerability notably affected versions 5.0 and earlier of Microsoft's IIS web server software.\n\n\n**** UTF-8 ****\nA badly implemented UTF-8 decoder may accept characters encoded using more bytes than necessary, leading to alternative character representations, such as %2e and %c0%ae both representing .. This is specifically forbidden by the UTF-8 standard, but has still led to directory traversal vulnerabilities in software such as the IIS web server.\n\n\n*** Archives ***\nSome archive formats like zip allow for directory traversal attacks: files in the archive can be written such that they overwrite files on the filesystem by backtracking. Code that extracts archive files can be written to check that the paths of the files in the archive do not engage in path traversal.\n\n== Prevention ==\nA possible algorithm for preventing directory traversal would be to:\n\nProcess URI requests that do not result in a file request, e.g., executing a hook into user code, before continuing below.\nWhen a URI request for a file/directory is to be made, build a full path to the file/directory if it exists, and normalize all characters (e.g., %20 converted to spaces).\nIt is assumed that a 'Document Root' fully qualified, normalized, path is known, and this string has a length N. Assume that no files outside this directory can be served.\nEnsure that the first N characters of the fully qualified path to the requested file is exactly the same as the 'Document Root'.\nIf so, allow the file to be returned.\nIf not, return an error, since the request is clearly out of bounds from what the web-server should be allowed to serve.Using a hard-coded predefined file extension to suffix the path does not necessarily limit the scope of the attack to files of that file extension.\n\nThe user can use the NULL character (indicating the end of the string) in order to bypass everything after the $_GET. (This is PHP-specific.)\n\n== Resources ==\nOpen Web Application Security Project\nThe WASC Threat Classification \u2013 Path Traversal\nPath Traversal Vulnerability Exploitation and Remediation\nCWE Common Weakness Enumeration - Path Traversal\n\nQuestion: What is a possible algorithm for preventing directory traversal attacks?\n\nAnswer:",
    "context": "",
    "output": "A possible algorithm for preventing directory traversal attacks involves processing URI requests before continuing, building a full path to the file/directory, normalizing all characters, ensuring that the first N characters of the fully qualified path are exactly the same as the 'Document Root', and returning an error if the request is out of bounds.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is a possible algorithm for preventing directory traversal attacks?",
      "answer": "A possible algorithm for preventing directory traversal attacks involves processing URI requests before continuing, building a full path to the file/directory, normalizing all characters, ensuring that the first N characters of the fully qualified path are exactly the same as the 'Document Root', and returning an error if the request is out of bounds.",
      "context": "Directory traversal attack\n\n==Introduction==\nA directory traversal (or path traversal) is a form of insecure direct object reference where insufficient security validation or sanitization of user-supplied file names can be exploited, such that characters representing \"traverse to parent directory\" are passed through to the operating system's file system API. An affected application can be exploited to gain unauthorized access to the file system.\n\n\n\n== Example ==\nA typical example of a vulnerable application in PHP code is:\n\nAn attack against this system could be to send the following HTTP request:\n\nThe server would then generate a response such as:\n\nThe repeated ../ characters after /home/users/phpguru/templates/ have caused \ninclude() to traverse to the root directory, and then include the Unix password file /etc/passwd.\nUnix /etc/passwd is a common file used to demonstrate directory traversal, as it is often used by crackers to try cracking the passwords. However, in more recent Unix systems, the /etc/passwd file does not contain the hashed passwords, and they are instead located in the /etc/shadow file, which cannot be read by unprivileged users on the machine. Even in that case, though, reading /etc/passwd does still show a list of user accounts.\n\n== Variations ==\nDirectory traversal in its simplest form uses the ../ pattern. Some common variations are listed below:\n\n\n*** Microsoft Windows ***\nMicrosoft Windows and DOS directory traversal uses the ..\\ or ../ patterns.Each partition has a separate root directory (labeled C:\\ where C could be any partition), and there is no common root directory above that. This means that for most directory vulnerabilities on Windows, attacks are limited to a single partition.\nDirectory traversal has been the cause of numerous Microsoft vulnerabilities.\n\n\n*** Percent encoding in URIs ***\nSome web applications attempt to prevent directory traversal by scanning the path of a request URI for patterns such as ../. This check is sometimes mistakenly performed before percent-decoding, causing URIs containing patterns like %2e%2e/ to be accepted despite being decoded into ../ before actual use.\n\n\n**** Double encoding ****\nPercent decoding may accidentally be performed multiple times; once before validation, but again afterwards, making the application vulnerable to Double percent-encoding attacks in which illegal characters are replaced by their double-percent-encoded form in order to bypass security countermeasures. For example, in a double percent-encoding attack, ../ may be replaced by its double-percent-encoded form %252E%252E%252F. This kind of vulnerability notably affected versions 5.0 and earlier of Microsoft's IIS web server software.\n\n\n**** UTF-8 ****\nA badly implemented UTF-8 decoder may accept characters encoded using more bytes than necessary, leading to alternative character representations, such as %2e and %c0%ae both representing .. This is specifically forbidden by the UTF-8 standard, but has still led to directory traversal vulnerabilities in software such as the IIS web server.\n\n\n*** Archives ***\nSome archive formats like zip allow for directory traversal attacks: files in the archive can be written such that they overwrite files on the filesystem by backtracking. Code that extracts archive files can be written to check that the paths of the files in the archive do not engage in path traversal.\n\n== Prevention ==\nA possible algorithm for preventing directory traversal would be to:\n\nProcess URI requests that do not result in a file request, e.g., executing a hook into user code, before continuing below.\nWhen a URI request for a file/directory is to be made, build a full path to the file/directory if it exists, and normalize all characters (e.g., %20 converted to spaces).\nIt is assumed that a 'Document Root' fully qualified, normalized, path is known, and this string has a length N. Assume that no files outside this directory can be served.\nEnsure that the first N characters of the fully qualified path to the requested file is exactly the same as the 'Document Root'.\nIf so, allow the file to be returned.\nIf not, return an error, since the request is clearly out of bounds from what the web-server should be allowed to serve.Using a hard-coded predefined file extension to suffix the path does not necessarily limit the scope of the attack to files of that file extension.\n\nThe user can use the NULL character (indicating the end of the string) in order to bypass everything after the $_GET. (This is PHP-specific.)\n\n== Resources ==\nOpen Web Application Security Project\nThe WASC Threat Classification \u2013 Path Traversal\nPath Traversal Vulnerability Exploitation and Remediation\nCWE Common Weakness Enumeration - Path Traversal"
    }
  },
  {
    "instruction": "Write an answer to the following question: In the context of the red/black concept, what is the difference between encrypted information and plaintext information?",
    "context": "",
    "output": "Encrypted information, or ciphertext, is the result of encrypting plaintext information using a cryptographic algorithm and a key.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "In the context of the red/black concept, what is the difference between encrypted information and plaintext information?",
      "answer": "Encrypted information, or ciphertext, is the result of encrypting plaintext information using a cryptographic algorithm and a key."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the use of a Trusted Platform Module (TPM) affect disk encryption?",
    "context": "",
    "output": "A limited number of disk encryption solutions have support for TPM, which can wrap the decryption key using the TPM and tie the hard disk drive to a particular device. This can prevent the disk from being accessed if it is removed from the device, but it can also create a single point of failure if something happens to the TPM or the motherboard.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the use of a Trusted Platform Module (TPM) affect disk encryption?",
      "answer": "A limited number of disk encryption solutions have support for TPM, which can wrap the decryption key using the TPM and tie the hard disk drive to a particular device. This can prevent the disk from being accessed if it is removed from the device, but it can also create a single point of failure if something happens to the TPM or the motherboard."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the role of PCH's board of directors, and who are its members?",
    "context": "",
    "output": "PCH's board of directors consists of Steve Feldman (chairman), Dorian Kim, and Bill Woodcock (executive director). They provide strategic direction and oversight for the organization.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of PCH's board of directors, and who are its members?",
      "answer": "PCH's board of directors consists of Steve Feldman (chairman), Dorian Kim, and Bill Woodcock (executive director). They provide strategic direction and oversight for the organization."
    }
  },
  {
    "instruction": "Write an answer to the following question: How is Hashcash used in building reputation in a digital marketplace?",
    "context": "",
    "output": "In a digital marketplace, service providers can use hashcash to build reputation to attract clients. To build reputation, a service provider first selects a public key as its ID, and then discovers by brute force a nonce that, when concatenated to the ID, results in a hash digest with several leading zeros. The more zeros, the higher the reputation.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How is Hashcash used in building reputation in a digital marketplace?",
      "answer": "In a digital marketplace, service providers can use hashcash to build reputation to attract clients. To build reputation, a service provider first selects a public key as its ID, and then discovers by brute force a nonce that, when concatenated to the ID, results in a hash digest with several leading zeros. The more zeros, the higher the reputation."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the function of Zfone's \"bump on the wire\" and how does it interact with existing VoIP clients?",
    "context": "",
    "output": "Zfone's \"bump on the wire\" acts as a barrier between the VoIP client and the Internet, intercepting and filtering all VoIP packets as they go in and out of the machine. It works in conjunction with existing SIP- and RTP-compliant VoIP programs, turning them into secure phones.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the function of Zfone's \"bump on the wire\" and how does it interact with existing VoIP clients?",
      "answer": "Zfone's \"bump on the wire\" acts as a barrier between the VoIP client and the Internet, intercepting and filtering all VoIP packets as they go in and out of the machine. It works in conjunction with existing SIP- and RTP-compliant VoIP programs, turning them into secure phones."
    }
  },
  {
    "instruction": "Crypt (Unix)\n\n==Introduction==\nIn Unix computing, crypt or enigma is a utility program used for encryption.  Due to the ease of breaking it, it is considered to be obsolete.\nThe program is usually used as a filter, and it has traditionally been implemented using a \"rotor machine\" algorithm based on the Enigma machine. It is considered to be cryptographically far too weak to provide any security against brute-force attacks by modern, commodity personal computers.Some versions of Unix shipped with an even weaker version of the crypt(1) command in order to comply with contemporaneous laws and regulations that limited the exportation of cryptographic software. Some of these were simply implementations of the Caesar cipher (effectively no more secure than ROT13, which is implemented as a Caesar cipher with a well-known key).\n\n\n\n== Crypt(1) under Linux ==\nLinux distributions generally do not include a Unix compatible version of the crypt command. This is largely due to a combination of three major factors:\n\ncrypt is relatively obscure and rarely used for e-mail attachments nor as a file format\ncrypt is considered to be cryptographically far too weak to withstand brute-force attacks by modern computing systems (Linux systems generally ship with GNU Privacy Guard which is considered to be reasonably secure by modern standards)\nDuring the early years of Linux development and adoption there was some concern that even as weak as the algorithm used by crypt was, that it might still run afoul of ITAR's export controls; so mainstream distribution developers in the United States generally excluded it, leaving their customers to fetch GnuPG or other strong cryptographic software from international sites, sometimes providing packages or scripts to automate that process.The source code to several old versions of the crypt command is available in The Unix Heritage Society's Unix Archive. The recent crypt source code is available in the OpenSolaris project. A public domain version is available from the Crypt Breaker's Workbench.\nEnhanced symmetric encryption utilities are available for Linux (and should also be portable to any other Unix-like system) including mcrypt and ccrypt.  While these provide support for much more sophisticated and modern algorithms, they can be used to encrypt and decrypt files which are compatible with the traditional crypt(1) command by providing the correct command line options.\n\n== Breaking crypt(1) encryption ==\nPrograms for breaking crypt(1) encryption are widely available. Bob Baldwin's public domain Crypt Breaker's Workbench, which was written in 1984-1985, is an interactive tool that provides successive plaintext guesses that must be corrected by the user. It also provides a working crypt(1) implementation used by modern BSD distributions.Peter Selinger's unixcrypt-breaker uses a simple statistical model similar to a dictionary-attack that takes a set of plain texts as input and processes it to guess plausible plaintexts, and does not require user interaction.\n\n== Relationship to password hash function ==\nThere is also a Unix password hash function with the same name, crypt. Though both are used for securing data in some sense, they are otherwise essentially unrelated. To distinguish between the two, writers often refer to the utility program as crypt(1), because it is documented in section 1 of the Unix manual pages, and refer to the password hash function as crypt(3), because its documentation is in section 3 of the manual.\n\nAnswer this question based on the above context: Why is the crypt utility program considered to be cryptographically weak?",
    "context": "",
    "output": "The crypt utility program is considered to be cryptographically weak because it can be easily broken into by modern computing systems, making it vulnerable to brute-force attacks.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Why is the crypt utility program considered to be cryptographically weak?",
      "answer": "The crypt utility program is considered to be cryptographically weak because it can be easily broken into by modern computing systems, making it vulnerable to brute-force attacks.",
      "context": "Crypt (Unix)\n\n==Introduction==\nIn Unix computing, crypt or enigma is a utility program used for encryption.  Due to the ease of breaking it, it is considered to be obsolete.\nThe program is usually used as a filter, and it has traditionally been implemented using a \"rotor machine\" algorithm based on the Enigma machine. It is considered to be cryptographically far too weak to provide any security against brute-force attacks by modern, commodity personal computers.Some versions of Unix shipped with an even weaker version of the crypt(1) command in order to comply with contemporaneous laws and regulations that limited the exportation of cryptographic software. Some of these were simply implementations of the Caesar cipher (effectively no more secure than ROT13, which is implemented as a Caesar cipher with a well-known key).\n\n\n\n== Crypt(1) under Linux ==\nLinux distributions generally do not include a Unix compatible version of the crypt command. This is largely due to a combination of three major factors:\n\ncrypt is relatively obscure and rarely used for e-mail attachments nor as a file format\ncrypt is considered to be cryptographically far too weak to withstand brute-force attacks by modern computing systems (Linux systems generally ship with GNU Privacy Guard which is considered to be reasonably secure by modern standards)\nDuring the early years of Linux development and adoption there was some concern that even as weak as the algorithm used by crypt was, that it might still run afoul of ITAR's export controls; so mainstream distribution developers in the United States generally excluded it, leaving their customers to fetch GnuPG or other strong cryptographic software from international sites, sometimes providing packages or scripts to automate that process.The source code to several old versions of the crypt command is available in The Unix Heritage Society's Unix Archive. The recent crypt source code is available in the OpenSolaris project. A public domain version is available from the Crypt Breaker's Workbench.\nEnhanced symmetric encryption utilities are available for Linux (and should also be portable to any other Unix-like system) including mcrypt and ccrypt.  While these provide support for much more sophisticated and modern algorithms, they can be used to encrypt and decrypt files which are compatible with the traditional crypt(1) command by providing the correct command line options.\n\n== Breaking crypt(1) encryption ==\nPrograms for breaking crypt(1) encryption are widely available. Bob Baldwin's public domain Crypt Breaker's Workbench, which was written in 1984-1985, is an interactive tool that provides successive plaintext guesses that must be corrected by the user. It also provides a working crypt(1) implementation used by modern BSD distributions.Peter Selinger's unixcrypt-breaker uses a simple statistical model similar to a dictionary-attack that takes a set of plain texts as input and processes it to guess plausible plaintexts, and does not require user interaction.\n\n== Relationship to password hash function ==\nThere is also a Unix password hash function with the same name, crypt. Though both are used for securing data in some sense, they are otherwise essentially unrelated. To distinguish between the two, writers often refer to the utility program as crypt(1), because it is documented in section 1 of the Unix manual pages, and refer to the password hash function as crypt(3), because its documentation is in section 3 of the manual."
    }
  },
  {
    "instruction": "Write an answer to the following question: How can the privacy paradox intertwine with the nothing to hide claim on SNS?",
    "context": "",
    "output": "The privacy paradox intertwines with the nothing to hide claim because individuals believe privacy is important but do not believe a privacy-related incident will happen to them over others. This concept offers an explanation for why individuals may be complacent in privacy setting management.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can the privacy paradox intertwine with the nothing to hide claim on SNS?",
      "answer": "The privacy paradox intertwines with the nothing to hide claim because individuals believe privacy is important but do not believe a privacy-related incident will happen to them over others. This concept offers an explanation for why individuals may be complacent in privacy setting management."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the recommended salt length for PBKDF2 according to the public key cryptography standard?",
    "context": "",
    "output": "The public key cryptography standard recommends a salt length of at least 64 bits for PBKDF2.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the recommended salt length for PBKDF2 according to the public key cryptography standard?",
      "answer": "The public key cryptography standard recommends a salt length of at least 64 bits for PBKDF2."
    }
  },
  {
    "instruction": "Write an answer to the following question: Who organizes the annual OSSEC Conference, and when was the most recent one held?",
    "context": "",
    "output": "Atomicorp organizes the annual OSSEC Conference. The most recent one, OSSEC Con 2019, was held in March 20-21st outside Washington DC.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Who organizes the annual OSSEC Conference, and when was the most recent one held?",
      "answer": "Atomicorp organizes the annual OSSEC Conference. The most recent one, OSSEC Con 2019, was held in March 20-21st outside Washington DC."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does CryptoVerif determine the probability of a successful attack against a protocol?",
    "context": "",
    "output": "CryptoVerif calculates the probability of a successful attack against a protocol by comparing it to the probability of breaking each cryptographic primitive used in the protocol.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does CryptoVerif determine the probability of a successful attack against a protocol?",
      "answer": "CryptoVerif calculates the probability of a successful attack against a protocol by comparing it to the probability of breaking each cryptographic primitive used in the protocol."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are some common disaster recovery strategies?",
    "context": "",
    "output": "Some common disaster recovery strategies include backups to tape and sent off-site, backups to disk on-site or off-site, replication off-site, private cloud solutions, and hybrid cloud solutions. Precautionary strategies may also include local mirrors of systems and/or data and use of disk protection technology such as RAID, surge protectors, use of an uninterruptible power supply (UPS) and/or backup generator, fire prevention/mitigation systems, and anti-virus software and other security measures.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are some common disaster recovery strategies?",
      "answer": "Some common disaster recovery strategies include backups to tape and sent off-site, backups to disk on-site or off-site, replication off-site, private cloud solutions, and hybrid cloud solutions. Precautionary strategies may also include local mirrors of systems and/or data and use of disk protection technology such as RAID, surge protectors, use of an uninterruptible power supply (UPS) and/or backup generator, fire prevention/mitigation systems, and anti-virus software and other security measures."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is a hardware kill switch and how does it work?",
    "context": "",
    "output": "A hardware kill switch (HKS) is a physical switch that cuts the signal or power line to the device or disable the chip running them. This provides a way to quickly and easily disable a device, preventing any unauthorized access or operation.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is a hardware kill switch and how does it work?",
      "answer": "A hardware kill switch (HKS) is a physical switch that cuts the signal or power line to the device or disable the chip running them. This provides a way to quickly and easily disable a device, preventing any unauthorized access or operation."
    }
  },
  {
    "instruction": "Write an answer to the following question: What security measures does Wizard Spider employ in their operations, and how do they handle their victims?",
    "context": "",
    "output": "Wizard Spider is very security conscious, not openly advertising on the darknet and only working with or selling access to trusted criminals. They belittle their victims via a leak site and publish stolen data.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What security measures does Wizard Spider employ in their operations, and how do they handle their victims?",
      "answer": "Wizard Spider is very security conscious, not openly advertising on the darknet and only working with or selling access to trusted criminals. They belittle their victims via a leak site and publish stolen data."
    }
  },
  {
    "instruction": "Write an answer to the following question: Why are ICMP DESTINATION UNREACHABLE messages that may be created by routers in response to the server's ICMP ECHO REQUEST messages ignored by the server in the ICMP hole punching method proposed by Samy Kamkar?",
    "context": "",
    "output": "In the ICMP hole punching method proposed by Samy Kamkar, ICMP DESTINATION UNREACHABLE messages that may be created by routers in response to the server's ICMP ECHO REQUEST messages are ignored by the server because the IP address 1.2.3.4 is not allocated and the ICMP REQUEST will not be routed by routers without a default route.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Why are ICMP DESTINATION UNREACHABLE messages that may be created by routers in response to the server's ICMP ECHO REQUEST messages ignored by the server in the ICMP hole punching method proposed by Samy Kamkar?",
      "answer": "In the ICMP hole punching method proposed by Samy Kamkar, ICMP DESTINATION UNREACHABLE messages that may be created by routers in response to the server's ICMP ECHO REQUEST messages are ignored by the server because the IP address 1.2.3.4 is not allocated and the ICMP REQUEST will not be routed by routers without a default route."
    }
  },
  {
    "instruction": "Write an answer to the following question: Which platforms are officially supported by ClamAV?",
    "context": "",
    "output": "ClamAV is officially available for Linux, BSD, macOS, OpenVMS, Windows, and OS/2 (including eComStation and ArcaOS) platforms.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Which platforms are officially supported by ClamAV?",
      "answer": "ClamAV is officially available for Linux, BSD, macOS, OpenVMS, Windows, and OS/2 (including eComStation and ArcaOS) platforms."
    }
  },
  {
    "instruction": "Cross-site cooking\n\n==Introduction==\nCross-site cooking is a type of browser exploit which allows a site attacker to set a cookie for a browser into the cookie domain of another site server.\nCross-site cooking can be used to perform session fixation attacks, as a malicious site can fixate the session identifier cookie of another site. \nOther attack scenarios may also be possible, for example: attacker may know of a security vulnerability in server, which is exploitable using a cookie. But if this security vulnerability requires e.g. an administrator password which attacker does not know, cross-site cooking could be used to fool innocent users to unintentionally perform the attack.\nCross site. Cross-site cooking is similar in concept to cross-site scripting, cross-site request forgery, cross-site tracing, cross-zone scripting etc., in that it involves the ability to move data or code between different web sites (or in some cases, between e-mail / instant messages and sites). These problems are linked to the fact that a web browser is a shared platform for different information / applications / sites. Only logical security boundaries maintained by browsers ensures that one site cannot corrupt or steal data from another. However a browser exploit such as cross-site cooking can be used to move things across the logical security boundaries.\n\n\n\n== Origins ==\nThe name cross-site cooking and concept was presented by Micha\u0142 Zalewski in 2006. The name is a mix of \"cookie\" and \"cross-site\", attempting to describe the nature of cookies being set across sites.\nIn Micha\u0142 Zalewski's article of 2006, Benjamin Franz was credited for his discovery, who in May 1998 reported a cookie domain related vulnerability to vendors. Benjamin Franz published the vulnerability and discussed it mainly as a way to circumvent \"privacy protection\" mechanisms in popular browsers.  Micha\u0142 Zalewski concluded that the bug, 8 years later, was still present (unresolved) in some browsers and could be exploited for cross-site cooking. Various remarks such as \"vendors [...] certainly are not in a hurry to fix this\" were made by Zalewski and others.\n\nHow can cross-site cooking be used to exploit security vulnerabilities that require privileged access?",
    "context": "",
    "output": "A: Cross-site cooking can be used to exploit security vulnerabilities that require privileged access by allowing a site attacker to set cookies for a browser within the cookie domain of another site server. This can be used to fool innocent users into performing actions that seem innocent, but actually allow the attacker to exploit security vulnerabilities that require privileged access, such as accessing sensitive data or executing code.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can cross-site cooking be used to exploit security vulnerabilities that require privileged access?",
      "answer": "Cross-site cooking can be used to exploit security vulnerabilities that require privileged access by allowing a site attacker to set cookies for a browser within the cookie domain of another site server. This can be used to fool innocent users into performing actions that seem innocent, but actually allow the attacker to exploit security vulnerabilities that require privileged access, such as accessing sensitive data or executing code.",
      "context": "Cross-site cooking\n\n==Introduction==\nCross-site cooking is a type of browser exploit which allows a site attacker to set a cookie for a browser into the cookie domain of another site server.\nCross-site cooking can be used to perform session fixation attacks, as a malicious site can fixate the session identifier cookie of another site. \nOther attack scenarios may also be possible, for example: attacker may know of a security vulnerability in server, which is exploitable using a cookie. But if this security vulnerability requires e.g. an administrator password which attacker does not know, cross-site cooking could be used to fool innocent users to unintentionally perform the attack.\nCross site. Cross-site cooking is similar in concept to cross-site scripting, cross-site request forgery, cross-site tracing, cross-zone scripting etc., in that it involves the ability to move data or code between different web sites (or in some cases, between e-mail / instant messages and sites). These problems are linked to the fact that a web browser is a shared platform for different information / applications / sites. Only logical security boundaries maintained by browsers ensures that one site cannot corrupt or steal data from another. However a browser exploit such as cross-site cooking can be used to move things across the logical security boundaries.\n\n\n\n== Origins ==\nThe name cross-site cooking and concept was presented by Micha\u0142 Zalewski in 2006. The name is a mix of \"cookie\" and \"cross-site\", attempting to describe the nature of cookies being set across sites.\nIn Micha\u0142 Zalewski's article of 2006, Benjamin Franz was credited for his discovery, who in May 1998 reported a cookie domain related vulnerability to vendors. Benjamin Franz published the vulnerability and discussed it mainly as a way to circumvent \"privacy protection\" mechanisms in popular browsers.  Micha\u0142 Zalewski concluded that the bug, 8 years later, was still present (unresolved) in some browsers and could be exploited for cross-site cooking. Various remarks such as \"vendors [...] certainly are not in a hurry to fix this\" were made by Zalewski and others."
    }
  },
  {
    "instruction": "Context: Information security\n\n==Introduction==\nInformation security, sometimes shortened to InfoSec, is the practice of protecting information by mitigating information risks. It is part of information risk management. It typically involves preventing or reducing the probability of unauthorized/inappropriate access to data, or the unlawful use, disclosure, disruption, deletion, corruption, modification, inspection, recording, or devaluation of information. It also involves actions intended to reduce the adverse impacts of such incidents. Protected information may take any form, e.g. electronic or physical, tangible (e.g. paperwork) or intangible (e.g. knowledge). Information security's primary focus is the balanced protection of the data confidentiality, data integrity, and data availability of data (also known as the CIA triad) while maintaining a focus on efficient policy implementation, all without hampering organization productivity. This is largely achieved through a structured risk management process that involves: \n\nidentifying information and related assets, plus potential threats, vulnerabilities, and impacts;\nevaluating the risks\ndeciding how to address or treat the risks i.e. to avoid, mitigate, share or accept them\nwhere risk mitigation is required, selecting or designing appropriate security controls and implementing them\nmonitoring the activities, making adjustments as necessary to address any issues, changes and improvement opportunitiesTo standardize this discipline, academics and professionals collaborate to offer guidance, policies, and industry standards on password, antivirus software, firewall, encryption software, legal liability, security awareness and training, and so forth. This standardization may be further driven by a wide variety of laws and regulations that affect how data is accessed, processed, stored, transferred and destroyed. However, the implementation of any standards and guidance within an entity may have limited effect if a culture of continual improvement is not adopted.\n\n\n\n== Definition ==\n\nVarious definitions of information security are suggested below, summarized from different sources:\n\n\"Preservation of confidentiality, integrity and availability of information. Note: In addition, other properties, such as authenticity, accountability, non-repudiation and reliability can also be involved.\" (ISO/IEC 27000:2009)\n\"The protection of information and information systems from unauthorized access, use, disclosure, disruption, modification, or destruction in order to provide confidentiality, integrity, and availability.\" (CNSS, 2010)\n\"Ensures that only authorized users (confidentiality) have access to accurate and complete information (integrity) when required (availability).\" (ISACA, 2008)\n\"Information Security is the process of protecting the intellectual property of an organisation.\"  (Pipkin, 2000)\n\"...information security is a risk management discipline, whose job is to manage the cost of information risk to the business.\" (McDermott and Geer, 2001)\n\"A well-informed sense of assurance that information risks and controls are in balance.\" (Anderson, J., 2003)\n\"Information security is the protection of information and minimizes the risk of exposing information to unauthorized parties.\" (Venter and Eloff, 2003)\n\"Information Security is a multidisciplinary area of study and professional activity which is concerned with the development and implementation of security mechanisms of all available types (technical, organizational, human-oriented and legal) in order to keep information in all its locations (within and outside the organization's perimeter) and, consequently, information systems, where information is created, processed, stored, transmitted and destroyed, free from threats. Threats to information and information systems may be categorized and a corresponding security goal may be defined for each category of threats. A set of security goals, identified as a result of a threat analysis, should be revised periodically to ensure its adequacy and conformance with the evolving environment. The currently relevant set of security goals may include: confidentiality, integrity, availability, privacy, authenticity & trustworthiness, non-repudiation, accountability and auditability.\" (Cherdantseva and Hilton, 2013)\nInformation and information resource security using telecommunication system or devices means protecting information, information systems or books from unauthorized access, damage, theft, or destruction (Kurose and Ross, 2010).\n\n== Overview ==\nAt the core of information security is information assurance, the act of maintaining the confidentiality, integrity, and availability (CIA) of information, ensuring that information is not compromised in any way when critical issues arise. These issues include but are not limited to natural disasters, computer/server malfunction, and physical theft. While paper-based business operations are still prevalent, requiring their own set of information security practices, enterprise digital initiatives are increasingly being emphasized, with information assurance now typically being dealt with by information technology (IT) security specialists. These specialists apply information security to technology (most often some form of computer system). It is worthwhile to note that a computer does not necessarily mean a home desktop. A computer is any device with a processor and some memory. Such devices can range from non-networked standalone devices as simple as calculators, to networked mobile computing devices such as smartphones and tablet computers. IT security specialists are almost always found in any major enterprise/establishment due to the nature and value of the data within larger businesses. They are responsible for keeping all of the technology within the company secure from malicious cyber attacks that often attempt to acquire critical private information or gain control of the internal systems.The field of information security has grown and evolved significantly in recent years. It offers many areas for specialization, including securing networks and allied infrastructure, securing applications and databases, security testing, information systems auditing, business continuity planning, electronic record discovery, and digital forensics. Information security professionals are very stable in their employment. As of 2013 more than 80 percent of professionals had no change in employer or employment over a period of a year, and the number of professionals is projected to continuously grow more than 11 percent annually from 2014 to 2019.\n\n\n*** Threats ***\nInformation security threats come in many different forms. Some of the most common threats today are software attacks, theft of intellectual property, theft of identity, theft of equipment or information, sabotage, and information extortion. Viruses, worms, phishing attacks, and Trojan horses are a few common examples of software attacks. The theft of intellectual property has also been an extensive issue for many businesses in the information technology (IT) field. Identity theft is the attempt to act as someone else usually to obtain that person's personal information or to take advantage of their access to vital information through social engineering. Theft of equipment or information is becoming more prevalent today due to the fact that most devices today are mobile, are prone to theft and have also become far more desirable as the amount of data capacity increases. Sabotage usually consists of the destruction of an organization's website in an attempt to cause loss of confidence on the part of its customers. Information extortion consists of theft of a company's property or information as an attempt to receive a payment in exchange for returning the information or property back to its owner, as with ransomware. There are many ways to help protect yourself from some of these attacks but one of the most functional precautions is conduct periodical user awareness. The number one threat to any organisation are users or internal employees, they are also called insider threats.Governments, military, corporations, financial institutions, hospitals, non-profit organisations, and private businesses amass a great deal of confidential information about their employees, customers, products, research, and financial status. Should confidential information about a business's customers or finances or new product line fall into the hands of a competitor or a black hat hacker, a business and its customers could suffer widespread, irreparable financial loss, as well as damage to the company's reputation. From a business perspective, information security must be balanced against cost; the Gordon-Loeb Model provides a mathematical economic approach for addressing this concern.For the individual, information security has a significant effect on privacy, which is viewed very differently in various cultures.\n\n\n**** Responses to threats ****\nPossible responses to a security threat or risk are:\nreduce/mitigate \u2013 implement safeguards and countermeasures to eliminate vulnerabilities or block threats\nassign/transfer \u2013 place the cost of the threat onto another entity or organization such as purchasing insurance or outsourcing\naccept \u2013 evaluate if the cost of the countermeasure outweighs the possible cost of loss due to the threat\n\n== Basic principles ==\n\n\n*** Key concepts ***\n\nThe CIA triad of confidentiality, integrity, and availability is at the heart of information security. (The members of the classic InfoSec triad\u2014confidentiality, integrity, and availability\u2014are interchangeably referred to in the literature as security attributes, properties, security goals, fundamental aspects, information criteria, critical information characteristics and basic building blocks.) However, debate continues about whether or not this CIA triad is sufficient to address rapidly changing technology and business requirements, with recommendations to consider expanding on the intersections between availability and confidentiality, as well as the relationship between security and privacy. Other principles such as \"accountability\" have sometimes been proposed; it has been pointed out that issues such as non-repudiation do not fit well within the three core concepts.The triad seems to have first been mentioned in a NIST publication in 1977.In 1992 and revised in 2002, the OECD's Guidelines for the Security of Information Systems and Networks proposed the nine generally accepted principles: awareness, responsibility, response, ethics, democracy, risk assessment, security design and implementation, security management, and reassessment. Building upon those, in 2004 the NIST's Engineering Principles for Information Technology Security proposed 33 principles. From each of these derived guidelines and practices.\nIn 1998, Donn Parker proposed an alternative model for the classic CIA triad that he called the six atomic elements of information. The elements are confidentiality, possession, integrity, authenticity, availability, and utility. The merits of the Parkerian Hexad are a subject of debate amongst security professionals.In 2011, The Open Group published the information security management standard O-ISM3. This standard proposed an operational definition of the key concepts of security, with elements called \"security objectives\", related to access control (9), availability (3), data quality (1), compliance, and technical (4). In 2009, DoD Software Protection Initiative Archived 2016-09-25 at the Wayback Machine released the Three Tenets of Cybersecurity Archived 2020-05-10 at the Wayback Machine which are System Susceptibility, Access to the Flaw, and Capability to Exploit the Flaw. Neither of these models are widely adopted.\n\n\n**** Confidentiality ****\nIn information security, confidentiality \"is the property, that information is not made available or disclosed to unauthorized individuals, entities, or processes.\" While similar to \"privacy,\" the two words are not interchangeable. Rather, confidentiality is a component of privacy that implements to protect our data from unauthorized viewers. Examples of confidentiality of electronic data being compromised include laptop theft, password theft, or sensitive emails being sent to the incorrect individuals.\n\n\n**** Integrity ****\nIn IT security, data integrity means maintaining and assuring the accuracy and completeness of data over its entire lifecycle. This means that data cannot be modified in an unauthorized or undetected manner. This is not the same thing as referential integrity in databases, although it can be viewed as a special case of consistency as understood in the classic ACID model of transaction processing. Information security systems typically incorporate controls to ensure their own integrity, in particular protecting the kernel or core functions against both deliberate and accidental threats. Multi-purpose and multi-user computer systems aim to compartmentalize the data and processing such that no user or process can adversely impact another: the controls may not succeed however, as we see in incidents such as malware infections, hacks, data theft, fraud, and privacy breaches.More broadly, integrity is an information security principle that involves human/social, process, and commercial integrity, as well as data integrity. As such it touches on aspects such as credibility, consistency, truthfulness, completeness, accuracy, timeliness, and assurance.\n\n\n**** Availability ****\nFor any information system to serve its purpose, the information must be available when it is needed. This means the computing systems used to store and process the information, the security controls used to protect it, and the communication channels used to access it must be functioning correctly. High availability systems aim to remain available at all times, preventing service disruptions due to power outages, hardware failures, and system upgrades. Ensuring availability also involves preventing denial-of-service attacks, such as a flood of incoming messages to the target system, essentially forcing it to shut down.In the realm of information security, availability can often be viewed as one of the most important parts of a successful information security program. Ultimately end-users need to be able to perform job functions; by ensuring availability an organization is able to perform to the standards that an organization's stakeholders expect. This can involve topics such as proxy configurations, outside web access, the ability to access shared drives and the ability to send emails. Executives oftentimes do not understand the technical side of information security and look at availability as an easy fix, but this often requires collaboration from many different organizational teams, such as network operations, development operations, incident response, and policy/change management. A successful information security team involves many different key roles to mesh and align for the CIA triad to be provided effectively.\n\n\n**** Non-repudiation ****\nIn law, non-repudiation implies one's intention to fulfill their obligations to a contract. It also implies that one party of a transaction cannot deny having received a transaction, nor can the other party deny having sent a transaction.It is important to note that while technology such as cryptographic systems can assist in non-repudiation efforts, the concept is at its core a legal concept transcending the realm of technology. It is not, for instance, sufficient to show that the message matches a digital signature signed with the sender's private key, and thus only the sender could have sent the message, and nobody else could have altered it in transit (data integrity). The alleged sender could in return demonstrate that the digital signature algorithm is vulnerable or flawed, or allege or prove that his signing key has been compromised. The fault for these violations may or may not lie with the sender, and such assertions may or may not relieve the sender of liability, but the assertion would invalidate the claim that the signature necessarily proves authenticity and integrity. As such, the sender may repudiate the message (because authenticity and integrity are pre-requisites for non-repudiation).\n\n== Risk management ==\n\nBroadly speaking, risk is the likelihood that something bad will happen that causes harm to an informational asset (or the loss of the asset). A vulnerability is a weakness that could be used to endanger or cause harm to an informational asset. A threat is anything (man-made or act of nature) that has the potential to cause harm. The likelihood that a threat will use a vulnerability to cause harm creates a risk. When a threat does use a vulnerability to inflict harm, it has an impact. In the context of information security, the impact is a loss of availability, integrity, and confidentiality, and possibly other losses (lost income, loss of life, loss of real property).The Certified Information Systems Auditor (CISA) Review Manual 2006 defines risk management as \"the process of identifying vulnerabilities and threats to the information resources used by an organization in achieving business objectives, and deciding what countermeasures, if any, to take in reducing risk to an acceptable level, based on the value of the information resource to the organization.\"There are two things in this definition that may need some clarification. First, the process of risk management is an ongoing, iterative process. It must be repeated indefinitely. The business environment is constantly changing and new threats and vulnerabilities emerge every day. Second, the choice of countermeasures (controls) used to manage risks must strike a balance between productivity, cost, effectiveness of the countermeasure, and the value of the informational asset being protected. Furthermore, these processes have limitations as security breaches are generally rare and emerge in a specific context which may not be easily duplicated. Thus, any process and countermeasure should itself be evaluated for vulnerabilities. It is not possible to identify all risks, nor is it possible to eliminate all risk. The remaining risk is called \"residual risk.\"\nA risk assessment is carried out by a team of people who have knowledge of specific areas of the business. Membership of the team may vary over time as different parts of the business are assessed. The assessment may use a subjective qualitative analysis based on informed opinion, or where reliable dollar figures and historical information is available, the analysis may use quantitative analysis.\nResearch has shown that the most vulnerable point in most information systems is the human user, operator, designer, or other human. The ISO/IEC 27002:2005 Code of practice for information security management recommends the following be examined during a risk assessment:\n\nsecurity policy,\norganization of information security,\nasset management,\nhuman resources security,\nphysical and environmental security,\ncommunications and operations management,\naccess control,\ninformation systems acquisition, development, and maintenance,\ninformation security incident management,\nbusiness continuity management\nregulatory compliance.In broad terms, the risk management process consists of:\nIdentification of assets and estimating their value. Include: people, buildings, hardware, software, data (electronic, print, other), supplies.\nConduct a threat assessment. Include: Acts of nature, acts of war, accidents, malicious acts originating from inside or outside the organization.\nConduct a vulnerability assessment, and for each vulnerability, calculate the probability that it will be exploited. Evaluate policies, procedures, standards, training, physical security, quality control, technical security.\nCalculate the impact that each threat would have on each asset. Use qualitative analysis or quantitative analysis.\nIdentify, select and implement appropriate controls. Provide a proportional response. Consider productivity, cost effectiveness, and value of the asset.\nEvaluate the effectiveness of the control measures. Ensure the controls provide the required cost effective protection without discernible loss of productivity.For any given risk, management can choose to accept the risk based upon the relative low value of the asset, the relative low frequency of occurrence, and the relative low impact on the business. Or, leadership may choose to mitigate the risk by selecting and implementing appropriate control measures to reduce the risk. In some cases, the risk can be transferred to another business by buying insurance or outsourcing to another business. The reality of some risks may be disputed. In such cases leadership may choose to deny the risk.\n\n\n*** Security controls ***\n\nSelecting and implementing proper security controls will initially help an organization bring down risk to acceptable levels. Control selection should follow and should be based on the risk assessment. Controls can vary in nature, but fundamentally they are ways of protecting the confidentiality, integrity or availability of information. ISO/IEC 27001 has defined controls in different areas. Organizations can implement additional controls according to requirement of the organization. ISO/IEC 27002 offers a guideline for organizational information security standards.\n\n\n**** Administrative ****\nAdministrative controls (also called procedural controls) consist of approved written policies, procedures, standards, and guidelines. Administrative controls form the framework for running the business and managing people. They inform people on how the business is to be run and how day-to-day operations are to be conducted. Laws and regulations created by government bodies are also a type of administrative control because they inform the business. Some industry sectors have policies, procedures, standards, and guidelines that must be followed \u2013 the Payment Card Industry Data Security Standard (PCI DSS) required by Visa and MasterCard is such an example. Other examples of administrative controls include the corporate security policy, password policy, hiring policies, and disciplinary policies.Administrative controls form the basis for the selection and implementation of logical and physical controls. Logical and physical controls are manifestations of administrative controls, which are of paramount importance.\n\n\n**** Logical ****\nLogical controls (also called technical controls) use software and data to monitor and control access to information and computing systems. Passwords, network and host-based firewalls, network intrusion detection systems, access control lists, and data encryption are examples of logical controls.An important logical control that is frequently overlooked is the principle of least privilege, which requires that an individual, program or system process not be granted any more access privileges than are necessary to perform the task. A blatant example of the failure to adhere to the principle of least privilege is logging into Windows as user Administrator to read email and surf the web. Violations of this principle can also occur when an individual collects additional access privileges over time. This happens when employees' job duties change, employees are promoted to a new position, or employees are transferred to another department. The access privileges required by their new duties are frequently added onto their already existing access privileges, which may no longer be necessary or appropriate.\n\n\n**** Physical ****\nPhysical controls monitor and control the environment of the work place and computing facilities. They also monitor and control access to and from such facilities and include doors, locks, heating and air conditioning, smoke and fire alarms, fire suppression systems, cameras, barricades, fencing, security guards, cable locks, etc. Separating the network and workplace into functional areas are also physical controls.An important physical control that is frequently overlooked is separation of duties, which ensures that an individual can not complete a critical task by himself. For example, an employee who submits a request for reimbursement should not also be able to authorize payment or print the check. An applications programmer should not also be the server administrator or the database administrator; these roles and responsibilities must be separated from one another.\n\n\n*** Defense in depth ***\n\nInformation security must protect information throughout its lifespan, from the initial creation of the information on through to the final disposal of the information. The information must be protected while in motion and while at rest. During its lifetime, information may pass through many different information processing systems and through many different parts of information processing systems. There are many different ways the information and information systems can be threatened. To fully protect the information during its lifetime, each component of the information processing system must have its own protection mechanisms. The building up, layering on, and overlapping of security measures is called \"defense in depth.\" In contrast to a metal chain, which is famously only as strong as its weakest link, the defense in depth strategy aims at a structure where, should one defensive measure fail, other measures will continue to provide protection.Recall the earlier discussion about administrative controls, logical controls, and physical controls. The three types of controls can be used to form the basis upon which to build a defense in depth strategy. With this approach, defense in depth can be conceptualized as three distinct layers or planes laid one on top of the other. Additional insight into defense in depth can be gained by thinking of it as forming the layers of an onion, with data at the core of the onion, people the next outer layer of the onion, and network security, host-based security, and application security forming the outermost layers of the onion. Both perspectives are equally valid, and each provides valuable insight into the implementation of a good defense in depth strategy.\n\n\n*** Classification ***\nAn important aspect of information security and risk management is recognizing the value of information and defining appropriate procedures and protection requirements for the information. Not all information is equal and so not all information requires the same degree of protection. This requires information to be assigned a security classification. The first step in information classification is to identify a member of senior management as the owner of the particular information to be classified. Next, develop a classification policy. The policy should describe the different classification labels, define the criteria for information to be assigned a particular label, and list the required security controls for each classification.Some factors that influence which classification information should be assigned include how much value that information has to the organization, how old the information is and whether or not the information has become obsolete. Laws and other regulatory requirements are also important considerations when classifying information. The Information Systems Audit and Control Association (ISACA) and its Business Model for Information Security also serves as a tool for security professionals to examine security from a systems perspective, creating an environment where security can be managed holistically, allowing actual risks to be addressed.The type of information security classification labels selected and used will depend on the nature of the organization, with examples being:\nIn the business sector, labels such as: Public, Sensitive, Private, Confidential.\nIn the government sector, labels such as: Unclassified, Unofficial, Protected, Confidential, Secret, Top Secret, and their non-English equivalents.\nIn cross-sectoral formations, the Traffic Light Protocol, which consists of: White, Green, Amber, and Red.\nIn the personal sector, one label such as Financial. This includes activities related to managing money, such as online banking.All employees in the organization, as well as business partners, must be trained on the classification schema and understand the required security controls and handling procedures for each classification. The classification of a particular information asset that has been assigned should be reviewed periodically to ensure the classification is still appropriate for the information and to ensure the security controls required by the classification are in place and are followed in their right procedures.\n\n\n*** Access control ***\nAccess to protected information must be restricted to people who are authorized to access the information. The computer programs, and in many cases the computers that process the information, must also be authorized. This requires that mechanisms be in place to control the access to protected information. The sophistication of the access control mechanisms should be in parity with the value of the information being protected; the more sensitive or valuable the information the stronger the control mechanisms need to be. The foundation on which access control mechanisms are built start with identification and authentication.Access control is generally considered in three steps: identification, authentication, and authorization.\n\n\n**** Identification ****\nIdentification is an assertion of who someone is or what something is. If a person makes the statement \"Hello, my name is John Doe\" they are making a claim of who they are. However, their claim may or may not be true. Before John Doe can be granted access to protected information it will be necessary to verify that the person claiming to be John Doe really is John Doe. Typically the claim is in the form of a username. By entering that username you are claiming \"I am the person the username belongs to\".\n\n\n**** Authentication ****\nAuthentication is the act of verifying a claim of identity. When John Doe goes into a bank to make a withdrawal, he tells the bank teller he is John Doe, a claim of identity. The bank teller asks to see a photo ID, so he hands the teller his driver's license. The bank teller checks the license to make sure it has John Doe printed on it and compares the photograph on the license against the person claiming to be John Doe. If the photo and name match the person, then the teller has authenticated that John Doe is who he claimed to be. Similarly, by entering the correct password, the user is providing evidence that he/she is the person the username belongs to.There are three different types of information that can be used for authentication:\nSomething you know: things such as a PIN, a password, or your mother's maiden name\nSomething you have: a driver's license or a magnetic swipe card\nSomething you are: biometrics, including palm prints, fingerprints, voice prints, and retina (eye) scansStrong authentication requires providing more than one type of authentication information (two-factor authentication). The username is the most common form of identification on computer systems today and the password is the most common form of authentication. Usernames and passwords have served their purpose, but they are increasingly inadequate. Usernames and passwords are slowly being replaced or supplemented with more sophisticated authentication mechanisms such as Time-based One-time Password algorithms.\n\n\n**** Authorization ****\nAfter a person, program or computer has successfully been identified and authenticated then it must be determined what informational resources they are permitted to access and what actions they will be allowed to perform (run, view, create, delete, or change). This is called authorization. Authorization to access information and other computing services begins with administrative policies and procedures. The policies prescribe what information and computing services can be accessed, by whom, and under what conditions. The access control mechanisms are then configured to enforce these policies. Different computing systems are equipped with different kinds of access control mechanisms. Some may even offer a choice of different access control mechanisms. The access control mechanism a system offers will be based upon one of three approaches to access control, or it may be derived from a combination of the three approaches.The non-discretionary approach consolidates all access control under a centralized administration. The access to information and other resources is usually based on the individuals function (role) in the organization or the tasks the individual must perform. The discretionary approach gives the creator or owner of the information resource the ability to control access to those resources. In the mandatory access control approach, access is granted or denied basing upon the security classification assigned to the information resource.Examples of common access control mechanisms in use today include role-based access control, available in many advanced database management systems; simple file permissions provided in the UNIX and Windows operating systems; Group Policy Objects provided in Windows network systems; and Kerberos, RADIUS, TACACS, and the simple access lists used in many firewalls and routers.To be effective, policies and other security controls must be enforceable and upheld. Effective policies ensure that people are held accountable for their actions. The U.S. Treasury's guidelines for systems processing sensitive or proprietary information, for example, states that all failed and successful authentication and access attempts must be logged, and all access to information must leave some type of audit trail.Also, the need-to-know principle needs to be in effect when talking about access control. This principle gives access rights to a person to perform their job functions. This principle is used in the government when dealing with difference clearances. Even though two employees in different departments have a top-secret clearance, they must have a need-to-know in order for information to be exchanged. Within the need-to-know principle, network administrators grant the employee the least amount of privilege to prevent employees from accessing more than what they are supposed to. Need-to-know helps to enforce the confidentiality-integrity-availability triad. Need-to-know directly impacts the confidential area of the triad.\n\n\n*** Cryptography ***\n\nInformation security uses cryptography to transform usable information into a form that renders it unusable by anyone other than an authorized user; this process is called encryption. Information that has been encrypted (rendered unusable) can be transformed back into its original usable form by an authorized user who possesses the cryptographic key, through the process of decryption. Cryptography is used in information security to protect information from unauthorized or accidental disclosure while the information is in transit (either electronically or physically) and while information is in storage.Cryptography provides information security with other useful applications as well, including improved authentication methods, message digests, digital signatures, non-repudiation, and encrypted network communications. Older, less secure applications such as Telnet and File Transfer Protocol (FTP) are slowly being replaced with more secure applications such as Secure Shell (SSH) that use encrypted network communications. Wireless communications can be encrypted using protocols such as WPA/WPA2 or the older (and less secure) WEP. Wired communications (such as ITU\u2011T G.hn) are secured using AES for encryption and X.1035 for authentication and key exchange. Software applications such as GnuPG or PGP can be used to encrypt data files and email.Cryptography can introduce security problems when it is not implemented correctly. Cryptographic solutions need to be implemented using industry-accepted solutions that have undergone rigorous peer review by independent experts in cryptography. The length and strength of the encryption key is also an important consideration. A key that is weak or too short will produce weak encryption. The keys used for encryption and decryption must be protected with the same degree of rigor as any other confidential information. They must be protected from unauthorized disclosure and destruction, and they must be available when needed. Public key infrastructure (PKI) solutions address many of the problems that surround key management.\n\n== Process ==\nThe terms \"reasonable and prudent person\", \"due care\", and \"due diligence\" have been used in the fields of finance, securities, and law for many years. In recent years these terms have found their way into the fields of computing and information security. U.S. Federal Sentencing Guidelines now make it possible to hold corporate officers liable for failing to exercise due care and due diligence in the management of their information systems.In the business world, stockholders, customers, business partners, and governments have the expectation that corporate officers will run the business in accordance with accepted business practices and in compliance with laws and other regulatory requirements. This is often described as the \"reasonable and prudent person\" rule. A prudent person takes due care to ensure that everything necessary is done to operate the business by sound business principles and in a legal, ethical manner. A prudent person is also diligent (mindful, attentive, ongoing) in their due care of the business.\nIn the field of information security, Harris\noffers the following definitions of due care and due diligence:\n\n\"Due care are steps that are taken to show that a company has taken responsibility for the activities that take place within the corporation and has taken the necessary steps to help protect the company, its resources, and employees.\" And, [Due diligence are the] \"continual activities that make sure the protection mechanisms are continually maintained and operational.\"\nAttention should be made to two important points in these definitions. First, in due care, steps are taken to show; this means that the steps can be verified, measured, or even produce tangible artifacts. Second, in due diligence, there are continual activities; this means that people are actually doing things to monitor and maintain the protection mechanisms, and these activities are ongoing.Organizations have a responsibility with practicing duty of care when applying information security. The Duty of Care Risk Analysis Standard (DoCRA) provides principles and practices for evaluating risk. It considers all parties that could be affected by those risks. DoCRA helps evaluate safeguards if they are appropriate in protecting others from harm while presenting a reasonable burden. With increased data breach litigation, companies must balance security controls, compliance, and its mission.\n\n\n*** Security governance ***\n\nThe Software Engineering Institute at Carnegie Mellon University, in a publication titled Governing for Enterprise Security (GES) Implementation Guide, defines characteristics of effective security governance. These include:\nAn enterprise-wide issue\nLeaders are accountable\nViewed as a business requirement\nRisk-based\nRoles, responsibilities, and segregation of duties defined\nAddressed and enforced in policy\nAdequate resources committed\nStaff aware and trained\nA development life cycle requirement\nPlanned, managed, measurable, and measured\nReviewed and audited\n\n\n*** Incident response plans ***\nAn incident response plan (IRP) is a group of policies that dictate an organizations reaction to a cyber attack. Once an security breach has been identified, for example by Network Intrusion Detection System (NIDS) or Host-Based Intrusion Detection System (HIDS) (if configured to do so),  the plan is initiated. It is important to note that there can be legal implications to a data breach. Knowing local and federal laws is critical. Every plan is unique to the needs of the organization, and it can involve skill sets that are not part of an IT team. For example, a lawyer may be included in the response plan to help navigate legal implications to a data breach.As mentioned above every plan is unique but most plans will include the following:\n\n\n**** Preparation ****\nGood preparation includes the development of an Incident Response Team (IRT). Skills need to be used by this team would be, penetration testing, computer forensics, network security, etc. This team should also keep track of trends in cybersecurity and modern attack strategies. A training program for end users is important as well as most modern attack strategies target users on the network.\n\n\n**** Identification ****\nThis part of the incident response plan identifies if there was a security event. When an end user reports information or an admin notices irregularities, an investigation is launched. An incident log is a crucial part of this step. All of the members of the team should be updating this log to ensure that information flows as fast as possible. If it has been identified that a security breach has occurred the next step should be activated.\n\n\n**** Containment ****\nIn this phase, the IRT works to isolate the areas that the breach took place to limit the scope of the security event. During this phase it is important to preserve information forensically so it can be analyzed later in the process. Containment could be as simple as physically containing a server room or as complex as segmenting a network to not allow the spread of a virus.\n\n\n**** Eradication ****\nThis is where the threat that was identified is removed from the affected systems. This could include deleting malicious files, terminating compromised accounts, or deleting other components. Some events do not require this step, however it is important to fully understand the event before moving to this step. This will help to ensure that the threat is completely removed.\n\n\n**** Recovery ****\nThis stage is where the systems are restored back to original operation. This stage could include the recovery of data, changing user access information, or updating firewall rules or policies to prevent a breach in the future. Without executing this step, the system could still be vulnerable to future security threats.\n\n\n**** Lessons Learned ****\nIn this step information that has been gathered during this process is used to make future decisions on security. This step is crucial to the ensure that future events are prevented. Using this information to further train admins is critical to the process. This step can also be used to process information that is distributed from other entities who have experienced a security event.\n\n\n*** Change management ***\n\nChange management is a formal process for directing and controlling alterations to the information processing environment. This includes alterations to desktop computers, the network, servers, and software. The objectives of change management are to reduce the risks posed by changes to the information processing environment and improve the stability and reliability of the processing environment as changes are made. It is not the objective of change management to prevent or hinder necessary changes from being implemented.Any change to the information processing environment introduces an element of risk. Even apparently simple changes can have unexpected effects. One of management's many responsibilities is the management of risk. Change management is a tool for managing the risks introduced by changes to the information processing environment. Part of the change management process ensures that changes are not implemented at inopportune times when they may disrupt critical business processes or interfere with other changes being implemented.Not every change needs to be managed. Some kinds of changes are a part of the everyday routine of information processing and adhere to a predefined procedure, which reduces the overall level of risk to the processing environment. Creating a new user account or deploying a new desktop computer are examples of changes that do not generally require change management. However, relocating user file shares, or upgrading the Email server pose a much higher level of risk to the processing environment and are not a normal everyday activity. The critical first steps in change management are (a) defining change (and communicating that definition) and (b) defining the scope of the change system.Change management is usually overseen by a change review board composed of representatives from key business areas, security, networking, systems administrators, database administration, application developers, desktop support, and the help desk. The tasks of the change review board can be facilitated with the use of automated work flow application. The responsibility of the change review board is to ensure the organization's documented change management procedures are followed. The change management process is as follows\nRequest: Anyone can request a change. The person making the change request may or may not be the same person that performs the analysis or implements the change. When a request for change is received, it may undergo a preliminary review to determine if the requested change is compatible with the organizations business model and practices, and to determine the amount of resources needed to implement the change.\nApprove: Management runs the business and controls the allocation of resources therefore, management must approve requests for changes and assign a priority for every change. Management might choose to reject a change request if the change is not compatible with the business model, industry standards or best practices. Management might also choose to reject a change request if the change requires more resources than can be allocated for the change.\nPlan: Planning a change involves discovering the scope and impact of the proposed change; analyzing the complexity of the change; allocation of resources and, developing, testing, and documenting both implementation and back-out plans. Need to define the criteria on which a decision to back out will be made.\nTest: Every change must be tested in a safe test environment, which closely reflects the actual production environment, before the change is applied to the production environment. The backout plan must also be tested.\nSchedule: Part of the change review board's responsibility is to assist in the scheduling of changes by reviewing the proposed implementation date for potential conflicts with other scheduled changes or critical business activities.\nCommunicate: Once a change has been scheduled it must be communicated. The communication is to give others the opportunity to remind the change review board about other changes or critical business activities that might have been overlooked when scheduling the change. The communication also serves to make the help desk and users aware that a change is about to occur. Another responsibility of the change review board is to ensure that scheduled changes have been properly communicated to those who will be affected by the change or otherwise have an interest in the change.\nImplement: At the appointed date and time, the changes must be implemented. Part of the planning process was to develop an implementation plan, testing plan and, a back out plan. If the implementation of the change should fail or, the post implementation testing fails or, other \"drop dead\" criteria have been met, the back out plan should be implemented.\nDocument: All changes must be documented. The documentation includes the initial request for change, its approval, the priority assigned to it, the implementation, testing and back out plans, the results of the change review board critique, the date/time the change was implemented, who implemented it, and whether the change was implemented successfully, failed or postponed.\nPost-change review: The change review board should hold a post-implementation review of changes. It is particularly important to review failed and backed out changes. The review board should try to understand the problems that were encountered, and look for areas for improvement.Change management procedures that are simple to follow and easy to use can greatly reduce the overall risks created when changes are made to the information processing environment. Good change management procedures improve the overall quality and success of changes as they are implemented. This is accomplished through planning, peer review, documentation, and communication.ISO/IEC 20000, The Visible OPS Handbook: Implementing ITIL in 4 Practical and Auditable Steps (Full book summary), and ITIL all provide valuable guidance on implementing an efficient and effective change management program information security.\n\n== Business continuity ==\nBusiness continuity management (BCM) concerns arrangements aiming to protect an organization's critical business functions from interruption due to incidents, or at least minimize the effects. BCM is essential to any organization to keep technology and business in line with current threats to the continuation of business as usual. The BCM should be included in an organizations risk analysis plan to ensure that all of the necessary business functions have what they need to keep going in the event of any type of threat to any business function.It encompasses:\n\nAnalysis of requirements, e.g., identifying critical business functions, dependencies and potential failure points, potential threats and hence incidents or risks of concern to the organization;\nSpecification, e.g., maximum tolerable outage periods; recovery point objectives (maximum acceptable periods of data loss);\nArchitecture and design, e.g., an appropriate combination of approaches including resilience (e.g. engineering IT systems and processes for high availability, avoiding or preventing situations that might interrupt the business), incident and emergency management (e.g., evacuating premises, calling the emergency services, triage/situation assessment and invoking recovery plans), recovery (e.g., rebuilding) and contingency management (generic capabilities to deal positively with whatever occurs using whatever resources are available);\nImplementation, e.g., configuring and scheduling backups, data transfers, etc., duplicating and strengthening critical elements; contracting with service and equipment suppliers;\nTesting, e.g., business continuity exercises of various types, costs and assurance levels;\nManagement, e.g., defining strategies, setting objectives and goals; planning and directing the work; allocating funds, people and other resources; prioritization relative to other activities; team building, leadership, control, motivation and coordination with other business functions and activities (e.g., IT, facilities, human resources, risk management, information risk and security, operations); monitoring the situation, checking and updating the arrangements when things change; maturing the approach through continuous improvement, learning and appropriate investment;\nAssurance, e.g., testing against specified requirements; measuring, analyzing, and reporting key parameters; conducting additional tests, reviews and audits for greater confidence that the arrangements will go to plan if invoked.Whereas BCM takes a broad approach to minimizing disaster-related risks by reducing both the probability and the severity of incidents, a disaster recovery plan (DRP) focuses specifically on resuming business operations as quickly as possible after a disaster. A disaster recovery plan, invoked soon after a disaster occurs, lays out the steps necessary to recover critical information and communications technology (ICT) infrastructure. Disaster recovery planning includes establishing a planning group, performing risk assessment, establishing priorities, developing recovery strategies, preparing inventories and documentation of the plan, developing verification criteria and procedure, and lastly implementing the plan.\n\n== Laws and regulations ==\n\nBelow is a partial listing of governmental laws and regulations in various parts of the world that have, had, or will have, a significant effect on data processing and information security. Important industry sector regulations have also been included when they have a significant impact on information security.\nThe UK Data Protection Act 1998 makes new provisions for the regulation of the processing of information relating to individuals, including the obtaining, holding, use or disclosure of such information. The European Union Data Protection Directive (EUDPD) requires that all E.U. members adopt national regulations to standardize the protection of data privacy for citizens throughout the E.U.\nThe Computer Misuse Act 1990 is an Act of the U.K. Parliament making computer crime (e.g., hacking) a criminal offense. The act has become a model upon which several other countries, including Canada and the Republic of Ireland, have drawn inspiration from when subsequently drafting their own information security laws.\nThe E.U.'s Data Retention Directive (annulled) required internet service providers and phone companies to keep data on every electronic message sent and phone call made for between six months and two years.\nThe Family Educational Rights and Privacy Act (FERPA) (20 U.S.C. \u00a7 1232 g; 34 CFR Part 99) is a U.S. Federal law that protects the privacy of student education records. The law applies to all schools that receive funds under an applicable program of the U.S. Department of Education. Generally, schools must have written permission from the parent or eligible student in order to release any information from a student's education record.\nThe Federal Financial Institutions Examination Council's (FFIEC) security guidelines for auditors specifies requirements for online banking security.\nThe Health Insurance Portability and Accountability Act (HIPAA) of 1996 requires the adoption of national standards for electronic health care transactions and national identifiers for providers, health insurance plans, and employers. Additionally, it requires health care providers, insurance providers and employers to safeguard the security and privacy of health data.\nThe Gramm\u2013Leach\u2013Bliley Act of 1999 (GLBA), also known as the Financial Services Modernization Act of 1999, protects the privacy and security of private financial information that financial institutions collect, hold, and process.\nSection 404 of the Sarbanes\u2013Oxley Act of 2002 (SOX) requires publicly traded companies to assess the effectiveness of their internal controls for financial reporting in annual reports they submit at the end of each fiscal year. Chief information officers are responsible for the security, accuracy, and the reliability of the systems that manage and report the financial data. The act also requires publicly traded companies to engage with independent auditors who must attest to, and report on, the validity of their assessments.\nThe Payment Card Industry Data Security Standard (PCI DSS) establishes comprehensive requirements for enhancing payment account data security. It was developed by the founding payment brands of the PCI Security Standards Council \u2014 including American Express, Discover Financial Services, JCB, MasterCard Worldwide, and Visa International \u2014 to help facilitate the broad adoption of consistent data security measures on a global basis. The PCI DSS is a multifaceted security standard that includes requirements for security management, policies, procedures, network architecture, software design, and other critical protective measures.\nState security breach notification laws (California and many others) require businesses, nonprofits, and state institutions to notify consumers when unencrypted \"personal information\" may have been compromised, lost, or stolen.\nThe Personal Information Protection and Electronics Document Act (PIPEDA) of Canada supports and promotes electronic commerce by protecting personal information that is collected, used or disclosed in certain circumstances, by providing for the use of electronic means to communicate or record information or transactions and by amending the Canada Evidence Act, the Statutory Instruments Act and the Statute Revision Act.\nGreece's Hellenic Authority for Communication Security and Privacy (ADAE) (Law 165/2011) establishes and describes the minimum information security controls that should be deployed by every company which provides electronic communication networks and/or services in Greece in order to protect customers' confidentiality. These include both managerial and technical controls (e.g., log records should be stored for two years).\nGreece's Hellenic Authority for Communication Security and Privacy (ADAE) (Law 205/2013) concentrates around the protection of the integrity and availability of the services and data offered by Greek telecommunication companies. The law forces these and other related companies to build, deploy, and test appropriate business continuity plans and redundant infrastructures.The US Department of Defense (DoD) issued DoD Directive 8570 in 2004, supplemented by DoD Directive 8140, requiring all DoD employees and all DoD contract personnel involved in information assurance roles and activities to earn and maintain various industry Information Technology (IT) certifications in an effort to ensure that all DoD personnel involved in network infrastructure defense have minimum levels of IT industry recognized knowledge, skills and abilities (KSA). Andersson and Reimers (2019) report these certifications range from CompTIA's A+ and Security+ through the ICS2.org's CISSP, etc..\n\n== Culture ==\nDescribing more than simply how security aware employees are, information security culture is the ideas, customs, and social behaviors of an organization that impact information security in both positive and negative ways. Cultural concepts can help different segments of the organization work effectively or work against effectiveness towards information security within an organization. The way employees think and feel about security and the actions they take can have a big impact on information security in organizations. Roer & Petric (2017) identify seven core dimensions of information security culture in organizations:\nAttitudes: Employees' feelings and emotions about the various activities that pertain to the organizational security of information.\nBehaviors: Actual or intended activities and risk-taking actions of employees that have direct or indirect impact on information security.\nCognition: Employees' awareness, verifiable knowledge, and beliefs regarding practices, activities, and self-efficacy relation that are related to information security.\nCommunication: Ways employees communicate with each other, sense of belonging, support for security issues, and incident reporting.\nCompliance: Adherence to organizational security policies, awareness of the existence of such policies and the ability to recall the substance of such policies.\nNorms: Perceptions of security-related organizational conduct and practices that are informally deemed either normal or deviant by employees and their peers, e.g. hidden expectations regarding security behaviors and unwritten rules regarding uses of information-communication technologies.\nResponsibilities: Employees' understanding of the roles and responsibilities they have as a critical factor in sustaining or endangering the security of information, and thereby the organization.Andersson and Reimers (2014) found that employees often do not see themselves as part of the organization Information Security \"effort\" and often take actions that ignore organizational information security best interests. Research shows information security culture needs to be improved continuously. In Information Security Culture from Analysis to Change, authors commented, \"It's a never ending process, a cycle of evaluation and change or maintenance.\" To manage the information security culture, five steps should be taken: pre-evaluation, strategic planning, operative planning, implementation, and post-evaluation.\nPre-Evaluation: to identify the awareness of information security within employees and to analyze current security policy\nStrategic Planning: to come up a better awareness-program, we need to set clear targets. Clustering people is helpful to achieve it\nOperative Planning: create a good security culture based on internal communication, management buy-in, security awareness, and training programs\nImplementation: should feature commitment of management, communication with organizational members, courses for all organizational members, and commitment of the employees\nPost-evaluation: to better gauge the effectiveness of the prior steps and build on continuous improvement\n\n== Sources of standards ==\n\nThe International Organization for Standardization (ISO) is an international standards organization organized as a consortium of national standards institutions from 167 countries, coordinated through a secretariat in Geneva, Switzerland. ISO is the world's largest developer of international standards. The International Electrotechnical Commission (IEC) is an international standards organization that deals with electrotechnology and cooperates closely with ISO. ISO/IEC 15443: \"Information technology \u2013 Security techniques \u2013 A framework for IT security assurance\", ISO/IEC 27002: \"Information technology \u2013 Security techniques \u2013 Code of practice for information security management\", ISO/IEC 20000: \"Information technology \u2013 Service management\", and ISO/IEC 27001: \"Information technology \u2013 Security techniques \u2013 Information security management systems \u2013 Requirements\" are of particular interest to information security professionals.\nThe US National Institute of Standards and Technology (NIST) is a non-regulatory federal agency within the U.S. Department of Commerce. The NIST Computer Security Division\ndevelops standards, metrics, tests, and validation programs as well as publishes standards and guidelines to increase secure IT planning, implementation, management, and operation. NIST is also the custodian of the U.S. Federal Information Processing Standard publications (FIPS).\nThe Internet Society is a professional membership society with more than 100 organizations and over 20,000 individual members in over 180 countries. It provides leadership in addressing issues that confront the future of the internet, and it is the organizational home for the groups responsible for internet infrastructure standards, including the Internet Engineering Task Force (IETF) and the Internet Architecture Board (IAB). The ISOC hosts the Requests for Comments (RFCs) which includes the Official Internet Protocol Standards and the RFC-2196 Site Security Handbook.\nThe Information Security Forum (ISF) is a global nonprofit organization of several hundred leading organizations in financial services, manufacturing, telecommunications, consumer goods, government, and other areas. It undertakes research into information security practices and offers advice in its biannual Standard of Good Practice and more detailed advisories for members.\nThe Institute of Information Security Professionals (IISP) is an independent, non-profit body governed by its members, with the principal objective of advancing the professionalism of information security practitioners and thereby the professionalism of the industry as a whole. The institute developed the IISP Skills Framework. This framework describes the range of competencies expected of information security and information assurance professionals in the effective performance of their roles. It was developed through collaboration between both private and public sector organizations, world-renowned academics, and security leaders.The German Federal Office for Information Security (in German Bundesamt f\u00fcr Sicherheit in der Informationstechnik (BSI)) BSI-Standards 100\u20131 to 100-4 are a set of recommendations including \"methods, processes, procedures, approaches and measures relating to information security\". The BSI-Standard 100-2 IT-Grundschutz Methodology describes how information security management can be implemented and operated. The standard includes a very specific guide, the IT Baseline Protection Catalogs (also known as IT-Grundschutz Catalogs). Before 2005, the catalogs were formerly known as \"IT Baseline Protection Manual\". The Catalogs are a collection of documents useful for detecting and combating security-relevant weak points in the IT environment (IT cluster). The collection encompasses as of September 2013 over 4,400 pages with the introduction and catalogs. The IT-Grundschutz approach is aligned with to the ISO/IEC 2700x family.\nThe European Telecommunications Standards Institute standardized a catalog of information security indicators, headed by the Industrial Specification Group (ISG) ISI.\n\nQuestion: How does the Gordon-Loeb Model approach the balance between information security and cost?\n\nAnswer:",
    "context": "",
    "output": "The Gordon-Loeb Model provides a mathematical economic approach for addressing the concern of balancing information security and cost, considering the value of the information resource to the organization.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the Gordon-Loeb Model approach the balance between information security and cost?",
      "answer": "The Gordon-Loeb Model provides a mathematical economic approach for addressing the concern of balancing information security and cost, considering the value of the information resource to the organization.",
      "context": "Information security\n\n==Introduction==\nInformation security, sometimes shortened to InfoSec, is the practice of protecting information by mitigating information risks. It is part of information risk management. It typically involves preventing or reducing the probability of unauthorized/inappropriate access to data, or the unlawful use, disclosure, disruption, deletion, corruption, modification, inspection, recording, or devaluation of information. It also involves actions intended to reduce the adverse impacts of such incidents. Protected information may take any form, e.g. electronic or physical, tangible (e.g. paperwork) or intangible (e.g. knowledge). Information security's primary focus is the balanced protection of the data confidentiality, data integrity, and data availability of data (also known as the CIA triad) while maintaining a focus on efficient policy implementation, all without hampering organization productivity. This is largely achieved through a structured risk management process that involves: \n\nidentifying information and related assets, plus potential threats, vulnerabilities, and impacts;\nevaluating the risks\ndeciding how to address or treat the risks i.e. to avoid, mitigate, share or accept them\nwhere risk mitigation is required, selecting or designing appropriate security controls and implementing them\nmonitoring the activities, making adjustments as necessary to address any issues, changes and improvement opportunitiesTo standardize this discipline, academics and professionals collaborate to offer guidance, policies, and industry standards on password, antivirus software, firewall, encryption software, legal liability, security awareness and training, and so forth. This standardization may be further driven by a wide variety of laws and regulations that affect how data is accessed, processed, stored, transferred and destroyed. However, the implementation of any standards and guidance within an entity may have limited effect if a culture of continual improvement is not adopted.\n\n\n\n== Definition ==\n\nVarious definitions of information security are suggested below, summarized from different sources:\n\n\"Preservation of confidentiality, integrity and availability of information. Note: In addition, other properties, such as authenticity, accountability, non-repudiation and reliability can also be involved.\" (ISO/IEC 27000:2009)\n\"The protection of information and information systems from unauthorized access, use, disclosure, disruption, modification, or destruction in order to provide confidentiality, integrity, and availability.\" (CNSS, 2010)\n\"Ensures that only authorized users (confidentiality) have access to accurate and complete information (integrity) when required (availability).\" (ISACA, 2008)\n\"Information Security is the process of protecting the intellectual property of an organisation.\"  (Pipkin, 2000)\n\"...information security is a risk management discipline, whose job is to manage the cost of information risk to the business.\" (McDermott and Geer, 2001)\n\"A well-informed sense of assurance that information risks and controls are in balance.\" (Anderson, J., 2003)\n\"Information security is the protection of information and minimizes the risk of exposing information to unauthorized parties.\" (Venter and Eloff, 2003)\n\"Information Security is a multidisciplinary area of study and professional activity which is concerned with the development and implementation of security mechanisms of all available types (technical, organizational, human-oriented and legal) in order to keep information in all its locations (within and outside the organization's perimeter) and, consequently, information systems, where information is created, processed, stored, transmitted and destroyed, free from threats. Threats to information and information systems may be categorized and a corresponding security goal may be defined for each category of threats. A set of security goals, identified as a result of a threat analysis, should be revised periodically to ensure its adequacy and conformance with the evolving environment. The currently relevant set of security goals may include: confidentiality, integrity, availability, privacy, authenticity & trustworthiness, non-repudiation, accountability and auditability.\" (Cherdantseva and Hilton, 2013)\nInformation and information resource security using telecommunication system or devices means protecting information, information systems or books from unauthorized access, damage, theft, or destruction (Kurose and Ross, 2010).\n\n== Overview ==\nAt the core of information security is information assurance, the act of maintaining the confidentiality, integrity, and availability (CIA) of information, ensuring that information is not compromised in any way when critical issues arise. These issues include but are not limited to natural disasters, computer/server malfunction, and physical theft. While paper-based business operations are still prevalent, requiring their own set of information security practices, enterprise digital initiatives are increasingly being emphasized, with information assurance now typically being dealt with by information technology (IT) security specialists. These specialists apply information security to technology (most often some form of computer system). It is worthwhile to note that a computer does not necessarily mean a home desktop. A computer is any device with a processor and some memory. Such devices can range from non-networked standalone devices as simple as calculators, to networked mobile computing devices such as smartphones and tablet computers. IT security specialists are almost always found in any major enterprise/establishment due to the nature and value of the data within larger businesses. They are responsible for keeping all of the technology within the company secure from malicious cyber attacks that often attempt to acquire critical private information or gain control of the internal systems.The field of information security has grown and evolved significantly in recent years. It offers many areas for specialization, including securing networks and allied infrastructure, securing applications and databases, security testing, information systems auditing, business continuity planning, electronic record discovery, and digital forensics. Information security professionals are very stable in their employment. As of 2013 more than 80 percent of professionals had no change in employer or employment over a period of a year, and the number of professionals is projected to continuously grow more than 11 percent annually from 2014 to 2019.\n\n\n*** Threats ***\nInformation security threats come in many different forms. Some of the most common threats today are software attacks, theft of intellectual property, theft of identity, theft of equipment or information, sabotage, and information extortion. Viruses, worms, phishing attacks, and Trojan horses are a few common examples of software attacks. The theft of intellectual property has also been an extensive issue for many businesses in the information technology (IT) field. Identity theft is the attempt to act as someone else usually to obtain that person's personal information or to take advantage of their access to vital information through social engineering. Theft of equipment or information is becoming more prevalent today due to the fact that most devices today are mobile, are prone to theft and have also become far more desirable as the amount of data capacity increases. Sabotage usually consists of the destruction of an organization's website in an attempt to cause loss of confidence on the part of its customers. Information extortion consists of theft of a company's property or information as an attempt to receive a payment in exchange for returning the information or property back to its owner, as with ransomware. There are many ways to help protect yourself from some of these attacks but one of the most functional precautions is conduct periodical user awareness. The number one threat to any organisation are users or internal employees, they are also called insider threats.Governments, military, corporations, financial institutions, hospitals, non-profit organisations, and private businesses amass a great deal of confidential information about their employees, customers, products, research, and financial status. Should confidential information about a business's customers or finances or new product line fall into the hands of a competitor or a black hat hacker, a business and its customers could suffer widespread, irreparable financial loss, as well as damage to the company's reputation. From a business perspective, information security must be balanced against cost; the Gordon-Loeb Model provides a mathematical economic approach for addressing this concern.For the individual, information security has a significant effect on privacy, which is viewed very differently in various cultures.\n\n\n**** Responses to threats ****\nPossible responses to a security threat or risk are:\nreduce/mitigate \u2013 implement safeguards and countermeasures to eliminate vulnerabilities or block threats\nassign/transfer \u2013 place the cost of the threat onto another entity or organization such as purchasing insurance or outsourcing\naccept \u2013 evaluate if the cost of the countermeasure outweighs the possible cost of loss due to the threat\n\n== Basic principles ==\n\n\n*** Key concepts ***\n\nThe CIA triad of confidentiality, integrity, and availability is at the heart of information security. (The members of the classic InfoSec triad\u2014confidentiality, integrity, and availability\u2014are interchangeably referred to in the literature as security attributes, properties, security goals, fundamental aspects, information criteria, critical information characteristics and basic building blocks.) However, debate continues about whether or not this CIA triad is sufficient to address rapidly changing technology and business requirements, with recommendations to consider expanding on the intersections between availability and confidentiality, as well as the relationship between security and privacy. Other principles such as \"accountability\" have sometimes been proposed; it has been pointed out that issues such as non-repudiation do not fit well within the three core concepts.The triad seems to have first been mentioned in a NIST publication in 1977.In 1992 and revised in 2002, the OECD's Guidelines for the Security of Information Systems and Networks proposed the nine generally accepted principles: awareness, responsibility, response, ethics, democracy, risk assessment, security design and implementation, security management, and reassessment. Building upon those, in 2004 the NIST's Engineering Principles for Information Technology Security proposed 33 principles. From each of these derived guidelines and practices.\nIn 1998, Donn Parker proposed an alternative model for the classic CIA triad that he called the six atomic elements of information. The elements are confidentiality, possession, integrity, authenticity, availability, and utility. The merits of the Parkerian Hexad are a subject of debate amongst security professionals.In 2011, The Open Group published the information security management standard O-ISM3. This standard proposed an operational definition of the key concepts of security, with elements called \"security objectives\", related to access control (9), availability (3), data quality (1), compliance, and technical (4). In 2009, DoD Software Protection Initiative Archived 2016-09-25 at the Wayback Machine released the Three Tenets of Cybersecurity Archived 2020-05-10 at the Wayback Machine which are System Susceptibility, Access to the Flaw, and Capability to Exploit the Flaw. Neither of these models are widely adopted.\n\n\n**** Confidentiality ****\nIn information security, confidentiality \"is the property, that information is not made available or disclosed to unauthorized individuals, entities, or processes.\" While similar to \"privacy,\" the two words are not interchangeable. Rather, confidentiality is a component of privacy that implements to protect our data from unauthorized viewers. Examples of confidentiality of electronic data being compromised include laptop theft, password theft, or sensitive emails being sent to the incorrect individuals.\n\n\n**** Integrity ****\nIn IT security, data integrity means maintaining and assuring the accuracy and completeness of data over its entire lifecycle. This means that data cannot be modified in an unauthorized or undetected manner. This is not the same thing as referential integrity in databases, although it can be viewed as a special case of consistency as understood in the classic ACID model of transaction processing. Information security systems typically incorporate controls to ensure their own integrity, in particular protecting the kernel or core functions against both deliberate and accidental threats. Multi-purpose and multi-user computer systems aim to compartmentalize the data and processing such that no user or process can adversely impact another: the controls may not succeed however, as we see in incidents such as malware infections, hacks, data theft, fraud, and privacy breaches.More broadly, integrity is an information security principle that involves human/social, process, and commercial integrity, as well as data integrity. As such it touches on aspects such as credibility, consistency, truthfulness, completeness, accuracy, timeliness, and assurance.\n\n\n**** Availability ****\nFor any information system to serve its purpose, the information must be available when it is needed. This means the computing systems used to store and process the information, the security controls used to protect it, and the communication channels used to access it must be functioning correctly. High availability systems aim to remain available at all times, preventing service disruptions due to power outages, hardware failures, and system upgrades. Ensuring availability also involves preventing denial-of-service attacks, such as a flood of incoming messages to the target system, essentially forcing it to shut down.In the realm of information security, availability can often be viewed as one of the most important parts of a successful information security program. Ultimately end-users need to be able to perform job functions; by ensuring availability an organization is able to perform to the standards that an organization's stakeholders expect. This can involve topics such as proxy configurations, outside web access, the ability to access shared drives and the ability to send emails. Executives oftentimes do not understand the technical side of information security and look at availability as an easy fix, but this often requires collaboration from many different organizational teams, such as network operations, development operations, incident response, and policy/change management. A successful information security team involves many different key roles to mesh and align for the CIA triad to be provided effectively.\n\n\n**** Non-repudiation ****\nIn law, non-repudiation implies one's intention to fulfill their obligations to a contract. It also implies that one party of a transaction cannot deny having received a transaction, nor can the other party deny having sent a transaction.It is important to note that while technology such as cryptographic systems can assist in non-repudiation efforts, the concept is at its core a legal concept transcending the realm of technology. It is not, for instance, sufficient to show that the message matches a digital signature signed with the sender's private key, and thus only the sender could have sent the message, and nobody else could have altered it in transit (data integrity). The alleged sender could in return demonstrate that the digital signature algorithm is vulnerable or flawed, or allege or prove that his signing key has been compromised. The fault for these violations may or may not lie with the sender, and such assertions may or may not relieve the sender of liability, but the assertion would invalidate the claim that the signature necessarily proves authenticity and integrity. As such, the sender may repudiate the message (because authenticity and integrity are pre-requisites for non-repudiation).\n\n== Risk management ==\n\nBroadly speaking, risk is the likelihood that something bad will happen that causes harm to an informational asset (or the loss of the asset). A vulnerability is a weakness that could be used to endanger or cause harm to an informational asset. A threat is anything (man-made or act of nature) that has the potential to cause harm. The likelihood that a threat will use a vulnerability to cause harm creates a risk. When a threat does use a vulnerability to inflict harm, it has an impact. In the context of information security, the impact is a loss of availability, integrity, and confidentiality, and possibly other losses (lost income, loss of life, loss of real property).The Certified Information Systems Auditor (CISA) Review Manual 2006 defines risk management as \"the process of identifying vulnerabilities and threats to the information resources used by an organization in achieving business objectives, and deciding what countermeasures, if any, to take in reducing risk to an acceptable level, based on the value of the information resource to the organization.\"There are two things in this definition that may need some clarification. First, the process of risk management is an ongoing, iterative process. It must be repeated indefinitely. The business environment is constantly changing and new threats and vulnerabilities emerge every day. Second, the choice of countermeasures (controls) used to manage risks must strike a balance between productivity, cost, effectiveness of the countermeasure, and the value of the informational asset being protected. Furthermore, these processes have limitations as security breaches are generally rare and emerge in a specific context which may not be easily duplicated. Thus, any process and countermeasure should itself be evaluated for vulnerabilities. It is not possible to identify all risks, nor is it possible to eliminate all risk. The remaining risk is called \"residual risk.\"\nA risk assessment is carried out by a team of people who have knowledge of specific areas of the business. Membership of the team may vary over time as different parts of the business are assessed. The assessment may use a subjective qualitative analysis based on informed opinion, or where reliable dollar figures and historical information is available, the analysis may use quantitative analysis.\nResearch has shown that the most vulnerable point in most information systems is the human user, operator, designer, or other human. The ISO/IEC 27002:2005 Code of practice for information security management recommends the following be examined during a risk assessment:\n\nsecurity policy,\norganization of information security,\nasset management,\nhuman resources security,\nphysical and environmental security,\ncommunications and operations management,\naccess control,\ninformation systems acquisition, development, and maintenance,\ninformation security incident management,\nbusiness continuity management\nregulatory compliance.In broad terms, the risk management process consists of:\nIdentification of assets and estimating their value. Include: people, buildings, hardware, software, data (electronic, print, other), supplies.\nConduct a threat assessment. Include: Acts of nature, acts of war, accidents, malicious acts originating from inside or outside the organization.\nConduct a vulnerability assessment, and for each vulnerability, calculate the probability that it will be exploited. Evaluate policies, procedures, standards, training, physical security, quality control, technical security.\nCalculate the impact that each threat would have on each asset. Use qualitative analysis or quantitative analysis.\nIdentify, select and implement appropriate controls. Provide a proportional response. Consider productivity, cost effectiveness, and value of the asset.\nEvaluate the effectiveness of the control measures. Ensure the controls provide the required cost effective protection without discernible loss of productivity.For any given risk, management can choose to accept the risk based upon the relative low value of the asset, the relative low frequency of occurrence, and the relative low impact on the business. Or, leadership may choose to mitigate the risk by selecting and implementing appropriate control measures to reduce the risk. In some cases, the risk can be transferred to another business by buying insurance or outsourcing to another business. The reality of some risks may be disputed. In such cases leadership may choose to deny the risk.\n\n\n*** Security controls ***\n\nSelecting and implementing proper security controls will initially help an organization bring down risk to acceptable levels. Control selection should follow and should be based on the risk assessment. Controls can vary in nature, but fundamentally they are ways of protecting the confidentiality, integrity or availability of information. ISO/IEC 27001 has defined controls in different areas. Organizations can implement additional controls according to requirement of the organization. ISO/IEC 27002 offers a guideline for organizational information security standards.\n\n\n**** Administrative ****\nAdministrative controls (also called procedural controls) consist of approved written policies, procedures, standards, and guidelines. Administrative controls form the framework for running the business and managing people. They inform people on how the business is to be run and how day-to-day operations are to be conducted. Laws and regulations created by government bodies are also a type of administrative control because they inform the business. Some industry sectors have policies, procedures, standards, and guidelines that must be followed \u2013 the Payment Card Industry Data Security Standard (PCI DSS) required by Visa and MasterCard is such an example. Other examples of administrative controls include the corporate security policy, password policy, hiring policies, and disciplinary policies.Administrative controls form the basis for the selection and implementation of logical and physical controls. Logical and physical controls are manifestations of administrative controls, which are of paramount importance.\n\n\n**** Logical ****\nLogical controls (also called technical controls) use software and data to monitor and control access to information and computing systems. Passwords, network and host-based firewalls, network intrusion detection systems, access control lists, and data encryption are examples of logical controls.An important logical control that is frequently overlooked is the principle of least privilege, which requires that an individual, program or system process not be granted any more access privileges than are necessary to perform the task. A blatant example of the failure to adhere to the principle of least privilege is logging into Windows as user Administrator to read email and surf the web. Violations of this principle can also occur when an individual collects additional access privileges over time. This happens when employees' job duties change, employees are promoted to a new position, or employees are transferred to another department. The access privileges required by their new duties are frequently added onto their already existing access privileges, which may no longer be necessary or appropriate.\n\n\n**** Physical ****\nPhysical controls monitor and control the environment of the work place and computing facilities. They also monitor and control access to and from such facilities and include doors, locks, heating and air conditioning, smoke and fire alarms, fire suppression systems, cameras, barricades, fencing, security guards, cable locks, etc. Separating the network and workplace into functional areas are also physical controls.An important physical control that is frequently overlooked is separation of duties, which ensures that an individual can not complete a critical task by himself. For example, an employee who submits a request for reimbursement should not also be able to authorize payment or print the check. An applications programmer should not also be the server administrator or the database administrator; these roles and responsibilities must be separated from one another.\n\n\n*** Defense in depth ***\n\nInformation security must protect information throughout its lifespan, from the initial creation of the information on through to the final disposal of the information. The information must be protected while in motion and while at rest. During its lifetime, information may pass through many different information processing systems and through many different parts of information processing systems. There are many different ways the information and information systems can be threatened. To fully protect the information during its lifetime, each component of the information processing system must have its own protection mechanisms. The building up, layering on, and overlapping of security measures is called \"defense in depth.\" In contrast to a metal chain, which is famously only as strong as its weakest link, the defense in depth strategy aims at a structure where, should one defensive measure fail, other measures will continue to provide protection.Recall the earlier discussion about administrative controls, logical controls, and physical controls. The three types of controls can be used to form the basis upon which to build a defense in depth strategy. With this approach, defense in depth can be conceptualized as three distinct layers or planes laid one on top of the other. Additional insight into defense in depth can be gained by thinking of it as forming the layers of an onion, with data at the core of the onion, people the next outer layer of the onion, and network security, host-based security, and application security forming the outermost layers of the onion. Both perspectives are equally valid, and each provides valuable insight into the implementation of a good defense in depth strategy.\n\n\n*** Classification ***\nAn important aspect of information security and risk management is recognizing the value of information and defining appropriate procedures and protection requirements for the information. Not all information is equal and so not all information requires the same degree of protection. This requires information to be assigned a security classification. The first step in information classification is to identify a member of senior management as the owner of the particular information to be classified. Next, develop a classification policy. The policy should describe the different classification labels, define the criteria for information to be assigned a particular label, and list the required security controls for each classification.Some factors that influence which classification information should be assigned include how much value that information has to the organization, how old the information is and whether or not the information has become obsolete. Laws and other regulatory requirements are also important considerations when classifying information. The Information Systems Audit and Control Association (ISACA) and its Business Model for Information Security also serves as a tool for security professionals to examine security from a systems perspective, creating an environment where security can be managed holistically, allowing actual risks to be addressed.The type of information security classification labels selected and used will depend on the nature of the organization, with examples being:\nIn the business sector, labels such as: Public, Sensitive, Private, Confidential.\nIn the government sector, labels such as: Unclassified, Unofficial, Protected, Confidential, Secret, Top Secret, and their non-English equivalents.\nIn cross-sectoral formations, the Traffic Light Protocol, which consists of: White, Green, Amber, and Red.\nIn the personal sector, one label such as Financial. This includes activities related to managing money, such as online banking.All employees in the organization, as well as business partners, must be trained on the classification schema and understand the required security controls and handling procedures for each classification. The classification of a particular information asset that has been assigned should be reviewed periodically to ensure the classification is still appropriate for the information and to ensure the security controls required by the classification are in place and are followed in their right procedures.\n\n\n*** Access control ***\nAccess to protected information must be restricted to people who are authorized to access the information. The computer programs, and in many cases the computers that process the information, must also be authorized. This requires that mechanisms be in place to control the access to protected information. The sophistication of the access control mechanisms should be in parity with the value of the information being protected; the more sensitive or valuable the information the stronger the control mechanisms need to be. The foundation on which access control mechanisms are built start with identification and authentication.Access control is generally considered in three steps: identification, authentication, and authorization.\n\n\n**** Identification ****\nIdentification is an assertion of who someone is or what something is. If a person makes the statement \"Hello, my name is John Doe\" they are making a claim of who they are. However, their claim may or may not be true. Before John Doe can be granted access to protected information it will be necessary to verify that the person claiming to be John Doe really is John Doe. Typically the claim is in the form of a username. By entering that username you are claiming \"I am the person the username belongs to\".\n\n\n**** Authentication ****\nAuthentication is the act of verifying a claim of identity. When John Doe goes into a bank to make a withdrawal, he tells the bank teller he is John Doe, a claim of identity. The bank teller asks to see a photo ID, so he hands the teller his driver's license. The bank teller checks the license to make sure it has John Doe printed on it and compares the photograph on the license against the person claiming to be John Doe. If the photo and name match the person, then the teller has authenticated that John Doe is who he claimed to be. Similarly, by entering the correct password, the user is providing evidence that he/she is the person the username belongs to.There are three different types of information that can be used for authentication:\nSomething you know: things such as a PIN, a password, or your mother's maiden name\nSomething you have: a driver's license or a magnetic swipe card\nSomething you are: biometrics, including palm prints, fingerprints, voice prints, and retina (eye) scansStrong authentication requires providing more than one type of authentication information (two-factor authentication). The username is the most common form of identification on computer systems today and the password is the most common form of authentication. Usernames and passwords have served their purpose, but they are increasingly inadequate. Usernames and passwords are slowly being replaced or supplemented with more sophisticated authentication mechanisms such as Time-based One-time Password algorithms.\n\n\n**** Authorization ****\nAfter a person, program or computer has successfully been identified and authenticated then it must be determined what informational resources they are permitted to access and what actions they will be allowed to perform (run, view, create, delete, or change). This is called authorization. Authorization to access information and other computing services begins with administrative policies and procedures. The policies prescribe what information and computing services can be accessed, by whom, and under what conditions. The access control mechanisms are then configured to enforce these policies. Different computing systems are equipped with different kinds of access control mechanisms. Some may even offer a choice of different access control mechanisms. The access control mechanism a system offers will be based upon one of three approaches to access control, or it may be derived from a combination of the three approaches.The non-discretionary approach consolidates all access control under a centralized administration. The access to information and other resources is usually based on the individuals function (role) in the organization or the tasks the individual must perform. The discretionary approach gives the creator or owner of the information resource the ability to control access to those resources. In the mandatory access control approach, access is granted or denied basing upon the security classification assigned to the information resource.Examples of common access control mechanisms in use today include role-based access control, available in many advanced database management systems; simple file permissions provided in the UNIX and Windows operating systems; Group Policy Objects provided in Windows network systems; and Kerberos, RADIUS, TACACS, and the simple access lists used in many firewalls and routers.To be effective, policies and other security controls must be enforceable and upheld. Effective policies ensure that people are held accountable for their actions. The U.S. Treasury's guidelines for systems processing sensitive or proprietary information, for example, states that all failed and successful authentication and access attempts must be logged, and all access to information must leave some type of audit trail.Also, the need-to-know principle needs to be in effect when talking about access control. This principle gives access rights to a person to perform their job functions. This principle is used in the government when dealing with difference clearances. Even though two employees in different departments have a top-secret clearance, they must have a need-to-know in order for information to be exchanged. Within the need-to-know principle, network administrators grant the employee the least amount of privilege to prevent employees from accessing more than what they are supposed to. Need-to-know helps to enforce the confidentiality-integrity-availability triad. Need-to-know directly impacts the confidential area of the triad.\n\n\n*** Cryptography ***\n\nInformation security uses cryptography to transform usable information into a form that renders it unusable by anyone other than an authorized user; this process is called encryption. Information that has been encrypted (rendered unusable) can be transformed back into its original usable form by an authorized user who possesses the cryptographic key, through the process of decryption. Cryptography is used in information security to protect information from unauthorized or accidental disclosure while the information is in transit (either electronically or physically) and while information is in storage.Cryptography provides information security with other useful applications as well, including improved authentication methods, message digests, digital signatures, non-repudiation, and encrypted network communications. Older, less secure applications such as Telnet and File Transfer Protocol (FTP) are slowly being replaced with more secure applications such as Secure Shell (SSH) that use encrypted network communications. Wireless communications can be encrypted using protocols such as WPA/WPA2 or the older (and less secure) WEP. Wired communications (such as ITU\u2011T G.hn) are secured using AES for encryption and X.1035 for authentication and key exchange. Software applications such as GnuPG or PGP can be used to encrypt data files and email.Cryptography can introduce security problems when it is not implemented correctly. Cryptographic solutions need to be implemented using industry-accepted solutions that have undergone rigorous peer review by independent experts in cryptography. The length and strength of the encryption key is also an important consideration. A key that is weak or too short will produce weak encryption. The keys used for encryption and decryption must be protected with the same degree of rigor as any other confidential information. They must be protected from unauthorized disclosure and destruction, and they must be available when needed. Public key infrastructure (PKI) solutions address many of the problems that surround key management.\n\n== Process ==\nThe terms \"reasonable and prudent person\", \"due care\", and \"due diligence\" have been used in the fields of finance, securities, and law for many years. In recent years these terms have found their way into the fields of computing and information security. U.S. Federal Sentencing Guidelines now make it possible to hold corporate officers liable for failing to exercise due care and due diligence in the management of their information systems.In the business world, stockholders, customers, business partners, and governments have the expectation that corporate officers will run the business in accordance with accepted business practices and in compliance with laws and other regulatory requirements. This is often described as the \"reasonable and prudent person\" rule. A prudent person takes due care to ensure that everything necessary is done to operate the business by sound business principles and in a legal, ethical manner. A prudent person is also diligent (mindful, attentive, ongoing) in their due care of the business.\nIn the field of information security, Harris\noffers the following definitions of due care and due diligence:\n\n\"Due care are steps that are taken to show that a company has taken responsibility for the activities that take place within the corporation and has taken the necessary steps to help protect the company, its resources, and employees.\" And, [Due diligence are the] \"continual activities that make sure the protection mechanisms are continually maintained and operational.\"\nAttention should be made to two important points in these definitions. First, in due care, steps are taken to show; this means that the steps can be verified, measured, or even produce tangible artifacts. Second, in due diligence, there are continual activities; this means that people are actually doing things to monitor and maintain the protection mechanisms, and these activities are ongoing.Organizations have a responsibility with practicing duty of care when applying information security. The Duty of Care Risk Analysis Standard (DoCRA) provides principles and practices for evaluating risk. It considers all parties that could be affected by those risks. DoCRA helps evaluate safeguards if they are appropriate in protecting others from harm while presenting a reasonable burden. With increased data breach litigation, companies must balance security controls, compliance, and its mission.\n\n\n*** Security governance ***\n\nThe Software Engineering Institute at Carnegie Mellon University, in a publication titled Governing for Enterprise Security (GES) Implementation Guide, defines characteristics of effective security governance. These include:\nAn enterprise-wide issue\nLeaders are accountable\nViewed as a business requirement\nRisk-based\nRoles, responsibilities, and segregation of duties defined\nAddressed and enforced in policy\nAdequate resources committed\nStaff aware and trained\nA development life cycle requirement\nPlanned, managed, measurable, and measured\nReviewed and audited\n\n\n*** Incident response plans ***\nAn incident response plan (IRP) is a group of policies that dictate an organizations reaction to a cyber attack. Once an security breach has been identified, for example by Network Intrusion Detection System (NIDS) or Host-Based Intrusion Detection System (HIDS) (if configured to do so),  the plan is initiated. It is important to note that there can be legal implications to a data breach. Knowing local and federal laws is critical. Every plan is unique to the needs of the organization, and it can involve skill sets that are not part of an IT team. For example, a lawyer may be included in the response plan to help navigate legal implications to a data breach.As mentioned above every plan is unique but most plans will include the following:\n\n\n**** Preparation ****\nGood preparation includes the development of an Incident Response Team (IRT). Skills need to be used by this team would be, penetration testing, computer forensics, network security, etc. This team should also keep track of trends in cybersecurity and modern attack strategies. A training program for end users is important as well as most modern attack strategies target users on the network.\n\n\n**** Identification ****\nThis part of the incident response plan identifies if there was a security event. When an end user reports information or an admin notices irregularities, an investigation is launched. An incident log is a crucial part of this step. All of the members of the team should be updating this log to ensure that information flows as fast as possible. If it has been identified that a security breach has occurred the next step should be activated.\n\n\n**** Containment ****\nIn this phase, the IRT works to isolate the areas that the breach took place to limit the scope of the security event. During this phase it is important to preserve information forensically so it can be analyzed later in the process. Containment could be as simple as physically containing a server room or as complex as segmenting a network to not allow the spread of a virus.\n\n\n**** Eradication ****\nThis is where the threat that was identified is removed from the affected systems. This could include deleting malicious files, terminating compromised accounts, or deleting other components. Some events do not require this step, however it is important to fully understand the event before moving to this step. This will help to ensure that the threat is completely removed.\n\n\n**** Recovery ****\nThis stage is where the systems are restored back to original operation. This stage could include the recovery of data, changing user access information, or updating firewall rules or policies to prevent a breach in the future. Without executing this step, the system could still be vulnerable to future security threats.\n\n\n**** Lessons Learned ****\nIn this step information that has been gathered during this process is used to make future decisions on security. This step is crucial to the ensure that future events are prevented. Using this information to further train admins is critical to the process. This step can also be used to process information that is distributed from other entities who have experienced a security event.\n\n\n*** Change management ***\n\nChange management is a formal process for directing and controlling alterations to the information processing environment. This includes alterations to desktop computers, the network, servers, and software. The objectives of change management are to reduce the risks posed by changes to the information processing environment and improve the stability and reliability of the processing environment as changes are made. It is not the objective of change management to prevent or hinder necessary changes from being implemented.Any change to the information processing environment introduces an element of risk. Even apparently simple changes can have unexpected effects. One of management's many responsibilities is the management of risk. Change management is a tool for managing the risks introduced by changes to the information processing environment. Part of the change management process ensures that changes are not implemented at inopportune times when they may disrupt critical business processes or interfere with other changes being implemented.Not every change needs to be managed. Some kinds of changes are a part of the everyday routine of information processing and adhere to a predefined procedure, which reduces the overall level of risk to the processing environment. Creating a new user account or deploying a new desktop computer are examples of changes that do not generally require change management. However, relocating user file shares, or upgrading the Email server pose a much higher level of risk to the processing environment and are not a normal everyday activity. The critical first steps in change management are (a) defining change (and communicating that definition) and (b) defining the scope of the change system.Change management is usually overseen by a change review board composed of representatives from key business areas, security, networking, systems administrators, database administration, application developers, desktop support, and the help desk. The tasks of the change review board can be facilitated with the use of automated work flow application. The responsibility of the change review board is to ensure the organization's documented change management procedures are followed. The change management process is as follows\nRequest: Anyone can request a change. The person making the change request may or may not be the same person that performs the analysis or implements the change. When a request for change is received, it may undergo a preliminary review to determine if the requested change is compatible with the organizations business model and practices, and to determine the amount of resources needed to implement the change.\nApprove: Management runs the business and controls the allocation of resources therefore, management must approve requests for changes and assign a priority for every change. Management might choose to reject a change request if the change is not compatible with the business model, industry standards or best practices. Management might also choose to reject a change request if the change requires more resources than can be allocated for the change.\nPlan: Planning a change involves discovering the scope and impact of the proposed change; analyzing the complexity of the change; allocation of resources and, developing, testing, and documenting both implementation and back-out plans. Need to define the criteria on which a decision to back out will be made.\nTest: Every change must be tested in a safe test environment, which closely reflects the actual production environment, before the change is applied to the production environment. The backout plan must also be tested.\nSchedule: Part of the change review board's responsibility is to assist in the scheduling of changes by reviewing the proposed implementation date for potential conflicts with other scheduled changes or critical business activities.\nCommunicate: Once a change has been scheduled it must be communicated. The communication is to give others the opportunity to remind the change review board about other changes or critical business activities that might have been overlooked when scheduling the change. The communication also serves to make the help desk and users aware that a change is about to occur. Another responsibility of the change review board is to ensure that scheduled changes have been properly communicated to those who will be affected by the change or otherwise have an interest in the change.\nImplement: At the appointed date and time, the changes must be implemented. Part of the planning process was to develop an implementation plan, testing plan and, a back out plan. If the implementation of the change should fail or, the post implementation testing fails or, other \"drop dead\" criteria have been met, the back out plan should be implemented.\nDocument: All changes must be documented. The documentation includes the initial request for change, its approval, the priority assigned to it, the implementation, testing and back out plans, the results of the change review board critique, the date/time the change was implemented, who implemented it, and whether the change was implemented successfully, failed or postponed.\nPost-change review: The change review board should hold a post-implementation review of changes. It is particularly important to review failed and backed out changes. The review board should try to understand the problems that were encountered, and look for areas for improvement.Change management procedures that are simple to follow and easy to use can greatly reduce the overall risks created when changes are made to the information processing environment. Good change management procedures improve the overall quality and success of changes as they are implemented. This is accomplished through planning, peer review, documentation, and communication.ISO/IEC 20000, The Visible OPS Handbook: Implementing ITIL in 4 Practical and Auditable Steps (Full book summary), and ITIL all provide valuable guidance on implementing an efficient and effective change management program information security.\n\n== Business continuity ==\nBusiness continuity management (BCM) concerns arrangements aiming to protect an organization's critical business functions from interruption due to incidents, or at least minimize the effects. BCM is essential to any organization to keep technology and business in line with current threats to the continuation of business as usual. The BCM should be included in an organizations risk analysis plan to ensure that all of the necessary business functions have what they need to keep going in the event of any type of threat to any business function.It encompasses:\n\nAnalysis of requirements, e.g., identifying critical business functions, dependencies and potential failure points, potential threats and hence incidents or risks of concern to the organization;\nSpecification, e.g., maximum tolerable outage periods; recovery point objectives (maximum acceptable periods of data loss);\nArchitecture and design, e.g., an appropriate combination of approaches including resilience (e.g. engineering IT systems and processes for high availability, avoiding or preventing situations that might interrupt the business), incident and emergency management (e.g., evacuating premises, calling the emergency services, triage/situation assessment and invoking recovery plans), recovery (e.g., rebuilding) and contingency management (generic capabilities to deal positively with whatever occurs using whatever resources are available);\nImplementation, e.g., configuring and scheduling backups, data transfers, etc., duplicating and strengthening critical elements; contracting with service and equipment suppliers;\nTesting, e.g., business continuity exercises of various types, costs and assurance levels;\nManagement, e.g., defining strategies, setting objectives and goals; planning and directing the work; allocating funds, people and other resources; prioritization relative to other activities; team building, leadership, control, motivation and coordination with other business functions and activities (e.g., IT, facilities, human resources, risk management, information risk and security, operations); monitoring the situation, checking and updating the arrangements when things change; maturing the approach through continuous improvement, learning and appropriate investment;\nAssurance, e.g., testing against specified requirements; measuring, analyzing, and reporting key parameters; conducting additional tests, reviews and audits for greater confidence that the arrangements will go to plan if invoked.Whereas BCM takes a broad approach to minimizing disaster-related risks by reducing both the probability and the severity of incidents, a disaster recovery plan (DRP) focuses specifically on resuming business operations as quickly as possible after a disaster. A disaster recovery plan, invoked soon after a disaster occurs, lays out the steps necessary to recover critical information and communications technology (ICT) infrastructure. Disaster recovery planning includes establishing a planning group, performing risk assessment, establishing priorities, developing recovery strategies, preparing inventories and documentation of the plan, developing verification criteria and procedure, and lastly implementing the plan.\n\n== Laws and regulations ==\n\nBelow is a partial listing of governmental laws and regulations in various parts of the world that have, had, or will have, a significant effect on data processing and information security. Important industry sector regulations have also been included when they have a significant impact on information security.\nThe UK Data Protection Act 1998 makes new provisions for the regulation of the processing of information relating to individuals, including the obtaining, holding, use or disclosure of such information. The European Union Data Protection Directive (EUDPD) requires that all E.U. members adopt national regulations to standardize the protection of data privacy for citizens throughout the E.U.\nThe Computer Misuse Act 1990 is an Act of the U.K. Parliament making computer crime (e.g., hacking) a criminal offense. The act has become a model upon which several other countries, including Canada and the Republic of Ireland, have drawn inspiration from when subsequently drafting their own information security laws.\nThe E.U.'s Data Retention Directive (annulled) required internet service providers and phone companies to keep data on every electronic message sent and phone call made for between six months and two years.\nThe Family Educational Rights and Privacy Act (FERPA) (20 U.S.C. \u00a7 1232 g; 34 CFR Part 99) is a U.S. Federal law that protects the privacy of student education records. The law applies to all schools that receive funds under an applicable program of the U.S. Department of Education. Generally, schools must have written permission from the parent or eligible student in order to release any information from a student's education record.\nThe Federal Financial Institutions Examination Council's (FFIEC) security guidelines for auditors specifies requirements for online banking security.\nThe Health Insurance Portability and Accountability Act (HIPAA) of 1996 requires the adoption of national standards for electronic health care transactions and national identifiers for providers, health insurance plans, and employers. Additionally, it requires health care providers, insurance providers and employers to safeguard the security and privacy of health data.\nThe Gramm\u2013Leach\u2013Bliley Act of 1999 (GLBA), also known as the Financial Services Modernization Act of 1999, protects the privacy and security of private financial information that financial institutions collect, hold, and process.\nSection 404 of the Sarbanes\u2013Oxley Act of 2002 (SOX) requires publicly traded companies to assess the effectiveness of their internal controls for financial reporting in annual reports they submit at the end of each fiscal year. Chief information officers are responsible for the security, accuracy, and the reliability of the systems that manage and report the financial data. The act also requires publicly traded companies to engage with independent auditors who must attest to, and report on, the validity of their assessments.\nThe Payment Card Industry Data Security Standard (PCI DSS) establishes comprehensive requirements for enhancing payment account data security. It was developed by the founding payment brands of the PCI Security Standards Council \u2014 including American Express, Discover Financial Services, JCB, MasterCard Worldwide, and Visa International \u2014 to help facilitate the broad adoption of consistent data security measures on a global basis. The PCI DSS is a multifaceted security standard that includes requirements for security management, policies, procedures, network architecture, software design, and other critical protective measures.\nState security breach notification laws (California and many others) require businesses, nonprofits, and state institutions to notify consumers when unencrypted \"personal information\" may have been compromised, lost, or stolen.\nThe Personal Information Protection and Electronics Document Act (PIPEDA) of Canada supports and promotes electronic commerce by protecting personal information that is collected, used or disclosed in certain circumstances, by providing for the use of electronic means to communicate or record information or transactions and by amending the Canada Evidence Act, the Statutory Instruments Act and the Statute Revision Act.\nGreece's Hellenic Authority for Communication Security and Privacy (ADAE) (Law 165/2011) establishes and describes the minimum information security controls that should be deployed by every company which provides electronic communication networks and/or services in Greece in order to protect customers' confidentiality. These include both managerial and technical controls (e.g., log records should be stored for two years).\nGreece's Hellenic Authority for Communication Security and Privacy (ADAE) (Law 205/2013) concentrates around the protection of the integrity and availability of the services and data offered by Greek telecommunication companies. The law forces these and other related companies to build, deploy, and test appropriate business continuity plans and redundant infrastructures.The US Department of Defense (DoD) issued DoD Directive 8570 in 2004, supplemented by DoD Directive 8140, requiring all DoD employees and all DoD contract personnel involved in information assurance roles and activities to earn and maintain various industry Information Technology (IT) certifications in an effort to ensure that all DoD personnel involved in network infrastructure defense have minimum levels of IT industry recognized knowledge, skills and abilities (KSA). Andersson and Reimers (2019) report these certifications range from CompTIA's A+ and Security+ through the ICS2.org's CISSP, etc..\n\n== Culture ==\nDescribing more than simply how security aware employees are, information security culture is the ideas, customs, and social behaviors of an organization that impact information security in both positive and negative ways. Cultural concepts can help different segments of the organization work effectively or work against effectiveness towards information security within an organization. The way employees think and feel about security and the actions they take can have a big impact on information security in organizations. Roer & Petric (2017) identify seven core dimensions of information security culture in organizations:\nAttitudes: Employees' feelings and emotions about the various activities that pertain to the organizational security of information.\nBehaviors: Actual or intended activities and risk-taking actions of employees that have direct or indirect impact on information security.\nCognition: Employees' awareness, verifiable knowledge, and beliefs regarding practices, activities, and self-efficacy relation that are related to information security.\nCommunication: Ways employees communicate with each other, sense of belonging, support for security issues, and incident reporting.\nCompliance: Adherence to organizational security policies, awareness of the existence of such policies and the ability to recall the substance of such policies.\nNorms: Perceptions of security-related organizational conduct and practices that are informally deemed either normal or deviant by employees and their peers, e.g. hidden expectations regarding security behaviors and unwritten rules regarding uses of information-communication technologies.\nResponsibilities: Employees' understanding of the roles and responsibilities they have as a critical factor in sustaining or endangering the security of information, and thereby the organization.Andersson and Reimers (2014) found that employees often do not see themselves as part of the organization Information Security \"effort\" and often take actions that ignore organizational information security best interests. Research shows information security culture needs to be improved continuously. In Information Security Culture from Analysis to Change, authors commented, \"It's a never ending process, a cycle of evaluation and change or maintenance.\" To manage the information security culture, five steps should be taken: pre-evaluation, strategic planning, operative planning, implementation, and post-evaluation.\nPre-Evaluation: to identify the awareness of information security within employees and to analyze current security policy\nStrategic Planning: to come up a better awareness-program, we need to set clear targets. Clustering people is helpful to achieve it\nOperative Planning: create a good security culture based on internal communication, management buy-in, security awareness, and training programs\nImplementation: should feature commitment of management, communication with organizational members, courses for all organizational members, and commitment of the employees\nPost-evaluation: to better gauge the effectiveness of the prior steps and build on continuous improvement\n\n== Sources of standards ==\n\nThe International Organization for Standardization (ISO) is an international standards organization organized as a consortium of national standards institutions from 167 countries, coordinated through a secretariat in Geneva, Switzerland. ISO is the world's largest developer of international standards. The International Electrotechnical Commission (IEC) is an international standards organization that deals with electrotechnology and cooperates closely with ISO. ISO/IEC 15443: \"Information technology \u2013 Security techniques \u2013 A framework for IT security assurance\", ISO/IEC 27002: \"Information technology \u2013 Security techniques \u2013 Code of practice for information security management\", ISO/IEC 20000: \"Information technology \u2013 Service management\", and ISO/IEC 27001: \"Information technology \u2013 Security techniques \u2013 Information security management systems \u2013 Requirements\" are of particular interest to information security professionals.\nThe US National Institute of Standards and Technology (NIST) is a non-regulatory federal agency within the U.S. Department of Commerce. The NIST Computer Security Division\ndevelops standards, metrics, tests, and validation programs as well as publishes standards and guidelines to increase secure IT planning, implementation, management, and operation. NIST is also the custodian of the U.S. Federal Information Processing Standard publications (FIPS).\nThe Internet Society is a professional membership society with more than 100 organizations and over 20,000 individual members in over 180 countries. It provides leadership in addressing issues that confront the future of the internet, and it is the organizational home for the groups responsible for internet infrastructure standards, including the Internet Engineering Task Force (IETF) and the Internet Architecture Board (IAB). The ISOC hosts the Requests for Comments (RFCs) which includes the Official Internet Protocol Standards and the RFC-2196 Site Security Handbook.\nThe Information Security Forum (ISF) is a global nonprofit organization of several hundred leading organizations in financial services, manufacturing, telecommunications, consumer goods, government, and other areas. It undertakes research into information security practices and offers advice in its biannual Standard of Good Practice and more detailed advisories for members.\nThe Institute of Information Security Professionals (IISP) is an independent, non-profit body governed by its members, with the principal objective of advancing the professionalism of information security practitioners and thereby the professionalism of the industry as a whole. The institute developed the IISP Skills Framework. This framework describes the range of competencies expected of information security and information assurance professionals in the effective performance of their roles. It was developed through collaboration between both private and public sector organizations, world-renowned academics, and security leaders.The German Federal Office for Information Security (in German Bundesamt f\u00fcr Sicherheit in der Informationstechnik (BSI)) BSI-Standards 100\u20131 to 100-4 are a set of recommendations including \"methods, processes, procedures, approaches and measures relating to information security\". The BSI-Standard 100-2 IT-Grundschutz Methodology describes how information security management can be implemented and operated. The standard includes a very specific guide, the IT Baseline Protection Catalogs (also known as IT-Grundschutz Catalogs). Before 2005, the catalogs were formerly known as \"IT Baseline Protection Manual\". The Catalogs are a collection of documents useful for detecting and combating security-relevant weak points in the IT environment (IT cluster). The collection encompasses as of September 2013 over 4,400 pages with the introduction and catalogs. The IT-Grundschutz approach is aligned with to the ISO/IEC 2700x family.\nThe European Telecommunications Standards Institute standardized a catalog of information security indicators, headed by the Industrial Specification Group (ISG) ISI."
    }
  },
  {
    "instruction": "Internet Security Association and Key Management Protocol\n\n==Introduction==\nInternet Security Association and Key Management Protocol (ISAKMP) is a protocol defined by RFC 2408 for establishing security association (SA) and cryptographic keys in an Internet environment. ISAKMP only provides a framework for authentication and key exchange and is designed to be key exchange independent; protocols such as Internet Key Exchange (IKE) and Kerberized Internet Negotiation of Keys (KINK) provide authenticated keying material for use with ISAKMP. For example: IKE describes a protocol using part of Oakley and part of SKEME in conjunction with ISAKMP to obtain authenticated keying material for use with ISAKMP, and for other security associations such as AH and ESP for the IETF IPsec DOI.\n\n\n\n== Overview ==\nISAKMP defines the procedures for authenticating a communicating peer, creation and management of Security Associations, key generation techniques and threat mitigation (e.g. denial of service and replay attacks).  As a framework, ISAKMP typically utilizes IKE for key exchange, although other methods have been implemented such as Kerberized Internet Negotiation of Keys.  A Preliminary SA is formed using this protocol; later a fresh keying is done.\nISAKMP is distinct from key exchange protocols in order to cleanly separate the details of security association management (and key management) from the details of key exchange.  There may be many different key exchange protocols, each with different security properties.  However, a common framework is required for agreeing to the format of SA attributes and for negotiating, modifying and deleting SAs.  ISAKMP serves as this common framework.\nISAKMP can be implemented over any transport protocol.  All implementations must include send and receive capability for ISAKMP using UDP on port 500.\n\n== Implementation ==\nOpenBSD first implemented ISAKMP in 1998 via its isakmpd(8) software.\nThe IPsec Services Service in Microsoft Windows handles this functionality.\nThe KAME project implements ISAKMP for Linux and most other open source BSDs.\nModern Cisco routers implement ISAKMP for VPN negotiation.\n\n== Vulnerabilities ==\nLeaked NSA presentations released by Der Spiegel indicate that ISAKMP is being exploited in an unknown manner to decrypt IPSec traffic, as is IKE. The researchers who discovered the Logjam attack state that breaking a 1024-bit Diffie\u2013Hellman group would break 66% of VPN servers, 18% of the top million HTTPS domains, and 26% of SSH servers, which is consistent with the leaks according to the researchers.\nQ: What is the role of Internet Security Association and Key Management Protocol (ISAKMP) in establishing security associations and cryptographic keys in an Internet environment?",
    "context": "",
    "output": "ISAKMP is a protocol that provides a framework for establishing security associations (SA) and cryptographic keys in an Internet environment. It is designed to be key exchange independent, and protocols such as Internet Key Exchange (IKE) and Kerberized Internet Negotiation of Keys (KINK) provide authenticated keying material for use with ISAKMP.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of Internet Security Association and Key Management Protocol (ISAKMP) in establishing security associations and cryptographic keys in an Internet environment?",
      "answer": "ISAKMP is a protocol that provides a framework for establishing security associations (SA) and cryptographic keys in an Internet environment. It is designed to be key exchange independent, and protocols such as Internet Key Exchange (IKE) and Kerberized Internet Negotiation of Keys (KINK) provide authenticated keying material for use with ISAKMP.",
      "context": "Internet Security Association and Key Management Protocol\n\n==Introduction==\nInternet Security Association and Key Management Protocol (ISAKMP) is a protocol defined by RFC 2408 for establishing security association (SA) and cryptographic keys in an Internet environment. ISAKMP only provides a framework for authentication and key exchange and is designed to be key exchange independent; protocols such as Internet Key Exchange (IKE) and Kerberized Internet Negotiation of Keys (KINK) provide authenticated keying material for use with ISAKMP. For example: IKE describes a protocol using part of Oakley and part of SKEME in conjunction with ISAKMP to obtain authenticated keying material for use with ISAKMP, and for other security associations such as AH and ESP for the IETF IPsec DOI.\n\n\n\n== Overview ==\nISAKMP defines the procedures for authenticating a communicating peer, creation and management of Security Associations, key generation techniques and threat mitigation (e.g. denial of service and replay attacks).  As a framework, ISAKMP typically utilizes IKE for key exchange, although other methods have been implemented such as Kerberized Internet Negotiation of Keys.  A Preliminary SA is formed using this protocol; later a fresh keying is done.\nISAKMP is distinct from key exchange protocols in order to cleanly separate the details of security association management (and key management) from the details of key exchange.  There may be many different key exchange protocols, each with different security properties.  However, a common framework is required for agreeing to the format of SA attributes and for negotiating, modifying and deleting SAs.  ISAKMP serves as this common framework.\nISAKMP can be implemented over any transport protocol.  All implementations must include send and receive capability for ISAKMP using UDP on port 500.\n\n== Implementation ==\nOpenBSD first implemented ISAKMP in 1998 via its isakmpd(8) software.\nThe IPsec Services Service in Microsoft Windows handles this functionality.\nThe KAME project implements ISAKMP for Linux and most other open source BSDs.\nModern Cisco routers implement ISAKMP for VPN negotiation.\n\n== Vulnerabilities ==\nLeaked NSA presentations released by Der Spiegel indicate that ISAKMP is being exploited in an unknown manner to decrypt IPSec traffic, as is IKE. The researchers who discovered the Logjam attack state that breaking a 1024-bit Diffie\u2013Hellman group would break 66% of VPN servers, 18% of the top million HTTPS domains, and 26% of SSH servers, which is consistent with the leaks according to the researchers."
    }
  },
  {
    "instruction": "Write an answer to the following question: How can stegomalware be removed from files?",
    "context": "",
    "output": "Stegomalware can be removed from certain files through content disarm and reconstruction (CDR) software, which involves reprocessing the entire file or removing parts from it. Actually detecting stegomalware in a file can be difficult and may involve testing the file behavior in virtual environments or deep learning analysis of the file.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can stegomalware be removed from files?",
      "answer": "Stegomalware can be removed from certain files through content disarm and reconstruction (CDR) software, which involves reprocessing the entire file or removing parts from it. Actually detecting stegomalware in a file can be difficult and may involve testing the file behavior in virtual environments or deep learning analysis of the file."
    }
  },
  {
    "instruction": "Write an answer to the following question: How can extreme weather events and natural disasters lead to internet outages?",
    "context": "",
    "output": "Extreme weather events and natural disasters can cause internet outages by directly destroying local ICT infrastructure or indirectly damaging the local electricity grid.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can extreme weather events and natural disasters lead to internet outages?",
      "answer": "Extreme weather events and natural disasters can cause internet outages by directly destroying local ICT infrastructure or indirectly damaging the local electricity grid."
    }
  },
  {
    "instruction": "Write an answer to the following question: What data serialization format does the CTAP protocol use?",
    "context": "",
    "output": "The CTAP protocol uses the CBOR binary data serialization format.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What data serialization format does the CTAP protocol use?",
      "answer": "The CTAP protocol uses the CBOR binary data serialization format."
    }
  },
  {
    "instruction": "Answer based on context:\n\nDigital forensic process\n\n==Introduction==\nThe digital forensic process is a recognized scientific and forensic process used in digital forensics investigations. Forensics researcher Eoghan Casey defines it as a number of steps from the original incident alert through to reporting of findings. The process is predominantly used in computer and mobile forensic investigations and consists of three steps: acquisition, analysis and reporting.\nDigital media seized for investigation is usually referred to as an \"exhibit\" in legal terminology. Investigators employ the scientific method to recover digital evidence to support or disprove a hypothesis, either for a court of law or in civil proceedings.\n\n== Personnel ==\nThe stages of the digital forensics process require different specialist training and knowledge. There are two rough levels of personnel:\nDigital forensic technician\nTechnicians gather or process evidence at crime scenes. These technicians are trained on the correct handling of technology (for example how to preserve the evidence). Technicians may be required to carry out \"Live analysis\" of evidence. Various tools to simplify this procedure have been produced, most notably Microsoft's COFEE.Digital Evidence Examiners\nExaminers specialize in one area of digital evidence; either at a broad level (i.e. computer or network forensics etc.) or as a sub-specialist (i.e. image analysis)\n\n== Process models ==\nThere have been many attempts to develop a process model but so far none have been universally accepted. Part of the reason for this may be due to the fact that many of the process models were designed for a specific environment, such as law enforcement, and they therefore could not be readily applied in other environments such as incident response. This is a list of the main models since 2001 in chronological order:\nThe Abstract Digital Forensic Model (Reith, et al., 2002)\nThe Integrated Digital Investigative Process (Carrier & Spafford, 2003) [1]\nAn Extended Model of Cybercrime Investigations (Ciardhuain, 2004)\nThe Enhanced Digital Investigation Process Model (Baryamureeba & Tushabe, 2004)[2]\nThe Digital Crime Scene Analysis Model (Rogers, 2004)\nA Hierarchical, Objectives-Based Framework for the Digital Investigations Process (Beebe & Clark, 2004)\nFramework for a Digital Investigation (Kohn, et al., 2006)[3]\nThe Four Step Forensic Process (Kent, et al., 2006)\nFORZA - Digital forensics investigation framework (Ieong, 2006)[4]\nProcess Flows for Cyber Forensics Training and Operations (Venter, 2006)\nThe Common Process Model (Freiling & Schwittay, (2007) [5]\nThe Two-Dimensional Evidence Reliability Amplification Process Model (Khatir, et al., 2008)[6]\nThe Digital Forensic Investigations Framework (Selamat, et al., 2008)\nThe Systematic Digital Forensic Investigation Model (SRDFIM) (Agarwal, et al., 2011)[7]\nThe Advanced Data Acquisition Model (ADAM): A process model for digital forensic practice (Adams, 2012) [8]\n\n== Seizure ==\nPrior to the actual examination, digital media will be seized. In criminal cases this will often be performed by law enforcement personnel trained as technicians to ensure the preservation of evidence. In civil matters it will usually be a company officer, often untrained. Various laws cover the seizure of material. In criminal matters, law related to search warrants is applicable. In civil proceedings, the assumption is that a company is able to investigate their own equipment without a warrant, so long as the privacy and human rights of employees are preserved.\n\n== Acquisition ==\n\nOnce exhibits have been seized, an exact sector level duplicate (or \"forensic duplicate\") of the media is created, usually via a write blocking device. The duplication process is referred to as Imaging or Acquisition. The duplicate is created using a hard-drive duplicator or software imaging tools such as DCFLdd, IXimager, Guymager, TrueBack, EnCase, FTK Imager or FDAS. The original drive is then returned to secure storage to prevent tampering.\nThe acquired image is verified by using the SHA-1 or MD5 hash functions. At critical points throughout the analysis, the media is verified again to ensure that the evidence is still in its original state. The process of verifying the image with a hash function is called \"hashing.\"\nGiven the problems associated with imaging large drives, multiple networked computers, file servers that cannot be shut down and cloud resources new techniques have been developed that combine digital forensic acquisition and ediscovery processes.\n\n== Analysis ==\nAfter acquisition the contents of (the HDD) image files are analysed to identify evidence that either supports or contradicts a hypothesis or for signs of tampering (to hide data). In 2002 the International Journal of Digital Evidence referred to this stage as \"an in-depth systematic search of evidence related to the suspected crime\". By contrast Brian Carrier, in 2006, describes a more \"intuitive procedure\" in which obvious evidence is first identified after which \"exhaustive searches are conducted to start filling in the holes\"During the analysis an investigator usually recovers evidence material using a number of different methodologies (and tools), often beginning with recovery of deleted material. Examiners use specialist tools (EnCase, ILOOKIX, FTK, etc.) to aid with viewing and recovering data. The type of data recovered varies depending on the investigation, but examples include email, chat logs, images, internet history or documents. The data can be recovered from accessible disk space, deleted (unallocated) space or from within operating system cache files.Various types of techniques are used to recover evidence, usually involving some form of keyword searching within the acquired image file, either to identify matches to relevant phrases or to filter out known file types. Certain files (such as graphic images) have a specific set of bytes which identify the start and end of a file. If identified, a deleted file can be reconstructed. Many forensic tools use hash signatures to identify notable files or to exclude known (benign) files; acquired data is hashed and compared to pre-compiled lists such as the Reference Data Set (RDS) from the National Software Reference LibraryOn most media types, including standard magnetic hard disks, once data has been securely deleted it can never be recovered.Once evidence is recovered the information is analysed to reconstruct events or actions and to reach conclusions, work that can often be performed by less specialized staff. Digital investigators, particularly in criminal investigations, have to ensure that conclusions are based upon data and their own expert knowledge. In the US, for example, Federal Rules of Evidence state that a qualified expert may testify \u201cin the form of an opinion or otherwise\u201d so long as:\n\n(1) the testimony is based upon sufficient facts or data, (2) the testimony is the product of reliable principles and methods, and (3) the witness has applied the principles and methods reliably to the facts of the case.\n\n== Reporting ==\nWhen an investigation is completed the information is often reported in a form suitable for non-technical individuals. Reports may also include audit information and other meta-documentation.When completed, reports are usually passed to those commissioning the investigation, such as law enforcement (for criminal cases) or the employing company (in civil cases), who will then decide whether to use the evidence in court. Generally, for a criminal court, the report package will consist of a written expert conclusion of the evidence as well as the evidence itself (often presented on digital media).\n\nWhat is the role of an examiner during the analysis stage of the digital forensic process?",
    "context": "",
    "output": "During the analysis, an investigator usually recovers evidence material using a number of different methodologies (and tools), often beginning with recovery of deleted material. Examiners use specialist tools to aid with viewing and recovering data, and the type of data recovered varies depending on the investigation.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of an examiner during the analysis stage of the digital forensic process?",
      "answer": "During the analysis, an investigator usually recovers evidence material using a number of different methodologies (and tools), often beginning with recovery of deleted material. Examiners use specialist tools to aid with viewing and recovering data, and the type of data recovered varies depending on the investigation.",
      "context": "Digital forensic process\n\n==Introduction==\nThe digital forensic process is a recognized scientific and forensic process used in digital forensics investigations. Forensics researcher Eoghan Casey defines it as a number of steps from the original incident alert through to reporting of findings. The process is predominantly used in computer and mobile forensic investigations and consists of three steps: acquisition, analysis and reporting.\nDigital media seized for investigation is usually referred to as an \"exhibit\" in legal terminology. Investigators employ the scientific method to recover digital evidence to support or disprove a hypothesis, either for a court of law or in civil proceedings.\n\n== Personnel ==\nThe stages of the digital forensics process require different specialist training and knowledge. There are two rough levels of personnel:\nDigital forensic technician\nTechnicians gather or process evidence at crime scenes. These technicians are trained on the correct handling of technology (for example how to preserve the evidence). Technicians may be required to carry out \"Live analysis\" of evidence. Various tools to simplify this procedure have been produced, most notably Microsoft's COFEE.Digital Evidence Examiners\nExaminers specialize in one area of digital evidence; either at a broad level (i.e. computer or network forensics etc.) or as a sub-specialist (i.e. image analysis)\n\n== Process models ==\nThere have been many attempts to develop a process model but so far none have been universally accepted. Part of the reason for this may be due to the fact that many of the process models were designed for a specific environment, such as law enforcement, and they therefore could not be readily applied in other environments such as incident response. This is a list of the main models since 2001 in chronological order:\nThe Abstract Digital Forensic Model (Reith, et al., 2002)\nThe Integrated Digital Investigative Process (Carrier & Spafford, 2003) [1]\nAn Extended Model of Cybercrime Investigations (Ciardhuain, 2004)\nThe Enhanced Digital Investigation Process Model (Baryamureeba & Tushabe, 2004)[2]\nThe Digital Crime Scene Analysis Model (Rogers, 2004)\nA Hierarchical, Objectives-Based Framework for the Digital Investigations Process (Beebe & Clark, 2004)\nFramework for a Digital Investigation (Kohn, et al., 2006)[3]\nThe Four Step Forensic Process (Kent, et al., 2006)\nFORZA - Digital forensics investigation framework (Ieong, 2006)[4]\nProcess Flows for Cyber Forensics Training and Operations (Venter, 2006)\nThe Common Process Model (Freiling & Schwittay, (2007) [5]\nThe Two-Dimensional Evidence Reliability Amplification Process Model (Khatir, et al., 2008)[6]\nThe Digital Forensic Investigations Framework (Selamat, et al., 2008)\nThe Systematic Digital Forensic Investigation Model (SRDFIM) (Agarwal, et al., 2011)[7]\nThe Advanced Data Acquisition Model (ADAM): A process model for digital forensic practice (Adams, 2012) [8]\n\n== Seizure ==\nPrior to the actual examination, digital media will be seized. In criminal cases this will often be performed by law enforcement personnel trained as technicians to ensure the preservation of evidence. In civil matters it will usually be a company officer, often untrained. Various laws cover the seizure of material. In criminal matters, law related to search warrants is applicable. In civil proceedings, the assumption is that a company is able to investigate their own equipment without a warrant, so long as the privacy and human rights of employees are preserved.\n\n== Acquisition ==\n\nOnce exhibits have been seized, an exact sector level duplicate (or \"forensic duplicate\") of the media is created, usually via a write blocking device. The duplication process is referred to as Imaging or Acquisition. The duplicate is created using a hard-drive duplicator or software imaging tools such as DCFLdd, IXimager, Guymager, TrueBack, EnCase, FTK Imager or FDAS. The original drive is then returned to secure storage to prevent tampering.\nThe acquired image is verified by using the SHA-1 or MD5 hash functions. At critical points throughout the analysis, the media is verified again to ensure that the evidence is still in its original state. The process of verifying the image with a hash function is called \"hashing.\"\nGiven the problems associated with imaging large drives, multiple networked computers, file servers that cannot be shut down and cloud resources new techniques have been developed that combine digital forensic acquisition and ediscovery processes.\n\n== Analysis ==\nAfter acquisition the contents of (the HDD) image files are analysed to identify evidence that either supports or contradicts a hypothesis or for signs of tampering (to hide data). In 2002 the International Journal of Digital Evidence referred to this stage as \"an in-depth systematic search of evidence related to the suspected crime\". By contrast Brian Carrier, in 2006, describes a more \"intuitive procedure\" in which obvious evidence is first identified after which \"exhaustive searches are conducted to start filling in the holes\"During the analysis an investigator usually recovers evidence material using a number of different methodologies (and tools), often beginning with recovery of deleted material. Examiners use specialist tools (EnCase, ILOOKIX, FTK, etc.) to aid with viewing and recovering data. The type of data recovered varies depending on the investigation, but examples include email, chat logs, images, internet history or documents. The data can be recovered from accessible disk space, deleted (unallocated) space or from within operating system cache files.Various types of techniques are used to recover evidence, usually involving some form of keyword searching within the acquired image file, either to identify matches to relevant phrases or to filter out known file types. Certain files (such as graphic images) have a specific set of bytes which identify the start and end of a file. If identified, a deleted file can be reconstructed. Many forensic tools use hash signatures to identify notable files or to exclude known (benign) files; acquired data is hashed and compared to pre-compiled lists such as the Reference Data Set (RDS) from the National Software Reference LibraryOn most media types, including standard magnetic hard disks, once data has been securely deleted it can never be recovered.Once evidence is recovered the information is analysed to reconstruct events or actions and to reach conclusions, work that can often be performed by less specialized staff. Digital investigators, particularly in criminal investigations, have to ensure that conclusions are based upon data and their own expert knowledge. In the US, for example, Federal Rules of Evidence state that a qualified expert may testify \u201cin the form of an opinion or otherwise\u201d so long as:\n\n(1) the testimony is based upon sufficient facts or data, (2) the testimony is the product of reliable principles and methods, and (3) the witness has applied the principles and methods reliably to the facts of the case.\n\n== Reporting ==\nWhen an investigation is completed the information is often reported in a form suitable for non-technical individuals. Reports may also include audit information and other meta-documentation.When completed, reports are usually passed to those commissioning the investigation, such as law enforcement (for criminal cases) or the employing company (in civil cases), who will then decide whether to use the evidence in court. Generally, for a criminal court, the report package will consist of a written expert conclusion of the evidence as well as the evidence itself (often presented on digital media)."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the CGA specification prevent an attacker from using a Sec value smaller than that of the target address in an attempt to skip the brute-force attack on Hash2?",
    "context": "",
    "output": "The CGA specification ensures that if an attacker tries to use a Sec value smaller than that of the target address, the result will be a different CGA from the target CGA since at least one of the three leftmost bits of the interface identifier would not match. If the target Sec value is written to the interface identifier anyway, then Hash2 will (almost certainly) be found to lack the required amount of leftmost 0-bits during the verification process.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the CGA specification prevent an attacker from using a Sec value smaller than that of the target address in an attempt to skip the brute-force attack on Hash2?",
      "answer": "The CGA specification ensures that if an attacker tries to use a Sec value smaller than that of the target address, the result will be a different CGA from the target CGA since at least one of the three leftmost bits of the interface identifier would not match. If the target Sec value is written to the interface identifier anyway, then Hash2 will (almost certainly) be found to lack the required amount of leftmost 0-bits during the verification process."
    }
  },
  {
    "instruction": "Context: Doxing\n\n==Introduction==\nDoxing or doxxing (originally spelled d0xing) is the act of publicly providing personally identifiable information about an individual or organization, usually via the Internet. Historically, the term has been used interchangeably to refer to both the aggregation of this information from public databases and social media websites (like Facebook), as well as the publication of previously private information obtained through criminal or otherwise fraudulent means (such as hacking and social engineering). The aggregation and provision of previously published material is generally a legal practice, though it may be subject to laws concerning stalking and intimidation. Doxing may be carried out for reasons such as online shaming, extortion, and vigilante aid to law enforcement. It also may be associated with hacktivism.\n\n\n\n== Etymology ==\n\"Doxing\" is a neologism. It originates from a spelling alteration of the abbreviation \"docs\", for \"documents\", and refers to \"compiling and releasing a dossier of personal information on someone\". Essentially, doxing is revealing and publicizing the records of an individual, which were previously private or difficult to obtain.\nThe term dox derives from the slang \"dropping dox\", which, according to a contributor to Wired, Mat Honan, was \"an old-school revenge tactic that emerged from hacker culture in 1990s\". Hackers operating outside the law in that era used the breach of an opponent's anonymity as a means to expose opponents to harassment or legal repercussions.Consequently, doxing often comes with a negative connotation because it can be a means of revenge via the violation of privacy.\n\n== Common techniques ==\nOnce people have been exposed through doxing, they may be targeted for harassment through methods such as actual harassment in person, fake signups for mail subscriptions, pizza deliveries, bombarding the address with letters, or through \u201cswatting\u201d\u2014the intentional dispatching of armed police teams (S.W.A.T.) to a person\u2019s address via falsely reported tips or through fake emergency services phone calls. The act of reporting a false tip to police\u2014and the subsequent summoning of an emergency response team (ERT)\u2014is an illegal, punishable offense in most jurisdictions, due to ERTs being compromised and potentially unavailable for real emergencies. It is, at the very least, an infraction in most US states (for first-time offenders); if multiple attempts are made, the charge increases to a misdemeanor (especially when the intention is harassment-based). Further repercussions include fines ranging from as low as USD$50 up to USD$2,000, six months spent in county jail, or both the fine and imprisonment.A hacker may obtain an individual's dox without making the information public. A hacker may look for this information to extort or coerce a known or unknown target. A hacker may also harvest a victim's information to break into their Internet accounts or take over their social media accounts.Doxing has also occurred in dating apps. In a survey conducted in 2021, 16% of respondents reported suffering doxing because of them. In a 2018 qualitative studio about intimate partner violence, 28 out of 89 participants (both professionals and survivors) reported the exposure of the victim's private information to third parties through digital technologies as a form of humiliation, shaming or harm frequently practiced by abusers, that may include the disclosure of intimate images and impersonation of the victim.Victims may also be shown their details as proof that they have been doxed as a form of intimidation. The perpetrator may use this fear to gain power over victims in order to extort or coerce. Doxing is therefore a standard tactic of online harassment and has been used by people associated with the Gamergate and vaccine controversies.\n\n== Examples ==\n\n\n*** Doxing of abortion providers ***\n\nIn the United States, in the 1970s and 80s (paper) and the 1990s (digitally), anti-abortion activists secured abortion providers' personal information, such as home addresses, phone numbers, and photographs, and posted them as a hit list. The courts later ruled this to be an immediate incitement to violence. Between 1993 and 2016, eight abortion providers were killed by anti-abortion activists, along with at least four police officers.\n\n\n*** Human flesh search engine ***\n\nStarting in March 2006, the Chinese Internet phenomenon of the \"Human flesh search engine\"\uff08\u4eba\u8089\u641c\u7d22\uff09shares much in common with doxing. Specifically, it refers to distributed, sometimes deliberately crowdsourced searches for similar kinds of information through use of digital media.\n\n\n*** Anonymous ***\n\nThe term \"dox\" entered mainstream public awareness through media attention attracted by Anonymous, the Internet-based group of hacktivists and pranksters who make frequent use of doxing, as well as related groups like AntiSec and LulzSec. The Washington Post has described the consequences for innocent people incorrectly accused of wrongdoing and doxed as \"nightmarish\".In December 2011, Anonymous exposed detailed information of 7,000 law enforcement members in response to investigations into hacking activities.In November 2014, Anonymous began releasing the identities of members of the Ku Klux Klan. This was concerning local Klan members in Ferguson, Missouri, making threats to shoot those protesting the shooting of Michael Brown. Anonymous also hijacked the group's Twitter page, causing Klan members to make veiled threats of violence against members of Anonymous. In November 2015, a major release of information about the KKK was planned. Discredited information was released prematurely, and Anonymous denied involvement. On 5 November 2015 (Guy Fawkes Night), Anonymous released an official list of supposed, but currently unverified, KKK members and sympathizers.\n\n\n*** Boston Marathon ***\nFollowing the 15 April 2013 Boston Marathon bombing, internet vigilantes on Reddit wrongly identified a number of people as suspects. Notable among misidentified bombing suspects was Sunil Tripathi, a student reported missing before the bombings took place. A body reported to be Tripathi's was found in Rhode Island's Providence River on 25 April 2013, as reported by the Rhode Island Health Department. The cause of death was not immediately known, but authorities said they did not suspect foul play. The family later confirmed Tripathi's death was a result of suicide. Reddit general manager Erik Martin later issued an apology for this behavior, criticizing the \"online witch hunts and dangerous speculation\" that took place on the website.\n\n\n*** Journalists ***\nJournalists with The Journal News of Westchester County, New York were accused of doxing gun owners in the region in a story the paper published in December 2012.Newsweek was criticized when writer Leah McGrath Goodman claimed to have revealed the identity of the anonymous creator of Bitcoin, Satoshi Nakamoto. Although she primarily drew on the public record, users on Reddit responded negatively.The Satoshi Nakamoto case brought doxing to greater attention on platforms such as Twitter, where users questioned the ethics of doxing in journalism. Many Twitter users argued that the practice was seemingly acceptable for professional journalists but wrong for anyone else. Other users discussed the effect the popularization that the concept of doxing could have on journalism in the public interest, raising questions over journalism concerning public and private figures in which journalists practicing doxing may blur the line between reporting information in the public's interest and releasing information about the private life of an individual without their consent.In September 2019, The Des Moines Register published racist tweets made by a 24-year-old Iowa man whose beer sign on ESPN College GameDay resulted in over $1 million in contributions to a children's hospital. Readers retaliated by sharing social media comments previously made by the reporter, Aaron Calvin, which contained racial slurs and condemnation of law enforcement. The newspaper later announced they no longer employed Calvin.\n\n\n*** Curt Schilling ***\nIn March 2015, former Major League Baseball (MLB) pitcher Curt Schilling used doxing to identify several people responsible for \"Twitter troll\" posts with obscene, sexually explicit comments about his teenage daughter. One person was suspended from his community college, and another lost a part-time job with the New York Yankees.\n\n\n*** Alondra Cano ***\nIn December 2015, Minneapolis city council member Alondra Cano used her Twitter account to publish private cellphone numbers and e-mail addresses of critics who wrote about her involvement in a Black Lives Matter rally.\n\n\n*** HIPAA Federal Register 6039G ***\nThe Health Insurance Portability and Accountability Act of 1996 (HIPAA) is a US federal law that requires the creation of national standards to protect sensitive patient health information from being disclosed without the patient\u2019s consent or knowledge. Embedded in that act, that is designed to protect the privacy of the patient, is ironically a provision that requires the Internal Revenue Service (IRS) to publish the names of Americans who renounce or relinquish their US citizenship. The IRS will publish a Quarterly Publication of Individuals Who Have Chosen to Expatriate, as Required by Section 6039G, 81 Fed. Reg. 50058. The expatriation provisions were included as \"revenue offsets... to avoid increasing the budget deficit.\" The expressed intent originated in The Expatriation Tax Act of 1995 by Bill Archer to publicly shame the expatriating individuals.\n\n\n*** Lou Dobbs ***\nIn 2016, Fox Business news anchor Lou Dobbs revealed the address and phone number of Jessica Leeds, one of the women who accused American presidential candidate Donald Trump of inappropriate sexual advances; Dobbs later apologized.\n\n\n*** Erdo\u011fan emails ***\nIn July 2016, WikiLeaks released 300,000 e-mails called the Erdo\u011fan emails, initially thought to be damaging to Turkish President Recep Tayyip Erdo\u011fan. Included in the leak was Michael Best, who uploaded Turkish citizens' information databases that WikiLeaks promoted, who came forward to say that doing so was a mistake after the site where he uploaded the information took it down. The files were removed due to privacy concerns. They included spreadsheets of private, sensitive information of what appears to be every female voter in 79 out of 81 provinces in Turkey, including their home addresses and other private information, sometimes including their cellphone numbers.\n\n\n*** Michael Hirsh ***\nIn November 2016, Politico editor Michael Hirsh resigned after publishing the home address of white nationalist Richard B. Spencer on Facebook.\n\n\n*** U.S. Presidential Advisory Commission on Election Integrity ***\nIn July 2017, the United States' Presidential Advisory Commission on Election Integrity, which was established in May 2017 by U.S. President Donald Trump to investigate his controversial allegation of voter fraud, published a 112-page document of unredacted emails of public comment on its work, which included both critics and supporters of the Commission. The Commission included the personal details of those critics, such as names, emails, phone numbers and home addresses. Most of the commenters who wrote to the White House expressed concern about publication of their personal information, with one person writing, \"DO NOT RELEASE ANY OF MY VOTER DATA PERIOD.\" Despite this, that person's name and email address were published by the commission.This act drew criticism from Theresa Lee, a staff attorney for the American Civil Liberties Union's Voting Rights Project, who stated, \"This cavalier attitude toward the public's personal information is especially concerning given the commission's request for sensitive data on every registered voter in the country.\" The White House defended the personal information publication, noting that everyone was warned that might happen. However, former Deputy Secretary of Labor Chris Lu stated that regardless of the legality, the White House has a moral obligation to protect sensitive data, saying, \"Whether or not it's legal to disclose this personal information, it's clearly improper, and no responsible White House would do this.\"Federal agencies often solicit and release public comments on proposed legislation. Regulations.gov, which is designated for public comments, includes a detailed set of guidelines explaining how to submit comments, what type of personal information is collected, and how that information may be used, stating, \"Some agencies may require that you include personal information, such as your name and email address, on the comment form. The Securities and Exchange Commission, for instance, warns commenters to 'submit only information that you wish to make available publicly.'\" Another agency, the Federal Trade Commission, tells commenters that \"published comments include the commenter's last name and state/country as well as the entire text of the comment. Please do not include any sensitive or confidential information.\" However, The White House does not appear to have issued any such public guidelines or warnings before many of the emails were sent. Marc Lotter, Press Secretary to Mike Pence, stated, \"These are public comments, similar to individuals appearing before commission to make comments and providing name before making comments. The Commission\u2019s Federal Register notice asking for public comments and its website make clear that information 'including names and contact information' sent to this email address may be released.\"\n\n\n*** Democratic U.S. House of Representatives intern ***\nOn 3 October 2018, Jackson Cosko, a House fellow for the Democratic Party, was arrested by the U.S. Capitol Police (USCP). He allegedly posted private, identifying information of several Senators to Wikipedia. According to the USCP, the personal information of Republican Senators Lindsey Graham, Mike Lee and Orrin Hatch was anonymously posted to Wikipedia the week before on Thursday 27 September 2018. The information included home addresses and phone numbers. All three lawmakers are with the Senate Judiciary Committee. The alleged doxing occurred during the hearing of Supreme Court nominee Judge Brett Kavanaugh. Cosko was initially charged with witness tampering, threats in interstate communications, unauthorized access of a government computer, identity theft, second degree burglary and unlawful entry. Cosko was fired after his arrest. He worked with Democratic Rep. Sheila Jackson Lee (D-TX), Sen. Dianne Feinstein (D-Calif), Sen. Maggie Hassan (D-N.H.), and former Sen. Barbara Boxer (D-Calif). Conviction of all six charges might have resulted in Cosko facing up to 20 years in prison. However, in June 2019, he was sentenced by Judge Thomas F. Hogan to four years in prison. An accomplice, Samantha DeForest Davis, was sentenced to two years of supervised probation and community service.\n\n\n*** Taylor Lorenz (Libs of TikTok) ***\nOn April 19, 2022, The Washington Post published an article written by journalist Taylor Lorenz about the Twitter account, Libs of TikTok. In the article, Lorenz revealed the account owner\u2019s name as Chaya Raichik, who previously operated anonymously. Lorenz defended this action, arguing that Raichik was \u201ca powerful influencer operating a massively impactful right wing media shaping the discourse around LGBTQ+ rights.\u201d In the article, Lorenz referenced Raichik\u2019s previous mention of her Orthodox Jewish faith in her Twitter biography, leading the latter\u2019s supporters to accuse Lorenz of antisemitism.YouTuber Tim Pool and The Daily Wire CEO Jeremy Boreing purchased a billboard in Times Square to accuse Lorenz of doxxing. In response, Lorenz called the billboard \"so idiotic it's hilarious\".\n\n\n*** Lisa-Maria Kellermayr ***\n\nLisa-Maria Kellermayr, an Austrian doctor, received targeted harassment, including death threats, first online, then in person, by anti-vaccination and conspiracy theorist groups during the COVID-19 pandemic until she took her life in July 2022. The harassment she received included attacks against the clinic in Seewalchen am Attersee where she worked, and that she had to close weeks before her death due to security costs.\n\n\n*** Keffals swatting and doxing ***\n\nOn August 5, 2022, Canadian Twitch streamer and transgender activist Clara Sorrenti was swatted after an e-mail impersonating her claiming intent to harm city councillors of London, Ontario.  After this incident, she moved to a hotel. Her new location was posted in Kiwi Farms, a forum frequently related to harassment campaigns that included a thread disclosing personal data from her, her family members and her friends, as well as sexually explicit content, which was started in March 21 of the same year, after what she started to receive prank pizza orders by trolls who used her former name, changed more than a decade before. At the time, police were also investigating a second doxing attempt. Sorrenti's Uber account was hacked days after the hotel location incident, leading to her receiving new prank orders. After that, she reported having been doxed again and announced her intention to leave Canada, given the targeted harassment she was receiving. Days later, her new location in Belfast, Northern Ireland was posted online and a new swatting attempt was made. Sorrenti campaigned for online security firm Cloudflare to terminate services for Kiwifarms, citing life-threatening harassment originating in the site. On September 3, 2022, the firm blocked access to Kiwifarms through its infrastructure, mentioning \"an imminent and emergency threat to human life\".\n\n\n*** Elon Musk ***\nIn December 2022 business magnate and investor Elon Musk, who was also CEO of Twitter, Inc., suspended the Twitter accounts of several journalists, whom he accused of doxing the location of his private jet, related to the social media account ElonJet. Two days later the accounts were restored.\n\n== Anti-doxing services ==\nParallel to the rise of doxing has been the evolution of cybersecurity, internet privacy, the Online Privacy Alliance, and even companies that provide anti-doxing services. Most recently, high profile groups like the University of California Berkeley have made online guidance for protecting its community members from doxing. Wired published an article on dealing with doxing, in which Eva Galperin, from the Electronic Frontier Foundation, advises people to \"Google yourself, lock yourself down, make it harder to access information about you.\"\n\n== Legislation ==\n\n\n*** Mainland China ***\nFrom March 1, 2020, the People\u2019s Republic of China\u2019s \"Regulations on the Ecological Governance of Online Information Content\" has been implemented, clarifying that users and producers of online information content services and platforms must not engage in online violence, doxing, deep forgery, data fraud, account manipulation and other illegal activities.\n\n\n**** Hong Kong ****\nAs of 2021, it is a criminal offense in Hong Kong to dox, where doxing is defined as releasing private or non-public information on a person for the purposes of \"threatening, intimidation, harassment or to cause psychological harm\". Persons convicted under this statute are liable to imprisonment for up to 5 years, and a fine of HK$1,000,000 (US$128,324.40).\n\n\n*** South Korea ***\nSouth Korea stands as one of few countries with a criminal statute that specifically addresses doxing. Article 49 of \"Act on promotion of information and communications network utilization, and information protection\" prohibits unlawful collection and dissemination of private information such as full name, birth date, address, likeliness, and any other information that is deemed sufficient to identify specific person(s) when viewed in summation, regardless of intent. In practice, however, due to the ambiguous nature of \"unlawful collection\" of private information in said statute, legal actions are often based upon article 44 from the same act, which prohibits insulting an individual with language derogatory or profane, and defamation of an individual through the dissemination of either misinformation or privileged factual information that may potentially damage an individual's reputation or honor (which often occurs in a doxing incident). It is important to note that this particular clause enforces harsher maximum sentences than a \"traditional\" defamation statute existing in the Korean criminal code and was originally enacted partially in response to the rise in celebrity suicides due to cyberbullying.\n\n\n*** Spain ***\nThe Spanish Criminal Code regulates penalties for the discovery and revelation of secrets in articles 197 to 201. It establishes, in its article 197 \u00a7 1, that \"whoever, in order to discover the secrets or violate the privacy of another, without their consent, seizes their papers, letters, e-mail messages or any other documents or personal effects, intercepts their telecommunications or uses technical devices for listening, transmission, recording or reproduction of sound or image, or any other communication signal, shall be punished with prison sentences of one to four years and a fine of twelve to twenty-four months\". Per article 197 \u00a7 2, the same penalty punishes those who \"seize, use or modify, to the detriment of a third party, reserved personal or family data of another that is registered in computer, electronic or telematic files or media, or in any other type of file or public or private record\". Those who \"disseminate, disclose or transfer\" the aforementioned data to third parties face a penalty of two to five prison years (one to three years of prison and fines of twelve to twenty-four months, if not directly involved in their discovery but \"with knowledge of its illicit origin\") per article 197 \u00a7 3. These offenses are particularly severe if made by the person responsible of the respective files, media, records or archives or through unauthorized use of personal data, if revealing of the ideology, religion, beliefs, health, racial origin or sexual life of the victim, if the victim is underage or disabled, and if it is made for economic profit.As established by the Criminal Code's reform in 2015, to \"disseminate, disclose or transfer to third parties images or audiovisual recordings of the one obtained with their consent in a home or in any other place out of sight of third parties, when the disclosure seriously undermines the personal privacy of that person\", without the authorization of the affected person, is also punished per article 197 \u00a7 7 to three months to a year in prison and fines of six to twelve moths. The offense is particularly severe if the victim is linked to the offender by marriage or an \"analogous affective relationship\", underage, or disabled.\n\n\n*** The Netherlands ***\nIn 2021, due to increasing doxing incidents targeting Dutch activists, politicians, journalists and others, a new law against doxing was proposed by then Minister of Justice and Security Ferdinand Grapperhaus. The law is aimed at curtailing those who share private information with the intent of intimidation, and carries a maximum penalty of a one-year prison sentence.\n\n\n*** The United States ***\nIn the United States, there are currently few legal remedies for the victims of doxing. Currently two federal laws exist that could potentially address the problem of doxing: the Interstate Communications Statute and the Interstate Stalking Statute.  However, as one scholar has argued, \"[t]hese statutes...are woefully inadequate to prevent doxing because their terms are underinclusive and they are rarely enforced\".  The Interstate Communications Statute, for example, \"only criminalizes explicit threats to kidnap or injure a person\".  But in many instances of doxing, a doxer may never convey an explicit threat to kidnap or injure, but the victim could still have good reason to be terrified.  And the Interstate Stalking Statute \"is rarely enforced and it serves only as a hollow protection from online harassment\". According to at least one estimate, over three million people are stalked over the internet each year, yet only about three are charged under the Interstate Stalking Statute. Accordingly, \"[t]his lack of federal enforcement means that the States must step in if doxing is to be reduced\".\nAnswer this question: What are some examples of doxing in the United States?",
    "context": "",
    "output": "Examples of doxing in the United States include the publication of personal information of abortion providers, journalists, gun owners, and politicians, often with malicious intent such as online shaming, harassment, or intimidation.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are some examples of doxing in the United States?",
      "answer": "Examples of doxing in the United States include the publication of personal information of abortion providers, journalists, gun owners, and politicians, often with malicious intent such as online shaming, harassment, or intimidation.",
      "context": "Doxing\n\n==Introduction==\nDoxing or doxxing (originally spelled d0xing) is the act of publicly providing personally identifiable information about an individual or organization, usually via the Internet. Historically, the term has been used interchangeably to refer to both the aggregation of this information from public databases and social media websites (like Facebook), as well as the publication of previously private information obtained through criminal or otherwise fraudulent means (such as hacking and social engineering). The aggregation and provision of previously published material is generally a legal practice, though it may be subject to laws concerning stalking and intimidation. Doxing may be carried out for reasons such as online shaming, extortion, and vigilante aid to law enforcement. It also may be associated with hacktivism.\n\n\n\n== Etymology ==\n\"Doxing\" is a neologism. It originates from a spelling alteration of the abbreviation \"docs\", for \"documents\", and refers to \"compiling and releasing a dossier of personal information on someone\". Essentially, doxing is revealing and publicizing the records of an individual, which were previously private or difficult to obtain.\nThe term dox derives from the slang \"dropping dox\", which, according to a contributor to Wired, Mat Honan, was \"an old-school revenge tactic that emerged from hacker culture in 1990s\". Hackers operating outside the law in that era used the breach of an opponent's anonymity as a means to expose opponents to harassment or legal repercussions.Consequently, doxing often comes with a negative connotation because it can be a means of revenge via the violation of privacy.\n\n== Common techniques ==\nOnce people have been exposed through doxing, they may be targeted for harassment through methods such as actual harassment in person, fake signups for mail subscriptions, pizza deliveries, bombarding the address with letters, or through \u201cswatting\u201d\u2014the intentional dispatching of armed police teams (S.W.A.T.) to a person\u2019s address via falsely reported tips or through fake emergency services phone calls. The act of reporting a false tip to police\u2014and the subsequent summoning of an emergency response team (ERT)\u2014is an illegal, punishable offense in most jurisdictions, due to ERTs being compromised and potentially unavailable for real emergencies. It is, at the very least, an infraction in most US states (for first-time offenders); if multiple attempts are made, the charge increases to a misdemeanor (especially when the intention is harassment-based). Further repercussions include fines ranging from as low as USD$50 up to USD$2,000, six months spent in county jail, or both the fine and imprisonment.A hacker may obtain an individual's dox without making the information public. A hacker may look for this information to extort or coerce a known or unknown target. A hacker may also harvest a victim's information to break into their Internet accounts or take over their social media accounts.Doxing has also occurred in dating apps. In a survey conducted in 2021, 16% of respondents reported suffering doxing because of them. In a 2018 qualitative studio about intimate partner violence, 28 out of 89 participants (both professionals and survivors) reported the exposure of the victim's private information to third parties through digital technologies as a form of humiliation, shaming or harm frequently practiced by abusers, that may include the disclosure of intimate images and impersonation of the victim.Victims may also be shown their details as proof that they have been doxed as a form of intimidation. The perpetrator may use this fear to gain power over victims in order to extort or coerce. Doxing is therefore a standard tactic of online harassment and has been used by people associated with the Gamergate and vaccine controversies.\n\n== Examples ==\n\n\n*** Doxing of abortion providers ***\n\nIn the United States, in the 1970s and 80s (paper) and the 1990s (digitally), anti-abortion activists secured abortion providers' personal information, such as home addresses, phone numbers, and photographs, and posted them as a hit list. The courts later ruled this to be an immediate incitement to violence. Between 1993 and 2016, eight abortion providers were killed by anti-abortion activists, along with at least four police officers.\n\n\n*** Human flesh search engine ***\n\nStarting in March 2006, the Chinese Internet phenomenon of the \"Human flesh search engine\"\uff08\u4eba\u8089\u641c\u7d22\uff09shares much in common with doxing. Specifically, it refers to distributed, sometimes deliberately crowdsourced searches for similar kinds of information through use of digital media.\n\n\n*** Anonymous ***\n\nThe term \"dox\" entered mainstream public awareness through media attention attracted by Anonymous, the Internet-based group of hacktivists and pranksters who make frequent use of doxing, as well as related groups like AntiSec and LulzSec. The Washington Post has described the consequences for innocent people incorrectly accused of wrongdoing and doxed as \"nightmarish\".In December 2011, Anonymous exposed detailed information of 7,000 law enforcement members in response to investigations into hacking activities.In November 2014, Anonymous began releasing the identities of members of the Ku Klux Klan. This was concerning local Klan members in Ferguson, Missouri, making threats to shoot those protesting the shooting of Michael Brown. Anonymous also hijacked the group's Twitter page, causing Klan members to make veiled threats of violence against members of Anonymous. In November 2015, a major release of information about the KKK was planned. Discredited information was released prematurely, and Anonymous denied involvement. On 5 November 2015 (Guy Fawkes Night), Anonymous released an official list of supposed, but currently unverified, KKK members and sympathizers.\n\n\n*** Boston Marathon ***\nFollowing the 15 April 2013 Boston Marathon bombing, internet vigilantes on Reddit wrongly identified a number of people as suspects. Notable among misidentified bombing suspects was Sunil Tripathi, a student reported missing before the bombings took place. A body reported to be Tripathi's was found in Rhode Island's Providence River on 25 April 2013, as reported by the Rhode Island Health Department. The cause of death was not immediately known, but authorities said they did not suspect foul play. The family later confirmed Tripathi's death was a result of suicide. Reddit general manager Erik Martin later issued an apology for this behavior, criticizing the \"online witch hunts and dangerous speculation\" that took place on the website.\n\n\n*** Journalists ***\nJournalists with The Journal News of Westchester County, New York were accused of doxing gun owners in the region in a story the paper published in December 2012.Newsweek was criticized when writer Leah McGrath Goodman claimed to have revealed the identity of the anonymous creator of Bitcoin, Satoshi Nakamoto. Although she primarily drew on the public record, users on Reddit responded negatively.The Satoshi Nakamoto case brought doxing to greater attention on platforms such as Twitter, where users questioned the ethics of doxing in journalism. Many Twitter users argued that the practice was seemingly acceptable for professional journalists but wrong for anyone else. Other users discussed the effect the popularization that the concept of doxing could have on journalism in the public interest, raising questions over journalism concerning public and private figures in which journalists practicing doxing may blur the line between reporting information in the public's interest and releasing information about the private life of an individual without their consent.In September 2019, The Des Moines Register published racist tweets made by a 24-year-old Iowa man whose beer sign on ESPN College GameDay resulted in over $1 million in contributions to a children's hospital. Readers retaliated by sharing social media comments previously made by the reporter, Aaron Calvin, which contained racial slurs and condemnation of law enforcement. The newspaper later announced they no longer employed Calvin.\n\n\n*** Curt Schilling ***\nIn March 2015, former Major League Baseball (MLB) pitcher Curt Schilling used doxing to identify several people responsible for \"Twitter troll\" posts with obscene, sexually explicit comments about his teenage daughter. One person was suspended from his community college, and another lost a part-time job with the New York Yankees.\n\n\n*** Alondra Cano ***\nIn December 2015, Minneapolis city council member Alondra Cano used her Twitter account to publish private cellphone numbers and e-mail addresses of critics who wrote about her involvement in a Black Lives Matter rally.\n\n\n*** HIPAA Federal Register 6039G ***\nThe Health Insurance Portability and Accountability Act of 1996 (HIPAA) is a US federal law that requires the creation of national standards to protect sensitive patient health information from being disclosed without the patient\u2019s consent or knowledge. Embedded in that act, that is designed to protect the privacy of the patient, is ironically a provision that requires the Internal Revenue Service (IRS) to publish the names of Americans who renounce or relinquish their US citizenship. The IRS will publish a Quarterly Publication of Individuals Who Have Chosen to Expatriate, as Required by Section 6039G, 81 Fed. Reg. 50058. The expatriation provisions were included as \"revenue offsets... to avoid increasing the budget deficit.\" The expressed intent originated in The Expatriation Tax Act of 1995 by Bill Archer to publicly shame the expatriating individuals.\n\n\n*** Lou Dobbs ***\nIn 2016, Fox Business news anchor Lou Dobbs revealed the address and phone number of Jessica Leeds, one of the women who accused American presidential candidate Donald Trump of inappropriate sexual advances; Dobbs later apologized.\n\n\n*** Erdo\u011fan emails ***\nIn July 2016, WikiLeaks released 300,000 e-mails called the Erdo\u011fan emails, initially thought to be damaging to Turkish President Recep Tayyip Erdo\u011fan. Included in the leak was Michael Best, who uploaded Turkish citizens' information databases that WikiLeaks promoted, who came forward to say that doing so was a mistake after the site where he uploaded the information took it down. The files were removed due to privacy concerns. They included spreadsheets of private, sensitive information of what appears to be every female voter in 79 out of 81 provinces in Turkey, including their home addresses and other private information, sometimes including their cellphone numbers.\n\n\n*** Michael Hirsh ***\nIn November 2016, Politico editor Michael Hirsh resigned after publishing the home address of white nationalist Richard B. Spencer on Facebook.\n\n\n*** U.S. Presidential Advisory Commission on Election Integrity ***\nIn July 2017, the United States' Presidential Advisory Commission on Election Integrity, which was established in May 2017 by U.S. President Donald Trump to investigate his controversial allegation of voter fraud, published a 112-page document of unredacted emails of public comment on its work, which included both critics and supporters of the Commission. The Commission included the personal details of those critics, such as names, emails, phone numbers and home addresses. Most of the commenters who wrote to the White House expressed concern about publication of their personal information, with one person writing, \"DO NOT RELEASE ANY OF MY VOTER DATA PERIOD.\" Despite this, that person's name and email address were published by the commission.This act drew criticism from Theresa Lee, a staff attorney for the American Civil Liberties Union's Voting Rights Project, who stated, \"This cavalier attitude toward the public's personal information is especially concerning given the commission's request for sensitive data on every registered voter in the country.\" The White House defended the personal information publication, noting that everyone was warned that might happen. However, former Deputy Secretary of Labor Chris Lu stated that regardless of the legality, the White House has a moral obligation to protect sensitive data, saying, \"Whether or not it's legal to disclose this personal information, it's clearly improper, and no responsible White House would do this.\"Federal agencies often solicit and release public comments on proposed legislation. Regulations.gov, which is designated for public comments, includes a detailed set of guidelines explaining how to submit comments, what type of personal information is collected, and how that information may be used, stating, \"Some agencies may require that you include personal information, such as your name and email address, on the comment form. The Securities and Exchange Commission, for instance, warns commenters to 'submit only information that you wish to make available publicly.'\" Another agency, the Federal Trade Commission, tells commenters that \"published comments include the commenter's last name and state/country as well as the entire text of the comment. Please do not include any sensitive or confidential information.\" However, The White House does not appear to have issued any such public guidelines or warnings before many of the emails were sent. Marc Lotter, Press Secretary to Mike Pence, stated, \"These are public comments, similar to individuals appearing before commission to make comments and providing name before making comments. The Commission\u2019s Federal Register notice asking for public comments and its website make clear that information 'including names and contact information' sent to this email address may be released.\"\n\n\n*** Democratic U.S. House of Representatives intern ***\nOn 3 October 2018, Jackson Cosko, a House fellow for the Democratic Party, was arrested by the U.S. Capitol Police (USCP). He allegedly posted private, identifying information of several Senators to Wikipedia. According to the USCP, the personal information of Republican Senators Lindsey Graham, Mike Lee and Orrin Hatch was anonymously posted to Wikipedia the week before on Thursday 27 September 2018. The information included home addresses and phone numbers. All three lawmakers are with the Senate Judiciary Committee. The alleged doxing occurred during the hearing of Supreme Court nominee Judge Brett Kavanaugh. Cosko was initially charged with witness tampering, threats in interstate communications, unauthorized access of a government computer, identity theft, second degree burglary and unlawful entry. Cosko was fired after his arrest. He worked with Democratic Rep. Sheila Jackson Lee (D-TX), Sen. Dianne Feinstein (D-Calif), Sen. Maggie Hassan (D-N.H.), and former Sen. Barbara Boxer (D-Calif). Conviction of all six charges might have resulted in Cosko facing up to 20 years in prison. However, in June 2019, he was sentenced by Judge Thomas F. Hogan to four years in prison. An accomplice, Samantha DeForest Davis, was sentenced to two years of supervised probation and community service.\n\n\n*** Taylor Lorenz (Libs of TikTok) ***\nOn April 19, 2022, The Washington Post published an article written by journalist Taylor Lorenz about the Twitter account, Libs of TikTok. In the article, Lorenz revealed the account owner\u2019s name as Chaya Raichik, who previously operated anonymously. Lorenz defended this action, arguing that Raichik was \u201ca powerful influencer operating a massively impactful right wing media shaping the discourse around LGBTQ+ rights.\u201d In the article, Lorenz referenced Raichik\u2019s previous mention of her Orthodox Jewish faith in her Twitter biography, leading the latter\u2019s supporters to accuse Lorenz of antisemitism.YouTuber Tim Pool and The Daily Wire CEO Jeremy Boreing purchased a billboard in Times Square to accuse Lorenz of doxxing. In response, Lorenz called the billboard \"so idiotic it's hilarious\".\n\n\n*** Lisa-Maria Kellermayr ***\n\nLisa-Maria Kellermayr, an Austrian doctor, received targeted harassment, including death threats, first online, then in person, by anti-vaccination and conspiracy theorist groups during the COVID-19 pandemic until she took her life in July 2022. The harassment she received included attacks against the clinic in Seewalchen am Attersee where she worked, and that she had to close weeks before her death due to security costs.\n\n\n*** Keffals swatting and doxing ***\n\nOn August 5, 2022, Canadian Twitch streamer and transgender activist Clara Sorrenti was swatted after an e-mail impersonating her claiming intent to harm city councillors of London, Ontario.  After this incident, she moved to a hotel. Her new location was posted in Kiwi Farms, a forum frequently related to harassment campaigns that included a thread disclosing personal data from her, her family members and her friends, as well as sexually explicit content, which was started in March 21 of the same year, after what she started to receive prank pizza orders by trolls who used her former name, changed more than a decade before. At the time, police were also investigating a second doxing attempt. Sorrenti's Uber account was hacked days after the hotel location incident, leading to her receiving new prank orders. After that, she reported having been doxed again and announced her intention to leave Canada, given the targeted harassment she was receiving. Days later, her new location in Belfast, Northern Ireland was posted online and a new swatting attempt was made. Sorrenti campaigned for online security firm Cloudflare to terminate services for Kiwifarms, citing life-threatening harassment originating in the site. On September 3, 2022, the firm blocked access to Kiwifarms through its infrastructure, mentioning \"an imminent and emergency threat to human life\".\n\n\n*** Elon Musk ***\nIn December 2022 business magnate and investor Elon Musk, who was also CEO of Twitter, Inc., suspended the Twitter accounts of several journalists, whom he accused of doxing the location of his private jet, related to the social media account ElonJet. Two days later the accounts were restored.\n\n== Anti-doxing services ==\nParallel to the rise of doxing has been the evolution of cybersecurity, internet privacy, the Online Privacy Alliance, and even companies that provide anti-doxing services. Most recently, high profile groups like the University of California Berkeley have made online guidance for protecting its community members from doxing. Wired published an article on dealing with doxing, in which Eva Galperin, from the Electronic Frontier Foundation, advises people to \"Google yourself, lock yourself down, make it harder to access information about you.\"\n\n== Legislation ==\n\n\n*** Mainland China ***\nFrom March 1, 2020, the People\u2019s Republic of China\u2019s \"Regulations on the Ecological Governance of Online Information Content\" has been implemented, clarifying that users and producers of online information content services and platforms must not engage in online violence, doxing, deep forgery, data fraud, account manipulation and other illegal activities.\n\n\n**** Hong Kong ****\nAs of 2021, it is a criminal offense in Hong Kong to dox, where doxing is defined as releasing private or non-public information on a person for the purposes of \"threatening, intimidation, harassment or to cause psychological harm\". Persons convicted under this statute are liable to imprisonment for up to 5 years, and a fine of HK$1,000,000 (US$128,324.40).\n\n\n*** South Korea ***\nSouth Korea stands as one of few countries with a criminal statute that specifically addresses doxing. Article 49 of \"Act on promotion of information and communications network utilization, and information protection\" prohibits unlawful collection and dissemination of private information such as full name, birth date, address, likeliness, and any other information that is deemed sufficient to identify specific person(s) when viewed in summation, regardless of intent. In practice, however, due to the ambiguous nature of \"unlawful collection\" of private information in said statute, legal actions are often based upon article 44 from the same act, which prohibits insulting an individual with language derogatory or profane, and defamation of an individual through the dissemination of either misinformation or privileged factual information that may potentially damage an individual's reputation or honor (which often occurs in a doxing incident). It is important to note that this particular clause enforces harsher maximum sentences than a \"traditional\" defamation statute existing in the Korean criminal code and was originally enacted partially in response to the rise in celebrity suicides due to cyberbullying.\n\n\n*** Spain ***\nThe Spanish Criminal Code regulates penalties for the discovery and revelation of secrets in articles 197 to 201. It establishes, in its article 197 \u00a7 1, that \"whoever, in order to discover the secrets or violate the privacy of another, without their consent, seizes their papers, letters, e-mail messages or any other documents or personal effects, intercepts their telecommunications or uses technical devices for listening, transmission, recording or reproduction of sound or image, or any other communication signal, shall be punished with prison sentences of one to four years and a fine of twelve to twenty-four months\". Per article 197 \u00a7 2, the same penalty punishes those who \"seize, use or modify, to the detriment of a third party, reserved personal or family data of another that is registered in computer, electronic or telematic files or media, or in any other type of file or public or private record\". Those who \"disseminate, disclose or transfer\" the aforementioned data to third parties face a penalty of two to five prison years (one to three years of prison and fines of twelve to twenty-four months, if not directly involved in their discovery but \"with knowledge of its illicit origin\") per article 197 \u00a7 3. These offenses are particularly severe if made by the person responsible of the respective files, media, records or archives or through unauthorized use of personal data, if revealing of the ideology, religion, beliefs, health, racial origin or sexual life of the victim, if the victim is underage or disabled, and if it is made for economic profit.As established by the Criminal Code's reform in 2015, to \"disseminate, disclose or transfer to third parties images or audiovisual recordings of the one obtained with their consent in a home or in any other place out of sight of third parties, when the disclosure seriously undermines the personal privacy of that person\", without the authorization of the affected person, is also punished per article 197 \u00a7 7 to three months to a year in prison and fines of six to twelve moths. The offense is particularly severe if the victim is linked to the offender by marriage or an \"analogous affective relationship\", underage, or disabled.\n\n\n*** The Netherlands ***\nIn 2021, due to increasing doxing incidents targeting Dutch activists, politicians, journalists and others, a new law against doxing was proposed by then Minister of Justice and Security Ferdinand Grapperhaus. The law is aimed at curtailing those who share private information with the intent of intimidation, and carries a maximum penalty of a one-year prison sentence.\n\n\n*** The United States ***\nIn the United States, there are currently few legal remedies for the victims of doxing. Currently two federal laws exist that could potentially address the problem of doxing: the Interstate Communications Statute and the Interstate Stalking Statute.  However, as one scholar has argued, \"[t]hese statutes...are woefully inadequate to prevent doxing because their terms are underinclusive and they are rarely enforced\".  The Interstate Communications Statute, for example, \"only criminalizes explicit threats to kidnap or injure a person\".  But in many instances of doxing, a doxer may never convey an explicit threat to kidnap or injure, but the victim could still have good reason to be terrified.  And the Interstate Stalking Statute \"is rarely enforced and it serves only as a hollow protection from online harassment\". According to at least one estimate, over three million people are stalked over the internet each year, yet only about three are charged under the Interstate Stalking Statute. Accordingly, \"[t]his lack of federal enforcement means that the States must step in if doxing is to be reduced\"."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the difference between the GSSAPI and Kerberos?",
    "context": "",
    "output": "The GSSAPI is a standardized application programming interface for security services, while Kerberos is an underlying GSSAPI implementation that provides actual names, tokens, and credentials. The dominant GSSAPI mechanism implementation in use is Kerberos, but unlike Kerberos, the Kerberos API has not been standardized. The GSSAPI allows Kerberos implementations to be API compatible.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the difference between the GSSAPI and Kerberos?",
      "answer": "The GSSAPI is a standardized application programming interface for security services, while Kerberos is an underlying GSSAPI implementation that provides actual names, tokens, and credentials. The dominant GSSAPI mechanism implementation in use is Kerberos, but unlike Kerberos, the Kerberos API has not been standardized. The GSSAPI allows Kerberos implementations to be API compatible."
    }
  },
  {
    "instruction": "Context: Spam in blogs\n\n==Introduction==\nSpam in blogs (also known as blog spam, comment spam, or social spam) is a form of spamdexing. (Note that blog spam also has another meaning, specifically when a blog author creates posts without adding any informational or educational value solely for publishing them on other websites). It may be done by posting random comments on other blog websites (usually by an automated process), or by copying other websites' content and using it on free-to-use publishing services like Blogger and WordPress or publicly accessible wikis, digital guest books, and internet forums.\nIn such posts and comments, spammers use these methods to artificially inflate their website ranking by linking back (also referred to as backlink) to their web pages. Backlink helps search algorithms determine the popularity of a web page, which plays a major role for search engines like Google and Microsoft Bing to decide a web page ranking on a certain search query. Normally, a web page with more backlinks is considered the most valuable. This helps the spammer's website to list ahead of other sites for certain searches, which helps them to increase the number of visitors to their website.\n\n== Application-specific implementations ==\nParticularly popular software products such as Movable Type and MediaWiki have developed or included anti-spam measures, as spammers focus more on targeting those platforms due to their prevalence on the Internet. Whitelists and blacklists that prevent certain IPs from posting, or that prevent people from posting content that matches certain filters, are common defences although most softwares tend to use a combination of the variety of different techniques documented below.\nThe goal in every potential solution is to allow legitimate users to continue posting their comments (and often even add links to their comments, as that is considered by some to be a valuable aspect of any comments section, when the links are relevant or related to the article or content) whilst preventing all spam links or irrelevant comments from being viewable to the site's owner and visitors.\nAnswer this question: How do spammers benefit from having their website rank higher in search results?",
    "context": "",
    "output": "By having their website rank higher in search results, spammers can increase the number of visitors to their website, which can lead to increased traffic, sales, or other desired outcomes.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do spammers benefit from having their website rank higher in search results?",
      "answer": "By having their website rank higher in search results, spammers can increase the number of visitors to their website, which can lead to increased traffic, sales, or other desired outcomes.",
      "context": "Spam in blogs\n\n==Introduction==\nSpam in blogs (also known as blog spam, comment spam, or social spam) is a form of spamdexing. (Note that blog spam also has another meaning, specifically when a blog author creates posts without adding any informational or educational value solely for publishing them on other websites). It may be done by posting random comments on other blog websites (usually by an automated process), or by copying other websites' content and using it on free-to-use publishing services like Blogger and WordPress or publicly accessible wikis, digital guest books, and internet forums.\nIn such posts and comments, spammers use these methods to artificially inflate their website ranking by linking back (also referred to as backlink) to their web pages. Backlink helps search algorithms determine the popularity of a web page, which plays a major role for search engines like Google and Microsoft Bing to decide a web page ranking on a certain search query. Normally, a web page with more backlinks is considered the most valuable. This helps the spammer's website to list ahead of other sites for certain searches, which helps them to increase the number of visitors to their website.\n\n== Application-specific implementations ==\nParticularly popular software products such as Movable Type and MediaWiki have developed or included anti-spam measures, as spammers focus more on targeting those platforms due to their prevalence on the Internet. Whitelists and blacklists that prevent certain IPs from posting, or that prevent people from posting content that matches certain filters, are common defences although most softwares tend to use a combination of the variety of different techniques documented below.\nThe goal in every potential solution is to allow legitimate users to continue posting their comments (and often even add links to their comments, as that is considered by some to be a valuable aspect of any comments section, when the links are relevant or related to the article or content) whilst preventing all spam links or irrelevant comments from being viewable to the site's owner and visitors."
    }
  },
  {
    "instruction": "VPNBook\n\n==Introduction==\nVPNBook is a VPN service offering servers in multiple countries.\n\n== Description ==\nThe service connects to a VPN via OpenVPN client or a PPTP connection. There are minimal variety of geographic locations. Available servers include the United States, Canada and Romania. VPNBook can be used to bypass some governmental restrictions. The service can be connected to by two ways, by connection via a third-party OpenVPN client or through PPTP. The Mac OS X, iOS, Android, Ubuntu, and Windows operating systems all have PPTP support built in.\nThe software (OpenVPN clients) can be used also, that provides the protocol stack, file system, and process scheduling. OpenVPN uses SSL protocol which is generally more secure than Layer 2 Tunnel Protocol's PPTP.\n\nAnswer this question based on the above context: What is the difference between OpenVPN and PPTP in terms of security?",
    "context": "",
    "output": "OpenVPN uses SSL protocol, which is generally more secure than PPTP.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the difference between OpenVPN and PPTP in terms of security?",
      "answer": "OpenVPN uses SSL protocol, which is generally more secure than PPTP.",
      "context": "VPNBook\n\n==Introduction==\nVPNBook is a VPN service offering servers in multiple countries.\n\n== Description ==\nThe service connects to a VPN via OpenVPN client or a PPTP connection. There are minimal variety of geographic locations. Available servers include the United States, Canada and Romania. VPNBook can be used to bypass some governmental restrictions. The service can be connected to by two ways, by connection via a third-party OpenVPN client or through PPTP. The Mac OS X, iOS, Android, Ubuntu, and Windows operating systems all have PPTP support built in.\nThe software (OpenVPN clients) can be used also, that provides the protocol stack, file system, and process scheduling. OpenVPN uses SSL protocol which is generally more secure than Layer 2 Tunnel Protocol's PPTP."
    }
  },
  {
    "instruction": "Slenfbot\n\n==Introduction==\nSlenfbot is the classification for a family of malicious software (malware), which infects files on Microsoft Windows systems. Slenfbot was first discovered in 2007 and, since then, numerous variants have followed; each with slightly different characteristics and new additions to the worm's payload, such as the ability to provide the attacker with unauthorized access to the compromised host. Slenfbot primarily spreads by luring users to follow links to websites, which contain a malicious payload. Slenfbot propagates via instant messaging applications, removable drives and/or the local network via network shares. The code for Slenfbot appears to be closely managed, which may provide attribution to a single group and/or indicate that a large portion of the code is shared amongst multiple groups.  The inclusion of other malware families and variants as well as its own continuous evolution, makes Slenfbot a highly effective downloader with a propensity to cause even more damage to compromised systems.\n\n== Aliases ==\nThe majority of Antivirus (A/V) vendors use the following naming conventions when referring to this family of malware (the * at the end of the names is a wildcard for all the possible classifications and/or distinctions for this malware family):\n\nSlenfbot\nStekct\n\n== Publicly Known Efforts ==\nNone publicly known.\n\n== Malware Profile ==\n\n\n*** Summary ***\nSlenfbot is a worm that spreads using links to websites containing malicious software (malware) via instant messaging programs, which may include MSN/Windows Live Messenger, AOL Instant Messenger (AIM), Yahoo Messenger, Google Chat, Facebook Chat, ICQ and Skype. The worm propagates automatically via removable drives and shares, or on the local network through the Windows file sharing service (i.e., Server or LanmanServer service). Slenfbot also contains backdoor capabilities that allow unauthorized access to an affected machine. The code appears to be closely controlled, which may provide attribution to one group and/or that the malware authors share a significant portion of the code. Slenfbot has been seen in the wild since 2007, obtained new features and capabilities over time, and subsequent variants have systematically gained similar, if not the same, feature sets.  Because of this, Slenfbot continues to operate as an effective infector and dynamic downloader of additional malware; thus, making it a highly functional delivery mechanism for other spyware, information stealers, spam bots as well as other malware.\n\n\n*** Installation ***\nWhen executed, Slenfbot copies a duplicate of the malicious payload to the %SYSTEM% folder with a filename, which varies per the particular variant and sets the attributes for the copy to read only, hidden and system to hide the contents in Windows Explorer. The worm then makes changes to the registry to maintain persistence so that the malware executes a duplicate copy on each subsequent startup of the system (e.g. copying the malicious executable to the HKLM\\Software\\Microsoft\\Windows\\CurrentVersion\\Run subkey).  Several variants may modify the registry during installation to add the malware to the list of applications that are authorized to access the Internet; thus, allowing the malware to communicate without raising Windows security alerts and run unimpeded by the Windows Firewall.In some cases, variants may instead modify the registry to install the malicious payload as a debugger for the benign system file ctfmon.exe so that ctfmon.exe executes on system startup, which leads to the execution of the malware.In most cases, Slenfbot will attempt to delete the original copy of the worm. Some variants may make additional modifications to the registry in order to delete the originally executed copy of the worm when the system restarts.Some Slenfbot variants may, on initial execution, test to see if MSN/Windows Live Messenger is currently running by looking for a window with the class name \"MSBLWindowClass\". If the worm finds the window, the malware may display a fake error message.If Slenfbot is launched from a removable drive, some variants may open Windows Explorer and display the contents of the affected drive. Certain Slenfbot variants may inject a thread into explorer.exe, which periodically checks for the presence of the malware in the System folder. If the file is not found, the malware downloads a new copy from a specified server and launches the new copy.\n\n\n*** Method of Propagation ***\n\n\n**** Instant Messaging ****\nSlenfbot uses instant messaging as an attack vector to spread the worm to other accounts and contacts. The   remote attacker may use the worm\u2019s backdoor capabilities to instruct Slenfbot to spread via MSN/Windows Live Messenger, AOL Instant Messenger (AIM), Yahoo Messenger, Google Chat, Facebook Chat, ICQ and Skype. The worm connects to a remote server and sends a copy of a URL, which contains a list of possible messages to send randomly; creates a ZIP archive, which contains a copy of the malware; and then sends the ZIP archive to other instant messaging client contacts. Following are some examples of the messages the worm may spread:\n\nAre you serious...is this really you?\nHAHA! this is funny! here, read this guys shirt.\nIs this really a pic of you?\nOMFG look at this!!!\nThis is my dream car right here! The ZIP file includes a file name for the Slenfbot executable, and may also contain a URL for a file to download in situations where the attacker instructs the worm to send arbitrary file(s).\n\n\n**** Removable Drives ****\nSlenfbot may spread to removable drives by creating a directory called \u201cRECYCLER\u201d in the root directory of the removable drive. The malware will then create a subdirectory in the \u201cRECYCLER\u201d folder (e.g. \u201cS-1-6-21-1257894210-1075856346-012573477-2315\u201d), and copy the malicious payload to the directory using a different name for the executable (e.g. \u201cfolderopen.exe\u201d). Slenfbot may also create an autorun.inf file in the root directory of the drive so that the worm may execute if the drive is connected to another system.Certain variants may download an updated copy of Slenfbot from a location specified in the worm, and write the file to a directory (e.g. using the name \u201c~secure\u201d). For all the locations the worm copies itself to, Slenfbot sets the hidden and system attributes on the respective directories and files. In some circumstances due to a programming issue, Slenfbot may only create one directory rather than two (e.g. \u201cE:\\RECYCLERS-1-6-21-1257894210-1075856346-012573477-2315\\folderopen.exe\u201d).\n\n\n**** File and Print Shares ****\nSlenfbot may spread to accessible shares upon successful compromise of a system.  The worm may also spread to file and print shares by exploiting known vulnerabilities such as MS06-040 or MS10-061, which pertain to issues with the Server and Print Spooler services, respectively. The attacker would have to instruct the worm to spread to the remote system via exploit or instant messaging in order to continue the propagation of Slenfbot.\n\n\n*** Payload ***\nSlenfbot attempts to connect to an Internet Relay Chat (IRC) server via a particular TCP port (the IRC channel and port number may vary per the variant), joins a channel and then waits for commands; the attacker may then use the backdoor to perform additional actions on the compromised system such as delete the malware, join another IRC channel, download/execute arbitrary files and/or propagate to other instant messaging accounts \nSlenfbot makes modifications to the hosts file by replacing %SYSTEM%\\drivers\\etc.\\hosts with a file of its own; the modified host file may contain several entries to point various anti-virus and security related domains to localhost (i.e. 127.0.0.1) or to a random IP address, which obstruct the user from visiting the list of domains; the file may also contain numerous blank lines to give the appearance that the hosts file has not been modified \nSlenfbot runs commands to delete files named *.zip and *.com in the current directory as well as the user's \"Received Files\" directory, which is the default location where Windows Messenger stores downloaded files; the latter may be to delete the original copy of the worm, which was received via Windows Messenger \nSome Slenfbot variants may create a file (e.g. \"RemoveMexxxx.bat\") in the %TEMP% directory, which is a batch file that tries to delete the copy after execution to prevent detection \nSlenfbot deletes various registry keys and any subkeys and values that they may contain in order to disable system restore, task manager, the use of the Windows Registry Editor and/or prevent the viewing of files with hidden attributes; the worm may also disable antivirus, firewall as well as attempt to disable Data Execution Prevention (DEP) by making other modifications to the system; some variants may periodically rewrite the changes in order to maintain persistence on the system \nSlenfbot may terminate security-related processes as well as stop, disable and delete services on the compromised system in order to remain undetected and maintain persistence \nSlenfbot may inject code into the Explorer process to \"lock\" the file in order to prevent the worm from being deleted and/or to reopen the payload upon process termination \nSlenfbot may also be capable of hiding the malicious process from task manager \nSlenfbot variants may create a mutex that differs according to variant \nSlenfbot may execute additional commands after receiving data from another remote system; commands may include additional instructions to further modify the compromised system \nSlenfbot may download and install additional malware to relay spam, steal information, install spyware toolbars as well as propagate other malicious campaigns; the initial Slenfbot payload serves as a first-stage downloader for the purpose of loading additional malware on the compromised host\n\n== Prevention ==\nThe following steps may help prevent infection:\n\nGet the latest computer updates for all your installed software\nUse up-to-date antivirus software\nLimit user privileges on the computer\nHave the sender confirm that they sent the link before clicking on it\nUse caution when clicking on links to webpages\nUse caution when opening attachments and accepting file transfers\nUse online services to analyze files and URLs (e.g. Malwr, VirusTotal, Anubis, Wepawet, etc.)\nOnly run software from publishers you trust\nProtect yourself against social engineering attacks\nUse strong passwords and change passwords periodically\n\n== Recovery ==\nSlenfbot uses stealth measures to maintain persistence on a system; thus, you may need to boot to a trusted environment in order to remove it. Slenfbot may also make changes to your computer such as changes to the Windows Registry, which makes it difficult to download, install and/or update your virus protection.  Also, since many variants of Slenfbot attempt to propagate to available removable/remote drives and network shares, it is important to ensure the recovery process thoroughly detects and removes the malware from any and all known/possible locations.\nOne possible solution would be to use Microsoft\u2019s Windows Defender Offline Beta to detect and remove Slenfbot from your system.  For more information on Windows Defender Offline, go to: \nhttp://windows.microsoft.com/en-US/windows/what-is-windows-defender-offline\nQuestion: How does Slenfbot download and install additional malware to relay spam, steal information, and propagate other malicious campaigns?",
    "context": "",
    "output": "Answer: Slenfbot downloads and installs additional malware by serving as a first-stage downloader for the purpose of loading additional malware on the compromised host.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does Slenfbot download and install additional malware to relay spam, steal information, and propagate other malicious campaigns?",
      "answer": "Slenfbot downloads and installs additional malware by serving as a first-stage downloader for the purpose of loading additional malware on the compromised host.",
      "context": "Slenfbot\n\n==Introduction==\nSlenfbot is the classification for a family of malicious software (malware), which infects files on Microsoft Windows systems. Slenfbot was first discovered in 2007 and, since then, numerous variants have followed; each with slightly different characteristics and new additions to the worm's payload, such as the ability to provide the attacker with unauthorized access to the compromised host. Slenfbot primarily spreads by luring users to follow links to websites, which contain a malicious payload. Slenfbot propagates via instant messaging applications, removable drives and/or the local network via network shares. The code for Slenfbot appears to be closely managed, which may provide attribution to a single group and/or indicate that a large portion of the code is shared amongst multiple groups.  The inclusion of other malware families and variants as well as its own continuous evolution, makes Slenfbot a highly effective downloader with a propensity to cause even more damage to compromised systems.\n\n== Aliases ==\nThe majority of Antivirus (A/V) vendors use the following naming conventions when referring to this family of malware (the * at the end of the names is a wildcard for all the possible classifications and/or distinctions for this malware family):\n\nSlenfbot\nStekct\n\n== Publicly Known Efforts ==\nNone publicly known.\n\n== Malware Profile ==\n\n\n*** Summary ***\nSlenfbot is a worm that spreads using links to websites containing malicious software (malware) via instant messaging programs, which may include MSN/Windows Live Messenger, AOL Instant Messenger (AIM), Yahoo Messenger, Google Chat, Facebook Chat, ICQ and Skype. The worm propagates automatically via removable drives and shares, or on the local network through the Windows file sharing service (i.e., Server or LanmanServer service). Slenfbot also contains backdoor capabilities that allow unauthorized access to an affected machine. The code appears to be closely controlled, which may provide attribution to one group and/or that the malware authors share a significant portion of the code. Slenfbot has been seen in the wild since 2007, obtained new features and capabilities over time, and subsequent variants have systematically gained similar, if not the same, feature sets.  Because of this, Slenfbot continues to operate as an effective infector and dynamic downloader of additional malware; thus, making it a highly functional delivery mechanism for other spyware, information stealers, spam bots as well as other malware.\n\n\n*** Installation ***\nWhen executed, Slenfbot copies a duplicate of the malicious payload to the %SYSTEM% folder with a filename, which varies per the particular variant and sets the attributes for the copy to read only, hidden and system to hide the contents in Windows Explorer. The worm then makes changes to the registry to maintain persistence so that the malware executes a duplicate copy on each subsequent startup of the system (e.g. copying the malicious executable to the HKLM\\Software\\Microsoft\\Windows\\CurrentVersion\\Run subkey).  Several variants may modify the registry during installation to add the malware to the list of applications that are authorized to access the Internet; thus, allowing the malware to communicate without raising Windows security alerts and run unimpeded by the Windows Firewall.In some cases, variants may instead modify the registry to install the malicious payload as a debugger for the benign system file ctfmon.exe so that ctfmon.exe executes on system startup, which leads to the execution of the malware.In most cases, Slenfbot will attempt to delete the original copy of the worm. Some variants may make additional modifications to the registry in order to delete the originally executed copy of the worm when the system restarts.Some Slenfbot variants may, on initial execution, test to see if MSN/Windows Live Messenger is currently running by looking for a window with the class name \"MSBLWindowClass\". If the worm finds the window, the malware may display a fake error message.If Slenfbot is launched from a removable drive, some variants may open Windows Explorer and display the contents of the affected drive. Certain Slenfbot variants may inject a thread into explorer.exe, which periodically checks for the presence of the malware in the System folder. If the file is not found, the malware downloads a new copy from a specified server and launches the new copy.\n\n\n*** Method of Propagation ***\n\n\n**** Instant Messaging ****\nSlenfbot uses instant messaging as an attack vector to spread the worm to other accounts and contacts. The   remote attacker may use the worm\u2019s backdoor capabilities to instruct Slenfbot to spread via MSN/Windows Live Messenger, AOL Instant Messenger (AIM), Yahoo Messenger, Google Chat, Facebook Chat, ICQ and Skype. The worm connects to a remote server and sends a copy of a URL, which contains a list of possible messages to send randomly; creates a ZIP archive, which contains a copy of the malware; and then sends the ZIP archive to other instant messaging client contacts. Following are some examples of the messages the worm may spread:\n\nAre you serious...is this really you?\nHAHA! this is funny! here, read this guys shirt.\nIs this really a pic of you?\nOMFG look at this!!!\nThis is my dream car right here! The ZIP file includes a file name for the Slenfbot executable, and may also contain a URL for a file to download in situations where the attacker instructs the worm to send arbitrary file(s).\n\n\n**** Removable Drives ****\nSlenfbot may spread to removable drives by creating a directory called \u201cRECYCLER\u201d in the root directory of the removable drive. The malware will then create a subdirectory in the \u201cRECYCLER\u201d folder (e.g. \u201cS-1-6-21-1257894210-1075856346-012573477-2315\u201d), and copy the malicious payload to the directory using a different name for the executable (e.g. \u201cfolderopen.exe\u201d). Slenfbot may also create an autorun.inf file in the root directory of the drive so that the worm may execute if the drive is connected to another system.Certain variants may download an updated copy of Slenfbot from a location specified in the worm, and write the file to a directory (e.g. using the name \u201c~secure\u201d). For all the locations the worm copies itself to, Slenfbot sets the hidden and system attributes on the respective directories and files. In some circumstances due to a programming issue, Slenfbot may only create one directory rather than two (e.g. \u201cE:\\RECYCLERS-1-6-21-1257894210-1075856346-012573477-2315\\folderopen.exe\u201d).\n\n\n**** File and Print Shares ****\nSlenfbot may spread to accessible shares upon successful compromise of a system.  The worm may also spread to file and print shares by exploiting known vulnerabilities such as MS06-040 or MS10-061, which pertain to issues with the Server and Print Spooler services, respectively. The attacker would have to instruct the worm to spread to the remote system via exploit or instant messaging in order to continue the propagation of Slenfbot.\n\n\n*** Payload ***\nSlenfbot attempts to connect to an Internet Relay Chat (IRC) server via a particular TCP port (the IRC channel and port number may vary per the variant), joins a channel and then waits for commands; the attacker may then use the backdoor to perform additional actions on the compromised system such as delete the malware, join another IRC channel, download/execute arbitrary files and/or propagate to other instant messaging accounts \nSlenfbot makes modifications to the hosts file by replacing %SYSTEM%\\drivers\\etc.\\hosts with a file of its own; the modified host file may contain several entries to point various anti-virus and security related domains to localhost (i.e. 127.0.0.1) or to a random IP address, which obstruct the user from visiting the list of domains; the file may also contain numerous blank lines to give the appearance that the hosts file has not been modified \nSlenfbot runs commands to delete files named *.zip and *.com in the current directory as well as the user's \"Received Files\" directory, which is the default location where Windows Messenger stores downloaded files; the latter may be to delete the original copy of the worm, which was received via Windows Messenger \nSome Slenfbot variants may create a file (e.g. \"RemoveMexxxx.bat\") in the %TEMP% directory, which is a batch file that tries to delete the copy after execution to prevent detection \nSlenfbot deletes various registry keys and any subkeys and values that they may contain in order to disable system restore, task manager, the use of the Windows Registry Editor and/or prevent the viewing of files with hidden attributes; the worm may also disable antivirus, firewall as well as attempt to disable Data Execution Prevention (DEP) by making other modifications to the system; some variants may periodically rewrite the changes in order to maintain persistence on the system \nSlenfbot may terminate security-related processes as well as stop, disable and delete services on the compromised system in order to remain undetected and maintain persistence \nSlenfbot may inject code into the Explorer process to \"lock\" the file in order to prevent the worm from being deleted and/or to reopen the payload upon process termination \nSlenfbot may also be capable of hiding the malicious process from task manager \nSlenfbot variants may create a mutex that differs according to variant \nSlenfbot may execute additional commands after receiving data from another remote system; commands may include additional instructions to further modify the compromised system \nSlenfbot may download and install additional malware to relay spam, steal information, install spyware toolbars as well as propagate other malicious campaigns; the initial Slenfbot payload serves as a first-stage downloader for the purpose of loading additional malware on the compromised host\n\n== Prevention ==\nThe following steps may help prevent infection:\n\nGet the latest computer updates for all your installed software\nUse up-to-date antivirus software\nLimit user privileges on the computer\nHave the sender confirm that they sent the link before clicking on it\nUse caution when clicking on links to webpages\nUse caution when opening attachments and accepting file transfers\nUse online services to analyze files and URLs (e.g. Malwr, VirusTotal, Anubis, Wepawet, etc.)\nOnly run software from publishers you trust\nProtect yourself against social engineering attacks\nUse strong passwords and change passwords periodically\n\n== Recovery ==\nSlenfbot uses stealth measures to maintain persistence on a system; thus, you may need to boot to a trusted environment in order to remove it. Slenfbot may also make changes to your computer such as changes to the Windows Registry, which makes it difficult to download, install and/or update your virus protection.  Also, since many variants of Slenfbot attempt to propagate to available removable/remote drives and network shares, it is important to ensure the recovery process thoroughly detects and removes the malware from any and all known/possible locations.\nOne possible solution would be to use Microsoft\u2019s Windows Defender Offline Beta to detect and remove Slenfbot from your system.  For more information on Windows Defender Offline, go to: \nhttp://windows.microsoft.com/en-US/windows/what-is-windows-defender-offline"
    }
  },
  {
    "instruction": "Write an answer to the following question: Why is it necessary to have expertise in internal controls and processes in the relevant area of the investigated company in forensic data analysis?",
    "context": "",
    "output": "Expertise in internal controls and processes in the relevant area of the investigated company is necessary in forensic data analysis to help formulate hypotheses and analyze data for supporting evidence in a meaningful and informed manner.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Why is it necessary to have expertise in internal controls and processes in the relevant area of the investigated company in forensic data analysis?",
      "answer": "Expertise in internal controls and processes in the relevant area of the investigated company is necessary in forensic data analysis to help formulate hypotheses and analyze data for supporting evidence in a meaningful and informed manner."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the role of the A12 interface in CDMA networks?",
    "context": "",
    "output": "The A12 interface is the interface between AN and AN-AAA used for enabling authentication and authorization functions to be performed at the AN.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of the A12 interface in CDMA networks?",
      "answer": "The A12 interface is the interface between AN and AN-AAA used for enabling authentication and authorization functions to be performed at the AN."
    }
  },
  {
    "instruction": "Key ceremony\n\n==Introduction==\nIn cryptography, a key ceremony is a ceremony held to generate or use a cryptographic key.A public example is the signing of the DNS root zone for DNSSEC.\n\n\n\n== Root Key Signing Ceremony ==\nIn public-key cryptography and computer security, a root key ceremony is a procedure where a unique pair of public and private root keys is generated.  Depending on the certificate policy, the generation of the root keys may require notarization, legal representation, witnesses, and \"key holders\" to be present, as the information on the system is the responsibility of the parties.  A commonly recognized practice is to follow the SAS 70 standard for root key ceremonies.\nAt the heart of every certificate authority (CA) is at least one root key or root certificate and usually at least one intermediate root certificate. A root key is a term for a unique passcode that must be generated for secure server interaction with a protective network, usually called the root zone. Prompts for information from this zone can be done through a server. The keys and certificates mentioned are the credentials and safeguards for the system. These digital certificates are made from a public and a private key.\n\n\n*** Examples ***\nExample A: These passcodes are used for Strong identification and non-repudiation for email and web access\nUnless the information being accessed or transmitted is valued in terms of millions of dollars, it is generally adequate that the root key ceremony be conducted within the security of the vendor's laboratory. The customer may opt to have the root key stored in a hardware security module, but in most cases, the safe storage of the root Key on a CD or hard disk is admissible. The root key is never stored on the CA server.\nExample B: Machine Readable Travel Document [MRTD] ID Card or e-Passport\nThis type of environment requires a much higher level of security.  When conducting the root key ceremony, the government or organization will require rigorous security checks on all personnel in attendance. Those normally required to attend the key ceremony include a minimum of two administrators from the organization, two signatories from the organization, one lawyer, a notary, and two video camera operators, in addition to the CA software vendor's technical team.\nExample A and B are at opposite ends of the security spectrum and no two environments are the same. Depending on the level of protection required, different levels of security will be used.\n\n\n*** Overview ***\nThe actual root key-pair generation is normally conducted in a secure vault that has no communication or contact with the outside world other than a single telephone line or intercom. Once the vault is secured, all personnel present must prove their identity using at least two legally recognized forms of identification. Every person present, every transaction, and every event is logged by the lawyer in a root key ceremony log book, and each page is notarized by the notary. From the moment the vault door is closed until it is re-opened, everything is also video recorded. The lawyer and the organization's two signatories must sign the recording and it too is then notarized.\nFinally, as part of the above process, the root key is broken into as many as twenty-one parts.  Each part is secured in a safe with a key and a numerical lock. The keys are distributed to as many as twenty-one people and the numerical code is distributed to another twenty-one people.\n\n\n*** Providers ***\nThe CA vendors and organisations, such as RSA, VeriSign and Digi-Sign, implement projects of this nature where conducting a root key ceremony would be a central component of their service.\n\n== IBM HSM key ceremony ==\nHardware security module (HSM) key ceremony is a procedure where the master key is generated and loaded to initialize the use of the HSM. The master key is at the top of the key hierarchy and is the root of trust to encrypt all other keys generated by the HSM. A master key is composed of at least two master key parts. Each key part is normally owned by a different person to enhance security.\n\n\n*** Master key types ***\nThe master key is stored within the HSM. IBM HSMs support two types of cryptographic mechanisms:\n\nThe PKCS#11 mechanism, called IBM Enterprise PKCS #11 (EP11), creates a high-security solution for application programs developed for this industry-standard API.\nThe IBM Common Cryptographic Architecture (CCA)  mechanism provides many functions of special interest in the finance industry, extensive support for distributed key management, and a base on which custom processing and cryptographic functions can be added.Depending on the cryptographic mechanisms that the HSM supports and the key objects that are encrypted by the master key, the following types of master keys are available:\n\nEP11 HSMs EP11 symmetric master key: used to encipher all kinds of sensitive materials including secret key objects and intermediate state information containing secret key materials.\nCCA HSMs SYM master key: used to encipher DES symmetric key objects\nASYM master key: used to encipher PKA-RSA asymmetric key objects\nAES master key: used to encipher AES, HMAC symmetric key objects\nAPKA master key: used to encipher PKA-ECC asymmetric key objects\n\n\n*** HSM key ceremony types ***\n\n\n**** On-premise HSM Key Ceremony ****\nFor IBM Z and LinuxONE Systems, the HSMs are used to perform cryptographic operations. The HSM has 85 domains with each having its own set of master keys. Before using the system, the HSM Key Ceremony must be conducted to load the master key securely and properly. For EP11 HSMs, the master key parts are stored on smart cards and loaded to the HSM with the Trusted Key Entry (TKE) workstation. For CCA HSMs, the master key parts can be stored either on smart cards or in files on the TKE workstation.\n\n\n**** Cloud HSM Key Ceremony ****\nEP11 HSM is currently the only type of HSM that supports Key Ceremony in the cloud. Both cloud command-line interface (CLI) or smart cards are provided to load the master key parts to the cloud HSM. IBM Cloud Hyper Protect Crypto Services is presently the only key management service and cloud HSM in the cloud to provide HSM key ceremony through both CLI and smart cards. \n\n\n*** Master key part storage ***\nDepending on the key ceremony types, the master key parts can be stored either on smart cards or in files on the workstation.\nSmart cards are protected by a personal identification number (PIN) that must be entered on a smart card reader pad. Each master key part owner has one smart card and only the owner knows its PIN. This solution ensures that the master key parts never appear in the clear outside the smart cards.\nCompared with the smart card solution, the workstation solution does not require the procurement of smart card readers and smart cards. This solution uses workstation files encrypted with keys derived from a file password to store master key parts. When the keys are used, file content is decrypted and appear temporarily in the clear in workstation memory.\n\n== In blockchain technology ==\nA key ceremony can be used to generate the private key for a cryptocurrency wallet.For Multiparty Computation(MPC), key ceremonies are used to split parts of keys to participants in a secure way. It is also use in Zero-Knowledge Proofs (zKP) protocols for key generation.\n\nAnswer this question based on the above context: What is an HSM key ceremony and what is its purpose?",
    "context": "",
    "output": "An HSM key ceremony is a procedure where the master key is generated and loaded to initialize the use of the HSM. The master key is at the top of the key hierarchy and is the root of trust to encrypt all other keys generated by the HSM. The purpose of an HSM key ceremony is to ensure the secure and proper loading of the master key.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is an HSM key ceremony and what is its purpose?",
      "answer": "An HSM key ceremony is a procedure where the master key is generated and loaded to initialize the use of the HSM. The master key is at the top of the key hierarchy and is the root of trust to encrypt all other keys generated by the HSM. The purpose of an HSM key ceremony is to ensure the secure and proper loading of the master key.",
      "context": "Key ceremony\n\n==Introduction==\nIn cryptography, a key ceremony is a ceremony held to generate or use a cryptographic key.A public example is the signing of the DNS root zone for DNSSEC.\n\n\n\n== Root Key Signing Ceremony ==\nIn public-key cryptography and computer security, a root key ceremony is a procedure where a unique pair of public and private root keys is generated.  Depending on the certificate policy, the generation of the root keys may require notarization, legal representation, witnesses, and \"key holders\" to be present, as the information on the system is the responsibility of the parties.  A commonly recognized practice is to follow the SAS 70 standard for root key ceremonies.\nAt the heart of every certificate authority (CA) is at least one root key or root certificate and usually at least one intermediate root certificate. A root key is a term for a unique passcode that must be generated for secure server interaction with a protective network, usually called the root zone. Prompts for information from this zone can be done through a server. The keys and certificates mentioned are the credentials and safeguards for the system. These digital certificates are made from a public and a private key.\n\n\n*** Examples ***\nExample A: These passcodes are used for Strong identification and non-repudiation for email and web access\nUnless the information being accessed or transmitted is valued in terms of millions of dollars, it is generally adequate that the root key ceremony be conducted within the security of the vendor's laboratory. The customer may opt to have the root key stored in a hardware security module, but in most cases, the safe storage of the root Key on a CD or hard disk is admissible. The root key is never stored on the CA server.\nExample B: Machine Readable Travel Document [MRTD] ID Card or e-Passport\nThis type of environment requires a much higher level of security.  When conducting the root key ceremony, the government or organization will require rigorous security checks on all personnel in attendance. Those normally required to attend the key ceremony include a minimum of two administrators from the organization, two signatories from the organization, one lawyer, a notary, and two video camera operators, in addition to the CA software vendor's technical team.\nExample A and B are at opposite ends of the security spectrum and no two environments are the same. Depending on the level of protection required, different levels of security will be used.\n\n\n*** Overview ***\nThe actual root key-pair generation is normally conducted in a secure vault that has no communication or contact with the outside world other than a single telephone line or intercom. Once the vault is secured, all personnel present must prove their identity using at least two legally recognized forms of identification. Every person present, every transaction, and every event is logged by the lawyer in a root key ceremony log book, and each page is notarized by the notary. From the moment the vault door is closed until it is re-opened, everything is also video recorded. The lawyer and the organization's two signatories must sign the recording and it too is then notarized.\nFinally, as part of the above process, the root key is broken into as many as twenty-one parts.  Each part is secured in a safe with a key and a numerical lock. The keys are distributed to as many as twenty-one people and the numerical code is distributed to another twenty-one people.\n\n\n*** Providers ***\nThe CA vendors and organisations, such as RSA, VeriSign and Digi-Sign, implement projects of this nature where conducting a root key ceremony would be a central component of their service.\n\n== IBM HSM key ceremony ==\nHardware security module (HSM) key ceremony is a procedure where the master key is generated and loaded to initialize the use of the HSM. The master key is at the top of the key hierarchy and is the root of trust to encrypt all other keys generated by the HSM. A master key is composed of at least two master key parts. Each key part is normally owned by a different person to enhance security.\n\n\n*** Master key types ***\nThe master key is stored within the HSM. IBM HSMs support two types of cryptographic mechanisms:\n\nThe PKCS#11 mechanism, called IBM Enterprise PKCS #11 (EP11), creates a high-security solution for application programs developed for this industry-standard API.\nThe IBM Common Cryptographic Architecture (CCA)  mechanism provides many functions of special interest in the finance industry, extensive support for distributed key management, and a base on which custom processing and cryptographic functions can be added.Depending on the cryptographic mechanisms that the HSM supports and the key objects that are encrypted by the master key, the following types of master keys are available:\n\nEP11 HSMs EP11 symmetric master key: used to encipher all kinds of sensitive materials including secret key objects and intermediate state information containing secret key materials.\nCCA HSMs SYM master key: used to encipher DES symmetric key objects\nASYM master key: used to encipher PKA-RSA asymmetric key objects\nAES master key: used to encipher AES, HMAC symmetric key objects\nAPKA master key: used to encipher PKA-ECC asymmetric key objects\n\n\n*** HSM key ceremony types ***\n\n\n**** On-premise HSM Key Ceremony ****\nFor IBM Z and LinuxONE Systems, the HSMs are used to perform cryptographic operations. The HSM has 85 domains with each having its own set of master keys. Before using the system, the HSM Key Ceremony must be conducted to load the master key securely and properly. For EP11 HSMs, the master key parts are stored on smart cards and loaded to the HSM with the Trusted Key Entry (TKE) workstation. For CCA HSMs, the master key parts can be stored either on smart cards or in files on the TKE workstation.\n\n\n**** Cloud HSM Key Ceremony ****\nEP11 HSM is currently the only type of HSM that supports Key Ceremony in the cloud. Both cloud command-line interface (CLI) or smart cards are provided to load the master key parts to the cloud HSM. IBM Cloud Hyper Protect Crypto Services is presently the only key management service and cloud HSM in the cloud to provide HSM key ceremony through both CLI and smart cards. \n\n\n*** Master key part storage ***\nDepending on the key ceremony types, the master key parts can be stored either on smart cards or in files on the workstation.\nSmart cards are protected by a personal identification number (PIN) that must be entered on a smart card reader pad. Each master key part owner has one smart card and only the owner knows its PIN. This solution ensures that the master key parts never appear in the clear outside the smart cards.\nCompared with the smart card solution, the workstation solution does not require the procurement of smart card readers and smart cards. This solution uses workstation files encrypted with keys derived from a file password to store master key parts. When the keys are used, file content is decrypted and appear temporarily in the clear in workstation memory.\n\n== In blockchain technology ==\nA key ceremony can be used to generate the private key for a cryptocurrency wallet.For Multiparty Computation(MPC), key ceremonies are used to split parts of keys to participants in a secure way. It is also use in Zero-Knowledge Proofs (zKP) protocols for key generation."
    }
  },
  {
    "instruction": "Write an answer to the following question: What were the charges brought against Andrew Auernheimer and Daniel Spitler by the Department of Justice?",
    "context": "",
    "output": "Andrew Auernheimer was charged with one count of conspiracy to access a computer without authorization and one count of fraud. Daniel Spitler was charged with one count of conspiracy to access a computer without authorization and released on bail.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What were the charges brought against Andrew Auernheimer and Daniel Spitler by the Department of Justice?",
      "answer": "Andrew Auernheimer was charged with one count of conspiracy to access a computer without authorization and one count of fraud. Daniel Spitler was charged with one count of conspiracy to access a computer without authorization and released on bail."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are the advantages of using hardware tokens implementing OATH HOTP compared to proprietary algorithms?",
    "context": "",
    "output": "Hardware tokens implementing OATH HOTP tend to be significantly cheaper than their competitors based on proprietary algorithms, and they can be purchased for a marginal price as of 2010.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are the advantages of using hardware tokens implementing OATH HOTP compared to proprietary algorithms?",
      "answer": "Hardware tokens implementing OATH HOTP tend to be significantly cheaper than their competitors based on proprietary algorithms, and they can be purchased for a marginal price as of 2010."
    }
  },
  {
    "instruction": "Answer based on context:\n\nOAuth\n\n==Introduction==\nOAuth (short for \"Open Authorization\") is an open standard for access delegation, commonly used as a way for internet users to grant websites or applications access to their information on other websites but without giving them the passwords. This mechanism is used by companies such as Amazon, Google, Facebook, Microsoft, and Twitter to permit users to share information about their accounts with third-party applications or websites.\nGenerally, the OAuth protocol provides a way for resource owners to provide a client [application] with secure delegated access to server resources. It specifies a process for resource owners to authorize third-party access to their server resources without providing credentials. Designed specifically to work with Hypertext Transfer Protocol (HTTP), OAuth essentially allows access tokens to be issued to third-party clients by an authorization server, with the approval of the resource owner. The third party then uses the access token to access the protected resources hosted by the resource server.\n\n== Security issues ==\n\n\n*** OAuth 1.0 ***\nOn 23 April 2009, a session fixation security flaw in the 1.0 protocol was announced. It affects the OAuth authorization flow (also known as \"3-legged OAuth\") in OAuth Core 1.0 Section 6.\nVersion 1.0a of the OAuth Core protocol was issued to address this issue.\n\n\n*** OAuth 2.0 ***\nIn January 2013, the Internet Engineering Task Force published a threat model for OAuth 2.0. Among the threats outlined is one called \"Open Redirector\"; in early 2014, a variant of this was described under the name \"Covert Redirect\" by Wang Jing.OAuth 2.0 has been analyzed using formal web protocol analysis. This analysis revealed that in setups with multiple authorization servers, one of which is behaving maliciously, clients can become confused about the authorization server to use and may forward secrets to the malicious authorization server (AS Mix-Up Attack). This prompted the creation of a new best current practice internet draft that sets out to define a new security standard for OAuth 2.0. Assuming a fix against the AS Mix-Up Attack in place, the security of OAuth 2.0 has been proven under strong attacker models using formal analysis.One implementation of OAuth 2.0 with numerous security flaws has been exposed.In April and May 2017, about one million users of Gmail (less than 0.1% of users as of May 2017) were targeted by an OAuth-based phishing attack, receiving an email purporting to be from a colleague, employer or friend wanting to share a document on Google Docs. Those who clicked on the link within the email were directed to sign in and allow a potentially malicious third-party program called \"Google Apps\" to access their \"email account, contacts and online documents\". Within \"approximately one hour\", the phishing attack was stopped by Google, who advised those who had given \"Google Apps\" access to their email to revoke such access and change their passwords.\nIn the draft of OAuth 2.1 the use of the PKCE extension for native apps has been recommended to all kinds of OAuth clients, including web applications and other confidential clients in order to avoid malicious browser extensions to perform OAuth 2.0 code injection attack.\n\n== Uses ==\nFacebook's Graph API only supports OAuth 2.0. Google supports OAuth 2.0 as the recommended authorization mechanism for all of its APIs. Microsoft also supports OAuth 2.0 for various APIs and its Azure Active Directory service, which is used to secure many Microsoft and third party APIs.\nOAuth can be used as an authorizing mechanism to access secured RSS/Atom feeds. Access to RSS/ATOM feeds that require authentication has always been an issue. For example, an RSS feed from a secured Google Site could not have been accessed using Google Reader. Instead, three-legged OAuth would have been used to authorize that RSS client to access the feed from the Google Site.\n\n== OAuth and other standards ==\nOAuth is a service that is complementary to and distinct from OpenID. OAuth is unrelated to OATH, which is a reference architecture for authentication, not a standard for authorization. However, OAuth is directly related to OpenID Connect (OIDC), since OIDC is an authentication layer built on top of OAuth 2.0. OAuth is also unrelated to XACML, which is an authorization policy standard. OAuth can be used in conjunction with XACML, where OAuth is used for ownership consent and access delegation whereas XACML is used to define the authorization policies (e.g., managers can view documents in their region).\n\n\n*** OpenID vis-\u00e0-vis pseudo-authentication using OAuth ***\nOAuth is an authorization protocol, rather than an authentication protocol. Using OAuth on its own as an authentication method may be referred to as pseudo-authentication. The following diagrams highlight the differences between using OpenID (specifically designed as an authentication protocol) and OAuth for authorization.\nThe communication flow in both processes is similar:\n\n(Not pictured) The user requests a resource or site login from the application.\nThe site sees that the user is not authenticated. It formulates a request for the identity provider, encodes it, and sends it to the user as part of a redirect URL.\nThe user's browser makes a request to the redirect URL for the identity provider, including the application's request\nIf necessary, the identity provider authenticates the user (perhaps by asking them for their username and password)\nOnce the identity provider is satisfied that the user is sufficiently authenticated, it processes the application's request, formulates a response, and sends that back to the user along with a redirect URL back to the application.\nThe user's browser requests the redirect URL that goes back to the application, including the identity provider's response\nThe application decodes the identity provider's response, and carries on accordingly.\n(OAuth only) The response includes an access token which the application can use to gain direct access to the identity provider's services on the user's behalf.The crucial difference is that in the OpenID authentication use case, the response from the identity provider is an assertion of identity; while in the OAuth authorization use case, the identity provider is also an API provider, and the response from the identity provider is an access token that may grant the application ongoing access to some of the identity provider's APIs, on the user's behalf. The access token acts as a kind of \"valet key\" that the application can include with its requests to the identity provider, which prove that it has permission from the user to access those APIs.\nBecause the identity provider typically (but not always) authenticates the user as part of the process of granting an OAuth access token, it is tempting to view a successful OAuth access token request as an authentication method itself. However, because OAuth was not designed with this use case in mind, making this assumption can lead to major security flaws.\n\n\n*** OAuth and XACML ***\nXACML is a policy-based, attribute-based access control authorization framework. It provides:\n\nAn access control architecture.\nA policy language with which to express a wide range of access control policies including policies that can use consents handled / defined via OAuth.\nA request / response scheme to send and receive authorization requests.XACML and OAuth can be combined to deliver a more comprehensive approach to authorization. OAuth does not provide a policy language with which to define access control policies. XACML can be used for its policy language.\nWhere OAuth focuses on delegated access (I, the user, grant Twitter access to my Facebook wall), and identity-centric authorization, XACML takes an attribute-based approach which can consider attributes of the user, the action, the resource, and the context (who, what, where, when, how). With XACML it is possible to define policies such as\n\nManagers can view documents in their department\nManagers can edit documents they own in draft modeXACML provides more fine-grained access control than OAuth does. OAuth is limited in granularity to the coarse functionality (the scopes) exposed by the target service. As a result, it often makes sense to combine OAuth and XACML together where OAuth will provide the delegated access use case and consent management and XACML will provide the authorization policies that work on the applications, processes, and data.\nLastly, XACML can work transparently across multiple stacks (APIs, web SSO, ESBs, home-grown apps, databases...). OAuth focuses exclusively on HTTP-based apps.\n\n== Controversy ==\nEran Hammer resigned from his role of lead author for the OAuth 2.0 project, withdrew from the IETF working group, and removed his name from the specification in July 2012. Hammer cited a conflict between web and enterprise cultures as his reason for leaving, noting that IETF is a community that is \"all about enterprise use cases\" and \"not capable of simple\". \"What is now offered is a blueprint for an authorization protocol\", he noted, \"that is the enterprise way\", providing a \"whole new frontier to sell consulting services and integration solutions\". In comparing OAuth 2.0 with OAuth 1.0, Hammer points out that it has become \"more complex, less interoperable, less useful, more incomplete, and most importantly, less secure\". He explains how architectural changes for 2.0 unbound tokens from clients, removed all signatures and cryptography at a protocol level and added expiring tokens (because tokens could not be revoked) while complicating the processing of authorization. Numerous items were left unspecified or unlimited in the specification because \"as has been the nature of this working group, no issue is too small to get stuck on or leave open for each implementation to decide.\"David Recordon later also removed his name from the specifications for unspecified reasons. Dick Hardt took over the editor role, and the framework was published in October 2012.David Harris, author of the email client Pegasus Mail, has criticised OAuth 2.0 as \"an absolute dog's breakfast\", requiring developers to write custom modules specific to each service (Gmail, Microsoft Mail services, etc.), and to register specifically with them.\n\nWho are the lead authors of the OAuth 2.0 project and why did they resign?",
    "context": "",
    "output": "Eran Hammer and David Recordon were the lead authors of the OAuth 2.0 project. Eran Hammer resigned due to a conflict between web and enterprise cultures and a belief that the specification had become more complex, less interoperable, less useful, more incomplete, and less secure than OAuth 1.0. David Recordon later also removed his name from the specifications for unspecified reasons.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Who are the lead authors of the OAuth 2.0 project and why did they resign?",
      "answer": "Eran Hammer and David Recordon were the lead authors of the OAuth 2.0 project. Eran Hammer resigned due to a conflict between web and enterprise cultures and a belief that the specification had become more complex, less interoperable, less useful, more incomplete, and less secure than OAuth 1.0. David Recordon later also removed his name from the specifications for unspecified reasons.",
      "context": "OAuth\n\n==Introduction==\nOAuth (short for \"Open Authorization\") is an open standard for access delegation, commonly used as a way for internet users to grant websites or applications access to their information on other websites but without giving them the passwords. This mechanism is used by companies such as Amazon, Google, Facebook, Microsoft, and Twitter to permit users to share information about their accounts with third-party applications or websites.\nGenerally, the OAuth protocol provides a way for resource owners to provide a client [application] with secure delegated access to server resources. It specifies a process for resource owners to authorize third-party access to their server resources without providing credentials. Designed specifically to work with Hypertext Transfer Protocol (HTTP), OAuth essentially allows access tokens to be issued to third-party clients by an authorization server, with the approval of the resource owner. The third party then uses the access token to access the protected resources hosted by the resource server.\n\n== Security issues ==\n\n\n*** OAuth 1.0 ***\nOn 23 April 2009, a session fixation security flaw in the 1.0 protocol was announced. It affects the OAuth authorization flow (also known as \"3-legged OAuth\") in OAuth Core 1.0 Section 6.\nVersion 1.0a of the OAuth Core protocol was issued to address this issue.\n\n\n*** OAuth 2.0 ***\nIn January 2013, the Internet Engineering Task Force published a threat model for OAuth 2.0. Among the threats outlined is one called \"Open Redirector\"; in early 2014, a variant of this was described under the name \"Covert Redirect\" by Wang Jing.OAuth 2.0 has been analyzed using formal web protocol analysis. This analysis revealed that in setups with multiple authorization servers, one of which is behaving maliciously, clients can become confused about the authorization server to use and may forward secrets to the malicious authorization server (AS Mix-Up Attack). This prompted the creation of a new best current practice internet draft that sets out to define a new security standard for OAuth 2.0. Assuming a fix against the AS Mix-Up Attack in place, the security of OAuth 2.0 has been proven under strong attacker models using formal analysis.One implementation of OAuth 2.0 with numerous security flaws has been exposed.In April and May 2017, about one million users of Gmail (less than 0.1% of users as of May 2017) were targeted by an OAuth-based phishing attack, receiving an email purporting to be from a colleague, employer or friend wanting to share a document on Google Docs. Those who clicked on the link within the email were directed to sign in and allow a potentially malicious third-party program called \"Google Apps\" to access their \"email account, contacts and online documents\". Within \"approximately one hour\", the phishing attack was stopped by Google, who advised those who had given \"Google Apps\" access to their email to revoke such access and change their passwords.\nIn the draft of OAuth 2.1 the use of the PKCE extension for native apps has been recommended to all kinds of OAuth clients, including web applications and other confidential clients in order to avoid malicious browser extensions to perform OAuth 2.0 code injection attack.\n\n== Uses ==\nFacebook's Graph API only supports OAuth 2.0. Google supports OAuth 2.0 as the recommended authorization mechanism for all of its APIs. Microsoft also supports OAuth 2.0 for various APIs and its Azure Active Directory service, which is used to secure many Microsoft and third party APIs.\nOAuth can be used as an authorizing mechanism to access secured RSS/Atom feeds. Access to RSS/ATOM feeds that require authentication has always been an issue. For example, an RSS feed from a secured Google Site could not have been accessed using Google Reader. Instead, three-legged OAuth would have been used to authorize that RSS client to access the feed from the Google Site.\n\n== OAuth and other standards ==\nOAuth is a service that is complementary to and distinct from OpenID. OAuth is unrelated to OATH, which is a reference architecture for authentication, not a standard for authorization. However, OAuth is directly related to OpenID Connect (OIDC), since OIDC is an authentication layer built on top of OAuth 2.0. OAuth is also unrelated to XACML, which is an authorization policy standard. OAuth can be used in conjunction with XACML, where OAuth is used for ownership consent and access delegation whereas XACML is used to define the authorization policies (e.g., managers can view documents in their region).\n\n\n*** OpenID vis-\u00e0-vis pseudo-authentication using OAuth ***\nOAuth is an authorization protocol, rather than an authentication protocol. Using OAuth on its own as an authentication method may be referred to as pseudo-authentication. The following diagrams highlight the differences between using OpenID (specifically designed as an authentication protocol) and OAuth for authorization.\nThe communication flow in both processes is similar:\n\n(Not pictured) The user requests a resource or site login from the application.\nThe site sees that the user is not authenticated. It formulates a request for the identity provider, encodes it, and sends it to the user as part of a redirect URL.\nThe user's browser makes a request to the redirect URL for the identity provider, including the application's request\nIf necessary, the identity provider authenticates the user (perhaps by asking them for their username and password)\nOnce the identity provider is satisfied that the user is sufficiently authenticated, it processes the application's request, formulates a response, and sends that back to the user along with a redirect URL back to the application.\nThe user's browser requests the redirect URL that goes back to the application, including the identity provider's response\nThe application decodes the identity provider's response, and carries on accordingly.\n(OAuth only) The response includes an access token which the application can use to gain direct access to the identity provider's services on the user's behalf.The crucial difference is that in the OpenID authentication use case, the response from the identity provider is an assertion of identity; while in the OAuth authorization use case, the identity provider is also an API provider, and the response from the identity provider is an access token that may grant the application ongoing access to some of the identity provider's APIs, on the user's behalf. The access token acts as a kind of \"valet key\" that the application can include with its requests to the identity provider, which prove that it has permission from the user to access those APIs.\nBecause the identity provider typically (but not always) authenticates the user as part of the process of granting an OAuth access token, it is tempting to view a successful OAuth access token request as an authentication method itself. However, because OAuth was not designed with this use case in mind, making this assumption can lead to major security flaws.\n\n\n*** OAuth and XACML ***\nXACML is a policy-based, attribute-based access control authorization framework. It provides:\n\nAn access control architecture.\nA policy language with which to express a wide range of access control policies including policies that can use consents handled / defined via OAuth.\nA request / response scheme to send and receive authorization requests.XACML and OAuth can be combined to deliver a more comprehensive approach to authorization. OAuth does not provide a policy language with which to define access control policies. XACML can be used for its policy language.\nWhere OAuth focuses on delegated access (I, the user, grant Twitter access to my Facebook wall), and identity-centric authorization, XACML takes an attribute-based approach which can consider attributes of the user, the action, the resource, and the context (who, what, where, when, how). With XACML it is possible to define policies such as\n\nManagers can view documents in their department\nManagers can edit documents they own in draft modeXACML provides more fine-grained access control than OAuth does. OAuth is limited in granularity to the coarse functionality (the scopes) exposed by the target service. As a result, it often makes sense to combine OAuth and XACML together where OAuth will provide the delegated access use case and consent management and XACML will provide the authorization policies that work on the applications, processes, and data.\nLastly, XACML can work transparently across multiple stacks (APIs, web SSO, ESBs, home-grown apps, databases...). OAuth focuses exclusively on HTTP-based apps.\n\n== Controversy ==\nEran Hammer resigned from his role of lead author for the OAuth 2.0 project, withdrew from the IETF working group, and removed his name from the specification in July 2012. Hammer cited a conflict between web and enterprise cultures as his reason for leaving, noting that IETF is a community that is \"all about enterprise use cases\" and \"not capable of simple\". \"What is now offered is a blueprint for an authorization protocol\", he noted, \"that is the enterprise way\", providing a \"whole new frontier to sell consulting services and integration solutions\". In comparing OAuth 2.0 with OAuth 1.0, Hammer points out that it has become \"more complex, less interoperable, less useful, more incomplete, and most importantly, less secure\". He explains how architectural changes for 2.0 unbound tokens from clients, removed all signatures and cryptography at a protocol level and added expiring tokens (because tokens could not be revoked) while complicating the processing of authorization. Numerous items were left unspecified or unlimited in the specification because \"as has been the nature of this working group, no issue is too small to get stuck on or leave open for each implementation to decide.\"David Recordon later also removed his name from the specifications for unspecified reasons. Dick Hardt took over the editor role, and the framework was published in October 2012.David Harris, author of the email client Pegasus Mail, has criticised OAuth 2.0 as \"an absolute dog's breakfast\", requiring developers to write custom modules specific to each service (Gmail, Microsoft Mail services, etc.), and to register specifically with them."
    }
  },
  {
    "instruction": "Write an answer to the following question: What type of crime is being targeted by Operation PowerOFF?",
    "context": "",
    "output": "Operation PowerOFF is targeting the illegal sale and use of DDoS attack services.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What type of crime is being targeted by Operation PowerOFF?",
      "answer": "Operation PowerOFF is targeting the illegal sale and use of DDoS attack services."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are the disadvantages of using delay pages and frame-based advertising in URL redirection services?",
    "context": "",
    "output": "Delay pages and frame-based advertising can lead to user frustration, as they might cause delays and distract users from the intended content. Additionally, they can negatively impact user experience and generate less revenue than other advertising methods.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are the disadvantages of using delay pages and frame-based advertising in URL redirection services?",
      "answer": "Delay pages and frame-based advertising can lead to user frustration, as they might cause delays and distract users from the intended content. Additionally, they can negatively impact user experience and generate less revenue than other advertising methods."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the SUID permission affect the behavior of an executable file owned by 'root' in Linux and Unix systems?",
    "context": "",
    "output": "If an executable file is owned by 'root' and the SUID permission is set, the file will be executed as 'root', allowing it to modify specific files that the user would not normally be allowed to.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the SUID permission affect the behavior of an executable file owned by 'root' in Linux and Unix systems?",
      "answer": "If an executable file is owned by 'root' and the SUID permission is set, the file will be executed as 'root', allowing it to modify specific files that the user would not normally be allowed to."
    }
  },
  {
    "instruction": "Cyberstalking legislation\n\n==Introduction==\nCyberstalking and cyberbullying are relatively new phenomena, but that does not mean that crimes committed through the network are not punishable under legislation drafted for that purpose. Although there are often existing laws that prohibit stalking or harassment in a general sense, legislators sometimes believe that such laws are inadequate or do not go far enough, and thus bring forward new legislation to address this perceived shortcoming. In the United States, for example, nearly every state has laws that address cyberstalking, cyberbullying, or both.\n\n== Issues at stake ==\nCyberbullying and cyberstalking, by their nature, define adversarial relationships. One person (or group), the provocateur, is exerting a view or opinion that the other person (or group), the target, finds offensive, hurtful, or damaging in some way. In a general sense, it would seem simple to legislate this type of behavior; slander and libel laws exist to tackle these situations. However, just as with slander and libel, it is important to balance the protection of freedom of speech of both parties with the need for protection of the target. Thus, something that may be deemed cyberbullying at first glance may, in fact, be more akin to something like parody or similar.\nA 2006 National Crime Prevention Council survey found that some 40% of teens had experienced cyberbullying at some point in their lives, making the problem particularly widespread. Not only is the issue of cyberbullying extensive, it has adverse effects on adolescents: increased depression, suicidal behavior, anxiety, and increased susceptibility of drug use and aggressive behavior.\n\n== Legislation by country ==\n\n\n*** Australia ***\nAustralia does not have specific cyberbullying legislation, although the scope of existing laws can be extended to deal with cyberbullying.\nState laws can deal with some forms of cyberbullying, such as documents containing threats, and threats to destroy and damage property.Commonwealth offences that criminalise the misuse of telecommunication services are also relevant when technology is used to communicate harassment or threats.The Family Law Act 1975 (Cth) protects individuals from harassment, including harassment that occurs via electronic communications.  However, this is limited to the victims of family violence.The Australian government has proposed specific cyberbullying laws to protect children.\n\n\n*** United States ***\n\n\n**** \"Cyberbullying\" versus \"cyberstalking\" ****\nIn the US, in practice, there is little legislative difference between the concepts of \"cyberbullying\" and \"cyberstalking.\" The primary distinction is one of age; if adults are involved, the act is usually termed cyberstalking, while among children it is usually referred to as cyberbullying. However, this distinction is one of semantics, and many laws treat bullying and stalking as much the same issue.\n\n\n**** Freedom of speech issues ****\nFirst Amendment concerns often arise when questionable speech is uttered or posted online. This is equally true when dealing with cyberbullying. Particularly in instances where there are no laws explicitly against cyberbullying, it is not uncommon for defendants to argue that their conduct amounts to an exercise of their freedom of speech.\nThe courts have variously come down on either side of that debate, even within the same state. For example, a student in California who was suspended from school based on cyberbullying claims took the school district to court, citing a breach of her First Amendment rights; the court agreed with the student and found the school district had overstepped its authority. In another California case, in which a student was harassed after posting personal information online, the court found that threatening posts were not protected speech. The state of North Carolina invalidated such a law in State v. Bishop.That said, true threats are not considered to be protected speech.Organizations such as the American Civil Liberties Union have taken the view that cyberbullying is an overly expansive term, and that the First Amendment protects all speech, even the reprehensible; this protection would extend to the Internet.In general, such organizations argue that while the need for legislation against cyberbullying may exist, legislators must take a cautious, reasoned approach to enacting laws, and not rush into creating laws that would curtail speech too much.Internet free speech issues have certainly made their way through the court systems, even as far back as cases from the mid-90s. In the case of United States v. Baker, for example, an undergraduate at the University of Michigan was charged with crimes related to snuff stories he had posted on Internet newsgroups, stories that named one of his fellow students. After progressing through the courts, the charges against Baker were dismissed primarily on grounds that there was no evidence that Baker would actually act out the fantasies contained in those stories. This case is now considered a landmark in the realm of First Amendment issues on the Internet.\n\n\n**** The need for new laws ****\nThe focus on legislating cyberbullying and cyberstalking has largely come about as a result of the perceived inadequacy, generally by legislators and parents of bullying victims, of existing laws, whether those existing laws cover stalking, unauthorized use of computer resources, or the like.\nThe motivation behind the bill in 1990 where 50 U.S. states and the federal government passed a bill to \"criminalize\" stalking was due to the cases of stalking against celebrities (Spitzberg & Hoobler, 2002).\nFor example, in the case of United States v. Lori Drew, in which Megan Meier had committed suicide after being bullied on MySpace, three of the four charges against the defendant (Drew) were actually in response to alleged violations of the Computer Fraud and Abuse Act, since specific statues against cyberbullying were not on the books. The jury eventually found Drew innocent of the charges (but guilty of a misdemeanor), a verdict that was later set aside by the judge. In this situation, legislators in Missouri, at the urging of the public and Meier's parents, passed \"Megan's Law\", primarily aimed at the crime of a person over 21 years of age bullying a person under 18 years of age.\nIn addition, prosecutors will sometimes use other legal avenues to prosecute offenders. In the case of Tyler Clementi, who killed himself after video of his homosexual encounter was broadcast on the Internet, prosecutors charged the defendants with invasion of privacy and computer crimes. Like the Meier case, the Clementi case spurred legislators (this time, in New Jersey) to pass a law specifically aimed at bullying, an \"Anti-bullying Bill of Rights\".While some laws are written such that the focus on cyberbullying is the set of acts that occur within a school, others are more general, targeting cyberbullying no matter where it occurs. In addition, some of these newly written laws (like one in Connecticut) put more of an onus on the school system, mandating that the school's administration must intervene at the first sign of bullying.Finally, it's not uncommon for cyberbullying to be coupled with \"traditional\", in-person bullying, for example, in the suicide of Phoebe Prince. Students at her school had bullied her for months in school, and that harassment eventually moved online as well. As in Connecticut, New Jersey, and Missouri, the Prince case led to stricter anti-bullying legislation in Massachusetts.\n\n\n**** Legislation at the state level ****\nSome U.S. states have begun to address the problem of cyberbullying. States that have passed legislation have done so generally in response to incidents within that state, to address what they believe to be shortcomings in federal laws, or to expand protection to victims above and beyond existing statutes.\nThere are laws that only address online harassment of children or focus on child predators as well as laws that protect adult cyberstalking victims, or victims of any age. While some sites specialize in laws that protect victims age 18 and under, Working to Halt Online Abuse is a help resource listing current and pending cyberstalking-related United States federal and state laws. It also lists those states that do not have laws yet and related laws from other countries.\n\n\n***** California*****\nCalifornia passed the first cyberstalking law in 1999. (\u00a7646.9 of the California Penal Code.) Its first use resulted in a six-year sentence for a man who harassed a woman who could identify him. After sending hundreds of threatening e-mails to an actress, another male convicted after spending months in jail waiting for trial was sentenced in 2001 to five years probation, forbidden access to computers and forced to attend mental health counseling. In 2011, a man was ordered to undergo psychiatric evaluation before sentencing for cyberstalking. On January 1, 2009, a California law became effective that allows schools to suspend or expel students who harass other students online. It also mandates that schools develop policies to address the problem. In addition, Section 1708.7 of the California Civil Code outlines grounds for an individual suing their cyberstalker and any accomplices for general damages, special damages, and punitive damages for cyberstalking.\n\n\n***** Florida*****\nUnder Florida Statute 784.048, \"cyberstalking,\" defined as to engage in a course of conduct to communicate, or to cause to be communicated, words, images, or language by or through the use of electronic mail or electronic communication, directed at a specific person, causing substantial emotional distress to that person and serving no legitimate purpose, is classified as a first degree misdemeanor. Cyberstalking a child under the age of 16 or a person of any age for which the offender has been ordered by the courts not to contact is considered \"aggravated stalking,\" a third degree felony under Florida law. Cyberstalking in conjunction with a credible threat is also considered aggravated stalking.In 2008, Florida passed the \"Jeffrey Johnston Stand Up For All Students Act\" in response to the suicide of 15-year-old Jeffrey Johnston, who had suffered cyberbullying over a long period of time. Unusual among state laws regarding cyberbullying is a provision that withholds funding for schools who are not in compliance with the provision that they must inform parents of those involved in cyberbullying\u2014both the bully and the target.\n\n\n***** Illinois*****\nAccording to \"Who@: Working to Halt Online Abuse\":\n\nSec. 1-2. Harassment through electronic communications.(a) Harassment through electronic communications is the use of electronic communication for any of the following\npurposes:\n\nMaking any comment, request, suggestion or proposal which is obscene with an intent to offend;\nInterrupting, with the intent to harass, the telephone service or the electronic communication service of any person;\nTransmitting to any person, with the intent to harass and regardless of whether the communication is read in its entirety or at all, any file, document, or other communication which prevents that person from using his or her telephone service or electronic communications device;\nTransmitting an electronic communication or knowingly inducing a person to transmit an electronic communication for the purpose of harassing another person who is under 13 years of age, regardless of whether the person under 13 years of age consents to the harassment, if the defendant is at least 16 years of age at the time of the commission of the offense;\nThreatening injury to the person or to the property of the person to whom an electronic communication is directed or to any of his or her family or household members; or\nKnowingly permitting any electronic communications device to be used for any of the purposes mentioned in this subsection (a).(b) As used in this Act: \n\n\"Electronic communication\" means any transfer of signs, signals, writings, images, sounds, data or intelligence of any nature transmitted in whole or in part by a wire, radio, electromagnetic, photoelectric or photo-optical system. \"Electronic communication\" includes transmissions by a computer through the Internet to another computer.\n\"Family or household member\" includes spouses, former spouses, parents, children, stepchildren and other persons related by blood or by present or prior marriage, persons who share or formerly shared a common dwelling, persons who have or allegedly share a blood relationship through a child, persons who have or have had a dating or engagement relationship, and persons with disabilities and their personal assistants. For purposes of this Act, neither a casual acquaintanceship nor ordinary fraternization between 2 individuals in business or social contexts shall be deemed to constitute a dating relationship.(c) Telecommunications carriers, commercial mobile service providers, and providers of information services, including, but not limited to, Internet service providers and hosting service providers, are not liable under this Section, except for willful and wanton misconduct, by virtue of the transmission, storage, or caching of electronic communications or messages of others or by virtue of the provision of other related telecommunications, commercial mobile services, or information services used by others in violation of this Section. (Source: P.A. 95-849, eff. 1-1-09; 95-984, eff. 6-1-09; 96-328, eff. 8-11-09.)\n\n\n***** Massachusetts*****\nIn response to Phoebe Prince's suicide, as well as that of Carl Walker\u2014both of whom had been bullied before taking their lives\u2014the Massachusetts legislature in 2010 passed what advocates call one of the toughest anti-bullying laws in the nation. The law prohibits both online taunting and physical or emotional abuse, and mandates training for faculty and students at schools. It further mandates that school administrators inform parents of bullying that occurs within the schools themselves.\n\n\n***** Missouri*****\nAs noted previously, in 2008 Missouri revised its statutes on harassment to include harassment and stalking through electronic and telephonic communications and cyber-bullying after the suicide of Megan Meier.\n\n\n***** New York*****\nNew York state passed the Dignity For All Students Act, focusing primarily on elementary and middle school students.\n\n\n***** Texas*****\nTexas enacted the Stalking by Electronic Communications Act in 2001.\n\n\n***** Washington state*****\nWashington passed one of the first cyberstalking laws in 2004, which states that a person that uses electronic communications with the \"intent to harass, intimidate, torment, or embarrass any other person\" if they use lewd or obscene language, use language implying physical threats, or repeatedly harass a person; such is treated as a gross misdemeanor. However, the constitutionality of this law has been challenged in courts, with Judge Ronald B. Leighton of the United States District Court for the Western District of Washington ruled in February 2019 that the law as written could include \"a large range of non-obscene, non-threatening speech\" and that \"As a result even public criticisms of public figures and public officials could be subject to criminal prosecution and punishment\". Judge Leighton placed an injunction on the law to block its enforcement pending appeal. In 2021, the senate introduced two bills at the aim of addressing cyberharassment, the first of which, Senate Bill (SB) 5881, which was mainly aimed at preventing doxing, led to the same free speech concerns as the existing cyberstalking laws. The other bill, SB 5628, focused on online harassment and was written with the Anti-Defamation League to update the existing law to uphold the First Amendment.Washington takes the approach of putting the focus on cyberbullying prevention and response directly on the schools. The law also requires schools to create policies to address bullying in a general sense.\n\n\n**** Legislation at the federal level ****\nAttempts at legislating cyberbullying have been tried at the federal level, primarily because the Commerce Clause of the U.S. Constitution specifically provides that only the federal government can regulate commerce between the states; this includes electronic communication over the Internet. An early example, the Violence Against Women Act, passed in 2000, included cyberbullying in a part of interstate status on harassment.\n\n\n***** Megan Meier Cyberbullying Prevention Act*****\nIn 2009, Representative Linda S\u00e1nchez (D-CA) brought legislation titled the \"Megan Meier Cyberbullying Prevention Act\" before the U.S. House of Representatives. Her efforts were met with little enthusiasm, however, as Representatives from both the Republican and Democratic parties were concerned with the bill's impact on the freedom of speech. One of the oft-cited arguments against the bill comes from talk radio, with the concern expressed being that the law would be used to silence political opponents who use the airwaves to espouse divergent viewpoints. Another issue is that would make violation of the law a felony, rather than a misdemeanor as has been done in most states. Opponents of the bill argue that since the target of such legislation is nominally teenagers, this would put an undue burden on the prison system\u2014since there are no long-term facilities for teenage offenders at the federal level. In addition, opponents call the proposed sentences (up to two years incarceration) excessive.While S\u00e1nchez' bill was discussed in committee, it has not passed that stage as of 2012.\n\n\n***** Tyler Clementi Higher Education Anti-Harassment Act*****\nIn early March 2011, U.S. Senator Frank Lautenberg (D-NJ) and Representative Rush D. Holt, Jr. (D-NJ-12) introduced the \"Tyler Clementi Higher Education Anti-Harassment Act\", which would mandate that colleges and universities that receive federal funding have policies in place to address harassment\u2014including cyberbullying. Universities would be required to address harassment that focuses on real or perceived race, color, national origin, sex, disability, sexual orientation, gender identity, or religion. The bill would also enable the U.S. Department of Education to provide training to institutes of higher education to prevent or address harassment. Furthermore, the bill addresses not just student-to-student harassment, but also harassment of students by faculty or staff as well.\nHowever, like the Megan Meier Cyberbullying Prevention Act, this bill also has its detractors. Opponents point out that harassment on college campuses is already prohibited under existing laws; furthermore, they point out that harassment based on sexual orientation is also covered under existing statutes. In addition, as with the S\u00e1nchez bill, there are questions as to the free speech implications.\n\n\n*** India ***\nPrior to February 2013, there were no laws that directly regulate cyberstalking in India. India's Information Technology Act of 2000 (IT Act) was a set of laws to regulate the cyberspace. However, it merely focused on financial crimes and neglected interpersonal criminal behaviours such as cyberstalking (Behera, 2010; Halder & Jaishankar, 2008; Nappinai, 2010). In 2013, Indian Parliament made amendments to the Indian Penal Code, introducing cyberstalking as a criminal offence. Stalking has been defined as a man or woman who follows or contacts a man or woman, despite clear indication of disinterest to such contact by the man or woman, or monitoring of use of internet or electronic communication of a man or a woman. A man or a woman committing the offence of stalking would be liable for imprisonment up to three years for the first offence, and shall also be liable to fine and for any subsequent conviction would be liable for imprisonment up to five years and with fine.\n\n\n*** Poland ***\nCyberstalking has been illegal since 2011.\n\n\n*** New Zealand ***\nNew Zealand Minister of Justice Judith Collins plans to introduce a law that would make it an offence to incite people to commit suicide, or post material that is grossly offensive by the end of 2013.\n\n== International law ==\n\n\n*** Convention on Cybercrime ***\n\nInternational law emphasizes a supranational concept related to cybercrime. This is the Convention on Cybercrime, signed by the Council of Europe in Budapest on November 23, 2001.The Global Cyber Law Database (GCLD) aims to become the most comprehensive and authoritative source of cyber laws for all countries.\n\n\n*** Universal Declaration of Human Rights ***\n\nArticle 5 of the Universal Declaration of Human Rights.No one shall be subjected to torture or to cruel, inhuman or degrading treatment.\nQ: What are some concerns raised by organizations such as the American Civil Liberties Union regarding cyberbullying legislation?",
    "context": "",
    "output": "Organizations such as the American Civil Liberties Union have taken the view that cyberbullying is an overly expansive term, and that the First Amendment protects all speech, even the reprehensible. They argue that while the need for legislation against cyberbullying may exist, legislators must take a cautious, reasoned approach to enacting laws, and not rush into creating laws that would curtail speech too much.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are some concerns raised by organizations such as the American Civil Liberties Union regarding cyberbullying legislation?",
      "answer": "Organizations such as the American Civil Liberties Union have taken the view that cyberbullying is an overly expansive term, and that the First Amendment protects all speech, even the reprehensible. They argue that while the need for legislation against cyberbullying may exist, legislators must take a cautious, reasoned approach to enacting laws, and not rush into creating laws that would curtail speech too much.",
      "context": "Cyberstalking legislation\n\n==Introduction==\nCyberstalking and cyberbullying are relatively new phenomena, but that does not mean that crimes committed through the network are not punishable under legislation drafted for that purpose. Although there are often existing laws that prohibit stalking or harassment in a general sense, legislators sometimes believe that such laws are inadequate or do not go far enough, and thus bring forward new legislation to address this perceived shortcoming. In the United States, for example, nearly every state has laws that address cyberstalking, cyberbullying, or both.\n\n== Issues at stake ==\nCyberbullying and cyberstalking, by their nature, define adversarial relationships. One person (or group), the provocateur, is exerting a view or opinion that the other person (or group), the target, finds offensive, hurtful, or damaging in some way. In a general sense, it would seem simple to legislate this type of behavior; slander and libel laws exist to tackle these situations. However, just as with slander and libel, it is important to balance the protection of freedom of speech of both parties with the need for protection of the target. Thus, something that may be deemed cyberbullying at first glance may, in fact, be more akin to something like parody or similar.\nA 2006 National Crime Prevention Council survey found that some 40% of teens had experienced cyberbullying at some point in their lives, making the problem particularly widespread. Not only is the issue of cyberbullying extensive, it has adverse effects on adolescents: increased depression, suicidal behavior, anxiety, and increased susceptibility of drug use and aggressive behavior.\n\n== Legislation by country ==\n\n\n*** Australia ***\nAustralia does not have specific cyberbullying legislation, although the scope of existing laws can be extended to deal with cyberbullying.\nState laws can deal with some forms of cyberbullying, such as documents containing threats, and threats to destroy and damage property.Commonwealth offences that criminalise the misuse of telecommunication services are also relevant when technology is used to communicate harassment or threats.The Family Law Act 1975 (Cth) protects individuals from harassment, including harassment that occurs via electronic communications.  However, this is limited to the victims of family violence.The Australian government has proposed specific cyberbullying laws to protect children.\n\n\n*** United States ***\n\n\n**** \"Cyberbullying\" versus \"cyberstalking\" ****\nIn the US, in practice, there is little legislative difference between the concepts of \"cyberbullying\" and \"cyberstalking.\" The primary distinction is one of age; if adults are involved, the act is usually termed cyberstalking, while among children it is usually referred to as cyberbullying. However, this distinction is one of semantics, and many laws treat bullying and stalking as much the same issue.\n\n\n**** Freedom of speech issues ****\nFirst Amendment concerns often arise when questionable speech is uttered or posted online. This is equally true when dealing with cyberbullying. Particularly in instances where there are no laws explicitly against cyberbullying, it is not uncommon for defendants to argue that their conduct amounts to an exercise of their freedom of speech.\nThe courts have variously come down on either side of that debate, even within the same state. For example, a student in California who was suspended from school based on cyberbullying claims took the school district to court, citing a breach of her First Amendment rights; the court agreed with the student and found the school district had overstepped its authority. In another California case, in which a student was harassed after posting personal information online, the court found that threatening posts were not protected speech. The state of North Carolina invalidated such a law in State v. Bishop.That said, true threats are not considered to be protected speech.Organizations such as the American Civil Liberties Union have taken the view that cyberbullying is an overly expansive term, and that the First Amendment protects all speech, even the reprehensible; this protection would extend to the Internet.In general, such organizations argue that while the need for legislation against cyberbullying may exist, legislators must take a cautious, reasoned approach to enacting laws, and not rush into creating laws that would curtail speech too much.Internet free speech issues have certainly made their way through the court systems, even as far back as cases from the mid-90s. In the case of United States v. Baker, for example, an undergraduate at the University of Michigan was charged with crimes related to snuff stories he had posted on Internet newsgroups, stories that named one of his fellow students. After progressing through the courts, the charges against Baker were dismissed primarily on grounds that there was no evidence that Baker would actually act out the fantasies contained in those stories. This case is now considered a landmark in the realm of First Amendment issues on the Internet.\n\n\n**** The need for new laws ****\nThe focus on legislating cyberbullying and cyberstalking has largely come about as a result of the perceived inadequacy, generally by legislators and parents of bullying victims, of existing laws, whether those existing laws cover stalking, unauthorized use of computer resources, or the like.\nThe motivation behind the bill in 1990 where 50 U.S. states and the federal government passed a bill to \"criminalize\" stalking was due to the cases of stalking against celebrities (Spitzberg & Hoobler, 2002).\nFor example, in the case of United States v. Lori Drew, in which Megan Meier had committed suicide after being bullied on MySpace, three of the four charges against the defendant (Drew) were actually in response to alleged violations of the Computer Fraud and Abuse Act, since specific statues against cyberbullying were not on the books. The jury eventually found Drew innocent of the charges (but guilty of a misdemeanor), a verdict that was later set aside by the judge. In this situation, legislators in Missouri, at the urging of the public and Meier's parents, passed \"Megan's Law\", primarily aimed at the crime of a person over 21 years of age bullying a person under 18 years of age.\nIn addition, prosecutors will sometimes use other legal avenues to prosecute offenders. In the case of Tyler Clementi, who killed himself after video of his homosexual encounter was broadcast on the Internet, prosecutors charged the defendants with invasion of privacy and computer crimes. Like the Meier case, the Clementi case spurred legislators (this time, in New Jersey) to pass a law specifically aimed at bullying, an \"Anti-bullying Bill of Rights\".While some laws are written such that the focus on cyberbullying is the set of acts that occur within a school, others are more general, targeting cyberbullying no matter where it occurs. In addition, some of these newly written laws (like one in Connecticut) put more of an onus on the school system, mandating that the school's administration must intervene at the first sign of bullying.Finally, it's not uncommon for cyberbullying to be coupled with \"traditional\", in-person bullying, for example, in the suicide of Phoebe Prince. Students at her school had bullied her for months in school, and that harassment eventually moved online as well. As in Connecticut, New Jersey, and Missouri, the Prince case led to stricter anti-bullying legislation in Massachusetts.\n\n\n**** Legislation at the state level ****\nSome U.S. states have begun to address the problem of cyberbullying. States that have passed legislation have done so generally in response to incidents within that state, to address what they believe to be shortcomings in federal laws, or to expand protection to victims above and beyond existing statutes.\nThere are laws that only address online harassment of children or focus on child predators as well as laws that protect adult cyberstalking victims, or victims of any age. While some sites specialize in laws that protect victims age 18 and under, Working to Halt Online Abuse is a help resource listing current and pending cyberstalking-related United States federal and state laws. It also lists those states that do not have laws yet and related laws from other countries.\n\n\n***** California*****\nCalifornia passed the first cyberstalking law in 1999. (\u00a7646.9 of the California Penal Code.) Its first use resulted in a six-year sentence for a man who harassed a woman who could identify him. After sending hundreds of threatening e-mails to an actress, another male convicted after spending months in jail waiting for trial was sentenced in 2001 to five years probation, forbidden access to computers and forced to attend mental health counseling. In 2011, a man was ordered to undergo psychiatric evaluation before sentencing for cyberstalking. On January 1, 2009, a California law became effective that allows schools to suspend or expel students who harass other students online. It also mandates that schools develop policies to address the problem. In addition, Section 1708.7 of the California Civil Code outlines grounds for an individual suing their cyberstalker and any accomplices for general damages, special damages, and punitive damages for cyberstalking.\n\n\n***** Florida*****\nUnder Florida Statute 784.048, \"cyberstalking,\" defined as to engage in a course of conduct to communicate, or to cause to be communicated, words, images, or language by or through the use of electronic mail or electronic communication, directed at a specific person, causing substantial emotional distress to that person and serving no legitimate purpose, is classified as a first degree misdemeanor. Cyberstalking a child under the age of 16 or a person of any age for which the offender has been ordered by the courts not to contact is considered \"aggravated stalking,\" a third degree felony under Florida law. Cyberstalking in conjunction with a credible threat is also considered aggravated stalking.In 2008, Florida passed the \"Jeffrey Johnston Stand Up For All Students Act\" in response to the suicide of 15-year-old Jeffrey Johnston, who had suffered cyberbullying over a long period of time. Unusual among state laws regarding cyberbullying is a provision that withholds funding for schools who are not in compliance with the provision that they must inform parents of those involved in cyberbullying\u2014both the bully and the target.\n\n\n***** Illinois*****\nAccording to \"Who@: Working to Halt Online Abuse\":\n\nSec. 1-2. Harassment through electronic communications.(a) Harassment through electronic communications is the use of electronic communication for any of the following\npurposes:\n\nMaking any comment, request, suggestion or proposal which is obscene with an intent to offend;\nInterrupting, with the intent to harass, the telephone service or the electronic communication service of any person;\nTransmitting to any person, with the intent to harass and regardless of whether the communication is read in its entirety or at all, any file, document, or other communication which prevents that person from using his or her telephone service or electronic communications device;\nTransmitting an electronic communication or knowingly inducing a person to transmit an electronic communication for the purpose of harassing another person who is under 13 years of age, regardless of whether the person under 13 years of age consents to the harassment, if the defendant is at least 16 years of age at the time of the commission of the offense;\nThreatening injury to the person or to the property of the person to whom an electronic communication is directed or to any of his or her family or household members; or\nKnowingly permitting any electronic communications device to be used for any of the purposes mentioned in this subsection (a).(b) As used in this Act: \n\n\"Electronic communication\" means any transfer of signs, signals, writings, images, sounds, data or intelligence of any nature transmitted in whole or in part by a wire, radio, electromagnetic, photoelectric or photo-optical system. \"Electronic communication\" includes transmissions by a computer through the Internet to another computer.\n\"Family or household member\" includes spouses, former spouses, parents, children, stepchildren and other persons related by blood or by present or prior marriage, persons who share or formerly shared a common dwelling, persons who have or allegedly share a blood relationship through a child, persons who have or have had a dating or engagement relationship, and persons with disabilities and their personal assistants. For purposes of this Act, neither a casual acquaintanceship nor ordinary fraternization between 2 individuals in business or social contexts shall be deemed to constitute a dating relationship.(c) Telecommunications carriers, commercial mobile service providers, and providers of information services, including, but not limited to, Internet service providers and hosting service providers, are not liable under this Section, except for willful and wanton misconduct, by virtue of the transmission, storage, or caching of electronic communications or messages of others or by virtue of the provision of other related telecommunications, commercial mobile services, or information services used by others in violation of this Section. (Source: P.A. 95-849, eff. 1-1-09; 95-984, eff. 6-1-09; 96-328, eff. 8-11-09.)\n\n\n***** Massachusetts*****\nIn response to Phoebe Prince's suicide, as well as that of Carl Walker\u2014both of whom had been bullied before taking their lives\u2014the Massachusetts legislature in 2010 passed what advocates call one of the toughest anti-bullying laws in the nation. The law prohibits both online taunting and physical or emotional abuse, and mandates training for faculty and students at schools. It further mandates that school administrators inform parents of bullying that occurs within the schools themselves.\n\n\n***** Missouri*****\nAs noted previously, in 2008 Missouri revised its statutes on harassment to include harassment and stalking through electronic and telephonic communications and cyber-bullying after the suicide of Megan Meier.\n\n\n***** New York*****\nNew York state passed the Dignity For All Students Act, focusing primarily on elementary and middle school students.\n\n\n***** Texas*****\nTexas enacted the Stalking by Electronic Communications Act in 2001.\n\n\n***** Washington state*****\nWashington passed one of the first cyberstalking laws in 2004, which states that a person that uses electronic communications with the \"intent to harass, intimidate, torment, or embarrass any other person\" if they use lewd or obscene language, use language implying physical threats, or repeatedly harass a person; such is treated as a gross misdemeanor. However, the constitutionality of this law has been challenged in courts, with Judge Ronald B. Leighton of the United States District Court for the Western District of Washington ruled in February 2019 that the law as written could include \"a large range of non-obscene, non-threatening speech\" and that \"As a result even public criticisms of public figures and public officials could be subject to criminal prosecution and punishment\". Judge Leighton placed an injunction on the law to block its enforcement pending appeal. In 2021, the senate introduced two bills at the aim of addressing cyberharassment, the first of which, Senate Bill (SB) 5881, which was mainly aimed at preventing doxing, led to the same free speech concerns as the existing cyberstalking laws. The other bill, SB 5628, focused on online harassment and was written with the Anti-Defamation League to update the existing law to uphold the First Amendment.Washington takes the approach of putting the focus on cyberbullying prevention and response directly on the schools. The law also requires schools to create policies to address bullying in a general sense.\n\n\n**** Legislation at the federal level ****\nAttempts at legislating cyberbullying have been tried at the federal level, primarily because the Commerce Clause of the U.S. Constitution specifically provides that only the federal government can regulate commerce between the states; this includes electronic communication over the Internet. An early example, the Violence Against Women Act, passed in 2000, included cyberbullying in a part of interstate status on harassment.\n\n\n***** Megan Meier Cyberbullying Prevention Act*****\nIn 2009, Representative Linda S\u00e1nchez (D-CA) brought legislation titled the \"Megan Meier Cyberbullying Prevention Act\" before the U.S. House of Representatives. Her efforts were met with little enthusiasm, however, as Representatives from both the Republican and Democratic parties were concerned with the bill's impact on the freedom of speech. One of the oft-cited arguments against the bill comes from talk radio, with the concern expressed being that the law would be used to silence political opponents who use the airwaves to espouse divergent viewpoints. Another issue is that would make violation of the law a felony, rather than a misdemeanor as has been done in most states. Opponents of the bill argue that since the target of such legislation is nominally teenagers, this would put an undue burden on the prison system\u2014since there are no long-term facilities for teenage offenders at the federal level. In addition, opponents call the proposed sentences (up to two years incarceration) excessive.While S\u00e1nchez' bill was discussed in committee, it has not passed that stage as of 2012.\n\n\n***** Tyler Clementi Higher Education Anti-Harassment Act*****\nIn early March 2011, U.S. Senator Frank Lautenberg (D-NJ) and Representative Rush D. Holt, Jr. (D-NJ-12) introduced the \"Tyler Clementi Higher Education Anti-Harassment Act\", which would mandate that colleges and universities that receive federal funding have policies in place to address harassment\u2014including cyberbullying. Universities would be required to address harassment that focuses on real or perceived race, color, national origin, sex, disability, sexual orientation, gender identity, or religion. The bill would also enable the U.S. Department of Education to provide training to institutes of higher education to prevent or address harassment. Furthermore, the bill addresses not just student-to-student harassment, but also harassment of students by faculty or staff as well.\nHowever, like the Megan Meier Cyberbullying Prevention Act, this bill also has its detractors. Opponents point out that harassment on college campuses is already prohibited under existing laws; furthermore, they point out that harassment based on sexual orientation is also covered under existing statutes. In addition, as with the S\u00e1nchez bill, there are questions as to the free speech implications.\n\n\n*** India ***\nPrior to February 2013, there were no laws that directly regulate cyberstalking in India. India's Information Technology Act of 2000 (IT Act) was a set of laws to regulate the cyberspace. However, it merely focused on financial crimes and neglected interpersonal criminal behaviours such as cyberstalking (Behera, 2010; Halder & Jaishankar, 2008; Nappinai, 2010). In 2013, Indian Parliament made amendments to the Indian Penal Code, introducing cyberstalking as a criminal offence. Stalking has been defined as a man or woman who follows or contacts a man or woman, despite clear indication of disinterest to such contact by the man or woman, or monitoring of use of internet or electronic communication of a man or a woman. A man or a woman committing the offence of stalking would be liable for imprisonment up to three years for the first offence, and shall also be liable to fine and for any subsequent conviction would be liable for imprisonment up to five years and with fine.\n\n\n*** Poland ***\nCyberstalking has been illegal since 2011.\n\n\n*** New Zealand ***\nNew Zealand Minister of Justice Judith Collins plans to introduce a law that would make it an offence to incite people to commit suicide, or post material that is grossly offensive by the end of 2013.\n\n== International law ==\n\n\n*** Convention on Cybercrime ***\n\nInternational law emphasizes a supranational concept related to cybercrime. This is the Convention on Cybercrime, signed by the Council of Europe in Budapest on November 23, 2001.The Global Cyber Law Database (GCLD) aims to become the most comprehensive and authoritative source of cyber laws for all countries.\n\n\n*** Universal Declaration of Human Rights ***\n\nArticle 5 of the Universal Declaration of Human Rights.No one shall be subjected to torture or to cruel, inhuman or degrading treatment."
    }
  },
  {
    "instruction": "Context: Distributed denial-of-service attacks on root nameservers\n\n==Introduction==\nDistributed denial-of-service attacks on root nameservers are Internet events in which distributed denial-of-service attacks target one or more of the thirteen Domain Name System root nameserver clusters. The root nameservers are critical infrastructure components of the Internet, mapping domain names to IP addresses and other resource record (RR) data.\nAttacks against the root nameservers could, in theory, impact operation of the entire global Domain Name System, and thus all Internet services that use the global DNS, rather than just specific websites. However, in practice, the root nameserver infrastructure is highly resilient and distributed, using both the inherent features of DNS (result caching, retries, and multiple servers for the same zone with fallback if one or more fail), and, in recent years, a combination of anycast and load balancer techniques used to implement most of the thirteen nominal individual root servers as globally distributed clusters of servers in multiple data centers.\nIn particular, the caching and redundancy features of DNS mean that it would require a sustained outage of all the major root servers for many days before any serious problems were created for most Internet users, and even then there are still numerous ways in which ISPs could set their systems up during that period to mitigate even a total loss of all root servers for an extended period of time: for example by installing their own copies of the global DNS root zone data on nameservers within their network, and redirecting traffic to the root server IP addresses to those servers. Nevertheless, DDoS attacks on the root zone are taken seriously as a risk by the operators of the root nameservers, and they continue to upgrade the capacity and DDoS mitigation capabilities of their infrastructure to resist any future attacks.\nAn effective attack against DNS might involve targeting top-level domain servers (such as those servicing the .com domain) instead of root name servers. Alternatively, a man-in-the-middle attack or DNS poisoning attack could be used, though they would be more difficult to carry out.\n\n\n\n== Attacks ==\n\n\n*** October 21, 2002 ***\nOn October 21, 2002 an attack lasting for approximately one hour was targeted at all 13 DNS root name servers. The attackers sent many ICMP ping packets using a botnet to each of the servers. However, because the servers were protected by packet filters which were configured to block all incoming ICMP ping packets, they did not sustain much damage and there was little to no impact on Internet users.\n\n\n*** February 6, 2007 ***\nOn February 6, 2007 an attack began at 10:00 UTC and lasted twenty-four hours. At least two of the root servers (G-ROOT and L-ROOT) reportedly \"suffered badly\" while two others (F-ROOT and M-ROOT) \"experienced heavy traffic\". The latter two servers largely mitigated the damage by distributing requests to other root server instances with anycast addressing. ICANN published a formal analysis shortly after the event.Due to a lack of detail, speculation about the incident proliferated in the press until details were released.\n\n\n*** November 30, 2015 ***\nDuring two intervals on November 30, 2015 and December 1, 2015, several of the root name servers received up to 5 million queries per second each, receiving valid queries for a single undisclosed domain name and then a different domain the next day. Source addresses were spread throughout IPv4 space, however these may have been spoofed. Some root server networks became saturated, resulting in timeouts, however redundancy among the root servers prevented downstream issues from occurring during this incident.\n\n== Threats ==\n\n\n*** Operation Global Blackout 2012 ***\nOn February 12, 2012, a statement was posted on Pastebin cited to be from Anonymous, threatening an attack on the root servers on March 31, 2012.\"To protest SOPA, Wallstreet, our irresponsible leaders and the beloved bankers who are starving the world for their own selfish needs out of sheer sadistic fun, On March 31, anonymous will shut the Internet down,\" reads the statement. \"Remember, this is a protest, we are not trying to \u2018kill' the Internet, we are only temporarily shutting it down where it hurts the most\u2026It may only last one hour, maybe more, maybe even a few days. No matter what, it will be global. It will be known.\"\n\nQuestion: How does the use of anycast addressing help in mitigating the impact of DDoS attacks on root nameservers?\n\nAnswer:",
    "context": "",
    "output": "Anycast addressing allows for the distribution of requests among multiple servers in different locations. This can help to reduce the risk of overloading any single server and increase the overall resilience of the root nameserver infrastructure.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the use of anycast addressing help in mitigating the impact of DDoS attacks on root nameservers?",
      "answer": "Anycast addressing allows for the distribution of requests among multiple servers in different locations. This can help to reduce the risk of overloading any single server and increase the overall resilience of the root nameserver infrastructure.",
      "context": "Distributed denial-of-service attacks on root nameservers\n\n==Introduction==\nDistributed denial-of-service attacks on root nameservers are Internet events in which distributed denial-of-service attacks target one or more of the thirteen Domain Name System root nameserver clusters. The root nameservers are critical infrastructure components of the Internet, mapping domain names to IP addresses and other resource record (RR) data.\nAttacks against the root nameservers could, in theory, impact operation of the entire global Domain Name System, and thus all Internet services that use the global DNS, rather than just specific websites. However, in practice, the root nameserver infrastructure is highly resilient and distributed, using both the inherent features of DNS (result caching, retries, and multiple servers for the same zone with fallback if one or more fail), and, in recent years, a combination of anycast and load balancer techniques used to implement most of the thirteen nominal individual root servers as globally distributed clusters of servers in multiple data centers.\nIn particular, the caching and redundancy features of DNS mean that it would require a sustained outage of all the major root servers for many days before any serious problems were created for most Internet users, and even then there are still numerous ways in which ISPs could set their systems up during that period to mitigate even a total loss of all root servers for an extended period of time: for example by installing their own copies of the global DNS root zone data on nameservers within their network, and redirecting traffic to the root server IP addresses to those servers. Nevertheless, DDoS attacks on the root zone are taken seriously as a risk by the operators of the root nameservers, and they continue to upgrade the capacity and DDoS mitigation capabilities of their infrastructure to resist any future attacks.\nAn effective attack against DNS might involve targeting top-level domain servers (such as those servicing the .com domain) instead of root name servers. Alternatively, a man-in-the-middle attack or DNS poisoning attack could be used, though they would be more difficult to carry out.\n\n\n\n== Attacks ==\n\n\n*** October 21, 2002 ***\nOn October 21, 2002 an attack lasting for approximately one hour was targeted at all 13 DNS root name servers. The attackers sent many ICMP ping packets using a botnet to each of the servers. However, because the servers were protected by packet filters which were configured to block all incoming ICMP ping packets, they did not sustain much damage and there was little to no impact on Internet users.\n\n\n*** February 6, 2007 ***\nOn February 6, 2007 an attack began at 10:00 UTC and lasted twenty-four hours. At least two of the root servers (G-ROOT and L-ROOT) reportedly \"suffered badly\" while two others (F-ROOT and M-ROOT) \"experienced heavy traffic\". The latter two servers largely mitigated the damage by distributing requests to other root server instances with anycast addressing. ICANN published a formal analysis shortly after the event.Due to a lack of detail, speculation about the incident proliferated in the press until details were released.\n\n\n*** November 30, 2015 ***\nDuring two intervals on November 30, 2015 and December 1, 2015, several of the root name servers received up to 5 million queries per second each, receiving valid queries for a single undisclosed domain name and then a different domain the next day. Source addresses were spread throughout IPv4 space, however these may have been spoofed. Some root server networks became saturated, resulting in timeouts, however redundancy among the root servers prevented downstream issues from occurring during this incident.\n\n== Threats ==\n\n\n*** Operation Global Blackout 2012 ***\nOn February 12, 2012, a statement was posted on Pastebin cited to be from Anonymous, threatening an attack on the root servers on March 31, 2012.\"To protest SOPA, Wallstreet, our irresponsible leaders and the beloved bankers who are starving the world for their own selfish needs out of sheer sadistic fun, On March 31, anonymous will shut the Internet down,\" reads the statement. \"Remember, this is a protest, we are not trying to \u2018kill' the Internet, we are only temporarily shutting it down where it hurts the most\u2026It may only last one hour, maybe more, maybe even a few days. No matter what, it will be global. It will be known.\""
    }
  },
  {
    "instruction": "Secure signature creation device\n\n==Introduction==\nA secure signature creation device (SSCD) is a specific type of computer hardware or software that is used in creating an electronic signature. To be put into service as a secure signature creation device, the device must meet the rigorous requirements laid out under Annex II of Regulation (EU) No 910/2014 (eIDAS), where it is referred to as a qualified (electronic) signature creation device (QSCD). Using secure signature creation devices helps in facilitating online business processes that save time and money with transactions made within the public and private sectors.\n\n\n\n== Description ==\nThe minimum requirements that must be met to elevate an electronic signature creation device to the level of a secure signature creation device are provided in Annex II of eIDAS. Through appropriate procedural and technical means, the device must reasonably assure the confidentiality of the data used to create an electronic signature. It further must ensure that the data used to create an electronic signature is unique and only used once. Lastly it shall only allow a qualified trust service provider or certificate authority to create or manage a signatory\u2019s electronic signature data.To ensure security, signature creation data used by the SSCD to create an electronic signature must provide reasonable protection through current technology to prevent forgery or duplication of the signature. The creation data must remain under the sole control of its signatory to prevent unauthorized use. The SSCD itself is prohibited from altering the signature\u2019s accompanying data.When a trust service provider or certificate authority places an SSCD into service, they must securely prepare the device according to Annex II of eIDAS in fully compliance to the following three conditions:\nWhile in use or in storage, the SSCD must remain secure.\nFurther, a reactivation and deactivation of the SSCD must occur under secure conditions.\nAny user activation data, include PIN codes be delivered separately from the SSCD after being prepared securely.\n\n== International security assurance requirements for SSCDs ==\nThe secure signature creation device must also meet the international standard for computer security certification, referred to as the Common Criteria for Information Technology Security Evaluation (ISO/IEC 15408). This standard gives computer system users the ability to specify security requirements via Protection Profiles (PPs) for security functional requirements (SFRs) and security assurance requirements (SARs). The trust service provider or certificate authority is the required to implement the specified requirements and attest to their product\u2019s security attributes. A third-party testing laboratory then evaluates the device to ensure that the level of security is as claimed by the provider.\n\n== Central authentication service ==\nWhen a secure signature creation device is used as part of a central authentication service (CAS), it may act as a CAS server in multi-tier authentication scenarios. The CAS software protocol allows users to be authenticated when signing into a web application.\nThe common scheme for a CAS protocol includes the client\u2019s web browser, an application requesting authentication and the CAS server. When authentication is needed, the application will send a request to the CAS server. The server will then compare the user\u2019s credentials against its database. If the information matches, the CAS will respond that the user has been authenticated.\n\n== Legal implications regarding secure signature creation devices ==\neIDAS has provided a tiered approach to determining the legal implications of electronic signatures. A signature that has been created with a secure signature creation device is considered to have the strongest probative value. A document or message that has been signed with such a device is non-reputable, meaning the signatory cannot deny they are responsible for the creation of the signature.Regulation (EU) No 910/2014 (eIDAS) evolved from Directive 1999/93/EC, the Electronic Signatures Directive. The intent of the directive was to make EU Member States responsible for creating legislation that would allow for the creation of the European Union\u2019s electronic signing system. The eIDAS Regulation required all Member States to follow its specifications for electronic signatures by its effective date of 1 July 2016.\n\nWhat is a secure signature creation device (SSCD) and what are its intended uses?",
    "context": "",
    "output": "A: A secure signature creation device (SSCD) is a specific type of computer hardware or software used for creating electronic signatures. It is designed to facilitate online business processes within the public and private sectors, providing secure and efficient transactions.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is a secure signature creation device (SSCD) and what are its intended uses?",
      "answer": "A secure signature creation device (SSCD) is a specific type of computer hardware or software used for creating electronic signatures. It is designed to facilitate online business processes within the public and private sectors, providing secure and efficient transactions.",
      "context": "Secure signature creation device\n\n==Introduction==\nA secure signature creation device (SSCD) is a specific type of computer hardware or software that is used in creating an electronic signature. To be put into service as a secure signature creation device, the device must meet the rigorous requirements laid out under Annex II of Regulation (EU) No 910/2014 (eIDAS), where it is referred to as a qualified (electronic) signature creation device (QSCD). Using secure signature creation devices helps in facilitating online business processes that save time and money with transactions made within the public and private sectors.\n\n\n\n== Description ==\nThe minimum requirements that must be met to elevate an electronic signature creation device to the level of a secure signature creation device are provided in Annex II of eIDAS. Through appropriate procedural and technical means, the device must reasonably assure the confidentiality of the data used to create an electronic signature. It further must ensure that the data used to create an electronic signature is unique and only used once. Lastly it shall only allow a qualified trust service provider or certificate authority to create or manage a signatory\u2019s electronic signature data.To ensure security, signature creation data used by the SSCD to create an electronic signature must provide reasonable protection through current technology to prevent forgery or duplication of the signature. The creation data must remain under the sole control of its signatory to prevent unauthorized use. The SSCD itself is prohibited from altering the signature\u2019s accompanying data.When a trust service provider or certificate authority places an SSCD into service, they must securely prepare the device according to Annex II of eIDAS in fully compliance to the following three conditions:\nWhile in use or in storage, the SSCD must remain secure.\nFurther, a reactivation and deactivation of the SSCD must occur under secure conditions.\nAny user activation data, include PIN codes be delivered separately from the SSCD after being prepared securely.\n\n== International security assurance requirements for SSCDs ==\nThe secure signature creation device must also meet the international standard for computer security certification, referred to as the Common Criteria for Information Technology Security Evaluation (ISO/IEC 15408). This standard gives computer system users the ability to specify security requirements via Protection Profiles (PPs) for security functional requirements (SFRs) and security assurance requirements (SARs). The trust service provider or certificate authority is the required to implement the specified requirements and attest to their product\u2019s security attributes. A third-party testing laboratory then evaluates the device to ensure that the level of security is as claimed by the provider.\n\n== Central authentication service ==\nWhen a secure signature creation device is used as part of a central authentication service (CAS), it may act as a CAS server in multi-tier authentication scenarios. The CAS software protocol allows users to be authenticated when signing into a web application.\nThe common scheme for a CAS protocol includes the client\u2019s web browser, an application requesting authentication and the CAS server. When authentication is needed, the application will send a request to the CAS server. The server will then compare the user\u2019s credentials against its database. If the information matches, the CAS will respond that the user has been authenticated.\n\n== Legal implications regarding secure signature creation devices ==\neIDAS has provided a tiered approach to determining the legal implications of electronic signatures. A signature that has been created with a secure signature creation device is considered to have the strongest probative value. A document or message that has been signed with such a device is non-reputable, meaning the signatory cannot deny they are responsible for the creation of the signature.Regulation (EU) No 910/2014 (eIDAS) evolved from Directive 1999/93/EC, the Electronic Signatures Directive. The intent of the directive was to make EU Member States responsible for creating legislation that would allow for the creation of the European Union\u2019s electronic signing system. The eIDAS Regulation required all Member States to follow its specifications for electronic signatures by its effective date of 1 July 2016."
    }
  },
  {
    "instruction": "Rainbow Series\n\n==Introduction==\nThe Rainbow Series (sometimes known as the Rainbow Books) is a series of computer security standards and guidelines published by the United States government in the 1980s and 1990s. They were originally published by the U.S. Department of Defense Computer Security Center, and then by the National Computer Security Center.\n\n== Objective ==\nThese standards describe a process of evaluation for trusted systems. In some cases, U.S. government entities (as well as private firms) would require formal validation of computer technology using this process as part of their procurement criteria. Many of these standards have influenced, and have been superseded by, the Common Criteria.\nThe books have nicknames based on the color of its cover. For example, the Trusted Computer System Evaluation Criteria was referred to as \"The Orange Book.\" In the book entitled Applied Cryptography, security expert Bruce Schneier states of NCSC-TG-021 that he \"can't even begin to describe the color of [the] cover\" and that some of the books in this series have \"hideously colored covers.\" He then goes on to describe how to receive a copy of them, saying \"Don't tell them I sent you.\"\n\n== Most significant Rainbow Series books ==\nQ: What was the primary objective of the Rainbow Series standards?",
    "context": "",
    "output": "The primary objective of the Rainbow Series standards was to describe a process of evaluation for trusted systems. These standards were used by U.S. government entities and private firms for formal validation of computer technology as part of their procurement criteria.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was the primary objective of the Rainbow Series standards?",
      "answer": "The primary objective of the Rainbow Series standards was to describe a process of evaluation for trusted systems. These standards were used by U.S. government entities and private firms for formal validation of computer technology as part of their procurement criteria.",
      "context": "Rainbow Series\n\n==Introduction==\nThe Rainbow Series (sometimes known as the Rainbow Books) is a series of computer security standards and guidelines published by the United States government in the 1980s and 1990s. They were originally published by the U.S. Department of Defense Computer Security Center, and then by the National Computer Security Center.\n\n== Objective ==\nThese standards describe a process of evaluation for trusted systems. In some cases, U.S. government entities (as well as private firms) would require formal validation of computer technology using this process as part of their procurement criteria. Many of these standards have influenced, and have been superseded by, the Common Criteria.\nThe books have nicknames based on the color of its cover. For example, the Trusted Computer System Evaluation Criteria was referred to as \"The Orange Book.\" In the book entitled Applied Cryptography, security expert Bruce Schneier states of NCSC-TG-021 that he \"can't even begin to describe the color of [the] cover\" and that some of the books in this series have \"hideously colored covers.\" He then goes on to describe how to receive a copy of them, saying \"Don't tell them I sent you.\"\n\n== Most significant Rainbow Series books =="
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the significance of David Chaum's 1982 dissertation \"Computer Systems Established, Maintained, and Trusted by Mutually Suspicious Groups\"?",
    "context": "",
    "output": "David Chaum's 1982 dissertation is significant because it is the first known proposal for a blockchain protocol. The dissertation proposed all but one element of the blockchain later detailed in the Bitcoin whitepaper, including the use of consensus state between nodes, chaining the history of consensus in blocks, and immutably time-stamping the chained data.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the significance of David Chaum's 1982 dissertation \"Computer Systems Established, Maintained, and Trusted by Mutually Suspicious Groups\"?",
      "answer": "David Chaum's 1982 dissertation is significant because it is the first known proposal for a blockchain protocol. The dissertation proposed all but one element of the blockchain later detailed in the Bitcoin whitepaper, including the use of consensus state between nodes, chaining the history of consensus in blocks, and immutably time-stamping the chained data."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the role of a personal key (PK) in electronic funds transfer systems?",
    "context": "",
    "output": "A personal key (PK) is a cryptographic key stored on a bank card that is used for personal verification processes.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of a personal key (PK) in electronic funds transfer systems?",
      "answer": "A personal key (PK) is a cryptographic key stored on a bank card that is used for personal verification processes."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the difference between local and global optimization in cryptography?",
    "context": "",
    "output": "Local optimization focuses on improving the worst-case behavior of a single round (or two rounds for Feistel ciphers), while global optimization optimizes the worst-case behavior of more than one round, allowing the use of less sophisticated components. This can lead to more efficient and secure cipher designs.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the difference between local and global optimization in cryptography?",
      "answer": "Local optimization focuses on improving the worst-case behavior of a single round (or two rounds for Feistel ciphers), while global optimization optimizes the worst-case behavior of more than one round, allowing the use of less sophisticated components. This can lead to more efficient and secure cipher designs."
    }
  },
  {
    "instruction": "Write an answer to the following question: Is OpenKeychain still being actively developed as of August 2021?",
    "context": "",
    "output": "No, OpenKeychain is no longer actively developed as of August 2021.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Is OpenKeychain still being actively developed as of August 2021?",
      "answer": "No, OpenKeychain is no longer actively developed as of August 2021."
    }
  },
  {
    "instruction": "Write an answer to the following question: What concerns have been expressed regarding the use of hash functions in SEND?",
    "context": "",
    "output": "There have been concerns expressed regarding the use of hash functions in SEND, specifically the use of the SHA-1 hash algorithm in CGA. These concerns, outlined in RFC 6273, stem from the potential for attacks on hash functions used by SEND.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What concerns have been expressed regarding the use of hash functions in SEND?",
      "answer": "There have been concerns expressed regarding the use of hash functions in SEND, specifically the use of the SHA-1 hash algorithm in CGA. These concerns, outlined in RFC 6273, stem from the potential for attacks on hash functions used by SEND."
    }
  },
  {
    "instruction": "Data theft\n\n==Introduction==\nData theft is a growing phenomenon primarily caused by system administrators and office workers with access to technology such as database servers, desktop computers and a growing list of hand-held devices capable of storing digital information, such as USB flash drives, iPods and even digital cameras. Since employees often spend a considerable amount of time developing contacts, confidential, and copyrighted information for the company they work for, they may feel they have some right to the information and are inclined to copy and/or delete part of it when they leave the company, or misuse it while they are still in employment. Information can be sold and bought and then used by criminals and criminal organizations. Alternatively, an employee may choose to deliberately abuse trusted access to information for the purpose of exposing misconduct by the employer. From the perspective of the society, such an act of whistleblowing can be seen as positive and is protected by law in certain situations in some jurisdictions, such as the USA.\nA common scenario is where a sales person makes a copy of the contact database for use in their next job. Typically, this is a clear violation of their terms of employment.\nNotable acts of data theft include those by leaker Chelsea Manning and self-proclaimed whistleblowers Edward Snowden and Herv\u00e9 Falciani.\n\n== Data theft methods ==\n\n\n*** Thumbsucking ***\nThumbsucking, similar to podslurping, is the intentional or undeliberate use of a portable USB mass storage device, such as a USB flash drive (or \"thumbdrive\"), to illicitly download confidential data from a network endpoint.A USB flash drive was allegedly used to remove without authorization highly classified documents about the design of U.S. nuclear weapons from a vault at Los Alamos.The threat of thumbsucking has been amplified for a number of reasons, including the following:\n\nThe storage capacity of portable USB storage devices has increased.\nThe cost of high-capacity portable USB storage devices has decreased.\nNetworks have grown more dispersed, the number of remote network access points has increased and methods of network connection have expanded, increasing the number of vectors for network infiltration.\n\n\n*** Data Leakage ***\nData leak is part of insider attack that accidental or unintentional data loss because of specific circuit stances.\n\n== Investigating data theft ==\nTechniques to investigate data theft include stochastic forensics, digital artifact analysis (especially of USB drive artifacts), and other computer forensics techniques.\n\nBased on the above text, answer a question. How can data leakage occur?",
    "context": "",
    "output": "Data leakage can occur due to a variety of circumstances, including misconfigured systems, human error, or malfunctioning hardware.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can data leakage occur?",
      "answer": "Data leakage can occur due to a variety of circumstances, including misconfigured systems, human error, or malfunctioning hardware.",
      "context": "Data theft\n\n==Introduction==\nData theft is a growing phenomenon primarily caused by system administrators and office workers with access to technology such as database servers, desktop computers and a growing list of hand-held devices capable of storing digital information, such as USB flash drives, iPods and even digital cameras. Since employees often spend a considerable amount of time developing contacts, confidential, and copyrighted information for the company they work for, they may feel they have some right to the information and are inclined to copy and/or delete part of it when they leave the company, or misuse it while they are still in employment. Information can be sold and bought and then used by criminals and criminal organizations. Alternatively, an employee may choose to deliberately abuse trusted access to information for the purpose of exposing misconduct by the employer. From the perspective of the society, such an act of whistleblowing can be seen as positive and is protected by law in certain situations in some jurisdictions, such as the USA.\nA common scenario is where a sales person makes a copy of the contact database for use in their next job. Typically, this is a clear violation of their terms of employment.\nNotable acts of data theft include those by leaker Chelsea Manning and self-proclaimed whistleblowers Edward Snowden and Herv\u00e9 Falciani.\n\n== Data theft methods ==\n\n\n*** Thumbsucking ***\nThumbsucking, similar to podslurping, is the intentional or undeliberate use of a portable USB mass storage device, such as a USB flash drive (or \"thumbdrive\"), to illicitly download confidential data from a network endpoint.A USB flash drive was allegedly used to remove without authorization highly classified documents about the design of U.S. nuclear weapons from a vault at Los Alamos.The threat of thumbsucking has been amplified for a number of reasons, including the following:\n\nThe storage capacity of portable USB storage devices has increased.\nThe cost of high-capacity portable USB storage devices has decreased.\nNetworks have grown more dispersed, the number of remote network access points has increased and methods of network connection have expanded, increasing the number of vectors for network infiltration.\n\n\n*** Data Leakage ***\nData leak is part of insider attack that accidental or unintentional data loss because of specific circuit stances.\n\n== Investigating data theft ==\nTechniques to investigate data theft include stochastic forensics, digital artifact analysis (especially of USB drive artifacts), and other computer forensics techniques."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the purpose of the Multiple Certificate Status Request extension, as specified in RFC 6961?",
    "context": "",
    "output": "The Multiple Certificate Status Request extension, specified in RFC 6961, adds support for sending multiple OCSP responses, addressing the limitation of OCSP stapling supporting only one OCSP response at a time.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the purpose of the Multiple Certificate Status Request extension, as specified in RFC 6961?",
      "answer": "The Multiple Certificate Status Request extension, specified in RFC 6961, adds support for sending multiple OCSP responses, addressing the limitation of OCSP stapling supporting only one OCSP response at a time."
    }
  },
  {
    "instruction": "Answer based on context:\n\nWargame (hacking)\n\n==Introduction==\nIn hacking, a wargame (or war game) is a cyber-security challenge and mind sport in which the competitors must exploit or defend a vulnerability in a system or application, and/or gain or prevent access to a computer system.A wargame usually involves a capture the flag logic, based on pentesting, semantic URL attacks, knowledge-based authentication, password cracking, reverse engineering of software (often JavaScript, C and assembly language), code injection, SQL injections, cross-site scripting, exploits, IP address spoofing, forensics, and other hacking techniques.\n\n== Wargames for preparedness ==\nWargames are also used as a method of cyberwarfare preparedness. The NATO Cooperative Cyber Defence Centre of Excellence (CCDCOE) organizes an annual  event, Locking Shields, which is an international live-fire cyber exercise. The exercise challenges cyber security experts through real-time attacks in fictional scenarios and is used to develop skills in national IT defense strategies.\n\n== Additional applications ==\nWargames can be used to teach the basics of web attacks and web security, giving participants a better understanding of how attackers exploit security vulnerabilities. Wargames are also used as a way to \"stress test\" an organization's response plan and serve as a drill to identify gaps in cyber disaster preparedness.\n\nHow do wargames apply the concept of capture the flag in cybersecurity?",
    "context": "",
    "output": "Wargames often use a capture the flag (CTF) logic, which involves competitors either exploiting or defending vulnerabilities in a system or application to gain or prevent access to a computer system. In this context, \"capture the flag\" refers to obtaining a specific piece of data or controlling a certain aspect of the system, similar to how one might capture a physical flag in a traditional game.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do wargames apply the concept of capture the flag in cybersecurity?",
      "answer": "Wargames often use a capture the flag (CTF) logic, which involves competitors either exploiting or defending vulnerabilities in a system or application to gain or prevent access to a computer system. In this context, \"capture the flag\" refers to obtaining a specific piece of data or controlling a certain aspect of the system, similar to how one might capture a physical flag in a traditional game.",
      "context": "Wargame (hacking)\n\n==Introduction==\nIn hacking, a wargame (or war game) is a cyber-security challenge and mind sport in which the competitors must exploit or defend a vulnerability in a system or application, and/or gain or prevent access to a computer system.A wargame usually involves a capture the flag logic, based on pentesting, semantic URL attacks, knowledge-based authentication, password cracking, reverse engineering of software (often JavaScript, C and assembly language), code injection, SQL injections, cross-site scripting, exploits, IP address spoofing, forensics, and other hacking techniques.\n\n== Wargames for preparedness ==\nWargames are also used as a method of cyberwarfare preparedness. The NATO Cooperative Cyber Defence Centre of Excellence (CCDCOE) organizes an annual  event, Locking Shields, which is an international live-fire cyber exercise. The exercise challenges cyber security experts through real-time attacks in fictional scenarios and is used to develop skills in national IT defense strategies.\n\n== Additional applications ==\nWargames can be used to teach the basics of web attacks and web security, giving participants a better understanding of how attackers exploit security vulnerabilities. Wargames are also used as a way to \"stress test\" an organization's response plan and serve as a drill to identify gaps in cyber disaster preparedness."
    }
  },
  {
    "instruction": "Write an answer to the following question: How is Blom's scheme related to secret sharing?",
    "context": "",
    "output": "Blom's scheme is a form of threshold secret sharing, where a trusted party distributes secret information (secret keys) among a group of participants. Any subset of k or more participants can then reconstruct the shared key, while a smaller subset cannot.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How is Blom's scheme related to secret sharing?",
      "answer": "Blom's scheme is a form of threshold secret sharing, where a trusted party distributes secret information (secret keys) among a group of participants. Any subset of k or more participants can then reconstruct the shared key, while a smaller subset cannot."
    }
  },
  {
    "instruction": "Write an answer to the following question: Why must applications be specifically coded to support Kerberos when using pam_krb5?",
    "context": "",
    "output": "pam_krb5 cannot itself get service tickets, so applications must be specifically coded to support Kerberos to fetch a service ticket for a particular application without prompting the user to enter credentials again.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Why must applications be specifically coded to support Kerberos when using pam_krb5?",
      "answer": "pam_krb5 cannot itself get service tickets, so applications must be specifically coded to support Kerberos to fetch a service ticket for a particular application without prompting the user to enter credentials again."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the role of the Secure Base Action pattern in handling security tasks?",
    "context": "",
    "output": "The Secure Base Action pattern centralizes handling of security tasks in a base action class, ensuring consistent and secure processing of user requests.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of the Secure Base Action pattern in handling security tasks?",
      "answer": "The Secure Base Action pattern centralizes handling of security tasks in a base action class, ensuring consistent and secure processing of user requests."
    }
  },
  {
    "instruction": "Write an answer to the following question: Who is the head of the research group that has expertise in security architectures for information and communication systems?",
    "context": "",
    "output": "Bart Preneel is the head of the Computer Security and Industrial Cryptography (COSIC) research group that has expertise in security architectures for information and communication systems.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Who is the head of the research group that has expertise in security architectures for information and communication systems?",
      "answer": "Bart Preneel is the head of the Computer Security and Industrial Cryptography (COSIC) research group that has expertise in security architectures for information and communication systems."
    }
  },
  {
    "instruction": "Cohen's cryptosystem\n\n==Introduction==\nCohen's cryptosystem is a public-key cryptosystem proposed in 1998 by Bram Cohen.\n\n== Key generation ==\nIn Cohen's cryptosystem, private key is a positive integer \n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n  .\nThe algorithm uses \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n   public-keys \n  \n    \n      \n        \n          w\n          \n            0\n          \n        \n        ,\n        \u2026\n        ,\n        \n          w\n          \n            k\n            \u2212\n            1\n          \n        \n      \n    \n    {\\displaystyle w_{0},\\ldots ,w_{k-1}}\n   defined as follows:\nGenerate \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n   random integers \n  \n    \n      \n        \n          u\n          \n            0\n          \n        \n        ,\n        \u2026\n        ,\n        \n          u\n          \n            k\n            \u2212\n            1\n          \n        \n      \n    \n    {\\displaystyle u_{0},\\ldots ,u_{k-1}}\n   chosen randomly and uniformly between \n  \n    \n      \n        \u2212\n        B\n      \n    \n    {\\displaystyle -B}\n   and \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n  . Where \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n   is some bound.\nLet \n  \n    \n      \n        A\n\n== Encrypting a bit ==\nTo encrypt a bit \n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n   Alice randomly adds \n  \n    \n      \n        \n          \n            k\n            2\n          \n        \n      \n    \n    {\\displaystyle {\\frac {k}{2}}}\n   public keys and multiplies the result by either 1 (if she wishes to send a 0) or by \u22121 (if she wishes to send a 1) to obtain the ciphertext \n  \n    \n      \n        c\n\n== De-cryption ==\nTo de-crypt, Bob computes \n  \n    \n      \n        h\nQuestion: How does Bob decrypt the ciphertext in Cohen's cryptosystem?",
    "context": "",
    "output": "Answer: Bob computes h(c) to decrypt the ciphertext in Cohen's cryptosystem.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does Bob decrypt the ciphertext in Cohen's cryptosystem?",
      "answer": "Bob computes h(c) to decrypt the ciphertext in Cohen's cryptosystem.",
      "context": "Cohen's cryptosystem\n\n==Introduction==\nCohen's cryptosystem is a public-key cryptosystem proposed in 1998 by Bram Cohen.\n\n== Key generation ==\nIn Cohen's cryptosystem, private key is a positive integer \n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n  .\nThe algorithm uses \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n   public-keys \n  \n    \n      \n        \n          w\n          \n            0\n          \n        \n        ,\n        \u2026\n        ,\n        \n          w\n          \n            k\n            \u2212\n            1\n          \n        \n      \n    \n    {\\displaystyle w_{0},\\ldots ,w_{k-1}}\n   defined as follows:\nGenerate \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n   random integers \n  \n    \n      \n        \n          u\n          \n            0\n          \n        \n        ,\n        \u2026\n        ,\n        \n          u\n          \n            k\n            \u2212\n            1\n          \n        \n      \n    \n    {\\displaystyle u_{0},\\ldots ,u_{k-1}}\n   chosen randomly and uniformly between \n  \n    \n      \n        \u2212\n        B\n      \n    \n    {\\displaystyle -B}\n   and \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n  . Where \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n   is some bound.\nLet \n  \n    \n      \n        A\n\n== Encrypting a bit ==\nTo encrypt a bit \n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n   Alice randomly adds \n  \n    \n      \n        \n          \n            k\n            2\n          \n        \n      \n    \n    {\\displaystyle {\\frac {k}{2}}}\n   public keys and multiplies the result by either 1 (if she wishes to send a 0) or by \u22121 (if she wishes to send a 1) to obtain the ciphertext \n  \n    \n      \n        c\n\n== De-cryption ==\nTo de-crypt, Bob computes \n  \n    \n      \n        h"
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the M8 cipher combine the left and right halves of the input block in each round?",
    "context": "",
    "output": "In each round, the left half of the input block undergoes a key-dependent transformation, and is then combined with the right half. Finally, the halves are swapped.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the M8 cipher combine the left and right halves of the input block in each round?",
      "answer": "In each round, the left half of the input block undergoes a key-dependent transformation, and is then combined with the right half. Finally, the halves are swapped."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the DNS server of an ISP respond when it receives a request for an unavailable or unrecognized name?",
    "context": "",
    "output": "When the ISP's DNS server receives a request for a name that is not recognized or unavailable, some ISPs spoof the NX (null) response and return the IP address of a search or advertising page to the client.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the DNS server of an ISP respond when it receives a request for an unavailable or unrecognized name?",
      "answer": "When the ISP's DNS server receives a request for a name that is not recognized or unavailable, some ISPs spoof the NX (null) response and return the IP address of a search or advertising page to the client."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the EC-130J Commando Solo used for in IO?",
    "context": "",
    "output": "The EC-130J Commando Solo is used to conduct psychological operations (PSYOP) and civil affairs broadcast missions in various frequency bands, targeting military or civilian personnel.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the EC-130J Commando Solo used for in IO?",
      "answer": "The EC-130J Commando Solo is used to conduct psychological operations (PSYOP) and civil affairs broadcast missions in various frequency bands, targeting military or civilian personnel."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are the obstacles to implementing Deep Content Inspection in terms of network throughput?",
    "context": "",
    "output": "DCI deals with real-time protocols that increase in complexity and size, making network throughput a key barrier. Solutions must effectively scale up while not introducing latency into the network environment.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are the obstacles to implementing Deep Content Inspection in terms of network throughput?",
      "answer": "DCI deals with real-time protocols that increase in complexity and size, making network throughput a key barrier. Solutions must effectively scale up while not introducing latency into the network environment."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does a mix node process incoming messages?",
    "context": "",
    "output": "When a mix node receives an encrypted message, it uses its secret key to open the outermost layer of encryption. Inside, it finds the recipient's address and an encrypted message bound for that recipient. The random string R1 is discarded.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does a mix node process incoming messages?",
      "answer": "When a mix node receives an encrypted message, it uses its secret key to open the outermost layer of encryption. Inside, it finds the recipient's address and an encrypted message bound for that recipient. The random string R1 is discarded."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the purpose of integrity in signcryption?",
    "context": "",
    "output": "Integrity in signcryption ensures that the recipient can verify that the received message is the original one sent by the sender, preventing any alterations during transmission.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the purpose of integrity in signcryption?",
      "answer": "Integrity in signcryption ensures that the recipient can verify that the received message is the original one sent by the sender, preventing any alterations during transmission."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the same-origin policy typically prevent web-based attacks?",
    "context": "",
    "output": "The same-origin policy is a fundamental security concept in web browsers that helps prevent cross-site scripting (XSS) and other web-based attacks. It restricts client-side scripts from accessing content or resources from a different host than the one that served the script. By comparing domain names, the same-origin policy enforces access control, ensuring that scripts can only interact with resources from the same domain.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the same-origin policy typically prevent web-based attacks?",
      "answer": "The same-origin policy is a fundamental security concept in web browsers that helps prevent cross-site scripting (XSS) and other web-based attacks. It restricts client-side scripts from accessing content or resources from a different host than the one that served the script. By comparing domain names, the same-origin policy enforces access control, ensuring that scripts can only interact with resources from the same domain."
    }
  },
  {
    "instruction": "Context: Needham\u2013Schroeder protocol\n\n==Introduction==\nThe Needham\u2013Schroeder protocol is one of the two key transport protocols intended for use over an insecure network, both proposed by Roger Needham and Michael Schroeder. These are:\n\nThe Needham\u2013Schroeder Symmetric Key Protocol, based on a symmetric encryption algorithm. It forms the basis for the Kerberos protocol. This protocol aims to establish a session key between two parties on a network, typically to protect further communication.\nThe Needham\u2013Schroeder Public-Key Protocol, based on public-key cryptography. This protocol is intended to provide mutual authentication between two parties communicating on a network, but in its proposed form is insecure.\n\n== The symmetric protocol ==\nHere, Alice \n  \n    \n      \n        (\n        A\n        )\n      \n    \n    {\\displaystyle (A)}\n   initiates the communication to Bob \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n  . \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n   is a server trusted by both parties. In the communication:\n\n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n   and \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n   are identities of Alice and Bob respectively\n\n  \n    \n      \n        \n          \n            K\n            \n              A\n              S\n            \n          \n        \n      \n    \n    {\\displaystyle {K_{AS}}}\n   is a symmetric key known only to \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n   and \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  \n\n  \n    \n      \n        \n          \n            K\n            \n              B\n              S\n            \n          \n        \n      \n    \n    {\\displaystyle {K_{BS}}}\n   is a symmetric key known only to \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n   and \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  \n\n  \n    \n      \n        \n          N\n          \n            A\n          \n        \n      \n    \n    {\\displaystyle N_{A}}\n   and \n  \n    \n      \n        \n          N\n          \n            B\n          \n        \n      \n    \n    {\\displaystyle N_{B}}\n   are nonces generated by \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n   and \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n   respectively\n\n  \n    \n      \n        \n          \n            K\n            \n              A\n              B\n            \n          \n        \n      \n    \n    {\\displaystyle {K_{AB}}}\n   is a symmetric, generated key, which will be the session key of the session between \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n   and \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n  The protocol can be specified as follows in security protocol notation:\n\n  \n    \n      \n        A\n        \u2192\n        S\n        :\n        \n          \n          \n            A\n            ,\n            B\n            ,\n            \n              N\n              \n                A\n              \n            \n          \n          \n        \n      \n    \n    {\\displaystyle A\\rightarrow S:\\left.A,B,N_{A}\\right.}\n  \n\nAlice sends a message to the server identifying herself and Bob, telling the server she wants to communicate with Bob.\n  \n    \n      \n        S\n        \u2192\n        A\n        :\n        {\n        \n          N\n          \n            A\n          \n        \n        ,\n        \n          K\n          \n            A\n            B\n          \n        \n        ,\n        B\n        ,\n        {\n        \n          K\n          \n            A\n            B\n          \n        \n        ,\n        A\n        \n          }\n          \n            \n              K\n              \n                B\n                S\n              \n            \n          \n        \n        \n          }\n          \n            \n              K\n              \n                A\n                S\n              \n            \n          \n        \n      \n    \n    {\\displaystyle S\\rightarrow A:\\{N_{A},K_{AB},B,\\{K_{AB},A\\}_{K_{BS}}\\}_{K_{AS}}}\n  \n\nThe server generates \n  \n    \n      \n        \n          \n            K\n            \n              A\n              B\n            \n          \n        \n      \n    \n    {\\displaystyle {K_{AB}}}\n   and sends back to Alice a copy encrypted under \n  \n    \n      \n        \n          \n            K\n            \n              B\n              S\n            \n          \n        \n      \n    \n    {\\displaystyle {K_{BS}}}\n   for Alice to forward to Bob and also a copy for Alice. Since Alice may be requesting keys for several different people, the nonce assures Alice that the message is fresh and that the server is replying to that particular message and the inclusion of Bob's name tells Alice who she is to share this key with.\n  \n    \n      \n        A\n        \u2192\n        B\n        :\n        {\n        \n          K\n          \n            A\n            B\n          \n        \n        ,\n        A\n        \n          }\n          \n            \n              K\n              \n                B\n                S\n              \n            \n          \n        \n      \n    \n    {\\displaystyle A\\rightarrow B:\\{K_{AB},A\\}_{K_{BS}}}\n  \n\nAlice forwards the key to Bob who can decrypt it with the key he shares with the server, thus authenticating the data.\n  \n    \n      \n        B\n        \u2192\n        A\n        :\n        {\n        \n          N\n          \n            B\n          \n        \n        \n          }\n          \n            \n              K\n              \n                A\n                B\n              \n            \n          \n        \n      \n    \n    {\\displaystyle B\\rightarrow A:\\{N_{B}\\}_{K_{AB}}}\n  \n\nBob sends Alice a nonce encrypted under \n  \n    \n      \n        \n          \n            K\n            \n              A\n              B\n            \n          \n        \n      \n    \n    {\\displaystyle {K_{AB}}}\n   to show that he has the key.\n  \n    \n      \n        A\n        \u2192\n        B\n        :\n        {\n        \n          N\n          \n            B\n          \n        \n        \u2212\n        1\n        \n          }\n          \n            \n              K\n              \n                A\n                B\n              \n            \n          \n        \n      \n    \n    {\\displaystyle A\\rightarrow B:\\{N_{B}-1\\}_{K_{AB}}}\n  \n\nAlice performs a simple operation on the nonce, re-encrypts it and sends it back verifying that she is still alive and that she holds the key.\n\n\n*** Attacks on the protocol ***\nThe protocol is vulnerable to a replay attack (as identified by Denning and Sacco). If an attacker uses an older, compromised value for \n  \n    \n      \n        \n          K\n          \n            A\n            B\n          \n        \n      \n    \n    {\\displaystyle K_{AB}}\n  , he can then replay the message \n  \n    \n      \n        {\n        \n          K\n          \n            A\n            B\n          \n        \n        ,\n        A\n        \n          }\n          \n            \n              K\n              \n                B\n                S\n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\{K_{AB},A\\}_{K_{BS}}}\n   to Bob, who will accept it, being unable to tell that the key is not fresh.\n\n\n*** Fixing the attack ***\nThis flaw is fixed in the Kerberos protocol by the inclusion of a timestamp. It can also be fixed with the  use of nonces as described below. At the beginning of the protocol:\n\n  \n    \n      \n        A\n        \u2192\n        B\n        :\n        A\n      \n    \n    {\\displaystyle A\\rightarrow B:A}\n  Alice sends to Bob a request.\n  \n    \n      \n        B\n        \u2192\n        A\n        :\n        {\n        A\n        ,\n        \n          \n            N\n            \n              B\n            \n            \u2032\n          \n        \n        \n          }\n          \n            \n              K\n              \n                B\n                S\n              \n            \n          \n        \n      \n    \n    {\\displaystyle B\\rightarrow A:\\{A,\\mathbf {N_{B}'} \\}_{K_{BS}}}\n  Bob responds with a nonce encrypted under his key with the Server.\n  \n    \n      \n        A\n        \u2192\n        S\n        :\n        \n          \n          \n            A\n            ,\n            B\n            ,\n            \n              N\n              \n                A\n              \n            \n            ,\n            {\n            A\n            ,\n            \n              \n                N\n                \n                  B\n                \n                \u2032\n              \n            \n            \n              }\n              \n                \n                  K\n                  \n                    B\n                    S\n                  \n                \n              \n            \n          \n          \n        \n      \n    \n    {\\displaystyle A\\rightarrow S:\\left.A,B,N_{A},\\{A,\\mathbf {N_{B}'} \\}_{K_{BS}}\\right.}\n  Alice sends a message to the server identifying herself and Bob, telling the server she wants to communicate with Bob.\n  \n    \n      \n        S\n        \u2192\n        A\n        :\n        {\n        \n          N\n          \n            A\n          \n        \n        ,\n        \n          K\n          \n            A\n            B\n          \n        \n        ,\n        B\n        ,\n        {\n        \n          K\n          \n            A\n            B\n          \n        \n        ,\n        A\n        ,\n        \n          \n            N\n            \n              B\n            \n            \u2032\n          \n        \n        \n          }\n          \n            \n              K\n              \n                B\n                S\n              \n            \n          \n        \n        \n          }\n          \n            \n              K\n              \n                A\n                S\n              \n            \n          \n        \n      \n    \n    {\\displaystyle S\\rightarrow A:\\{N_{A},K_{AB},B,\\{K_{AB},A,\\mathbf {N_{B}'} \\}_{K_{BS}}\\}_{K_{AS}}}\n  Note the inclusion of the nonce.The protocol then continues as described through the final three steps as described in the original protocol above. Note that \n  \n    \n      \n        \n          N\n          \n            B\n          \n          \u2032\n        \n      \n    \n    {\\displaystyle N_{B}'}\n   is a different nonce from \n  \n    \n      \n        \n          N\n          \n            B\n          \n        \n      \n    \n    {\\displaystyle N_{B}}\n  . The inclusion of this new nonce prevents the replaying of a compromised version of \n  \n    \n      \n        {\n        \n          K\n          \n            A\n            B\n          \n        \n        ,\n        A\n        \n          }\n          \n            \n              K\n              \n                B\n                S\n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\{K_{AB},A\\}_{K_{BS}}}\n   since such a message would need to be of the form \n  \n    \n      \n        {\n        \n          K\n          \n            A\n            B\n          \n        \n        ,\n        A\n        ,\n        \n          \n            N\n            \n              B\n            \n            \u2032\n          \n        \n        \n          }\n          \n            \n              K\n              \n                B\n                S\n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\{K_{AB},A,\\mathbf {N_{B}'} \\}_{K_{BS}}}\n   which the attacker can't forge since she does not have \n  \n    \n      \n        \n          K\n          \n            B\n            S\n          \n        \n      \n    \n    {\\displaystyle K_{BS}}\n  .\n\n== The public-key protocol ==\nThis assumes the use of a public-key encryption algorithm.\nHere, Alice \n  \n    \n      \n        (\n        A\n        )\n      \n    \n    {\\displaystyle (A)}\n   and Bob \n  \n    \n      \n        (\n        B\n        )\n      \n    \n    {\\displaystyle (B)}\n   use a trusted server \n  \n    \n      \n        (\n        S\n        )\n      \n    \n    {\\displaystyle (S)}\n   to distribute public keys on request. These keys are:\n\n  \n    \n      \n        \n          K\n          \n            P\n            A\n          \n        \n      \n    \n    {\\displaystyle K_{PA}}\n   and \n  \n    \n      \n        \n          K\n          \n            S\n            A\n          \n        \n      \n    \n    {\\displaystyle K_{SA}}\n  , respectively public and private halves of an encryption key-pair belonging to \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n   (\n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n   stands for \"secret key\" here)\n\n  \n    \n      \n        \n          K\n          \n            P\n            B\n          \n        \n      \n    \n    {\\displaystyle K_{PB}}\n   and \n  \n    \n      \n        \n          K\n          \n            S\n            B\n          \n        \n      \n    \n    {\\displaystyle K_{SB}}\n  , similar belonging to \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n  \n\n  \n    \n      \n        \n          K\n          \n            P\n            S\n          \n        \n      \n    \n    {\\displaystyle K_{PS}}\n   and \n  \n    \n      \n        \n          K\n          \n            S\n            S\n          \n        \n      \n    \n    {\\displaystyle K_{SS}}\n  , similar belonging to \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  . (Note that this key-pair will be used for digital signatures, i.e., \n  \n    \n      \n        \n          K\n          \n            S\n            S\n          \n        \n      \n    \n    {\\displaystyle K_{SS}}\n   used for signing a message and \n  \n    \n      \n        \n          K\n          \n            P\n            S\n          \n        \n      \n    \n    {\\displaystyle K_{PS}}\n   used for verification.  \n  \n    \n      \n        \n          K\n          \n            P\n            S\n          \n        \n      \n    \n    {\\displaystyle K_{PS}}\n   must be known to \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n   and \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n   before the protocol starts.)The protocol runs as follows:\n\n  \n    \n      \n        A\n        \u2192\n        S\n        :\n        \n          \n          \n            A\n            ,\n            B\n          \n          \n        \n      \n    \n    {\\displaystyle A\\rightarrow S:\\left.A,B\\right.}\n  \n\n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n   requests \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n  's public keys from \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  \n  \n    \n      \n        S\n        \u2192\n        A\n        :\n        {\n        \n          K\n          \n            P\n            B\n          \n        \n        ,\n        B\n        \n          }\n          \n            \n              K\n              \n                S\n                S\n              \n            \n          \n        \n      \n    \n    {\\displaystyle S\\rightarrow A:\\{K_{PB},B\\}_{K_{SS}}}\n  \n\n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n   responds with public key \n  \n    \n      \n        \n          K\n          \n            P\n            B\n          \n        \n      \n    \n    {\\displaystyle K_{PB}}\n   alongside \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n  's identity, signed by the server for authentication purposes.\n  \n    \n      \n        A\n        \u2192\n        B\n        :\n        {\n        \n          N\n          \n            A\n          \n        \n        ,\n        A\n        \n          }\n          \n            \n              K\n              \n                P\n                B\n              \n            \n          \n        \n      \n    \n    {\\displaystyle A\\rightarrow B:\\{N_{A},A\\}_{K_{PB}}}\n  \n\n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n   chooses a random \n  \n    \n      \n        \n          N\n          \n            A\n          \n        \n      \n    \n    {\\displaystyle N_{A}}\n   and sends it to \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n  .\n  \n    \n      \n        B\n        \u2192\n        S\n        :\n        \n          \n          \n            B\n            ,\n            A\n          \n          \n        \n      \n    \n    {\\displaystyle B\\rightarrow S:\\left.B,A\\right.}\n  \n\n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n   now knows A wants to communicate, so \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n   requests \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  's public keys.\n  \n    \n      \n        S\n        \u2192\n        B\n        :\n        {\n        \n          K\n          \n            P\n            A\n          \n        \n        ,\n        A\n        \n          }\n          \n            \n              K\n              \n                S\n                S\n              \n            \n          \n        \n      \n    \n    {\\displaystyle S\\rightarrow B:\\{K_{PA},A\\}_{K_{SS}}}\n  \n\nServer responds.\n  \n    \n      \n        B\n        \u2192\n        A\n        :\n        {\n        \n          N\n          \n            A\n          \n        \n        ,\n        \n          N\n          \n            B\n          \n        \n        \n          }\n          \n            \n              K\n              \n                P\n                A\n              \n            \n          \n        \n      \n    \n    {\\displaystyle B\\rightarrow A:\\{N_{A},N_{B}\\}_{K_{PA}}}\n  \n\n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n   chooses a random \n  \n    \n      \n        \n          N\n          \n            B\n          \n        \n      \n    \n    {\\displaystyle N_{B}}\n  , and sends it to \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n   along with \n  \n    \n      \n        \n          N\n          \n            A\n          \n        \n      \n    \n    {\\displaystyle N_{A}}\n   to prove ability to decrypt with \n  \n    \n      \n        \n          K\n          \n            S\n            B\n          \n        \n      \n    \n    {\\displaystyle K_{SB}}\n  .\n  \n    \n      \n        A\n        \u2192\n        B\n        :\n        {\n        \n          N\n          \n            B\n          \n        \n        \n          }\n          \n            \n              K\n              \n                P\n                B\n              \n            \n          \n        \n      \n    \n    {\\displaystyle A\\rightarrow B:\\{N_{B}\\}_{K_{PB}}}\n  \n\n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n   confirms \n  \n    \n      \n        \n          N\n          \n            B\n          \n        \n      \n    \n    {\\displaystyle N_{B}}\n   to \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n  , to prove ability to decrypt with \n  \n    \n      \n        \n          K\n          \n            S\n            A\n          \n        \n      \n    \n    {\\displaystyle K_{SA}}\n  At the end of the protocol, \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n   and \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n   know each other's identities, and know both \n  \n    \n      \n        \n          N\n          \n            A\n          \n        \n      \n    \n    {\\displaystyle N_{A}}\n   and \n  \n    \n      \n        \n          N\n          \n            B\n          \n        \n      \n    \n    {\\displaystyle N_{B}}\n  . These nonces are not known to eavesdroppers.\n\n\n*** An attack on the protocol ***\nThis protocol is vulnerable to a man-in-the-middle attack. If an impostor \n  \n    \n      \n        I\n      \n    \n    {\\displaystyle I}\n   can persuade \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n   to initiate a session with them, they can relay the messages to \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n   and convince \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n   that he is communicating with \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  .\nIgnoring the traffic to and from \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  , which is unchanged, the attack runs as follows:\n\n  \n    \n      \n        A\n        \u2192\n        I\n        :\n        {\n        \n          N\n          \n            A\n          \n        \n        ,\n        A\n        \n          }\n          \n            \n              K\n              \n                P\n                I\n              \n            \n          \n        \n      \n    \n    {\\displaystyle A\\rightarrow I:\\{N_{A},A\\}_{K_{PI}}}\n  \n\n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n   sends \n  \n    \n      \n        \n          N\n          \n            A\n          \n        \n      \n    \n    {\\displaystyle N_{A}}\n   to \n  \n    \n      \n        I\n      \n    \n    {\\displaystyle I}\n  , who decrypts the message with \n  \n    \n      \n        \n          K\n          \n            S\n            I\n          \n        \n      \n    \n    {\\displaystyle K_{SI}}\n  \n  \n    \n      \n        I\n        \u2192\n        B\n        :\n        {\n        \n          N\n          \n            A\n          \n        \n        ,\n        A\n        \n          }\n          \n            \n              K\n              \n                P\n                B\n              \n            \n          \n        \n      \n    \n    {\\displaystyle I\\rightarrow B:\\{N_{A},A\\}_{K_{PB}}}\n  \n\n  \n    \n      \n        I\n      \n    \n    {\\displaystyle I}\n   relays the message to \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n  , pretending that \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n   is communicating\n  \n    \n      \n        B\n        \u2192\n        I\n        :\n        {\n        \n          N\n          \n            A\n          \n        \n        ,\n        \n          N\n          \n            B\n          \n        \n        \n          }\n          \n            \n              K\n              \n                P\n                A\n              \n            \n          \n        \n      \n    \n    {\\displaystyle B\\rightarrow I:\\{N_{A},N_{B}\\}_{K_{PA}}}\n  \n\n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n   sends \n  \n    \n      \n        \n          N\n          \n            B\n          \n        \n      \n    \n    {\\displaystyle N_{B}}\n  \n  \n    \n      \n        I\n        \u2192\n        A\n        :\n        {\n        \n          N\n          \n            A\n          \n        \n        ,\n        \n          N\n          \n            B\n          \n        \n        \n          }\n          \n            \n              K\n              \n                P\n                A\n              \n            \n          \n        \n      \n    \n    {\\displaystyle I\\rightarrow A:\\{N_{A},N_{B}\\}_{K_{PA}}}\n  \n\n  \n    \n      \n        I\n      \n    \n    {\\displaystyle I}\n   relays it to \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n  \n    \n      \n        A\n        \u2192\n        I\n        :\n        {\n        \n          N\n          \n            B\n          \n        \n        \n          }\n          \n            \n              K\n              \n                P\n                I\n              \n            \n          \n        \n      \n    \n    {\\displaystyle A\\rightarrow I:\\{N_{B}\\}_{K_{PI}}}\n  \n\n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n   decrypts \n  \n    \n      \n        N\n        B\n      \n    \n    {\\displaystyle NB}\n   and confirms it to \n  \n    \n      \n        I\n      \n    \n    {\\displaystyle I}\n  , who learns it\n  \n    \n      \n        I\n        \u2192\n        B\n        :\n        {\n        \n          N\n          \n            B\n          \n        \n        \n          }\n          \n            \n              K\n              \n                P\n                B\n              \n            \n          \n        \n      \n    \n    {\\displaystyle I\\rightarrow B:\\{N_{B}\\}_{K_{PB}}}\n  \n\n  \n    \n      \n        I\n      \n    \n    {\\displaystyle I}\n   re-encrypts \n  \n    \n      \n        \n          N\n          \n            B\n          \n        \n      \n    \n    {\\displaystyle N_{B}}\n  , and convinces \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n   that she's decrypted itAt the end of the attack, \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n   falsely believes that \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n   is communicating with him, and that \n  \n    \n      \n        \n          N\n          \n            A\n          \n        \n      \n    \n    {\\displaystyle N_{A}}\n   and \n  \n    \n      \n        \n          N\n          \n            B\n          \n        \n      \n    \n    {\\displaystyle N_{B}}\n   are known only to \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n   and \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n  .\nThe following example illustrates the attack. Alice (A) would like to contact her bank (B). We assume that an impostor (I) successfully convinces A that they are the bank. As a consequence A uses the public key of I instead of using the public key of B to encrypt the messages she intends to send to her bank. Therefore, A sends I her nonce encrypted with the public key of I. I decrypts the message using their private key and contacts B sending it the nonce of A encrypted with the public key of B. B has no way to know that this message was actually sent by I. B responds with their own nonce and encrypts the message with the public key of A. Since I is not in possession of the private key of A they have to relay the message to A without knowing the content. A decrypts the message with her private key and respond with the nonce of B encrypted with the public key of I. I decrypts the message using their private key and is now in possession of nonce A and B. Therefore, they can now impersonate the bank and the client respectively.\n\n\n*** Fixing the man-in-the-middle attack ***\nThe attack was first described in a 1995 paper by Gavin Lowe.\nThe paper also describes a fixed version of the scheme, referred to as the Needham\u2013Schroeder\u2013Lowe protocol. The fix involves the modification of message six to include the responder's identity, that is we replace:\n\n  \n    \n      \n        B\n        \u2192\n        A\n        :\n        {\n        \n          N\n          \n            A\n          \n        \n        ,\n        \n          N\n          \n            B\n          \n        \n        \n          }\n          \n            \n              K\n              \n                P\n                A\n              \n            \n          \n        \n      \n    \n    {\\displaystyle B\\rightarrow A:\\{N_{A},N_{B}\\}_{K_{PA}}}\n  \nwith the fixed version:\n\n  \n    \n      \n        B\n        \u2192\n        A\n        :\n        {\n        \n          N\n          \n            A\n          \n        \n        ,\n        \n          N\n          \n            B\n          \n        \n        ,\n        B\n        \n          }\n          \n            \n              K\n              \n                P\n                A\n              \n            \n          \n        \n      \n    \n    {\\displaystyle B\\rightarrow A:\\{N_{A},N_{B},B\\}_{K_{PA}}}\n  \nand the intruder cannot successfully replay the message because A is expecting a message containing the identity of I whereas the message will have identity of B.\n\nQuestion: How does the Needham-Schroeder public-key protocol ensure the integrity of the messages?\n\nAnswer:",
    "context": "",
    "output": "The Needham-Schroeder public-key protocol ensures the integrity of the messages by using digital signatures. The digital signatures are generated using the sender's private key, and can be verified using the sender's public key. This ensures that the messages are intact, and have not been tampered with.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the Needham-Schroeder public-key protocol ensure the integrity of the messages?",
      "answer": "The Needham-Schroeder public-key protocol ensures the integrity of the messages by using digital signatures. The digital signatures are generated using the sender's private key, and can be verified using the sender's public key. This ensures that the messages are intact, and have not been tampered with.",
      "context": "Needham\u2013Schroeder protocol\n\n==Introduction==\nThe Needham\u2013Schroeder protocol is one of the two key transport protocols intended for use over an insecure network, both proposed by Roger Needham and Michael Schroeder. These are:\n\nThe Needham\u2013Schroeder Symmetric Key Protocol, based on a symmetric encryption algorithm. It forms the basis for the Kerberos protocol. This protocol aims to establish a session key between two parties on a network, typically to protect further communication.\nThe Needham\u2013Schroeder Public-Key Protocol, based on public-key cryptography. This protocol is intended to provide mutual authentication between two parties communicating on a network, but in its proposed form is insecure.\n\n== The symmetric protocol ==\nHere, Alice \n  \n    \n      \n        (\n        A\n        )\n      \n    \n    {\\displaystyle (A)}\n   initiates the communication to Bob \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n  . \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n   is a server trusted by both parties. In the communication:\n\n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n   and \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n   are identities of Alice and Bob respectively\n\n  \n    \n      \n        \n          \n            K\n            \n              A\n              S\n            \n          \n        \n      \n    \n    {\\displaystyle {K_{AS}}}\n   is a symmetric key known only to \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n   and \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  \n\n  \n    \n      \n        \n          \n            K\n            \n              B\n              S\n            \n          \n        \n      \n    \n    {\\displaystyle {K_{BS}}}\n   is a symmetric key known only to \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n   and \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  \n\n  \n    \n      \n        \n          N\n          \n            A\n          \n        \n      \n    \n    {\\displaystyle N_{A}}\n   and \n  \n    \n      \n        \n          N\n          \n            B\n          \n        \n      \n    \n    {\\displaystyle N_{B}}\n   are nonces generated by \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n   and \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n   respectively\n\n  \n    \n      \n        \n          \n            K\n            \n              A\n              B\n            \n          \n        \n      \n    \n    {\\displaystyle {K_{AB}}}\n   is a symmetric, generated key, which will be the session key of the session between \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n   and \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n  The protocol can be specified as follows in security protocol notation:\n\n  \n    \n      \n        A\n        \u2192\n        S\n        :\n        \n          \n          \n            A\n            ,\n            B\n            ,\n            \n              N\n              \n                A\n              \n            \n          \n          \n        \n      \n    \n    {\\displaystyle A\\rightarrow S:\\left.A,B,N_{A}\\right.}\n  \n\nAlice sends a message to the server identifying herself and Bob, telling the server she wants to communicate with Bob.\n  \n    \n      \n        S\n        \u2192\n        A\n        :\n        {\n        \n          N\n          \n            A\n          \n        \n        ,\n        \n          K\n          \n            A\n            B\n          \n        \n        ,\n        B\n        ,\n        {\n        \n          K\n          \n            A\n            B\n          \n        \n        ,\n        A\n        \n          }\n          \n            \n              K\n              \n                B\n                S\n              \n            \n          \n        \n        \n          }\n          \n            \n              K\n              \n                A\n                S\n              \n            \n          \n        \n      \n    \n    {\\displaystyle S\\rightarrow A:\\{N_{A},K_{AB},B,\\{K_{AB},A\\}_{K_{BS}}\\}_{K_{AS}}}\n  \n\nThe server generates \n  \n    \n      \n        \n          \n            K\n            \n              A\n              B\n            \n          \n        \n      \n    \n    {\\displaystyle {K_{AB}}}\n   and sends back to Alice a copy encrypted under \n  \n    \n      \n        \n          \n            K\n            \n              B\n              S\n            \n          \n        \n      \n    \n    {\\displaystyle {K_{BS}}}\n   for Alice to forward to Bob and also a copy for Alice. Since Alice may be requesting keys for several different people, the nonce assures Alice that the message is fresh and that the server is replying to that particular message and the inclusion of Bob's name tells Alice who she is to share this key with.\n  \n    \n      \n        A\n        \u2192\n        B\n        :\n        {\n        \n          K\n          \n            A\n            B\n          \n        \n        ,\n        A\n        \n          }\n          \n            \n              K\n              \n                B\n                S\n              \n            \n          \n        \n      \n    \n    {\\displaystyle A\\rightarrow B:\\{K_{AB},A\\}_{K_{BS}}}\n  \n\nAlice forwards the key to Bob who can decrypt it with the key he shares with the server, thus authenticating the data.\n  \n    \n      \n        B\n        \u2192\n        A\n        :\n        {\n        \n          N\n          \n            B\n          \n        \n        \n          }\n          \n            \n              K\n              \n                A\n                B\n              \n            \n          \n        \n      \n    \n    {\\displaystyle B\\rightarrow A:\\{N_{B}\\}_{K_{AB}}}\n  \n\nBob sends Alice a nonce encrypted under \n  \n    \n      \n        \n          \n            K\n            \n              A\n              B\n            \n          \n        \n      \n    \n    {\\displaystyle {K_{AB}}}\n   to show that he has the key.\n  \n    \n      \n        A\n        \u2192\n        B\n        :\n        {\n        \n          N\n          \n            B\n          \n        \n        \u2212\n        1\n        \n          }\n          \n            \n              K\n              \n                A\n                B\n              \n            \n          \n        \n      \n    \n    {\\displaystyle A\\rightarrow B:\\{N_{B}-1\\}_{K_{AB}}}\n  \n\nAlice performs a simple operation on the nonce, re-encrypts it and sends it back verifying that she is still alive and that she holds the key.\n\n\n*** Attacks on the protocol ***\nThe protocol is vulnerable to a replay attack (as identified by Denning and Sacco). If an attacker uses an older, compromised value for \n  \n    \n      \n        \n          K\n          \n            A\n            B\n          \n        \n      \n    \n    {\\displaystyle K_{AB}}\n  , he can then replay the message \n  \n    \n      \n        {\n        \n          K\n          \n            A\n            B\n          \n        \n        ,\n        A\n        \n          }\n          \n            \n              K\n              \n                B\n                S\n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\{K_{AB},A\\}_{K_{BS}}}\n   to Bob, who will accept it, being unable to tell that the key is not fresh.\n\n\n*** Fixing the attack ***\nThis flaw is fixed in the Kerberos protocol by the inclusion of a timestamp. It can also be fixed with the  use of nonces as described below. At the beginning of the protocol:\n\n  \n    \n      \n        A\n        \u2192\n        B\n        :\n        A\n      \n    \n    {\\displaystyle A\\rightarrow B:A}\n  Alice sends to Bob a request.\n  \n    \n      \n        B\n        \u2192\n        A\n        :\n        {\n        A\n        ,\n        \n          \n            N\n            \n              B\n            \n            \u2032\n          \n        \n        \n          }\n          \n            \n              K\n              \n                B\n                S\n              \n            \n          \n        \n      \n    \n    {\\displaystyle B\\rightarrow A:\\{A,\\mathbf {N_{B}'} \\}_{K_{BS}}}\n  Bob responds with a nonce encrypted under his key with the Server.\n  \n    \n      \n        A\n        \u2192\n        S\n        :\n        \n          \n          \n            A\n            ,\n            B\n            ,\n            \n              N\n              \n                A\n              \n            \n            ,\n            {\n            A\n            ,\n            \n              \n                N\n                \n                  B\n                \n                \u2032\n              \n            \n            \n              }\n              \n                \n                  K\n                  \n                    B\n                    S\n                  \n                \n              \n            \n          \n          \n        \n      \n    \n    {\\displaystyle A\\rightarrow S:\\left.A,B,N_{A},\\{A,\\mathbf {N_{B}'} \\}_{K_{BS}}\\right.}\n  Alice sends a message to the server identifying herself and Bob, telling the server she wants to communicate with Bob.\n  \n    \n      \n        S\n        \u2192\n        A\n        :\n        {\n        \n          N\n          \n            A\n          \n        \n        ,\n        \n          K\n          \n            A\n            B\n          \n        \n        ,\n        B\n        ,\n        {\n        \n          K\n          \n            A\n            B\n          \n        \n        ,\n        A\n        ,\n        \n          \n            N\n            \n              B\n            \n            \u2032\n          \n        \n        \n          }\n          \n            \n              K\n              \n                B\n                S\n              \n            \n          \n        \n        \n          }\n          \n            \n              K\n              \n                A\n                S\n              \n            \n          \n        \n      \n    \n    {\\displaystyle S\\rightarrow A:\\{N_{A},K_{AB},B,\\{K_{AB},A,\\mathbf {N_{B}'} \\}_{K_{BS}}\\}_{K_{AS}}}\n  Note the inclusion of the nonce.The protocol then continues as described through the final three steps as described in the original protocol above. Note that \n  \n    \n      \n        \n          N\n          \n            B\n          \n          \u2032\n        \n      \n    \n    {\\displaystyle N_{B}'}\n   is a different nonce from \n  \n    \n      \n        \n          N\n          \n            B\n          \n        \n      \n    \n    {\\displaystyle N_{B}}\n  . The inclusion of this new nonce prevents the replaying of a compromised version of \n  \n    \n      \n        {\n        \n          K\n          \n            A\n            B\n          \n        \n        ,\n        A\n        \n          }\n          \n            \n              K\n              \n                B\n                S\n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\{K_{AB},A\\}_{K_{BS}}}\n   since such a message would need to be of the form \n  \n    \n      \n        {\n        \n          K\n          \n            A\n            B\n          \n        \n        ,\n        A\n        ,\n        \n          \n            N\n            \n              B\n            \n            \u2032\n          \n        \n        \n          }\n          \n            \n              K\n              \n                B\n                S\n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\{K_{AB},A,\\mathbf {N_{B}'} \\}_{K_{BS}}}\n   which the attacker can't forge since she does not have \n  \n    \n      \n        \n          K\n          \n            B\n            S\n          \n        \n      \n    \n    {\\displaystyle K_{BS}}\n  .\n\n== The public-key protocol ==\nThis assumes the use of a public-key encryption algorithm.\nHere, Alice \n  \n    \n      \n        (\n        A\n        )\n      \n    \n    {\\displaystyle (A)}\n   and Bob \n  \n    \n      \n        (\n        B\n        )\n      \n    \n    {\\displaystyle (B)}\n   use a trusted server \n  \n    \n      \n        (\n        S\n        )\n      \n    \n    {\\displaystyle (S)}\n   to distribute public keys on request. These keys are:\n\n  \n    \n      \n        \n          K\n          \n            P\n            A\n          \n        \n      \n    \n    {\\displaystyle K_{PA}}\n   and \n  \n    \n      \n        \n          K\n          \n            S\n            A\n          \n        \n      \n    \n    {\\displaystyle K_{SA}}\n  , respectively public and private halves of an encryption key-pair belonging to \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n   (\n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n   stands for \"secret key\" here)\n\n  \n    \n      \n        \n          K\n          \n            P\n            B\n          \n        \n      \n    \n    {\\displaystyle K_{PB}}\n   and \n  \n    \n      \n        \n          K\n          \n            S\n            B\n          \n        \n      \n    \n    {\\displaystyle K_{SB}}\n  , similar belonging to \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n  \n\n  \n    \n      \n        \n          K\n          \n            P\n            S\n          \n        \n      \n    \n    {\\displaystyle K_{PS}}\n   and \n  \n    \n      \n        \n          K\n          \n            S\n            S\n          \n        \n      \n    \n    {\\displaystyle K_{SS}}\n  , similar belonging to \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  . (Note that this key-pair will be used for digital signatures, i.e., \n  \n    \n      \n        \n          K\n          \n            S\n            S\n          \n        \n      \n    \n    {\\displaystyle K_{SS}}\n   used for signing a message and \n  \n    \n      \n        \n          K\n          \n            P\n            S\n          \n        \n      \n    \n    {\\displaystyle K_{PS}}\n   used for verification.  \n  \n    \n      \n        \n          K\n          \n            P\n            S\n          \n        \n      \n    \n    {\\displaystyle K_{PS}}\n   must be known to \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n   and \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n   before the protocol starts.)The protocol runs as follows:\n\n  \n    \n      \n        A\n        \u2192\n        S\n        :\n        \n          \n          \n            A\n            ,\n            B\n          \n          \n        \n      \n    \n    {\\displaystyle A\\rightarrow S:\\left.A,B\\right.}\n  \n\n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n   requests \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n  's public keys from \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  \n  \n    \n      \n        S\n        \u2192\n        A\n        :\n        {\n        \n          K\n          \n            P\n            B\n          \n        \n        ,\n        B\n        \n          }\n          \n            \n              K\n              \n                S\n                S\n              \n            \n          \n        \n      \n    \n    {\\displaystyle S\\rightarrow A:\\{K_{PB},B\\}_{K_{SS}}}\n  \n\n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n   responds with public key \n  \n    \n      \n        \n          K\n          \n            P\n            B\n          \n        \n      \n    \n    {\\displaystyle K_{PB}}\n   alongside \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n  's identity, signed by the server for authentication purposes.\n  \n    \n      \n        A\n        \u2192\n        B\n        :\n        {\n        \n          N\n          \n            A\n          \n        \n        ,\n        A\n        \n          }\n          \n            \n              K\n              \n                P\n                B\n              \n            \n          \n        \n      \n    \n    {\\displaystyle A\\rightarrow B:\\{N_{A},A\\}_{K_{PB}}}\n  \n\n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n   chooses a random \n  \n    \n      \n        \n          N\n          \n            A\n          \n        \n      \n    \n    {\\displaystyle N_{A}}\n   and sends it to \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n  .\n  \n    \n      \n        B\n        \u2192\n        S\n        :\n        \n          \n          \n            B\n            ,\n            A\n          \n          \n        \n      \n    \n    {\\displaystyle B\\rightarrow S:\\left.B,A\\right.}\n  \n\n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n   now knows A wants to communicate, so \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n   requests \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  's public keys.\n  \n    \n      \n        S\n        \u2192\n        B\n        :\n        {\n        \n          K\n          \n            P\n            A\n          \n        \n        ,\n        A\n        \n          }\n          \n            \n              K\n              \n                S\n                S\n              \n            \n          \n        \n      \n    \n    {\\displaystyle S\\rightarrow B:\\{K_{PA},A\\}_{K_{SS}}}\n  \n\nServer responds.\n  \n    \n      \n        B\n        \u2192\n        A\n        :\n        {\n        \n          N\n          \n            A\n          \n        \n        ,\n        \n          N\n          \n            B\n          \n        \n        \n          }\n          \n            \n              K\n              \n                P\n                A\n              \n            \n          \n        \n      \n    \n    {\\displaystyle B\\rightarrow A:\\{N_{A},N_{B}\\}_{K_{PA}}}\n  \n\n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n   chooses a random \n  \n    \n      \n        \n          N\n          \n            B\n          \n        \n      \n    \n    {\\displaystyle N_{B}}\n  , and sends it to \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n   along with \n  \n    \n      \n        \n          N\n          \n            A\n          \n        \n      \n    \n    {\\displaystyle N_{A}}\n   to prove ability to decrypt with \n  \n    \n      \n        \n          K\n          \n            S\n            B\n          \n        \n      \n    \n    {\\displaystyle K_{SB}}\n  .\n  \n    \n      \n        A\n        \u2192\n        B\n        :\n        {\n        \n          N\n          \n            B\n          \n        \n        \n          }\n          \n            \n              K\n              \n                P\n                B\n              \n            \n          \n        \n      \n    \n    {\\displaystyle A\\rightarrow B:\\{N_{B}\\}_{K_{PB}}}\n  \n\n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n   confirms \n  \n    \n      \n        \n          N\n          \n            B\n          \n        \n      \n    \n    {\\displaystyle N_{B}}\n   to \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n  , to prove ability to decrypt with \n  \n    \n      \n        \n          K\n          \n            S\n            A\n          \n        \n      \n    \n    {\\displaystyle K_{SA}}\n  At the end of the protocol, \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n   and \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n   know each other's identities, and know both \n  \n    \n      \n        \n          N\n          \n            A\n          \n        \n      \n    \n    {\\displaystyle N_{A}}\n   and \n  \n    \n      \n        \n          N\n          \n            B\n          \n        \n      \n    \n    {\\displaystyle N_{B}}\n  . These nonces are not known to eavesdroppers.\n\n\n*** An attack on the protocol ***\nThis protocol is vulnerable to a man-in-the-middle attack. If an impostor \n  \n    \n      \n        I\n      \n    \n    {\\displaystyle I}\n   can persuade \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n   to initiate a session with them, they can relay the messages to \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n   and convince \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n   that he is communicating with \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  .\nIgnoring the traffic to and from \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  , which is unchanged, the attack runs as follows:\n\n  \n    \n      \n        A\n        \u2192\n        I\n        :\n        {\n        \n          N\n          \n            A\n          \n        \n        ,\n        A\n        \n          }\n          \n            \n              K\n              \n                P\n                I\n              \n            \n          \n        \n      \n    \n    {\\displaystyle A\\rightarrow I:\\{N_{A},A\\}_{K_{PI}}}\n  \n\n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n   sends \n  \n    \n      \n        \n          N\n          \n            A\n          \n        \n      \n    \n    {\\displaystyle N_{A}}\n   to \n  \n    \n      \n        I\n      \n    \n    {\\displaystyle I}\n  , who decrypts the message with \n  \n    \n      \n        \n          K\n          \n            S\n            I\n          \n        \n      \n    \n    {\\displaystyle K_{SI}}\n  \n  \n    \n      \n        I\n        \u2192\n        B\n        :\n        {\n        \n          N\n          \n            A\n          \n        \n        ,\n        A\n        \n          }\n          \n            \n              K\n              \n                P\n                B\n              \n            \n          \n        \n      \n    \n    {\\displaystyle I\\rightarrow B:\\{N_{A},A\\}_{K_{PB}}}\n  \n\n  \n    \n      \n        I\n      \n    \n    {\\displaystyle I}\n   relays the message to \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n  , pretending that \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n   is communicating\n  \n    \n      \n        B\n        \u2192\n        I\n        :\n        {\n        \n          N\n          \n            A\n          \n        \n        ,\n        \n          N\n          \n            B\n          \n        \n        \n          }\n          \n            \n              K\n              \n                P\n                A\n              \n            \n          \n        \n      \n    \n    {\\displaystyle B\\rightarrow I:\\{N_{A},N_{B}\\}_{K_{PA}}}\n  \n\n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n   sends \n  \n    \n      \n        \n          N\n          \n            B\n          \n        \n      \n    \n    {\\displaystyle N_{B}}\n  \n  \n    \n      \n        I\n        \u2192\n        A\n        :\n        {\n        \n          N\n          \n            A\n          \n        \n        ,\n        \n          N\n          \n            B\n          \n        \n        \n          }\n          \n            \n              K\n              \n                P\n                A\n              \n            \n          \n        \n      \n    \n    {\\displaystyle I\\rightarrow A:\\{N_{A},N_{B}\\}_{K_{PA}}}\n  \n\n  \n    \n      \n        I\n      \n    \n    {\\displaystyle I}\n   relays it to \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n  \n    \n      \n        A\n        \u2192\n        I\n        :\n        {\n        \n          N\n          \n            B\n          \n        \n        \n          }\n          \n            \n              K\n              \n                P\n                I\n              \n            \n          \n        \n      \n    \n    {\\displaystyle A\\rightarrow I:\\{N_{B}\\}_{K_{PI}}}\n  \n\n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n   decrypts \n  \n    \n      \n        N\n        B\n      \n    \n    {\\displaystyle NB}\n   and confirms it to \n  \n    \n      \n        I\n      \n    \n    {\\displaystyle I}\n  , who learns it\n  \n    \n      \n        I\n        \u2192\n        B\n        :\n        {\n        \n          N\n          \n            B\n          \n        \n        \n          }\n          \n            \n              K\n              \n                P\n                B\n              \n            \n          \n        \n      \n    \n    {\\displaystyle I\\rightarrow B:\\{N_{B}\\}_{K_{PB}}}\n  \n\n  \n    \n      \n        I\n      \n    \n    {\\displaystyle I}\n   re-encrypts \n  \n    \n      \n        \n          N\n          \n            B\n          \n        \n      \n    \n    {\\displaystyle N_{B}}\n  , and convinces \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n   that she's decrypted itAt the end of the attack, \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n   falsely believes that \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n   is communicating with him, and that \n  \n    \n      \n        \n          N\n          \n            A\n          \n        \n      \n    \n    {\\displaystyle N_{A}}\n   and \n  \n    \n      \n        \n          N\n          \n            B\n          \n        \n      \n    \n    {\\displaystyle N_{B}}\n   are known only to \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n   and \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n  .\nThe following example illustrates the attack. Alice (A) would like to contact her bank (B). We assume that an impostor (I) successfully convinces A that they are the bank. As a consequence A uses the public key of I instead of using the public key of B to encrypt the messages she intends to send to her bank. Therefore, A sends I her nonce encrypted with the public key of I. I decrypts the message using their private key and contacts B sending it the nonce of A encrypted with the public key of B. B has no way to know that this message was actually sent by I. B responds with their own nonce and encrypts the message with the public key of A. Since I is not in possession of the private key of A they have to relay the message to A without knowing the content. A decrypts the message with her private key and respond with the nonce of B encrypted with the public key of I. I decrypts the message using their private key and is now in possession of nonce A and B. Therefore, they can now impersonate the bank and the client respectively.\n\n\n*** Fixing the man-in-the-middle attack ***\nThe attack was first described in a 1995 paper by Gavin Lowe.\nThe paper also describes a fixed version of the scheme, referred to as the Needham\u2013Schroeder\u2013Lowe protocol. The fix involves the modification of message six to include the responder's identity, that is we replace:\n\n  \n    \n      \n        B\n        \u2192\n        A\n        :\n        {\n        \n          N\n          \n            A\n          \n        \n        ,\n        \n          N\n          \n            B\n          \n        \n        \n          }\n          \n            \n              K\n              \n                P\n                A\n              \n            \n          \n        \n      \n    \n    {\\displaystyle B\\rightarrow A:\\{N_{A},N_{B}\\}_{K_{PA}}}\n  \nwith the fixed version:\n\n  \n    \n      \n        B\n        \u2192\n        A\n        :\n        {\n        \n          N\n          \n            A\n          \n        \n        ,\n        \n          N\n          \n            B\n          \n        \n        ,\n        B\n        \n          }\n          \n            \n              K\n              \n                P\n                A\n              \n            \n          \n        \n      \n    \n    {\\displaystyle B\\rightarrow A:\\{N_{A},N_{B},B\\}_{K_{PA}}}\n  \nand the intruder cannot successfully replay the message because A is expecting a message containing the identity of I whereas the message will have identity of B."
    }
  },
  {
    "instruction": "Open-source intelligence\n\n==Introduction==\nOpen-source intelligence (OSINT) is the collection and analysis of data gathered from open sources (covert sources and publicly available information [PAI]) to produce actionable intelligence. OSINT is primarily used in national security, law enforcement, and business intelligence functions and is of value to analysts who use non-sensitive intelligence in answering classified, unclassified, or proprietary intelligence requirements across the previous intelligence disciplines.OSINT sources can be divided up into six different categories of information flow:\nMedia, print newspapers, magazines, radio, and television from across and between countries.\nInternet, online publications, blogs, discussion groups, citizen media (i.e. \u2013 cell phone videos, and user created content), YouTube, and other social media websites (i.e. \u2013 Facebook, Twitter, Instagram, etc.). This source also outpaces a variety of other sources due to its timeliness and ease of access.\nPublic government data, public government reports, budgets, hearings, telephone directories, press conferences, websites, and speeches. Although this source comes from an official source they are publicly accessible and may be used openly and freely.\nProfessional and academic publications, information acquired from journals, conferences, symposia, academic papers, dissertations, and theses.\nCommercial data, commercial imagery, financial and industrial assessments, and databases.\nGrey literature, technical reports, preprints, patents, working papers, business documents, unpublished works, and newsletters.OSINT is distinguished from research in that it applies the process of intelligence to create tailored knowledge supportive of a specific decision by a specific individual or group.\n\n== Definition ==\nOSINT is defined in the United States of America by Public Law 109-163 as cited by both the U.S. Director of National Intelligence and the U.S. Department of Defense (DoD), as intelligence \"produced from publicly available information that is collected, exploited, and disseminated in a timely manner to an appropriate audience for the purpose of addressing a specific intelligence requirement.\"  As defined by NATO, OSINT is intelligence \"derived from publicly available information, as well as other unclassified information that has limited public distribution or access.\"According to political scientist Jeffrey T. Richelson, \u201copen source acquisition involves procuring verbal, written, or electronically transmitted material that can be obtained legally. In addition to documents and videos available via the Internet or provided by a human source, others are obtained after U.S. or allied forces have taken control of a facility or site formerly operated by a foreign government or terrorist group.\u201dFormer Assistant Director of Central Intelligence for Analysis Mark M. Lowenthal defines OSINT as \u201cany and all information that can be derived from overt collection: all types of media, government reports and other documents, scientific research and reports, commercial vendors of information, the Internet, and so on. The main qualifiers to open-source information are that it does not require any type of clandestine collection techniques to obtain it and that it must be obtained through means that entirely meet the copyright and commercial requirements of the vendors where applicable.\"\n\n== Risks for practitioners ==\nA main hindrance to practical OSINT is the volume of information it has to deal with (\"information explosion\"). The amount of data being distributed increases at a rate that it becomes difficult to evaluate sources in intelligence analysis. To a small degree the work has sometimes been done by amateur crowd-sourcing.Accredited journalists have some protection in asking questions, and researching for recognized media outlets. Even so, they can be imprisoned, even executed, for seeking out OSINT. Private individuals illegally collecting data for a foreign military or intelligence agency is considered espionage in most countries. Of course, espionage that is not treason (i.e. betraying one's country of citizenship) has been a tool of statecraft since ancient times.\n\n== Professional association ==\nThe OSINT Foundation is a professional association for OSINT practitioners in the United States Intelligence Community. It is open to U.S. Citizens and seeks to raise the prominence of the open-source intelligence discipline.\n\n== Literature ==\nScientific PublicationsArthur S. Hulnick: 'The Dilemma of Open Source Intelligence: Is OSINT Really Intelligence?', pages 229\u2013241, The Oxford Handbook of National Security Intelligence, 2010\nCody Burke: 'Freeing knowledge, telling secrets: Open source intelligence and development', Bond University, May 2007 Archived 2016-08-17 at the Wayback Machine\nFlorian Schaurer, Jan St\u00f6rger: 'The Evolution of Open Source Intelligence', OSINT Report 3/2010, ISN, ETH Z\u00fcrich, October 2010\nAbdelrahman Rashdan: 'The Social Media OSINT Challenge to US Intelligence: Culture Not Gigabytes', in New Media Politics Rethinking Activism and National Security in Cyberspace. Ed. Banu Baybars-Hawks. Cambridge Scholars Publishing, 2015\nHassan, Nihad A. (30 June 2018). Open source intelligence methods and tools : a practical guide to online intelligence. Hijazi, Rami. [United States]. ISBN 978-1-4842-3213-2. OCLC 1043830928.\nRead the text above and answer this question: What is the main qualifier for open-source information?",
    "context": "",
    "output": "The main qualifier for open-source information is that it does not require any type of clandestine collection techniques to obtain it and that it must be obtained through means that entirely meet the copyright and commercial requirements of the vendors where applicable.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the main qualifier for open-source information?",
      "answer": "The main qualifier for open-source information is that it does not require any type of clandestine collection techniques to obtain it and that it must be obtained through means that entirely meet the copyright and commercial requirements of the vendors where applicable.",
      "context": "Open-source intelligence\n\n==Introduction==\nOpen-source intelligence (OSINT) is the collection and analysis of data gathered from open sources (covert sources and publicly available information [PAI]) to produce actionable intelligence. OSINT is primarily used in national security, law enforcement, and business intelligence functions and is of value to analysts who use non-sensitive intelligence in answering classified, unclassified, or proprietary intelligence requirements across the previous intelligence disciplines.OSINT sources can be divided up into six different categories of information flow:\nMedia, print newspapers, magazines, radio, and television from across and between countries.\nInternet, online publications, blogs, discussion groups, citizen media (i.e. \u2013 cell phone videos, and user created content), YouTube, and other social media websites (i.e. \u2013 Facebook, Twitter, Instagram, etc.). This source also outpaces a variety of other sources due to its timeliness and ease of access.\nPublic government data, public government reports, budgets, hearings, telephone directories, press conferences, websites, and speeches. Although this source comes from an official source they are publicly accessible and may be used openly and freely.\nProfessional and academic publications, information acquired from journals, conferences, symposia, academic papers, dissertations, and theses.\nCommercial data, commercial imagery, financial and industrial assessments, and databases.\nGrey literature, technical reports, preprints, patents, working papers, business documents, unpublished works, and newsletters.OSINT is distinguished from research in that it applies the process of intelligence to create tailored knowledge supportive of a specific decision by a specific individual or group.\n\n== Definition ==\nOSINT is defined in the United States of America by Public Law 109-163 as cited by both the U.S. Director of National Intelligence and the U.S. Department of Defense (DoD), as intelligence \"produced from publicly available information that is collected, exploited, and disseminated in a timely manner to an appropriate audience for the purpose of addressing a specific intelligence requirement.\"  As defined by NATO, OSINT is intelligence \"derived from publicly available information, as well as other unclassified information that has limited public distribution or access.\"According to political scientist Jeffrey T. Richelson, \u201copen source acquisition involves procuring verbal, written, or electronically transmitted material that can be obtained legally. In addition to documents and videos available via the Internet or provided by a human source, others are obtained after U.S. or allied forces have taken control of a facility or site formerly operated by a foreign government or terrorist group.\u201dFormer Assistant Director of Central Intelligence for Analysis Mark M. Lowenthal defines OSINT as \u201cany and all information that can be derived from overt collection: all types of media, government reports and other documents, scientific research and reports, commercial vendors of information, the Internet, and so on. The main qualifiers to open-source information are that it does not require any type of clandestine collection techniques to obtain it and that it must be obtained through means that entirely meet the copyright and commercial requirements of the vendors where applicable.\"\n\n== Risks for practitioners ==\nA main hindrance to practical OSINT is the volume of information it has to deal with (\"information explosion\"). The amount of data being distributed increases at a rate that it becomes difficult to evaluate sources in intelligence analysis. To a small degree the work has sometimes been done by amateur crowd-sourcing.Accredited journalists have some protection in asking questions, and researching for recognized media outlets. Even so, they can be imprisoned, even executed, for seeking out OSINT. Private individuals illegally collecting data for a foreign military or intelligence agency is considered espionage in most countries. Of course, espionage that is not treason (i.e. betraying one's country of citizenship) has been a tool of statecraft since ancient times.\n\n== Professional association ==\nThe OSINT Foundation is a professional association for OSINT practitioners in the United States Intelligence Community. It is open to U.S. Citizens and seeks to raise the prominence of the open-source intelligence discipline.\n\n== Literature ==\nScientific PublicationsArthur S. Hulnick: 'The Dilemma of Open Source Intelligence: Is OSINT Really Intelligence?', pages 229\u2013241, The Oxford Handbook of National Security Intelligence, 2010\nCody Burke: 'Freeing knowledge, telling secrets: Open source intelligence and development', Bond University, May 2007 Archived 2016-08-17 at the Wayback Machine\nFlorian Schaurer, Jan St\u00f6rger: 'The Evolution of Open Source Intelligence', OSINT Report 3/2010, ISN, ETH Z\u00fcrich, October 2010\nAbdelrahman Rashdan: 'The Social Media OSINT Challenge to US Intelligence: Culture Not Gigabytes', in New Media Politics Rethinking Activism and National Security in Cyberspace. Ed. Banu Baybars-Hawks. Cambridge Scholars Publishing, 2015\nHassan, Nihad A. (30 June 2018). Open source intelligence methods and tools : a practical guide to online intelligence. Hijazi, Rami. [United States]. ISBN 978-1-4842-3213-2. OCLC 1043830928."
    }
  },
  {
    "instruction": "Write an answer to the following question: How is the Internet Storm Center (ISC) related to the SANS Institute?",
    "context": "",
    "output": "The Internet Storm Center (ISC) is a program of the SANS Technology Institute, which is a branch of the SANS Institute.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How is the Internet Storm Center (ISC) related to the SANS Institute?",
      "answer": "The Internet Storm Center (ISC) is a program of the SANS Technology Institute, which is a branch of the SANS Institute."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does ICMP hole punching allow for the establishment of connectivity between two hosts behind network address translators (NATs)?",
    "context": "",
    "output": "ICMP hole punching exploits the loose acceptance of inbound ICMP Time Exceeded packets by NATs to allow for the passing of information between one or more NATs. This is done by sending an ICMP Time Exceeded packet to the destination NAT, which allows arbitrary data in the packet to reach the destination server, allowing the server to obtain the client's public IP address and other data stored in the packet from the client.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does ICMP hole punching allow for the establishment of connectivity between two hosts behind network address translators (NATs)?",
      "answer": "ICMP hole punching exploits the loose acceptance of inbound ICMP Time Exceeded packets by NATs to allow for the passing of information between one or more NATs. This is done by sending an ICMP Time Exceeded packet to the destination NAT, which allows arbitrary data in the packet to reach the destination server, allowing the server to obtain the client's public IP address and other data stored in the packet from the client."
    }
  },
  {
    "instruction": "Write an answer to the following question: What assumption does quantum cryptography make regarding single-photon sources?",
    "context": "",
    "output": "Quantum cryptography relies on the theoretical assumption of using single-photon sources, which are difficult to construct in reality. Real-world systems commonly use faint laser sources as a medium for information transfer.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What assumption does quantum cryptography make regarding single-photon sources?",
      "answer": "Quantum cryptography relies on the theoretical assumption of using single-photon sources, which are difficult to construct in reality. Real-world systems commonly use faint laser sources as a medium for information transfer."
    }
  },
  {
    "instruction": "Write an answer to the following question: Who are some of Candiru's subsidiaries?",
    "context": "",
    "output": "As of December 2020, Candiru has at least one subsidiary \u2013 Sokoto.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Who are some of Candiru's subsidiaries?",
      "answer": "As of December 2020, Candiru has at least one subsidiary \u2013 Sokoto."
    }
  },
  {
    "instruction": "Answer based on context:\n\nESET NOD32\n\n==Introduction==\nESET NOD32 Antivirus, commonly known as NOD32, is an antivirus software package made by the Slovak company ESET. ESET NOD32 Antivirus is sold in two editions, Home Edition and Business Edition. The Business Edition packages add ESET Remote Administrator allowing for server deployment and management, mirroring of threat signature database updates and the ability to install on Microsoft Windows Server operating systems.\n\n== Development ==\n\n\n*** File Security for Microsoft Windows Server ***\nOn June 1, 2010, the first release candidate for ESET File Security for Microsoft Windows Server v4.3 was made available to the public. This program is an updated version of ESET NOD32 Antivirus Business Edition designed for Microsoft Windows Server operating systems and contains a revised user interface, automatic exclusions for critical directories and files and unspecified optimizations for operation on servers.\n\n\n*** Mobile Security ***\nOn April 22, 2010, ESET Mobile Security for Windows Mobile and Symbian OS went into public beta. The Home Edition was released on September 2, 2010, and on January 20, 2011, the Business Edition went into beta.On April 29, 2011, ESET a beta test version for Android was released. On August 10, 2011, the release candidate was made available.\n\n\n*** NOD32 for Mac OS X and Linux Desktop ***\nOn December 2, 2009, ESET NOD32 Antivirus 4 for Mac OS X Desktop and ESET NOD32 Antivirus 4 for Linux Desktop were released for public testing.  ESET stated the release automatically detects and cleans cross-platform malware, scans archives, automatically scans removable media such as USB flash drives when mounted, performs real-time scanning, provides reports and offers a GUI similar to the Microsoft Windows version. The second beta test versions were released January 9, 2010, and the third on June 10, 2010.On September 13, 2010, ESET released ESET NOD32 Antivirus for Mac OS X Business Edition. and announced a release candidate for ESET Cybersecurity for Mac OS XOn September 24, 2010, ESET released a Release Candidate for ESET Cybersecurity for Mac OS X and on January 21, 2011, ESET released a Release Candidate for ESET NOD32 Antivirus for Linux Desktop\n\n\n*** Smart Security ***\nOn May 5, 2011, ESET released a beta test version of ESET Smart Security 5.0. The beta version adds parental control, a cloud-based file reputation service, gamer mode, HIPS and improvements to its antispam, firewall and removable media control functions. On June 14, 2011, ESET released a release candidate for ESET Smart Security version 5.0.On August 5, 2014, ESET Smart Security version 8.0 public beta 1 was released. It offers enhanced exploit blocking and botnet detection.\n\n== Discontinued products ==\n\n\n*** Mobile Antivirus ***\nESET Mobile Antivirus was aimed at protecting smartphones from viruses, spyware, adware, trojans, worms, rootkits, and other unwanted software.  It also provided antispam filtering for SMS messages. Versions for Windows Mobile and Symbian OS were available. ESET discontinued ESET Mobile Antivirus in January 2011 and provides ESET Mobile Security as a free upgrade to licensed users of ESET Mobile Antivirus.\n\n\n*** NOD32 Antivirus v2.7 and older ***\nOn February 1, 2010, ESET discontinued version 2.7 of NOD32 Antivirus and all previous versions of NOD32 Antivirus. They were removed from the ESET website, including product pages and e-Store. Version 2.7 was the last version supporting Microsoft 95/98/ME and Novell NetWare operating systems.\nVirus signature database updates and customer support was discontinued on February 1, 2012.\n\n== Technical information ==\nOn a network, NOD32 clients can update from a central \"mirror server\" on the network.\n\nWhen was the first version of ESET NOD32 Antivirus for Mac OS X Desktop and ESET NOD32 Antivirus for Linux Desktop released for public testing?",
    "context": "",
    "output": "ESET NOD32 Antivirus 4 for Mac OS X Desktop and ESET NOD32 Antivirus 4 for Linux Desktop were released for public testing on December 2, 2009.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "When was the first version of ESET NOD32 Antivirus for Mac OS X Desktop and ESET NOD32 Antivirus for Linux Desktop released for public testing?",
      "answer": "ESET NOD32 Antivirus 4 for Mac OS X Desktop and ESET NOD32 Antivirus 4 for Linux Desktop were released for public testing on December 2, 2009.",
      "context": "ESET NOD32\n\n==Introduction==\nESET NOD32 Antivirus, commonly known as NOD32, is an antivirus software package made by the Slovak company ESET. ESET NOD32 Antivirus is sold in two editions, Home Edition and Business Edition. The Business Edition packages add ESET Remote Administrator allowing for server deployment and management, mirroring of threat signature database updates and the ability to install on Microsoft Windows Server operating systems.\n\n== Development ==\n\n\n*** File Security for Microsoft Windows Server ***\nOn June 1, 2010, the first release candidate for ESET File Security for Microsoft Windows Server v4.3 was made available to the public. This program is an updated version of ESET NOD32 Antivirus Business Edition designed for Microsoft Windows Server operating systems and contains a revised user interface, automatic exclusions for critical directories and files and unspecified optimizations for operation on servers.\n\n\n*** Mobile Security ***\nOn April 22, 2010, ESET Mobile Security for Windows Mobile and Symbian OS went into public beta. The Home Edition was released on September 2, 2010, and on January 20, 2011, the Business Edition went into beta.On April 29, 2011, ESET a beta test version for Android was released. On August 10, 2011, the release candidate was made available.\n\n\n*** NOD32 for Mac OS X and Linux Desktop ***\nOn December 2, 2009, ESET NOD32 Antivirus 4 for Mac OS X Desktop and ESET NOD32 Antivirus 4 for Linux Desktop were released for public testing.  ESET stated the release automatically detects and cleans cross-platform malware, scans archives, automatically scans removable media such as USB flash drives when mounted, performs real-time scanning, provides reports and offers a GUI similar to the Microsoft Windows version. The second beta test versions were released January 9, 2010, and the third on June 10, 2010.On September 13, 2010, ESET released ESET NOD32 Antivirus for Mac OS X Business Edition. and announced a release candidate for ESET Cybersecurity for Mac OS XOn September 24, 2010, ESET released a Release Candidate for ESET Cybersecurity for Mac OS X and on January 21, 2011, ESET released a Release Candidate for ESET NOD32 Antivirus for Linux Desktop\n\n\n*** Smart Security ***\nOn May 5, 2011, ESET released a beta test version of ESET Smart Security 5.0. The beta version adds parental control, a cloud-based file reputation service, gamer mode, HIPS and improvements to its antispam, firewall and removable media control functions. On June 14, 2011, ESET released a release candidate for ESET Smart Security version 5.0.On August 5, 2014, ESET Smart Security version 8.0 public beta 1 was released. It offers enhanced exploit blocking and botnet detection.\n\n== Discontinued products ==\n\n\n*** Mobile Antivirus ***\nESET Mobile Antivirus was aimed at protecting smartphones from viruses, spyware, adware, trojans, worms, rootkits, and other unwanted software.  It also provided antispam filtering for SMS messages. Versions for Windows Mobile and Symbian OS were available. ESET discontinued ESET Mobile Antivirus in January 2011 and provides ESET Mobile Security as a free upgrade to licensed users of ESET Mobile Antivirus.\n\n\n*** NOD32 Antivirus v2.7 and older ***\nOn February 1, 2010, ESET discontinued version 2.7 of NOD32 Antivirus and all previous versions of NOD32 Antivirus. They were removed from the ESET website, including product pages and e-Store. Version 2.7 was the last version supporting Microsoft 95/98/ME and Novell NetWare operating systems.\nVirus signature database updates and customer support was discontinued on February 1, 2012.\n\n== Technical information ==\nOn a network, NOD32 clients can update from a central \"mirror server\" on the network."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the purpose of the Exploit Database and how is it used in penetration testing?",
    "context": "",
    "output": "The Exploit Database is an archive of vulnerable software and exploits that have been made public by the information security community. It is designed to help penetration testers test small projects easily by sharing information with each other and contains proof-of-concepts (POC) to help information security professionals learn new exploits variations.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the purpose of the Exploit Database and how is it used in penetration testing?",
      "answer": "The Exploit Database is an archive of vulnerable software and exploits that have been made public by the information security community. It is designed to help penetration testers test small projects easily by sharing information with each other and contains proof-of-concepts (POC) to help information security professionals learn new exploits variations."
    }
  },
  {
    "instruction": "Nothing-up-my-sleeve number\n\n==Introduction==\nIn cryptography, nothing-up-my-sleeve numbers are any numbers which, by their construction, are above suspicion of hidden properties. They are used in creating cryptographic functions such as hashes and ciphers.  These algorithms often need randomized constants for mixing or initialization purposes. The cryptographer may wish to pick these values in a way that demonstrates the constants were not selected for a nefarious purpose, for example, to create a backdoor to the algorithm. These fears can be allayed by using numbers created in a way that leaves little room for adjustment.  An example would be the use of initial digits from the number \u03c0 as the constants. Using digits of \u03c0 millions of places after the decimal point would not be considered trustworthy because the algorithm designer might have selected that starting point because it created a secret weakness the designer could later exploit.\nDigits in the positional representations of real numbers such as \u03c0, e, and irrational roots are believed to appear with equal frequency (see normal number). Such numbers can be viewed as the opposite extreme of Chaitin\u2013Kolmogorov random numbers in that they appear random but have very low information entropy. Their use is motivated by early controversy over the U.S. Government's 1975 Data Encryption Standard, which came under criticism because no explanation was supplied for the constants used in its S-box (though they were later found to have been carefully selected to protect against the then-classified technique of differential cryptanalysis). Thus a need was felt for a more transparent way to generate constants used in cryptography.\n\"Nothing up my sleeve\" is a phrase associated with magicians, who sometimes preface a magic trick by holding open their sleeves to show they have no objects hidden inside.\n\n== Examples ==\nRon Rivest used the trigonometric sine function to generate constants for the widely used MD5 hash.\nThe U.S. National Security Agency used the square roots of small integers to produce the constants used in its \"Secure Hash Algorithm\" SHA-1. The SHA-2 functions use the square roots and cube roots of small primes. SHA-1 also uses 0123456789ABCDEFFEDCBA9876543210F0E1D2C3 as its initial hash value.\nThe Blowfish encryption algorithm uses the binary representation of \u03c0 (without the initial 3) to initialize its key schedule.\nRFC 3526 describes prime numbers for internet key exchange that are also generated from \u03c0.\nThe S-box of the NewDES cipher is derived from the United States Declaration of Independence.\nThe AES candidate DFC derives all of its arbitrary constants, including all entries of the S-box, from the binary expansion of e.\nThe ARIA key schedule uses the binary expansion of 1/\u03c0.\nThe key schedule of the RC5 cipher uses binary digits from both e and the golden ratio.\nMultiple ciphers including TEA and Red Pike use 2654435769 or 0x9e3779b9 which is \u230a232/\u03d5\u230b, where \u03d5 is the golden ratio.\nThe BLAKE hash function, a finalist in the SHA-3 competition, uses a table of 16 constant words which are the leading 512 or 1024 bits of the fractional part of \u03c0.\nThe key schedule of the KASUMI cipher uses 0x123456789ABCDEFFEDCBA9876543210 to derive the modified key.\nThe Salsa20 family of ciphers use the ASCII string \"expand 32-byte k\" as constants in its block initialization process.\nBcrypt uses the string \"OrpheanBeholderScryDoubt\" as an initialization string\n\n== Counterexamples ==\nThe Streebog hash function S-box was claimed to be generated randomly, but was reverse-engineered and proven to be generated algorithmically with some \"puzzling\" weaknesses.\nThe Data Encryption Standard (DES) has constants that were given out by NSA. They turned out to be far from random, but instead made the algorithm resilient against differential cryptanalysis, a method not publicly known at the time.\nDual_EC_DRBG, a NIST-recommended cryptographic pseudo-random bit generator, came under criticism in 2007 because constants recommended for use in the algorithm could have been selected in a way that would permit their author to predict future outputs given a sample of past generated values. In September 2013 The New York Times wrote that \"internal memos leaked by a former NSA contractor, Edward Snowden, suggest that the NSA generated one of the random number generators used in a 2006 NIST standard\u2014called the Dual EC DRBG standard\u2014which contains a back door for the NSA.\"\nP curves are standardized by NIST for elliptic curve cryptography. The coefficients in these curves are generated by hashing unexplained random seeds, such as:\nP-224: bd713447 99d5c7fc dc45b59f a3b9ab8f 6a948bc5.\nP-256: c49d3608 86e70493 6a6678e1 139d26b7 819f7e90.\nP-384: a335926a a319a27a 1d00896a 6773a482 7acdac73.Although not directly related, after the backdoor in Dual_EC_DRBG had been exposed, suspicious aspects of the NIST's P curve constants led to concerns that the NSA had chosen values that gave them an advantage in finding private keys. Since then, many protocols and programs started to use Curve25519 as an alternative to NIST P-256 curve.\n\nI no longer trust the constants. I believe the NSA has manipulated them through their relationships with industry.\n\n== Limitations ==\nBernstein and coauthors demonstrate that use of nothing-up-my-sleeve numbers as the starting point in a complex procedure for generating cryptographic objects, such as elliptic curves, may not be sufficient to prevent insertion of back doors. For example, many candidates of seemingly harmless and \"uninteresting\" simple mathematical constants exist, such as \u03c0, e, Euler gamma, \u221a2, \u221a3, \u221a5, \u221a7, log(2), (1 + \u221a5)/2, \u03b6(3), \u03b6(5), sin(1), sin(2), cos(1), cos(2), tan(1), or tan(2). For these constants, there also exists several different binary representations to choose. If a constant is used as a random seed, a large number of hash function candidates also exist for selection, such as SHA-1, SHA-256, SHA-384, SHA-512, SHA-512/256, SHA3-256, or SHA3-384.\nIf there are enough adjustable parameters in the object selection procedure, combinatorial explosion ensures that the universe of possible design choices and of apparently simple constants can be large enough so that an automatic search of the possibilities allows construction of an object with desired backdoor properties.\n\n== Footnotes ==\n\nBased on the above text, answer a question. What is the significance of the use of the binary representation of \u03c0 in the Blowfish encryption algorithm?",
    "context": "",
    "output": "The binary representation of \u03c0 is used in the Blowfish encryption algorithm to initialize its key schedule. This use demonstrates that the constants were not selected for a nefarious purpose.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the significance of the use of the binary representation of \u03c0 in the Blowfish encryption algorithm?",
      "answer": "The binary representation of \u03c0 is used in the Blowfish encryption algorithm to initialize its key schedule. This use demonstrates that the constants were not selected for a nefarious purpose.",
      "context": "Nothing-up-my-sleeve number\n\n==Introduction==\nIn cryptography, nothing-up-my-sleeve numbers are any numbers which, by their construction, are above suspicion of hidden properties. They are used in creating cryptographic functions such as hashes and ciphers.  These algorithms often need randomized constants for mixing or initialization purposes. The cryptographer may wish to pick these values in a way that demonstrates the constants were not selected for a nefarious purpose, for example, to create a backdoor to the algorithm. These fears can be allayed by using numbers created in a way that leaves little room for adjustment.  An example would be the use of initial digits from the number \u03c0 as the constants. Using digits of \u03c0 millions of places after the decimal point would not be considered trustworthy because the algorithm designer might have selected that starting point because it created a secret weakness the designer could later exploit.\nDigits in the positional representations of real numbers such as \u03c0, e, and irrational roots are believed to appear with equal frequency (see normal number). Such numbers can be viewed as the opposite extreme of Chaitin\u2013Kolmogorov random numbers in that they appear random but have very low information entropy. Their use is motivated by early controversy over the U.S. Government's 1975 Data Encryption Standard, which came under criticism because no explanation was supplied for the constants used in its S-box (though they were later found to have been carefully selected to protect against the then-classified technique of differential cryptanalysis). Thus a need was felt for a more transparent way to generate constants used in cryptography.\n\"Nothing up my sleeve\" is a phrase associated with magicians, who sometimes preface a magic trick by holding open their sleeves to show they have no objects hidden inside.\n\n== Examples ==\nRon Rivest used the trigonometric sine function to generate constants for the widely used MD5 hash.\nThe U.S. National Security Agency used the square roots of small integers to produce the constants used in its \"Secure Hash Algorithm\" SHA-1. The SHA-2 functions use the square roots and cube roots of small primes. SHA-1 also uses 0123456789ABCDEFFEDCBA9876543210F0E1D2C3 as its initial hash value.\nThe Blowfish encryption algorithm uses the binary representation of \u03c0 (without the initial 3) to initialize its key schedule.\nRFC 3526 describes prime numbers for internet key exchange that are also generated from \u03c0.\nThe S-box of the NewDES cipher is derived from the United States Declaration of Independence.\nThe AES candidate DFC derives all of its arbitrary constants, including all entries of the S-box, from the binary expansion of e.\nThe ARIA key schedule uses the binary expansion of 1/\u03c0.\nThe key schedule of the RC5 cipher uses binary digits from both e and the golden ratio.\nMultiple ciphers including TEA and Red Pike use 2654435769 or 0x9e3779b9 which is \u230a232/\u03d5\u230b, where \u03d5 is the golden ratio.\nThe BLAKE hash function, a finalist in the SHA-3 competition, uses a table of 16 constant words which are the leading 512 or 1024 bits of the fractional part of \u03c0.\nThe key schedule of the KASUMI cipher uses 0x123456789ABCDEFFEDCBA9876543210 to derive the modified key.\nThe Salsa20 family of ciphers use the ASCII string \"expand 32-byte k\" as constants in its block initialization process.\nBcrypt uses the string \"OrpheanBeholderScryDoubt\" as an initialization string\n\n== Counterexamples ==\nThe Streebog hash function S-box was claimed to be generated randomly, but was reverse-engineered and proven to be generated algorithmically with some \"puzzling\" weaknesses.\nThe Data Encryption Standard (DES) has constants that were given out by NSA. They turned out to be far from random, but instead made the algorithm resilient against differential cryptanalysis, a method not publicly known at the time.\nDual_EC_DRBG, a NIST-recommended cryptographic pseudo-random bit generator, came under criticism in 2007 because constants recommended for use in the algorithm could have been selected in a way that would permit their author to predict future outputs given a sample of past generated values. In September 2013 The New York Times wrote that \"internal memos leaked by a former NSA contractor, Edward Snowden, suggest that the NSA generated one of the random number generators used in a 2006 NIST standard\u2014called the Dual EC DRBG standard\u2014which contains a back door for the NSA.\"\nP curves are standardized by NIST for elliptic curve cryptography. The coefficients in these curves are generated by hashing unexplained random seeds, such as:\nP-224: bd713447 99d5c7fc dc45b59f a3b9ab8f 6a948bc5.\nP-256: c49d3608 86e70493 6a6678e1 139d26b7 819f7e90.\nP-384: a335926a a319a27a 1d00896a 6773a482 7acdac73.Although not directly related, after the backdoor in Dual_EC_DRBG had been exposed, suspicious aspects of the NIST's P curve constants led to concerns that the NSA had chosen values that gave them an advantage in finding private keys. Since then, many protocols and programs started to use Curve25519 as an alternative to NIST P-256 curve.\n\nI no longer trust the constants. I believe the NSA has manipulated them through their relationships with industry.\n\n== Limitations ==\nBernstein and coauthors demonstrate that use of nothing-up-my-sleeve numbers as the starting point in a complex procedure for generating cryptographic objects, such as elliptic curves, may not be sufficient to prevent insertion of back doors. For example, many candidates of seemingly harmless and \"uninteresting\" simple mathematical constants exist, such as \u03c0, e, Euler gamma, \u221a2, \u221a3, \u221a5, \u221a7, log(2), (1 + \u221a5)/2, \u03b6(3), \u03b6(5), sin(1), sin(2), cos(1), cos(2), tan(1), or tan(2). For these constants, there also exists several different binary representations to choose. If a constant is used as a random seed, a large number of hash function candidates also exist for selection, such as SHA-1, SHA-256, SHA-384, SHA-512, SHA-512/256, SHA3-256, or SHA3-384.\nIf there are enough adjustable parameters in the object selection procedure, combinatorial explosion ensures that the universe of possible design choices and of apparently simple constants can be large enough so that an automatic search of the possibilities allows construction of an object with desired backdoor properties.\n\n== Footnotes =="
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the background of Gary McKinnon and what is he accused of?",
    "context": "",
    "output": "Gary McKinnon is a Scottish systems administrator and hacker, born on 10 February 1966. He was accused in 2002 of perpetrating the \"biggest military computer hack of all time\", where he allegedly hacked into 97 United States military and NASA computers over a 13-month period. He is accused of causing damage to these systems, deleting critical files, and copying data onto his own computer. The cost of tracking and correcting the problems caused by his actions was over $700,000.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the background of Gary McKinnon and what is he accused of?",
      "answer": "Gary McKinnon is a Scottish systems administrator and hacker, born on 10 February 1966. He was accused in 2002 of perpetrating the \"biggest military computer hack of all time\", where he allegedly hacked into 97 United States military and NASA computers over a 13-month period. He is accused of causing damage to these systems, deleting critical files, and copying data onto his own computer. The cost of tracking and correcting the problems caused by his actions was over $700,000."
    }
  },
  {
    "instruction": "Write an answer to the following question: What was the maximum duration of a license available for purchase on Exclu?",
    "context": "",
    "output": "The maximum duration of a license available for purchase on Exclu was six months.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was the maximum duration of a license available for purchase on Exclu?",
      "answer": "The maximum duration of a license available for purchase on Exclu was six months."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the significance of the check digit characters in alphanumeric strings calculated by the ISO/IEC 7064 standard?",
    "context": "",
    "output": "The check digit characters calculated by the ISO/IEC 7064 standard for alphanumeric strings serve as a mechanism for error detection and data integrity assurance, making them critical for the security and accuracy of the data.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the significance of the check digit characters in alphanumeric strings calculated by the ISO/IEC 7064 standard?",
      "answer": "The check digit characters calculated by the ISO/IEC 7064 standard for alphanumeric strings serve as a mechanism for error detection and data integrity assurance, making them critical for the security and accuracy of the data."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the significance of the zero trust security model used by dope.swg?",
    "context": "",
    "output": "The zero trust security model is a security concept that requires strict identity verification for every user and device trying to access resources on a network, regardless of whether they are within or outside the network perimeter. This helps prevent unauthorized access and data breaches.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the significance of the zero trust security model used by dope.swg?",
      "answer": "The zero trust security model is a security concept that requires strict identity verification for every user and device trying to access resources on a network, regardless of whether they are within or outside the network perimeter. This helps prevent unauthorized access and data breaches."
    }
  },
  {
    "instruction": "Context: Anonymous blog\n\n==Introduction==\nAn anonymous blog is a blog without any acknowledged author or contributor. Anonymous bloggers may achieve anonymity through the simple use of a pseudonym, or through more sophisticated techniques such as layered encryption routing, manipulation of post dates, or posting only from publicly accessible computers. Motivations for posting anonymously include a desire for privacy or fear of retribution by an employer (e.g., in whistleblower cases), a government (in countries that monitor or censor online communication), or another group.\n\n\n\n== Deanonymizing techniques ==\nFundamentally, deanonymization can be divided into two categories:\n\nSocial correlation compares known details about a person's life with the contents of an anonymous blog to look for similarities. If the author does not attempt to conceal their identity, social correlation is a very straightforward procedure: a simple correlation between the \"anonymous\" blogger's name, profession, lifestyle, etc., and the known person. Even if an author generally attempts to conceal their identity (by not providing their name, location, etc.), the blog can be deanonymized by correlating seemingly innocuous, general details.\nTechnical identification determines the author's identity through the blog's technical details. In extreme cases, technical identification entails looking at the server logs, the Internet provider logs, and payment information associated with the domain name.These techniques may be used together. The order of techniques employed typically escalates from the social correlation techniques, which do not require the compliance of any outside authorities (e.g., Internet providers, server providers, etc.), to more technical identification.\n\n== Types ==\nJust as a blog can be on any subject, so can an anonymous blog. Most fall into the following major categories:\n\nPolitical: A commentary on the political situation within a country, where being open may risk prosecution. Anonymous blogging can also add power to a political debate, such as in 2008 when blogger Eduwonkette, later revealed as Columbia University sociology graduate student Jennifer Jennings, successfully questioned New York Mayor Michael Bloomberg's takeover of New York schools.\nRevolutionary and counter-revolutionary: These can either be inspiring activity or counter activity, often against a violent state apparatus. For example, Salam Pax, the Baghdad blogger, wrote for The Guardian newspaper under a pseudonym that he could shed only when Saddam Hussein no longer ruled in Iraq. Similar bloggers appeared during the Arab Spring.\nDissident:  Dissident blogs may document life under an oppressive or secretive regime, while not actively promoting or inspiring revolutionary or counter-revolutionary action. Mosul Eye, which has described life under ISIL occupation in Mosul, Iraq, has been called one of the few reliable sources of information on life inside the city since it began in June 2014.\nReligious: Views and comments about religious view points and issues, perhaps questioning some written standpoints.\nWhistleblower: The whistleblower blog is a modern-day twist on the classical \"insider spotting illegality\" theme. This can cover all sectors or issues. Among the most notable is that by the Irish Red Cross head of the international department Noel Wardick, who highlighted that \u20ac162,000 in donations to the 2004 Indian Ocean earthquake and tsunami had sat in an account for over three years. After spending over \u20ac140,000 on private investigators and legal expenses to find the whistle blower, including court orders to obtain Wardick's identity from UPC and Google, the IRC disciplined and later dismissed Wardick. In 2010, an internal enquiry into Wardick's allegations found other such bank accounts, and proposals to overhaul the IRC's management were discussed in the D\u00e1il on 15 December. Questions were answered by Tony Killeen, then the Minister of Defence. Wardick later successfully sued the IRC for unfair dismissal.\nCompany insider: A company employee or insider reports on company operations and issues from within the organisation. The most famous is probably the Dooce.com blogger Heather Armstrong, who was fired for writing satirical accounts of her experiences at a dot-com startup on her personal blog, dooce.com.\nCommunity pressure: Written by a citizen of an area, on a particular subject, to bring about a change. In 2007, reporter and blogger Mike Stark came out in support of anonymous blogger Spocko, who was trying to bring what he called \"violent commentary\" on San Francisco area radio station KSFO to the attention of its advertisers.\nExperience/Customer Service: Most experience blogs focus on personal insights or views of customer service, frequently with dissatisfaction. Most anonymous experience blogs are written anonymously as they allow the customer/user to keep experiencing and using the service, and reporting/blogging, while nudging at a defined and appropriate level against the target organisation. Among these are Sarah Wu's/Mrs Q. \"Fed Up With Lunch\" blog, a chronicle of her experience as an adult eating Chicago area high school lunch every day for a year, which has now been turned into a book.\nPersonal: The personal blog strays into personal life in ways that allow more risk taking and open in terms of detail. Hence, many of these blogs are sexual in nature, although many also exist for those with health problems and disabilities and how they see the world and cope with its challenges. Some of the latest personal blogs are seen by many as extended group therapy, covering issues including weight loss.Recently, anonymous blogging has moved into a more aggressive and active style, with organized crime groups such as the Mafia using anonymous blogs against mayors and local administrators in Italy.\n\n== How online identity is determined ==\n\n\n*** IP addresses ***\nAn IP address is a unique numerical label assigned to a computer connected to a computer network that uses the Internet Protocol for communication. The most popular implementation of the Internet Protocol would be the Internet (capitalized, to differentiate it from smaller internetworks). Internet Service Providers (ISPs) are allocated chunks of IP addresses by a Regional Internet registry, which they then assign to customers. However, ISPs do not have enough addresses to give the customers their own address. Instead, DHCP is used; a customer's device (typically a modem or router) is assigned an IP address from a pool of available addresses. It keeps that address for a certain amount of time (e.g., two weeks). If the device is still active at the end of the lease, it can renew its connection and keep the same IP address. Otherwise, the IP address is collected and added to the pool to be redistributed. Thus, IP addresses provide regional information (through Regional Internet registries) and, if the ISP has logs, specific customer information. While this does not prove that a specific person was the originator of a blog post (it could have been someone else using that customer's Internet, after all), it provides powerful circumstantial evidence.\n\n\n*** Word and character frequency analysis ***\nCharacter frequency analysis takes advantage of the fact that all individuals have a different vocabulary: if there is a large body of data that can be tied to an individual (for example, a public figure with an official blog), statistical analysis can be applied to both this body of data and an anonymous blog to see how similar they are. In this way, anonymous bloggers can tentatively be deanonymized. This is known as stylometry; adversarial stylometry is the study of techniques for resisting such stylistic identification.\nAnswer this question: How do adversarial stylometry techniques help resist stylistic identification?",
    "context": "",
    "output": "Adversarial stylometry is the study of techniques for resisting stylistic identification. By using these techniques, anonymous bloggers can make it more difficult to deanonymize them through stylometry.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do adversarial stylometry techniques help resist stylistic identification?",
      "answer": "Adversarial stylometry is the study of techniques for resisting stylistic identification. By using these techniques, anonymous bloggers can make it more difficult to deanonymize them through stylometry.",
      "context": "Anonymous blog\n\n==Introduction==\nAn anonymous blog is a blog without any acknowledged author or contributor. Anonymous bloggers may achieve anonymity through the simple use of a pseudonym, or through more sophisticated techniques such as layered encryption routing, manipulation of post dates, or posting only from publicly accessible computers. Motivations for posting anonymously include a desire for privacy or fear of retribution by an employer (e.g., in whistleblower cases), a government (in countries that monitor or censor online communication), or another group.\n\n\n\n== Deanonymizing techniques ==\nFundamentally, deanonymization can be divided into two categories:\n\nSocial correlation compares known details about a person's life with the contents of an anonymous blog to look for similarities. If the author does not attempt to conceal their identity, social correlation is a very straightforward procedure: a simple correlation between the \"anonymous\" blogger's name, profession, lifestyle, etc., and the known person. Even if an author generally attempts to conceal their identity (by not providing their name, location, etc.), the blog can be deanonymized by correlating seemingly innocuous, general details.\nTechnical identification determines the author's identity through the blog's technical details. In extreme cases, technical identification entails looking at the server logs, the Internet provider logs, and payment information associated with the domain name.These techniques may be used together. The order of techniques employed typically escalates from the social correlation techniques, which do not require the compliance of any outside authorities (e.g., Internet providers, server providers, etc.), to more technical identification.\n\n== Types ==\nJust as a blog can be on any subject, so can an anonymous blog. Most fall into the following major categories:\n\nPolitical: A commentary on the political situation within a country, where being open may risk prosecution. Anonymous blogging can also add power to a political debate, such as in 2008 when blogger Eduwonkette, later revealed as Columbia University sociology graduate student Jennifer Jennings, successfully questioned New York Mayor Michael Bloomberg's takeover of New York schools.\nRevolutionary and counter-revolutionary: These can either be inspiring activity or counter activity, often against a violent state apparatus. For example, Salam Pax, the Baghdad blogger, wrote for The Guardian newspaper under a pseudonym that he could shed only when Saddam Hussein no longer ruled in Iraq. Similar bloggers appeared during the Arab Spring.\nDissident:  Dissident blogs may document life under an oppressive or secretive regime, while not actively promoting or inspiring revolutionary or counter-revolutionary action. Mosul Eye, which has described life under ISIL occupation in Mosul, Iraq, has been called one of the few reliable sources of information on life inside the city since it began in June 2014.\nReligious: Views and comments about religious view points and issues, perhaps questioning some written standpoints.\nWhistleblower: The whistleblower blog is a modern-day twist on the classical \"insider spotting illegality\" theme. This can cover all sectors or issues. Among the most notable is that by the Irish Red Cross head of the international department Noel Wardick, who highlighted that \u20ac162,000 in donations to the 2004 Indian Ocean earthquake and tsunami had sat in an account for over three years. After spending over \u20ac140,000 on private investigators and legal expenses to find the whistle blower, including court orders to obtain Wardick's identity from UPC and Google, the IRC disciplined and later dismissed Wardick. In 2010, an internal enquiry into Wardick's allegations found other such bank accounts, and proposals to overhaul the IRC's management were discussed in the D\u00e1il on 15 December. Questions were answered by Tony Killeen, then the Minister of Defence. Wardick later successfully sued the IRC for unfair dismissal.\nCompany insider: A company employee or insider reports on company operations and issues from within the organisation. The most famous is probably the Dooce.com blogger Heather Armstrong, who was fired for writing satirical accounts of her experiences at a dot-com startup on her personal blog, dooce.com.\nCommunity pressure: Written by a citizen of an area, on a particular subject, to bring about a change. In 2007, reporter and blogger Mike Stark came out in support of anonymous blogger Spocko, who was trying to bring what he called \"violent commentary\" on San Francisco area radio station KSFO to the attention of its advertisers.\nExperience/Customer Service: Most experience blogs focus on personal insights or views of customer service, frequently with dissatisfaction. Most anonymous experience blogs are written anonymously as they allow the customer/user to keep experiencing and using the service, and reporting/blogging, while nudging at a defined and appropriate level against the target organisation. Among these are Sarah Wu's/Mrs Q. \"Fed Up With Lunch\" blog, a chronicle of her experience as an adult eating Chicago area high school lunch every day for a year, which has now been turned into a book.\nPersonal: The personal blog strays into personal life in ways that allow more risk taking and open in terms of detail. Hence, many of these blogs are sexual in nature, although many also exist for those with health problems and disabilities and how they see the world and cope with its challenges. Some of the latest personal blogs are seen by many as extended group therapy, covering issues including weight loss.Recently, anonymous blogging has moved into a more aggressive and active style, with organized crime groups such as the Mafia using anonymous blogs against mayors and local administrators in Italy.\n\n== How online identity is determined ==\n\n\n*** IP addresses ***\nAn IP address is a unique numerical label assigned to a computer connected to a computer network that uses the Internet Protocol for communication. The most popular implementation of the Internet Protocol would be the Internet (capitalized, to differentiate it from smaller internetworks). Internet Service Providers (ISPs) are allocated chunks of IP addresses by a Regional Internet registry, which they then assign to customers. However, ISPs do not have enough addresses to give the customers their own address. Instead, DHCP is used; a customer's device (typically a modem or router) is assigned an IP address from a pool of available addresses. It keeps that address for a certain amount of time (e.g., two weeks). If the device is still active at the end of the lease, it can renew its connection and keep the same IP address. Otherwise, the IP address is collected and added to the pool to be redistributed. Thus, IP addresses provide regional information (through Regional Internet registries) and, if the ISP has logs, specific customer information. While this does not prove that a specific person was the originator of a blog post (it could have been someone else using that customer's Internet, after all), it provides powerful circumstantial evidence.\n\n\n*** Word and character frequency analysis ***\nCharacter frequency analysis takes advantage of the fact that all individuals have a different vocabulary: if there is a large body of data that can be tied to an individual (for example, a public figure with an official blog), statistical analysis can be applied to both this body of data and an anonymous blog to see how similar they are. In this way, anonymous bloggers can tentatively be deanonymized. This is known as stylometry; adversarial stylometry is the study of techniques for resisting such stylistic identification."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the Indian Supreme Court view the interception of telecommunications in India?",
    "context": "",
    "output": "The Indian Supreme Court has upheld the constitutional validity of interceptions and monitoring under Section 5(2) of the Act through its order dated 18.12.1996 in Writ Petition (C) No.256/1991 by People's Union for Civil Liberties (PUCL) Vs. Union of India. The court has held that telephone tapping would infringe the Right to Life and Right to Freedom of Speech & Expression enshrined in Articles 21 and 19(1)(a) respectively of the Constitution of India, unless it is permitted under the procedure established by law. The court further observed that Section 5(2) of the Act clearly provides that \u2018occurrence of any public emergency\u2019 or \u2018interest of public safety\u2019 is a sine qua non for the application of these provisions.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the Indian Supreme Court view the interception of telecommunications in India?",
      "answer": "The Indian Supreme Court has upheld the constitutional validity of interceptions and monitoring under Section 5(2) of the Act through its order dated 18.12.1996 in Writ Petition (C) No.256/1991 by People's Union for Civil Liberties (PUCL) Vs. Union of India. The court has held that telephone tapping would infringe the Right to Life and Right to Freedom of Speech & Expression enshrined in Articles 21 and 19(1)(a) respectively of the Constitution of India, unless it is permitted under the procedure established by law. The court further observed that Section 5(2) of the Act clearly provides that \u2018occurrence of any public emergency\u2019 or \u2018interest of public safety\u2019 is a sine qua non for the application of these provisions."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the key schedule of the xmx cipher generate subkeys for the different rounds?",
    "context": "",
    "output": "The key schedule of the xmx cipher generates subkeys for the different rounds using the same key for all the multipliers, and three different subkeys for the others: the key itself for the first half of the cipher, its multiplicative inverse mod n for the last half, and the XOR of these two for the middle subkey. This simple key schedule ensures that the same key is used throughout the cipher, but with different subkeys applied in each round.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the key schedule of the xmx cipher generate subkeys for the different rounds?",
      "answer": "The key schedule of the xmx cipher generates subkeys for the different rounds using the same key for all the multipliers, and three different subkeys for the others: the key itself for the first half of the cipher, its multiplicative inverse mod n for the last half, and the XOR of these two for the middle subkey. This simple key schedule ensures that the same key is used throughout the cipher, but with different subkeys applied in each round."
    }
  },
  {
    "instruction": "Write an answer to the following question: Is CounterSpy still available for purchase?",
    "context": "",
    "output": "No, CounterSpy is no longer available for purchase as it was discontinued in 2011.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Is CounterSpy still available for purchase?",
      "answer": "No, CounterSpy is no longer available for purchase as it was discontinued in 2011."
    }
  },
  {
    "instruction": "Write an answer to the following question: How can IoT-based attacks be prevented through a cyber security risk mitigating end-user program?",
    "context": "",
    "output": "A cyber security risk mitigating end-user program can help prevent IoT-based attacks by maintaining an accurate inventory of assets, practicing patch control, and changing default credentials for IoT devices. This will ensure that vulnerabilities in embedded devices found in various objects are addressed, reducing the risk of attacks.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can IoT-based attacks be prevented through a cyber security risk mitigating end-user program?",
      "answer": "A cyber security risk mitigating end-user program can help prevent IoT-based attacks by maintaining an accurate inventory of assets, practicing patch control, and changing default credentials for IoT devices. This will ensure that vulnerabilities in embedded devices found in various objects are addressed, reducing the risk of attacks."
    }
  },
  {
    "instruction": "Write an answer to the following question: What was EnGarde Secure Linux's role in the adoption of SELinux for complete server implementations?",
    "context": "",
    "output": "EnGarde Secure Linux was one of the earliest distributions to include SELinux for complete server implementations, and was one of the first Linux server platforms designed solely for security.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was EnGarde Secure Linux's role in the adoption of SELinux for complete server implementations?",
      "answer": "EnGarde Secure Linux was one of the earliest distributions to include SELinux for complete server implementations, and was one of the first Linux server platforms designed solely for security."
    }
  },
  {
    "instruction": "Write an answer to the following question: When did the Viasat hack occur and what was the impact?",
    "context": "",
    "output": "The Viasat hack occurred on 24 February 2022, resulting in thousands of modems getting bricked and thousands of customers in Europe being without internet for a month. Additionally, remote control of 5,800 wind turbines belonging to Enercon in Central Europe was affected.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "When did the Viasat hack occur and what was the impact?",
      "answer": "The Viasat hack occurred on 24 February 2022, resulting in thousands of modems getting bricked and thousands of customers in Europe being without internet for a month. Additionally, remote control of 5,800 wind turbines belonging to Enercon in Central Europe was affected."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does a Science DMZ enable the movement of large data sets using modern networks?",
    "context": "",
    "output": "A Science DMZ enables the movement of large data sets by providing a network architecture optimized for high-speed flows, free from packet loss and middleboxes such as traffic shapers or firewalls. This allows for efficient transfer of huge data sets, such as 10 Terabytes of data, within a reasonable time frame, such as less than 4 hours on a 10 Gigabit Ethernet network path.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does a Science DMZ enable the movement of large data sets using modern networks?",
      "answer": "A Science DMZ enables the movement of large data sets by providing a network architecture optimized for high-speed flows, free from packet loss and middleboxes such as traffic shapers or firewalls. This allows for efficient transfer of huge data sets, such as 10 Terabytes of data, within a reasonable time frame, such as less than 4 hours on a 10 Gigabit Ethernet network path."
    }
  },
  {
    "instruction": "Write an answer to the following question: How has Kubernetes been affected by the \"billion laughs\" attack?",
    "context": "",
    "output": "Kubernetes has been affected by the \"billion laughs\" attack through its YAML parser, which could result in a denial-of-service.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How has Kubernetes been affected by the \"billion laughs\" attack?",
      "answer": "Kubernetes has been affected by the \"billion laughs\" attack through its YAML parser, which could result in a denial-of-service."
    }
  },
  {
    "instruction": "Trellix\n\n==Introduction==\nTrellix (formerly FireEye and McAfee Enterprise) is a privately held cybersecurity company founded in 2022. It has been involved in the detection and prevention of major cybersecurity attacks.\nIt provides hardware, software, and services to investigate cybersecurity attacks, protect against malicious software, and analyze IT security risks.In March 2021, Symphony Technology Group (STG) announced its acquisition of McAfee Enterprise in an all-cash transaction for US$4.0 billion. STG completed the acquisition of McAfee\u2019s Enterprise business in July 2021 with plans for re-branding. In June 2021, FireEye sold its name and products business to STG for $1.2bn. STG combined FireEye with its acquisition of McAfee's enterprise business to launch Trellix, an extended detection and response (XDR) company. Meanwhile, McAfee Enterprise's security service edge (SSE) business would operate as a separate company to be known as Skyhigh Security.\n\n== Products and services ==\nFireEye started as a \"sandboxing\" company. Sandboxing is where incoming network traffic is opened within a virtual machine to test it for malicious software, before being introduced into the network. FireEye's products diversified over time, in part through acquisitions. In 2017, FireEye transitioned from primarily selling appliances, to a software-as-a-service model.FireEye sells technology products including network, email, and endpoint security, a platform for managing security operations centers called Helix, consulting services primarily based on incident response, and threat intelligence products.The Central Management System (CMS) consolidates the management, reporting, and data sharing of Web MPS (Malware Protection System), Email MPS, File MPS, and Malware Analysis System (MAS) into a single network-based appliance by acting as a distribution hub for malware security intelligence.The FireEye Cloud crowd-sources Dynamic Threat Intelligence (DTI) detected by individual FireEye MPS appliances and automatically distributes this time-sensitive zero-day intelligence globally to all subscribed customers in frequent updates. Content Updates include a combination of DTI and FireEye Labs generated intelligence identified through research efforts.\nAs of its inception in January 2022, Trellix has more than 40,000 customers, 5,000 employees, and $2bn in annual revenue. Trellix includes the endpoint, cloud, collaboration, data and user, application, and infrastructure security capabilities of FireEye and McAfee. The business focuses on threat detection and response using machine learning and automation, with security technology that can learn and adapt to combat advanced threats.\n\n== Operations ==\nFireEye has been known for uncovering high-profile hacking groups.\n\n\n*** 2008\u20132014 ***\nIn October/November 2009, FireEye participated to take down the Mega-D botnet (also known as Ozdok). On March 16, 2011, the Rustock botnet was taken down through action by Microsoft, US federal law enforcement agents, FireEye, and the University of Washington. In July 2012, FireEye was involved in the analysis of the Grum botnet's command and control servers located in the Netherlands, Panama, and Russia.In 2013, Mandiant (before being acquired by FireEye) uncovered a multi-year espionage effort by a Chinese hacking group called APT1.In 2014, the FireEye Labs team identified two new zero-day vulnerabilities \u2013 CVE-2014\u20134148 and CVE-2014\u20134113 \u2013 as part of limited, targeted attacks against major corporations. Both zero-days exploit the Windows kernel. Microsoft addressed the vulnerabilities in October 2014 Security Bulletin. Also in 2014, FireEye provided information on a threat group it calls FIN4. FIN4 appears to conduct intrusions that are focused on a single objective: obtaining access to insider information capable of making or breaking the stock prices of public companies. The group has targeted hundreds of companies and specifically targets the emails of C-level executives, legal counsel, regulatory, risk, and compliance personnel, and other individuals who would regularly discuss confidential, market-moving information. Also in 2014, FireEye released a report focused on a threat group it refers to as APT28. APT28 focuses on collecting intelligence that would be most useful to a government. FireEye found that since at least 2007, APT28 has been targeting privileged information related to governments, militaries, and security organizations that would likely benefit the Russian government.\n\n\n*** 2015 ***\nIn 2015, FireEye confirmed the existence of at least 14 router implants spread across four different countries: Ukraine, the Philippines, Mexico, and India. Referred to as SYNful Knock, the implant is a stealthy modification of the router\u2019s firmware image that can be used to maintain persistence within a victim\u2019s network.In September 2015, FireEye obtained an injunction against a security researcher attempting to report vulnerabilities in FireEye Malware Protection System.In 2015, FireEye uncovered an attack exploiting two previously unknown vulnerabilities, one in Microsoft Office (CVE-2015\u20132545) and another in Windows (CVE-2015\u20132546). The attackers hid the exploit within a Microsoft Word document (.docx) that appeared to be a r\u00e9sum\u00e9. The combination of these two exploits grants fully privileged remote code execution. Both vulnerabilities were patched by Microsoft.In 2015, the FireEye as a Service team in Singapore uncovered a phishing campaign exploiting an Adobe Flash Player zero-day vulnerability (CVE-2015\u20133113). Adobe released a patch for the vulnerability with an out-of-band security bulletin. FireEye attributed the activity to a China-based threat group it tracks as APT3.\n\n\n*** 2016 ***\nIn 2016, FireEye announced that it has been tracking a pair of cybercriminals referred to as the \u201cVendetta Brothers.\u201d The company said that the enterprising duo uses various strategies to compromise point-of-sale systems, steal payment card information and sell it on their underground marketplace \u201cVendetta World.\u201d\nIn mid-2016, FireEye released a report on the impact of the 2015 agreement between former U.S. President Barack Obama and China's paramount leader Xi Jinping that neither government would \u201cconduct or knowingly support cyber-enabled theft of intellectual property\u201d for economic advantage. The security firm reviewed the activity of 72 groups that it suspects are operating in China or otherwise support Chinese state interests and determined that, as of mid-2014, there was an overall decrease in successful network compromises by China-based groups against organizations in the U.S. and 25 other countries.In 2016, FireEye announced that it had identified several versions of an ICS-focused malware \u2013 dubbed IRON GATE \u2013 crafted to manipulate a specific industrial process running within a simulated Siemens control system environment. Although Siemens Product Computer Emergency Readiness Team (ProductCERT) confirmed to FireEye that IRON GATE is not viable against operational Siemens control systems and that IRON GATE does not exploit any vulnerabilities in Siemens products, the security firm said that IRON GATE invokes ICS attack concepts first seen in Stuxnet.On May 8, 2016, FireEye detected an attack exploiting a previously unknown vulnerability in Adobe Flash Player (CVE-2016\u20134117). The security firm reported the issue to the Adobe Product Security Incident Response Team (PSIRT) and Adobe released a patch for the vulnerability just four days later.In 2016, FireEye discovered a widespread vulnerability affecting Android devices that permits local privilege escalation to the built-in user \u201cradio\u201d, making it so an attacker can potentially perform activities such as viewing the victim\u2019s SMS database and phone history. FireEye reached out to Qualcomm in January 2016 and subsequently worked with the Qualcomm Product Security Team to address the issue.In 2016, FireEye provided details on FIN6, a cybercriminal group that steals payment card data for monetization from targets predominately in the hospitality and retail sectors. The group was observed aggressively targeting and compromising point-of-sale (POS) systems, and making off millions of payment card numbers that were later sold on an underground marketplace.\n\n\n*** 2017\u20132019 ***\nIn 2017, FireEye detected malicious Microsoft Office RTF documents leveraging a previously undisclosed vulnerability, CVE-2017-0199. This vulnerability allows a malicious actor to download and execute a Visual Basic script containing PowerShell commands when a user opens a document containing an embedded exploit. FireEye shared the details of the vulnerability with Microsoft and coordinated public disclosure timed with the release of a patch by Microsoft to address the vulnerability.In 2018, FireEye helped Facebook identify 652 fake accounts.\n\n\n*** 2020\u20132021 ***\nFireEye revealed on Tuesday, December 8, 2020, that its systems were pierced by what it called \"a nation with top-tier offensive capabilities\". The company said the attackers used \"novel techniques\" to steal copies of FireEye's red team tool kit, which the attackers could potentially use in other attacks. The same day, FireEye published countermeasures against the tools that had been stolen.A week later in December 2020, FireEye reported the SolarWinds supply chain attack to the U.S. National Security Agency (NSA), the federal agency responsible for defending the U.S. from cyberattacks, and said its tools were stolen by the same actors. The NSA is not known to have been aware of the attack before being notified by FireEye. The NSA uses SolarWinds software itself.Within a week of FireEye's breach, cyber-security firm McAfee said the stolen tools had been used in at least 19 countries, including the US, the UK, Ireland, the Netherlands, and Australia.During the continued investigation of the hack of their data and that of federal agencies revealed on December 8, 2020, FireEye reported in early January that the hacks originated from inside the USA, sometimes very close to the facilities affected, which enabled the hackers to evade surveillance by the National Security Agency and the defenses used by the Department of Homeland Security.\n\n\n*** 2022 ***\nA 2022 report by Trellix noted that hacking groups Wicked Panda (linked to China) and Cozy Bear (linked to Russia) were behind 46% of all state-sponsored hacking campaigns in the third quarter of 2021 and that in a third of all state-sponsored cyber attacks, the hackers abused Cobalt Strike security tools to get access to the victim's network. In a January 2022 report on Fox News, Trellix CEO Bryan Palma stated that there is an increasing level of cyberwarfare threats from Russia and China.A 2022 Trellix report stated that hackers are using Microsoft OneDrive in an espionage campaign against government officials in Western Asia. The malware, named by Trellix as Graphite, employs Microsoft Graph to use OneDrive as a command and control server and execute the malware. The attack is split into multiple stages to remain hidden for as long as possible.\n\n== Acquisitions ==\nQ: How did FireEye contribute to the analysis of the Grum botnet's command and control servers in 2012?",
    "context": "",
    "output": "FireEye was involved in the analysis of the Grum botnet's command and control servers located in the Netherlands, Panama, and Russia, contributing to the global effort to combat cybercrime.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How did FireEye contribute to the analysis of the Grum botnet's command and control servers in 2012?",
      "answer": "FireEye was involved in the analysis of the Grum botnet's command and control servers located in the Netherlands, Panama, and Russia, contributing to the global effort to combat cybercrime.",
      "context": "Trellix\n\n==Introduction==\nTrellix (formerly FireEye and McAfee Enterprise) is a privately held cybersecurity company founded in 2022. It has been involved in the detection and prevention of major cybersecurity attacks.\nIt provides hardware, software, and services to investigate cybersecurity attacks, protect against malicious software, and analyze IT security risks.In March 2021, Symphony Technology Group (STG) announced its acquisition of McAfee Enterprise in an all-cash transaction for US$4.0 billion. STG completed the acquisition of McAfee\u2019s Enterprise business in July 2021 with plans for re-branding. In June 2021, FireEye sold its name and products business to STG for $1.2bn. STG combined FireEye with its acquisition of McAfee's enterprise business to launch Trellix, an extended detection and response (XDR) company. Meanwhile, McAfee Enterprise's security service edge (SSE) business would operate as a separate company to be known as Skyhigh Security.\n\n== Products and services ==\nFireEye started as a \"sandboxing\" company. Sandboxing is where incoming network traffic is opened within a virtual machine to test it for malicious software, before being introduced into the network. FireEye's products diversified over time, in part through acquisitions. In 2017, FireEye transitioned from primarily selling appliances, to a software-as-a-service model.FireEye sells technology products including network, email, and endpoint security, a platform for managing security operations centers called Helix, consulting services primarily based on incident response, and threat intelligence products.The Central Management System (CMS) consolidates the management, reporting, and data sharing of Web MPS (Malware Protection System), Email MPS, File MPS, and Malware Analysis System (MAS) into a single network-based appliance by acting as a distribution hub for malware security intelligence.The FireEye Cloud crowd-sources Dynamic Threat Intelligence (DTI) detected by individual FireEye MPS appliances and automatically distributes this time-sensitive zero-day intelligence globally to all subscribed customers in frequent updates. Content Updates include a combination of DTI and FireEye Labs generated intelligence identified through research efforts.\nAs of its inception in January 2022, Trellix has more than 40,000 customers, 5,000 employees, and $2bn in annual revenue. Trellix includes the endpoint, cloud, collaboration, data and user, application, and infrastructure security capabilities of FireEye and McAfee. The business focuses on threat detection and response using machine learning and automation, with security technology that can learn and adapt to combat advanced threats.\n\n== Operations ==\nFireEye has been known for uncovering high-profile hacking groups.\n\n\n*** 2008\u20132014 ***\nIn October/November 2009, FireEye participated to take down the Mega-D botnet (also known as Ozdok). On March 16, 2011, the Rustock botnet was taken down through action by Microsoft, US federal law enforcement agents, FireEye, and the University of Washington. In July 2012, FireEye was involved in the analysis of the Grum botnet's command and control servers located in the Netherlands, Panama, and Russia.In 2013, Mandiant (before being acquired by FireEye) uncovered a multi-year espionage effort by a Chinese hacking group called APT1.In 2014, the FireEye Labs team identified two new zero-day vulnerabilities \u2013 CVE-2014\u20134148 and CVE-2014\u20134113 \u2013 as part of limited, targeted attacks against major corporations. Both zero-days exploit the Windows kernel. Microsoft addressed the vulnerabilities in October 2014 Security Bulletin. Also in 2014, FireEye provided information on a threat group it calls FIN4. FIN4 appears to conduct intrusions that are focused on a single objective: obtaining access to insider information capable of making or breaking the stock prices of public companies. The group has targeted hundreds of companies and specifically targets the emails of C-level executives, legal counsel, regulatory, risk, and compliance personnel, and other individuals who would regularly discuss confidential, market-moving information. Also in 2014, FireEye released a report focused on a threat group it refers to as APT28. APT28 focuses on collecting intelligence that would be most useful to a government. FireEye found that since at least 2007, APT28 has been targeting privileged information related to governments, militaries, and security organizations that would likely benefit the Russian government.\n\n\n*** 2015 ***\nIn 2015, FireEye confirmed the existence of at least 14 router implants spread across four different countries: Ukraine, the Philippines, Mexico, and India. Referred to as SYNful Knock, the implant is a stealthy modification of the router\u2019s firmware image that can be used to maintain persistence within a victim\u2019s network.In September 2015, FireEye obtained an injunction against a security researcher attempting to report vulnerabilities in FireEye Malware Protection System.In 2015, FireEye uncovered an attack exploiting two previously unknown vulnerabilities, one in Microsoft Office (CVE-2015\u20132545) and another in Windows (CVE-2015\u20132546). The attackers hid the exploit within a Microsoft Word document (.docx) that appeared to be a r\u00e9sum\u00e9. The combination of these two exploits grants fully privileged remote code execution. Both vulnerabilities were patched by Microsoft.In 2015, the FireEye as a Service team in Singapore uncovered a phishing campaign exploiting an Adobe Flash Player zero-day vulnerability (CVE-2015\u20133113). Adobe released a patch for the vulnerability with an out-of-band security bulletin. FireEye attributed the activity to a China-based threat group it tracks as APT3.\n\n\n*** 2016 ***\nIn 2016, FireEye announced that it has been tracking a pair of cybercriminals referred to as the \u201cVendetta Brothers.\u201d The company said that the enterprising duo uses various strategies to compromise point-of-sale systems, steal payment card information and sell it on their underground marketplace \u201cVendetta World.\u201d\nIn mid-2016, FireEye released a report on the impact of the 2015 agreement between former U.S. President Barack Obama and China's paramount leader Xi Jinping that neither government would \u201cconduct or knowingly support cyber-enabled theft of intellectual property\u201d for economic advantage. The security firm reviewed the activity of 72 groups that it suspects are operating in China or otherwise support Chinese state interests and determined that, as of mid-2014, there was an overall decrease in successful network compromises by China-based groups against organizations in the U.S. and 25 other countries.In 2016, FireEye announced that it had identified several versions of an ICS-focused malware \u2013 dubbed IRON GATE \u2013 crafted to manipulate a specific industrial process running within a simulated Siemens control system environment. Although Siemens Product Computer Emergency Readiness Team (ProductCERT) confirmed to FireEye that IRON GATE is not viable against operational Siemens control systems and that IRON GATE does not exploit any vulnerabilities in Siemens products, the security firm said that IRON GATE invokes ICS attack concepts first seen in Stuxnet.On May 8, 2016, FireEye detected an attack exploiting a previously unknown vulnerability in Adobe Flash Player (CVE-2016\u20134117). The security firm reported the issue to the Adobe Product Security Incident Response Team (PSIRT) and Adobe released a patch for the vulnerability just four days later.In 2016, FireEye discovered a widespread vulnerability affecting Android devices that permits local privilege escalation to the built-in user \u201cradio\u201d, making it so an attacker can potentially perform activities such as viewing the victim\u2019s SMS database and phone history. FireEye reached out to Qualcomm in January 2016 and subsequently worked with the Qualcomm Product Security Team to address the issue.In 2016, FireEye provided details on FIN6, a cybercriminal group that steals payment card data for monetization from targets predominately in the hospitality and retail sectors. The group was observed aggressively targeting and compromising point-of-sale (POS) systems, and making off millions of payment card numbers that were later sold on an underground marketplace.\n\n\n*** 2017\u20132019 ***\nIn 2017, FireEye detected malicious Microsoft Office RTF documents leveraging a previously undisclosed vulnerability, CVE-2017-0199. This vulnerability allows a malicious actor to download and execute a Visual Basic script containing PowerShell commands when a user opens a document containing an embedded exploit. FireEye shared the details of the vulnerability with Microsoft and coordinated public disclosure timed with the release of a patch by Microsoft to address the vulnerability.In 2018, FireEye helped Facebook identify 652 fake accounts.\n\n\n*** 2020\u20132021 ***\nFireEye revealed on Tuesday, December 8, 2020, that its systems were pierced by what it called \"a nation with top-tier offensive capabilities\". The company said the attackers used \"novel techniques\" to steal copies of FireEye's red team tool kit, which the attackers could potentially use in other attacks. The same day, FireEye published countermeasures against the tools that had been stolen.A week later in December 2020, FireEye reported the SolarWinds supply chain attack to the U.S. National Security Agency (NSA), the federal agency responsible for defending the U.S. from cyberattacks, and said its tools were stolen by the same actors. The NSA is not known to have been aware of the attack before being notified by FireEye. The NSA uses SolarWinds software itself.Within a week of FireEye's breach, cyber-security firm McAfee said the stolen tools had been used in at least 19 countries, including the US, the UK, Ireland, the Netherlands, and Australia.During the continued investigation of the hack of their data and that of federal agencies revealed on December 8, 2020, FireEye reported in early January that the hacks originated from inside the USA, sometimes very close to the facilities affected, which enabled the hackers to evade surveillance by the National Security Agency and the defenses used by the Department of Homeland Security.\n\n\n*** 2022 ***\nA 2022 report by Trellix noted that hacking groups Wicked Panda (linked to China) and Cozy Bear (linked to Russia) were behind 46% of all state-sponsored hacking campaigns in the third quarter of 2021 and that in a third of all state-sponsored cyber attacks, the hackers abused Cobalt Strike security tools to get access to the victim's network. In a January 2022 report on Fox News, Trellix CEO Bryan Palma stated that there is an increasing level of cyberwarfare threats from Russia and China.A 2022 Trellix report stated that hackers are using Microsoft OneDrive in an espionage campaign against government officials in Western Asia. The malware, named by Trellix as Graphite, employs Microsoft Graph to use OneDrive as a command and control server and execute the malware. The attack is split into multiple stages to remain hidden for as long as possible.\n\n== Acquisitions =="
    }
  },
  {
    "instruction": "Key derivation function\n\n==Introduction==\nIn cryptography, a key derivation function (KDF) is a cryptographic algorithm that derives one or more secret keys from a secret value such as a master key, a password, or a passphrase using a pseudorandom function (which typically uses a cryptographic hash function or block cipher). KDFs can be used to stretch keys into longer keys or to obtain keys of a required format, such as converting a group element that is the result of a Diffie\u2013Hellman key exchange into a symmetric key for use with AES. Keyed cryptographic hash functions are popular examples of pseudorandom functions used for key derivation.\n\n== Key derivation ==\nThe original use for a KDF is key derivation, the generation of keys from secret passwords or passphrases. Variations on this theme include:\n\nIn conjunction with non-secret parameters to derive one or more keys from a common secret value (which is sometimes also referred to as \"key diversification\"). Such use may prevent an attacker who obtains a derived key from learning useful information about either the input secret value or any of the other derived keys. A KDF may also be used to ensure that derived keys have other desirable properties, such as avoiding \"weak keys\" in some specific encryption systems.\nAs components of multiparty key-agreement protocols. Examples of such key derivation functions include KDF1, defined in IEEE Std 1363-2000, and similar functions in ANSI X9.42.\nTo derive keys from secret passwords or passphrases (a password-based KDF).\nTo derive keys of different length from the ones provided: one example of KDFs designed for this purpose is HKDF.\nKey stretching and key strengthening.\n\n\n*** Key stretching and key strengthening ***\n\nKey derivation functions are also used in applications to derive keys from secret passwords or passphrases, which typically do not have the desired properties to be used directly as cryptographic keys. In such applications, it is generally recommended that the key derivation function be made deliberately slow so as to frustrate brute-force attack or dictionary attack on the password or passphrase input value.\nSuch use may be expressed as DK\n\n== Password hashing ==\nDespite their original use for key derivation, KDFs are possibly better known for their use in password hashing (password verification by hash comparison), as used by the passwd file or shadow password file. Password hash functions should be relatively expensive to calculate in case of brute-force attacks, and the key stretching of KDFs happen to provide this characteristic. The non-secret parameters are called \"salt\" in this context.\nIn 2013 a Password Hashing Competition was announced to choose a new, standard algorithm for password hashing. On 20 July 2015 the competition ended and Argon2 was announced as the final winner. Four other algorithms received special recognition: Catena, Lyra2, Makwa and yescrypt.As of May 2023, OWASP recommends the following KDFs for password hashing, listed in order of priority:1. Argon2id\n2. scrypt if Argon2id is unavailable\n3. bcrypt for legacy systems\n4. PBKDF2 if FIPS-140 compliance is required\n\nHow are KDFs used in password hashing?",
    "context": "",
    "output": "KDFs are used in password hashing to hash passwords and compare them for verification. Password hash functions should be relatively expensive to calculate in case of brute-force attacks, and the key stretching of KDFs happens to provide this characteristic. The non-secret parameters are called \"salt\" in this context.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How are KDFs used in password hashing?",
      "answer": "KDFs are used in password hashing to hash passwords and compare them for verification. Password hash functions should be relatively expensive to calculate in case of brute-force attacks, and the key stretching of KDFs happens to provide this characteristic. The non-secret parameters are called \"salt\" in this context.",
      "context": "Key derivation function\n\n==Introduction==\nIn cryptography, a key derivation function (KDF) is a cryptographic algorithm that derives one or more secret keys from a secret value such as a master key, a password, or a passphrase using a pseudorandom function (which typically uses a cryptographic hash function or block cipher). KDFs can be used to stretch keys into longer keys or to obtain keys of a required format, such as converting a group element that is the result of a Diffie\u2013Hellman key exchange into a symmetric key for use with AES. Keyed cryptographic hash functions are popular examples of pseudorandom functions used for key derivation.\n\n== Key derivation ==\nThe original use for a KDF is key derivation, the generation of keys from secret passwords or passphrases. Variations on this theme include:\n\nIn conjunction with non-secret parameters to derive one or more keys from a common secret value (which is sometimes also referred to as \"key diversification\"). Such use may prevent an attacker who obtains a derived key from learning useful information about either the input secret value or any of the other derived keys. A KDF may also be used to ensure that derived keys have other desirable properties, such as avoiding \"weak keys\" in some specific encryption systems.\nAs components of multiparty key-agreement protocols. Examples of such key derivation functions include KDF1, defined in IEEE Std 1363-2000, and similar functions in ANSI X9.42.\nTo derive keys from secret passwords or passphrases (a password-based KDF).\nTo derive keys of different length from the ones provided: one example of KDFs designed for this purpose is HKDF.\nKey stretching and key strengthening.\n\n\n*** Key stretching and key strengthening ***\n\nKey derivation functions are also used in applications to derive keys from secret passwords or passphrases, which typically do not have the desired properties to be used directly as cryptographic keys. In such applications, it is generally recommended that the key derivation function be made deliberately slow so as to frustrate brute-force attack or dictionary attack on the password or passphrase input value.\nSuch use may be expressed as DK\n\n== Password hashing ==\nDespite their original use for key derivation, KDFs are possibly better known for their use in password hashing (password verification by hash comparison), as used by the passwd file or shadow password file. Password hash functions should be relatively expensive to calculate in case of brute-force attacks, and the key stretching of KDFs happen to provide this characteristic. The non-secret parameters are called \"salt\" in this context.\nIn 2013 a Password Hashing Competition was announced to choose a new, standard algorithm for password hashing. On 20 July 2015 the competition ended and Argon2 was announced as the final winner. Four other algorithms received special recognition: Catena, Lyra2, Makwa and yescrypt.As of May 2023, OWASP recommends the following KDFs for password hashing, listed in order of priority:1. Argon2id\n2. scrypt if Argon2id is unavailable\n3. bcrypt for legacy systems\n4. PBKDF2 if FIPS-140 compliance is required"
    }
  },
  {
    "instruction": "Write an answer to the following question: How does CISA help ensure that DoD Components take appropriate mitigating actions against vulnerabilities to avoid serious compromises to DoD computer system assets that would potentially degrade mission performance?",
    "context": "",
    "output": "CISA, which includes the National Cybersecurity and Communications Integration Center (NCCIC), manages the US-CERT to identify and notify about computer application software or operating system vulnerabilities, and coordinates with all affected organizations to determine operational impact before instituting a disconnection.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does CISA help ensure that DoD Components take appropriate mitigating actions against vulnerabilities to avoid serious compromises to DoD computer system assets that would potentially degrade mission performance?",
      "answer": "CISA, which includes the National Cybersecurity and Communications Integration Center (NCCIC), manages the US-CERT to identify and notify about computer application software or operating system vulnerabilities, and coordinates with all affected organizations to determine operational impact before instituting a disconnection."
    }
  },
  {
    "instruction": "TeslaTeam\n\n==Introduction==\nTeslaTeam is a group of  computer hackers. Using denial of service attacks, defacement, and other methods, it mainly targets political groups and Albanian websites, including news organizations and human rights groups. TeslaTeam is currently the only virtual army in Serbia to openly launch cyber attacks.\n\n\n\n== Targets ==\nTeslaTeam mainly targets websites of political organisations, NGOs, and websites of anti-Serb organisations.\n\n== Attacks ==\nTeslaTeam's attacks began in February 2013, during a demonstration against the introduction of the Cyrillic alphabet and Serbian language in Vukovar. They began operation Cirilica which led to defacement and security breaches on over 100 websites across Croatia.\n\n\n*** Timeline of notable defacements ***\n9 February 2013: Vukovar Institute for Peace Research and Education\n13 February 2013: Polytechnic Lavoslav Ru\u017ei\u010dka Vukovar\n18 February 2013: Croatian Bishops' Conference\n20 February 2013: University of Osijek\n25 February 2013: Croatian Pure Party of Rights\n13 August 2013: 200 Montenegro sites defaced\n30 October 2013: Website of  Librazhd Municipality in Albania\n14 December 2013: 100 Croatian websites defaced\n\n\n*** Timeline of notable security breaches ***\n7 November 2012: TeslaTeam claimed to have hacked the website of the Ministry of Economy, Trade and Energy of Albania\n9  November 2013: TeslaTeam claimed to have hacked the website of the Chicago Tribune\n13 November 2013: TeslaTeam claimed to have hacked the database of Vevo\n18 November 2013: TeslaTeam claimed to have hacked the website of E! News\n29 November 2013: Websites of Bulgarian and Albanian Government\n29 November 2013: Cambridge University database hacked\n3 December 2013: Court of Bosnia and Herzegovina\n\nWhich notable Montenegrin websites were targeted by TeslaTeam in August 2013?",
    "context": "",
    "output": "A: 200 Montenegrin websites were targeted by TeslaTeam in August 2013.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Which notable Montenegrin websites were targeted by TeslaTeam in August 2013?",
      "answer": "200 Montenegrin websites were targeted by TeslaTeam in August 2013.",
      "context": "TeslaTeam\n\n==Introduction==\nTeslaTeam is a group of  computer hackers. Using denial of service attacks, defacement, and other methods, it mainly targets political groups and Albanian websites, including news organizations and human rights groups. TeslaTeam is currently the only virtual army in Serbia to openly launch cyber attacks.\n\n\n\n== Targets ==\nTeslaTeam mainly targets websites of political organisations, NGOs, and websites of anti-Serb organisations.\n\n== Attacks ==\nTeslaTeam's attacks began in February 2013, during a demonstration against the introduction of the Cyrillic alphabet and Serbian language in Vukovar. They began operation Cirilica which led to defacement and security breaches on over 100 websites across Croatia.\n\n\n*** Timeline of notable defacements ***\n9 February 2013: Vukovar Institute for Peace Research and Education\n13 February 2013: Polytechnic Lavoslav Ru\u017ei\u010dka Vukovar\n18 February 2013: Croatian Bishops' Conference\n20 February 2013: University of Osijek\n25 February 2013: Croatian Pure Party of Rights\n13 August 2013: 200 Montenegro sites defaced\n30 October 2013: Website of  Librazhd Municipality in Albania\n14 December 2013: 100 Croatian websites defaced\n\n\n*** Timeline of notable security breaches ***\n7 November 2012: TeslaTeam claimed to have hacked the website of the Ministry of Economy, Trade and Energy of Albania\n9  November 2013: TeslaTeam claimed to have hacked the website of the Chicago Tribune\n13 November 2013: TeslaTeam claimed to have hacked the database of Vevo\n18 November 2013: TeslaTeam claimed to have hacked the website of E! News\n29 November 2013: Websites of Bulgarian and Albanian Government\n29 November 2013: Cambridge University database hacked\n3 December 2013: Court of Bosnia and Herzegovina"
    }
  },
  {
    "instruction": "Write an answer to the following question: Is it possible to disable compression in Microsoft SEAL?",
    "context": "",
    "output": "Yes, compression can always be disabled in Microsoft SEAL.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Is it possible to disable compression in Microsoft SEAL?",
      "answer": "Yes, compression can always be disabled in Microsoft SEAL."
    }
  },
  {
    "instruction": "Write an answer to the following question: How do some alternative 3rd-party firmware make DVD+Rs readable by older DVD players?",
    "context": "",
    "output": "Some alternative 3rd-party firmware make DVD+Rs readable by older DVD players by enabling the Bitsetting/Booktyping feature, which makes the burned DVDs appear as DVD-ROMs and are playable by older DVD players.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do some alternative 3rd-party firmware make DVD+Rs readable by older DVD players?",
      "answer": "Some alternative 3rd-party firmware make DVD+Rs readable by older DVD players by enabling the Bitsetting/Booktyping feature, which makes the burned DVDs appear as DVD-ROMs and are playable by older DVD players."
    }
  },
  {
    "instruction": "Context: Strong RSA assumption\n\n==Introduction==\nIn cryptography,  the strong RSA assumption states that the RSA problem is intractable even when the solver is allowed to choose the public exponent e (for e \u2265 3).  More specifically, given a modulus N of unknown factorization, and a ciphertext C, it is infeasible to find any pair (M, e) such that C \u2261 M e mod N.\nThe strong RSA assumption was first used for constructing signature schemes provably secure against existential forgery without resorting to the random oracle model.\n\n\n\n\n\nQuestion: How does the strong RSA assumption contribute to the construction of signature schemes, and why is it an improvement over the random oracle model?\n\nAnswer:",
    "context": "",
    "output": "The strong RSA assumption is the foundation for constructing signature schemes that are provably secure against existential forgery. It allows for the creation of schemes that do not rely on the random oracle model, which is a theoretical construct that assumes the existence of a random function that can be queried by the adversary. While the random oracle model is useful for proving the security of certain cryptographic constructions, it does not always reflect the true security of a scheme when implemented in practice. By using the strong RSA assumption, cryptographers can create signature schemes with provable security guarantees that are more likely to hold in real-world scenarios.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the strong RSA assumption contribute to the construction of signature schemes, and why is it an improvement over the random oracle model?",
      "answer": "The strong RSA assumption is the foundation for constructing signature schemes that are provably secure against existential forgery. It allows for the creation of schemes that do not rely on the random oracle model, which is a theoretical construct that assumes the existence of a random function that can be queried by the adversary. While the random oracle model is useful for proving the security of certain cryptographic constructions, it does not always reflect the true security of a scheme when implemented in practice. By using the strong RSA assumption, cryptographers can create signature schemes with provable security guarantees that are more likely to hold in real-world scenarios.",
      "context": "Strong RSA assumption\n\n==Introduction==\nIn cryptography,  the strong RSA assumption states that the RSA problem is intractable even when the solver is allowed to choose the public exponent e (for e \u2265 3).  More specifically, given a modulus N of unknown factorization, and a ciphertext C, it is infeasible to find any pair (M, e) such that C \u2261 M e mod N.\nThe strong RSA assumption was first used for constructing signature schemes provably secure against existential forgery without resorting to the random oracle model.\n\n\n\n"
    }
  },
  {
    "instruction": "Context: OGUsers\n\n==Introduction==\nOGUsers (OGU) was an internet forum that facilitates the discussion and hacking of social media accounts and online usernames. Established in 2017, the website is dedicated to the buying and selling of \"rare\" or \"OG\" online accounts that are considered valuable due to their name or age. The website acts as a platform for cybercrime and the harassment of individuals for access to their online accounts. Several high-profile incidents have been linked to the forum, most notably the 2020 Twitter account hijacking.\n\n\n\n== Incidents ==\nThe site has been linked to various SIM swap scams, where discussion took place on identity theft methods to change login information for online accounts.Graham Ivan Clark, regarded as the \"mastermind\" behind the 2020 Twitter account hijacking, was a former member of the forum. Two participants, Mason Sheppard and Nima Fazeli, acted as brokers in selling of Twitter handles on the website.In 2020, a man from Tennessee died from a heart attack from a swatting. An individual in the United Kingdom was attempting to coerce the man for an online username by ulitilizing tactics of the site, with him later being sentenced to five years in prison.\n\n\n*** Security breaches ***\nThe website was hacked in May 2019, with the administrator of RaidForums uploading the database of the website for anyone to access. In December 2020, the website was hacked again with user data being stolen. In April 2021, the information of 350,000 members of the forum was breached.\n\nQuestion: What was the role of OGUsers in the 2020 Twitter account hijacking?\n\nAnswer:",
    "context": "",
    "output": "Several individuals involved in the 2020 Twitter account hijacking were former members of OGUsers. Graham Ivan Clark, who was regarded as the \"mastermind\" behind the incident, was a member of the forum, as were two other participants who acted as brokers in the selling of Twitter handles on the website.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was the role of OGUsers in the 2020 Twitter account hijacking?",
      "answer": "Several individuals involved in the 2020 Twitter account hijacking were former members of OGUsers. Graham Ivan Clark, who was regarded as the \"mastermind\" behind the incident, was a member of the forum, as were two other participants who acted as brokers in the selling of Twitter handles on the website.",
      "context": "OGUsers\n\n==Introduction==\nOGUsers (OGU) was an internet forum that facilitates the discussion and hacking of social media accounts and online usernames. Established in 2017, the website is dedicated to the buying and selling of \"rare\" or \"OG\" online accounts that are considered valuable due to their name or age. The website acts as a platform for cybercrime and the harassment of individuals for access to their online accounts. Several high-profile incidents have been linked to the forum, most notably the 2020 Twitter account hijacking.\n\n\n\n== Incidents ==\nThe site has been linked to various SIM swap scams, where discussion took place on identity theft methods to change login information for online accounts.Graham Ivan Clark, regarded as the \"mastermind\" behind the 2020 Twitter account hijacking, was a former member of the forum. Two participants, Mason Sheppard and Nima Fazeli, acted as brokers in selling of Twitter handles on the website.In 2020, a man from Tennessee died from a heart attack from a swatting. An individual in the United Kingdom was attempting to coerce the man for an online username by ulitilizing tactics of the site, with him later being sentenced to five years in prison.\n\n\n*** Security breaches ***\nThe website was hacked in May 2019, with the administrator of RaidForums uploading the database of the website for anyone to access. In December 2020, the website was hacked again with user data being stolen. In April 2021, the information of 350,000 members of the forum was breached."
    }
  },
  {
    "instruction": "Write an answer to the following question: How do robust fuzzy extractors solve the problem of active attacks in fuzzy extractors?",
    "context": "",
    "output": "Robust fuzzy extractors allow the reproduce function to fail if a modified helper string is provided as input, preventing an adversary from changing the helper string to output an incorrect secret string.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do robust fuzzy extractors solve the problem of active attacks in fuzzy extractors?",
      "answer": "Robust fuzzy extractors allow the reproduce function to fail if a modified helper string is provided as input, preventing an adversary from changing the helper string to output an incorrect secret string."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are some methods used for eavesdropping on cookies?",
    "context": "",
    "output": "Cookies that are sent over unencrypted channels can be subject to eavesdropping, where the contents of the cookie can be read by the attacker. This type of threat can be prevented by the use of Secure Sockets Layer (SSL) protocol in servers and Internet browsers.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are some methods used for eavesdropping on cookies?",
      "answer": "Cookies that are sent over unencrypted channels can be subject to eavesdropping, where the contents of the cookie can be read by the attacker. This type of threat can be prevented by the use of Secure Sockets Layer (SSL) protocol in servers and Internet browsers."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the Intel Management Engine (ME) and where is it located in an Intel motherboard?",
    "context": "",
    "output": "The Intel Management Engine (ME) is an autonomous subsystem located in the Platform Controller Hub of modern Intel motherboards. It runs as long as the motherboard is receiving power and performs tasks during boot-up, while the computer is running, and while it is asleep.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the Intel Management Engine (ME) and where is it located in an Intel motherboard?",
      "answer": "The Intel Management Engine (ME) is an autonomous subsystem located in the Platform Controller Hub of modern Intel motherboards. It runs as long as the motherboard is receiving power and performs tasks during boot-up, while the computer is running, and while it is asleep."
    }
  },
  {
    "instruction": "Write an answer to the following question: How can a lack of understanding of privacy terms contribute to information leakage?",
    "context": "",
    "output": "Privacy terms that are too lengthy, involve professional vocabularies, or do not clearly specify the parties the information is being granted to can lead to a lack of understanding and contribute to information leakage.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can a lack of understanding of privacy terms contribute to information leakage?",
      "answer": "Privacy terms that are too lengthy, involve professional vocabularies, or do not clearly specify the parties the information is being granted to can lead to a lack of understanding and contribute to information leakage."
    }
  },
  {
    "instruction": "Write an answer to the following question: How can opportunistic encryption be used in Linux and Unix-like systems?",
    "context": "",
    "output": "The FreeS/WAN and forks such as Openswan and strongSwan offer VPNs which can also operate in OE mode using IPsec based technology. Obfuscated TCP is another method of implementing OE.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can opportunistic encryption be used in Linux and Unix-like systems?",
      "answer": "The FreeS/WAN and forks such as Openswan and strongSwan offer VPNs which can also operate in OE mode using IPsec based technology. Obfuscated TCP is another method of implementing OE."
    }
  },
  {
    "instruction": "Context: 3-subset meet-in-the-middle attack\n\n==Introduction==\nThe 3-subset meet-in-the-middle (hereafter shortened MITM) attack is a variant of the generic meet-in-the-middle attack, which is used in cryptology for hash and block cipher cryptanalysis. The 3-subset variant opens up the possibility to apply MITM attacks on ciphers, where it is not trivial to divide the keybits into two independent key-spaces, as required by the MITM attack.\nThe 3-subset variant relaxes the restriction for the key-spaces to be independent, by moving the intersecting parts of the keyspaces into a subset, which contains the keybits common between the two key-spaces.\n\n\n\n== Procedure ==\nAs with general MITM attacks, the attack is split into two phases: A key-reducing phase and a key-verification phase. In the first phase, the domain of key-candidates is reduced, by applying the MITM attack. In the second phase, the found key-candidates are tested on another plain-/ciphertext pair to filter away the wrong key(s).\n\n\n*** Key-reducing phase ***\nIn the key-reducing phase, the attacked cipher is split into two subciphers, \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n   and \n  \n    \n      \n        g\n      \n    \n    {\\displaystyle g}\n  , with each their independent keybits, as is normal with MITM attacks. Instead of having to conform to the limitation that the keybits of the two subciphers should be independent, the 3-subset attack allows for splitting the cipher into two subciphers, where some of the bits are allowed to be used in both of the subciphers.\nThis is done by splitting the key into three subsets instead, namely:\n\n  \n    \n      \n        \n          A\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle A_{0}}\n\n== Example ==\nThe following example is based on the attack done by Rechberger and Bogdanov on the KTANTAN cipher-family. The naming-conventions used in their paper is also used for this example. The attack reduces the computational complexity of KTANTAN32 to \n  \n    \n      \n        \n          2\n          \n            75.170\n          \n        \n      \n    \n    {\\displaystyle 2^{75.170}}\n  , down from \n  \n    \n      \n        \n          2\n          \n            80\n          \n        \n      \n    \n    {\\displaystyle 2^{80}}\n   if compared with a bruteforce attack. A computational complexity of \n  \n    \n      \n        \n          2\n          \n            75.170\n          \n        \n      \n    \n    {\\displaystyle 2^{75.170}}\n   is of 2014 still not practical to break, and the attack is thus not computationally feasible as of now. The same goes for KTANTAN48 and KTANTAN64, which complexities can be seen at the end of the example.\nThe attack is possible, due to weaknesses exploited in KTANTAN's bit-wise key-schedule. It is applicable to both KTANTAN32, KTANTAN48 and KTANTAN64, since all the variations uses the same key-schedule. It is not applicable to the related KANTAN family of block-ciphers, due to the variations in the key-schedule between KTANTAN and KANTAN.\n\n\n*** Overview of KTANTAN ***\nKTANTAN is a lightweight block-cipher, meant for constrained platforms such as RFID tags, where a cryptographic primitive such as AES, would be either impossible (given the hardware) or too expensive to implement. It was invented by Canniere, Dunkelman and Knezevic in 2009. It takes a block size of either 32, 48 or 64 bits, and encrypts it using an 80-bit key over 254 rounds. Each round utilizes two bits of the key (selected by the key schedule) as round key.\n\n\n*** Attack ***\n\n\n**** Preparation ****\nIn preparation to the attack, weaknesses in the key schedule of KTANTAN that allows the 3-subset MITM attack was identified. \nSince only two key-bits are used each round, the diffusion of the key per round is small - the safety lies in the number of rounds. Due to this structure of the key-schedule, it was possible to find a large number of consecutive rounds, which never utilized certain key-bits.\nMore precisely, the authors of the attack found that:\n\nRound 1 to 111 never uses the key-bits: \n  \n    \n      \n        \n          k\n          \n            32\n          \n        \n        ,\n        \n          k\n          \n            39\n          \n        \n        ,\n        \n          k\n          \n            44\n          \n        \n        ,\n        \n          k\n          \n            61\n          \n        \n        ,\n        \n          k\n          \n            66\n          \n        \n        ,\n        \n          k\n          \n            75\n          \n        \n      \n    \n    {\\displaystyle k_{32},k_{39},k_{44},k_{61},k_{66},k_{75}}\n  \nRound 131 to 254 never uses the key-bits: \n  \n    \n      \n        \n          k\n          \n            3\n          \n        \n        ,\n        \n          k\n          \n            20\n          \n        \n        ,\n        \n          k\n          \n            41\n          \n        \n        ,\n        \n          k\n          \n            47\n          \n        \n        ,\n        \n          k\n          \n            63\n          \n        \n        ,\n        \n          k\n          \n            74\n          \n        \n      \n    \n    {\\displaystyle k_{3},k_{20},k_{41},k_{47},k_{63},k_{74}}\n  This characteristics of the key-schedule is used for staging the 3-subset MITM attack, as we now are able to split the cipher into two blocks with independent key-bits. The parameters for the attack are thus: \n\n  \n    \n      \n        \n          A\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle A_{0}}\n\nQuestion: Is the 3-subset MITM attack applicable to the KANTAN family of block-ciphers?\n\nAnswer:",
    "context": "",
    "output": "No, the 3-subset MITM attack is not applicable to the KANTAN family of block-ciphers due to the variations in the key-schedule between KTANTAN and KANTAN.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Is the 3-subset MITM attack applicable to the KANTAN family of block-ciphers?",
      "answer": "No, the 3-subset MITM attack is not applicable to the KANTAN family of block-ciphers due to the variations in the key-schedule between KTANTAN and KANTAN.",
      "context": "3-subset meet-in-the-middle attack\n\n==Introduction==\nThe 3-subset meet-in-the-middle (hereafter shortened MITM) attack is a variant of the generic meet-in-the-middle attack, which is used in cryptology for hash and block cipher cryptanalysis. The 3-subset variant opens up the possibility to apply MITM attacks on ciphers, where it is not trivial to divide the keybits into two independent key-spaces, as required by the MITM attack.\nThe 3-subset variant relaxes the restriction for the key-spaces to be independent, by moving the intersecting parts of the keyspaces into a subset, which contains the keybits common between the two key-spaces.\n\n\n\n== Procedure ==\nAs with general MITM attacks, the attack is split into two phases: A key-reducing phase and a key-verification phase. In the first phase, the domain of key-candidates is reduced, by applying the MITM attack. In the second phase, the found key-candidates are tested on another plain-/ciphertext pair to filter away the wrong key(s).\n\n\n*** Key-reducing phase ***\nIn the key-reducing phase, the attacked cipher is split into two subciphers, \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n   and \n  \n    \n      \n        g\n      \n    \n    {\\displaystyle g}\n  , with each their independent keybits, as is normal with MITM attacks. Instead of having to conform to the limitation that the keybits of the two subciphers should be independent, the 3-subset attack allows for splitting the cipher into two subciphers, where some of the bits are allowed to be used in both of the subciphers.\nThis is done by splitting the key into three subsets instead, namely:\n\n  \n    \n      \n        \n          A\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle A_{0}}\n\n== Example ==\nThe following example is based on the attack done by Rechberger and Bogdanov on the KTANTAN cipher-family. The naming-conventions used in their paper is also used for this example. The attack reduces the computational complexity of KTANTAN32 to \n  \n    \n      \n        \n          2\n          \n            75.170\n          \n        \n      \n    \n    {\\displaystyle 2^{75.170}}\n  , down from \n  \n    \n      \n        \n          2\n          \n            80\n          \n        \n      \n    \n    {\\displaystyle 2^{80}}\n   if compared with a bruteforce attack. A computational complexity of \n  \n    \n      \n        \n          2\n          \n            75.170\n          \n        \n      \n    \n    {\\displaystyle 2^{75.170}}\n   is of 2014 still not practical to break, and the attack is thus not computationally feasible as of now. The same goes for KTANTAN48 and KTANTAN64, which complexities can be seen at the end of the example.\nThe attack is possible, due to weaknesses exploited in KTANTAN's bit-wise key-schedule. It is applicable to both KTANTAN32, KTANTAN48 and KTANTAN64, since all the variations uses the same key-schedule. It is not applicable to the related KANTAN family of block-ciphers, due to the variations in the key-schedule between KTANTAN and KANTAN.\n\n\n*** Overview of KTANTAN ***\nKTANTAN is a lightweight block-cipher, meant for constrained platforms such as RFID tags, where a cryptographic primitive such as AES, would be either impossible (given the hardware) or too expensive to implement. It was invented by Canniere, Dunkelman and Knezevic in 2009. It takes a block size of either 32, 48 or 64 bits, and encrypts it using an 80-bit key over 254 rounds. Each round utilizes two bits of the key (selected by the key schedule) as round key.\n\n\n*** Attack ***\n\n\n**** Preparation ****\nIn preparation to the attack, weaknesses in the key schedule of KTANTAN that allows the 3-subset MITM attack was identified. \nSince only two key-bits are used each round, the diffusion of the key per round is small - the safety lies in the number of rounds. Due to this structure of the key-schedule, it was possible to find a large number of consecutive rounds, which never utilized certain key-bits.\nMore precisely, the authors of the attack found that:\n\nRound 1 to 111 never uses the key-bits: \n  \n    \n      \n        \n          k\n          \n            32\n          \n        \n        ,\n        \n          k\n          \n            39\n          \n        \n        ,\n        \n          k\n          \n            44\n          \n        \n        ,\n        \n          k\n          \n            61\n          \n        \n        ,\n        \n          k\n          \n            66\n          \n        \n        ,\n        \n          k\n          \n            75\n          \n        \n      \n    \n    {\\displaystyle k_{32},k_{39},k_{44},k_{61},k_{66},k_{75}}\n  \nRound 131 to 254 never uses the key-bits: \n  \n    \n      \n        \n          k\n          \n            3\n          \n        \n        ,\n        \n          k\n          \n            20\n          \n        \n        ,\n        \n          k\n          \n            41\n          \n        \n        ,\n        \n          k\n          \n            47\n          \n        \n        ,\n        \n          k\n          \n            63\n          \n        \n        ,\n        \n          k\n          \n            74\n          \n        \n      \n    \n    {\\displaystyle k_{3},k_{20},k_{41},k_{47},k_{63},k_{74}}\n  This characteristics of the key-schedule is used for staging the 3-subset MITM attack, as we now are able to split the cipher into two blocks with independent key-bits. The parameters for the attack are thus: \n\n  \n    \n      \n        \n          A\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle A_{0}}"
    }
  },
  {
    "instruction": "Global Commission on the Stability of Cyberspace\n\n==Introduction==\nThe Global Commission on the Stability of Cyberspace was a multistakeholder Internet governance organization, dedicated to the creation of diplomatic norms of governmental non-aggression in cyberspace. It operated for three years, from 2017 through 2019, and produced the diplomatic norm for which it was chartered and seven others.\n\n== Origins ==\nTogether with the Global Forum on Cyber Expertise, the GCSC was a product of the 2015-2017 Dutch chairmanship of the London Process, and particularly the work of Wouter Jurgens who, as head of the cyber security department of the Dutch Ministry of Foreign Affairs, had responsibility for organizing the 4th Global Conference on CyberSpace ministerial, which was held in The Hague April 16\u201317 of 2015, and formalizing its outcomes. Jurgens had been working for several years on the topic of governmental non-aggression in cyberspace, in collaboration with Uri Rosenthal, Bill Woodcock, Olaf Kolkman, James Lewis, and others who would subsequently become GCSC commissioners.The GCSC was launched by Dutch Foreign Minister Bert Koenders at the 53rd Munich Security Conference, on February 18, 2017, with a three-year charter, and issued its final report at the Paris Peace Forum, on November 13, 2019.\n\n== Published norms ==\n\n\n*** Norm to Protect the Public Core of the Internet ***\n\"State and non-state actors should neither conduct nor knowingly allow activity that intentionally and substantially damages the general availability or integrity of the public core of the Internet, and therefore the stability of cyberspace.\"\nThe Norm to Protect the Public Core is the GCSC's principal product, and has been included or referenced in many subsequent legislative and diplomatic work. It was included in the European Union's Cybersecurity Act, which extends the mandate of the European Union Agency for Cybersecurity to include the protection of the public core. The Paris Call for Trust and Security in Cyberspace included a call for compliance with the Public Core norm. The United Nations cites the Public Core norm in the 2019 report of the Secretary General and the report of the Secretary General\u2019s High-level Panel on Digital Cooperation, The Age of Digital Interdependence.\n\n\n*** Norm to Protect the Electoral Infrastructure ***\n\"State and non-state actors must not pursue, support or allow cyber operations intended to disrupt the technical infrastructure essential to elections, referenda or plebiscites.\"\n\n\n*** Norm to Avoid Tampering ***\n\"State and non-state actors should not tamper with products and services in development and production, nor allow them to be tampered with, if doing so may substantially impair the stability of cyberspace.\"\n\n\n*** Norm Against Commandeering of ICT Devices into Botnets ***\n\"State and non-state actors should not commandeer the general public\u2019s ICT resources for use as botnets or for similar purposes.\"\n\n\n*** Norm for States to Create a Vulnerabilities Equities Process ***\n\"States should create procedurally transparent frameworks to assess whether and when to disclose not publicly known vulnerabilities or flaws they are aware of in information systems and technologies. The default presumption should be in favor of disclosure.\"\n\n\n*** Norm to Reduce and Mitigate Significant Vulnerabilities ***\n\"Developers and producers of products and services on which the stability of cyberspace depends should (1) prioritize security and stability, (2) take reasonable steps to ensure that their products or services are free from significant vulnerabilities, and (3) take measures to timely mitigate vulnerabilities that are later discovered and to be transparent about their process. All actors have a duty to share information on vulnerabilities in order to help prevent or mitigate malicious cyber activity.\"\n\n\n*** Norm on Basic Cyber Hygiene as Foundation Defense ***\n\"States should enact appropriate measures, including laws and regulations, to ensure basic cyber hygiene.\"\n\n\n*** Norm Against Offensive Cyber Operations by Non-State Actors ***\n\"Non-state actors should not engage in offensive cyber operations and state actors should prevent such activities and respond if they occur.\"\n\n== Other publications ==\nIn addition to the Norm to Protect the Public Core and the seven subsequent norms, the GCSC has published several other documents.\n\n\n*** Definition of the Public Core, to which the Norm Applies ***\nEarly in the process of defining the Norm to Protect the Public Core the effort was divided into two working groups, one, principally diplomatic, to specify what actions should be precluded; the other, involving subject-matter experts, to specify which infrastructures were deemed most worthy of protection. This latter working group specified a survey of cybersecurity experts, delegated implementation of the survey to Packet Clearing House, and integrated its results to form the Definition of the Public Core, to which the Norm Applies. This definition of the \"public core of the Internet\" to include packet routing and forwarding, naming and numbering systems, the cryptographic mechanisms of security and identity, and physical transmission media, with more-specific details attending to each, has since been used by the OECD and others as a standardized description of the principal elements of Internet critical infrastructure.\n\n\n*** Statement on the Interpretation of the Norm on Non-Interference with the Public Core ***\nOn September 22, 2021, the GCSC released a three-page statement responding, in large part, to Russia's submission to the ITU Council Working Group on International Internet-related Public Policy Issues, Risk Analysis of the Existing Internet Governance and Operational Model. The statement reiterates the GCSC's findings that state actors are the primary threat to Internet stability, not private actors; that the GCSC believes that the multistakeholder model of Internet governance is key to maintaining Internet stability, and that the Internet's critical infrastructure is principally operated by the private sector.\n\n== Derivative work ==\nIn addition to the norms the commission published, several other organizations were created and efforts undertaken as byproducts of the commission's work.\n\n\n*** CyberPeace Institute ***\nOne of the most notable derivative outcomes of the GCSC's work was the formation of the CyberPeace Institute, headed by GCSC commissioner Marietje Schaake and Europol veteran St\u00e9phane Duguin. This independent, non governmental organization has the mission to highlight the human aspect of cyberattacks. It works in close collaboration with relevant partners to reduce the harms from cyberattacks on people\u2019s lives worldwide. The Institute builds on the GCSC's work by monitoring compliance with its norms and coordinating cyber-attack forensic and analytic efforts that broaden public understanding of norm violations.\n\n\n*** Critical infrastructure assessment ***\nAs input to the Definition of the Public Core, a global survey of Internet infrastructure security experts was conducted in 2017 by Packet Clearing House, headed by GCSC commissioner Bill Woodcock.\n\n== Participants ==\n\n\n*** Commissioners ***\nMarina Kaljurand (Co-chair 2017-2018)\nLatha Reddy (Co-chair 2017-2019)\nMichael Chertoff (Co-chair 2019)\nMotohiro Tsuchiya\nJoseph Nye\nChristopher Painter\nIlya Sachkov\nJeff Moss\nKhoo Boon Hui\nAnriette Esterhuysen\nXiadong Lee\nAbdul-Hakeem Ajijola\nVirgilio Almeida\nMarietje Schaake\nBill Woodcock\nWolfgang Kleinw\u00e4chter\nScott Charney\nElina Noor\nIsaac Ben-Israel\nJonathan Zittrain\nNigel Inkster\nJane Holl Lute\nSamir Saran\n\n\n*** Former commissioners ***\nWilliam Saito\nWolff Heintschel von Heinegg\nSigrid Kaag\nHugo Zylerberg\n\n\n*** Research Advisory Group ***\nSean Kanuck (Chair)\nLiis Vihul (Deputy Chair for Law)\nMarilia Maciel (Deputy Chair for Internet Governance)\nHugo Zylberberg (Deputy Chair for International Peace & Security)\nKoichiro Komiyama (Deputy Chair for Technical and Information Security)\n\n\n*** Secretariat ***\nBruce McConnell (EastWest Institute)\nAlexander Klimburg (Hague Centre for Strategic Studies)\nQuestion: What is the main objective of the Global Commission on the Stability of Cyberspace (GCSC)?",
    "context": "",
    "output": "Answer: The Global Commission on the Stability of Cyberspace is dedicated to the creation of diplomatic norms of governmental non-aggression in cyberspace, with the goal of enhancing the stability and security of the internet.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the main objective of the Global Commission on the Stability of Cyberspace (GCSC)?",
      "answer": "The Global Commission on the Stability of Cyberspace is dedicated to the creation of diplomatic norms of governmental non-aggression in cyberspace, with the goal of enhancing the stability and security of the internet.",
      "context": "Global Commission on the Stability of Cyberspace\n\n==Introduction==\nThe Global Commission on the Stability of Cyberspace was a multistakeholder Internet governance organization, dedicated to the creation of diplomatic norms of governmental non-aggression in cyberspace. It operated for three years, from 2017 through 2019, and produced the diplomatic norm for which it was chartered and seven others.\n\n== Origins ==\nTogether with the Global Forum on Cyber Expertise, the GCSC was a product of the 2015-2017 Dutch chairmanship of the London Process, and particularly the work of Wouter Jurgens who, as head of the cyber security department of the Dutch Ministry of Foreign Affairs, had responsibility for organizing the 4th Global Conference on CyberSpace ministerial, which was held in The Hague April 16\u201317 of 2015, and formalizing its outcomes. Jurgens had been working for several years on the topic of governmental non-aggression in cyberspace, in collaboration with Uri Rosenthal, Bill Woodcock, Olaf Kolkman, James Lewis, and others who would subsequently become GCSC commissioners.The GCSC was launched by Dutch Foreign Minister Bert Koenders at the 53rd Munich Security Conference, on February 18, 2017, with a three-year charter, and issued its final report at the Paris Peace Forum, on November 13, 2019.\n\n== Published norms ==\n\n\n*** Norm to Protect the Public Core of the Internet ***\n\"State and non-state actors should neither conduct nor knowingly allow activity that intentionally and substantially damages the general availability or integrity of the public core of the Internet, and therefore the stability of cyberspace.\"\nThe Norm to Protect the Public Core is the GCSC's principal product, and has been included or referenced in many subsequent legislative and diplomatic work. It was included in the European Union's Cybersecurity Act, which extends the mandate of the European Union Agency for Cybersecurity to include the protection of the public core. The Paris Call for Trust and Security in Cyberspace included a call for compliance with the Public Core norm. The United Nations cites the Public Core norm in the 2019 report of the Secretary General and the report of the Secretary General\u2019s High-level Panel on Digital Cooperation, The Age of Digital Interdependence.\n\n\n*** Norm to Protect the Electoral Infrastructure ***\n\"State and non-state actors must not pursue, support or allow cyber operations intended to disrupt the technical infrastructure essential to elections, referenda or plebiscites.\"\n\n\n*** Norm to Avoid Tampering ***\n\"State and non-state actors should not tamper with products and services in development and production, nor allow them to be tampered with, if doing so may substantially impair the stability of cyberspace.\"\n\n\n*** Norm Against Commandeering of ICT Devices into Botnets ***\n\"State and non-state actors should not commandeer the general public\u2019s ICT resources for use as botnets or for similar purposes.\"\n\n\n*** Norm for States to Create a Vulnerabilities Equities Process ***\n\"States should create procedurally transparent frameworks to assess whether and when to disclose not publicly known vulnerabilities or flaws they are aware of in information systems and technologies. The default presumption should be in favor of disclosure.\"\n\n\n*** Norm to Reduce and Mitigate Significant Vulnerabilities ***\n\"Developers and producers of products and services on which the stability of cyberspace depends should (1) prioritize security and stability, (2) take reasonable steps to ensure that their products or services are free from significant vulnerabilities, and (3) take measures to timely mitigate vulnerabilities that are later discovered and to be transparent about their process. All actors have a duty to share information on vulnerabilities in order to help prevent or mitigate malicious cyber activity.\"\n\n\n*** Norm on Basic Cyber Hygiene as Foundation Defense ***\n\"States should enact appropriate measures, including laws and regulations, to ensure basic cyber hygiene.\"\n\n\n*** Norm Against Offensive Cyber Operations by Non-State Actors ***\n\"Non-state actors should not engage in offensive cyber operations and state actors should prevent such activities and respond if they occur.\"\n\n== Other publications ==\nIn addition to the Norm to Protect the Public Core and the seven subsequent norms, the GCSC has published several other documents.\n\n\n*** Definition of the Public Core, to which the Norm Applies ***\nEarly in the process of defining the Norm to Protect the Public Core the effort was divided into two working groups, one, principally diplomatic, to specify what actions should be precluded; the other, involving subject-matter experts, to specify which infrastructures were deemed most worthy of protection. This latter working group specified a survey of cybersecurity experts, delegated implementation of the survey to Packet Clearing House, and integrated its results to form the Definition of the Public Core, to which the Norm Applies. This definition of the \"public core of the Internet\" to include packet routing and forwarding, naming and numbering systems, the cryptographic mechanisms of security and identity, and physical transmission media, with more-specific details attending to each, has since been used by the OECD and others as a standardized description of the principal elements of Internet critical infrastructure.\n\n\n*** Statement on the Interpretation of the Norm on Non-Interference with the Public Core ***\nOn September 22, 2021, the GCSC released a three-page statement responding, in large part, to Russia's submission to the ITU Council Working Group on International Internet-related Public Policy Issues, Risk Analysis of the Existing Internet Governance and Operational Model. The statement reiterates the GCSC's findings that state actors are the primary threat to Internet stability, not private actors; that the GCSC believes that the multistakeholder model of Internet governance is key to maintaining Internet stability, and that the Internet's critical infrastructure is principally operated by the private sector.\n\n== Derivative work ==\nIn addition to the norms the commission published, several other organizations were created and efforts undertaken as byproducts of the commission's work.\n\n\n*** CyberPeace Institute ***\nOne of the most notable derivative outcomes of the GCSC's work was the formation of the CyberPeace Institute, headed by GCSC commissioner Marietje Schaake and Europol veteran St\u00e9phane Duguin. This independent, non governmental organization has the mission to highlight the human aspect of cyberattacks. It works in close collaboration with relevant partners to reduce the harms from cyberattacks on people\u2019s lives worldwide. The Institute builds on the GCSC's work by monitoring compliance with its norms and coordinating cyber-attack forensic and analytic efforts that broaden public understanding of norm violations.\n\n\n*** Critical infrastructure assessment ***\nAs input to the Definition of the Public Core, a global survey of Internet infrastructure security experts was conducted in 2017 by Packet Clearing House, headed by GCSC commissioner Bill Woodcock.\n\n== Participants ==\n\n\n*** Commissioners ***\nMarina Kaljurand (Co-chair 2017-2018)\nLatha Reddy (Co-chair 2017-2019)\nMichael Chertoff (Co-chair 2019)\nMotohiro Tsuchiya\nJoseph Nye\nChristopher Painter\nIlya Sachkov\nJeff Moss\nKhoo Boon Hui\nAnriette Esterhuysen\nXiadong Lee\nAbdul-Hakeem Ajijola\nVirgilio Almeida\nMarietje Schaake\nBill Woodcock\nWolfgang Kleinw\u00e4chter\nScott Charney\nElina Noor\nIsaac Ben-Israel\nJonathan Zittrain\nNigel Inkster\nJane Holl Lute\nSamir Saran\n\n\n*** Former commissioners ***\nWilliam Saito\nWolff Heintschel von Heinegg\nSigrid Kaag\nHugo Zylerberg\n\n\n*** Research Advisory Group ***\nSean Kanuck (Chair)\nLiis Vihul (Deputy Chair for Law)\nMarilia Maciel (Deputy Chair for Internet Governance)\nHugo Zylberberg (Deputy Chair for International Peace & Security)\nKoichiro Komiyama (Deputy Chair for Technical and Information Security)\n\n\n*** Secretariat ***\nBruce McConnell (EastWest Institute)\nAlexander Klimburg (Hague Centre for Strategic Studies)"
    }
  },
  {
    "instruction": "Answer based on context:\n\nMonth of bugs\n\n==Introduction==\nA month of bugs is a strategy used by security researchers to draw attention to the lax security procedures of commercial software corporations.\nResearchers have started such a project for software products where they believe corporations have shown themselves to be unresponsive and uncooperative to security alerts. Responsible disclosure is not working properly, and then find and disclose one security vulnerability each day for one month.\n\n\n\n== Examples ==\nThe original \"Month of Bugs\" was the Month of Browser Bugs (MoBB) run by security researcher H. D. Moore.Subsequent similar projects include:\n\nThe Month of Kernel Bugs (MoKB) which published kernel bugs for Mac OS X (now macOS), Linux, FreeBSD, Solaris and Windows, as well as four wireless driver bugs.\nThe Month of Apple Bugs (MoAB) conducted by researchers Kevin Finisterre and LMH which published bugs related to Mac OS X.\nThe Month of PHP Bugs sponsored by the Hardened PHP team which published 44 PHP bugs.\n\nWhat is the role of end-users in mitigating the risks associated with the \"Month of Bugs\" strategy?",
    "context": "",
    "output": "End-users play a critical role in mitigating the risks associated with the \"Month of Bugs\" strategy by staying informed about security vulnerabilities and updates, practicing good security habits, and applying patches and updates as soon as they become available. By taking a proactive approach to security, end-users can reduce their exposure to potential threats and help to ensure the overall security and integrity of their systems and data.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of end-users in mitigating the risks associated with the \"Month of Bugs\" strategy?",
      "answer": "End-users play a critical role in mitigating the risks associated with the \"Month of Bugs\" strategy by staying informed about security vulnerabilities and updates, practicing good security habits, and applying patches and updates as soon as they become available. By taking a proactive approach to security, end-users can reduce their exposure to potential threats and help to ensure the overall security and integrity of their systems and data.",
      "context": "Month of bugs\n\n==Introduction==\nA month of bugs is a strategy used by security researchers to draw attention to the lax security procedures of commercial software corporations.\nResearchers have started such a project for software products where they believe corporations have shown themselves to be unresponsive and uncooperative to security alerts. Responsible disclosure is not working properly, and then find and disclose one security vulnerability each day for one month.\n\n\n\n== Examples ==\nThe original \"Month of Bugs\" was the Month of Browser Bugs (MoBB) run by security researcher H. D. Moore.Subsequent similar projects include:\n\nThe Month of Kernel Bugs (MoKB) which published kernel bugs for Mac OS X (now macOS), Linux, FreeBSD, Solaris and Windows, as well as four wireless driver bugs.\nThe Month of Apple Bugs (MoAB) conducted by researchers Kevin Finisterre and LMH which published bugs related to Mac OS X.\nThe Month of PHP Bugs sponsored by the Hardened PHP team which published 44 PHP bugs."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the purpose of the counter in the Master Password algorithm?",
    "context": "",
    "output": "The counter in the Master Password algorithm is an integer that can be incremented when the service requests a new password. It is used in the generation of the template seed.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the purpose of the counter in the Master Password algorithm?",
      "answer": "The counter in the Master Password algorithm is an integer that can be incremented when the service requests a new password. It is used in the generation of the template seed."
    }
  },
  {
    "instruction": "Computer security compromised by hardware failure\n\n==Introduction==\nComputer security compromised by hardware failure is a branch of computer security applied to hardware.\nThe objective of computer security includes protection of information and property from theft, corruption, or natural disaster, while allowing the information and property to remain accessible and productive to its intended users. Such secret information could be retrieved by different ways. This article focus on the retrieval of data thanks to misused hardware or hardware failure. Hardware could be misused or exploited to get secret data. This article collects main types of attack that can lead to data theft.\nComputer security can be comprised by devices, such as keyboards, monitors or printers (thanks to electromagnetic or acoustic emanation for example) or by components of the computer, such as the memory, the network card or the processor (thanks to time or temperature analysis for example).\n\n\n\n== Devices ==\n\n\n*** Monitor ***\nThe monitor is the main device used to access data on a computer.  It has been shown that monitors radiate or reflect data on their environment, potentially giving attackers access to information displayed on the monitor.\n\n\n**** Electromagnetic emanations ****\nVideo display units radiate:\n\nnarrowband harmonics of the digital clock signals ;\nbroadband harmonics of the various 'random' digital signals such as the video signal.Known as compromising emanations or TEMPEST radiation, a code word for a U.S. government programme aimed at attacking the problem, the electromagnetic broadcast of data has been a significant concern in sensitive computer applications. Eavesdroppers can reconstruct video screen content from radio frequency emanations. Each (radiated) harmonic of the video signal shows a remarkable resemblance to a broadcast TV signal. It is therefore possible to reconstruct the picture displayed on the video display unit from the radiated emission by means of a normal television receiver. If no preventive measures are taken, eavesdropping on a video display unit is possible at distances up to several hundreds of meters, using only a normal black-and-white TV receiver, a directional antenna and an antenna amplifier. It is even possible to pick up information from some types of video display units at a distance of over 1 kilometer. If more sophisticated receiving and decoding equipment is used, the maximum distance can be much greater.\n\n\n**** Compromising reflections ****\nWhat is displayed by the monitor is reflected on the environment. The time-varying diffuse reflections of the light emitted by a CRT monitor can be exploited to recover the original monitor image.  This is an eavesdropping technique for spying at a distance on data that is displayed on an arbitrary computer screen, including the currently prevalent LCD monitors.\nThe technique exploits reflections of the screen's optical emanations in various objects that one commonly finds in close proximity to the screen and uses those reflections to recover the original screen content. Such objects include eyeglasses, tea pots, spoons, plastic bottles, and even the eye of the user. This attack can be successfully mounted to spy on even small fonts using inexpensive, off-the-shelf equipment (less than 1500 dollars) from a distance of up to 10 meters. Relying on more expensive equipment allowed to conduct this attack from over 30 meters away, demonstrating that similar attacks are feasible from the other side of the street or from a close by building.Many objects that may be found at a usual workplace can be exploited to retrieve information on a computer's display by an outsider. Particularly good results were obtained from reflections in a user's eyeglasses or a tea pot located on the desk next to the screen. Reflections that stem from the eye of the user also provide good results. However, eyes are harder to spy on at a distance because they are fast-moving objects and require high exposure times. Using more expensive equipment with lower exposure times helps to remedy this problem.The reflections gathered from curved surfaces on close by objects indeed pose a substantial threat to the confidentiality of data displayed on the screen. Fully invalidating this threat without at the same time hiding the screen from the legitimate user seems difficult, without using curtains on the windows or similar forms of strong optical shielding. Most users, however, will not be aware of this risk and may not be willing to close the curtains on a nice day. The reflection of an object, a computer display, in a curved mirror creates a virtual image that is located behind the reflecting surface. For a flat mirror this virtual image has the same size and is located behind the mirror at the same distance as the original object. For curved mirrors, however, the situation is more complex.\n\n\n*** Keyboard ***\n\n\n**** Electromagnetic emanations ****\nComputer keyboards are often used to transmit confidential data such as passwords. Since they contain electronic components, keyboards emit electromagnetic waves. These emanations could reveal sensitive information such as keystrokes. Electromagnetic emanations have turned out to constitute a security threat to computer equipment. The figure below presents how a keystroke is retrieved and what material is necessary.\n\nThe approach is to acquire the raw signal directly from the antenna and to process the entire captured electromagnetic spectrum. Thanks to this method, four different kinds of compromising electromagnetic emanations have been detected, generated by wired and wireless keyboards. These emissions lead to a full or a partial recovery of the keystrokes. The best practical attack fully recovered 95% of the keystrokes of a PS/2 keyboard at a distance up to 20 meters, even through walls. Because each keyboard has a specific fingerprint based on the clock frequency inconsistencies, it can determine the source keyboard of a compromising emanation, even if multiple keyboards from the same model are used at the same time.The four different kinds way of compromising electromagnetic emanations are described below.\n\n\n***** The Falling Edge Transition Technique*****\nWhen a key is pressed, released or held down, the keyboard sends a packet of information known as a scan code to the computer. The protocol used to transmit these scan codes is a bidirectional serial communication, based on four wires: Vcc (5 volts), ground, data and clock. Clock and data signals are identically generated. Hence, the compromising emanation detected is the combination of both signals. However, the edges of the data and the clock lines are not superposed. Thus, they can be easily separated to obtain independent signals.\n\n\n***** The Generalized Transition Technique*****\nThe Falling Edge Transition attack is limited to a partial recovery of the keystrokes. This is a significant limitation. The GTT is a falling edge transition attack improved, which recover almost all keystrokes. Indeed, between two traces, there is exactly one data rising edge. If attackers are able to detect this transition, they can fully recover the keystrokes.\n\n\n***** The Modulation Technique*****\nHarmonics compromising electromagnetic emissions come from unintentional emanations such as radiations emitted by the clock, non-linear elements, crosstalk, ground pollution, etc. Determining theoretically the reasons of these compromising radiations is a very complex task. These harmonics correspond to a carrier of approximately 4 MHz which is very likely the internal clock of the micro-controller inside the keyboard. These harmonics are correlated with both clock and data signals, which describe modulated signals (in amplitude and frequency) and the full state of both clock and data signals. This means that the scan code can be completely recovered from these harmonics.\n\n\n***** The Matrix Scan Technique*****\nKeyboard manufacturers arrange the keys in a matrix. The keyboard controller, often an 8-bit processor, parses columns one-by-one and recovers the state of 8 keys at once. This matrix scan process can be described as 192 keys (some keys may not be used, for instance modern keyboards use 104/105 keys) arranged in 24 columns and 8 rows. These columns are continuously pulsed one-by-one for at least 3\u03bcs. Thus, these leads may act as an antenna and generate electromagnetic emanations. If an attacker is able to capture these emanations, he can easily recover the column of the pressed key. Even if this signal does not fully describe the pressed key, it still gives partial information on the transmitted scan code, i.e. the column number.Note that the matrix scan routine loops continuously. When no key is pressed, we still have a signal composed of multiple equidistant peaks. These emanations may be used to remotely detect the presence of powered computers. Concerning wireless keyboards, the wireless data burst transmission can be used as an electromagnetic trigger to detect exactly when a key is pressed, while the matrix scan emanations are used to determine the column it belongs to.\n\n\n***** Summary*****\nSome techniques can only target some keyboards. This table sums up which technique could be used to find keystroke for different kind of keyboard.\n\nIn their paper called \"Compromising Electromagnetic Emanations of Wired and Wireless Keyboards\", Martin Vuagnoux and Sylvain Pasini tested 12 different keyboard models, with PS/2, USB connectors and wireless communication in different setups: a semi-anechoic chamber, a small office, an adjacent office and a flat in a building. The table below presents their results.\n\n\n**** Acoustic emanations ****\nAttacks against emanations caused by human typing have attracted interest in recent years. In particular, works showed that keyboard acoustic emanations do leak information that can be exploited to reconstruct the typed text.PC keyboards, notebook keyboards are vulnerable to attacks based on differentiating the sound emanated by different keys. This attack takes as input an audio signal containing a recording of a single word typed by a single person on a keyboard, and a dictionary of words. It is assumed that the typed word is present in the dictionary. The aim of the attack is to reconstruct the original word from the signal. This attack, taking as input a 10-minute sound recording of a user typing English text using a keyboard, and then recovering up to 96% of typed characters. This attack is inexpensive because the other hardware required is a parabolic microphone and non-invasive because it does not require physical intrusion into the system. The attack employs a neural network to recognize the key being pressed. It combines signal processing and efficient data structures and algorithms, to successfully reconstruct single words of 7-13 characters from a recording of the clicks made when typing them on a keyboard. The sound of clicks can differ slightly from key to key, because the keys are positioned at different positions on the keyboard plate, although the clicks of different keys sound similar to the human ear.On average, there were only 0.5 incorrect recognitions per 20 clicks, which shows the exposure of keyboard to the eavesdropping using this attack.\nThe attack is very efficient, taking under 20 seconds per word on a standard PC. A 90% or better success rate of finding the correct word for words of 10 or more characters, and a success rate of 73% over all the words tested. In practice, a human attacker can typically determine if text is random. An attacker can also identify occasions when the user types user names and passwords. Short audio signals containing a single word, with seven or more characters long was considered. This means that the signal is only a few seconds long. Such short words are often chosen as a password. The dominant factors affecting the attack's success are the word length, and more importantly, the number of repeated characters within the word.This is a procedure that makes it possible to efficiently uncover a word out of audio recordings of keyboard click sounds. More recently, extracting information out of another type of emanations was demonstrated: acoustic emanations from mechanical devices such as dot-matrix printers.\n\n\n**** Video Eavesdropping on Keyboard ****\nWhile extracting private information by watching somebody typing on a keyboard might seem to be an easy task, it becomes extremely challenging if it has to be automated. However, an automated tool is needed in the case of long-lasting surveillance procedures or long user activity, as a human being is able to reconstruct only a few characters per minute. The paper \"ClearShot: Eavesdropping on Keyboard Input from Video\" presents a novel approach to automatically recovering the text being typed on a keyboard, based solely on a video of the user typing.Automatically recognizing the keys being pressed by a user is a hard problem that requires sophisticated motion analysis. Experiments show that, for a human, reconstructing a few sentences requires lengthy hours of slow-motion analysis of the video. The attacker might install a surveillance device in the room of the victim, might take control of an existing camera by exploiting a vulnerability in the camera's control software, or might simply point a mobile phone with an integrated camera at the laptop's keyboard when the victim is working in a public space.Balzarotti's analysis is divided into two main phases (figure below).\nThe first phase analyzes the video recorded by the camera using computer vision techniques. For each frame of the video, the computer vision analysis computes the set of keys that were likely pressed, the set of keys that were certainly not pressed, and the position of space characters. Because the results of this phase of the analysis are noisy, a second phase, called the text analysis, is required. The goal of this phase is to remove errors using both language and context-sensitive techniques. The result of this phase is the reconstructed text, where each word is represented by a list of possible candidates, ranked by likelihood.\n\n\n*** Printer ***\n\n\n**** Acoustic emanations ****\nWith acoustic emanations, an attack that recovers what a dot-matrix printer processing English text is printing is possible. It is based on a record of the sound the printer makes, if the microphone is close enough to it. This attack recovers up to 72% of printed words, and up to 95% if knowledge about the text are done, with a microphone at a distance of 10 cm from the printer.After an upfront training phase (\"a\" in the picture below), the attack (\"b\" in the picture below) is fully automated and uses a combination of machine learning, audio processing, and speech recognition techniques, including spectrum features, Hidden Markov Models and linear classification. The fundamental reason why the reconstruction of the printed text works is that, the emitted sound becomes louder if more needles strike the paper at a given time. There is a correlation between the number of needles and the intensity of the acoustic emanation.A training phase was conducted where words from a dictionary are printed and characteristic sound features of these words are extracted and stored in a database. The trained characteristic features was used to recognize the printed English text. But, this task is not trivial. Major challenges include :\n\nIdentifying and extracting sound features that suitably capture the acoustic emanation of dot-matrix printers;\nCompensating for the blurred and overlapping features that are induced by the substantial decay time of the emanations;\nIdentifying and eliminating wrongly recognized words to increase the overall percentage of correctly identified words (recognition rate).\n\n== Computer components ==\n\n\n*** Network Interface Card ***\n\n\n**** Timing attack ****\nTiming attacks enable an attacker to extract secrets maintained in a security system by observing the time it takes the system to respond to various queries.SSH is designed to provide a secure channel between two hosts. Despite the encryption and authentication mechanisms it uses, SSH has weaknesses. In interactive mode, every individual keystroke that a user types is sent to the remote machine in a separate IP packet immediately after the key is pressed, which leaks the inter-keystroke timing information of users\u2019 typing. Below, the picture represents the command su processed through a SSH connection.\n\nA very simple statistical techniques suffice to reveal sensitive information such as the length of users\u2019 passwords or even root passwords. By using advanced statistical techniques on timing information collected from the network, the eavesdropper can learn significant information about what users type in SSH sessions. Because the time it takes the operating system to send out the packet after the keypress is in general negligible comparing to the interkeystroke timing, this also enables an eavesdropper to learn the precise interkeystroke timings of users\u2019 typing from the arrival times of packets.\n\n\n*** Memory ***\n\n\n**** Physical chemistry ****\nData remanence problems not only affect obvious areas such as RAM and non-volatile memory cells but can also occur in other areas of the device through hot-carrier effects (which change the characteristics of the semiconductors in the device) and various other effects which are examined alongside the more obvious memory-cell remanence problems. It is possible to analyse and recover data from these cells and from semiconductor devices in general long after it should (in theory) have vanished.Electromigration, which means to physically move the atom to new locations (to physically alter the device itself) is another type of attack. It involves the relocation of metal atoms due to high current densities, a phenomenon in which atoms are carried along by an \"electron wind\" in the opposite direction to the conventional current, producing voids at the negative electrode and hillocks and whiskers at the positive electrode. Void formation leads to a local increase in current density and Joule heating (the interaction of electrons and metal ions to produce thermal energy), producing further electromigration effects. When the external stress is removed, the disturbed system tends to relax back to its original equilibrium state, resulting in a backflow which heals some of the electromigration damage. In the long term though, this can cause device failure, but in less extreme cases it simply serves to alter a device's operating characteristics in noticeable ways.\nFor example, the excavations of voids leads to increased wiring resistance and the growth of whiskers leads to contact formation and current leakage. An example of a conductor which exhibits whisker growth due to electromigration is shown in the figure below:\n\nOne example which exhibits void formation (in this case severe enough to have led to complete failure) is shown in this figure:\n\n\n**** Temperature ****\nContrary to popular assumption, DRAMs used in most modern computers retain their contents for several seconds after power is lost, even at room temperature and even if removed from a motherboard.Many products do cryptographic and other security-related computations using secret keys or other variables that the equipment's operator must not be able to read out or alter. The usual solution is for the secret data to be kept in volatile memory inside a tamper-sensing enclosure. Security processors typically store secret key material in static RAM, from which power is removed if the device is tampered with. At temperatures below \u221220 \u00b0C, the contents of SRAM can be \u2018frozen\u2019. It is interesting to know the period of time for which a static RAM device will retain data once the power has been removed. Low temperatures can increase the data retention time of SRAM to many seconds or even minutes.\n\n\n**** Read/Write exploits thanks to FireWire ****\nMaximillian Dornseif presented a technique in these slides, which let him take the control of an Apple computer thanks to an iPod. The attacks needed a first generic phase where the iPod software was modified so that it behaves as master on the FireWire bus. Then the iPod had full read/write access on the Apple Computer when the iPod was plugged into a FireWire port. FireWire is used by : audio devices, printers, scanners, cameras, gps, etc. Generally, a device connected by FireWire has full access (read/write). Indeed, OHCI Standard (FireWire standard) reads :\n\nPhysical requests, including physical read, physical write and lock requests to some CSR registers (section 5.5), are handled directly by the Host Controller without assistance by system software.\nSo, any device connected by FireWire can read and write data on the computer memory. For example, a device can :\n\nGrab the screen contents ;\nJust search the memory for strings such as login, passwords ;\nScan for possible key material ;\nSearch cryptographic keys stored in RAM ;\nParse the whole physical memory to understand logical memory layout.or\n\nMess up the memory ;\nChange screen content ;\nChange UID/GID of a certain process ;\nInject code into a process ;\nInject an additional process.\n\n\n*** Processor ***\n\n\n**** Cache attack ****\nTo increase the computational power, processors are generally equipped with a cache memory which decreases the memory access latency. Below, the figure shows the hierarchy between the processor and the memory. First the processor looks for data in the cache L1, then L2, then in the memory.\n\nWhen the data is not where the processor is looking for, it is called a cache-miss. Below, pictures show how the processor fetch data when there are two cache levels.\n\nUnfortunately caches contain only a small portion of the application data and can introduce additional latency to the memory transaction in the case of a miss. This involves also additional power consumption which is due to the activation of memory devices down in the memory hierarchy. The miss penalty has been already used to attack symmetric encryption algorithms, like DES. The basic idea proposed in this paper is to force a cache miss while the processor is executing the AES encryption algorithm on a known plain text. The attacks allow an unprivileged process to attack other process running in parallel on the same processor, despite partitioning methods such as memory protection, sandboxing and virtualization.\n\n\n**** Timing attack ****\nBy carefully measuring the amount of time required to perform private key operations, attackers may be able to find fixed Diffie-Hellman exponents, factor RSA keys, and break other cryptosystems. Against a vulnerable system, the attack is computationally inexpensive and often requires only known ciphertext.\nThe attack can be treated as a signal detection problem. The signal consists of the timing variation due to the target exponent bit, and noise results from measurement inaccuracies and timing variations due to unknown exponent bits. The properties of the signal and noise determine the number of timing measurements required to for the attack. Timing attacks can potentially be used against other cryptosystems, including symmetric functions.\n\n\n**** Privilege escalation ****\n\nA simple and generic processor backdoor can be used by attackers as a means to privilege escalation to get to privileges equivalent to those of any given running operating system. Also, a non-privileged process of one of the non-privileged invited domain running on top of a virtual machine monitor can get to privileges equivalent to those of the virtual machine monitor.Lo\u00efc Duflot studied Intel processors in the paper \"CPU bugs, CPU backdoors and consequences on security\" ; he explains that the processor defines four different privilege rings numbered from 0 (most privileged) to 3 (least privileged). Kernel code is usually running in ring 0, whereas user-space code is generally running in ring 3. The use of some security-critical assembly language instructions is restricted to ring 0 code. In order to escalate privilege through the backdoor, the attacker must :\nactivate the backdoor by placing the CPU in the desired state ;\ninject code and run it in ring 0 ;\nget back to ring 3 in order to return the system to a stable state. Indeed, when code is running in ring 0, system calls do not work : Leaving the system in ring 0 and running a random system call (exit() typically) is likely to crash the system.The backdoors Lo\u00efc Duflot presents are simple as they only modify the behavior of three assembly language instructions and have very simple and specific activation conditions, so that they are very unlikely to be accidentally activated. Recent inventions have begun to target these types of processor-based escalation attacks.\n\n== Bibliography ==\n\n\n*** Acoustic ***\nAsonov, D.; Agrawal, R. (2004). \"Keyboard acoustic emanations\". IEEE Symposium on Security and Privacy, 2004. Proceedings. 2004. Proceedings 2004 IEEE Symposium on Security and Privacy. pp. 3\u201311. CiteSeerX 10.1.1.89.8231. doi:10.1109/SECPRI.2004.1301311. ISBN 978-0-7695-2136-7. ISSN 1081-6011. S2CID 216795.\nZhuang, Li; Zhou, Feng; Tygar, J.D. (2005). \"Keyboard acoustic emanations revisited\". ACM Transactions on Information and System Security (TISSEC). Proceedings of the 12th ACM Conference on Computer and Communications Security. ACM Transactions on Information Systems. Vol. 13, no. 1. Alexandria, Virginia, USA: ACM New York, NY, USA. pp. 373\u2013382. CiteSeerX 10.1.1.117.5791. doi:10.1145/1609956.1609959. ISBN 978-1-59593-226-6. ISSN 1094-9224.\nBerger, Yigael; Wool, Avishai; Yeredor, Arie (2006). \"Dictionary attacks using keyboard acoustic emanations\". Proceedings of the 13th ACM conference on Computer and communications security \u2013 CCS '06. Proceedings of the 13th ACM Conference on Computer and Communications Security. Alexandria, Virginia, USA: ACM New York, NY, USA. pp. 245\u2013254. CiteSeerX 10.1.1.99.8028. doi:10.1145/1180405.1180436. ISBN 978-1-59593-518-2. S2CID 2596394.\nBackes, Michael; D\u00fcrmuth, Markus; Gerling, Sebastian; Pinkal, Manfred; Sporleder, Caroline (2010), \"Acoustic Side-Channel Attacks on Printers\" (PDF), Proceedings of the 19th USENIX Security Symposium, Washington, DC, ISBN 978-1-931971-77-5\n\n\n*** Cache attack ***\nOsvik, Dag Arne; Shamir, Adi; Tromer, Eran (2006). \"Cache Attacks and Countermeasures: The Case of AES\". Topics in Cryptology \u2013 CT-RSA 2006. Topics in Cryptology CT-RSA. Lecture Notes in Computer Science. Vol. 3860. San Jose, California, USA: Springer-Verlag Berlin, Heidelberg. pp. 1\u201320. CiteSeerX 10.1.1.60.1857. doi:10.1007/11605805_1. ISBN 978-3-540-31033-4. ISSN 0302-9743.\nPage, Daniel (2005), \"Partitioned cache architecture as a side-channel defence mechanism\" (PDF), Cryptology ePrint Archive\nBertoni, Guido; Zaccaria, Vittorio; Breveglieri, Luca; Monchiero, Matteo; Palermo, Gianluca (2005). \"AES power attack based on induced cache miss and countermeasure\" (PDF). International Conference on Information Technology: Coding and Computing (ITCC'05) \u2013 Volume II. International Conference on Information Technology: Coding and Computing (ITCC'05). Vol. 1. Washington, DC, USA: IEEE Computer Society, Los Alamitos, California, USA. pp. 586\u2013591. CiteSeerX 10.1.1.452.3319. doi:10.1109/ITCC.2005.62. ISBN 978-0-7695-2315-6. S2CID 9364961.\n\n\n*** Chemical ***\nGutmann, Peter (2001), \"Data Remanence in Semiconductor Devices\" (PDF), Proceedings of the 10th Conference on USENIX Security Symposium SSYM'01, USENIX Association Berkeley, California, USA, vol. 10, p. 4, archived from the original (PDF) on 2007-02-21, retrieved 2010-12-13\n\n\n*** Electromagnetic ***\nKuhn, Markus G.; Anderson, Ross J. (1998). \"Soft Tempest: Hidden Data Transmission Using Electromagnetic Emanations\". Information Hiding. Lecture Notes in Computer Science. Lecture Notes in Computer Science. Vol. 1525. pp. 124\u2013142. CiteSeerX 10.1.1.64.6982. doi:10.1007/3-540-49380-8_10. ISBN 978-3-540-65386-8.\nVan Eck, Wim; Laborato, Neher (1985), \"Electromagnetic Radiation from Video Display Units: An Eavesdropping Risk?\", Computers & Security, vol. 4, no. 4, pp. 269\u2013286, CiteSeerX 10.1.1.35.1695, doi:10.1016/0167-4048(85)90046-X\nKuhn, Markus G. (2002). \"Optical time-domain eavesdropping risks of CRT displays\". Proceedings 2002 IEEE Symposium on Security and Privacy. Proceedings of the 2002 IEEE Symposium on Security and Privacy. pp. 3\u2013. CiteSeerX 10.1.1.7.5870. doi:10.1109/SECPRI.2002.1004358. ISBN 978-0-7695-1543-4. S2CID 2385507.\nVuagnoux, Martin; Pasini, Sylvain (2009), \"Compromising electromagnetic emanations of wired and wireless keyboards\" (PDF), In Proceedings of the 18th Conference on USENIX Security Symposium (SSYM'09), pp. 1\u201316\nBackes, Michael; D\u00fcrmuth, Markus; Unruh, Dominique (2008). \"Optical time-domain eavesdropping risks of CRT displays\" (PDF). Compromising Reflections-or-How to Read LCD Monitors around the Corner. Proceedings of the IEEE Symposium on Security and Privacy. Oakland, California, USA. pp. 158\u2013169. CiteSeerX 10.1.1.7.5870. doi:10.1109/SECPRI.2002.1004358. ISBN 978-0-7695-3168-7. S2CID 2385507.\n\n\n*** FireWire ***\nDornseif, Maximillian (2004), \"0wned by an iPod\" (PDF), PacSec\nDornseif, Maximillian (2005), \"FireWire all your memory are belong to us\" (PDF), CanSecWest, archived from the original (PDF) on 2009-12-29, retrieved 2010-12-17\n\n\n*** Processor bug and backdoors ***\nDuflot, Lo\u00efc (2008). \"CPU Bugs, CPU Backdoors and Consequences on Security\". Computer Security - ESORICS 2008. ESORICS '08 Proceedings of the 13th European Symposium on Research in Computer Security: Computer Security. Lecture Notes in Computer Science. Vol. 5283. pp. 580\u2013599. doi:10.1007/978-3-540-88313-5_37. ISBN 978-3-540-88312-8.\nDuflot, Lo\u00efc (2008), \"Using CPU System Management Mode to Circumvent Operating System Security Functions\" (PDF), Proceedings of CanSecWest, pp. 580\u2013599, archived from the original (PDF) on 2006-05-26\nWaksman, Adam (2010), \"Tamper Evident Microprocessors\" (PDF), Proceedings of the IEEE Symposium on Security and Privacy, Oakland, California, archived from the original (PDF) on 2013-09-21\n\n\n*** Temperature ***\nSkorobogatov, Sergei (2002), \"Low temperature data remanence in static RAM\" (PDF), Technical Report - University of Cambridge. Computer Laboratory, Cambridge, UK: University of Cambridge Computer Laboratory, ISSN 1476-2986\nHalderman, J. Alex; Schoen, Seth D.; Heninger, Nadia; Clarkson, William; Paul, William; Calandrino, Joseph A.; Feldman, Ariel J.; Appelbaum, Jacob; Felten, Edward W. (2008). \"Lest We Remember: Cold Boot Attacks on Encryption Keys\". Communications of the ACM \u2013 Security in the Browser (PDF). Proceedings of the USENIX Security Symposium. Vol. 52. ACM New York, New York, USA. pp. 45\u201360. doi:10.1145/1506409.1506429. ISBN 978-1-931971-60-7. ISSN 0001-0782. S2CID 7770695. Archived from the original (PDF) on 2011-09-04.\n\n\n*** Timing attacks ***\nSong, Dawn Xiaodong; Wagner, David; Tian, Xuqing (2001), \"Timing analysis of keystrokes and timing attacks on SSH\" (PDF), Proceedings of the 10th Conference on USENIX Security Symposium, Washington, D.C., USA: USENIX Association Berkeley, California, USA, vol. 10, pp. 337\u2013352\nKocher, Paul C. (1996). \"Timing Attacks on Implementations of Diffie-Hellman, RSA, DSS, and Other Systems\". Advances in Cryptology \u2013 CRYPTO '96. Proceedings of the 16th Annual International Cryptology Conference on Advances in Cryptology \u2013 CRYPTO '96. Lecture Notes in Computer Science. Vol. 1109. Santa Barbara, California, USA: Springer-Verlag, London, UK. pp. 104\u2013113. CiteSeerX 10.1.1.40.5024. doi:10.1007/3-540-68697-5_9. ISBN 978-3-540-61512-5.\nBrumley, David; Boneh, Dan (2003), \"Remote timing attacks are practical\" (PDF), Proceedings of the 12th Conference on USENIX Security Symposium SSYM'03, Washington, DC, USA: USENIX Association Berkeley, California, USA, vol. 12, no. 5, p. 701, CiteSeerX 10.1.1.12.2615, doi:10.1016/j.comnet.2005.01.010\n\n\n*** Other ***\nBalzarotti, D.; Cova, M.; Vigna, G. (2008). \"Clear Shot: Eavesdropping on Keyboard Input from Video\". 2008 IEEE Symposium on Security and Privacy (sp 2008). Security and Privacy, 2008. SP 2008. IEEE Symposium on. Oakland, CA. pp. 170\u2013183. CiteSeerX 10.1.1.219.239. doi:10.1109/SP.2008.28. ISBN 978-0-7695-3168-7. ISSN 1081-6011. S2CID 1498613.\nDuflot, Lo\u00efc (2007), Contribution \u00e0 la s\u00e9curit\u00e9 des syst\u00e8mes d'exploitation et des microprocesseurs (PDF) (in French)\nQ: How do electromagnetic emanations from keyboards pose a security threat?",
    "context": "",
    "output": "Electromagnetic emanations from keyboards can reveal sensitive information such as keystrokes, which can lead to a full or partial recovery of the keystrokes. This can be used to determine the source keyboard of a compromising emanation, even if multiple keyboards from the same model are used at the same time.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do electromagnetic emanations from keyboards pose a security threat?",
      "answer": "Electromagnetic emanations from keyboards can reveal sensitive information such as keystrokes, which can lead to a full or partial recovery of the keystrokes. This can be used to determine the source keyboard of a compromising emanation, even if multiple keyboards from the same model are used at the same time.",
      "context": "Computer security compromised by hardware failure\n\n==Introduction==\nComputer security compromised by hardware failure is a branch of computer security applied to hardware.\nThe objective of computer security includes protection of information and property from theft, corruption, or natural disaster, while allowing the information and property to remain accessible and productive to its intended users. Such secret information could be retrieved by different ways. This article focus on the retrieval of data thanks to misused hardware or hardware failure. Hardware could be misused or exploited to get secret data. This article collects main types of attack that can lead to data theft.\nComputer security can be comprised by devices, such as keyboards, monitors or printers (thanks to electromagnetic or acoustic emanation for example) or by components of the computer, such as the memory, the network card or the processor (thanks to time or temperature analysis for example).\n\n\n\n== Devices ==\n\n\n*** Monitor ***\nThe monitor is the main device used to access data on a computer.  It has been shown that monitors radiate or reflect data on their environment, potentially giving attackers access to information displayed on the monitor.\n\n\n**** Electromagnetic emanations ****\nVideo display units radiate:\n\nnarrowband harmonics of the digital clock signals ;\nbroadband harmonics of the various 'random' digital signals such as the video signal.Known as compromising emanations or TEMPEST radiation, a code word for a U.S. government programme aimed at attacking the problem, the electromagnetic broadcast of data has been a significant concern in sensitive computer applications. Eavesdroppers can reconstruct video screen content from radio frequency emanations. Each (radiated) harmonic of the video signal shows a remarkable resemblance to a broadcast TV signal. It is therefore possible to reconstruct the picture displayed on the video display unit from the radiated emission by means of a normal television receiver. If no preventive measures are taken, eavesdropping on a video display unit is possible at distances up to several hundreds of meters, using only a normal black-and-white TV receiver, a directional antenna and an antenna amplifier. It is even possible to pick up information from some types of video display units at a distance of over 1 kilometer. If more sophisticated receiving and decoding equipment is used, the maximum distance can be much greater.\n\n\n**** Compromising reflections ****\nWhat is displayed by the monitor is reflected on the environment. The time-varying diffuse reflections of the light emitted by a CRT monitor can be exploited to recover the original monitor image.  This is an eavesdropping technique for spying at a distance on data that is displayed on an arbitrary computer screen, including the currently prevalent LCD monitors.\nThe technique exploits reflections of the screen's optical emanations in various objects that one commonly finds in close proximity to the screen and uses those reflections to recover the original screen content. Such objects include eyeglasses, tea pots, spoons, plastic bottles, and even the eye of the user. This attack can be successfully mounted to spy on even small fonts using inexpensive, off-the-shelf equipment (less than 1500 dollars) from a distance of up to 10 meters. Relying on more expensive equipment allowed to conduct this attack from over 30 meters away, demonstrating that similar attacks are feasible from the other side of the street or from a close by building.Many objects that may be found at a usual workplace can be exploited to retrieve information on a computer's display by an outsider. Particularly good results were obtained from reflections in a user's eyeglasses or a tea pot located on the desk next to the screen. Reflections that stem from the eye of the user also provide good results. However, eyes are harder to spy on at a distance because they are fast-moving objects and require high exposure times. Using more expensive equipment with lower exposure times helps to remedy this problem.The reflections gathered from curved surfaces on close by objects indeed pose a substantial threat to the confidentiality of data displayed on the screen. Fully invalidating this threat without at the same time hiding the screen from the legitimate user seems difficult, without using curtains on the windows or similar forms of strong optical shielding. Most users, however, will not be aware of this risk and may not be willing to close the curtains on a nice day. The reflection of an object, a computer display, in a curved mirror creates a virtual image that is located behind the reflecting surface. For a flat mirror this virtual image has the same size and is located behind the mirror at the same distance as the original object. For curved mirrors, however, the situation is more complex.\n\n\n*** Keyboard ***\n\n\n**** Electromagnetic emanations ****\nComputer keyboards are often used to transmit confidential data such as passwords. Since they contain electronic components, keyboards emit electromagnetic waves. These emanations could reveal sensitive information such as keystrokes. Electromagnetic emanations have turned out to constitute a security threat to computer equipment. The figure below presents how a keystroke is retrieved and what material is necessary.\n\nThe approach is to acquire the raw signal directly from the antenna and to process the entire captured electromagnetic spectrum. Thanks to this method, four different kinds of compromising electromagnetic emanations have been detected, generated by wired and wireless keyboards. These emissions lead to a full or a partial recovery of the keystrokes. The best practical attack fully recovered 95% of the keystrokes of a PS/2 keyboard at a distance up to 20 meters, even through walls. Because each keyboard has a specific fingerprint based on the clock frequency inconsistencies, it can determine the source keyboard of a compromising emanation, even if multiple keyboards from the same model are used at the same time.The four different kinds way of compromising electromagnetic emanations are described below.\n\n\n***** The Falling Edge Transition Technique*****\nWhen a key is pressed, released or held down, the keyboard sends a packet of information known as a scan code to the computer. The protocol used to transmit these scan codes is a bidirectional serial communication, based on four wires: Vcc (5 volts), ground, data and clock. Clock and data signals are identically generated. Hence, the compromising emanation detected is the combination of both signals. However, the edges of the data and the clock lines are not superposed. Thus, they can be easily separated to obtain independent signals.\n\n\n***** The Generalized Transition Technique*****\nThe Falling Edge Transition attack is limited to a partial recovery of the keystrokes. This is a significant limitation. The GTT is a falling edge transition attack improved, which recover almost all keystrokes. Indeed, between two traces, there is exactly one data rising edge. If attackers are able to detect this transition, they can fully recover the keystrokes.\n\n\n***** The Modulation Technique*****\nHarmonics compromising electromagnetic emissions come from unintentional emanations such as radiations emitted by the clock, non-linear elements, crosstalk, ground pollution, etc. Determining theoretically the reasons of these compromising radiations is a very complex task. These harmonics correspond to a carrier of approximately 4 MHz which is very likely the internal clock of the micro-controller inside the keyboard. These harmonics are correlated with both clock and data signals, which describe modulated signals (in amplitude and frequency) and the full state of both clock and data signals. This means that the scan code can be completely recovered from these harmonics.\n\n\n***** The Matrix Scan Technique*****\nKeyboard manufacturers arrange the keys in a matrix. The keyboard controller, often an 8-bit processor, parses columns one-by-one and recovers the state of 8 keys at once. This matrix scan process can be described as 192 keys (some keys may not be used, for instance modern keyboards use 104/105 keys) arranged in 24 columns and 8 rows. These columns are continuously pulsed one-by-one for at least 3\u03bcs. Thus, these leads may act as an antenna and generate electromagnetic emanations. If an attacker is able to capture these emanations, he can easily recover the column of the pressed key. Even if this signal does not fully describe the pressed key, it still gives partial information on the transmitted scan code, i.e. the column number.Note that the matrix scan routine loops continuously. When no key is pressed, we still have a signal composed of multiple equidistant peaks. These emanations may be used to remotely detect the presence of powered computers. Concerning wireless keyboards, the wireless data burst transmission can be used as an electromagnetic trigger to detect exactly when a key is pressed, while the matrix scan emanations are used to determine the column it belongs to.\n\n\n***** Summary*****\nSome techniques can only target some keyboards. This table sums up which technique could be used to find keystroke for different kind of keyboard.\n\nIn their paper called \"Compromising Electromagnetic Emanations of Wired and Wireless Keyboards\", Martin Vuagnoux and Sylvain Pasini tested 12 different keyboard models, with PS/2, USB connectors and wireless communication in different setups: a semi-anechoic chamber, a small office, an adjacent office and a flat in a building. The table below presents their results.\n\n\n**** Acoustic emanations ****\nAttacks against emanations caused by human typing have attracted interest in recent years. In particular, works showed that keyboard acoustic emanations do leak information that can be exploited to reconstruct the typed text.PC keyboards, notebook keyboards are vulnerable to attacks based on differentiating the sound emanated by different keys. This attack takes as input an audio signal containing a recording of a single word typed by a single person on a keyboard, and a dictionary of words. It is assumed that the typed word is present in the dictionary. The aim of the attack is to reconstruct the original word from the signal. This attack, taking as input a 10-minute sound recording of a user typing English text using a keyboard, and then recovering up to 96% of typed characters. This attack is inexpensive because the other hardware required is a parabolic microphone and non-invasive because it does not require physical intrusion into the system. The attack employs a neural network to recognize the key being pressed. It combines signal processing and efficient data structures and algorithms, to successfully reconstruct single words of 7-13 characters from a recording of the clicks made when typing them on a keyboard. The sound of clicks can differ slightly from key to key, because the keys are positioned at different positions on the keyboard plate, although the clicks of different keys sound similar to the human ear.On average, there were only 0.5 incorrect recognitions per 20 clicks, which shows the exposure of keyboard to the eavesdropping using this attack.\nThe attack is very efficient, taking under 20 seconds per word on a standard PC. A 90% or better success rate of finding the correct word for words of 10 or more characters, and a success rate of 73% over all the words tested. In practice, a human attacker can typically determine if text is random. An attacker can also identify occasions when the user types user names and passwords. Short audio signals containing a single word, with seven or more characters long was considered. This means that the signal is only a few seconds long. Such short words are often chosen as a password. The dominant factors affecting the attack's success are the word length, and more importantly, the number of repeated characters within the word.This is a procedure that makes it possible to efficiently uncover a word out of audio recordings of keyboard click sounds. More recently, extracting information out of another type of emanations was demonstrated: acoustic emanations from mechanical devices such as dot-matrix printers.\n\n\n**** Video Eavesdropping on Keyboard ****\nWhile extracting private information by watching somebody typing on a keyboard might seem to be an easy task, it becomes extremely challenging if it has to be automated. However, an automated tool is needed in the case of long-lasting surveillance procedures or long user activity, as a human being is able to reconstruct only a few characters per minute. The paper \"ClearShot: Eavesdropping on Keyboard Input from Video\" presents a novel approach to automatically recovering the text being typed on a keyboard, based solely on a video of the user typing.Automatically recognizing the keys being pressed by a user is a hard problem that requires sophisticated motion analysis. Experiments show that, for a human, reconstructing a few sentences requires lengthy hours of slow-motion analysis of the video. The attacker might install a surveillance device in the room of the victim, might take control of an existing camera by exploiting a vulnerability in the camera's control software, or might simply point a mobile phone with an integrated camera at the laptop's keyboard when the victim is working in a public space.Balzarotti's analysis is divided into two main phases (figure below).\nThe first phase analyzes the video recorded by the camera using computer vision techniques. For each frame of the video, the computer vision analysis computes the set of keys that were likely pressed, the set of keys that were certainly not pressed, and the position of space characters. Because the results of this phase of the analysis are noisy, a second phase, called the text analysis, is required. The goal of this phase is to remove errors using both language and context-sensitive techniques. The result of this phase is the reconstructed text, where each word is represented by a list of possible candidates, ranked by likelihood.\n\n\n*** Printer ***\n\n\n**** Acoustic emanations ****\nWith acoustic emanations, an attack that recovers what a dot-matrix printer processing English text is printing is possible. It is based on a record of the sound the printer makes, if the microphone is close enough to it. This attack recovers up to 72% of printed words, and up to 95% if knowledge about the text are done, with a microphone at a distance of 10 cm from the printer.After an upfront training phase (\"a\" in the picture below), the attack (\"b\" in the picture below) is fully automated and uses a combination of machine learning, audio processing, and speech recognition techniques, including spectrum features, Hidden Markov Models and linear classification. The fundamental reason why the reconstruction of the printed text works is that, the emitted sound becomes louder if more needles strike the paper at a given time. There is a correlation between the number of needles and the intensity of the acoustic emanation.A training phase was conducted where words from a dictionary are printed and characteristic sound features of these words are extracted and stored in a database. The trained characteristic features was used to recognize the printed English text. But, this task is not trivial. Major challenges include :\n\nIdentifying and extracting sound features that suitably capture the acoustic emanation of dot-matrix printers;\nCompensating for the blurred and overlapping features that are induced by the substantial decay time of the emanations;\nIdentifying and eliminating wrongly recognized words to increase the overall percentage of correctly identified words (recognition rate).\n\n== Computer components ==\n\n\n*** Network Interface Card ***\n\n\n**** Timing attack ****\nTiming attacks enable an attacker to extract secrets maintained in a security system by observing the time it takes the system to respond to various queries.SSH is designed to provide a secure channel between two hosts. Despite the encryption and authentication mechanisms it uses, SSH has weaknesses. In interactive mode, every individual keystroke that a user types is sent to the remote machine in a separate IP packet immediately after the key is pressed, which leaks the inter-keystroke timing information of users\u2019 typing. Below, the picture represents the command su processed through a SSH connection.\n\nA very simple statistical techniques suffice to reveal sensitive information such as the length of users\u2019 passwords or even root passwords. By using advanced statistical techniques on timing information collected from the network, the eavesdropper can learn significant information about what users type in SSH sessions. Because the time it takes the operating system to send out the packet after the keypress is in general negligible comparing to the interkeystroke timing, this also enables an eavesdropper to learn the precise interkeystroke timings of users\u2019 typing from the arrival times of packets.\n\n\n*** Memory ***\n\n\n**** Physical chemistry ****\nData remanence problems not only affect obvious areas such as RAM and non-volatile memory cells but can also occur in other areas of the device through hot-carrier effects (which change the characteristics of the semiconductors in the device) and various other effects which are examined alongside the more obvious memory-cell remanence problems. It is possible to analyse and recover data from these cells and from semiconductor devices in general long after it should (in theory) have vanished.Electromigration, which means to physically move the atom to new locations (to physically alter the device itself) is another type of attack. It involves the relocation of metal atoms due to high current densities, a phenomenon in which atoms are carried along by an \"electron wind\" in the opposite direction to the conventional current, producing voids at the negative electrode and hillocks and whiskers at the positive electrode. Void formation leads to a local increase in current density and Joule heating (the interaction of electrons and metal ions to produce thermal energy), producing further electromigration effects. When the external stress is removed, the disturbed system tends to relax back to its original equilibrium state, resulting in a backflow which heals some of the electromigration damage. In the long term though, this can cause device failure, but in less extreme cases it simply serves to alter a device's operating characteristics in noticeable ways.\nFor example, the excavations of voids leads to increased wiring resistance and the growth of whiskers leads to contact formation and current leakage. An example of a conductor which exhibits whisker growth due to electromigration is shown in the figure below:\n\nOne example which exhibits void formation (in this case severe enough to have led to complete failure) is shown in this figure:\n\n\n**** Temperature ****\nContrary to popular assumption, DRAMs used in most modern computers retain their contents for several seconds after power is lost, even at room temperature and even if removed from a motherboard.Many products do cryptographic and other security-related computations using secret keys or other variables that the equipment's operator must not be able to read out or alter. The usual solution is for the secret data to be kept in volatile memory inside a tamper-sensing enclosure. Security processors typically store secret key material in static RAM, from which power is removed if the device is tampered with. At temperatures below \u221220 \u00b0C, the contents of SRAM can be \u2018frozen\u2019. It is interesting to know the period of time for which a static RAM device will retain data once the power has been removed. Low temperatures can increase the data retention time of SRAM to many seconds or even minutes.\n\n\n**** Read/Write exploits thanks to FireWire ****\nMaximillian Dornseif presented a technique in these slides, which let him take the control of an Apple computer thanks to an iPod. The attacks needed a first generic phase where the iPod software was modified so that it behaves as master on the FireWire bus. Then the iPod had full read/write access on the Apple Computer when the iPod was plugged into a FireWire port. FireWire is used by : audio devices, printers, scanners, cameras, gps, etc. Generally, a device connected by FireWire has full access (read/write). Indeed, OHCI Standard (FireWire standard) reads :\n\nPhysical requests, including physical read, physical write and lock requests to some CSR registers (section 5.5), are handled directly by the Host Controller without assistance by system software.\nSo, any device connected by FireWire can read and write data on the computer memory. For example, a device can :\n\nGrab the screen contents ;\nJust search the memory for strings such as login, passwords ;\nScan for possible key material ;\nSearch cryptographic keys stored in RAM ;\nParse the whole physical memory to understand logical memory layout.or\n\nMess up the memory ;\nChange screen content ;\nChange UID/GID of a certain process ;\nInject code into a process ;\nInject an additional process.\n\n\n*** Processor ***\n\n\n**** Cache attack ****\nTo increase the computational power, processors are generally equipped with a cache memory which decreases the memory access latency. Below, the figure shows the hierarchy between the processor and the memory. First the processor looks for data in the cache L1, then L2, then in the memory.\n\nWhen the data is not where the processor is looking for, it is called a cache-miss. Below, pictures show how the processor fetch data when there are two cache levels.\n\nUnfortunately caches contain only a small portion of the application data and can introduce additional latency to the memory transaction in the case of a miss. This involves also additional power consumption which is due to the activation of memory devices down in the memory hierarchy. The miss penalty has been already used to attack symmetric encryption algorithms, like DES. The basic idea proposed in this paper is to force a cache miss while the processor is executing the AES encryption algorithm on a known plain text. The attacks allow an unprivileged process to attack other process running in parallel on the same processor, despite partitioning methods such as memory protection, sandboxing and virtualization.\n\n\n**** Timing attack ****\nBy carefully measuring the amount of time required to perform private key operations, attackers may be able to find fixed Diffie-Hellman exponents, factor RSA keys, and break other cryptosystems. Against a vulnerable system, the attack is computationally inexpensive and often requires only known ciphertext.\nThe attack can be treated as a signal detection problem. The signal consists of the timing variation due to the target exponent bit, and noise results from measurement inaccuracies and timing variations due to unknown exponent bits. The properties of the signal and noise determine the number of timing measurements required to for the attack. Timing attacks can potentially be used against other cryptosystems, including symmetric functions.\n\n\n**** Privilege escalation ****\n\nA simple and generic processor backdoor can be used by attackers as a means to privilege escalation to get to privileges equivalent to those of any given running operating system. Also, a non-privileged process of one of the non-privileged invited domain running on top of a virtual machine monitor can get to privileges equivalent to those of the virtual machine monitor.Lo\u00efc Duflot studied Intel processors in the paper \"CPU bugs, CPU backdoors and consequences on security\" ; he explains that the processor defines four different privilege rings numbered from 0 (most privileged) to 3 (least privileged). Kernel code is usually running in ring 0, whereas user-space code is generally running in ring 3. The use of some security-critical assembly language instructions is restricted to ring 0 code. In order to escalate privilege through the backdoor, the attacker must :\nactivate the backdoor by placing the CPU in the desired state ;\ninject code and run it in ring 0 ;\nget back to ring 3 in order to return the system to a stable state. Indeed, when code is running in ring 0, system calls do not work : Leaving the system in ring 0 and running a random system call (exit() typically) is likely to crash the system.The backdoors Lo\u00efc Duflot presents are simple as they only modify the behavior of three assembly language instructions and have very simple and specific activation conditions, so that they are very unlikely to be accidentally activated. Recent inventions have begun to target these types of processor-based escalation attacks.\n\n== Bibliography ==\n\n\n*** Acoustic ***\nAsonov, D.; Agrawal, R. (2004). \"Keyboard acoustic emanations\". IEEE Symposium on Security and Privacy, 2004. Proceedings. 2004. Proceedings 2004 IEEE Symposium on Security and Privacy. pp. 3\u201311. CiteSeerX 10.1.1.89.8231. doi:10.1109/SECPRI.2004.1301311. ISBN 978-0-7695-2136-7. ISSN 1081-6011. S2CID 216795.\nZhuang, Li; Zhou, Feng; Tygar, J.D. (2005). \"Keyboard acoustic emanations revisited\". ACM Transactions on Information and System Security (TISSEC). Proceedings of the 12th ACM Conference on Computer and Communications Security. ACM Transactions on Information Systems. Vol. 13, no. 1. Alexandria, Virginia, USA: ACM New York, NY, USA. pp. 373\u2013382. CiteSeerX 10.1.1.117.5791. doi:10.1145/1609956.1609959. ISBN 978-1-59593-226-6. ISSN 1094-9224.\nBerger, Yigael; Wool, Avishai; Yeredor, Arie (2006). \"Dictionary attacks using keyboard acoustic emanations\". Proceedings of the 13th ACM conference on Computer and communications security \u2013 CCS '06. Proceedings of the 13th ACM Conference on Computer and Communications Security. Alexandria, Virginia, USA: ACM New York, NY, USA. pp. 245\u2013254. CiteSeerX 10.1.1.99.8028. doi:10.1145/1180405.1180436. ISBN 978-1-59593-518-2. S2CID 2596394.\nBackes, Michael; D\u00fcrmuth, Markus; Gerling, Sebastian; Pinkal, Manfred; Sporleder, Caroline (2010), \"Acoustic Side-Channel Attacks on Printers\" (PDF), Proceedings of the 19th USENIX Security Symposium, Washington, DC, ISBN 978-1-931971-77-5\n\n\n*** Cache attack ***\nOsvik, Dag Arne; Shamir, Adi; Tromer, Eran (2006). \"Cache Attacks and Countermeasures: The Case of AES\". Topics in Cryptology \u2013 CT-RSA 2006. Topics in Cryptology CT-RSA. Lecture Notes in Computer Science. Vol. 3860. San Jose, California, USA: Springer-Verlag Berlin, Heidelberg. pp. 1\u201320. CiteSeerX 10.1.1.60.1857. doi:10.1007/11605805_1. ISBN 978-3-540-31033-4. ISSN 0302-9743.\nPage, Daniel (2005), \"Partitioned cache architecture as a side-channel defence mechanism\" (PDF), Cryptology ePrint Archive\nBertoni, Guido; Zaccaria, Vittorio; Breveglieri, Luca; Monchiero, Matteo; Palermo, Gianluca (2005). \"AES power attack based on induced cache miss and countermeasure\" (PDF). International Conference on Information Technology: Coding and Computing (ITCC'05) \u2013 Volume II. International Conference on Information Technology: Coding and Computing (ITCC'05). Vol. 1. Washington, DC, USA: IEEE Computer Society, Los Alamitos, California, USA. pp. 586\u2013591. CiteSeerX 10.1.1.452.3319. doi:10.1109/ITCC.2005.62. ISBN 978-0-7695-2315-6. S2CID 9364961.\n\n\n*** Chemical ***\nGutmann, Peter (2001), \"Data Remanence in Semiconductor Devices\" (PDF), Proceedings of the 10th Conference on USENIX Security Symposium SSYM'01, USENIX Association Berkeley, California, USA, vol. 10, p. 4, archived from the original (PDF) on 2007-02-21, retrieved 2010-12-13\n\n\n*** Electromagnetic ***\nKuhn, Markus G.; Anderson, Ross J. (1998). \"Soft Tempest: Hidden Data Transmission Using Electromagnetic Emanations\". Information Hiding. Lecture Notes in Computer Science. Lecture Notes in Computer Science. Vol. 1525. pp. 124\u2013142. CiteSeerX 10.1.1.64.6982. doi:10.1007/3-540-49380-8_10. ISBN 978-3-540-65386-8.\nVan Eck, Wim; Laborato, Neher (1985), \"Electromagnetic Radiation from Video Display Units: An Eavesdropping Risk?\", Computers & Security, vol. 4, no. 4, pp. 269\u2013286, CiteSeerX 10.1.1.35.1695, doi:10.1016/0167-4048(85)90046-X\nKuhn, Markus G. (2002). \"Optical time-domain eavesdropping risks of CRT displays\". Proceedings 2002 IEEE Symposium on Security and Privacy. Proceedings of the 2002 IEEE Symposium on Security and Privacy. pp. 3\u2013. CiteSeerX 10.1.1.7.5870. doi:10.1109/SECPRI.2002.1004358. ISBN 978-0-7695-1543-4. S2CID 2385507.\nVuagnoux, Martin; Pasini, Sylvain (2009), \"Compromising electromagnetic emanations of wired and wireless keyboards\" (PDF), In Proceedings of the 18th Conference on USENIX Security Symposium (SSYM'09), pp. 1\u201316\nBackes, Michael; D\u00fcrmuth, Markus; Unruh, Dominique (2008). \"Optical time-domain eavesdropping risks of CRT displays\" (PDF). Compromising Reflections-or-How to Read LCD Monitors around the Corner. Proceedings of the IEEE Symposium on Security and Privacy. Oakland, California, USA. pp. 158\u2013169. CiteSeerX 10.1.1.7.5870. doi:10.1109/SECPRI.2002.1004358. ISBN 978-0-7695-3168-7. S2CID 2385507.\n\n\n*** FireWire ***\nDornseif, Maximillian (2004), \"0wned by an iPod\" (PDF), PacSec\nDornseif, Maximillian (2005), \"FireWire all your memory are belong to us\" (PDF), CanSecWest, archived from the original (PDF) on 2009-12-29, retrieved 2010-12-17\n\n\n*** Processor bug and backdoors ***\nDuflot, Lo\u00efc (2008). \"CPU Bugs, CPU Backdoors and Consequences on Security\". Computer Security - ESORICS 2008. ESORICS '08 Proceedings of the 13th European Symposium on Research in Computer Security: Computer Security. Lecture Notes in Computer Science. Vol. 5283. pp. 580\u2013599. doi:10.1007/978-3-540-88313-5_37. ISBN 978-3-540-88312-8.\nDuflot, Lo\u00efc (2008), \"Using CPU System Management Mode to Circumvent Operating System Security Functions\" (PDF), Proceedings of CanSecWest, pp. 580\u2013599, archived from the original (PDF) on 2006-05-26\nWaksman, Adam (2010), \"Tamper Evident Microprocessors\" (PDF), Proceedings of the IEEE Symposium on Security and Privacy, Oakland, California, archived from the original (PDF) on 2013-09-21\n\n\n*** Temperature ***\nSkorobogatov, Sergei (2002), \"Low temperature data remanence in static RAM\" (PDF), Technical Report - University of Cambridge. Computer Laboratory, Cambridge, UK: University of Cambridge Computer Laboratory, ISSN 1476-2986\nHalderman, J. Alex; Schoen, Seth D.; Heninger, Nadia; Clarkson, William; Paul, William; Calandrino, Joseph A.; Feldman, Ariel J.; Appelbaum, Jacob; Felten, Edward W. (2008). \"Lest We Remember: Cold Boot Attacks on Encryption Keys\". Communications of the ACM \u2013 Security in the Browser (PDF). Proceedings of the USENIX Security Symposium. Vol. 52. ACM New York, New York, USA. pp. 45\u201360. doi:10.1145/1506409.1506429. ISBN 978-1-931971-60-7. ISSN 0001-0782. S2CID 7770695. Archived from the original (PDF) on 2011-09-04.\n\n\n*** Timing attacks ***\nSong, Dawn Xiaodong; Wagner, David; Tian, Xuqing (2001), \"Timing analysis of keystrokes and timing attacks on SSH\" (PDF), Proceedings of the 10th Conference on USENIX Security Symposium, Washington, D.C., USA: USENIX Association Berkeley, California, USA, vol. 10, pp. 337\u2013352\nKocher, Paul C. (1996). \"Timing Attacks on Implementations of Diffie-Hellman, RSA, DSS, and Other Systems\". Advances in Cryptology \u2013 CRYPTO '96. Proceedings of the 16th Annual International Cryptology Conference on Advances in Cryptology \u2013 CRYPTO '96. Lecture Notes in Computer Science. Vol. 1109. Santa Barbara, California, USA: Springer-Verlag, London, UK. pp. 104\u2013113. CiteSeerX 10.1.1.40.5024. doi:10.1007/3-540-68697-5_9. ISBN 978-3-540-61512-5.\nBrumley, David; Boneh, Dan (2003), \"Remote timing attacks are practical\" (PDF), Proceedings of the 12th Conference on USENIX Security Symposium SSYM'03, Washington, DC, USA: USENIX Association Berkeley, California, USA, vol. 12, no. 5, p. 701, CiteSeerX 10.1.1.12.2615, doi:10.1016/j.comnet.2005.01.010\n\n\n*** Other ***\nBalzarotti, D.; Cova, M.; Vigna, G. (2008). \"Clear Shot: Eavesdropping on Keyboard Input from Video\". 2008 IEEE Symposium on Security and Privacy (sp 2008). Security and Privacy, 2008. SP 2008. IEEE Symposium on. Oakland, CA. pp. 170\u2013183. CiteSeerX 10.1.1.219.239. doi:10.1109/SP.2008.28. ISBN 978-0-7695-3168-7. ISSN 1081-6011. S2CID 1498613.\nDuflot, Lo\u00efc (2007), Contribution \u00e0 la s\u00e9curit\u00e9 des syst\u00e8mes d'exploitation et des microprocesseurs (PDF) (in French)"
    }
  },
  {
    "instruction": "Write an answer to the following question: In the context of the OMB definition of PII, can information lack context and still be considered PII?",
    "context": "",
    "output": "Yes, information can still be considered PII even if it lacks context, such as the name John Smith or a Social Security Number (SSN) without a name or any other associated identity or context information.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "In the context of the OMB definition of PII, can information lack context and still be considered PII?",
      "answer": "Yes, information can still be considered PII even if it lacks context, such as the name John Smith or a Social Security Number (SSN) without a name or any other associated identity or context information."
    }
  },
  {
    "instruction": "Answer based on context:\n\nBarracuda Networks\n\n==Introduction==\nBarracuda Networks, Inc. is a company providing security, networking and storage products based on network appliances and cloud services. The company's security products include products for protection against email, web surfing, web hackers and instant messaging threats such as spam, spyware, trojans, and viruses. The company's networking and storage products include web filtering, load balancing, application delivery controllers, message archiving, NG firewalls, backup services and data protection.\n\n== Products ==\nIn chronological order:\n\nEmail Security Gateway - In October 2003, Barracuda announced its spam and virus firewall plug-in appliance. In June 2008, Barracuda launched a spam and virus firewall for large enterprises and ISPs.\nWeb Security Gateway - In April 2005, the company introduced its web filtering appliance to prevent spyware and viruses from gathering and transmitting user data, and to control web surfing.\nLoad balancer ADC - In November 2006, the company introduced a load balancing appliance for high availability distribution of network traffic across multiple servers.\nMessage Archiver - In July 2007, the company introduced message archiving to index and preserve emails, and to meet legal and regulatory compliance.\nSSL VPN & Remote Access - In November 2008, the company launched its secure sockets layer virtual private network product to provide secure, clientless, remote access.\nWeb Application Firewall - Announced in February 2008, for securing Web applications for large enterprises and to address regulation compliance such as PCI DSS.\nLink Balancer - Announced in September 2008, to optimize and aggregate internet connections from different providers, is currently End Of Life.\nBarracuda Backup - In November 2008, the company announced a service to back up data in the cloud, including on-site backup with data deduplication and off-site data replication for disaster recovery. In January 2009, Barracuda added message-level backup for Microsoft Exchange and Novell GroupWise, integrating Barracuda Backup Service with Yosemite Backup, formerly Tapeware.\nWeb Security Service - In October 2009, in conjunction with its acquisition of Purewire, Barracuda Networks launched the Purewire Web Security Service which is a software as a service offering for Web filtering, content security, and safe web surfing.\nNextGen Firewall - In February 2010, Barracuda announced its NextGen Firewalls to protect enterprise network infrastructures. The firewalls integrate web and email filtering, intrusion prevention, layer 7 application profiling, and network access control into one platform that is centrally managed across multiple distributed enterprise network locations. NextGen Firewalls are available as a hardware appliance, virtual appliance and public cloud instance.  The product includes wide area network traffic optimization.\nCudaTel Communication Server (PBX) - in August 2010, Barracuda announced the release of CudaTel, a VOIP Private branch exchange designed for IT administrators. CudaTel features FreeSWITCH, an open-source project sponsored by Barracuda Networks.\nCopy.com was announced as a cloud storage service in February 2013. The service was discontinued on May 1, 2016.\nBarracuda Sentinel - In June 2017, Barracuda launched an artificial intelligence service to prevent spear phishing and cyber fraud.\nBarracuda Mobile Device Manager end-of-life was announced in December 2017.  The free service was launched in 2014.[2]\n\n== Acquisitions ==\nIn September 2007, Barracuda Networks acquired NetContinuum, a company providing application controllers  to secure and manage enterprise web applications.In November 2008, Barracuda Networks expanded into cloud-based backup services by acquiring BitLeap.In November 2008, Barracuda Networks acquired 3SP, allowing the company to introduce Secure Sockets Layer (SSL) Virtual Private Network (VPN) products to allow secure remote access to network file shares, internal Web sites and remote control capabilities for desktops and servers.In January 2009, Barracuda Networks acquired Yosemite Technologies to add software agents for incremental backups of applications such as Microsoft Exchange Server and SQL Server, and Windows system states.In September 2009, Barracuda Networks acquired controlling interest in phion AG, an Austria-based public company  delivering enterprise-class firewalls.In October 2009, Barracuda Networks acquired Purewire Inc, a software as a service (SaaS) company offering cloud based web filtering and security.In April 2013, Barracuda Networks acquired SignNow.In 2014, Barracuda Networks purchased C2C Systems UK.In October 2015, Barracuda Networks acquired Intronis.In November 2017, Barracuda purchased SonianIn November 2017, Barracuda announced that it was being acquired by private equity investment firm Thoma Bravo, LLC.In January 2018, Barracuda acquired PhishLine.\n\n== Controversies ==\n\n\n*** Security Issue ***\nIn January 2013, a backdoor was discovered: \"A variety of firewall, VPN, and spam filtering gear sold by Barracuda Networks contains undocumented backdoor accounts that allow people to remotely log in and access sensitive information, researchers with an Austrian security firm have warned.\" The backdoor was then secured shortly after the announcement.\n\n\n*** IP reputation and Emailreg.org ***\nOn April 13, 2009, Emailreg.org published a notice clarifying that it is a whitelist of domains that had no impact on Barracuda Blog Lists.  April 10, 2010, a blog entry appeared alleging that Barracuda Networks SPAM blocking deliberately targets non-spamming IP addresses and tries to get them to sign up for an email whitelisting service \"emailreg.org\".  In 2019 Emailreg.org announced that it was no longer accepting new customers but would continue services for existing customers until further notice.  Emailreg.org discontinued services shortly thereafter and is no longer in operation. As of May 2, 2020, the same warning appears for some IP addresses.\n\nWhat company did Barracuda Networks acquire in January 2018 for phishing and social engineering attack simulations?",
    "context": "",
    "output": "PhishLine was acquired in January 2018 for phishing and social engineering attack simulations.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What company did Barracuda Networks acquire in January 2018 for phishing and social engineering attack simulations?",
      "answer": "PhishLine was acquired in January 2018 for phishing and social engineering attack simulations.",
      "context": "Barracuda Networks\n\n==Introduction==\nBarracuda Networks, Inc. is a company providing security, networking and storage products based on network appliances and cloud services. The company's security products include products for protection against email, web surfing, web hackers and instant messaging threats such as spam, spyware, trojans, and viruses. The company's networking and storage products include web filtering, load balancing, application delivery controllers, message archiving, NG firewalls, backup services and data protection.\n\n== Products ==\nIn chronological order:\n\nEmail Security Gateway - In October 2003, Barracuda announced its spam and virus firewall plug-in appliance. In June 2008, Barracuda launched a spam and virus firewall for large enterprises and ISPs.\nWeb Security Gateway - In April 2005, the company introduced its web filtering appliance to prevent spyware and viruses from gathering and transmitting user data, and to control web surfing.\nLoad balancer ADC - In November 2006, the company introduced a load balancing appliance for high availability distribution of network traffic across multiple servers.\nMessage Archiver - In July 2007, the company introduced message archiving to index and preserve emails, and to meet legal and regulatory compliance.\nSSL VPN & Remote Access - In November 2008, the company launched its secure sockets layer virtual private network product to provide secure, clientless, remote access.\nWeb Application Firewall - Announced in February 2008, for securing Web applications for large enterprises and to address regulation compliance such as PCI DSS.\nLink Balancer - Announced in September 2008, to optimize and aggregate internet connections from different providers, is currently End Of Life.\nBarracuda Backup - In November 2008, the company announced a service to back up data in the cloud, including on-site backup with data deduplication and off-site data replication for disaster recovery. In January 2009, Barracuda added message-level backup for Microsoft Exchange and Novell GroupWise, integrating Barracuda Backup Service with Yosemite Backup, formerly Tapeware.\nWeb Security Service - In October 2009, in conjunction with its acquisition of Purewire, Barracuda Networks launched the Purewire Web Security Service which is a software as a service offering for Web filtering, content security, and safe web surfing.\nNextGen Firewall - In February 2010, Barracuda announced its NextGen Firewalls to protect enterprise network infrastructures. The firewalls integrate web and email filtering, intrusion prevention, layer 7 application profiling, and network access control into one platform that is centrally managed across multiple distributed enterprise network locations. NextGen Firewalls are available as a hardware appliance, virtual appliance and public cloud instance.  The product includes wide area network traffic optimization.\nCudaTel Communication Server (PBX) - in August 2010, Barracuda announced the release of CudaTel, a VOIP Private branch exchange designed for IT administrators. CudaTel features FreeSWITCH, an open-source project sponsored by Barracuda Networks.\nCopy.com was announced as a cloud storage service in February 2013. The service was discontinued on May 1, 2016.\nBarracuda Sentinel - In June 2017, Barracuda launched an artificial intelligence service to prevent spear phishing and cyber fraud.\nBarracuda Mobile Device Manager end-of-life was announced in December 2017.  The free service was launched in 2014.[2]\n\n== Acquisitions ==\nIn September 2007, Barracuda Networks acquired NetContinuum, a company providing application controllers  to secure and manage enterprise web applications.In November 2008, Barracuda Networks expanded into cloud-based backup services by acquiring BitLeap.In November 2008, Barracuda Networks acquired 3SP, allowing the company to introduce Secure Sockets Layer (SSL) Virtual Private Network (VPN) products to allow secure remote access to network file shares, internal Web sites and remote control capabilities for desktops and servers.In January 2009, Barracuda Networks acquired Yosemite Technologies to add software agents for incremental backups of applications such as Microsoft Exchange Server and SQL Server, and Windows system states.In September 2009, Barracuda Networks acquired controlling interest in phion AG, an Austria-based public company  delivering enterprise-class firewalls.In October 2009, Barracuda Networks acquired Purewire Inc, a software as a service (SaaS) company offering cloud based web filtering and security.In April 2013, Barracuda Networks acquired SignNow.In 2014, Barracuda Networks purchased C2C Systems UK.In October 2015, Barracuda Networks acquired Intronis.In November 2017, Barracuda purchased SonianIn November 2017, Barracuda announced that it was being acquired by private equity investment firm Thoma Bravo, LLC.In January 2018, Barracuda acquired PhishLine.\n\n== Controversies ==\n\n\n*** Security Issue ***\nIn January 2013, a backdoor was discovered: \"A variety of firewall, VPN, and spam filtering gear sold by Barracuda Networks contains undocumented backdoor accounts that allow people to remotely log in and access sensitive information, researchers with an Austrian security firm have warned.\" The backdoor was then secured shortly after the announcement.\n\n\n*** IP reputation and Emailreg.org ***\nOn April 13, 2009, Emailreg.org published a notice clarifying that it is a whitelist of domains that had no impact on Barracuda Blog Lists.  April 10, 2010, a blog entry appeared alleging that Barracuda Networks SPAM blocking deliberately targets non-spamming IP addresses and tries to get them to sign up for an email whitelisting service \"emailreg.org\".  In 2019 Emailreg.org announced that it was no longer accepting new customers but would continue services for existing customers until further notice.  Emailreg.org discontinued services shortly thereafter and is no longer in operation. As of May 2, 2020, the same warning appears for some IP addresses."
    }
  },
  {
    "instruction": "Weird machine\n\n==Introduction==\nIn computer security, a weird machine is a computational artifact where additional code execution can happen outside the original specification of the program. It is closely related to the concept of weird instructions, which are the building blocks of an exploit based on crafted input data.The concept of weird machine is a theoretical framework to understand the existence of exploits for security vulnerabilities. Exploits exist empirically, but were not studied from a theoretical perspective prior to the emergence of the framework of weird machines.\n\n\n\n== Theory ==\nFrom a theoretical perspective, the emergence of weird machines becomes clear when one considers software as a way to restrict the number of reachable states and state transitions of a computer: The general-purpose CPU is, through software, specialized to simulate a finite-state machine (with potentially very large state space). Many states the CPU could be in are excluded, and certain state transitions are ruled out - for example those that violate the software's security requirements. When the system is somehow moved into a state that \"makes no sense\" when viewed from the perspective of the intended finite-state machine (through memory corruption, hardware failure, or other programming mistakes), the software will keep transforming the broken state into new broken states, triggered by further user input. A new computational device arises: The weird machine which can reach different states of the CPU than the programmer anticipated, and which does so in reaction to inputs.\n\n== Applications ==\n\nWhile expected, valid input activates the normal, intended functionality in a computer program, input that was unexpected by the program developer may activate unintended functionality. The weird machine consists of this unintended functionality that can be programmed with selected inputs in an exploit.\nIn a classical attack taking advantage of a stack buffer overflow, the input given to a vulnerable program is crafted and delivered so that it itself becomes executed as program code. However, if the data areas of the program memory have been protected so that they cannot be executed directly like this, the input may instead take the form of pointers into pieces of existing program code that then become executed in an unexpected order to generate the functionality of the exploit. These snippets of code that are used by the exploit are referred to as gadgets in the context of return-oriented programming.\nThrough interpretation of data as code, weird machine functionality that is by definition outside the original program specification can be reached also by proof-carrying code (PCC), which has been formally proven to function in a certain specific way. This disparity is essentially caused by a disconnect between formal abstract modelling of a computer program and its real-world instance, which can be influenced by events that are not captured in the original abstraction, such as memory errors or power outages.\nWeird machine behaviors are observed even in hardware. For instance, it has been shown that one can do computation with only MOV instructions in x86.\n\n== Mitigation ==\nTwo central categories of mitigation to the problems caused by weird machine functionality include input validation within the software and protecting against problems arising from the platform on which the program runs, such as memory errors. Input validation aims to limit the scope and forms of unexpected inputs e.g. through whitelists of allowed inputs, so that the software program itself would not end up in an unexpected state by interpreting the data internally. Equally importantly, secure programming practices such as protecting against buffer overflows make it less likely that input data becomes interpreted in unintended ways by lower layers, such as the hardware on which the program is executed.\n\nQ: What is the relationship between software and finite-state machines in the context of weird machines?",
    "context": "",
    "output": "A: Software specializes the general-purpose CPU to simulate a finite-state machine with a potentially large state space, excluding many states and state transitions that violate security requirements.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the relationship between software and finite-state machines in the context of weird machines?",
      "answer": "Software specializes the general-purpose CPU to simulate a finite-state machine with a potentially large state space, excluding many states and state transitions that violate security requirements.",
      "context": "Weird machine\n\n==Introduction==\nIn computer security, a weird machine is a computational artifact where additional code execution can happen outside the original specification of the program. It is closely related to the concept of weird instructions, which are the building blocks of an exploit based on crafted input data.The concept of weird machine is a theoretical framework to understand the existence of exploits for security vulnerabilities. Exploits exist empirically, but were not studied from a theoretical perspective prior to the emergence of the framework of weird machines.\n\n\n\n== Theory ==\nFrom a theoretical perspective, the emergence of weird machines becomes clear when one considers software as a way to restrict the number of reachable states and state transitions of a computer: The general-purpose CPU is, through software, specialized to simulate a finite-state machine (with potentially very large state space). Many states the CPU could be in are excluded, and certain state transitions are ruled out - for example those that violate the software's security requirements. When the system is somehow moved into a state that \"makes no sense\" when viewed from the perspective of the intended finite-state machine (through memory corruption, hardware failure, or other programming mistakes), the software will keep transforming the broken state into new broken states, triggered by further user input. A new computational device arises: The weird machine which can reach different states of the CPU than the programmer anticipated, and which does so in reaction to inputs.\n\n== Applications ==\n\nWhile expected, valid input activates the normal, intended functionality in a computer program, input that was unexpected by the program developer may activate unintended functionality. The weird machine consists of this unintended functionality that can be programmed with selected inputs in an exploit.\nIn a classical attack taking advantage of a stack buffer overflow, the input given to a vulnerable program is crafted and delivered so that it itself becomes executed as program code. However, if the data areas of the program memory have been protected so that they cannot be executed directly like this, the input may instead take the form of pointers into pieces of existing program code that then become executed in an unexpected order to generate the functionality of the exploit. These snippets of code that are used by the exploit are referred to as gadgets in the context of return-oriented programming.\nThrough interpretation of data as code, weird machine functionality that is by definition outside the original program specification can be reached also by proof-carrying code (PCC), which has been formally proven to function in a certain specific way. This disparity is essentially caused by a disconnect between formal abstract modelling of a computer program and its real-world instance, which can be influenced by events that are not captured in the original abstraction, such as memory errors or power outages.\nWeird machine behaviors are observed even in hardware. For instance, it has been shown that one can do computation with only MOV instructions in x86.\n\n== Mitigation ==\nTwo central categories of mitigation to the problems caused by weird machine functionality include input validation within the software and protecting against problems arising from the platform on which the program runs, such as memory errors. Input validation aims to limit the scope and forms of unexpected inputs e.g. through whitelists of allowed inputs, so that the software program itself would not end up in an unexpected state by interpreting the data internally. Equally importantly, secure programming practices such as protecting against buffer overflows make it less likely that input data becomes interpreted in unintended ways by lower layers, such as the hardware on which the program is executed."
    }
  },
  {
    "instruction": "Write an answer to the following question: Can a LOIC attack be traced back to the IP addresses used?",
    "context": "",
    "output": "Yes, LOIC attacks can be traced back to the IP addresses used, making it possible to track down the origin of the attack.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Can a LOIC attack be traced back to the IP addresses used?",
      "answer": "Yes, LOIC attacks can be traced back to the IP addresses used, making it possible to track down the origin of the attack."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the role of XOR operation in the CDMF algorithm?",
    "context": "",
    "output": "The XOR operation in the CDMF algorithm is used as a key whitening step, which introduces additional complexity and randomness to the key generation process.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of XOR operation in the CDMF algorithm?",
      "answer": "The XOR operation in the CDMF algorithm is used as a key whitening step, which introduces additional complexity and randomness to the key generation process."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the open-source social VPN implementation based on the Facebook social network service and the Brunet P2P overlay support security?",
    "context": "",
    "output": "The open-source social VPN implementation based on the Facebook social network service and the Brunet P2P overlay supports security by establishing encrypted communication between two endpoints using the acquired public keys and symmetric keys exchanged during the process of establishing an end-to-end link by two social VPN peers.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the open-source social VPN implementation based on the Facebook social network service and the Brunet P2P overlay support security?",
      "answer": "The open-source social VPN implementation based on the Facebook social network service and the Brunet P2P overlay supports security by establishing encrypted communication between two endpoints using the acquired public keys and symmetric keys exchanged during the process of establishing an end-to-end link by two social VPN peers."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is a \"preplaced key\" in the context of HAIPE?",
    "context": "",
    "output": "A \"preplaced key\" in the context of HAIPE is a key that is loaded on all HAIPE devices that will participate in a multicast session in advance of data transmission. It is used to encrypt multicast data.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is a \"preplaced key\" in the context of HAIPE?",
      "answer": "A \"preplaced key\" in the context of HAIPE is a key that is loaded on all HAIPE devices that will participate in a multicast session in advance of data transmission. It is used to encrypt multicast data."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does a HIDS protect its object-database, checksum-database, and reports from tampering?",
    "context": "",
    "output": "A HIDS protects its object-database, checksum-database, and reports from tampering by using crypto-techniques, storing the databases on read-only memory devices, and sending its logs off-system immediately using VPN channels to some central management system.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does a HIDS protect its object-database, checksum-database, and reports from tampering?",
      "answer": "A HIDS protects its object-database, checksum-database, and reports from tampering by using crypto-techniques, storing the databases on read-only memory devices, and sending its logs off-system immediately using VPN channels to some central management system."
    }
  },
  {
    "instruction": "Stars virus\n\n==Introduction==\nThe Stars virus is a computer virus which infects computers running Microsoft Windows. It was named and discovered by Iranian authorities in April 2011. Iran claimed it was used as a tool to commit espionage. Western researchers came to believe it is probably the same thing as the Duqu virus, part of the Stuxnet attack on Iran.\n\n\n\nBased on the above text, answer a question. Who discovered the Stars virus and what was their conclusion about its use?",
    "context": "",
    "output": "The Stars virus was discovered by Iranian authorities in April 2011. They believed that it was used as a tool to commit espionage. Western researchers later suggested that it is likely the same as the Duqu virus, which was part of the Stuxnet attack on Iran.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Who discovered the Stars virus and what was their conclusion about its use?",
      "answer": "The Stars virus was discovered by Iranian authorities in April 2011. They believed that it was used as a tool to commit espionage. Western researchers later suggested that it is likely the same as the Duqu virus, which was part of the Stuxnet attack on Iran.",
      "context": "Stars virus\n\n==Introduction==\nThe Stars virus is a computer virus which infects computers running Microsoft Windows. It was named and discovered by Iranian authorities in April 2011. Iran claimed it was used as a tool to commit espionage. Western researchers came to believe it is probably the same thing as the Duqu virus, part of the Stuxnet attack on Iran.\n\n"
    }
  },
  {
    "instruction": "Write an answer to the following question: How did the Moonlight Maze hackers relay their connection to conceal their location?",
    "context": "",
    "output": "The hackers relayed their connection through various vulnerable institutions, such as universities and libraries, to conceal their location. The servers they hacked could only see the last location they routed through, which is called proxying.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How did the Moonlight Maze hackers relay their connection to conceal their location?",
      "answer": "The hackers relayed their connection through various vulnerable institutions, such as universities and libraries, to conceal their location. The servers they hacked could only see the last location they routed through, which is called proxying."
    }
  },
  {
    "instruction": "Answer based on context:\n\n2021 cyberattacks on Sri Lanka\n\n==Introduction==\nThe 2021 cyberattacks on Sri Lanka were a series of cyberattacks on at least 10 Sri Lankan national websites including Google.lk domain.\n\n\n\n== First Cyber-Attack ==\nThe first cyber-attack was launched on The LK Domain Registry website on 6th February 2021. The investigations are currently carried out by Sri Lanka Computer Emergency Readiness Team along with the Information Technology Society of Sri Lanka (ITSSL). Telecommunications Regulatory Commission of Sri Lanka were also tweeted regarding the Cyberattack as public alert.\n\n== Second Cyber-Attack ==\nThe second cyber-attack was carried out on 18 May 2021.  The website of the Chinese Embassy operating in Sri Lanka, The websites of the Health Ministry, Energy Ministry and the Rajarata University websites were affected by this cyberattack.  This cyber attack conducted by a group called 'Tamil Eelam Cyber Force'.\n\n== Cyber-Attack On Prime Minister Mahinda's Website ==\nThe official website of Sri Lankan Prime Minister Mahinda Rajapaksa was hacked on June 3rd 2021. \nThe Information Technology Society Sri Lanka - ITSSL said the PM\u2019s website was hacked in a manner in which any visitor to the website would be redirected to another website which displays content related to the Bitcoin cryptocurrency.\n\nWhat was the date of the first cyberattack in the 2021 cyberattacks on Sri Lanka?",
    "context": "",
    "output": "The first cyberattack in the 2021 cyberattacks on Sri Lanka occurred on February 6th, 2021.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was the date of the first cyberattack in the 2021 cyberattacks on Sri Lanka?",
      "answer": "The first cyberattack in the 2021 cyberattacks on Sri Lanka occurred on February 6th, 2021.",
      "context": "2021 cyberattacks on Sri Lanka\n\n==Introduction==\nThe 2021 cyberattacks on Sri Lanka were a series of cyberattacks on at least 10 Sri Lankan national websites including Google.lk domain.\n\n\n\n== First Cyber-Attack ==\nThe first cyber-attack was launched on The LK Domain Registry website on 6th February 2021. The investigations are currently carried out by Sri Lanka Computer Emergency Readiness Team along with the Information Technology Society of Sri Lanka (ITSSL). Telecommunications Regulatory Commission of Sri Lanka were also tweeted regarding the Cyberattack as public alert.\n\n== Second Cyber-Attack ==\nThe second cyber-attack was carried out on 18 May 2021.  The website of the Chinese Embassy operating in Sri Lanka, The websites of the Health Ministry, Energy Ministry and the Rajarata University websites were affected by this cyberattack.  This cyber attack conducted by a group called 'Tamil Eelam Cyber Force'.\n\n== Cyber-Attack On Prime Minister Mahinda's Website ==\nThe official website of Sri Lankan Prime Minister Mahinda Rajapaksa was hacked on June 3rd 2021. \nThe Information Technology Society Sri Lanka - ITSSL said the PM\u2019s website was hacked in a manner in which any visitor to the website would be redirected to another website which displays content related to the Bitcoin cryptocurrency."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does a router implementing ingress filtering determine if a packet is illegitimate?",
    "context": "",
    "output": "A router implementing ingress filtering checks the source IP field of IP packets it receives and drops packets if the packets don't have an IP address in the IP address block to which the interface is connected.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does a router implementing ingress filtering determine if a packet is illegitimate?",
      "answer": "A router implementing ingress filtering checks the source IP field of IP packets it receives and drops packets if the packets don't have an IP address in the IP address block to which the interface is connected."
    }
  },
  {
    "instruction": "Write an answer to the following question: Who were the two Russian intelligence agencies that infiltrated the DNC computer systems and led to a data breach in 2015 and 2016?",
    "context": "",
    "output": "The two Russian intelligence agencies are Cozy Bear and Fancy Bear.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Who were the two Russian intelligence agencies that infiltrated the DNC computer systems and led to a data breach in 2015 and 2016?",
      "answer": "The two Russian intelligence agencies are Cozy Bear and Fancy Bear."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the relationship between PKCS #12 and PFX file formats?",
    "context": "",
    "output": "PKCS #12 is the successor to Microsoft's PFX format, but the terms \"PKCS #12 file\" and \"PFX file\" are sometimes used interchangeably.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the relationship between PKCS #12 and PFX file formats?",
      "answer": "PKCS #12 is the successor to Microsoft's PFX format, but the terms \"PKCS #12 file\" and \"PFX file\" are sometimes used interchangeably."
    }
  },
  {
    "instruction": "Write an answer to the following question: Which block cipher was broken using higher-order differential cryptanalysis?",
    "context": "",
    "output": "The KN-Cipher, a block cipher previously proved to be immune against standard differential cryptanalysis, was broken using higher-order differential cryptanalysis.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Which block cipher was broken using higher-order differential cryptanalysis?",
      "answer": "The KN-Cipher, a block cipher previously proved to be immune against standard differential cryptanalysis, was broken using higher-order differential cryptanalysis."
    }
  },
  {
    "instruction": "Write an answer to the following question: How can the security of HECC be further increased beyond the choice of genus g and field size q^k?",
    "context": "",
    "output": "The security of HECC can be further increased by choosing a curve and a field with a large prime factor in the order of the Jacobian, as this will make the DLP more difficult to solve. Additionally, HECC can be combined with other cryptographic techniques, such as key agreement or encryption, to provide additional security.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can the security of HECC be further increased beyond the choice of genus g and field size q^k?",
      "answer": "The security of HECC can be further increased by choosing a curve and a field with a large prime factor in the order of the Jacobian, as this will make the DLP more difficult to solve. Additionally, HECC can be combined with other cryptographic techniques, such as key agreement or encryption, to provide additional security."
    }
  },
  {
    "instruction": "Write an answer to the following question: What was the message displayed during the Tapandegan's hack of the Tabriz International Airport?",
    "context": "",
    "output": "The message displayed during the Tapandegan's hack of the Tabriz International Airport protested the wasting of Iranians' resources and expressed support for Iranian truckers who were on strike.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was the message displayed during the Tapandegan's hack of the Tabriz International Airport?",
      "answer": "The message displayed during the Tapandegan's hack of the Tabriz International Airport protested the wasting of Iranians' resources and expressed support for Iranian truckers who were on strike."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the Cyber Essentials program address information risk management?",
    "context": "",
    "output": "At the Cyber Essentials Plus level, Cyber Essentials is integrated into the organization's information risk management, ensuring that information security risks are identified, assessed, and managed.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the Cyber Essentials program address information risk management?",
      "answer": "At the Cyber Essentials Plus level, Cyber Essentials is integrated into the organization's information risk management, ensuring that information security risks are identified, assessed, and managed."
    }
  },
  {
    "instruction": "Write an answer to the following question: How can piggybackers take advantage of an authorized person's disregard for the law or rules?",
    "context": "",
    "output": "Piggybackers can take advantage of an authorized person's disregard for the law or rules by finding an authorized person who disregards the law or the rules of the facility and agreeably allows the piggybacker to tag along.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can piggybackers take advantage of an authorized person's disregard for the law or rules?",
      "answer": "Piggybackers can take advantage of an authorized person's disregard for the law or rules by finding an authorized person who disregards the law or the rules of the facility and agreeably allows the piggybacker to tag along."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the TCSEC ensure the security of computer systems?",
    "context": "",
    "output": "The TCSEC ensures the security of computer systems by setting basic requirements for assessing the effectiveness of computer security controls built into a computer system, enforcing explicit, well-defined, and enforced security policies, providing individual accountability, ensuring assurance through hardware/software mechanisms that can be independently evaluated, and continuously protecting trusted mechanisms against tampering or unauthorized changes.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the TCSEC ensure the security of computer systems?",
      "answer": "The TCSEC ensures the security of computer systems by setting basic requirements for assessing the effectiveness of computer security controls built into a computer system, enforcing explicit, well-defined, and enforced security policies, providing individual accountability, ensuring assurance through hardware/software mechanisms that can be independently evaluated, and continuously protecting trusted mechanisms against tampering or unauthorized changes."
    }
  },
  {
    "instruction": "ICMP tunnel\n\n==Introduction==\nAn ICMP tunnel establishes a covert connection between two remote computers (a client and proxy), using ICMP echo requests and reply packets. An example of this technique is tunneling complete TCP traffic over ping requests and replies.\n\n\n\n== Technical details ==\nICMP tunneling works by injecting arbitrary data into an echo packet sent to a remote computer.  The remote computer replies in the same manner, injecting an answer into another ICMP packet and sending it back.  The client performs all communication using ICMP echo request packets, while the proxy uses echo reply packets.\nIn theory, it is possible to have the proxy use echo request packets (which makes implementation much easier), but these packets are not necessarily forwarded to the client, as the client could be behind a translated address (NAT).  This bidirectional data flow can be abstracted with an ordinary serial line.\nICMP tunneling is possible because RFC 792, which defines the structure of ICMP packets, allows for an arbitrary data length for any type 0 (echo reply) or 8 (echo message) ICMP packets.\n\n== Uses ==\nICMP tunneling can be used to bypass firewalls rules through obfuscation of the actual traffic. Depending on the implementation of the ICMP tunneling software, this type of connection can also be categorized as an encrypted communication channel between two computers. Without proper deep packet inspection or log review, network administrators will not be able to detect this type of traffic through their network.\n\n== Mitigation ==\nOne way to prevent this type of tunneling is to block ICMP traffic, at the cost of losing some network functionality that people usually take for granted (e.g. it might take tens of seconds to determine that a peer is offline, rather than almost instantaneously). Another method for mitigating this type of attack is to only allow fixed sized ICMP packets through firewalls, which can impede or eliminate this type of behavior.ICMP-tunnels are sometimes used to circumvent firewalls that block traffic between the LAN and the outside world. For example, by commercial wifi services that require the user to pay for usage, or a library that requires the user to first log in at a web portal. If the network operator made the erroneous assumption that it is enough to only block normal transport protocols like TCP and UDP, but not core protocols such as ICMP, then it is sometimes possible to use an ICMP-tunnel to access the internet despite not having been authorized for network access. Encryption and per-user rules that disallow users exchanging ICMP packets (and all other types of packets, maybe by using IEEE 802.1X) with external peers before authorization solves this problem.\n\nBased on the above text, answer a question. How does ICMP tunneling abstract the data flow between the client and proxy?",
    "context": "",
    "output": "The bidirectional data flow in ICMP tunneling can be abstracted with an ordinary serial line, where the client communicates using ICMP echo request packets and the proxy uses echo reply packets.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does ICMP tunneling abstract the data flow between the client and proxy?",
      "answer": "The bidirectional data flow in ICMP tunneling can be abstracted with an ordinary serial line, where the client communicates using ICMP echo request packets and the proxy uses echo reply packets.",
      "context": "ICMP tunnel\n\n==Introduction==\nAn ICMP tunnel establishes a covert connection between two remote computers (a client and proxy), using ICMP echo requests and reply packets. An example of this technique is tunneling complete TCP traffic over ping requests and replies.\n\n\n\n== Technical details ==\nICMP tunneling works by injecting arbitrary data into an echo packet sent to a remote computer.  The remote computer replies in the same manner, injecting an answer into another ICMP packet and sending it back.  The client performs all communication using ICMP echo request packets, while the proxy uses echo reply packets.\nIn theory, it is possible to have the proxy use echo request packets (which makes implementation much easier), but these packets are not necessarily forwarded to the client, as the client could be behind a translated address (NAT).  This bidirectional data flow can be abstracted with an ordinary serial line.\nICMP tunneling is possible because RFC 792, which defines the structure of ICMP packets, allows for an arbitrary data length for any type 0 (echo reply) or 8 (echo message) ICMP packets.\n\n== Uses ==\nICMP tunneling can be used to bypass firewalls rules through obfuscation of the actual traffic. Depending on the implementation of the ICMP tunneling software, this type of connection can also be categorized as an encrypted communication channel between two computers. Without proper deep packet inspection or log review, network administrators will not be able to detect this type of traffic through their network.\n\n== Mitigation ==\nOne way to prevent this type of tunneling is to block ICMP traffic, at the cost of losing some network functionality that people usually take for granted (e.g. it might take tens of seconds to determine that a peer is offline, rather than almost instantaneously). Another method for mitigating this type of attack is to only allow fixed sized ICMP packets through firewalls, which can impede or eliminate this type of behavior.ICMP-tunnels are sometimes used to circumvent firewalls that block traffic between the LAN and the outside world. For example, by commercial wifi services that require the user to pay for usage, or a library that requires the user to first log in at a web portal. If the network operator made the erroneous assumption that it is enough to only block normal transport protocols like TCP and UDP, but not core protocols such as ICMP, then it is sometimes possible to use an ICMP-tunnel to access the internet despite not having been authorized for network access. Encryption and per-user rules that disallow users exchanging ICMP packets (and all other types of packets, maybe by using IEEE 802.1X) with external peers before authorization solves this problem."
    }
  },
  {
    "instruction": "IMSI-catcher\n\n==Introduction==\nAn international mobile subscriber identity-catcher, or IMSI-catcher, is a telephone eavesdropping device used for intercepting mobile phone traffic and tracking location data of mobile phone users. Essentially a \"fake\" mobile tower acting between the target mobile phone and the service provider's real towers, it is considered a man-in-the-middle (MITM) attack. The 3G wireless standard offers some risk mitigation due to mutual authentication required from both the handset and the network. However, sophisticated attacks may be able to downgrade 3G and LTE to non-LTE network services which do not require mutual authentication.IMSI-catchers are used in a number of countries by law enforcement and intelligence agencies, but their use has raised significant civil liberty and privacy concerns and is strictly regulated in some countries such as under the German Strafprozessordnung (StPO / Code of Criminal Procedure). Some countries do not have encrypted phone data traffic (or very weak encryption), thus rendering an IMSI-catcher unnecessary.\n\n\n\n== Overview ==\nA virtual base transceiver station (VBTS) is a device for identifying the  temporary mobile subscriber identity (TMSI), international mobile subscriber identity (IMSI) of a nearby GSM mobile phone and intercepting its calls, some are even advanced enough to detect the international mobile equipment identity (IMEI). It was patented and first commercialized by Rohde & Schwarz in 2003. The device can be viewed as simply a modified cell tower with a malicious operator, and on 4 January 2012, the Court of Appeal of England and Wales held that the patent is invalid for obviousness.IMSI-catchers are often deployed by court order without a search warrant, the lower judicial standard of a pen register and trap-and-trace order being preferred by law enforcement. They can also be used in search and rescue operation for missing persons. Police departments have been reluctant to reveal use of these programs and contracts with vendors such as Harris Corporation, the maker of Stingray and Kingfish phone tracker devices.In the UK, the first public body to admit using IMSI catchers was the Scottish Prison Service, though it is likely that the Metropolitan Police Service has been using IMSI catchers since 2011 or before.Body-worn IMSI-catchers that target nearby mobile phones are being advertised to law enforcement agencies in the US.The GSM specification requires the handset to authenticate to the network, but does not require the network to authenticate to the handset. This well-known security hole is exploited by an IMSI catcher. The IMSI catcher masquerades as a base station and logs the IMSI numbers of all the mobile stations in the area, as they attempt to attach to the IMSI-catcher. It allows forcing the mobile phone connected to it to use no call encryption (A5/0 mode) or to use easily breakable encryption (A5/1 or A5/2 mode), making the call data easy to intercept and convert to audio. \nThe 3G wireless standard mitigates risk and enhanced security of the protocol due to mutual authentication required from both the handset and the network and removes the false base station attack in GSM. Some sophisticated attacks against 3G and LTE may be able to downgrade to non-LTE network services which then does not require mutual authentication.\n\n== Functionalities ==\n\n\n*** Identifying an IMSI ***\nEvery mobile phone has the requirement to optimize its reception. If there is more than one base station of the subscribed network operator accessible, it will always choose the one with the strongest signal. An IMSI-catcher masquerades as a base station and causes every mobile phone of the simulated network operator within a defined radius to log in. With the help of a special identity request, it is able to force the transmission of the IMSI.\n\n\n*** Tapping a mobile phone ***\nThe IMSI-catcher subjects the phones in its vicinity to a man-in-the-middle attack, appearing to them as a preferred base station in terms of signal strength. With the help of a SIM, it simultaneously logs into the GSM network as a mobile station. Since the encryption mode is chosen by the base station, the IMSI-catcher can induce the mobile station to use no encryption at all. Hence it can encrypt the plain text traffic from the mobile station and pass it to the base station.\nA targeted mobile phone is sent signals where the user will not be able to tell apart the device from authentic cell service provider infrastructure. This means that the device will be able to retrieve data that a normal cell tower receives from mobile phones if registered.There is only an indirect connection from mobile station via IMSI-catcher to the GSM network. For this reason, incoming phone calls cannot generally be patched through to the mobile station by the GSM network, although more modern versions of these devices have their own mobile patch-through solutions in order to provide this functionality.\n\n\n*** Passive IMSI Detection ***\nThe difference between a passive IMSI-catcher and an active IMSI-catcher is that an active IMSI-catcher intercepts the data in transfer such as spoke, text, mail, and web traffic between the endpoint and cell tower.\nActive IMSI-catchers generally also intercept all conversations and data traffic within a large range and are therefore also called rogue cell towers. It sends a signal with a plethora of commands to the endpoints, which respond by establishing a connection and routes all conversations and data traffic between the endpoints and the actual cell tower for as long as the attacker wishes.\nA passive IMSI-catcher on the other hand only detects the IMSI, TMSI or IMEI of an endpoint. Once the IMSI, TMSI or IMEI address is detected, the endpoint is immediately released. The passive IMSI-catcher sends out a signal with only one specific command to the endpoints, which respond to it and share the identifiers of the endpoint with the passive IMSI-catcher. The vendors of passive IMSI-catchers take privacy more into account.\n\n== Universal Mobile Telecommunications System (UMTS) ==\nFalse base station attacks are prevented by a combination of key freshness and integrity protection of signaling data, not by authenticating the serving network.To provide a high network coverage, the UMTS standard allows for inter-operation with GSM. Therefore, not only UMTS but also GSM base stations are connected to the UMTS service network. This fallback is a security disadvantage and allows a new possibility of a man-in-the-middle attack.\n\n== Tell-tales and difficulties ==\nThe assignment of an IMSI catcher has a number of difficulties:\n\nIt must be ensured that the mobile phone of the observed person is in standby mode and the correct network operator is found out. Otherwise, for the mobile station, there is no need to log into the simulated base station.\nDepending on the signal strength of the IMSI-catcher, numerous IMSIs can be located. The problem is to find out the right one.\nAll mobile phones in the area covered by the catcher have no access to the network. Incoming and outgoing calls cannot be patched through for these subscribers. Only the observed person has an indirect connection.\nThere are some disclosing factors. In most cases, the operation cannot be recognized immediately by the subscriber. But there are a few mobile phones that show a small symbol on the display, e.g. an exclamation point, if encryption is not used. This \"Ciphering Indication Feature\" can be suppressed by the network provider, however, by setting the OFM bit in EFAD on the SIM card. Since the network access is handled with the SIM/USIM of the IMSI-catcher, the receiver cannot see the number of the calling party. Of course, this also implies that the tapped calls are not listed in the itemized bill.\nThe assignment near the base station can be difficult, due to the high signal level of the original base station.\nAs most mobile phones prefer the faster modes of communication such as 4G or 3G, downgrading to 2G can require blocking frequency ranges for 4G and 3G.\n\n== Detection and counter-measures ==\nSome preliminary research has been done in trying to detect and frustrate IMSI-catchers. One such project is through the Osmocom open source mobile station software. This is a special type of mobile phone firmware that can be used to detect and fingerprint certain network characteristics of IMSI-catchers, and warn the user that there is such a device operating in their area. But this firmware/software-based detection is strongly limited to a select few, outdated GSM mobile phones (i.e. Motorola) that are no longer available on the open market. The main problem is the closed-source nature of the major mobile phone producers.\nThe application Android IMSI-Catcher Detector (AIMSICD) is being developed to detect and circumvent IMSI-catchers by StingRay and silent SMS. Technology for a stationary network of IMSI-catcher detectors has also been developed. Several apps listed on the Google Play Store as IMSI catcher detector apps include SnoopSnitch, Cell Spy Catcher, and GSM Spy Finder and have between 100,000 and 500,000 app downloads each. However, these apps have limitations in that they do not have access to phone's underlying hardware and may offer only minimal protection.\n\n== External  links ==\nChris Paget's presentation Practical Cellphone Spying at  DEF CON 18\nVerrimus - Mobile Phone Intercept Detection\n\n== Footnotes ==\n\nBased on the above text, answer a question. How can an IMSI-catcher be used in a man-in-the-middle attack?",
    "context": "",
    "output": "An IMSI-catcher can be used in a man-in-the-middle attack by appearing to nearby mobile phones as a preferred base station in terms of signal strength and logging into the GSM network as a mobile station.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can an IMSI-catcher be used in a man-in-the-middle attack?",
      "answer": "An IMSI-catcher can be used in a man-in-the-middle attack by appearing to nearby mobile phones as a preferred base station in terms of signal strength and logging into the GSM network as a mobile station.",
      "context": "IMSI-catcher\n\n==Introduction==\nAn international mobile subscriber identity-catcher, or IMSI-catcher, is a telephone eavesdropping device used for intercepting mobile phone traffic and tracking location data of mobile phone users. Essentially a \"fake\" mobile tower acting between the target mobile phone and the service provider's real towers, it is considered a man-in-the-middle (MITM) attack. The 3G wireless standard offers some risk mitigation due to mutual authentication required from both the handset and the network. However, sophisticated attacks may be able to downgrade 3G and LTE to non-LTE network services which do not require mutual authentication.IMSI-catchers are used in a number of countries by law enforcement and intelligence agencies, but their use has raised significant civil liberty and privacy concerns and is strictly regulated in some countries such as under the German Strafprozessordnung (StPO / Code of Criminal Procedure). Some countries do not have encrypted phone data traffic (or very weak encryption), thus rendering an IMSI-catcher unnecessary.\n\n\n\n== Overview ==\nA virtual base transceiver station (VBTS) is a device for identifying the  temporary mobile subscriber identity (TMSI), international mobile subscriber identity (IMSI) of a nearby GSM mobile phone and intercepting its calls, some are even advanced enough to detect the international mobile equipment identity (IMEI). It was patented and first commercialized by Rohde & Schwarz in 2003. The device can be viewed as simply a modified cell tower with a malicious operator, and on 4 January 2012, the Court of Appeal of England and Wales held that the patent is invalid for obviousness.IMSI-catchers are often deployed by court order without a search warrant, the lower judicial standard of a pen register and trap-and-trace order being preferred by law enforcement. They can also be used in search and rescue operation for missing persons. Police departments have been reluctant to reveal use of these programs and contracts with vendors such as Harris Corporation, the maker of Stingray and Kingfish phone tracker devices.In the UK, the first public body to admit using IMSI catchers was the Scottish Prison Service, though it is likely that the Metropolitan Police Service has been using IMSI catchers since 2011 or before.Body-worn IMSI-catchers that target nearby mobile phones are being advertised to law enforcement agencies in the US.The GSM specification requires the handset to authenticate to the network, but does not require the network to authenticate to the handset. This well-known security hole is exploited by an IMSI catcher. The IMSI catcher masquerades as a base station and logs the IMSI numbers of all the mobile stations in the area, as they attempt to attach to the IMSI-catcher. It allows forcing the mobile phone connected to it to use no call encryption (A5/0 mode) or to use easily breakable encryption (A5/1 or A5/2 mode), making the call data easy to intercept and convert to audio. \nThe 3G wireless standard mitigates risk and enhanced security of the protocol due to mutual authentication required from both the handset and the network and removes the false base station attack in GSM. Some sophisticated attacks against 3G and LTE may be able to downgrade to non-LTE network services which then does not require mutual authentication.\n\n== Functionalities ==\n\n\n*** Identifying an IMSI ***\nEvery mobile phone has the requirement to optimize its reception. If there is more than one base station of the subscribed network operator accessible, it will always choose the one with the strongest signal. An IMSI-catcher masquerades as a base station and causes every mobile phone of the simulated network operator within a defined radius to log in. With the help of a special identity request, it is able to force the transmission of the IMSI.\n\n\n*** Tapping a mobile phone ***\nThe IMSI-catcher subjects the phones in its vicinity to a man-in-the-middle attack, appearing to them as a preferred base station in terms of signal strength. With the help of a SIM, it simultaneously logs into the GSM network as a mobile station. Since the encryption mode is chosen by the base station, the IMSI-catcher can induce the mobile station to use no encryption at all. Hence it can encrypt the plain text traffic from the mobile station and pass it to the base station.\nA targeted mobile phone is sent signals where the user will not be able to tell apart the device from authentic cell service provider infrastructure. This means that the device will be able to retrieve data that a normal cell tower receives from mobile phones if registered.There is only an indirect connection from mobile station via IMSI-catcher to the GSM network. For this reason, incoming phone calls cannot generally be patched through to the mobile station by the GSM network, although more modern versions of these devices have their own mobile patch-through solutions in order to provide this functionality.\n\n\n*** Passive IMSI Detection ***\nThe difference between a passive IMSI-catcher and an active IMSI-catcher is that an active IMSI-catcher intercepts the data in transfer such as spoke, text, mail, and web traffic between the endpoint and cell tower.\nActive IMSI-catchers generally also intercept all conversations and data traffic within a large range and are therefore also called rogue cell towers. It sends a signal with a plethora of commands to the endpoints, which respond by establishing a connection and routes all conversations and data traffic between the endpoints and the actual cell tower for as long as the attacker wishes.\nA passive IMSI-catcher on the other hand only detects the IMSI, TMSI or IMEI of an endpoint. Once the IMSI, TMSI or IMEI address is detected, the endpoint is immediately released. The passive IMSI-catcher sends out a signal with only one specific command to the endpoints, which respond to it and share the identifiers of the endpoint with the passive IMSI-catcher. The vendors of passive IMSI-catchers take privacy more into account.\n\n== Universal Mobile Telecommunications System (UMTS) ==\nFalse base station attacks are prevented by a combination of key freshness and integrity protection of signaling data, not by authenticating the serving network.To provide a high network coverage, the UMTS standard allows for inter-operation with GSM. Therefore, not only UMTS but also GSM base stations are connected to the UMTS service network. This fallback is a security disadvantage and allows a new possibility of a man-in-the-middle attack.\n\n== Tell-tales and difficulties ==\nThe assignment of an IMSI catcher has a number of difficulties:\n\nIt must be ensured that the mobile phone of the observed person is in standby mode and the correct network operator is found out. Otherwise, for the mobile station, there is no need to log into the simulated base station.\nDepending on the signal strength of the IMSI-catcher, numerous IMSIs can be located. The problem is to find out the right one.\nAll mobile phones in the area covered by the catcher have no access to the network. Incoming and outgoing calls cannot be patched through for these subscribers. Only the observed person has an indirect connection.\nThere are some disclosing factors. In most cases, the operation cannot be recognized immediately by the subscriber. But there are a few mobile phones that show a small symbol on the display, e.g. an exclamation point, if encryption is not used. This \"Ciphering Indication Feature\" can be suppressed by the network provider, however, by setting the OFM bit in EFAD on the SIM card. Since the network access is handled with the SIM/USIM of the IMSI-catcher, the receiver cannot see the number of the calling party. Of course, this also implies that the tapped calls are not listed in the itemized bill.\nThe assignment near the base station can be difficult, due to the high signal level of the original base station.\nAs most mobile phones prefer the faster modes of communication such as 4G or 3G, downgrading to 2G can require blocking frequency ranges for 4G and 3G.\n\n== Detection and counter-measures ==\nSome preliminary research has been done in trying to detect and frustrate IMSI-catchers. One such project is through the Osmocom open source mobile station software. This is a special type of mobile phone firmware that can be used to detect and fingerprint certain network characteristics of IMSI-catchers, and warn the user that there is such a device operating in their area. But this firmware/software-based detection is strongly limited to a select few, outdated GSM mobile phones (i.e. Motorola) that are no longer available on the open market. The main problem is the closed-source nature of the major mobile phone producers.\nThe application Android IMSI-Catcher Detector (AIMSICD) is being developed to detect and circumvent IMSI-catchers by StingRay and silent SMS. Technology for a stationary network of IMSI-catcher detectors has also been developed. Several apps listed on the Google Play Store as IMSI catcher detector apps include SnoopSnitch, Cell Spy Catcher, and GSM Spy Finder and have between 100,000 and 500,000 app downloads each. However, these apps have limitations in that they do not have access to phone's underlying hardware and may offer only minimal protection.\n\n== External  links ==\nChris Paget's presentation Practical Cellphone Spying at  DEF CON 18\nVerrimus - Mobile Phone Intercept Detection\n\n== Footnotes =="
    }
  },
  {
    "instruction": "Context: Alina (malware)\n\n==Introduction==\nAlina is a Point of Sale Malware or POS RAM Scraper that is used by cybercriminals to scrape credit card and debit card information from the point of sale system. It first started to scrape information in late 2012. It resembles JackPOS Malware.\n\n\n\n== Process of Alina POS RAM Scraper ==\nOnce executed, it gets installed on the user's computer and checks for updates. If an update is found, it removes the existing Alina code and installs the latest version. Then, for new installations, it adds the file path to an AutoStart runkey to maintain persistence. Finally, it adds java.exe to the %APPDATA% directory and executes it using the parameter alina\nAnswer this question: What type of malware is Alina POS RAM Scraper?",
    "context": "",
    "output": "Alina POS RAM Scraper is a type of Point of Sale Malware or POS RAM Scraper, used by cybercriminals to scrape credit card and debit card information from the point of sale system.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What type of malware is Alina POS RAM Scraper?",
      "answer": "Alina POS RAM Scraper is a type of Point of Sale Malware or POS RAM Scraper, used by cybercriminals to scrape credit card and debit card information from the point of sale system.",
      "context": "Alina (malware)\n\n==Introduction==\nAlina is a Point of Sale Malware or POS RAM Scraper that is used by cybercriminals to scrape credit card and debit card information from the point of sale system. It first started to scrape information in late 2012. It resembles JackPOS Malware.\n\n\n\n== Process of Alina POS RAM Scraper ==\nOnce executed, it gets installed on the user's computer and checks for updates. If an update is found, it removes the existing Alina code and installs the latest version. Then, for new installations, it adds the file path to an AutoStart runkey to maintain persistence. Finally, it adds java.exe to the %APPDATA% directory and executes it using the parameter alina"
    }
  },
  {
    "instruction": "FoxBlade\n\n==Introduction==\nFoxBlade is a trojan horse wiper malware identified on 23 February 2022 by Microsoft's Threat Assessment Center that appeared to be aimed at targets in Ukraine's government.  FoxBlade was discovered in Ukrainian networks on the day of the 2022 Ukraine invasion, and it is suspected it is part of the cyberattacks on Ukraine connected with that invasion.  Coordination between the United States and Microsoft was reported as unusually productive, as executives were given security clearances to join calls with intelligence officials. Microsoft coordinated with the European Union to prevent FoxBlade from being used against other countries in Europe.\n\n\n\n\n\nHow does the collaboration between Microsoft and the United States government in response to FoxBlade differ from typical cybersecurity incident responses?",
    "context": "",
    "output": "In response to the FoxBlade trojan horse wiper malware, Microsoft and the United States government's collaboration was unusually productive due to executives being given security clearances to join calls with intelligence officials. This level of coordination and information sharing between a private company and the government is not commonly seen in cybersecurity incident responses, making it a more sophisticated and comprehensive approach to addressing the threat.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the collaboration between Microsoft and the United States government in response to FoxBlade differ from typical cybersecurity incident responses?",
      "answer": "In response to the FoxBlade trojan horse wiper malware, Microsoft and the United States government's collaboration was unusually productive due to executives being given security clearances to join calls with intelligence officials. This level of coordination and information sharing between a private company and the government is not commonly seen in cybersecurity incident responses, making it a more sophisticated and comprehensive approach to addressing the threat.",
      "context": "FoxBlade\n\n==Introduction==\nFoxBlade is a trojan horse wiper malware identified on 23 February 2022 by Microsoft's Threat Assessment Center that appeared to be aimed at targets in Ukraine's government.  FoxBlade was discovered in Ukrainian networks on the day of the 2022 Ukraine invasion, and it is suspected it is part of the cyberattacks on Ukraine connected with that invasion.  Coordination between the United States and Microsoft was reported as unusually productive, as executives were given security clearances to join calls with intelligence officials. Microsoft coordinated with the European Union to prevent FoxBlade from being used against other countries in Europe.\n\n\n\n"
    }
  },
  {
    "instruction": "Write an answer to the following question: What is SMS spoofing and what are its legitimate uses?",
    "context": "",
    "output": "SMS spoofing is a technology that manipulates the sender ID of a Short Message Service (SMS) to make it appear as if it came from a different number or alphanumeric text. Legitimate uses of SMS spoofing include setting the company name or product name as the sender ID, setting your own mobile number as the sender ID, and sending anonymous SMS messages using the default network gateway identifier.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is SMS spoofing and what are its legitimate uses?",
      "answer": "SMS spoofing is a technology that manipulates the sender ID of a Short Message Service (SMS) to make it appear as if it came from a different number or alphanumeric text. Legitimate uses of SMS spoofing include setting the company name or product name as the sender ID, setting your own mobile number as the sender ID, and sending anonymous SMS messages using the default network gateway identifier."
    }
  },
  {
    "instruction": "Multiple Independent Levels of Security\n\n==Introduction==\nMultiple Independent Levels of Security/Safety (MILS) is a high-assurance security architecture based on the concepts of separation and controlled information flow. It is implemented by separation mechanisms that support both untrusted and trustworthy components; ensuring that the total security solution is non-bypassable, evaluatable, always invoked, and tamperproof.\n\n\n\n== Overview ==\nA MILS solution allows for independent evaluation of security components and trusted composition. MILS builds on the older Bell and La Padula theories on secure systems that represent the foundational theories of the DoD Orange Book.\nA MILS system employs one or more separation mechanisms (e.g., Separation kernel, Partitioning Communication System, physical separation) to maintain assured data and process separation. A MILS system supports enforcement of one or more application/system specific security policies by authorizing information flow only between components in the same security domain or through trustworthy security monitors (e.g., access control guards, downgraders, crypto devices, etc.).\n\n\n*** NEAT ***\nProperties:\n\nNon-bypassable: a component can not use another communication path, including lower level mechanisms to bypass the security monitor.\nEvaluatable: any trusted component can be evaluated to the level of assurance required of that component. This means the components are modular, well designed, well specified, well implemented, small, low complexity, etc.\nAlways-invoked: each and every access/message is checked by the appropriate security monitors (i.e., a security monitor will not just check on a first access and then pass all subsequent accesses/messages through).\nTamperproof: the system controls \"modify\" rights to the security monitor code, configuration and data; preventing unauthorized changes.A convenient acronym for these characteristics is NEAT.\n\n\n*** Trustworthiness ***\n'Trustworthy' means that the component have been certified to satisfy well defined security policies to a level of assurance commensurate with the level of risk for that component (e.g., we can have single level access control guards evaluated at CC EAL4; separation mechanisms evaluated at High Robustness; two-level separation guards at EAL 5; and TYPE I crypto all in the same MILS system).\n'Untrusted' means that we have no confidence that the system meets its specification with respect to the security policy.\n\n\n*** Companies ***\nThe following companies have MILS separation kernel products:\n\nGreen Hills Software\nLynuxWorks\nSYSGO\nWind River Systems\nBertin Technologies\nOK LabsCompanies with other separation methods creating MILS products:\n\nThales\n\n== MILS Research and Technology ==\nThe MILS CommunityThe MILS Community [1] is a global international, open membership, not-for-profit competence network on MILS architecture and technologies.Research ProjectsEURO-MILS: Secure European Virtualisation for Trustworthy Applications in Critical Domains [2]\nD-MILS: Distributed MILS for dependable information and communication infrastructures [3].\ncertMILS: Compositional security certification for medium- to high-assurance COTS-based systems in environments with emerging threats [4]\nQ: What are some companies that provide MILS separation kernel products?",
    "context": "",
    "output": "Some companies that provide MILS separation kernel products include Green Hills Software, LynuxWorks, SYSGO, Wind River Systems, and Bertin Technologies.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are some companies that provide MILS separation kernel products?",
      "answer": "Some companies that provide MILS separation kernel products include Green Hills Software, LynuxWorks, SYSGO, Wind River Systems, and Bertin Technologies.",
      "context": "Multiple Independent Levels of Security\n\n==Introduction==\nMultiple Independent Levels of Security/Safety (MILS) is a high-assurance security architecture based on the concepts of separation and controlled information flow. It is implemented by separation mechanisms that support both untrusted and trustworthy components; ensuring that the total security solution is non-bypassable, evaluatable, always invoked, and tamperproof.\n\n\n\n== Overview ==\nA MILS solution allows for independent evaluation of security components and trusted composition. MILS builds on the older Bell and La Padula theories on secure systems that represent the foundational theories of the DoD Orange Book.\nA MILS system employs one or more separation mechanisms (e.g., Separation kernel, Partitioning Communication System, physical separation) to maintain assured data and process separation. A MILS system supports enforcement of one or more application/system specific security policies by authorizing information flow only between components in the same security domain or through trustworthy security monitors (e.g., access control guards, downgraders, crypto devices, etc.).\n\n\n*** NEAT ***\nProperties:\n\nNon-bypassable: a component can not use another communication path, including lower level mechanisms to bypass the security monitor.\nEvaluatable: any trusted component can be evaluated to the level of assurance required of that component. This means the components are modular, well designed, well specified, well implemented, small, low complexity, etc.\nAlways-invoked: each and every access/message is checked by the appropriate security monitors (i.e., a security monitor will not just check on a first access and then pass all subsequent accesses/messages through).\nTamperproof: the system controls \"modify\" rights to the security monitor code, configuration and data; preventing unauthorized changes.A convenient acronym for these characteristics is NEAT.\n\n\n*** Trustworthiness ***\n'Trustworthy' means that the component have been certified to satisfy well defined security policies to a level of assurance commensurate with the level of risk for that component (e.g., we can have single level access control guards evaluated at CC EAL4; separation mechanisms evaluated at High Robustness; two-level separation guards at EAL 5; and TYPE I crypto all in the same MILS system).\n'Untrusted' means that we have no confidence that the system meets its specification with respect to the security policy.\n\n\n*** Companies ***\nThe following companies have MILS separation kernel products:\n\nGreen Hills Software\nLynuxWorks\nSYSGO\nWind River Systems\nBertin Technologies\nOK LabsCompanies with other separation methods creating MILS products:\n\nThales\n\n== MILS Research and Technology ==\nThe MILS CommunityThe MILS Community [1] is a global international, open membership, not-for-profit competence network on MILS architecture and technologies.Research ProjectsEURO-MILS: Secure European Virtualisation for Trustworthy Applications in Critical Domains [2]\nD-MILS: Distributed MILS for dependable information and communication infrastructures [3].\ncertMILS: Compositional security certification for medium- to high-assurance COTS-based systems in environments with emerging threats [4]"
    }
  },
  {
    "instruction": "Infraud Organization\n\n==Introduction==\nInfraud Organization was an international cybercrime organization, operating between October 2010 and February 2018, that was involved in carding, stealing personal credit cards and online banking information. The organization was created by Svyatoslav Bondarenko, a 34-year-old man from Ukraine. In February 2018, authorities in the United States indicted 36 individuals involved with the organization on charges of racketeering, conspiracy, possession of 15 or more access devices, and aiding and abetting.  As of February 2018, 13 of the 36 have been arrested. The US Justice Department stated that as of March 2017, the organization had 10,901 registered members and was the \"largest cyber fraud enterprise prosecutions ever undertaken by the Department of Justice\" and had resulted in $530 million in actual losses, with an estimated $2.2 billion in intended losses.Presently (01/22/2022)\n\n\n\n== Organization Roles ==\nThe organization was split into different roles, the administrators, the super moderators, the moderators, vendors, VIP members and members.The administrators served as the governing council of the group, initially made up of \"reputable\" vendors. They handled management decisions, long-term strategic planning and managing of users of the site. Administrators had full privileges and access to the computer servers hosting Infraud's websites.\nSuper Moderators oversaw subject-matter specific areas of the forums which were either part of their expertise or was part of their geographical location. They were limited to editing and deleting posts by members as well as resolving disputes. They often reviewed other vendor's products or services which was in their area of expertise.\nModerators were similar to super moderators, however, they had less authority within the forums and were generally limited to moderating one or two specific sub-forums.\nVendors sold illicit product or services to other members of the organization which would usually be done through the vendor's website. Products or services would be reviewed by members to ensure that products which were purchased were of high quality and vendors of low-quality products or services did not remain in the organization.\nVIP members were premiere members of the Infraud Organization. The role would be given to longstanding or notable members of the organization to distinguish them between members and vendors.\nMembers were general members of the organization who used the site to gather and provide information about perpetrating criminal activity as well as to use the vendors to facilitate unlawful purchases of credit card dumps and other illegal products or services.\n\n== Indictment ==\nThe indictment was released on 7 February 2018. It listed 36 individuals who were alleged to be involved with the organization. They are:\n\nSvyatoslav Bondarenko, the founder of Infraud from Ukraine. He allegedly stopped posted on and/or using Infraud in 2015.\nAldo Ymeraj, an Albanian vendor who advertised credit card dumps.\nSergey Medvedev, the co-founder of Infraud and has been an active member since 2010. After Bondarenko disappeared in 2015, he took over as owner and administrator of Infraud after saying that Bondarenko had \"gone missing\". Medvedev was arrested in Bangkok, Thailand with over 100,000 bitcoins (worth roughly $822 million at the time).\nAmjad Ali, a Pakistani member of Infraud since December 2010 who was promoted to Super Moderator status. He was involved with the sale of CVVs and purchased in excess of 130 compromised credit card dumps from Musliu.\nRoland Patrick N\u2019Djimbi Tchikaya, a French member of Infraud who was a vendor involved with the sale of CVVs. Tchikaya also purchased compromised credit card numbers from a vendor who is not listed in the indictment.\nArnaldo Sanchez, a VIP member of Infraud who advertised the sale of CVVs and credit card profile lookups.\nMiroslav Kovacevic, a Serbian member of Infraud who advertised the sale of plastics, templates and scans.\nFredrick Thomas, from Alabama who was a vendor for social security numbers and date of birth lookups.\nOsalma Abdelhamed, an Egyptian vendor who sold credit card dumps and operator of multiple websites which he used to sell dumps. Abdelhamed also purchased multiple credit card numbers from Fawaz.\nBesart Hoxha, a Kosovo vendor who advertised plastic card stock and holograms.\nRaihan Ahmed Gut, a Bangladesh vendor for compromised PayPal accounts. Ahmed had purchased over 1,300 compromised PayPal logins from a vendor who is not listed in the indictment.\nAndrey Sergeevich Novak, a Russian vendor for CVVs.\nValerian Chiochiu, a Moldovan who provided guidance to other members for the development, deployment and use of RAM point of sale malware as a means of harvesting stolen data.\nGennaro Fioretti, an Italian VIP member who made numerous illicit purchases from Infraud members.\nEdgar Andres Viloria, an Australian VIP member. He purchased credit card dumps from Musliu.\nJohn Telusma, a vendor from New York who provided cashout and drop services, as well as selling credit card dumps.\nRami Fawaz, a member from Ivory Coast who sold compromised account data.\nMuhammed Shiraz, a Pakistani vendor of credit card dumps.\nJose Gamboa, a Californian vendor who advertised the sale of custom-built ATM skimmers.\nAlexey Klimenko, a Ukraine vendor who advertised services which allowed people to create, operate, maintain and protect their own online contraband stores.\nEdward Lavoile, a Canadian member who advertised the sale of CVVs which he had personally hacked.\nAnthony Nnamdi Okeakpu, a UK super moderator for Infraud. Okeakpu purchased six compromised credit card fulls from Doe #8.\nPius Wilson, a VIP member from New York who was extremely active on Infraud forums.\nMuhammad Khan, a Pakistani vendor who was assigned to checking stolen credit card numbers to check whether they were still operable or if they were shut down by the bank for fraud.\nDavid Jonathan Vargas, a Californian vendor for carded travel services. Vargas purchased two CVVs from Musliu.\nMarko Leopard, a vendor from North Macedonia who advertised services which allowed people to create, operate, maintain and protect their own online contraband stores.\nLiridon Musliu, a vendor from Kosovo who advertised credit card dumps.\nMena Mouries El-Malak, an Egyptian vendor who advertised credit card dumps.There are 8 others who are either unknown or deceased and is referred to as John Doe in the indictment. They are:\n\nJohn Doe #1, a vendor of credit card dumps.\nJohn Doe #2, a vendor of drop services.\nJohn Doe #3, a vendor of credit card dumps.\nJohn Doe #4, a vendor of credit card dumps.\nJohn Doe #5, a vendor of credit card dumps.\nJohn Doe #6, a vendor of credit card dumps.\nJohn Doe #7, a vendor of credit card dumps. Doe #7 used Medvedev's service to complete a criminal transaction.\nJohn Doe #8, a vendor of compromised online bank logins. Doe #8 claimed that he had 795,000 HSBC logins for sale.According to the indictment, many vendors redirected traffic and potential purchases of their products to their own websites in order to complete the transaction. Each individual who owned a website has their website listed in the indictment. Some vendors occasionally gave out free credit card dumps or compromised PayPal logins for fun, to showcase their products.\nThe indictment contains information about the crimes the individuals face, the roles of the organization, a list of each individuals name and their alias used within the Infraud organization, a brief explanation of their part in Infraud and examples of some of the crimes each individual committed. The charges in the indictment are only allegations, and are presumed innocent until proven guilty.\n\n== Infraud Takedown ==\nOn 2 August 2017, an undercover Homeland Security Investigations agent posing as a member purchased 15 credit card dumps from Doe #6 and 15 from Novak. On 4 August 2017, the agent purchased 54 compromised credit card dumps from Novak and 15 more from Doe #6.A joint operation between the United States, European, Australian and Asian law enforcement agencies arrested thirteen defendants, as of 8 February 2018. The Infraud website was taken down and a message saying \"This operation is a coordinated effort by United States, European, Australian and Asian law enforcement agencies to disrupt and dismantle the transnational criminal enterprise known as Infraud Organization\".The thirteen arrested are: Sergey Medvedev, Roland Patrick N\u2019Djimbi Tchikaya, Miroslav Kovacevic, Fredrick Thomas, Besart Hoxha, John Telusma, Jose Gamboa, David Jonathan Vargas, Liridon Musliu, Gennaro Fioretti, Edgar Andres Viloria Rojas, Pius Sushil Wilson and Edward Lavoile.Acting Assistant Attorney General Cronan from United States Department of Justice said that \"as alleged in the indictment, Infraud operated like a business to facilitate cyberfraud on a global scale\" and that \"the Department of Justice refuses to allow these cybercriminals to use the perceived anonymity of the Internet as a shield for their crimes. We are committed to working closely with our international counterparts to identify, investigate, and bring to justice the perpetrators of these crimes, wherever in the world they operate.\" Acting Executive Associate Director Benner from Homeland Security Investigations mentioned that \"criminal cyber organizations like Infraud threaten not just U.S. citizens but people in every corner of the globe\" and that \"the actions of computer hackers and identity thieves not only harm countless innocent Americans, but the threat they pose to our financial system and global commerce cannot be overstated\".\nQ: What was the role of Edward Lavoile in the Infraud Organization?",
    "context": "",
    "output": "Edward Lavoile, a Canadian member of Infraud, advertised the sale of CVVs which he had personally hacked.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was the role of Edward Lavoile in the Infraud Organization?",
      "answer": "Edward Lavoile, a Canadian member of Infraud, advertised the sale of CVVs which he had personally hacked.",
      "context": "Infraud Organization\n\n==Introduction==\nInfraud Organization was an international cybercrime organization, operating between October 2010 and February 2018, that was involved in carding, stealing personal credit cards and online banking information. The organization was created by Svyatoslav Bondarenko, a 34-year-old man from Ukraine. In February 2018, authorities in the United States indicted 36 individuals involved with the organization on charges of racketeering, conspiracy, possession of 15 or more access devices, and aiding and abetting.  As of February 2018, 13 of the 36 have been arrested. The US Justice Department stated that as of March 2017, the organization had 10,901 registered members and was the \"largest cyber fraud enterprise prosecutions ever undertaken by the Department of Justice\" and had resulted in $530 million in actual losses, with an estimated $2.2 billion in intended losses.Presently (01/22/2022)\n\n\n\n== Organization Roles ==\nThe organization was split into different roles, the administrators, the super moderators, the moderators, vendors, VIP members and members.The administrators served as the governing council of the group, initially made up of \"reputable\" vendors. They handled management decisions, long-term strategic planning and managing of users of the site. Administrators had full privileges and access to the computer servers hosting Infraud's websites.\nSuper Moderators oversaw subject-matter specific areas of the forums which were either part of their expertise or was part of their geographical location. They were limited to editing and deleting posts by members as well as resolving disputes. They often reviewed other vendor's products or services which was in their area of expertise.\nModerators were similar to super moderators, however, they had less authority within the forums and were generally limited to moderating one or two specific sub-forums.\nVendors sold illicit product or services to other members of the organization which would usually be done through the vendor's website. Products or services would be reviewed by members to ensure that products which were purchased were of high quality and vendors of low-quality products or services did not remain in the organization.\nVIP members were premiere members of the Infraud Organization. The role would be given to longstanding or notable members of the organization to distinguish them between members and vendors.\nMembers were general members of the organization who used the site to gather and provide information about perpetrating criminal activity as well as to use the vendors to facilitate unlawful purchases of credit card dumps and other illegal products or services.\n\n== Indictment ==\nThe indictment was released on 7 February 2018. It listed 36 individuals who were alleged to be involved with the organization. They are:\n\nSvyatoslav Bondarenko, the founder of Infraud from Ukraine. He allegedly stopped posted on and/or using Infraud in 2015.\nAldo Ymeraj, an Albanian vendor who advertised credit card dumps.\nSergey Medvedev, the co-founder of Infraud and has been an active member since 2010. After Bondarenko disappeared in 2015, he took over as owner and administrator of Infraud after saying that Bondarenko had \"gone missing\". Medvedev was arrested in Bangkok, Thailand with over 100,000 bitcoins (worth roughly $822 million at the time).\nAmjad Ali, a Pakistani member of Infraud since December 2010 who was promoted to Super Moderator status. He was involved with the sale of CVVs and purchased in excess of 130 compromised credit card dumps from Musliu.\nRoland Patrick N\u2019Djimbi Tchikaya, a French member of Infraud who was a vendor involved with the sale of CVVs. Tchikaya also purchased compromised credit card numbers from a vendor who is not listed in the indictment.\nArnaldo Sanchez, a VIP member of Infraud who advertised the sale of CVVs and credit card profile lookups.\nMiroslav Kovacevic, a Serbian member of Infraud who advertised the sale of plastics, templates and scans.\nFredrick Thomas, from Alabama who was a vendor for social security numbers and date of birth lookups.\nOsalma Abdelhamed, an Egyptian vendor who sold credit card dumps and operator of multiple websites which he used to sell dumps. Abdelhamed also purchased multiple credit card numbers from Fawaz.\nBesart Hoxha, a Kosovo vendor who advertised plastic card stock and holograms.\nRaihan Ahmed Gut, a Bangladesh vendor for compromised PayPal accounts. Ahmed had purchased over 1,300 compromised PayPal logins from a vendor who is not listed in the indictment.\nAndrey Sergeevich Novak, a Russian vendor for CVVs.\nValerian Chiochiu, a Moldovan who provided guidance to other members for the development, deployment and use of RAM point of sale malware as a means of harvesting stolen data.\nGennaro Fioretti, an Italian VIP member who made numerous illicit purchases from Infraud members.\nEdgar Andres Viloria, an Australian VIP member. He purchased credit card dumps from Musliu.\nJohn Telusma, a vendor from New York who provided cashout and drop services, as well as selling credit card dumps.\nRami Fawaz, a member from Ivory Coast who sold compromised account data.\nMuhammed Shiraz, a Pakistani vendor of credit card dumps.\nJose Gamboa, a Californian vendor who advertised the sale of custom-built ATM skimmers.\nAlexey Klimenko, a Ukraine vendor who advertised services which allowed people to create, operate, maintain and protect their own online contraband stores.\nEdward Lavoile, a Canadian member who advertised the sale of CVVs which he had personally hacked.\nAnthony Nnamdi Okeakpu, a UK super moderator for Infraud. Okeakpu purchased six compromised credit card fulls from Doe #8.\nPius Wilson, a VIP member from New York who was extremely active on Infraud forums.\nMuhammad Khan, a Pakistani vendor who was assigned to checking stolen credit card numbers to check whether they were still operable or if they were shut down by the bank for fraud.\nDavid Jonathan Vargas, a Californian vendor for carded travel services. Vargas purchased two CVVs from Musliu.\nMarko Leopard, a vendor from North Macedonia who advertised services which allowed people to create, operate, maintain and protect their own online contraband stores.\nLiridon Musliu, a vendor from Kosovo who advertised credit card dumps.\nMena Mouries El-Malak, an Egyptian vendor who advertised credit card dumps.There are 8 others who are either unknown or deceased and is referred to as John Doe in the indictment. They are:\n\nJohn Doe #1, a vendor of credit card dumps.\nJohn Doe #2, a vendor of drop services.\nJohn Doe #3, a vendor of credit card dumps.\nJohn Doe #4, a vendor of credit card dumps.\nJohn Doe #5, a vendor of credit card dumps.\nJohn Doe #6, a vendor of credit card dumps.\nJohn Doe #7, a vendor of credit card dumps. Doe #7 used Medvedev's service to complete a criminal transaction.\nJohn Doe #8, a vendor of compromised online bank logins. Doe #8 claimed that he had 795,000 HSBC logins for sale.According to the indictment, many vendors redirected traffic and potential purchases of their products to their own websites in order to complete the transaction. Each individual who owned a website has their website listed in the indictment. Some vendors occasionally gave out free credit card dumps or compromised PayPal logins for fun, to showcase their products.\nThe indictment contains information about the crimes the individuals face, the roles of the organization, a list of each individuals name and their alias used within the Infraud organization, a brief explanation of their part in Infraud and examples of some of the crimes each individual committed. The charges in the indictment are only allegations, and are presumed innocent until proven guilty.\n\n== Infraud Takedown ==\nOn 2 August 2017, an undercover Homeland Security Investigations agent posing as a member purchased 15 credit card dumps from Doe #6 and 15 from Novak. On 4 August 2017, the agent purchased 54 compromised credit card dumps from Novak and 15 more from Doe #6.A joint operation between the United States, European, Australian and Asian law enforcement agencies arrested thirteen defendants, as of 8 February 2018. The Infraud website was taken down and a message saying \"This operation is a coordinated effort by United States, European, Australian and Asian law enforcement agencies to disrupt and dismantle the transnational criminal enterprise known as Infraud Organization\".The thirteen arrested are: Sergey Medvedev, Roland Patrick N\u2019Djimbi Tchikaya, Miroslav Kovacevic, Fredrick Thomas, Besart Hoxha, John Telusma, Jose Gamboa, David Jonathan Vargas, Liridon Musliu, Gennaro Fioretti, Edgar Andres Viloria Rojas, Pius Sushil Wilson and Edward Lavoile.Acting Assistant Attorney General Cronan from United States Department of Justice said that \"as alleged in the indictment, Infraud operated like a business to facilitate cyberfraud on a global scale\" and that \"the Department of Justice refuses to allow these cybercriminals to use the perceived anonymity of the Internet as a shield for their crimes. We are committed to working closely with our international counterparts to identify, investigate, and bring to justice the perpetrators of these crimes, wherever in the world they operate.\" Acting Executive Associate Director Benner from Homeland Security Investigations mentioned that \"criminal cyber organizations like Infraud threaten not just U.S. citizens but people in every corner of the globe\" and that \"the actions of computer hackers and identity thieves not only harm countless innocent Americans, but the threat they pose to our financial system and global commerce cannot be overstated\"."
    }
  },
  {
    "instruction": "Answer based on context:\n\nTeslaCrypt\n\n==Introduction==\nTeslaCrypt was a ransomware trojan. It is now defunct, and its master key was released by the developers.\nIn its early forms, TeslaCrypt targeted game-play data for specific computer games. Newer variants of the malware also affect other file types.\nIn its original, game-player campaign, upon infection the malware searched for 185 file extensions related to 40 different games, which include the Call of Duty series, World of Warcraft, Minecraft and World of Tanks, and encrypted such files. The files targeted involve the save data, player profiles, custom maps and game mods stored on the victim's hard drives. Newer variants of TeslaCrypt were not focused on computer games alone but also encrypted Word, PDF, JPEG and other files. In all cases, the victim would then be prompted to pay a ransom of $500 worth of bitcoins in order to obtain the key to decrypt the files.Although resembling CryptoLocker in form and function, Teslacrypt shares no code with CryptoLocker and was developed independently. The malware infected computers via the Angler Adobe Flash exploit.Even though the ransomware claimed TeslaCrypt used asymmetric encryption, researchers from Cisco's Talos Group found that symmetric encryption was used and developed a decryption tool for it.  This \"deficiency\" was changed in version 2.0, rendering it impossible to decrypt files affected by TeslaCrypt-2.0.By November 2015, security researchers from Kaspersky had been quietly circulating that there was a new weakness in version 2.0, but carefully keeping that knowledge away from the malware developer so that they could not fix the flaw. As of January 2016, a new version 3.0 was discovered that had fixed the flaw.A full behavior report, which shows BehaviorGraphs and ExecutionGraphs was published by JoeSecurity.\n\n== Shut down ==\nIn May 2016, the developers of TeslaCrypt shut down the ransomware and released the master decryption key, thus bringing an end to the ransomware. After a few days, ESET released a public tool to decrypt affected computers at no charge.\n\nHow did TeslaCrypt infect computers, and what exploit did it use?",
    "context": "",
    "output": "TeslaCrypt infected computers through the Angler Adobe Flash exploit.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How did TeslaCrypt infect computers, and what exploit did it use?",
      "answer": "TeslaCrypt infected computers through the Angler Adobe Flash exploit.",
      "context": "TeslaCrypt\n\n==Introduction==\nTeslaCrypt was a ransomware trojan. It is now defunct, and its master key was released by the developers.\nIn its early forms, TeslaCrypt targeted game-play data for specific computer games. Newer variants of the malware also affect other file types.\nIn its original, game-player campaign, upon infection the malware searched for 185 file extensions related to 40 different games, which include the Call of Duty series, World of Warcraft, Minecraft and World of Tanks, and encrypted such files. The files targeted involve the save data, player profiles, custom maps and game mods stored on the victim's hard drives. Newer variants of TeslaCrypt were not focused on computer games alone but also encrypted Word, PDF, JPEG and other files. In all cases, the victim would then be prompted to pay a ransom of $500 worth of bitcoins in order to obtain the key to decrypt the files.Although resembling CryptoLocker in form and function, Teslacrypt shares no code with CryptoLocker and was developed independently. The malware infected computers via the Angler Adobe Flash exploit.Even though the ransomware claimed TeslaCrypt used asymmetric encryption, researchers from Cisco's Talos Group found that symmetric encryption was used and developed a decryption tool for it.  This \"deficiency\" was changed in version 2.0, rendering it impossible to decrypt files affected by TeslaCrypt-2.0.By November 2015, security researchers from Kaspersky had been quietly circulating that there was a new weakness in version 2.0, but carefully keeping that knowledge away from the malware developer so that they could not fix the flaw. As of January 2016, a new version 3.0 was discovered that had fixed the flaw.A full behavior report, which shows BehaviorGraphs and ExecutionGraphs was published by JoeSecurity.\n\n== Shut down ==\nIn May 2016, the developers of TeslaCrypt shut down the ransomware and released the master decryption key, thus bringing an end to the ransomware. After a few days, ESET released a public tool to decrypt affected computers at no charge."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the length requirement for the bit string to undergo the pseudo-Hadamard transform?",
    "context": "",
    "output": "The bit string must be of even length to undergo the pseudo-Hadamard transform, so that it can be split into two equal halves of equal length.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the length requirement for the bit string to undergo the pseudo-Hadamard transform?",
      "answer": "The bit string must be of even length to undergo the pseudo-Hadamard transform, so that it can be split into two equal halves of equal length."
    }
  },
  {
    "instruction": "NSO Group\n\n==Introduction==\nNSO Group Technologies (NSO standing for Niv, Shalev and Omri, the names of the company's founders) is an Israeli cyber-intelligence firm primarily known for its proprietary spyware Pegasus, which is capable of remote zero-click surveillance of smartphones. It employed almost 500 people as of 2017.NSO claims that it provides authorized governments with technology that helps them combat terror and crime. The company says that it deals with government clients only. Pegasus spyware is classified as a weapon by Israel and any export of the technology must be approved by the government.According to several reports, NSO Group spyware has been used to target human rights activists and journalists in various countries, was used for state espionage against Pakistan, for warrantless domestic surveillance of Israeli citizens by Israeli police, and played a role in the murder of Saudi dissident Jamal Khashoggi by agents of the Saudi government.In 2019, instant messaging company WhatsApp and its parent company Meta Platforms (then known as Facebook) sued NSO under the United States Computer Fraud and Abuse Act. In 2021, Apple filed a lawsuit against NSO in the U.S., and the US included NSO Group in its Entity List for acting against U.S. national security and foreign policy interests, effectively banning U.S. companies from supplying NSO.\n\n\n\n== Corporate profile ==\n\n\n*** Overview ***\nNSO Group is a subsidiary of the Q Cyber Technologies group of companies. Q Cyber Technologies is the name the NSO Group uses in Israel, but the company goes by OSY Technologies in Luxembourg, and in North America, a subsidiary formerly known as Westbridge. It has operated through various other companies around the world.\n\n\n**** Founding ****\nNSO Group was founded in 2010 by Niv Karmi, Omri Lavie, and Shalev Hulio. Hulio and Lavie were school friends who went into the technology start-up sector during the mid-2000s. The pair founded a company - CommuniTake - which offered a tool that let cellphone tech support workers access the customers' devices (but necessitating that the customer grant permission to enable access). After a European intelligence agency expressed interest in the product, the pair realised they could instead develop a tool that could gain access to phones without user authorisation, and market it to security and intelligence agencies. Karmi, who served in military intelligence and the Mossad, was brought on board to help market the tool with the help of his contacts. The first iteration of NSO's Pegasus spyware was finalised in 2011.\n\n\n**** Operations ****\nNSO Group has come to employ over 700 personnel globally. Almost all of NSO's research team is made up of former Israeli military intelligence personnel, most of them having served in Israel's Military Intelligence Directorate, and many of these in its Unit 8200. The company's most valuable staff are graduates of the military intelligence's highly selective advanced cyberweapons training programs. NSO seeks to uncover a surfeit of zero-day exploits in target devices to ensure smooth continuous access even as some of the security vulnerabilities exploited by NSO are inevitably discovered and patched, with labs in the company's Herzliya headquarters featuring racks stacked with phones being tested against new exploits.\n\n\n**** Relationship with the Israeli state ****\nPegasus spyware is classified as a military export by Israel and its sale is controlled by the government. According to The New York Times, \"Israel\u2019s government has long seen Pegasus as a critical tool for its foreign policy.\" and that it \"[...] has treated NSO as a de facto arm of the state, granting licenses for Pegasus to numerous countries [...] with which the Israeli government hoped to nurture stronger security and diplomatic ties.\" Israel has used the sale of NSO products as a diplomatic bargaining chip to advance its foreign policy interests as well as limiting its sale to or its use against certain states to maintain good relations with certain states. Israel has faced criticism for approving the sale of NSO technologies to countries with poor human rights records. U.S. intelligence officials have also said the Israeli state presumably has backdoor access to data obtained by Pegasus. NSO denies being \"a tool of Israeli diplomacy\", and denies the presence of a backdoor in its spyware tools.Israel, wary of angering the U.S. in the wake of the Snowden revelations, required NSO to prevent Pegasus from targeting American phone numbers. Israel has used Pegasus to advance its interests in the region, with Pegasus playing a role in negotiating the Abraham Accords. A New York Times investigation highlighted several instances in which the sale of Pegasus to a particular government coincided with that government's increased support of Israel. Israel has used Pegasus sales in its diplomatic efforts to forge a united front against Israel, thus clearing the sale of the spyware to Azerbaijan, Morocco, the UAE, and Saudi Arabia. The Israeli government also blocked the sale of Pegasus to Estonia and Ukraine for fear that Israel's relations with Russia would be damaged if the spyware was used against Russia. Israel initially authorised the export of Pegasus to Estonia (which made a $30 million down payment to obtain the system), but after a senior Russian official approached Israeli security agencies and informed them that Russia had learned of Estonia's attempts to obtain Pegasus, the Israeli Ministry of Defense decided to disallow Estonia from using Pegasus against any Russian phone numbers following a heated debate on the issue among Israeli officials, and subsequently blocked the sale.\n\n\n*** Corporate history ***\nThe company's start-up funding came from a group of investors headed by Eddy Shalev, a partner in venture capital fund Genesis Partners which invested a total of $1.8 million for a 30% stake.In 2013, NSO's annual revenues were around US$40 million.In 2014, the U.S.-based private equity firm Francisco Partners bought the company for $130 million.In 2014, the surveillance firm Circles (which produces is a phone geolocation tool) was acquired by Francisco Parterns for $130 million, and thus became a corporate affiliate of NSO's.In 2015 Francisco was seeking to sell the company for up to $1 billion.Annual revenues were around $150 million in 2015.In June 2017, the company was put up for sale for more than $1 billion by Francisco Partners (roughly ten times what Francisco originally paid to acquire it in 2014). At the time it was put up for sale, NSO had almost 500 employees (up from around 50 in 2014).On February 14, 2019, Francisco Partners sold a majority (60%) stake of NSO back to co-founders Shalev Hulio and Omri Lavie, who were supported in the purchase by European private equity fund Novalpina Capital which specialises in investments in controversial companies. Hulio and Lavie invested $100 million, with Novalpina acquiring the remaining portion of the majority stake, thus valuing the company at approximately $1 billion. The day after the acquisition, Novalpina attempted to address the concerns raised by Citizen Lab with a letter, stating their belief that NSO operates with sufficient integrity and caution.In July 2021, investors in Novalpina Capital stripped Novalpina Capital of control over its assets (including NSO) after an unresolved personal dispute amongst the co-founders of Novalpina Capital. Berkeley Research Group (BRG), a California-based consultancy firm, was subsequently handed control over the assets (including NSO).By the time of BRG's takeover, NSO Group was in perilous financial straits, having gone months without a new sale and in risk of missing its debt payments and its November 2021 payroll payments. NSO CEO Shalev Hulio suggested to BRG that the company should improve its financial standing by starting to sell its products to high-risk customers previously deemed unacceptable, responding to objections by joking that missing debt payments was risky too. BRG was categorically opposed to the suggestion despite acknowledging that selling to high-risk customers was the only realistic way of maintaining NSO's business operations. Hulio proposed increasing sales to Israel's western allies (including U.S. law enforcement, the most lucrative prospective market), but the November 2021 U.S. blacklisting of NSO subsequently ended the company's prospects of breaking into the U.S. market (Hulio then devised a plan to split up the company in order to circumvent the U.S. sanctions). According to the Financial Times, NSO also seemed to have been abandoned by the previously doting Israeli government due to a proliferation of Israeli companies offering comparable technologies (including some established by former NSO employees). In a court filing, BRG described NSO as \"valueless\" to its private equity backers; in December 2021, a group of NSO creditors described NSO as insolvent in a letter to NSO's majority shareholders.Two of the ousted co-founders attempted to reclaim control over Novalpina Capital's assets by filing a lawsuit in Luxemburg, with a U.K. court allowing the case to proceed to trial in April 2022. In an April 2022 letter, BRG told an EU committee investigating abuse of NSO's products that NSO's management has not been forthcoming in providing information about its business operations, including on the issue of the company's blacklisting in the U.S.In the months after the November 2021 blacklisting of NSO by the U.S. Department of Commerce that resulted in an U.S. export ban for the company, and amid a campaign by the Israeli government to find a way to prevent the floundering NSO from going under, the U.S. Commerce Department sent a list of questions to NSO about how its spyware products operate. In 2022, L3Harris Technologies, a U.S. military contractor with experience in the spyware technology sector, was conducting talks on the possibility of acquiring NSO. L3Harris sought to acquire NSO's technology and code with the acquisition of the company's employees discussed as well. L3Harris executives travelled to Israel to conduct the talks which were not disclosed to the public. L3Harris reportedly told their NSO counterparts that they had the blessing and backing of the U.S. government and U.S. intelligence in pursuing the acquisition as long as the Pegasus source code and the cache of zero-day vulnerabilities uncovered by NSO could be passed on to the other intelligence agencies of the Five Eyes. The Israeli authorities were reportedly willing to fulfill the latter and reluctant to comply with the former, and also insisted that Israel ultimately retain control over issuing export licences for NSO's products. The Israeli authorities were also opposed to allowing L3Harris' employees to join NSO's development team in NSO's Israeli headquarters. The talks were revealed to the public by the press in June 2022, resulting in a scramble by the parties involved, with White House officials publicly condemning the negotiation in harsh terms, and L3Harris (which is heavily reliant on government contracts) reportedly notifying the U.S. government that they had abandoned the acquisition attempt. There were reportedly attempts to revive the negotiations in the weeks after the preceding negotiations were revealed by the press. An acquisition by a U.S.-based corporation could have lifted the blacklisting of NSO by the U.S. which had barred NSO from receiving exports from U.S. companies, hindering NSO's operations. Experts consulted by The Guardian said that due to the blacklisting of NSO Group, a new corporate entity would likely have had to be created before the U.S. government would allow the acquisition. A senior White House official commented anonymously for the article that made the secret acquisition negotiations public, stating that the White House had not been in any way involved in the deal, further stating that the U.S. government \"opposes efforts by foreign companies to circumvent US export control measures or sanctions [...]\".In August 2022, Hulio stepped down from his post as CEO, with the company's COO Yaron Shohat temporarily assuming the role until a full-time replacement was to be named. Hulio's resignation from his post as CEO came amid a restructuring of the company as it attempted to focus on pursuing clients among NATO member countries. The reorganisation also entailed a downsizing NSO's workforce, with 100 employees (out of a total of 750 employees) being let go.In March 2023, it was reported that Omrie Lavie had emerged in control of the company after multiple legal fights between NSO and a US financial firm called Treo, which previously controlled the equity fund that held a majority stake in the Israeli firm.\n\n\n*** Foreign offices and export controls ***\nIn late 2020, Vice Media published an article in which it reported that NSO Group had closed the Cyprus-based offices of Circles, the company it had acquired in 2014. The article, based on interviews with two former employees, described the integration between the two companies as \"awful\" and stated that NSO would rely on Circles' Bulgarian office instead. According to Vice, this came just over a year after an activist group known as Access Now wrote to authorities in both Cyprus and Bulgaria, asking them to further scrutinise NSO exports. Access now had stated that they had received denials from both the Bulgarian and Cypriot authorities, with both countries stating that they had not provided export licenses to the NSO group. Despite this, an article written by The Guardian during the 2021 Pegasus scandal quoted NSO Group as saying that it had been \"regulated by the export control regimes of Israel, Cyprus and Bulgaria\". NSO's own \"Transparency and Responsibility Report 2021\", published about a month before the scandal, makes the same statement, adding that those were the three countries through which NSO exported its products. Circles' Bulgarian office, in particular, was stated to have been founded as a \"bogus phone company\" in 2015 by Citizen Lab citing IntelligenceOnline, a part of Indigo Publications. This report was reprinted by the Bulgarian investigation publication Bivol in December 2020, which appended it with public registry documents which indicated that the company's Bulgarian office had grown to employ up to 150 people and had received two loans worth about 275 million American dollars in 2017 from two offshore companies and a Swiss bank registered in the Cayman Islands.\n\n== Products and services ==\n\n\n*** Pegasus ***\n\nNSO Groups offers the smartphone spyware tool Pegasus to government clients for the exclusive intended purpose of combating crime and terrorism. The first version of Pegasus was finalised in 2011. Pegasus spyware is classified as a weapon by Israel and any export of the technology must be approved by the government. The Israeli Ministry of Defense licenses the export of Pegasus to foreign governments, but not to private entities.Pegasus is compatible with iPhone and Android devices. It can be deployed remotely. Once deployed, it allows the client to access the target phone's data and sensors, including: location data, texts, emails, social media messages, files, camera, and microphone. The client-facing side of the tool is user friendly, and all that may be required (depending upon the case) of the client to begin deployment of Pegasus is to enter the target's phone number into the tool.\n\n\n**** Phantom ****\nPhantom is a phone hacking product marketed by Westbridge, the United States branch of NSO Group. According to a former NSO employee, \"Phantom\" is the brand name for the Pegasus in the U.S., but the two tools are otherwise identical. Israel required NSO Group to program Pegasus so as not to be able to target US phone numbers. NSO then launched Phantom for the U.S. market for use on U.S. targets, receiving permission from Israel to develop it as a specialty tool for exclusive use by U.S. governmental agencies.\n\n\n*** Circles ***\nIn 2014, the surveillance firm Circles was acquired by Francisco Partners, becoming a corporate affiliate of NSO Group. Circles' product is a phone geolocation tool. The firm has two systems. One operates by connecting to the purchasing country's local telecommunications companies\u2019 infrastructure. The other separate system, known as the \u201cCircles Cloud\u201d, is capable of interconnecting with telecommunications companies across the globe.In December 2020, the Citizen Lab reported that Supreme Council on National Security (SCNS) of the United Arab Emirates was set to receive both these systems. In a lawsuit filed against the NSO group in Israel, emails revealed links between Circles and several customers in the United Arab Emirates. Documents also revealed that Circles sent targets\u2019 locations and phone records to the UAE SCNS. Aside from Israel and the UAE, the report named the governments of Australia, Belgium, Botswana, Chile, Denmark, Ecuador, El Salvador, Estonia, Equatorial Guinea, Guatemala, Honduras, Indonesia, Kenya, Malaysia, Mexico, Morocco, Nigeria, Peru, Serbia, Vietnam, Zambia, and Zimbabwe as likely customers of Circles surveillance technology.In September 2021, Forensic News published shipping records showing that in 2020 Circles supplied equipment to Uzbekistan's State Security Service (SGB).\n\n== Criticism and controversies ==\n\n\n*** Use of undercover private investigators to pursue critics ***\nIn October 2018, Associated Press reported that two Citizen Lab researchers were being pursued by undercover operatives with false identities. The undercover agents had been inquiring about their work involving NSO Group, and also appeared to be trying to goad the researchers into making anti-Semitic or otherwise damaging remarks. After growing suspicious, one researcher contacted AP reporters. Together, they managed to arrange a sting during a meeting with a suspected undercover operative at a hotel luncheon with AP journalists secretly awaiting nearby; after the journalists approached the operative to question him, the operative fled, bumping into chairs and circling the room as he tried to get away. There also appeared to be two additional undercover operatives in the room. The operative that met the researcher appeared to be filming the researcher with a hidden camera during the meeting, and one of the operatives standing nearby appeared to be recording the meeting as well. The operative was later identified as a former Israeli security official. Responding to the AP report, NSO denied any involvement. It was later also uncovered that the identified undercover agent had previously worked on a case linked to the Israeli private intelligence agency Black Cube; NSO Group subsequently denied contracting Black Cube, and Black Cube denied involvement as well.In February 2019, Associated Press reported that at least four more individuals - three lawyers involved in lawsuits against NSO Group for alleged sales of NSO spyware to governments with poor human rights records, and one journalist who had been covering said litigation - were being pursued by undercover operatives for their work on NSO. Undercover agents again tried to goad the individuals into making racist or anti-Israel remarks. Two of the individuals were surreptitiously recorded by the undercover operatives. Channel 12, an Israeli television channel, obtained and aired the secret recordings made by the undercover operatives shortly before the AP published the revelations. Channel 12 claimed the two individuals were attempting to smear NSO Group on behalf of Qatar. Channel 12 also confirmed that Black Cube undercover investigators were involved.\n\n\n*** WhatsApp lawsuit ***\nIn May 2019, messaging service WhatsApp alleged that a spyware injection exploit targeting its calling feature was developed by NSO. Victims were exposed to the spyware payload even if they did not answer the call. WhatsApp told the Financial Times that \"the attack has all the hallmarks of a private company known to work with governments to deliver spyware that reportedly takes over the functions of mobile phone operating systems.\" NSO denied involvement in selecting or targeting victims, but did not explicitly deny creating the exploit. In response to the alleged cyberattack, WhatsApp sued NSO under the Computer Fraud and Abuse Act and other US laws in a San Francisco court on October 29. WhatsApp stated that the exploit targeted 1,400 users in 20 countries, including \"at least 100 human-rights defenders, journalists and other members of civil society\". WhatsApp alerted the 1,400 targeted users. In at least one case, the surveillance was authorized by a judge.NSO employees had complained to WhatsApp about improved security, according to the court filings by WhatsApp and its parent company Facebook:\nOn or about May 13, 2019, Facebook publicly announced that it had investigated and identified a vulnerability involving the WhatsApp Service (CVE-2019-3568). WhatsApp and Facebook closed the vulnerability, contacted law enforcement, and advised users to update the WhatsApp app. Defendants subsequently complained that WhatsApp had closed the vulnerability. Specifically, NSO Employee 1 stated, \"You just closed our biggest remote for cellular ... It's on the news all over the world.\"\nIn April 2020, NSO group blamed its government clients for the hacking of 1,400 WhatsApp users, including journalists and human rights activists. However, the firm did not disclose the names of the clients which, as Citizen Lab stated, include authorities in Saudi Arabia, UAE, Bahrain, Kazakhstan, Morocco, and Mexico. In court filings WhatsApp alleged that its investigation showed that the hacks originated from NSO Group servers rather than its clients'. WhatsApp said \"NSO used a network of computers to monitor and update Pegasus after it was implanted on users' devices. These NSO-controlled computers served as the nerve centre through which NSO controlled its customers' operation and use of Pegasus.\" WhatsApp said that NSO gained \"unauthorised access\" to WhatsApp servers by reverse-engineering the WhatsApp app to be able to evade security features. NSO responded \"NSO Group does not operate the Pegasus software for its clients\".\n\n\n*** Apple lawsuit ***\nIn November 2021, Apple Inc. filed a complaint against NSO Group and its parent company Q Cyber Technologies in the United States District Court for the Northern District of California about the FORCEDENTRY exploit used to deploy the Pegasus spyware package, requesting injunctive relief, compensatory damages, punitive damages, and disgorgement of profits. The \"zero-click\" exploit was discovered by the Canadian Citizen Lab after Saudi activist Loujain al-Hathloul's iPhone was hacked. Technical information uncovered by Bill Marczak's team at the lab allowed Apple to warn thousands of its users, including U.S. State Department employees in Uganda. Researchers also discovered that spyware from QuaDream, another Israeli vendor, took advantage of the same vulnerability in iPhones.\n\nAnswer this question based on the above context: How has NSO Group's financial situation evolved, and what are the implications for the future of the company and its technologies?",
    "context": "",
    "output": "NSO Group has experienced financial struggles, including going months without a new sale and facing the risk of missing debt payments and its November 2021 payroll payments. This, coupled with a proliferation of Israeli companies offering comparable technologies, has led to uncertainty about the future of the company and its technologies.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How has NSO Group's financial situation evolved, and what are the implications for the future of the company and its technologies?",
      "answer": "NSO Group has experienced financial struggles, including going months without a new sale and facing the risk of missing debt payments and its November 2021 payroll payments. This, coupled with a proliferation of Israeli companies offering comparable technologies, has led to uncertainty about the future of the company and its technologies.",
      "context": "NSO Group\n\n==Introduction==\nNSO Group Technologies (NSO standing for Niv, Shalev and Omri, the names of the company's founders) is an Israeli cyber-intelligence firm primarily known for its proprietary spyware Pegasus, which is capable of remote zero-click surveillance of smartphones. It employed almost 500 people as of 2017.NSO claims that it provides authorized governments with technology that helps them combat terror and crime. The company says that it deals with government clients only. Pegasus spyware is classified as a weapon by Israel and any export of the technology must be approved by the government.According to several reports, NSO Group spyware has been used to target human rights activists and journalists in various countries, was used for state espionage against Pakistan, for warrantless domestic surveillance of Israeli citizens by Israeli police, and played a role in the murder of Saudi dissident Jamal Khashoggi by agents of the Saudi government.In 2019, instant messaging company WhatsApp and its parent company Meta Platforms (then known as Facebook) sued NSO under the United States Computer Fraud and Abuse Act. In 2021, Apple filed a lawsuit against NSO in the U.S., and the US included NSO Group in its Entity List for acting against U.S. national security and foreign policy interests, effectively banning U.S. companies from supplying NSO.\n\n\n\n== Corporate profile ==\n\n\n*** Overview ***\nNSO Group is a subsidiary of the Q Cyber Technologies group of companies. Q Cyber Technologies is the name the NSO Group uses in Israel, but the company goes by OSY Technologies in Luxembourg, and in North America, a subsidiary formerly known as Westbridge. It has operated through various other companies around the world.\n\n\n**** Founding ****\nNSO Group was founded in 2010 by Niv Karmi, Omri Lavie, and Shalev Hulio. Hulio and Lavie were school friends who went into the technology start-up sector during the mid-2000s. The pair founded a company - CommuniTake - which offered a tool that let cellphone tech support workers access the customers' devices (but necessitating that the customer grant permission to enable access). After a European intelligence agency expressed interest in the product, the pair realised they could instead develop a tool that could gain access to phones without user authorisation, and market it to security and intelligence agencies. Karmi, who served in military intelligence and the Mossad, was brought on board to help market the tool with the help of his contacts. The first iteration of NSO's Pegasus spyware was finalised in 2011.\n\n\n**** Operations ****\nNSO Group has come to employ over 700 personnel globally. Almost all of NSO's research team is made up of former Israeli military intelligence personnel, most of them having served in Israel's Military Intelligence Directorate, and many of these in its Unit 8200. The company's most valuable staff are graduates of the military intelligence's highly selective advanced cyberweapons training programs. NSO seeks to uncover a surfeit of zero-day exploits in target devices to ensure smooth continuous access even as some of the security vulnerabilities exploited by NSO are inevitably discovered and patched, with labs in the company's Herzliya headquarters featuring racks stacked with phones being tested against new exploits.\n\n\n**** Relationship with the Israeli state ****\nPegasus spyware is classified as a military export by Israel and its sale is controlled by the government. According to The New York Times, \"Israel\u2019s government has long seen Pegasus as a critical tool for its foreign policy.\" and that it \"[...] has treated NSO as a de facto arm of the state, granting licenses for Pegasus to numerous countries [...] with which the Israeli government hoped to nurture stronger security and diplomatic ties.\" Israel has used the sale of NSO products as a diplomatic bargaining chip to advance its foreign policy interests as well as limiting its sale to or its use against certain states to maintain good relations with certain states. Israel has faced criticism for approving the sale of NSO technologies to countries with poor human rights records. U.S. intelligence officials have also said the Israeli state presumably has backdoor access to data obtained by Pegasus. NSO denies being \"a tool of Israeli diplomacy\", and denies the presence of a backdoor in its spyware tools.Israel, wary of angering the U.S. in the wake of the Snowden revelations, required NSO to prevent Pegasus from targeting American phone numbers. Israel has used Pegasus to advance its interests in the region, with Pegasus playing a role in negotiating the Abraham Accords. A New York Times investigation highlighted several instances in which the sale of Pegasus to a particular government coincided with that government's increased support of Israel. Israel has used Pegasus sales in its diplomatic efforts to forge a united front against Israel, thus clearing the sale of the spyware to Azerbaijan, Morocco, the UAE, and Saudi Arabia. The Israeli government also blocked the sale of Pegasus to Estonia and Ukraine for fear that Israel's relations with Russia would be damaged if the spyware was used against Russia. Israel initially authorised the export of Pegasus to Estonia (which made a $30 million down payment to obtain the system), but after a senior Russian official approached Israeli security agencies and informed them that Russia had learned of Estonia's attempts to obtain Pegasus, the Israeli Ministry of Defense decided to disallow Estonia from using Pegasus against any Russian phone numbers following a heated debate on the issue among Israeli officials, and subsequently blocked the sale.\n\n\n*** Corporate history ***\nThe company's start-up funding came from a group of investors headed by Eddy Shalev, a partner in venture capital fund Genesis Partners which invested a total of $1.8 million for a 30% stake.In 2013, NSO's annual revenues were around US$40 million.In 2014, the U.S.-based private equity firm Francisco Partners bought the company for $130 million.In 2014, the surveillance firm Circles (which produces is a phone geolocation tool) was acquired by Francisco Parterns for $130 million, and thus became a corporate affiliate of NSO's.In 2015 Francisco was seeking to sell the company for up to $1 billion.Annual revenues were around $150 million in 2015.In June 2017, the company was put up for sale for more than $1 billion by Francisco Partners (roughly ten times what Francisco originally paid to acquire it in 2014). At the time it was put up for sale, NSO had almost 500 employees (up from around 50 in 2014).On February 14, 2019, Francisco Partners sold a majority (60%) stake of NSO back to co-founders Shalev Hulio and Omri Lavie, who were supported in the purchase by European private equity fund Novalpina Capital which specialises in investments in controversial companies. Hulio and Lavie invested $100 million, with Novalpina acquiring the remaining portion of the majority stake, thus valuing the company at approximately $1 billion. The day after the acquisition, Novalpina attempted to address the concerns raised by Citizen Lab with a letter, stating their belief that NSO operates with sufficient integrity and caution.In July 2021, investors in Novalpina Capital stripped Novalpina Capital of control over its assets (including NSO) after an unresolved personal dispute amongst the co-founders of Novalpina Capital. Berkeley Research Group (BRG), a California-based consultancy firm, was subsequently handed control over the assets (including NSO).By the time of BRG's takeover, NSO Group was in perilous financial straits, having gone months without a new sale and in risk of missing its debt payments and its November 2021 payroll payments. NSO CEO Shalev Hulio suggested to BRG that the company should improve its financial standing by starting to sell its products to high-risk customers previously deemed unacceptable, responding to objections by joking that missing debt payments was risky too. BRG was categorically opposed to the suggestion despite acknowledging that selling to high-risk customers was the only realistic way of maintaining NSO's business operations. Hulio proposed increasing sales to Israel's western allies (including U.S. law enforcement, the most lucrative prospective market), but the November 2021 U.S. blacklisting of NSO subsequently ended the company's prospects of breaking into the U.S. market (Hulio then devised a plan to split up the company in order to circumvent the U.S. sanctions). According to the Financial Times, NSO also seemed to have been abandoned by the previously doting Israeli government due to a proliferation of Israeli companies offering comparable technologies (including some established by former NSO employees). In a court filing, BRG described NSO as \"valueless\" to its private equity backers; in December 2021, a group of NSO creditors described NSO as insolvent in a letter to NSO's majority shareholders.Two of the ousted co-founders attempted to reclaim control over Novalpina Capital's assets by filing a lawsuit in Luxemburg, with a U.K. court allowing the case to proceed to trial in April 2022. In an April 2022 letter, BRG told an EU committee investigating abuse of NSO's products that NSO's management has not been forthcoming in providing information about its business operations, including on the issue of the company's blacklisting in the U.S.In the months after the November 2021 blacklisting of NSO by the U.S. Department of Commerce that resulted in an U.S. export ban for the company, and amid a campaign by the Israeli government to find a way to prevent the floundering NSO from going under, the U.S. Commerce Department sent a list of questions to NSO about how its spyware products operate. In 2022, L3Harris Technologies, a U.S. military contractor with experience in the spyware technology sector, was conducting talks on the possibility of acquiring NSO. L3Harris sought to acquire NSO's technology and code with the acquisition of the company's employees discussed as well. L3Harris executives travelled to Israel to conduct the talks which were not disclosed to the public. L3Harris reportedly told their NSO counterparts that they had the blessing and backing of the U.S. government and U.S. intelligence in pursuing the acquisition as long as the Pegasus source code and the cache of zero-day vulnerabilities uncovered by NSO could be passed on to the other intelligence agencies of the Five Eyes. The Israeli authorities were reportedly willing to fulfill the latter and reluctant to comply with the former, and also insisted that Israel ultimately retain control over issuing export licences for NSO's products. The Israeli authorities were also opposed to allowing L3Harris' employees to join NSO's development team in NSO's Israeli headquarters. The talks were revealed to the public by the press in June 2022, resulting in a scramble by the parties involved, with White House officials publicly condemning the negotiation in harsh terms, and L3Harris (which is heavily reliant on government contracts) reportedly notifying the U.S. government that they had abandoned the acquisition attempt. There were reportedly attempts to revive the negotiations in the weeks after the preceding negotiations were revealed by the press. An acquisition by a U.S.-based corporation could have lifted the blacklisting of NSO by the U.S. which had barred NSO from receiving exports from U.S. companies, hindering NSO's operations. Experts consulted by The Guardian said that due to the blacklisting of NSO Group, a new corporate entity would likely have had to be created before the U.S. government would allow the acquisition. A senior White House official commented anonymously for the article that made the secret acquisition negotiations public, stating that the White House had not been in any way involved in the deal, further stating that the U.S. government \"opposes efforts by foreign companies to circumvent US export control measures or sanctions [...]\".In August 2022, Hulio stepped down from his post as CEO, with the company's COO Yaron Shohat temporarily assuming the role until a full-time replacement was to be named. Hulio's resignation from his post as CEO came amid a restructuring of the company as it attempted to focus on pursuing clients among NATO member countries. The reorganisation also entailed a downsizing NSO's workforce, with 100 employees (out of a total of 750 employees) being let go.In March 2023, it was reported that Omrie Lavie had emerged in control of the company after multiple legal fights between NSO and a US financial firm called Treo, which previously controlled the equity fund that held a majority stake in the Israeli firm.\n\n\n*** Foreign offices and export controls ***\nIn late 2020, Vice Media published an article in which it reported that NSO Group had closed the Cyprus-based offices of Circles, the company it had acquired in 2014. The article, based on interviews with two former employees, described the integration between the two companies as \"awful\" and stated that NSO would rely on Circles' Bulgarian office instead. According to Vice, this came just over a year after an activist group known as Access Now wrote to authorities in both Cyprus and Bulgaria, asking them to further scrutinise NSO exports. Access now had stated that they had received denials from both the Bulgarian and Cypriot authorities, with both countries stating that they had not provided export licenses to the NSO group. Despite this, an article written by The Guardian during the 2021 Pegasus scandal quoted NSO Group as saying that it had been \"regulated by the export control regimes of Israel, Cyprus and Bulgaria\". NSO's own \"Transparency and Responsibility Report 2021\", published about a month before the scandal, makes the same statement, adding that those were the three countries through which NSO exported its products. Circles' Bulgarian office, in particular, was stated to have been founded as a \"bogus phone company\" in 2015 by Citizen Lab citing IntelligenceOnline, a part of Indigo Publications. This report was reprinted by the Bulgarian investigation publication Bivol in December 2020, which appended it with public registry documents which indicated that the company's Bulgarian office had grown to employ up to 150 people and had received two loans worth about 275 million American dollars in 2017 from two offshore companies and a Swiss bank registered in the Cayman Islands.\n\n== Products and services ==\n\n\n*** Pegasus ***\n\nNSO Groups offers the smartphone spyware tool Pegasus to government clients for the exclusive intended purpose of combating crime and terrorism. The first version of Pegasus was finalised in 2011. Pegasus spyware is classified as a weapon by Israel and any export of the technology must be approved by the government. The Israeli Ministry of Defense licenses the export of Pegasus to foreign governments, but not to private entities.Pegasus is compatible with iPhone and Android devices. It can be deployed remotely. Once deployed, it allows the client to access the target phone's data and sensors, including: location data, texts, emails, social media messages, files, camera, and microphone. The client-facing side of the tool is user friendly, and all that may be required (depending upon the case) of the client to begin deployment of Pegasus is to enter the target's phone number into the tool.\n\n\n**** Phantom ****\nPhantom is a phone hacking product marketed by Westbridge, the United States branch of NSO Group. According to a former NSO employee, \"Phantom\" is the brand name for the Pegasus in the U.S., but the two tools are otherwise identical. Israel required NSO Group to program Pegasus so as not to be able to target US phone numbers. NSO then launched Phantom for the U.S. market for use on U.S. targets, receiving permission from Israel to develop it as a specialty tool for exclusive use by U.S. governmental agencies.\n\n\n*** Circles ***\nIn 2014, the surveillance firm Circles was acquired by Francisco Partners, becoming a corporate affiliate of NSO Group. Circles' product is a phone geolocation tool. The firm has two systems. One operates by connecting to the purchasing country's local telecommunications companies\u2019 infrastructure. The other separate system, known as the \u201cCircles Cloud\u201d, is capable of interconnecting with telecommunications companies across the globe.In December 2020, the Citizen Lab reported that Supreme Council on National Security (SCNS) of the United Arab Emirates was set to receive both these systems. In a lawsuit filed against the NSO group in Israel, emails revealed links between Circles and several customers in the United Arab Emirates. Documents also revealed that Circles sent targets\u2019 locations and phone records to the UAE SCNS. Aside from Israel and the UAE, the report named the governments of Australia, Belgium, Botswana, Chile, Denmark, Ecuador, El Salvador, Estonia, Equatorial Guinea, Guatemala, Honduras, Indonesia, Kenya, Malaysia, Mexico, Morocco, Nigeria, Peru, Serbia, Vietnam, Zambia, and Zimbabwe as likely customers of Circles surveillance technology.In September 2021, Forensic News published shipping records showing that in 2020 Circles supplied equipment to Uzbekistan's State Security Service (SGB).\n\n== Criticism and controversies ==\n\n\n*** Use of undercover private investigators to pursue critics ***\nIn October 2018, Associated Press reported that two Citizen Lab researchers were being pursued by undercover operatives with false identities. The undercover agents had been inquiring about their work involving NSO Group, and also appeared to be trying to goad the researchers into making anti-Semitic or otherwise damaging remarks. After growing suspicious, one researcher contacted AP reporters. Together, they managed to arrange a sting during a meeting with a suspected undercover operative at a hotel luncheon with AP journalists secretly awaiting nearby; after the journalists approached the operative to question him, the operative fled, bumping into chairs and circling the room as he tried to get away. There also appeared to be two additional undercover operatives in the room. The operative that met the researcher appeared to be filming the researcher with a hidden camera during the meeting, and one of the operatives standing nearby appeared to be recording the meeting as well. The operative was later identified as a former Israeli security official. Responding to the AP report, NSO denied any involvement. It was later also uncovered that the identified undercover agent had previously worked on a case linked to the Israeli private intelligence agency Black Cube; NSO Group subsequently denied contracting Black Cube, and Black Cube denied involvement as well.In February 2019, Associated Press reported that at least four more individuals - three lawyers involved in lawsuits against NSO Group for alleged sales of NSO spyware to governments with poor human rights records, and one journalist who had been covering said litigation - were being pursued by undercover operatives for their work on NSO. Undercover agents again tried to goad the individuals into making racist or anti-Israel remarks. Two of the individuals were surreptitiously recorded by the undercover operatives. Channel 12, an Israeli television channel, obtained and aired the secret recordings made by the undercover operatives shortly before the AP published the revelations. Channel 12 claimed the two individuals were attempting to smear NSO Group on behalf of Qatar. Channel 12 also confirmed that Black Cube undercover investigators were involved.\n\n\n*** WhatsApp lawsuit ***\nIn May 2019, messaging service WhatsApp alleged that a spyware injection exploit targeting its calling feature was developed by NSO. Victims were exposed to the spyware payload even if they did not answer the call. WhatsApp told the Financial Times that \"the attack has all the hallmarks of a private company known to work with governments to deliver spyware that reportedly takes over the functions of mobile phone operating systems.\" NSO denied involvement in selecting or targeting victims, but did not explicitly deny creating the exploit. In response to the alleged cyberattack, WhatsApp sued NSO under the Computer Fraud and Abuse Act and other US laws in a San Francisco court on October 29. WhatsApp stated that the exploit targeted 1,400 users in 20 countries, including \"at least 100 human-rights defenders, journalists and other members of civil society\". WhatsApp alerted the 1,400 targeted users. In at least one case, the surveillance was authorized by a judge.NSO employees had complained to WhatsApp about improved security, according to the court filings by WhatsApp and its parent company Facebook:\nOn or about May 13, 2019, Facebook publicly announced that it had investigated and identified a vulnerability involving the WhatsApp Service (CVE-2019-3568). WhatsApp and Facebook closed the vulnerability, contacted law enforcement, and advised users to update the WhatsApp app. Defendants subsequently complained that WhatsApp had closed the vulnerability. Specifically, NSO Employee 1 stated, \"You just closed our biggest remote for cellular ... It's on the news all over the world.\"\nIn April 2020, NSO group blamed its government clients for the hacking of 1,400 WhatsApp users, including journalists and human rights activists. However, the firm did not disclose the names of the clients which, as Citizen Lab stated, include authorities in Saudi Arabia, UAE, Bahrain, Kazakhstan, Morocco, and Mexico. In court filings WhatsApp alleged that its investigation showed that the hacks originated from NSO Group servers rather than its clients'. WhatsApp said \"NSO used a network of computers to monitor and update Pegasus after it was implanted on users' devices. These NSO-controlled computers served as the nerve centre through which NSO controlled its customers' operation and use of Pegasus.\" WhatsApp said that NSO gained \"unauthorised access\" to WhatsApp servers by reverse-engineering the WhatsApp app to be able to evade security features. NSO responded \"NSO Group does not operate the Pegasus software for its clients\".\n\n\n*** Apple lawsuit ***\nIn November 2021, Apple Inc. filed a complaint against NSO Group and its parent company Q Cyber Technologies in the United States District Court for the Northern District of California about the FORCEDENTRY exploit used to deploy the Pegasus spyware package, requesting injunctive relief, compensatory damages, punitive damages, and disgorgement of profits. The \"zero-click\" exploit was discovered by the Canadian Citizen Lab after Saudi activist Loujain al-Hathloul's iPhone was hacked. Technical information uncovered by Bill Marczak's team at the lab allowed Apple to warn thousands of its users, including U.S. State Department employees in Uganda. Researchers also discovered that spyware from QuaDream, another Israeli vendor, took advantage of the same vulnerability in iPhones."
    }
  },
  {
    "instruction": "Answer based on context:\n\nCyberwarfare\n\n==Introduction==\nCyberwarfare is the use of cyber attacks against an enemy state, causing comparable harm to actual warfare and/or disrupting vital computer systems. Some intended outcomes could be espionage, sabotage, propaganda, manipulation or economic warfare.\nThere is significant debate among experts regarding the definition of cyberwarfare, and even if such a thing exists. One view is that the term is a misnomer, since no cyber attacks to date could be described as war. An alternative view is that it is a suitable label for cyber attacks which cause physical damage to people and objects in the real world.Many countries including the United States, United Kingdom, Russia, China, Israel, Iran, and North Korea have active cyber capabilities for offensive and defensive operations. As states explore the use of cyber operations and combine capabilities, the likelihood of physical confrontation and violence playing out as a result of, or part of, a cyber operation is increased. However, meeting the scale and protracted nature of war is unlikely, thus ambiguity remains.The first instance of kinetic military action used in response to a cyber-attack resulting in the loss of human life was observed on 5 May 2019, when the Israel Defense Forces targeted and destroyed a building associated with an ongoing cyber-attack.\n\n\n\n== Definition ==\nThere is ongoing debate over how cyberwarfare should be defined and no absolute definition is widely agreed upon. While the majority of scholars, militaries and governments use definitions which refer to state and state-sponsored actors, other definitions may include non-state actors, such as terrorist groups, companies, political or ideological extremist groups, hacktivists, and transnational criminal organizations depending on the context of the work.Examples of definitions proposed by experts in the field are as follows.\n\n'Cyberwarfare' is used in a broad context to denote interstate use of technological force within computer networks in which information is stored, shared or communicated online.Parks and Duggan focused on analyzing cyberwarfare in terms of computer networks and pointed out that \"Cyberwarfare is a combination of computer network attack and defense and special technical operations.\" According to this perspective, the notion of cyberwarfare brings a new paradigm into the military doctrine. Paulo Shakarian and colleagues, put forward the following definition in 2013 drawing from various works including Clausewitz's definition of war: \"War is the continuation of politics by other means\":Cyberwarfare is an extension of policy by actions taken in cyberspace by state actors (or by non-state actors with significant state direction or support) that constitute a serious threat to another state's security, or an action of the same nature taken in response to a serious threat to a state's security (actual or perceived).\nTaddeo offered the following definition in 2012:\n\nThe warfare grounded on certain uses of ICTs within an offensive or defensive military strategy endorsed by a state and aiming at the immediate disruption or control of the enemy's resources, and which is waged within the informational environment, with agents and targets ranging both on the physical and non-physical domains and whose level of violence may vary upon circumstances.\nRobinson et al. proposed in 2015, that the intent of the attacker dictates whether an attack is warfare or not, defining cyber warfare as \"the use of cyber attacks with a warfare-like intent.\"In 2010, the former US National Coordinator for Security, Infrastructure Protection and Counter-terrorism, Richard A. Clarke, defined cyberwarfare as \"actions by a nation-state to penetrate another nation's computers or networks for the purposes of causing damage or disruption.\" Own cyber-physical infrastructure may be weaponized and used by the adversary in case of a cyber conflict, thus turning such infrastructure into tactical weapons.\n\n\n*** Controversy of term ***\nThere is debate on whether the term \"cyberwarfare\" is accurate. In 2012, Eugene Kaspersky, founder of Kaspersky Lab, concludes that \"cyberterrorism\" is a more accurate term than \"cyberwar.\" He states that \"with today's attacks, you are clueless about who did it or when they will strike again. It's not cyber-war, but cyberterrorism.\" Howard Schmidt, former Cyber Security Coordinator of the Obama Administration, said that \"there is no cyberwar... I think that is a terrible metaphor and I think that is a terrible concept. There are no winners in that environment.\"Some experts take issue with the possible consequences linked to the warfare analogy. In 2011, Ron Deibert, of Canada's Citizen Lab, has warned of a \"militarization of cyberspace\", as militaristic responses may not be appropriate. Although, to date, even serious cyber attacks which have disrupted large parts of a nations electrical grids (230,000 customers, Ukraine, 2015) or affected access to medical care, thus endangering life (NHS, WannaCry, 2017) have not led to military action.In 2017, Oxford academic Lucas Kello proposed a new term \u2013 \"Unpeace\" \u2013 to denote highly damaging cyber actions whose non-violent effects do not rise to the level of traditional war. Such actions are neither warlike nor peace-like. Although they are non-violent, and thus not acts of war, their damaging effects on the economy and society may be greater than even some armed attacks. This term is closely related to the concept of the \"grey zone\" which has come to prominence in 2017, describing actions which fall below the traditional threshold of war.\n\n\n*** Cyberwarfare vs. cyber war ***\nThe term \"cyberwarfare\" is distinct from the term \"cyber war.\" \"Cyberwarfare\" does not imply scale, protraction or violence which are typically associated with the term \"war\". Cyber warfare includes techniques, tactics and procedures which may be involved in a cyber war. The term war inherently refers to a large scale action, typically over a protracted period of time and may include objectives seeking to utilize violence or the aim to kill. A cyber war could accurately describe a protracted period of back-and-forth cyber attacks (including in combination with traditional military action) between warring states. To date, no such action is known to have occurred. Instead, tit-for-tat military-cyber actions are more commonplace. For example, in June 2019, the United States launched a cyber attack against Iranian weapons systems in retaliation to the shooting down of a US drone being in the Strait of Hormuz.\n\n\n*** Cyberwarfare and cyber sanctions ***\nThe use of digital attacks, as described by the concept of cyberwarfare, in this page can be a retaliatory response to the cyber attacks. In addition, countries can use cyber sanctions as a reaction to being the targets of the cyber attacks. Sometimes, it is not easy to detect the attacker; however, it might be the case that suspicions can focus on a certain country or group of countries. In these cases, unilateral and multilateral economic sanctions can be used instead of cyberwarfare. For example, economic sanctions related to cyber attacks have been frequently used by the United States government. There are two Executive Orders, EO 13694 in 2015 and EO 13757 in 2016, issued during the Obama administration specifically focused on the implementation of the cyber sanctions. Later on, these Executive Orders have been frequently used by the following US presidents. Furthermore, the Congress is an important actor when it comes to the cyber sanctions. For example, Iran Cyber Sanctions Act of 2016 is a bill that imposes sanctions on specific individuals responsible for the cyber attacks.\n\n== Types of threat ==\n\n== Types of warfare ==\nCyber warfare can present a multitude of threats towards a nation. At the most basic level, cyber attacks can be used to support traditional warfare. For example, tampering with the operation of air defenses via cyber means in order to facilitate an air attack. Aside from these \"hard\" threats, cyber warfare can also contribute towards \"soft\" threats such as espionage and propaganda.\nEugene Kaspersky, founder of Kaspersky Lab, equates large-scale cyber weapons, such as Flame and NetTraveler which his company discovered, to biological weapons, claiming that in an interconnected world, they have the potential to be equally destructive.\n\n\n*** Espionage ***\n\nTraditional espionage is not an act of war, nor is cyber-espionage, and both are generally assumed to be ongoing between major powers. Despite this assumption, some incidents can cause serious tensions between nations, and are often described as \"attacks\". For example:\nMassive spying by the US on many countries, revealed by Edward Snowden.\nAfter the NSA's spying on Germany's Chancellor Angela Merkel was revealed, the Chancellor compared the NSA with the Stasi.\nThe NSA recording nearly every cell phone conversation in the Bahamas, without the Bahamian government's permission, and similar programs in Kenya, the Philippines, Mexico and Afghanistan.\nThe \"Titan Rain\" probes of American defense contractors computer systems since 2003.\nThe Office of Personnel Management data breach, in the US, widely attributed to China.\nThe security firm Area 1 published details of a breach that compromised one of the European Union's diplomatic communication channels for three years.Out of all cyber attacks, 25% of them are espionage based.\n\n\n*** Sabotage ***\nComputers and satellites that coordinate other activities are vulnerable components of a system and could lead to the disruption of equipment. Compromise of military systems, such as C4ISTAR components that are responsible for orders and communications could lead to their interception or malicious replacement. Power, water, fuel, communications, and transportation infrastructure all may be vulnerable to disruption. According to Clarke, the civilian realm is also at risk, noting that the security breaches have already gone beyond stolen credit card numbers, and that potential targets can also include the electric power grid, trains, or the stock market.In mid-July 2010, security experts discovered a malicious software program called Stuxnet that had infiltrated factory computers and had spread to plants around the world. It is considered \"the first attack on critical industrial infrastructure that sits at the foundation of modern economies,\" notes The New York Times.Stuxnet, while extremely effective in delaying Iran's nuclear program for the development of nuclear weaponry, came at a high cost. For the first time, it became clear that not only could cyber weapons be defensive but they could be offensive. The large decentralization and scale of cyberspace makes it extremely difficult to direct from a policy perspective. Non-state actors can play as large a part in the cyberwar space as state actors, which leads to dangerous, sometimes disastrous, consequences. Small groups of highly skilled malware developers are able to as effectively impact global politics and cyber warfare as large governmental agencies. A major aspect of this ability lies in the willingness of these groups to share their exploits and developments on the web as a form of arms proliferation. This allows lesser hackers to become more proficient in creating the large scale attacks that once only a small handful were skillful enough to manage. In addition, thriving black markets for these kinds of cyber weapons are buying and selling these cyber capabilities to the highest bidder without regard for consequences.\n\n\n**** Denial-of-service attack ****\n\nIn computing, a denial-of-service attack (DoS attack) or distributed denial-of-service attack (DDoS attack) is an attempt to make a machine or network resource unavailable to its intended users. Perpetrators of DoS attacks typically target sites or services hosted on high-profile web servers such as banks, credit card payment gateways, and even root nameservers. DoS attacks often leverage internet-connected devices with vulnerable security measures to carry out these large-scale attacks. DoS attacks may not be limited to computer-based methods, as strategic physical attacks against infrastructure can be just as devastating. For example, cutting undersea communication cables may severely cripple some regions and countries with regards to their information warfare ability.\n\n\n**** Electrical power grid ****\nThe federal government of the United States admits that the electric power grid is susceptible to cyberwarfare. The United States Department of Homeland Security works with industries to identify vulnerabilities and to help industries enhance the security of control system networks. The federal government is also working to ensure that security is built in as the next generation of \"smart grid\" networks are developed. In April 2009, reports surfaced that China and Russia had infiltrated the U.S. electrical grid and left behind software programs that could be used to disrupt the system, according to current and former national security officials. The North American Electric Reliability Corporation (NERC) has issued a public notice that warns that the electrical grid is not adequately protected from cyber attack. China denies intruding into the U.S. electrical grid. One countermeasure would be to disconnect the power grid from the Internet and run the net with droop speed control only. Massive power outages caused by a cyber attack could disrupt the economy, distract from a simultaneous military attack, or create a national trauma.Iranian hackers, possibly Iranian Cyber Army pushed a massive power outage for 12 hours in 44 of 81 provinces of Turkey, impacting 40 million people. Istanbul and Ankara were among the places suffering blackout.Howard Schmidt, former Cyber-Security Coordinator of the US, commented on those possibilities:\nIt's possible that hackers have gotten into administrative computer systems of utility companies, but says those aren't linked to the equipment controlling the grid, at least not in developed countries. [Schmidt] has never heard that the grid itself has been hacked.\nIn June 2019, Russia said that its electrical grid has been under cyber-attack by the United States. The New York Times reported that American hackers from the United States Cyber Command planted malware potentially capable of disrupting the Russian electrical grid.\n\n\n*** Propaganda ***\nCyber propaganda is an effort to control information in whatever form it takes, and influence public opinion. It is a form of psychological warfare, except it uses social media, fake news websites and other digital means. In 2018, Sir Nicholas Carter, Chief of the General Staff of the British Army stated that this kind of attack from actors such as Russia \"is a form of system warfare that seeks to de-legitimize the political and social system on which our military strength is based\".Jowell and O'Donnell (2006) state that \"propaganda is the deliberate, systematic attempt to shape perceptions, manipulate cognitions, and direct behavior to achieve a response that furthers the desired intent of the propagandist\" (p. 7). The internet is the most important means of communication today. People can convey their messages quickly across to a huge audience, and this can open a window for evil. Terrorist organizations can exploit this and may use this medium to brainwash people. It has been suggested that restricted media coverage of terrorist attacks would in turn decrease the number of terrorist attacks that occur afterwards.\n\n\n*** Economic disruption ***\nIn 2017, the WannaCry and Petya (NotPetya) cyber attacks, masquerading as ransomware, caused large-scale disruptions in Ukraine as well as to the U.K.'s National Health Service, pharmaceutical giant Merck, Maersk shipping company and other organizations around the world. These attacks are also categorized as cybercrimes, specifically financial crime because they negatively affect a company or group.\n\n\n*** Surprise cyber attack ***\nThe idea of a \"cyber Pearl Harbor\" has been debated by scholars, drawing an analogy to the historical act of war. Others have used \"cyber 9/11\" to draw attention to the nontraditional, asymmetric, or irregular aspect of cyber action against a state.\n\n== Motivations ==\nThere are a number of reasons nations undertake offensive cyber operations. Sandro Gaycken, a cyber security expert and adviser to NATO, advocates that states take cyber warfare seriously as they are viewed as an attractive activity by many nations, in times of war and peace. Offensive cyber operations offer a large variety of cheap and risk-free options to weaken other countries and strengthen their own positions. Considered from a long-term, geostrategic perspective, cyber offensive operations can cripple whole economies, change political views, agitate conflicts within or among states, reduce their military efficiency and equalize the capacities of high-tech nations to that of low-tech nations, and use access to their critical infrastructures to blackmail them.\n\n\n*** Military ***\nWith the emergence of cyber as a substantial threat to national and global security, cyber war, warfare and/or attacks also became a domain of interest and purpose for the military.In the U.S., General Keith B. Alexander, first head of USCYBERCOM, told the Senate Armed Services Committee that computer network warfare is evolving so rapidly that there is a \"mismatch between our technical capabilities to conduct operations and the governing laws and policies. Cyber Command is the newest global combatant and its sole mission is cyberspace, outside the traditional battlefields of land, sea, air and space.\" It will attempt to find and, when necessary, neutralize cyberattacks and to defend military computer networks.Alexander sketched out the broad battlefield envisioned for the computer warfare command, listing the kind of targets that his new headquarters could be ordered to attack, including \"traditional battlefield prizes \u2013 command-and-control systems at military headquarters, air defense networks and weapons systems that require computers to operate.\"One cyber warfare scenario, Cyber-ShockWave, which was wargamed on the cabinet level by former administration officials, raised issues ranging from the National Guard to the power grid to the limits of statutory authority.The distributed nature of internet based attacks means that it is difficult to determine motivation and attacking party, meaning that it is unclear when a specific act should be considered an act of war.Examples of cyberwarfare driven by political motivations can be found worldwide. In 2008, Russia began a cyber attack on the Georgian government website, which was carried out along with Georgian military operations in South Ossetia. In 2008, Chinese \"nationalist hackers\" attacked CNN as it reported on Chinese repression on Tibet. Hackers from Armenia and Azerbaijan have actively participated in cyberwarfare as part of the Nagorno-Karabakh conflict, with Azerbaijani hackers targeting Armenian websites and posting Ilham Aliyev's statements.Jobs in cyberwarfare have become increasingly popular in the military. All four branches of the United States military actively recruit for cyber warfare positions.As the military have become more and more entangled into the national and global threat proposed by the utilization of the cyber domain, a new research field within the Military Science field have slowly emerged. In essence, its focus is centered towards describing, understanding and explaining what Military Cyber Operations is, can do and be tackled. In the Handbook of Military Sciences Aaron Brantly and Max Smeets define Military Cyber Operations to be \"those cyber operations which a military entity of a nation-state plans and conducts to achieve strategic, operational, or tactical gain.\" More so, they argue these types of military operations are commonly divided into three types of operations.\n\nDefensive Cyber Operations: Encompassing \"those actions taken through the use of computer networks to protect, monitor, analyze, detect, and respond to unauthorized activity within a governments information systems and computer networks\".\nCyber Espionage Operations: Encompassing \"those actions taken through the use of computer networks to gather data from target or adversary information systems or network\".\"\nOffensive Cyber Operations: Encompassing \"those actions taken through the use of computer networks to disrupt, deny, degrade, or destroy information resident in computers and computer networks, or the computers and networks themselves, or in basic, operations designed to achieve tangible effects\".\"\n\n\n*** Civil ***\nPotential targets in internet sabotage include all aspects of the Internet from the backbones of the web, to the internet service providers, to the varying types of data communication mediums and network equipment. This would include: web servers, enterprise information systems, client server systems, communication links, network equipment, and the desktops and laptops in businesses and homes. Electrical grids, financial networks, and telecommunication systems are also deemed vulnerable, especially due to current trends in computerization and automation.\n\n\n*** Hacktivism ***\nPolitically motivated hacktivism involves the subversive use of computers and computer networks to promote an agenda, and can potentially extend to attacks, theft and virtual sabotage that could be seen as cyberwarfare \u2013 or mistaken for it.\nHacktivists use their knowledge and software tools to gain unauthorized access to computer systems they seek to manipulate or damage not for material gain or to cause widespread destruction, but to draw attention to their cause through well-publicized disruptions of select targets. Anonymous and other hacktivist groups are often portrayed in the media as cyber-terrorists, wreaking havoc by hacking websites, posting sensitive information about their victims, and threatening further attacks if their demands are not met. However, hacktivism is more than that. Actors are politically motivated to change the world, through the use of fundamentalism. Groups like Anonymous, however, have divided opinion with their methods.\n\n\n*** Income generation ***\nCyber attacks, including ransomware, can be used to generate income. States can use these techniques to generate significant sources of income, which can evade sanctions and perhaps while simultaneously harming adversaries (depending on targets). This tactic was observed in August 2019 when it was revealed North Korea had generated $2 billion to fund its weapons program, avoiding the blanket of sanctions levied by the United States, United Nations and the European Union.\n\n\n*** Private sector ***\n\nComputer hacking represents a modern threat in ongoing global conflicts and industrial espionage and as such is presumed to widely occur. It is typical that this type of crime is underreported to the extent they are known. According to McAfee's George Kurtz, corporations around the world face millions of cyberattacks a day. \"Most of these attacks don't gain any media attention or lead to strong political statements by victims.\" This type of crime is usually financially motivated.\n\n\n*** Non-profit research ***\nBut not all those who engage in cyberwarfare do so for financial or ideological reasons. There are institutes and companies like the University of Cincinnati or the Kaspersky Security Lab which engage in cyberwarfare so as to better understand the field through actions like the researching and publishing of new security threats.\n\n== Preparedness ==\nA number of countries conduct exercise to increase preparedness and explore the strategy, tactics and operations involved in conducting and defending against cyber attacks against hostile states, this is typically done in the form of war games.The Cooperative Cyber Defence Centre of Excellence (CCDCE), part of the North Atlantic Treaty Organization (NATO), have conducted a yearly war game called Locked Shields since 2010 designed to test readiness and improve skills, strategy tactics and operational decision making of participating national organizations. Locked Shields 2019 saw 1200 participants from 30 countries compete in a red team vs. blue team exercise. The war game involved a fictional country, Berylia, which was \"experiencing a deteriorating security situation, where a number of hostile events coincide with coordinated cyber attacks against a major civilian internet service provider and maritime surveillance system. The attacks caused severe disruptions in the power generation and distribution, 4G communication systems, maritime surveillance, water purification plant and other critical infrastructure components\". CCDCE describe the aim of the exercise was to \"maintain the operation of various systems under intense pressure, the strategic part addresses the capability to understand the impact of decisions made at the strategic and policy level.\" Ultimately, France was the winner of Locked Shields 2019.The European Union conducts cyber war game scenarios with member states and foreign partner states to improve readiness, skills and observe how strategic and tactical decisions may affect the scenario.As well as war games which serve a broader purpose to explore options and improve skills, cyber war games are targeted at preparing for specific threats. In 2018 the Sunday Times reported the UK government was conducting cyber war games which could \"blackout Moscow\". These types of war games move beyond defensive preparedness, as previously described above and onto preparing offensive capabilities which can be used as deterrence, or for \"war\".\n\n== Cyber activities by nation ==\n\nApproximately 120 countries have been developing ways to use the Internet as a weapon and target financial markets, government computer systems and utilities.\n\n\n*** Asia ***\n\n\n**** China ****\n\nForeign Policy magazine puts the size of China's \"hacker army\" at anywhere from 50,000 to 100,000 individuals.Diplomatic cables highlight US concerns that China is using access to Microsoft source code and 'harvesting the talents of its private sector' to boost its offensive and defensive capabilities.The 2018 cyberattack on the Marriott hotel chain that collected personal details of roughly 500 million guests is now known to be a part of a Chinese intelligence-gathering effort that also hacked health insurers and the security clearance files of millions more Americans, The hackers, are suspected of working on behalf of the Ministry of State Security (MSS), the country's Communist-controlled civilian spy agency.  \"The information is exactly what the Chinese use to root out spies, recruit intelligence agents and build a rich repository of Americans' personal data for future targeting.\"\nA 2008 article in the Culture Mandala: The Bulletin of the Centre for East-West Cultural and Economic Studies by Jason Fritz alleges that the Chinese government from 1995 to 2008 was involved in a number of high-profile cases of espionage, primarily through the use of a \"decentralized network of students, business people, scientists, diplomats, and engineers from within the Chinese Diaspora\". A defector in Belgium, purportedly an agent, claimed that there were hundreds of spies in industries throughout Europe, and on his defection to Australia Chinese diplomat Chen Yonglin said there were over 1,000 such in that country.  In 2007, a Russian executive was sentenced to 11 years for passing information about the rocket and space technology organization to China. Targets in the United States have included \"aerospace engineering programs, space shuttle design, C4ISR data, high-performance computers, Nuclear weapon design, cruise missile data, semiconductors, integrated circuit design, and details of US arms sales to Taiwan\".While China continues to be held responsible for a string of cyber-attacks on a number of public and private institutions in the United States, India, Russia, Canada, and France, the Chinese government denies any involvement in cyber-spying campaigns. The administration maintains the position that China is not the threat but rather the victim of an increasing number of cyber-attacks. Most reports about China's cyber warfare capabilities have yet to be confirmed by the Chinese government.According to Fritz, China has expanded its cyber capabilities and military technology by acquiring foreign military technology. Fritz states that the Chinese government uses \"new space-based surveillance and intelligence gathering systems, Anti-satellite weapon, anti-radar, infrared decoys, and false target generators\" to assist in this quest, and that they support their \"Informatisation\" of their military through \"increased education of soldiers in cyber warfare; improving the information network for military training, and has built more virtual laboratories, digital libraries and digital campuses.\" Through this informatisation, they hope to prepare their forces to engage in a different kind of warfare, against technically capable adversaries. Many recent news reports link China's technological capabilities to the beginning of a new \"cyber cold war.\"Operation Shady RAT is an ongoing series of cyber attacks starting mid-2006, reported by Internet security company McAfee in August 2011. China is widely believed to be the state actor behind these attacks which hit at least 72 organizations including governments and defense contractors.On 14 September 2020, a database showing personal details of about 2.4 million people around the world was leaked and published.  A Chinese company, Zhenhua Data compiled the database. According to the information from \"National Enterprise Credit Information Publicity System\", which is run by State Administration for Market Regulation in China, the shareholders of Zhenhua Data Information Technology Co., Ltd. are two natural persons and one general partnership enterprise whose partners are natural persons. Wang Xuefeng, who is the chief executive and the shareholder of Zhenhua Data, has publicly boasted that he supports \"hybrid warfare\" through manipulation of public opinion and \"psychological warfare\".\n\n\n**** India ****\n\nThe Department of Information Technology created the Indian Computer Emergency Response Team (CERT-In) in 2004 to thwart cyber attacks in India. That year, there were 23 reported cyber security breaches. In 2011, there were 13,301. That year, the government created a new subdivision, the National Critical Information Infrastructure Protection Centre (NCIIPC) to thwart attacks against energy, transport, banking, telecom, defense, space and other sensitive areas.The executive director of the Nuclear Power Corporation of India (NPCIL) stated in February 2013 that his company alone was forced to block up to ten targeted attacks a day. CERT-In was left to protect less critical sectors.A high-profile cyber attack on 12 July 2012 breached the email accounts of about 12,000 people, including those of officials from the Ministry of External Affairs, Ministry of Home Affairs, Defense Research and Development Organizations (DRDO), and the Indo-Tibetan Border Police (ITBP). A government-private sector plan being overseen by National Security Advisor (NSA) Shivshankar Menon began in October 2012, and intends to boost up India's cyber security capabilities in the light of a group of experts findings that India faces a 470,000 shortfall of such experts despite the country's reputation of being an IT and software powerhouse.In February 2013, Information Technology Secretary J. Satyanarayana stated that the NCIIPC was finalizing policies related to national cyber security that would focus on domestic security solutions, reducing exposure through foreign technology. Other steps include the isolation of various security agencies to ensure that a synchronised attack could not succeed on all fronts and the planned appointment of a National Cyber Security Coordinator. As of that month, there had been no significant economic or physical damage to India related to cyber attacks.\nOn 26 November 2010, a group calling itself the Indian Cyber Army hacked the websites belonging to the Pakistan Army and the others belong to different ministries, including the Ministry of Foreign Affairs, Ministry of Education, Ministry of Finance, Pakistan Computer Bureau, Council of Islamic Ideology, etc. The attack was done as a revenge for the Mumbai terrorist attacks.On 4 December 2010, a group calling itself the Pakistan Cyber Army hacked the website of India's top investigating agency, the Central Bureau of Investigation (CBI). The National Informatics Center (NIC) has begun an inquiry.In July 2016, Cymmetria researchers discovered and revealed the cyber attack dubbed 'Patchwork', which compromised an estimated 2500 corporate and government agencies using code stolen from GitHub and the dark web. Examples of weapons used are an exploit for the Sandworm vulnerability (CVE-2014-4114), a compiled AutoIt script, and UAC bypass code dubbed UACME. Targets are believed to be mainly military and political assignments around Southeast Asia and the South China Sea and the attackers are believed to be of Indian origin and gathering intelligence from influential parties.The Defence Cyber Agency, which is the Indian Military agency responsible for Cyberwarfare, is expected to become operational by November 2019.\n\n\n**** Iran ****\nThe Iranian state sponsored group MuddyWater is active since at least 2017 and is responsible for many cyber attacks on various sectors.\n\n\n**** Philippines ****\nThe Chinese are being blamed after a cybersecurity company, F-Secure Labs, found a malware, NanHaiShu, which targeted the Philippines Department of Justice. It sent information in an infected machine to a server with a Chinese IP address. The malware which is considered particularly sophisticated in nature was introduced by phishing emails that were designed to look like they were coming from an authentic sources. The information sent is believed to be relating to the South China Sea legal case.\n\n\n**** South Korea ****\n\nIn July 2009, there were a series of coordinated denial of service attacks against major government, news media, and financial websites in South Korea and the United States. While many thought the attack was directed by North Korea, one researcher traced the attacks to the United Kingdom. Security researcher Chris Kubecka presented evidence multiple European Union and United Kingdom companies unwittingly helped attack South Korea due to a W32.Dozer infections, malware used in part of the attack. Some of the companies used in the attack were partially owned by several governments, further complicating attribution.\n\nIn July 2011, the South Korean company SK Communications was hacked, resulting in the theft of the personal details (including names, phone numbers, home and email addresses and resident registration numbers) of up to 35 million people. A trojaned software update was used to gain access to the SK Communications network. Links exist between this hack and other malicious activity and it is believed to be part of a broader, concerted hacking effort.With ongoing tensions on the Korean Peninsula, South Korea's defense ministry stated that South Korea was going to improve cyber-defense strategies in hopes of preparing itself from possible cyber attacks. In March 2013, South Korea's major banks \u2013 Shinhan Bank, Woori Bank and NongHyup Bank \u2013 as well as many broadcasting stations \u2013 KBS, YTN and MBC \u2013 were hacked and more than 30,000 computers were affected; it is one of the biggest attacks South Korea has faced in years. Although it remains uncertain as to who was involved in this incident, there has been immediate assertions that North Korea is connected, as it threatened to attack South Korea's government institutions, major national banks and traditional newspapers numerous times \u2013 in reaction to the sanctions it received from nuclear testing and to the continuation of Foal Eagle, South Korea's annual joint military exercise with the United States. North Korea's cyber warfare capabilities raise the alarm for South Korea, as North Korea is increasing its manpower through military academies specializing in hacking. Current figures state that South Korea only has 400 units of specialized personnel, while North Korea has more than 3,000 highly trained hackers; this portrays a huge gap in cyber warfare capabilities and sends a message to South Korea that it has to step up and strengthen its Cyber Warfare Command forces. Therefore, in order to be prepared from future attacks, South Korea and the United States will discuss further about deterrence plans at the Security Consultative Meeting (SCM). At SCM, they plan on developing strategies that focuses on accelerating the deployment of ballistic missiles as well as fostering its defense shield program, known as the Korean Air and Missile Defense.\n\n\n**** Sri Lanka ****\n\n\n**** North Korea ****\n\n\n*** Africa ***\n\n\n**** Egypt ****\nIn an extension of a bilateral dispute between Ethiopia and Egypt over the Grand Ethiopian Renaissance Dam, Ethiopian government websites have been hacked by the Egypt-based hackers in June 2020.\n\n\n*** Europe ***\n\n\n**** Cyprus ****\nThe New York Times published an expos\u00e9 revealing an extensive three-year phishing campaign aimed against diplomats based in Cyprus. After accessing the state system the hackers had access to the European Union's entire exchange database. By login into Coreu, hackers accessed communications linking all EU states, on both sensitive and not so sensitive matters. The event exposed poor protection of routine exchanges among European Union officials and a coordinated effort from a foreign entity to spy on another country. \"After over a decade of experience countering Chinese cyberoperations and extensive technical analysis, there is no doubt this campaign is connected to the Chinese government\", said Blake Darche, one of the Area 1 Security experts - the company revealing the stolen documents. The Chinese Embassy in the US did not return calls for comment. In 2019, another coordinated effort took place that allowed hackers to gain access to government (gov.cy) emails. Cisco's Talos Security Department revealed that \"Sea Turtle\" hackers carried out a broad piracy campaign in the DNS countries, hitting 40 different organizations, including Cyprus.\n\n\n**** Estonia ****\nIn April 2007, Estonia came under cyber attack in the wake of relocation of the Bronze Soldier of Tallinn. The largest part of the attacks were coming from Russia and from official servers of the authorities of Russia. In the attack, ministries, banks, and media were targeted. This attack on Estonia, a seemingly small Baltic state, was so effective because of how most of Estonian government services are run online. Estonia has implemented an e-government, where banking services, political elections, taxes, and other components of a modern society are now all done online.\n\n\n**** France ****\n\nIn 2013, the French Minister of Defense, Mr Jean-Yves Le Drian, ordered the creation of a cyber army, representing its fourth national army corps (along with ground, naval and air forces) under the French Ministry of Defense, to protect French and European interests on its soil and abroad. A contract was made with French firm EADS (Airbus) to identify and secure its main elements susceptible to cyber threats. In 2016 France had planned 2600 \"cyber-soldiers\" and a 440 million euros investment for cybersecurity products for this new army corps. An additional 4400 reservists constitute the heart of this army from 2019.\n\n\n**** Germany ****\nIn 2013, Germany revealed the existence of their 60-person Computer Network Operation unit. The German intelligence agency, BND, announced it was seeking to hire 130 \"hackers\" for a new \"cyber defence station\" unit.  In March 2013, BND president Gerhard Schindler announced that his agency had observed up to five attacks a day on government authorities, thought mainly to originate in China.  He confirmed the attackers had so far only accessed data and expressed concern that the stolen information could be used as the basis of future sabotage attacks against arms manufacturers, telecommunications companies and government and military agencies. Shortly after Edward Snowden leaked details of the U.S. National Security Agency's cyber surveillance system, German Interior Minister Hans-Peter Friedrich announced that the BND would be given an additional budget of 100 million Euros to increase their cyber surveillance capability from 5% of total internet traffic in Germany to 20% of total traffic, the maximum amount allowed by German law.\n\n\n**** Netherlands ****\n\nIn the Netherlands, Cyber Defense is nationally coordinated by the National Cyber Security Centrum (NCSC). The Dutch Ministry of Defense laid out a cyber strategy in 2011. The first focus is to improve the cyber defense handled by the Joint IT branch (JIVC). To improve intel operations, the intel community in the Netherlands (including the military intel organization, MIVD) has set up the Joint Sigint Cyber Unit (JSCU). The Ministry of Defense oversees an offensive cyber force, called Defensive Cyber Command (DCC).\n\n\n**** Norway ****\n\n\n**** Russia ****\n\nRussian, South Ossetian, Georgian and Azerbaijani sites were attacked by hackers during the 2008 South Ossetia War.American-led cyberattacks against Soviet Union and Russia\n\nWhen Russia was still a part of the Soviet Union in 1982, a portion of a Trans-Siberia pipeline within its territory exploded, allegedly due to a Trojan Horse computer malware implanted in the pirated Canadian software by the Central Intelligence Agency. The malware caused the SCADA system running the pipeline to malfunction. The \"Farewell Dossier\" provided information on this attack, and wrote that compromised computer chips would become a part of Soviet military equipment, flawed turbines would be placed in the gas pipeline, and defective plans would disrupt the output of chemical plants and a tractor factory. This caused the \"most monumental nonnuclear explosion and fire ever seen from space.\" However, the Soviet Union did not blame the United States for the attack.In June 2019, the New York Times reported that American hackers from the United States Cyber Command planted malware potentially capable of disrupting the Russian electrical grid.Russian-led cyberattacks\n\nIt has been claimed that Russian security services organized a number of denial of service attacks as a part of their cyber-warfare against other countries, most notably the 2007 cyberattacks on Estonia and the 2008 cyberattacks on Russia, South Ossetia, Georgia, and Azerbaijan. One identified young Russian hacker said that he was paid by Russian state security services to lead hacking attacks on NATO computers. He was studying computer sciences at the Department of the Defense of Information. His tuition was paid for by the FSB.\n\n\n**** Sweden ****\nIn January 2017, Sweden's armed forces were subjected to a cyber-attack that caused them to shutdown a so-called Caxcis IT system used in military exercises.\n\n\n**** Ukraine ****\nAccording to CrowdStrike from 2014 to 2016, the Russian APT Fancy Bear used Android malware to target the Ukrainian Army's Rocket Forces and Artillery. They distributed an infected version of an Android app whose original purpose was to control targeting data for the D-30 Howitzer artillery. The app, used by Ukrainian officers, was loaded with the X-Agent spyware and posted online on military forums. The attack was claimed by Crowd-Strike to be successful, with more than 80% of Ukrainian D-30 Howitzers destroyed, the highest percentage loss of any artillery pieces in the army (a percentage that had never been previously reported and would mean the loss of nearly the entire arsenal of the biggest artillery piece of the Ukrainian Armed Forces). According to the Ukrainian army this number is incorrect and that losses in artillery weapons \"were way below those reported\" and that these losses \"have nothing to do with the stated cause\".In 2014, the Russians were suspected to use a cyber weapon called \"Snake\", or \"Ouroboros,\" to conduct a cyber attack on Ukraine during a period of political turmoil. The Snake tool kit began spreading into Ukrainian computer systems in 2010. It performed Computer Network Exploitation (CNE), as well as highly sophisticated Computer Network Attacks (CNA).On 23 December 2015 the Black-Energy malware was used in a cyberattack on Ukraine's power-grid that left more than 200,000 people temporarily without power. A mining company and a large railway operator were also victims of the attack.Ukraine saw a massive surge in cyber attacks during the 2022 Russian invasion of Ukraine. Several websites belonging to Ukrainian banks and government departments became inaccessible.\n\n\n**** United Kingdom ****\nMI6 reportedly infiltrated an Al Qaeda website and replaced the instructions for making a pipe bomb with the recipe for making cupcakes.In October 2010, Iain Lobban, the director of the Government Communications Headquarters (GCHQ), said the UK faces a \"real and credible\" threat from cyber attacks by hostile states and criminals and government systems are targeted 1,000 times each month, such attacks threatened the UK's economic future, and some countries were already using cyber assaults to put pressure on other nations.On 12 November 2013, financial organizations in London conducted cyber war games dubbed \"Waking Shark 2\" to simulate massive internet-based attacks against bank and other financial organizations. The Waking Shark 2 cyber war games followed a similar exercise in Wall Street.\n\n\n*** Middle East ***\n\n\n**** Iran ****\n\nIran has been both victim and perpetrator of several cyberwarfare operations. Iran is considered an emerging military power in the field.\n\nIn September 2010, Iran was attacked by the Stuxnet worm, thought to specifically target its Natanz nuclear enrichment facility. It was a 500-kilobyte computer worm that infected at least 14 industrial sites in Iran, including the Natanz uranium-enrichment plant. Although the official authors of Stuxnet haven't been officially identified, Stuxnet is believed to be developed and deployed by the United States and Israel. The worm is said to be the most advanced piece of malware ever discovered and significantly increases the profile of cyberwarfare.Iranian Cyber Police department, FATA, was dismissed one year after its creation in 2011 because of the arrest and death of Sattar Behesti, a blogger, in the custody of FATA. Since then, the main responsible institution for the cyberwarfare in Iran is the \"Cyber Defense Command\" operating under the Joint Staff of Iranian Armed Forces.\n\n\n**** Israel ****\nIn the 2006 war against Hezbollah, Israel alleges that cyber-warfare was part of the conflict, where the Israel Defense Forces (IDF) intelligence estimates several countries in the Middle East used Russian hackers and scientists to operate on their behalf. As a result, Israel attached growing importance to cyber-tactics, and became, along with the U.S., France and a couple of other nations, involved in cyber-war planning. Many international high-tech companies are now locating research and development operations in Israel, where local hires are often veterans of the IDF's elite computer units. Richard A. Clarke adds that \"our Israeli friends have learned a thing or two from the programs we have been working on for more than two decades.\":\u200a8\u200aIn September 2007, Israel carried out an airstrike on a suspected nuclear reactor in Syria dubbed Operation Orchard. U.S. industry and military sources speculated that the Israelis may have used cyberwarfare to allow their planes to pass undetected by radar into Syria.Following US President Donald Trump's decision to pull out of the Iran nuclear deal in May 2018, cyber warfare units in the United States and Israel monitoring internet traffic out of Iran noted a surge in retaliatory cyber attacks from Iran. Security firms warned that Iranian hackers were sending emails containing malware to diplomats who work in the foreign affairs offices of US allies and employees at telecommunications companies, trying to infiltrate their computer systems.\n\n\n**** Saudi Arabia ****\nOn 15 August 2012 at 11:08 am local time, the Shamoon virus began destroying over 35,000 computer systems, rendering them inoperable. The virus used to target the Saudi government by causing destruction to the state owned national oil company Saudi Aramco. The attackers posted a pastie on PasteBin.com hours prior to the wiper logic bomb occurring, citing oppression and the Al-Saud regime as a reason behind the attack.  The attack was well staged according to Chris Kubecka, a former security advisor to Saudi Aramco after the attack and group leader of security for Aramco Overseas. It was an unnamed Saudi Aramco employee on the Information Technology team which opened a malicious phishing email, allowing initial entry into the computer network around mid-2012.\nKubecka also detailed in her Black Hat USA talk Saudi Aramco placed the majority of their security budget on the ICS control network, leaving the business network at risk for a major incident. \"When you realize most of your security budget was spent on ICS & IT gets Pwnd\". The virus has been noted to have behavior differing from other malware attacks, due to the destructive nature and the cost of the attack and recovery. US Defense Secretary Leon Panetta called the attack a \"Cyber Pearl Harbor\". Known years later as the \"Biggest hack in history\" and intended for cyber warfare. Shamoon can spread from an infected machine to other computers on the network. Once a system is infected, the virus continues to compile a list of files from specific locations on the system, upload them to the attacker, and erase them. Finally the virus overwrites the master boot record of the infected computer, making it unusable. The virus has been used for cyber warfare against the national oil companies Saudi Aramco and Qatar's RasGas.Saudi Aramco announced the attack on their Facebook page and went offline again until a company statement was issued on 25 August 2012. The statement falsely reported normal business was resumed on 25 August 2012. However a Middle Eastern journalist leaked photographs taken on 1 September 2012 showing kilometers of petrol trucks unable to be loaded due to backed business systems still inoperable. \n\nOn 29 August 2012 the same attackers behind Shamoon posted another pastie on PasteBin.com, taunting Saudi Aramco with proof they still retained access to the company network. The post contained the username and password on security and network equipment and the new password for the CEO Khalid Al- Falih The attackers also referenced a portion of the Shamoon malware as further proof in the pastie.According to Kubecka, in order to restore operations. Saudi Aramco used its large private fleet of aircraft and available funds to purchase much of the world's hard drives, driving the price up. New hard drives were required as quickly as possible so oil prices were not affected by speculation. By 1 September 2012 gasoline resources were dwindling for the public of Saudi Arabia 17 days after the 15 August attack. RasGas was also affected by a different variant, crippling them in a similar manner.\n\n\n**** Qatar ****\nIn March 2018 American Republican fundraiser Elliott Broidy filed a lawsuit against Qatar, alleging that Qatar's government stole and leaked his emails in order to discredit him because he was viewed \"as an impediment to their plan to improve the country's standing in Washington.\" In May 2018, the lawsuit named Mohammed bin Hamad bin Khalifa Al Thani, brother of the Emir of Qatar, and his associate Ahmed Al-Rumaihi, as allegedly orchestrating Qatar's cyber warfare campaign against Broidy. Further litigation revealed that the same cybercriminals who targeted Broidy had targeted as many as 1,200 other individuals, some of whom are also \"well-known enemies of Qatar\" such as senior officials of the U.A.E., Egypt, Saudi Arabia, and Bahrain. While these hackers almost always obscured their location, some of their activity was traced to a telecommunication network in Qatar.\n\n\n**** United Arab Emirates ****\nThe United Arab Emirates has launched several cyber-attacks in the past targeting dissidents. Ahmed Mansoor, an Emirati citizen, was jailed for sharing his thoughts on Facebook and Twitter. He was given the code name Egret under the state-led covert project called Raven, which spied on top political opponents, dissidents, and journalists. Project Raven deployed a secret hacking tool called Karma, to spy without requiring the target to engage with any web links.In September 2021, three of the former American intelligence officers, Marc Baier, Ryan Adams, and Daniel Gericke, admitted to assisting the UAE in hacking crimes by providing them with advanced technology and violating US laws. Under a three-year deferred prosecution agreement with the Justice Department, the three defendants also agreed to pay nearly $1.7 million in fines to evade prison sentences. The court documents revealed that the Emirates hacked into the computers and mobile phones of dissidents, activists, and journalists. They also attempted to break into the systems of the US and rest of the world.\n\n\n*** North America ***\n\n\n**** United States ****\n\nCyberwarfare in the United States is a part of the American military strategy of proactive cyber defence and the use of cyberwarfare as a platform for attack. The new United States military strategy makes explicit that a cyberattack is casus belli just as a traditional act of war.U.S. government security expert Richard A. Clarke, in his book Cyber War (May 2010), had defined \"cyberwarfare\" as \"actions by a nation-state to penetrate another nation's computers or networks for the purposes of causing damage or disruption.\":\u200a6\u200a The Economist describes cyberspace as \"the fifth domain of warfare,\" and William J. Lynn, U.S. Deputy Secretary of Defense, states that \"as a doctrinal matter, the Pentagon has formally recognized cyberspace as a new domain in warfare . . . [which] has become just as critical to military operations as land, sea, air, and space.\"In 2009, president Barack Obama declared America's digital infrastructure to be a \"strategic national asset,\" and in May 2010 the Pentagon set up its new U.S. Cyber Command (USCYBERCOM), headed by General Keith B. Alexander, director of the National Security Agency (NSA), to defend American military networks and attack other countries' systems. The EU has set up ENISA (European Union Agency for Network and Information Security) which is headed by Prof. Udo Helmbrecht and there are now further plans to significantly expand ENISA's capabilities. The United Kingdom has also set up a cyber-security and \"operations centre\" based in Government Communications Headquarters (GCHQ), the British equivalent of the NSA. In the U.S. however, Cyber Command is only set up to protect the military, whereas the government and corporate infrastructures are primarily the responsibility respectively of the Department of Homeland Security and private companies.In February 2010, top American lawmakers warned that the \"threat of a crippling attack on telecommunications and computer networks was sharply on the rise.\" According to The Lipman Report, numerous key sectors of the U.S. economy along with that of other nations, are currently at risk, including cyber threats to public and private facilities, banking and finance, transportation, manufacturing, medical, education and government, all of which are now dependent on computers for daily operations. In 2009, president Obama stated that \"cyber intruders have probed our electrical grids.\"On 19 June 2010, United States Senator Joe Lieberman (I-CT) introduced a bill called \"Protecting Cyberspace as a National Asset Act of 2010\", which he co-wrote with Senator Susan Collins (R-ME) and Senator Thomas Carper (D-DE). If signed into law, this controversial bill, which the American media dubbed the \"Kill switch bill\", would grant the president emergency powers over parts of the Internet. However, all three co-authors of the bill issued a statement that instead, the bill \"[narrowed] existing broad presidential authority to take over telecommunications networks\".\nIn June 2012 the New York Times reported that president Obama had ordered the cyber attack on Iranian nuclear enrichment facilities.In July 2010, The Economist wrote that China had plans of \"winning informationised wars by the mid-21st century\",  that other countries were likewise organizing for cyberwar, among them Russia, Israel and North Korea, and that Iran boasted of having the world's second-largest cyber-army. James Gosler, a government cybersecurity specialist, worried that the U.S. has a severe shortage of computer security specialists, estimating that there are only about 1,000 qualified people in the country today, but needs a force of 20,000 to 30,000 skilled experts. At the July 2010 Black Hat computer security conference, Michael Hayden, former deputy director of national intelligence, challenged thousands of attendees to help devise ways to \"reshape the Internet's security architecture\", explaining, \"You guys made the cyberworld look like the north German plain.\"In August 2010, the U.S. for the first time warned publicly about the Chinese military's use of civilian computer experts in clandestine cyber attacks aimed at American companies and government agencies. The Pentagon also pointed to an alleged China-based computer spying network dubbed GhostNet which was revealed in a 2009 research report. The Pentagon stated:\n\nThe People's Liberation Army is using \"information warfare units\" to develop viruses to attack enemy computer systems and networks, and those units include civilian computer professionals. Commander Bob Mehal, will monitor the PLA's buildup of its cyberwarfare capabilities and will continue to develop capabilities to counter any potential threat.\n\nThe United States Department of Defense sees the use of computers and the Internet to conduct warfare in cyberspace as a threat to national security. The United States Joint Forces Command describes some of its attributes:\n\nCyberspace technology is emerging as an \"instrument of power\" in societies, and is becoming more available to a country's opponents, who may use it to attack, degrade, and disrupt communications and the flow of information. With low barriers to entry, coupled with the anonymous nature of activities in cyberspace, the list of potential adversaries is broad.  Furthermore, the globe-spanning range of cyberspace and its disregard for national borders will challenge legal systems and complicate a nation's ability to deter threats and respond to contingencies.\n\nIn February 2010, the United States Joint Forces Command released a study which included a summary of the threats posed by the internet:\nWith very little investment, and cloaked in a veil of anonymity, our adversaries will inevitably attempt to harm our national interests. Cyberspace will become a main front in both irregular and traditional conflicts. Enemies in cyberspace will include both states and non-states and will range from the unsophisticated amateur to highly trained professional hackers. Through cyberspace, enemies will target industry, academia, government, as well as the military in the air, land, maritime, and space domains. In much the same way that airpower transformed the battlefield of World War II, cyberspace has fractured the physical barriers that shield a nation from attacks on its commerce and communication. Indeed, adversaries have already taken advantage of computer networks and the power of information technology not only to plan and execute savage acts of terrorism, but also to influence directly the perceptions and will of the U.S. Government and the American population.\nOn 6 October 2011, it was announced that Creech AFB's drone and Predator fleet's command and control data stream had been keylogged, resisting all attempts to reverse the exploit, for the past two weeks. The Air Force issued a statement that the virus had \"posed no threat to our operational mission\".On 21 November 2011, it was widely reported in the U.S. media that a hacker had destroyed a water pump at the Curran-Gardner Township Public Water District in Illinois. However, it later turned out that this information was not only false, but had been inappropriately leaked from the Illinois Statewide Terrorism and Intelligence Center.In 2012, the US used cyberattacks for tactical advantage in Afghanistan.According to a 2013 Foreign Policy magazine article, NSA's Tailored Access Operations (TAO) unit \"has successfully penetrated Chinese computer and telecommunications systems for almost 15 years, generating some of the best and most reliable intelligence information about what is going on inside the People's Republic of China.\"In 2013 cyberwarfare was, for the first time, considered a larger threat than Al Qaeda or terrorism, by many U.S. intelligence officials. In 2017, Representative Mike Rogers, chairman of the U.S. House Permanent Select Committee on Intelligence, for instance, said that \n\"We are in a cyber war in this country, and most Americans don't know it. And we are not necessarily winning. We have got huge challenges when it comes to cybersecurity.\"In 2014, Barack Obama ordered an intensification of cyberwarfare against North Korea's missile program for sabotaging test launches in their opening seconds. \nOn 24 November 2014, Sony Pictures Entertainment hack was a release of confidential data belonging to Sony Pictures Entertainment (SPE).\nIn June 2015, the United States Office of Personnel Management (OPM) announced that it had been the target of a data breach targeting the records of as many as four million people. Later, FBI Director James Comey put the number at 18 million. The Washington Post has reported that the attack originated in China, citing unnamed government officials.In October 2016, Jeh Johnson the United States Secretary of Homeland Security and James Clapper the U.S. Director of National Intelligence issued a joint statement accusing Russia of interfering with the 2016 United States presidential election. The New York Times reported the Obama administration formally accused Russia of stealing and disclosing Democratic National Committee emails. Under U.S. law (50 U.S.C.Title 50 \u2013 War and National Defense, Chapter 15 \u2013 National Security, Subchapter III Accountability for Intelligence Activities) there must be a formal Presidential finding prior to authorizing a covert attack. Then U.S. vice president Joe Biden said on the American news interview program Meet The Press that the United States will respond. The New York Times noted that Biden's comment \"seems to suggest that Mr. Obama is prepared to order \u2013 or has already ordered \u2013 some kind of covert action\". \nIn 2016 President Barack Obama authorized the planting of cyber weapons in Russian infrastructure in the final weeks of his presidency in response to Moscow's interference in the 2016 presidential election. On 29 December 2016 United States imposed the most extensive sanctions against Russia since the Cold War, expelling 35 Russian diplomats from the United States.Economic sanctions are the most frequently used the foreign policy instruments by the United States today Thus, it is not surprising to see that economic sanctions are also used as counter policies against cyberattacks. According to Onder (2021), economic sanctions are also information gathering mechanisms for the sanctioning states about the capabilities of the sanctioned states.In March 2017, WikiLeaks published more than 8,000 documents on the CIA. The confidential documents, codenamed Vault 7 and dated from 2013 to 2016, include details on CIA's software capabilities, such as the ability to compromise cars, smart TVs, web browsers (including Google Chrome, Microsoft Edge, Mozilla Firefox, and Opera Software ASA), and the operating systems of most smartphones (including Apple's iOS and Google's Android), as well as other operating systems such as Microsoft Windows, macOS, and Linux.For a global perspective of countries and other actors engaged in cyber warfare, see the George Washington University-based National Security Archive's CyberWar map.\n\n== Cyberpeace ==\n\nThe rise of cyber as a warfighting domain has led to efforts to determine how cyberspace can be used to foster peace.  For example, the German civil rights panel FIfF runs a campaign for cyberpeace \u2212 for the control of cyberweapons and surveillance technology and against the militarization of cyberspace and the development and stockpiling of offensive exploits and malware. Measures for cyberpeace include policymakers developing new rules and norms for warfare, individuals and organizations building new tools and secure infrastructures, promoting open source, the establishment of cyber security centers, auditing of critical infrastructure cybersecurity, obligations to disclose vulnerabilities, disarmament, defensive security strategies, decentralization, education and widely applying relevant tools and infrastructures, encryption and other cyberdefenses.The topics of cyber peacekeeping and cyber peacemaking have also been studied by researchers, as a way to restore and strengthen peace in the aftermath of both cyber and traditional warfare.\n\n== Cyber counterintelligence ==\nCyber counter-intelligence are measures to identify, penetrate, or neutralize foreign operations that use cyber means as the primary tradecraft methodology, as well as foreign intelligence service collection efforts that use traditional methods to gauge cyber capabilities and intentions.\nOn 7 April 2009, The Pentagon announced they spent more than $100 million in the last six months responding to and repairing damage from cyber attacks and other computer network problems.\nOn 1 April 2009, U.S. lawmakers pushed for the appointment of a White House cyber security \"czar\" to dramatically escalate U.S. defenses against cyber attacks, crafting proposals that would empower the government to set and enforce security standards for private industry for the first time.\nOn 9 February 2009, the White House announced that it will conduct a review of the country's cyber security to ensure that the Federal government of the United States cyber security initiatives are appropriately integrated, resourced and coordinated with the United States Congress and the private sector.\nIn the wake of the 2007 cyberwar waged against Estonia, NATO established the Cooperative Cyber Defence Centre of Excellence (CCD CoE) in Tallinn, Estonia, in order to enhance the organization's cyber defence capability. The center was formally established on 14 May 2008, and it received full accreditation by NATO and attained the status of International Military Organization on 28 October 2008. Since Estonia has led international efforts to fight cybercrime, the United States Federal Bureau of Investigation says it will permanently base a computer crime expert in Estonia in 2009 to help fight international threats against computer systems.\nIn 2015, the Department of Defense released an updated cyber strategy memorandum detailing the present and future tactics deployed in the service of defense against cyberwarfare.  In this memorandum, three cybermissions are laid out.  The first cybermission seeks to arm and maintain existing capabilities in the area of cyberspace, the second cybermission focuses on prevention of cyberwarfare, and the third cybermission includes strategies for retaliation and preemption (as distinguished from prevention).One of the hardest issues in cyber counterintelligence is the problem of attribution. Unlike conventional warfare, figuring out who is behind an attack can be very difficult. However Defense Secretary Leon Panetta has claimed that the United States has the capability to trace attacks back to their sources and hold the attackers \"accountable\".\n\n== Doubts about existence ==\nIn October 2011 the Journal of Strategic Studies, a leading journal in that field, published an article by Thomas Rid, \"Cyber War Will Not Take Place\" which argued that all politically motivated cyber attacks are merely sophisticated versions of sabotage, espionage, or subversion \u2013 and that it is unlikely that cyber war will occur in the future.\n\n== Legal perspective ==\nNIST, a cyberwarfare framework, was published in 2014 in the US.S.The Tallinn Manual, published in 2013, is an academic, non-binding study on how international law, in particular the jus ad bellum and international humanitarian law, apply to cyber conflicts and cyber warfare. It was written at the invitation of the Tallinn-based NATO Cooperative Cyber Defence Centre of Excellence by an international group of approximately twenty experts between 2009 and 2012.The Shanghai Cooperation Organisation (members of which include China and Russia) defines cyberwar to include dissemination of information \"harmful to the spiritual, moral and cultural spheres of other states\". In September 2011, these countries proposed to the UN Secretary General a document called \"International code of conduct for information security\".In contrast, the United approach focuses on physical and economic damage and injury, putting political concerns under freedom of speech. This difference of opinion has led to reluctance in the West to pursue global cyber arms control agreements. However, American General Keith B. Alexander did endorse talks with Russia over a proposal to limit military attacks in cyberspace. In June 2013, Barack Obama and Vladimir Putin agreed to install a secure Cyberwar-Hotline providing \"a direct secure voice communications line between the US cybersecurity coordinator and the Russian deputy secretary of the security council, should there be a need to directly manage a crisis situation arising from an ICT security incident\" (White House quote).A Ukrainian international law scholar, Alexander Merezhko, has developed a project called the International Convention on Prohibition of Cyberwar in Internet. According to this project, cyberwar is defined as the use of Internet and related technological means by one state against the political, economic, technological and information sovereignty and independence of another state. Professor Merezhko's project suggests that the Internet ought to remain free from warfare tactics and be treated as an international landmark. He states that the Internet (cyberspace) is a \"common heritage of mankind\".On the February 2017 RSA Conference Microsoft president Brad Smith suggested global rules \u2013 a \"Digital Geneva Convention\" \u2013 for cyber attacks that \"ban the nation-state hacking of all the civilian aspects of our economic and political infrastructures\". He also stated that an independent organization could investigate and publicly disclose evidence that attributes nation-state attacks to specific countries. Furthermore, he said that the technology sector should collectively and neutrally work together to protect Internet users and pledge to remain neutral in conflict and not aid governments in offensive activity and to adopt a coordinated disclosure process for software and hardware vulnerabilities. A fact-binding body has also been proposed to regulate cyber operations.\n\n== In popular culture ==\n\n\n*** In films ***\n\nIndependence Day (1996)\nTerminator 3: Rise of the Machines (2003)\nLive Free or Die Hard (2007)\nTerminator Genisys (2015)\nSnowden (2016)\nTerminator: Dark Fate (2019)Documentaries\nHacking the Infrastructure: Cyber Warfare (2016) by Viceland\nCyber War Threat (2015)\nDarknet, Hacker, Cyberwar (2017)\nZero Days (2016)\nThe Perfect Weapon (2020)\n\n\n*** In television ***\n\"Cancelled\", an episode of the animated sitcom South Park\nSeries 2 of COBRA, a British thriller series, revolves around a sustained campaign of cyberwar against the United Kingdom and the British government's response to it.\n\nWhat is the goal of the German Ministry of Defense's Computer Network Operation unit?",
    "context": "",
    "output": "The German Ministry of Defense's Computer Network Operation unit is responsible for protecting German and European interests on its soil and abroad, and for increasing cyber surveillance capabilities.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the goal of the German Ministry of Defense's Computer Network Operation unit?",
      "answer": "The German Ministry of Defense's Computer Network Operation unit is responsible for protecting German and European interests on its soil and abroad, and for increasing cyber surveillance capabilities.",
      "context": "Cyberwarfare\n\n==Introduction==\nCyberwarfare is the use of cyber attacks against an enemy state, causing comparable harm to actual warfare and/or disrupting vital computer systems. Some intended outcomes could be espionage, sabotage, propaganda, manipulation or economic warfare.\nThere is significant debate among experts regarding the definition of cyberwarfare, and even if such a thing exists. One view is that the term is a misnomer, since no cyber attacks to date could be described as war. An alternative view is that it is a suitable label for cyber attacks which cause physical damage to people and objects in the real world.Many countries including the United States, United Kingdom, Russia, China, Israel, Iran, and North Korea have active cyber capabilities for offensive and defensive operations. As states explore the use of cyber operations and combine capabilities, the likelihood of physical confrontation and violence playing out as a result of, or part of, a cyber operation is increased. However, meeting the scale and protracted nature of war is unlikely, thus ambiguity remains.The first instance of kinetic military action used in response to a cyber-attack resulting in the loss of human life was observed on 5 May 2019, when the Israel Defense Forces targeted and destroyed a building associated with an ongoing cyber-attack.\n\n\n\n== Definition ==\nThere is ongoing debate over how cyberwarfare should be defined and no absolute definition is widely agreed upon. While the majority of scholars, militaries and governments use definitions which refer to state and state-sponsored actors, other definitions may include non-state actors, such as terrorist groups, companies, political or ideological extremist groups, hacktivists, and transnational criminal organizations depending on the context of the work.Examples of definitions proposed by experts in the field are as follows.\n\n'Cyberwarfare' is used in a broad context to denote interstate use of technological force within computer networks in which information is stored, shared or communicated online.Parks and Duggan focused on analyzing cyberwarfare in terms of computer networks and pointed out that \"Cyberwarfare is a combination of computer network attack and defense and special technical operations.\" According to this perspective, the notion of cyberwarfare brings a new paradigm into the military doctrine. Paulo Shakarian and colleagues, put forward the following definition in 2013 drawing from various works including Clausewitz's definition of war: \"War is the continuation of politics by other means\":Cyberwarfare is an extension of policy by actions taken in cyberspace by state actors (or by non-state actors with significant state direction or support) that constitute a serious threat to another state's security, or an action of the same nature taken in response to a serious threat to a state's security (actual or perceived).\nTaddeo offered the following definition in 2012:\n\nThe warfare grounded on certain uses of ICTs within an offensive or defensive military strategy endorsed by a state and aiming at the immediate disruption or control of the enemy's resources, and which is waged within the informational environment, with agents and targets ranging both on the physical and non-physical domains and whose level of violence may vary upon circumstances.\nRobinson et al. proposed in 2015, that the intent of the attacker dictates whether an attack is warfare or not, defining cyber warfare as \"the use of cyber attacks with a warfare-like intent.\"In 2010, the former US National Coordinator for Security, Infrastructure Protection and Counter-terrorism, Richard A. Clarke, defined cyberwarfare as \"actions by a nation-state to penetrate another nation's computers or networks for the purposes of causing damage or disruption.\" Own cyber-physical infrastructure may be weaponized and used by the adversary in case of a cyber conflict, thus turning such infrastructure into tactical weapons.\n\n\n*** Controversy of term ***\nThere is debate on whether the term \"cyberwarfare\" is accurate. In 2012, Eugene Kaspersky, founder of Kaspersky Lab, concludes that \"cyberterrorism\" is a more accurate term than \"cyberwar.\" He states that \"with today's attacks, you are clueless about who did it or when they will strike again. It's not cyber-war, but cyberterrorism.\" Howard Schmidt, former Cyber Security Coordinator of the Obama Administration, said that \"there is no cyberwar... I think that is a terrible metaphor and I think that is a terrible concept. There are no winners in that environment.\"Some experts take issue with the possible consequences linked to the warfare analogy. In 2011, Ron Deibert, of Canada's Citizen Lab, has warned of a \"militarization of cyberspace\", as militaristic responses may not be appropriate. Although, to date, even serious cyber attacks which have disrupted large parts of a nations electrical grids (230,000 customers, Ukraine, 2015) or affected access to medical care, thus endangering life (NHS, WannaCry, 2017) have not led to military action.In 2017, Oxford academic Lucas Kello proposed a new term \u2013 \"Unpeace\" \u2013 to denote highly damaging cyber actions whose non-violent effects do not rise to the level of traditional war. Such actions are neither warlike nor peace-like. Although they are non-violent, and thus not acts of war, their damaging effects on the economy and society may be greater than even some armed attacks. This term is closely related to the concept of the \"grey zone\" which has come to prominence in 2017, describing actions which fall below the traditional threshold of war.\n\n\n*** Cyberwarfare vs. cyber war ***\nThe term \"cyberwarfare\" is distinct from the term \"cyber war.\" \"Cyberwarfare\" does not imply scale, protraction or violence which are typically associated with the term \"war\". Cyber warfare includes techniques, tactics and procedures which may be involved in a cyber war. The term war inherently refers to a large scale action, typically over a protracted period of time and may include objectives seeking to utilize violence or the aim to kill. A cyber war could accurately describe a protracted period of back-and-forth cyber attacks (including in combination with traditional military action) between warring states. To date, no such action is known to have occurred. Instead, tit-for-tat military-cyber actions are more commonplace. For example, in June 2019, the United States launched a cyber attack against Iranian weapons systems in retaliation to the shooting down of a US drone being in the Strait of Hormuz.\n\n\n*** Cyberwarfare and cyber sanctions ***\nThe use of digital attacks, as described by the concept of cyberwarfare, in this page can be a retaliatory response to the cyber attacks. In addition, countries can use cyber sanctions as a reaction to being the targets of the cyber attacks. Sometimes, it is not easy to detect the attacker; however, it might be the case that suspicions can focus on a certain country or group of countries. In these cases, unilateral and multilateral economic sanctions can be used instead of cyberwarfare. For example, economic sanctions related to cyber attacks have been frequently used by the United States government. There are two Executive Orders, EO 13694 in 2015 and EO 13757 in 2016, issued during the Obama administration specifically focused on the implementation of the cyber sanctions. Later on, these Executive Orders have been frequently used by the following US presidents. Furthermore, the Congress is an important actor when it comes to the cyber sanctions. For example, Iran Cyber Sanctions Act of 2016 is a bill that imposes sanctions on specific individuals responsible for the cyber attacks.\n\n== Types of threat ==\n\n== Types of warfare ==\nCyber warfare can present a multitude of threats towards a nation. At the most basic level, cyber attacks can be used to support traditional warfare. For example, tampering with the operation of air defenses via cyber means in order to facilitate an air attack. Aside from these \"hard\" threats, cyber warfare can also contribute towards \"soft\" threats such as espionage and propaganda.\nEugene Kaspersky, founder of Kaspersky Lab, equates large-scale cyber weapons, such as Flame and NetTraveler which his company discovered, to biological weapons, claiming that in an interconnected world, they have the potential to be equally destructive.\n\n\n*** Espionage ***\n\nTraditional espionage is not an act of war, nor is cyber-espionage, and both are generally assumed to be ongoing between major powers. Despite this assumption, some incidents can cause serious tensions between nations, and are often described as \"attacks\". For example:\nMassive spying by the US on many countries, revealed by Edward Snowden.\nAfter the NSA's spying on Germany's Chancellor Angela Merkel was revealed, the Chancellor compared the NSA with the Stasi.\nThe NSA recording nearly every cell phone conversation in the Bahamas, without the Bahamian government's permission, and similar programs in Kenya, the Philippines, Mexico and Afghanistan.\nThe \"Titan Rain\" probes of American defense contractors computer systems since 2003.\nThe Office of Personnel Management data breach, in the US, widely attributed to China.\nThe security firm Area 1 published details of a breach that compromised one of the European Union's diplomatic communication channels for three years.Out of all cyber attacks, 25% of them are espionage based.\n\n\n*** Sabotage ***\nComputers and satellites that coordinate other activities are vulnerable components of a system and could lead to the disruption of equipment. Compromise of military systems, such as C4ISTAR components that are responsible for orders and communications could lead to their interception or malicious replacement. Power, water, fuel, communications, and transportation infrastructure all may be vulnerable to disruption. According to Clarke, the civilian realm is also at risk, noting that the security breaches have already gone beyond stolen credit card numbers, and that potential targets can also include the electric power grid, trains, or the stock market.In mid-July 2010, security experts discovered a malicious software program called Stuxnet that had infiltrated factory computers and had spread to plants around the world. It is considered \"the first attack on critical industrial infrastructure that sits at the foundation of modern economies,\" notes The New York Times.Stuxnet, while extremely effective in delaying Iran's nuclear program for the development of nuclear weaponry, came at a high cost. For the first time, it became clear that not only could cyber weapons be defensive but they could be offensive. The large decentralization and scale of cyberspace makes it extremely difficult to direct from a policy perspective. Non-state actors can play as large a part in the cyberwar space as state actors, which leads to dangerous, sometimes disastrous, consequences. Small groups of highly skilled malware developers are able to as effectively impact global politics and cyber warfare as large governmental agencies. A major aspect of this ability lies in the willingness of these groups to share their exploits and developments on the web as a form of arms proliferation. This allows lesser hackers to become more proficient in creating the large scale attacks that once only a small handful were skillful enough to manage. In addition, thriving black markets for these kinds of cyber weapons are buying and selling these cyber capabilities to the highest bidder without regard for consequences.\n\n\n**** Denial-of-service attack ****\n\nIn computing, a denial-of-service attack (DoS attack) or distributed denial-of-service attack (DDoS attack) is an attempt to make a machine or network resource unavailable to its intended users. Perpetrators of DoS attacks typically target sites or services hosted on high-profile web servers such as banks, credit card payment gateways, and even root nameservers. DoS attacks often leverage internet-connected devices with vulnerable security measures to carry out these large-scale attacks. DoS attacks may not be limited to computer-based methods, as strategic physical attacks against infrastructure can be just as devastating. For example, cutting undersea communication cables may severely cripple some regions and countries with regards to their information warfare ability.\n\n\n**** Electrical power grid ****\nThe federal government of the United States admits that the electric power grid is susceptible to cyberwarfare. The United States Department of Homeland Security works with industries to identify vulnerabilities and to help industries enhance the security of control system networks. The federal government is also working to ensure that security is built in as the next generation of \"smart grid\" networks are developed. In April 2009, reports surfaced that China and Russia had infiltrated the U.S. electrical grid and left behind software programs that could be used to disrupt the system, according to current and former national security officials. The North American Electric Reliability Corporation (NERC) has issued a public notice that warns that the electrical grid is not adequately protected from cyber attack. China denies intruding into the U.S. electrical grid. One countermeasure would be to disconnect the power grid from the Internet and run the net with droop speed control only. Massive power outages caused by a cyber attack could disrupt the economy, distract from a simultaneous military attack, or create a national trauma.Iranian hackers, possibly Iranian Cyber Army pushed a massive power outage for 12 hours in 44 of 81 provinces of Turkey, impacting 40 million people. Istanbul and Ankara were among the places suffering blackout.Howard Schmidt, former Cyber-Security Coordinator of the US, commented on those possibilities:\nIt's possible that hackers have gotten into administrative computer systems of utility companies, but says those aren't linked to the equipment controlling the grid, at least not in developed countries. [Schmidt] has never heard that the grid itself has been hacked.\nIn June 2019, Russia said that its electrical grid has been under cyber-attack by the United States. The New York Times reported that American hackers from the United States Cyber Command planted malware potentially capable of disrupting the Russian electrical grid.\n\n\n*** Propaganda ***\nCyber propaganda is an effort to control information in whatever form it takes, and influence public opinion. It is a form of psychological warfare, except it uses social media, fake news websites and other digital means. In 2018, Sir Nicholas Carter, Chief of the General Staff of the British Army stated that this kind of attack from actors such as Russia \"is a form of system warfare that seeks to de-legitimize the political and social system on which our military strength is based\".Jowell and O'Donnell (2006) state that \"propaganda is the deliberate, systematic attempt to shape perceptions, manipulate cognitions, and direct behavior to achieve a response that furthers the desired intent of the propagandist\" (p. 7). The internet is the most important means of communication today. People can convey their messages quickly across to a huge audience, and this can open a window for evil. Terrorist organizations can exploit this and may use this medium to brainwash people. It has been suggested that restricted media coverage of terrorist attacks would in turn decrease the number of terrorist attacks that occur afterwards.\n\n\n*** Economic disruption ***\nIn 2017, the WannaCry and Petya (NotPetya) cyber attacks, masquerading as ransomware, caused large-scale disruptions in Ukraine as well as to the U.K.'s National Health Service, pharmaceutical giant Merck, Maersk shipping company and other organizations around the world. These attacks are also categorized as cybercrimes, specifically financial crime because they negatively affect a company or group.\n\n\n*** Surprise cyber attack ***\nThe idea of a \"cyber Pearl Harbor\" has been debated by scholars, drawing an analogy to the historical act of war. Others have used \"cyber 9/11\" to draw attention to the nontraditional, asymmetric, or irregular aspect of cyber action against a state.\n\n== Motivations ==\nThere are a number of reasons nations undertake offensive cyber operations. Sandro Gaycken, a cyber security expert and adviser to NATO, advocates that states take cyber warfare seriously as they are viewed as an attractive activity by many nations, in times of war and peace. Offensive cyber operations offer a large variety of cheap and risk-free options to weaken other countries and strengthen their own positions. Considered from a long-term, geostrategic perspective, cyber offensive operations can cripple whole economies, change political views, agitate conflicts within or among states, reduce their military efficiency and equalize the capacities of high-tech nations to that of low-tech nations, and use access to their critical infrastructures to blackmail them.\n\n\n*** Military ***\nWith the emergence of cyber as a substantial threat to national and global security, cyber war, warfare and/or attacks also became a domain of interest and purpose for the military.In the U.S., General Keith B. Alexander, first head of USCYBERCOM, told the Senate Armed Services Committee that computer network warfare is evolving so rapidly that there is a \"mismatch between our technical capabilities to conduct operations and the governing laws and policies. Cyber Command is the newest global combatant and its sole mission is cyberspace, outside the traditional battlefields of land, sea, air and space.\" It will attempt to find and, when necessary, neutralize cyberattacks and to defend military computer networks.Alexander sketched out the broad battlefield envisioned for the computer warfare command, listing the kind of targets that his new headquarters could be ordered to attack, including \"traditional battlefield prizes \u2013 command-and-control systems at military headquarters, air defense networks and weapons systems that require computers to operate.\"One cyber warfare scenario, Cyber-ShockWave, which was wargamed on the cabinet level by former administration officials, raised issues ranging from the National Guard to the power grid to the limits of statutory authority.The distributed nature of internet based attacks means that it is difficult to determine motivation and attacking party, meaning that it is unclear when a specific act should be considered an act of war.Examples of cyberwarfare driven by political motivations can be found worldwide. In 2008, Russia began a cyber attack on the Georgian government website, which was carried out along with Georgian military operations in South Ossetia. In 2008, Chinese \"nationalist hackers\" attacked CNN as it reported on Chinese repression on Tibet. Hackers from Armenia and Azerbaijan have actively participated in cyberwarfare as part of the Nagorno-Karabakh conflict, with Azerbaijani hackers targeting Armenian websites and posting Ilham Aliyev's statements.Jobs in cyberwarfare have become increasingly popular in the military. All four branches of the United States military actively recruit for cyber warfare positions.As the military have become more and more entangled into the national and global threat proposed by the utilization of the cyber domain, a new research field within the Military Science field have slowly emerged. In essence, its focus is centered towards describing, understanding and explaining what Military Cyber Operations is, can do and be tackled. In the Handbook of Military Sciences Aaron Brantly and Max Smeets define Military Cyber Operations to be \"those cyber operations which a military entity of a nation-state plans and conducts to achieve strategic, operational, or tactical gain.\" More so, they argue these types of military operations are commonly divided into three types of operations.\n\nDefensive Cyber Operations: Encompassing \"those actions taken through the use of computer networks to protect, monitor, analyze, detect, and respond to unauthorized activity within a governments information systems and computer networks\".\nCyber Espionage Operations: Encompassing \"those actions taken through the use of computer networks to gather data from target or adversary information systems or network\".\"\nOffensive Cyber Operations: Encompassing \"those actions taken through the use of computer networks to disrupt, deny, degrade, or destroy information resident in computers and computer networks, or the computers and networks themselves, or in basic, operations designed to achieve tangible effects\".\"\n\n\n*** Civil ***\nPotential targets in internet sabotage include all aspects of the Internet from the backbones of the web, to the internet service providers, to the varying types of data communication mediums and network equipment. This would include: web servers, enterprise information systems, client server systems, communication links, network equipment, and the desktops and laptops in businesses and homes. Electrical grids, financial networks, and telecommunication systems are also deemed vulnerable, especially due to current trends in computerization and automation.\n\n\n*** Hacktivism ***\nPolitically motivated hacktivism involves the subversive use of computers and computer networks to promote an agenda, and can potentially extend to attacks, theft and virtual sabotage that could be seen as cyberwarfare \u2013 or mistaken for it.\nHacktivists use their knowledge and software tools to gain unauthorized access to computer systems they seek to manipulate or damage not for material gain or to cause widespread destruction, but to draw attention to their cause through well-publicized disruptions of select targets. Anonymous and other hacktivist groups are often portrayed in the media as cyber-terrorists, wreaking havoc by hacking websites, posting sensitive information about their victims, and threatening further attacks if their demands are not met. However, hacktivism is more than that. Actors are politically motivated to change the world, through the use of fundamentalism. Groups like Anonymous, however, have divided opinion with their methods.\n\n\n*** Income generation ***\nCyber attacks, including ransomware, can be used to generate income. States can use these techniques to generate significant sources of income, which can evade sanctions and perhaps while simultaneously harming adversaries (depending on targets). This tactic was observed in August 2019 when it was revealed North Korea had generated $2 billion to fund its weapons program, avoiding the blanket of sanctions levied by the United States, United Nations and the European Union.\n\n\n*** Private sector ***\n\nComputer hacking represents a modern threat in ongoing global conflicts and industrial espionage and as such is presumed to widely occur. It is typical that this type of crime is underreported to the extent they are known. According to McAfee's George Kurtz, corporations around the world face millions of cyberattacks a day. \"Most of these attacks don't gain any media attention or lead to strong political statements by victims.\" This type of crime is usually financially motivated.\n\n\n*** Non-profit research ***\nBut not all those who engage in cyberwarfare do so for financial or ideological reasons. There are institutes and companies like the University of Cincinnati or the Kaspersky Security Lab which engage in cyberwarfare so as to better understand the field through actions like the researching and publishing of new security threats.\n\n== Preparedness ==\nA number of countries conduct exercise to increase preparedness and explore the strategy, tactics and operations involved in conducting and defending against cyber attacks against hostile states, this is typically done in the form of war games.The Cooperative Cyber Defence Centre of Excellence (CCDCE), part of the North Atlantic Treaty Organization (NATO), have conducted a yearly war game called Locked Shields since 2010 designed to test readiness and improve skills, strategy tactics and operational decision making of participating national organizations. Locked Shields 2019 saw 1200 participants from 30 countries compete in a red team vs. blue team exercise. The war game involved a fictional country, Berylia, which was \"experiencing a deteriorating security situation, where a number of hostile events coincide with coordinated cyber attacks against a major civilian internet service provider and maritime surveillance system. The attacks caused severe disruptions in the power generation and distribution, 4G communication systems, maritime surveillance, water purification plant and other critical infrastructure components\". CCDCE describe the aim of the exercise was to \"maintain the operation of various systems under intense pressure, the strategic part addresses the capability to understand the impact of decisions made at the strategic and policy level.\" Ultimately, France was the winner of Locked Shields 2019.The European Union conducts cyber war game scenarios with member states and foreign partner states to improve readiness, skills and observe how strategic and tactical decisions may affect the scenario.As well as war games which serve a broader purpose to explore options and improve skills, cyber war games are targeted at preparing for specific threats. In 2018 the Sunday Times reported the UK government was conducting cyber war games which could \"blackout Moscow\". These types of war games move beyond defensive preparedness, as previously described above and onto preparing offensive capabilities which can be used as deterrence, or for \"war\".\n\n== Cyber activities by nation ==\n\nApproximately 120 countries have been developing ways to use the Internet as a weapon and target financial markets, government computer systems and utilities.\n\n\n*** Asia ***\n\n\n**** China ****\n\nForeign Policy magazine puts the size of China's \"hacker army\" at anywhere from 50,000 to 100,000 individuals.Diplomatic cables highlight US concerns that China is using access to Microsoft source code and 'harvesting the talents of its private sector' to boost its offensive and defensive capabilities.The 2018 cyberattack on the Marriott hotel chain that collected personal details of roughly 500 million guests is now known to be a part of a Chinese intelligence-gathering effort that also hacked health insurers and the security clearance files of millions more Americans, The hackers, are suspected of working on behalf of the Ministry of State Security (MSS), the country's Communist-controlled civilian spy agency.  \"The information is exactly what the Chinese use to root out spies, recruit intelligence agents and build a rich repository of Americans' personal data for future targeting.\"\nA 2008 article in the Culture Mandala: The Bulletin of the Centre for East-West Cultural and Economic Studies by Jason Fritz alleges that the Chinese government from 1995 to 2008 was involved in a number of high-profile cases of espionage, primarily through the use of a \"decentralized network of students, business people, scientists, diplomats, and engineers from within the Chinese Diaspora\". A defector in Belgium, purportedly an agent, claimed that there were hundreds of spies in industries throughout Europe, and on his defection to Australia Chinese diplomat Chen Yonglin said there were over 1,000 such in that country.  In 2007, a Russian executive was sentenced to 11 years for passing information about the rocket and space technology organization to China. Targets in the United States have included \"aerospace engineering programs, space shuttle design, C4ISR data, high-performance computers, Nuclear weapon design, cruise missile data, semiconductors, integrated circuit design, and details of US arms sales to Taiwan\".While China continues to be held responsible for a string of cyber-attacks on a number of public and private institutions in the United States, India, Russia, Canada, and France, the Chinese government denies any involvement in cyber-spying campaigns. The administration maintains the position that China is not the threat but rather the victim of an increasing number of cyber-attacks. Most reports about China's cyber warfare capabilities have yet to be confirmed by the Chinese government.According to Fritz, China has expanded its cyber capabilities and military technology by acquiring foreign military technology. Fritz states that the Chinese government uses \"new space-based surveillance and intelligence gathering systems, Anti-satellite weapon, anti-radar, infrared decoys, and false target generators\" to assist in this quest, and that they support their \"Informatisation\" of their military through \"increased education of soldiers in cyber warfare; improving the information network for military training, and has built more virtual laboratories, digital libraries and digital campuses.\" Through this informatisation, they hope to prepare their forces to engage in a different kind of warfare, against technically capable adversaries. Many recent news reports link China's technological capabilities to the beginning of a new \"cyber cold war.\"Operation Shady RAT is an ongoing series of cyber attacks starting mid-2006, reported by Internet security company McAfee in August 2011. China is widely believed to be the state actor behind these attacks which hit at least 72 organizations including governments and defense contractors.On 14 September 2020, a database showing personal details of about 2.4 million people around the world was leaked and published.  A Chinese company, Zhenhua Data compiled the database. According to the information from \"National Enterprise Credit Information Publicity System\", which is run by State Administration for Market Regulation in China, the shareholders of Zhenhua Data Information Technology Co., Ltd. are two natural persons and one general partnership enterprise whose partners are natural persons. Wang Xuefeng, who is the chief executive and the shareholder of Zhenhua Data, has publicly boasted that he supports \"hybrid warfare\" through manipulation of public opinion and \"psychological warfare\".\n\n\n**** India ****\n\nThe Department of Information Technology created the Indian Computer Emergency Response Team (CERT-In) in 2004 to thwart cyber attacks in India. That year, there were 23 reported cyber security breaches. In 2011, there were 13,301. That year, the government created a new subdivision, the National Critical Information Infrastructure Protection Centre (NCIIPC) to thwart attacks against energy, transport, banking, telecom, defense, space and other sensitive areas.The executive director of the Nuclear Power Corporation of India (NPCIL) stated in February 2013 that his company alone was forced to block up to ten targeted attacks a day. CERT-In was left to protect less critical sectors.A high-profile cyber attack on 12 July 2012 breached the email accounts of about 12,000 people, including those of officials from the Ministry of External Affairs, Ministry of Home Affairs, Defense Research and Development Organizations (DRDO), and the Indo-Tibetan Border Police (ITBP). A government-private sector plan being overseen by National Security Advisor (NSA) Shivshankar Menon began in October 2012, and intends to boost up India's cyber security capabilities in the light of a group of experts findings that India faces a 470,000 shortfall of such experts despite the country's reputation of being an IT and software powerhouse.In February 2013, Information Technology Secretary J. Satyanarayana stated that the NCIIPC was finalizing policies related to national cyber security that would focus on domestic security solutions, reducing exposure through foreign technology. Other steps include the isolation of various security agencies to ensure that a synchronised attack could not succeed on all fronts and the planned appointment of a National Cyber Security Coordinator. As of that month, there had been no significant economic or physical damage to India related to cyber attacks.\nOn 26 November 2010, a group calling itself the Indian Cyber Army hacked the websites belonging to the Pakistan Army and the others belong to different ministries, including the Ministry of Foreign Affairs, Ministry of Education, Ministry of Finance, Pakistan Computer Bureau, Council of Islamic Ideology, etc. The attack was done as a revenge for the Mumbai terrorist attacks.On 4 December 2010, a group calling itself the Pakistan Cyber Army hacked the website of India's top investigating agency, the Central Bureau of Investigation (CBI). The National Informatics Center (NIC) has begun an inquiry.In July 2016, Cymmetria researchers discovered and revealed the cyber attack dubbed 'Patchwork', which compromised an estimated 2500 corporate and government agencies using code stolen from GitHub and the dark web. Examples of weapons used are an exploit for the Sandworm vulnerability (CVE-2014-4114), a compiled AutoIt script, and UAC bypass code dubbed UACME. Targets are believed to be mainly military and political assignments around Southeast Asia and the South China Sea and the attackers are believed to be of Indian origin and gathering intelligence from influential parties.The Defence Cyber Agency, which is the Indian Military agency responsible for Cyberwarfare, is expected to become operational by November 2019.\n\n\n**** Iran ****\nThe Iranian state sponsored group MuddyWater is active since at least 2017 and is responsible for many cyber attacks on various sectors.\n\n\n**** Philippines ****\nThe Chinese are being blamed after a cybersecurity company, F-Secure Labs, found a malware, NanHaiShu, which targeted the Philippines Department of Justice. It sent information in an infected machine to a server with a Chinese IP address. The malware which is considered particularly sophisticated in nature was introduced by phishing emails that were designed to look like they were coming from an authentic sources. The information sent is believed to be relating to the South China Sea legal case.\n\n\n**** South Korea ****\n\nIn July 2009, there were a series of coordinated denial of service attacks against major government, news media, and financial websites in South Korea and the United States. While many thought the attack was directed by North Korea, one researcher traced the attacks to the United Kingdom. Security researcher Chris Kubecka presented evidence multiple European Union and United Kingdom companies unwittingly helped attack South Korea due to a W32.Dozer infections, malware used in part of the attack. Some of the companies used in the attack were partially owned by several governments, further complicating attribution.\n\nIn July 2011, the South Korean company SK Communications was hacked, resulting in the theft of the personal details (including names, phone numbers, home and email addresses and resident registration numbers) of up to 35 million people. A trojaned software update was used to gain access to the SK Communications network. Links exist between this hack and other malicious activity and it is believed to be part of a broader, concerted hacking effort.With ongoing tensions on the Korean Peninsula, South Korea's defense ministry stated that South Korea was going to improve cyber-defense strategies in hopes of preparing itself from possible cyber attacks. In March 2013, South Korea's major banks \u2013 Shinhan Bank, Woori Bank and NongHyup Bank \u2013 as well as many broadcasting stations \u2013 KBS, YTN and MBC \u2013 were hacked and more than 30,000 computers were affected; it is one of the biggest attacks South Korea has faced in years. Although it remains uncertain as to who was involved in this incident, there has been immediate assertions that North Korea is connected, as it threatened to attack South Korea's government institutions, major national banks and traditional newspapers numerous times \u2013 in reaction to the sanctions it received from nuclear testing and to the continuation of Foal Eagle, South Korea's annual joint military exercise with the United States. North Korea's cyber warfare capabilities raise the alarm for South Korea, as North Korea is increasing its manpower through military academies specializing in hacking. Current figures state that South Korea only has 400 units of specialized personnel, while North Korea has more than 3,000 highly trained hackers; this portrays a huge gap in cyber warfare capabilities and sends a message to South Korea that it has to step up and strengthen its Cyber Warfare Command forces. Therefore, in order to be prepared from future attacks, South Korea and the United States will discuss further about deterrence plans at the Security Consultative Meeting (SCM). At SCM, they plan on developing strategies that focuses on accelerating the deployment of ballistic missiles as well as fostering its defense shield program, known as the Korean Air and Missile Defense.\n\n\n**** Sri Lanka ****\n\n\n**** North Korea ****\n\n\n*** Africa ***\n\n\n**** Egypt ****\nIn an extension of a bilateral dispute between Ethiopia and Egypt over the Grand Ethiopian Renaissance Dam, Ethiopian government websites have been hacked by the Egypt-based hackers in June 2020.\n\n\n*** Europe ***\n\n\n**** Cyprus ****\nThe New York Times published an expos\u00e9 revealing an extensive three-year phishing campaign aimed against diplomats based in Cyprus. After accessing the state system the hackers had access to the European Union's entire exchange database. By login into Coreu, hackers accessed communications linking all EU states, on both sensitive and not so sensitive matters. The event exposed poor protection of routine exchanges among European Union officials and a coordinated effort from a foreign entity to spy on another country. \"After over a decade of experience countering Chinese cyberoperations and extensive technical analysis, there is no doubt this campaign is connected to the Chinese government\", said Blake Darche, one of the Area 1 Security experts - the company revealing the stolen documents. The Chinese Embassy in the US did not return calls for comment. In 2019, another coordinated effort took place that allowed hackers to gain access to government (gov.cy) emails. Cisco's Talos Security Department revealed that \"Sea Turtle\" hackers carried out a broad piracy campaign in the DNS countries, hitting 40 different organizations, including Cyprus.\n\n\n**** Estonia ****\nIn April 2007, Estonia came under cyber attack in the wake of relocation of the Bronze Soldier of Tallinn. The largest part of the attacks were coming from Russia and from official servers of the authorities of Russia. In the attack, ministries, banks, and media were targeted. This attack on Estonia, a seemingly small Baltic state, was so effective because of how most of Estonian government services are run online. Estonia has implemented an e-government, where banking services, political elections, taxes, and other components of a modern society are now all done online.\n\n\n**** France ****\n\nIn 2013, the French Minister of Defense, Mr Jean-Yves Le Drian, ordered the creation of a cyber army, representing its fourth national army corps (along with ground, naval and air forces) under the French Ministry of Defense, to protect French and European interests on its soil and abroad. A contract was made with French firm EADS (Airbus) to identify and secure its main elements susceptible to cyber threats. In 2016 France had planned 2600 \"cyber-soldiers\" and a 440 million euros investment for cybersecurity products for this new army corps. An additional 4400 reservists constitute the heart of this army from 2019.\n\n\n**** Germany ****\nIn 2013, Germany revealed the existence of their 60-person Computer Network Operation unit. The German intelligence agency, BND, announced it was seeking to hire 130 \"hackers\" for a new \"cyber defence station\" unit.  In March 2013, BND president Gerhard Schindler announced that his agency had observed up to five attacks a day on government authorities, thought mainly to originate in China.  He confirmed the attackers had so far only accessed data and expressed concern that the stolen information could be used as the basis of future sabotage attacks against arms manufacturers, telecommunications companies and government and military agencies. Shortly after Edward Snowden leaked details of the U.S. National Security Agency's cyber surveillance system, German Interior Minister Hans-Peter Friedrich announced that the BND would be given an additional budget of 100 million Euros to increase their cyber surveillance capability from 5% of total internet traffic in Germany to 20% of total traffic, the maximum amount allowed by German law.\n\n\n**** Netherlands ****\n\nIn the Netherlands, Cyber Defense is nationally coordinated by the National Cyber Security Centrum (NCSC). The Dutch Ministry of Defense laid out a cyber strategy in 2011. The first focus is to improve the cyber defense handled by the Joint IT branch (JIVC). To improve intel operations, the intel community in the Netherlands (including the military intel organization, MIVD) has set up the Joint Sigint Cyber Unit (JSCU). The Ministry of Defense oversees an offensive cyber force, called Defensive Cyber Command (DCC).\n\n\n**** Norway ****\n\n\n**** Russia ****\n\nRussian, South Ossetian, Georgian and Azerbaijani sites were attacked by hackers during the 2008 South Ossetia War.American-led cyberattacks against Soviet Union and Russia\n\nWhen Russia was still a part of the Soviet Union in 1982, a portion of a Trans-Siberia pipeline within its territory exploded, allegedly due to a Trojan Horse computer malware implanted in the pirated Canadian software by the Central Intelligence Agency. The malware caused the SCADA system running the pipeline to malfunction. The \"Farewell Dossier\" provided information on this attack, and wrote that compromised computer chips would become a part of Soviet military equipment, flawed turbines would be placed in the gas pipeline, and defective plans would disrupt the output of chemical plants and a tractor factory. This caused the \"most monumental nonnuclear explosion and fire ever seen from space.\" However, the Soviet Union did not blame the United States for the attack.In June 2019, the New York Times reported that American hackers from the United States Cyber Command planted malware potentially capable of disrupting the Russian electrical grid.Russian-led cyberattacks\n\nIt has been claimed that Russian security services organized a number of denial of service attacks as a part of their cyber-warfare against other countries, most notably the 2007 cyberattacks on Estonia and the 2008 cyberattacks on Russia, South Ossetia, Georgia, and Azerbaijan. One identified young Russian hacker said that he was paid by Russian state security services to lead hacking attacks on NATO computers. He was studying computer sciences at the Department of the Defense of Information. His tuition was paid for by the FSB.\n\n\n**** Sweden ****\nIn January 2017, Sweden's armed forces were subjected to a cyber-attack that caused them to shutdown a so-called Caxcis IT system used in military exercises.\n\n\n**** Ukraine ****\nAccording to CrowdStrike from 2014 to 2016, the Russian APT Fancy Bear used Android malware to target the Ukrainian Army's Rocket Forces and Artillery. They distributed an infected version of an Android app whose original purpose was to control targeting data for the D-30 Howitzer artillery. The app, used by Ukrainian officers, was loaded with the X-Agent spyware and posted online on military forums. The attack was claimed by Crowd-Strike to be successful, with more than 80% of Ukrainian D-30 Howitzers destroyed, the highest percentage loss of any artillery pieces in the army (a percentage that had never been previously reported and would mean the loss of nearly the entire arsenal of the biggest artillery piece of the Ukrainian Armed Forces). According to the Ukrainian army this number is incorrect and that losses in artillery weapons \"were way below those reported\" and that these losses \"have nothing to do with the stated cause\".In 2014, the Russians were suspected to use a cyber weapon called \"Snake\", or \"Ouroboros,\" to conduct a cyber attack on Ukraine during a period of political turmoil. The Snake tool kit began spreading into Ukrainian computer systems in 2010. It performed Computer Network Exploitation (CNE), as well as highly sophisticated Computer Network Attacks (CNA).On 23 December 2015 the Black-Energy malware was used in a cyberattack on Ukraine's power-grid that left more than 200,000 people temporarily without power. A mining company and a large railway operator were also victims of the attack.Ukraine saw a massive surge in cyber attacks during the 2022 Russian invasion of Ukraine. Several websites belonging to Ukrainian banks and government departments became inaccessible.\n\n\n**** United Kingdom ****\nMI6 reportedly infiltrated an Al Qaeda website and replaced the instructions for making a pipe bomb with the recipe for making cupcakes.In October 2010, Iain Lobban, the director of the Government Communications Headquarters (GCHQ), said the UK faces a \"real and credible\" threat from cyber attacks by hostile states and criminals and government systems are targeted 1,000 times each month, such attacks threatened the UK's economic future, and some countries were already using cyber assaults to put pressure on other nations.On 12 November 2013, financial organizations in London conducted cyber war games dubbed \"Waking Shark 2\" to simulate massive internet-based attacks against bank and other financial organizations. The Waking Shark 2 cyber war games followed a similar exercise in Wall Street.\n\n\n*** Middle East ***\n\n\n**** Iran ****\n\nIran has been both victim and perpetrator of several cyberwarfare operations. Iran is considered an emerging military power in the field.\n\nIn September 2010, Iran was attacked by the Stuxnet worm, thought to specifically target its Natanz nuclear enrichment facility. It was a 500-kilobyte computer worm that infected at least 14 industrial sites in Iran, including the Natanz uranium-enrichment plant. Although the official authors of Stuxnet haven't been officially identified, Stuxnet is believed to be developed and deployed by the United States and Israel. The worm is said to be the most advanced piece of malware ever discovered and significantly increases the profile of cyberwarfare.Iranian Cyber Police department, FATA, was dismissed one year after its creation in 2011 because of the arrest and death of Sattar Behesti, a blogger, in the custody of FATA. Since then, the main responsible institution for the cyberwarfare in Iran is the \"Cyber Defense Command\" operating under the Joint Staff of Iranian Armed Forces.\n\n\n**** Israel ****\nIn the 2006 war against Hezbollah, Israel alleges that cyber-warfare was part of the conflict, where the Israel Defense Forces (IDF) intelligence estimates several countries in the Middle East used Russian hackers and scientists to operate on their behalf. As a result, Israel attached growing importance to cyber-tactics, and became, along with the U.S., France and a couple of other nations, involved in cyber-war planning. Many international high-tech companies are now locating research and development operations in Israel, where local hires are often veterans of the IDF's elite computer units. Richard A. Clarke adds that \"our Israeli friends have learned a thing or two from the programs we have been working on for more than two decades.\":\u200a8\u200aIn September 2007, Israel carried out an airstrike on a suspected nuclear reactor in Syria dubbed Operation Orchard. U.S. industry and military sources speculated that the Israelis may have used cyberwarfare to allow their planes to pass undetected by radar into Syria.Following US President Donald Trump's decision to pull out of the Iran nuclear deal in May 2018, cyber warfare units in the United States and Israel monitoring internet traffic out of Iran noted a surge in retaliatory cyber attacks from Iran. Security firms warned that Iranian hackers were sending emails containing malware to diplomats who work in the foreign affairs offices of US allies and employees at telecommunications companies, trying to infiltrate their computer systems.\n\n\n**** Saudi Arabia ****\nOn 15 August 2012 at 11:08 am local time, the Shamoon virus began destroying over 35,000 computer systems, rendering them inoperable. The virus used to target the Saudi government by causing destruction to the state owned national oil company Saudi Aramco. The attackers posted a pastie on PasteBin.com hours prior to the wiper logic bomb occurring, citing oppression and the Al-Saud regime as a reason behind the attack.  The attack was well staged according to Chris Kubecka, a former security advisor to Saudi Aramco after the attack and group leader of security for Aramco Overseas. It was an unnamed Saudi Aramco employee on the Information Technology team which opened a malicious phishing email, allowing initial entry into the computer network around mid-2012.\nKubecka also detailed in her Black Hat USA talk Saudi Aramco placed the majority of their security budget on the ICS control network, leaving the business network at risk for a major incident. \"When you realize most of your security budget was spent on ICS & IT gets Pwnd\". The virus has been noted to have behavior differing from other malware attacks, due to the destructive nature and the cost of the attack and recovery. US Defense Secretary Leon Panetta called the attack a \"Cyber Pearl Harbor\". Known years later as the \"Biggest hack in history\" and intended for cyber warfare. Shamoon can spread from an infected machine to other computers on the network. Once a system is infected, the virus continues to compile a list of files from specific locations on the system, upload them to the attacker, and erase them. Finally the virus overwrites the master boot record of the infected computer, making it unusable. The virus has been used for cyber warfare against the national oil companies Saudi Aramco and Qatar's RasGas.Saudi Aramco announced the attack on their Facebook page and went offline again until a company statement was issued on 25 August 2012. The statement falsely reported normal business was resumed on 25 August 2012. However a Middle Eastern journalist leaked photographs taken on 1 September 2012 showing kilometers of petrol trucks unable to be loaded due to backed business systems still inoperable. \n\nOn 29 August 2012 the same attackers behind Shamoon posted another pastie on PasteBin.com, taunting Saudi Aramco with proof they still retained access to the company network. The post contained the username and password on security and network equipment and the new password for the CEO Khalid Al- Falih The attackers also referenced a portion of the Shamoon malware as further proof in the pastie.According to Kubecka, in order to restore operations. Saudi Aramco used its large private fleet of aircraft and available funds to purchase much of the world's hard drives, driving the price up. New hard drives were required as quickly as possible so oil prices were not affected by speculation. By 1 September 2012 gasoline resources were dwindling for the public of Saudi Arabia 17 days after the 15 August attack. RasGas was also affected by a different variant, crippling them in a similar manner.\n\n\n**** Qatar ****\nIn March 2018 American Republican fundraiser Elliott Broidy filed a lawsuit against Qatar, alleging that Qatar's government stole and leaked his emails in order to discredit him because he was viewed \"as an impediment to their plan to improve the country's standing in Washington.\" In May 2018, the lawsuit named Mohammed bin Hamad bin Khalifa Al Thani, brother of the Emir of Qatar, and his associate Ahmed Al-Rumaihi, as allegedly orchestrating Qatar's cyber warfare campaign against Broidy. Further litigation revealed that the same cybercriminals who targeted Broidy had targeted as many as 1,200 other individuals, some of whom are also \"well-known enemies of Qatar\" such as senior officials of the U.A.E., Egypt, Saudi Arabia, and Bahrain. While these hackers almost always obscured their location, some of their activity was traced to a telecommunication network in Qatar.\n\n\n**** United Arab Emirates ****\nThe United Arab Emirates has launched several cyber-attacks in the past targeting dissidents. Ahmed Mansoor, an Emirati citizen, was jailed for sharing his thoughts on Facebook and Twitter. He was given the code name Egret under the state-led covert project called Raven, which spied on top political opponents, dissidents, and journalists. Project Raven deployed a secret hacking tool called Karma, to spy without requiring the target to engage with any web links.In September 2021, three of the former American intelligence officers, Marc Baier, Ryan Adams, and Daniel Gericke, admitted to assisting the UAE in hacking crimes by providing them with advanced technology and violating US laws. Under a three-year deferred prosecution agreement with the Justice Department, the three defendants also agreed to pay nearly $1.7 million in fines to evade prison sentences. The court documents revealed that the Emirates hacked into the computers and mobile phones of dissidents, activists, and journalists. They also attempted to break into the systems of the US and rest of the world.\n\n\n*** North America ***\n\n\n**** United States ****\n\nCyberwarfare in the United States is a part of the American military strategy of proactive cyber defence and the use of cyberwarfare as a platform for attack. The new United States military strategy makes explicit that a cyberattack is casus belli just as a traditional act of war.U.S. government security expert Richard A. Clarke, in his book Cyber War (May 2010), had defined \"cyberwarfare\" as \"actions by a nation-state to penetrate another nation's computers or networks for the purposes of causing damage or disruption.\":\u200a6\u200a The Economist describes cyberspace as \"the fifth domain of warfare,\" and William J. Lynn, U.S. Deputy Secretary of Defense, states that \"as a doctrinal matter, the Pentagon has formally recognized cyberspace as a new domain in warfare . . . [which] has become just as critical to military operations as land, sea, air, and space.\"In 2009, president Barack Obama declared America's digital infrastructure to be a \"strategic national asset,\" and in May 2010 the Pentagon set up its new U.S. Cyber Command (USCYBERCOM), headed by General Keith B. Alexander, director of the National Security Agency (NSA), to defend American military networks and attack other countries' systems. The EU has set up ENISA (European Union Agency for Network and Information Security) which is headed by Prof. Udo Helmbrecht and there are now further plans to significantly expand ENISA's capabilities. The United Kingdom has also set up a cyber-security and \"operations centre\" based in Government Communications Headquarters (GCHQ), the British equivalent of the NSA. In the U.S. however, Cyber Command is only set up to protect the military, whereas the government and corporate infrastructures are primarily the responsibility respectively of the Department of Homeland Security and private companies.In February 2010, top American lawmakers warned that the \"threat of a crippling attack on telecommunications and computer networks was sharply on the rise.\" According to The Lipman Report, numerous key sectors of the U.S. economy along with that of other nations, are currently at risk, including cyber threats to public and private facilities, banking and finance, transportation, manufacturing, medical, education and government, all of which are now dependent on computers for daily operations. In 2009, president Obama stated that \"cyber intruders have probed our electrical grids.\"On 19 June 2010, United States Senator Joe Lieberman (I-CT) introduced a bill called \"Protecting Cyberspace as a National Asset Act of 2010\", which he co-wrote with Senator Susan Collins (R-ME) and Senator Thomas Carper (D-DE). If signed into law, this controversial bill, which the American media dubbed the \"Kill switch bill\", would grant the president emergency powers over parts of the Internet. However, all three co-authors of the bill issued a statement that instead, the bill \"[narrowed] existing broad presidential authority to take over telecommunications networks\".\nIn June 2012 the New York Times reported that president Obama had ordered the cyber attack on Iranian nuclear enrichment facilities.In July 2010, The Economist wrote that China had plans of \"winning informationised wars by the mid-21st century\",  that other countries were likewise organizing for cyberwar, among them Russia, Israel and North Korea, and that Iran boasted of having the world's second-largest cyber-army. James Gosler, a government cybersecurity specialist, worried that the U.S. has a severe shortage of computer security specialists, estimating that there are only about 1,000 qualified people in the country today, but needs a force of 20,000 to 30,000 skilled experts. At the July 2010 Black Hat computer security conference, Michael Hayden, former deputy director of national intelligence, challenged thousands of attendees to help devise ways to \"reshape the Internet's security architecture\", explaining, \"You guys made the cyberworld look like the north German plain.\"In August 2010, the U.S. for the first time warned publicly about the Chinese military's use of civilian computer experts in clandestine cyber attacks aimed at American companies and government agencies. The Pentagon also pointed to an alleged China-based computer spying network dubbed GhostNet which was revealed in a 2009 research report. The Pentagon stated:\n\nThe People's Liberation Army is using \"information warfare units\" to develop viruses to attack enemy computer systems and networks, and those units include civilian computer professionals. Commander Bob Mehal, will monitor the PLA's buildup of its cyberwarfare capabilities and will continue to develop capabilities to counter any potential threat.\n\nThe United States Department of Defense sees the use of computers and the Internet to conduct warfare in cyberspace as a threat to national security. The United States Joint Forces Command describes some of its attributes:\n\nCyberspace technology is emerging as an \"instrument of power\" in societies, and is becoming more available to a country's opponents, who may use it to attack, degrade, and disrupt communications and the flow of information. With low barriers to entry, coupled with the anonymous nature of activities in cyberspace, the list of potential adversaries is broad.  Furthermore, the globe-spanning range of cyberspace and its disregard for national borders will challenge legal systems and complicate a nation's ability to deter threats and respond to contingencies.\n\nIn February 2010, the United States Joint Forces Command released a study which included a summary of the threats posed by the internet:\nWith very little investment, and cloaked in a veil of anonymity, our adversaries will inevitably attempt to harm our national interests. Cyberspace will become a main front in both irregular and traditional conflicts. Enemies in cyberspace will include both states and non-states and will range from the unsophisticated amateur to highly trained professional hackers. Through cyberspace, enemies will target industry, academia, government, as well as the military in the air, land, maritime, and space domains. In much the same way that airpower transformed the battlefield of World War II, cyberspace has fractured the physical barriers that shield a nation from attacks on its commerce and communication. Indeed, adversaries have already taken advantage of computer networks and the power of information technology not only to plan and execute savage acts of terrorism, but also to influence directly the perceptions and will of the U.S. Government and the American population.\nOn 6 October 2011, it was announced that Creech AFB's drone and Predator fleet's command and control data stream had been keylogged, resisting all attempts to reverse the exploit, for the past two weeks. The Air Force issued a statement that the virus had \"posed no threat to our operational mission\".On 21 November 2011, it was widely reported in the U.S. media that a hacker had destroyed a water pump at the Curran-Gardner Township Public Water District in Illinois. However, it later turned out that this information was not only false, but had been inappropriately leaked from the Illinois Statewide Terrorism and Intelligence Center.In 2012, the US used cyberattacks for tactical advantage in Afghanistan.According to a 2013 Foreign Policy magazine article, NSA's Tailored Access Operations (TAO) unit \"has successfully penetrated Chinese computer and telecommunications systems for almost 15 years, generating some of the best and most reliable intelligence information about what is going on inside the People's Republic of China.\"In 2013 cyberwarfare was, for the first time, considered a larger threat than Al Qaeda or terrorism, by many U.S. intelligence officials. In 2017, Representative Mike Rogers, chairman of the U.S. House Permanent Select Committee on Intelligence, for instance, said that \n\"We are in a cyber war in this country, and most Americans don't know it. And we are not necessarily winning. We have got huge challenges when it comes to cybersecurity.\"In 2014, Barack Obama ordered an intensification of cyberwarfare against North Korea's missile program for sabotaging test launches in their opening seconds. \nOn 24 November 2014, Sony Pictures Entertainment hack was a release of confidential data belonging to Sony Pictures Entertainment (SPE).\nIn June 2015, the United States Office of Personnel Management (OPM) announced that it had been the target of a data breach targeting the records of as many as four million people. Later, FBI Director James Comey put the number at 18 million. The Washington Post has reported that the attack originated in China, citing unnamed government officials.In October 2016, Jeh Johnson the United States Secretary of Homeland Security and James Clapper the U.S. Director of National Intelligence issued a joint statement accusing Russia of interfering with the 2016 United States presidential election. The New York Times reported the Obama administration formally accused Russia of stealing and disclosing Democratic National Committee emails. Under U.S. law (50 U.S.C.Title 50 \u2013 War and National Defense, Chapter 15 \u2013 National Security, Subchapter III Accountability for Intelligence Activities) there must be a formal Presidential finding prior to authorizing a covert attack. Then U.S. vice president Joe Biden said on the American news interview program Meet The Press that the United States will respond. The New York Times noted that Biden's comment \"seems to suggest that Mr. Obama is prepared to order \u2013 or has already ordered \u2013 some kind of covert action\". \nIn 2016 President Barack Obama authorized the planting of cyber weapons in Russian infrastructure in the final weeks of his presidency in response to Moscow's interference in the 2016 presidential election. On 29 December 2016 United States imposed the most extensive sanctions against Russia since the Cold War, expelling 35 Russian diplomats from the United States.Economic sanctions are the most frequently used the foreign policy instruments by the United States today Thus, it is not surprising to see that economic sanctions are also used as counter policies against cyberattacks. According to Onder (2021), economic sanctions are also information gathering mechanisms for the sanctioning states about the capabilities of the sanctioned states.In March 2017, WikiLeaks published more than 8,000 documents on the CIA. The confidential documents, codenamed Vault 7 and dated from 2013 to 2016, include details on CIA's software capabilities, such as the ability to compromise cars, smart TVs, web browsers (including Google Chrome, Microsoft Edge, Mozilla Firefox, and Opera Software ASA), and the operating systems of most smartphones (including Apple's iOS and Google's Android), as well as other operating systems such as Microsoft Windows, macOS, and Linux.For a global perspective of countries and other actors engaged in cyber warfare, see the George Washington University-based National Security Archive's CyberWar map.\n\n== Cyberpeace ==\n\nThe rise of cyber as a warfighting domain has led to efforts to determine how cyberspace can be used to foster peace.  For example, the German civil rights panel FIfF runs a campaign for cyberpeace \u2212 for the control of cyberweapons and surveillance technology and against the militarization of cyberspace and the development and stockpiling of offensive exploits and malware. Measures for cyberpeace include policymakers developing new rules and norms for warfare, individuals and organizations building new tools and secure infrastructures, promoting open source, the establishment of cyber security centers, auditing of critical infrastructure cybersecurity, obligations to disclose vulnerabilities, disarmament, defensive security strategies, decentralization, education and widely applying relevant tools and infrastructures, encryption and other cyberdefenses.The topics of cyber peacekeeping and cyber peacemaking have also been studied by researchers, as a way to restore and strengthen peace in the aftermath of both cyber and traditional warfare.\n\n== Cyber counterintelligence ==\nCyber counter-intelligence are measures to identify, penetrate, or neutralize foreign operations that use cyber means as the primary tradecraft methodology, as well as foreign intelligence service collection efforts that use traditional methods to gauge cyber capabilities and intentions.\nOn 7 April 2009, The Pentagon announced they spent more than $100 million in the last six months responding to and repairing damage from cyber attacks and other computer network problems.\nOn 1 April 2009, U.S. lawmakers pushed for the appointment of a White House cyber security \"czar\" to dramatically escalate U.S. defenses against cyber attacks, crafting proposals that would empower the government to set and enforce security standards for private industry for the first time.\nOn 9 February 2009, the White House announced that it will conduct a review of the country's cyber security to ensure that the Federal government of the United States cyber security initiatives are appropriately integrated, resourced and coordinated with the United States Congress and the private sector.\nIn the wake of the 2007 cyberwar waged against Estonia, NATO established the Cooperative Cyber Defence Centre of Excellence (CCD CoE) in Tallinn, Estonia, in order to enhance the organization's cyber defence capability. The center was formally established on 14 May 2008, and it received full accreditation by NATO and attained the status of International Military Organization on 28 October 2008. Since Estonia has led international efforts to fight cybercrime, the United States Federal Bureau of Investigation says it will permanently base a computer crime expert in Estonia in 2009 to help fight international threats against computer systems.\nIn 2015, the Department of Defense released an updated cyber strategy memorandum detailing the present and future tactics deployed in the service of defense against cyberwarfare.  In this memorandum, three cybermissions are laid out.  The first cybermission seeks to arm and maintain existing capabilities in the area of cyberspace, the second cybermission focuses on prevention of cyberwarfare, and the third cybermission includes strategies for retaliation and preemption (as distinguished from prevention).One of the hardest issues in cyber counterintelligence is the problem of attribution. Unlike conventional warfare, figuring out who is behind an attack can be very difficult. However Defense Secretary Leon Panetta has claimed that the United States has the capability to trace attacks back to their sources and hold the attackers \"accountable\".\n\n== Doubts about existence ==\nIn October 2011 the Journal of Strategic Studies, a leading journal in that field, published an article by Thomas Rid, \"Cyber War Will Not Take Place\" which argued that all politically motivated cyber attacks are merely sophisticated versions of sabotage, espionage, or subversion \u2013 and that it is unlikely that cyber war will occur in the future.\n\n== Legal perspective ==\nNIST, a cyberwarfare framework, was published in 2014 in the US.S.The Tallinn Manual, published in 2013, is an academic, non-binding study on how international law, in particular the jus ad bellum and international humanitarian law, apply to cyber conflicts and cyber warfare. It was written at the invitation of the Tallinn-based NATO Cooperative Cyber Defence Centre of Excellence by an international group of approximately twenty experts between 2009 and 2012.The Shanghai Cooperation Organisation (members of which include China and Russia) defines cyberwar to include dissemination of information \"harmful to the spiritual, moral and cultural spheres of other states\". In September 2011, these countries proposed to the UN Secretary General a document called \"International code of conduct for information security\".In contrast, the United approach focuses on physical and economic damage and injury, putting political concerns under freedom of speech. This difference of opinion has led to reluctance in the West to pursue global cyber arms control agreements. However, American General Keith B. Alexander did endorse talks with Russia over a proposal to limit military attacks in cyberspace. In June 2013, Barack Obama and Vladimir Putin agreed to install a secure Cyberwar-Hotline providing \"a direct secure voice communications line between the US cybersecurity coordinator and the Russian deputy secretary of the security council, should there be a need to directly manage a crisis situation arising from an ICT security incident\" (White House quote).A Ukrainian international law scholar, Alexander Merezhko, has developed a project called the International Convention on Prohibition of Cyberwar in Internet. According to this project, cyberwar is defined as the use of Internet and related technological means by one state against the political, economic, technological and information sovereignty and independence of another state. Professor Merezhko's project suggests that the Internet ought to remain free from warfare tactics and be treated as an international landmark. He states that the Internet (cyberspace) is a \"common heritage of mankind\".On the February 2017 RSA Conference Microsoft president Brad Smith suggested global rules \u2013 a \"Digital Geneva Convention\" \u2013 for cyber attacks that \"ban the nation-state hacking of all the civilian aspects of our economic and political infrastructures\". He also stated that an independent organization could investigate and publicly disclose evidence that attributes nation-state attacks to specific countries. Furthermore, he said that the technology sector should collectively and neutrally work together to protect Internet users and pledge to remain neutral in conflict and not aid governments in offensive activity and to adopt a coordinated disclosure process for software and hardware vulnerabilities. A fact-binding body has also been proposed to regulate cyber operations.\n\n== In popular culture ==\n\n\n*** In films ***\n\nIndependence Day (1996)\nTerminator 3: Rise of the Machines (2003)\nLive Free or Die Hard (2007)\nTerminator Genisys (2015)\nSnowden (2016)\nTerminator: Dark Fate (2019)Documentaries\nHacking the Infrastructure: Cyber Warfare (2016) by Viceland\nCyber War Threat (2015)\nDarknet, Hacker, Cyberwar (2017)\nZero Days (2016)\nThe Perfect Weapon (2020)\n\n\n*** In television ***\n\"Cancelled\", an episode of the animated sitcom South Park\nSeries 2 of COBRA, a British thriller series, revolves around a sustained campaign of cyberwar against the United Kingdom and the British government's response to it."
    }
  },
  {
    "instruction": "Write an answer to the following question: What kind of funding does the BLADE software receive, and what is the primary objective of its development?",
    "context": "",
    "output": "The BLADE software receives funding from various sources, including the National Science Foundation, the United States Army Research Laboratory, and the Office of Naval Research. The primary objective of its development is to prevent drive-by download malware attacks, a common and dangerous form of cyber threat. By blocking these attacks in real-time, BLADE provides an essential service in protecting computer systems and networks from compromise.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What kind of funding does the BLADE software receive, and what is the primary objective of its development?",
      "answer": "The BLADE software receives funding from various sources, including the National Science Foundation, the United States Army Research Laboratory, and the Office of Naval Research. The primary objective of its development is to prevent drive-by download malware attacks, a common and dangerous form of cyber threat. By blocking these attacks in real-time, BLADE provides an essential service in protecting computer systems and networks from compromise."
    }
  },
  {
    "instruction": "Encryption\n\n==Introduction==\nIn cryptography, encryption is the process of encoding information. This process converts the original representation of the information, known as plaintext, into an alternative form known as ciphertext. Ideally, only authorized parties can decipher a ciphertext back to plaintext and access the original information. Encryption does not itself prevent interference but denies the intelligible content to a would-be interceptor. \nFor technical reasons, an encryption scheme usually uses a pseudo-random encryption key generated by an algorithm. It is possible to decrypt the message without possessing the key but, for a well-designed encryption scheme, considerable computational resources and skills are required. An authorized recipient can easily decrypt the message with the key provided by the originator to recipients but not to unauthorized users. \nHistorically, various forms of encryption have been used to aid in cryptography. Early encryption techniques were often used in military messaging. Since then, new techniques have emerged and become commonplace in all areas of modern computing. Modern encryption schemes use the concepts of public-key and symmetric-key. Modern encryption techniques ensure security because modern computers are inefficient at cracking the encryption.\n\n\n\n== Encryption in cryptography ==\nIn the context of cryptography, encryption serves as a mechanism to ensure confidentiality. Since data may be visible on the Internet, sensitive information such as passwords and personal communication may be exposed to potential interceptors. The process of encrypting and decrypting messages involves keys. The two main types of keys in cryptographic systems are symmetric-key and public-key (also known as asymmetric-key).Many complex cryptographic algorithms often use simple modular arithmetic in their implementations.\n\n\n*** Types ***\nIn symmetric-key schemes, the encryption and decryption keys are the same. Communicating parties must have the same key in order to achieve secure communication. The German Enigma Machine utilized a new symmetric-key each day for encoding and decoding messages.\nIn public-key encryption schemes, the encryption key is published for anyone to use and encrypt messages. However, only the receiving party has access to the decryption key that enables messages to be read. Public-key encryption was first described in a secret document in 1973; beforehand, all encryption schemes were symmetric-key (also called private-key).:\u200a478\u200a Although published subsequently, the work of Diffie and Hellman was published in a journal with a large readership, and the value of the methodology was explicitly described. The method became known as the Diffie-Hellman key exchange.\nRSA (Rivest\u2013Shamir\u2013Adleman) is another notable public-key cryptosystem. Created in 1978, it is still used today for applications involving digital signatures. Using number theory, the RSA algorithm selects two prime numbers, which help generate both the encryption and decryption keys.A publicly available public-key encryption application called Pretty Good Privacy (PGP) was written in 1991 by Phil Zimmermann, and distributed free of charge with source code. PGP was purchased by Symantec in 2010 and is regularly updated.\n\n== Uses ==\nEncryption has long been used by militaries and governments to facilitate secret communication. It is now commonly used in protecting information within many kinds of civilian systems. For example, the Computer Security Institute reported that in 2007, 71% of companies surveyed utilized encryption for some of their data in transit, and 53% utilized encryption for some of their data in storage. Encryption can be used to protect data \"at rest\", such as information stored on computers and storage devices (e.g. USB flash drives). In recent years, there have been numerous reports of confidential data, such as customers' personal records, being exposed through loss or theft of laptops or backup drives; encrypting such files at rest helps protect them if physical security measures fail. Digital rights management systems, which prevent unauthorized use or reproduction of copyrighted material and protect software against reverse engineering (see also copy protection), is another somewhat different example of using encryption on data at rest.Encryption is also used to protect data in transit, for example data being transferred via networks (e.g. the Internet, e-commerce), mobile telephones, wireless microphones, wireless intercom systems, Bluetooth devices and bank automatic teller machines. There have been numerous reports of data in transit being intercepted in recent years. Data should also be encrypted when transmitted across networks in order to protect against eavesdropping of network traffic by unauthorized users.\n\n\n*** Data erasure ***\n\nConventional methods for permanently deleting data from a storage device involve overwriting the device's whole content with zeros, ones, or other patterns \u2013 a process which can take a significant amount of time, depending on the capacity and the type of storage medium. Cryptography offers a way of making the erasure almost instantaneous. This method is called crypto-shredding. An example implementation of this method can be found on iOS devices, where the cryptographic key is kept in a dedicated 'effaceable storage'. Because the key is stored on the same device, this setup on its own does not offer full privacy or security protection if an unauthorized person gains physical access to the device.\n\n== Limitations ==\nEncryption is used in the 21st century to protect digital data and information systems. As computing power increased over the years, encryption technology has only become more advanced and secure. However, this advancement in technology has also exposed a potential limitation of today's encryption methods.\nThe length of the encryption key is an indicator of the strength of the encryption method. For example, the original encryption key, DES (Data Encryption Standard), was 56 bits, meaning it had 2^56 combination possibilities. With today's computing power, a 56-bit key is no longer secure, being vulnerable to hacking by brute force attack.Quantum computing utilizes properties of quantum mechanics in order to process large amounts of data simultaneously. Quantum computing has been found to achieve computing speeds thousands of times faster than today's supercomputers. This computing power presents a challenge to today's encryption technology. For example, RSA encryption utilizes the multiplication of very large prime numbers to create a semiprime number for its public key. Decoding this key without its private key requires this semiprime number to be factored, which can take a very long time to do with modern computers. It would take a supercomputer anywhere between weeks to months to factor in this key. However, quantum computing can use quantum algorithms to factor this semiprime number in the same amount of time it takes for normal computers to generate it. This would make all data protected by current public-key encryption vulnerable to quantum computing attacks. Other encryption techniques like elliptic curve cryptography and symmetric key encryption are also vulnerable to quantum computing.While quantum computing could be a threat to encryption security in the future, quantum computing as it currently stands is still very limited. Quantum computing currently is not commercially available, cannot handle large amounts of code, and only exists as computational devices, not computers. Furthermore, quantum computing advancements will be able to be utilized in favor of encryption as well. The National Security Agency (NSA) is currently preparing post-quantum encryption standards for the future. Quantum encryption promises a level of security that will be able to counter the threat of quantum computing.\n\n== Attacks and countermeasures ==\nEncryption is an important tool but is not sufficient alone to ensure the security or privacy of sensitive information throughout its lifetime. Most applications of encryption protect information only at rest or in transit, leaving sensitive data in clear text and potentially vulnerable to improper disclosure during processing, such as by a cloud service for example. Homomorphic encryption and secure multi-party computation are emerging techniques to compute on encrypted data; these techniques are general and Turing complete but incur high computational and/or communication costs.\nIn response to encryption of data at rest, cyber-adversaries have developed new types of attacks. These more recent threats to encryption of data at rest include cryptographic attacks, stolen ciphertext attacks, attacks on encryption keys, insider attacks, data corruption or integrity attacks, data destruction attacks, and ransomware attacks. Data fragmentation and active defense data protection technologies attempt to counter some of these attacks, by distributing, moving, or mutating ciphertext so it is more difficult to identify, steal, corrupt, or destroy.\n\n== The debate around encryption ==\nThe question of balancing the need for national security with the right to privacy has been debated for years, since encryption has become critical in today's digital society. The modern encryption debate started around the '90 when US government tried to ban cryptography because, according to them, it would threaten national security. The debate is polarized around two opposing views. Those who see strong encryption as a problem making it easier for criminals to hide their illegal acts online and others who argue that encryption keep digital communications safe. The debate heated up in 2014, when Big Tech like Apple and Google set encryption by default in their devices. This was the start of a series of controversies that puts governments, companies and internet users at stake.\n\n\n*** Integrity protection of ciphertexts ***\nEncryption, by itself, can protect the confidentiality of messages, but other techniques are still needed to protect the integrity and authenticity of a message; for example, verification of a message authentication code (MAC) or a digital signature usually done by a hashing algorithm or a PGP signature. Authenticated encryption algorithms are designed to provide both encryption and integrity protection together. Standards for cryptographic software and hardware to perform encryption are widely available, but successfully using encryption to ensure security may be a challenging problem. A single error in system design or execution can allow successful attacks. Sometimes an adversary can obtain unencrypted information without directly undoing the encryption. See for example traffic analysis, TEMPEST, or Trojan horse.Integrity protection mechanisms such as MACs and digital signatures must be applied to the ciphertext when it is first created, typically on the same device used to compose the message, to protect a message end-to-end along its full transmission path; otherwise, any node between the sender and the encryption agent could potentially tamper with it. Encrypting at the time of creation is only secure if the encryption device itself has correct keys and has not been tampered with. If an endpoint device has been configured to trust a root certificate that an attacker controls, for example, then the attacker can both inspect and tamper with encrypted data by performing a man-in-the-middle attack anywhere along the message's path. The common practice of TLS interception by network operators represents a controlled and institutionally sanctioned form of such an attack, but countries have also attempted to employ such attacks as a form of control and censorship.\n\n\n*** Ciphertext length and padding ***\n\nEven when encryption correctly hides a message's content and it cannot be tampered with at rest or in transit, a message's length is a form of metadata that can still leak sensitive information about the message. For example, the well-known CRIME and BREACH attacks against HTTPS were side-channel attacks that relied on information leakage via the length of encrypted content. Traffic analysis is a broad class of techniques that often employs message lengths to infer sensitive implementation about traffic flows by aggregating information about a large number of messages.\nPadding a message's payload before encrypting it can help obscure the cleartext's true length, at the cost of increasing the ciphertext's size and introducing or increasing bandwidth overhead. Messages may be padded randomly or deterministically, with each approach having different tradeoffs. Encrypting and padding messages to form padded uniform random blobs or PURBs is a practice guaranteeing that the cipher text leaks no metadata about its cleartext's content, and leaks asymptotically minimal \n  \n    \n      \n        O\n        (\n        log\n        \u2061\n        log\n        \u2061\n        M\n        )\n      \n    \n    {\\displaystyle O(\\log \\log M)}\n   information via its length.\n\nQ: What are PURBs and how do they guarantee metadata privacy?",
    "context": "",
    "output": "A: PURBs are padded uniform random blobs that encrypt and pad messages to form padded uniform random blobs. This practice guarantees that the ciphertext leaks no metadata about its cleartext's content and leaks asymptotically minimal information via its length.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are PURBs and how do they guarantee metadata privacy?",
      "answer": "PURBs are padded uniform random blobs that encrypt and pad messages to form padded uniform random blobs. This practice guarantees that the ciphertext leaks no metadata about its cleartext's content and leaks asymptotically minimal information via its length.",
      "context": "Encryption\n\n==Introduction==\nIn cryptography, encryption is the process of encoding information. This process converts the original representation of the information, known as plaintext, into an alternative form known as ciphertext. Ideally, only authorized parties can decipher a ciphertext back to plaintext and access the original information. Encryption does not itself prevent interference but denies the intelligible content to a would-be interceptor. \nFor technical reasons, an encryption scheme usually uses a pseudo-random encryption key generated by an algorithm. It is possible to decrypt the message without possessing the key but, for a well-designed encryption scheme, considerable computational resources and skills are required. An authorized recipient can easily decrypt the message with the key provided by the originator to recipients but not to unauthorized users. \nHistorically, various forms of encryption have been used to aid in cryptography. Early encryption techniques were often used in military messaging. Since then, new techniques have emerged and become commonplace in all areas of modern computing. Modern encryption schemes use the concepts of public-key and symmetric-key. Modern encryption techniques ensure security because modern computers are inefficient at cracking the encryption.\n\n\n\n== Encryption in cryptography ==\nIn the context of cryptography, encryption serves as a mechanism to ensure confidentiality. Since data may be visible on the Internet, sensitive information such as passwords and personal communication may be exposed to potential interceptors. The process of encrypting and decrypting messages involves keys. The two main types of keys in cryptographic systems are symmetric-key and public-key (also known as asymmetric-key).Many complex cryptographic algorithms often use simple modular arithmetic in their implementations.\n\n\n*** Types ***\nIn symmetric-key schemes, the encryption and decryption keys are the same. Communicating parties must have the same key in order to achieve secure communication. The German Enigma Machine utilized a new symmetric-key each day for encoding and decoding messages.\nIn public-key encryption schemes, the encryption key is published for anyone to use and encrypt messages. However, only the receiving party has access to the decryption key that enables messages to be read. Public-key encryption was first described in a secret document in 1973; beforehand, all encryption schemes were symmetric-key (also called private-key).:\u200a478\u200a Although published subsequently, the work of Diffie and Hellman was published in a journal with a large readership, and the value of the methodology was explicitly described. The method became known as the Diffie-Hellman key exchange.\nRSA (Rivest\u2013Shamir\u2013Adleman) is another notable public-key cryptosystem. Created in 1978, it is still used today for applications involving digital signatures. Using number theory, the RSA algorithm selects two prime numbers, which help generate both the encryption and decryption keys.A publicly available public-key encryption application called Pretty Good Privacy (PGP) was written in 1991 by Phil Zimmermann, and distributed free of charge with source code. PGP was purchased by Symantec in 2010 and is regularly updated.\n\n== Uses ==\nEncryption has long been used by militaries and governments to facilitate secret communication. It is now commonly used in protecting information within many kinds of civilian systems. For example, the Computer Security Institute reported that in 2007, 71% of companies surveyed utilized encryption for some of their data in transit, and 53% utilized encryption for some of their data in storage. Encryption can be used to protect data \"at rest\", such as information stored on computers and storage devices (e.g. USB flash drives). In recent years, there have been numerous reports of confidential data, such as customers' personal records, being exposed through loss or theft of laptops or backup drives; encrypting such files at rest helps protect them if physical security measures fail. Digital rights management systems, which prevent unauthorized use or reproduction of copyrighted material and protect software against reverse engineering (see also copy protection), is another somewhat different example of using encryption on data at rest.Encryption is also used to protect data in transit, for example data being transferred via networks (e.g. the Internet, e-commerce), mobile telephones, wireless microphones, wireless intercom systems, Bluetooth devices and bank automatic teller machines. There have been numerous reports of data in transit being intercepted in recent years. Data should also be encrypted when transmitted across networks in order to protect against eavesdropping of network traffic by unauthorized users.\n\n\n*** Data erasure ***\n\nConventional methods for permanently deleting data from a storage device involve overwriting the device's whole content with zeros, ones, or other patterns \u2013 a process which can take a significant amount of time, depending on the capacity and the type of storage medium. Cryptography offers a way of making the erasure almost instantaneous. This method is called crypto-shredding. An example implementation of this method can be found on iOS devices, where the cryptographic key is kept in a dedicated 'effaceable storage'. Because the key is stored on the same device, this setup on its own does not offer full privacy or security protection if an unauthorized person gains physical access to the device.\n\n== Limitations ==\nEncryption is used in the 21st century to protect digital data and information systems. As computing power increased over the years, encryption technology has only become more advanced and secure. However, this advancement in technology has also exposed a potential limitation of today's encryption methods.\nThe length of the encryption key is an indicator of the strength of the encryption method. For example, the original encryption key, DES (Data Encryption Standard), was 56 bits, meaning it had 2^56 combination possibilities. With today's computing power, a 56-bit key is no longer secure, being vulnerable to hacking by brute force attack.Quantum computing utilizes properties of quantum mechanics in order to process large amounts of data simultaneously. Quantum computing has been found to achieve computing speeds thousands of times faster than today's supercomputers. This computing power presents a challenge to today's encryption technology. For example, RSA encryption utilizes the multiplication of very large prime numbers to create a semiprime number for its public key. Decoding this key without its private key requires this semiprime number to be factored, which can take a very long time to do with modern computers. It would take a supercomputer anywhere between weeks to months to factor in this key. However, quantum computing can use quantum algorithms to factor this semiprime number in the same amount of time it takes for normal computers to generate it. This would make all data protected by current public-key encryption vulnerable to quantum computing attacks. Other encryption techniques like elliptic curve cryptography and symmetric key encryption are also vulnerable to quantum computing.While quantum computing could be a threat to encryption security in the future, quantum computing as it currently stands is still very limited. Quantum computing currently is not commercially available, cannot handle large amounts of code, and only exists as computational devices, not computers. Furthermore, quantum computing advancements will be able to be utilized in favor of encryption as well. The National Security Agency (NSA) is currently preparing post-quantum encryption standards for the future. Quantum encryption promises a level of security that will be able to counter the threat of quantum computing.\n\n== Attacks and countermeasures ==\nEncryption is an important tool but is not sufficient alone to ensure the security or privacy of sensitive information throughout its lifetime. Most applications of encryption protect information only at rest or in transit, leaving sensitive data in clear text and potentially vulnerable to improper disclosure during processing, such as by a cloud service for example. Homomorphic encryption and secure multi-party computation are emerging techniques to compute on encrypted data; these techniques are general and Turing complete but incur high computational and/or communication costs.\nIn response to encryption of data at rest, cyber-adversaries have developed new types of attacks. These more recent threats to encryption of data at rest include cryptographic attacks, stolen ciphertext attacks, attacks on encryption keys, insider attacks, data corruption or integrity attacks, data destruction attacks, and ransomware attacks. Data fragmentation and active defense data protection technologies attempt to counter some of these attacks, by distributing, moving, or mutating ciphertext so it is more difficult to identify, steal, corrupt, or destroy.\n\n== The debate around encryption ==\nThe question of balancing the need for national security with the right to privacy has been debated for years, since encryption has become critical in today's digital society. The modern encryption debate started around the '90 when US government tried to ban cryptography because, according to them, it would threaten national security. The debate is polarized around two opposing views. Those who see strong encryption as a problem making it easier for criminals to hide their illegal acts online and others who argue that encryption keep digital communications safe. The debate heated up in 2014, when Big Tech like Apple and Google set encryption by default in their devices. This was the start of a series of controversies that puts governments, companies and internet users at stake.\n\n\n*** Integrity protection of ciphertexts ***\nEncryption, by itself, can protect the confidentiality of messages, but other techniques are still needed to protect the integrity and authenticity of a message; for example, verification of a message authentication code (MAC) or a digital signature usually done by a hashing algorithm or a PGP signature. Authenticated encryption algorithms are designed to provide both encryption and integrity protection together. Standards for cryptographic software and hardware to perform encryption are widely available, but successfully using encryption to ensure security may be a challenging problem. A single error in system design or execution can allow successful attacks. Sometimes an adversary can obtain unencrypted information without directly undoing the encryption. See for example traffic analysis, TEMPEST, or Trojan horse.Integrity protection mechanisms such as MACs and digital signatures must be applied to the ciphertext when it is first created, typically on the same device used to compose the message, to protect a message end-to-end along its full transmission path; otherwise, any node between the sender and the encryption agent could potentially tamper with it. Encrypting at the time of creation is only secure if the encryption device itself has correct keys and has not been tampered with. If an endpoint device has been configured to trust a root certificate that an attacker controls, for example, then the attacker can both inspect and tamper with encrypted data by performing a man-in-the-middle attack anywhere along the message's path. The common practice of TLS interception by network operators represents a controlled and institutionally sanctioned form of such an attack, but countries have also attempted to employ such attacks as a form of control and censorship.\n\n\n*** Ciphertext length and padding ***\n\nEven when encryption correctly hides a message's content and it cannot be tampered with at rest or in transit, a message's length is a form of metadata that can still leak sensitive information about the message. For example, the well-known CRIME and BREACH attacks against HTTPS were side-channel attacks that relied on information leakage via the length of encrypted content. Traffic analysis is a broad class of techniques that often employs message lengths to infer sensitive implementation about traffic flows by aggregating information about a large number of messages.\nPadding a message's payload before encrypting it can help obscure the cleartext's true length, at the cost of increasing the ciphertext's size and introducing or increasing bandwidth overhead. Messages may be padded randomly or deterministically, with each approach having different tradeoffs. Encrypting and padding messages to form padded uniform random blobs or PURBs is a practice guaranteeing that the cipher text leaks no metadata about its cleartext's content, and leaks asymptotically minimal \n  \n    \n      \n        O\n        (\n        log\n        \u2061\n        log\n        \u2061\n        M\n        )\n      \n    \n    {\\displaystyle O(\\log \\log M)}\n   information via its length."
    }
  },
  {
    "instruction": "Automated information systems security\n\n==Introduction==\nIn telecommunication, automated information systems security comprises measures and controls that ensure confidentiality, integrity, and availability of the information processed and stored by automated information systems. The unauthorized disclosure, modification, or destruction may be accidental or intentional.\nAutomated information systems security includes consideration of all computer hardware and software functions, characteristics and features; operational procedures; accountability procedures; and access controls at the central computer facility, remote computer, and terminal facilities; management constraints; physical structures and devices, such as computers, transmission lines, and power sources; and personnel and communications controls needed to provide an acceptable level of risk for the automated information system and for the data and information contained in the system. Automated information systems security also includes the totality of security safeguards needed to provide an acceptable protection level for an automated information system and for the data handled by an automated information system.\nIn information security, automated information systems security is a synonym for computer security.\n\n\n\nBased on the above text, answer a question. How does the concept of automated information systems security relate to the protection of information in computer hardware and software functions, operational procedures, and physical structures?",
    "context": "",
    "output": "Automated information systems security encompasses the protection of information in various aspects of computer systems, including hardware and software functions, operational procedures, and physical structures. This protection is crucial to ensure the confidentiality, integrity, and availability of the information processed and stored by automated information systems. By considering all these elements together, automated information systems security provides a comprehensive approach to securing computer systems and the data they handle.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the concept of automated information systems security relate to the protection of information in computer hardware and software functions, operational procedures, and physical structures?",
      "answer": "Automated information systems security encompasses the protection of information in various aspects of computer systems, including hardware and software functions, operational procedures, and physical structures. This protection is crucial to ensure the confidentiality, integrity, and availability of the information processed and stored by automated information systems. By considering all these elements together, automated information systems security provides a comprehensive approach to securing computer systems and the data they handle.",
      "context": "Automated information systems security\n\n==Introduction==\nIn telecommunication, automated information systems security comprises measures and controls that ensure confidentiality, integrity, and availability of the information processed and stored by automated information systems. The unauthorized disclosure, modification, or destruction may be accidental or intentional.\nAutomated information systems security includes consideration of all computer hardware and software functions, characteristics and features; operational procedures; accountability procedures; and access controls at the central computer facility, remote computer, and terminal facilities; management constraints; physical structures and devices, such as computers, transmission lines, and power sources; and personnel and communications controls needed to provide an acceptable level of risk for the automated information system and for the data and information contained in the system. Automated information systems security also includes the totality of security safeguards needed to provide an acceptable protection level for an automated information system and for the data handled by an automated information system.\nIn information security, automated information systems security is a synonym for computer security.\n\n"
    }
  },
  {
    "instruction": "Session poisoning\n\n==Introduction==\nSession poisoning (also referred to as \"session data pollution\" and \"session modification\") is a method to exploit insufficient input validation within a server application. Typically a server application that is vulnerable to this type of exploit will copy user input into session variables.\nThe underlying vulnerability is a state management problem: shared state, race condition, ambiguity in use or plain unprotected modifications of state values.\nSession poisoning has been demonstrated in server environments where different, non-malicious applications (scripts) share the same session states but where usage differ, causing ambiguity and race conditions.\nSession poisoning has been demonstrated in scenarios where attacker is able to introduce malicious scripts into the server environment, which is possible if attacker and victim share a web host.\n\n== Origins ==\nSession poisoning was first discussed as a (potentially new) vulnerability class in the Full disclosure mailing list.  Alla Bezroutchko inquired if \"Session data pollution vulnerabilities in web applications\" was a new problem in January 2006. However, this was an old vulnerability previously noted by others: \"this is a classic state management issue\" - Yvan Boily; \"This is not new\" - /someone.Earlier examples of these vulnerabilities can be found in major security resources/archives such as Bugtraq, e.g.\n\nJuly 2001, Serious security hole in Mambo Site Server version 3.0.X by Ismael Peinado Palomo of reverseonline.com\nSeptember 2005, PHP Session modification by unknown (from uw-team) and adam_iSession pollution has also been covered in some articles, such as PHP Session Security, Przemek Sobstel, 2007.\n\n== Attack examples ==\n\n\n*** Trivial attack scenario ***\nAn example code vulnerable to this problem is:\n\nSession(\"Login\")\n\nBased on the above text, answer a question. Why is input validation important in preventing session poisoning?",
    "context": "",
    "output": "Input validation is important in preventing session poisoning because it helps ensure that only legitimate and authorized inputs are copied into session variables, reducing the risk of exploitation.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Why is input validation important in preventing session poisoning?",
      "answer": "Input validation is important in preventing session poisoning because it helps ensure that only legitimate and authorized inputs are copied into session variables, reducing the risk of exploitation.",
      "context": "Session poisoning\n\n==Introduction==\nSession poisoning (also referred to as \"session data pollution\" and \"session modification\") is a method to exploit insufficient input validation within a server application. Typically a server application that is vulnerable to this type of exploit will copy user input into session variables.\nThe underlying vulnerability is a state management problem: shared state, race condition, ambiguity in use or plain unprotected modifications of state values.\nSession poisoning has been demonstrated in server environments where different, non-malicious applications (scripts) share the same session states but where usage differ, causing ambiguity and race conditions.\nSession poisoning has been demonstrated in scenarios where attacker is able to introduce malicious scripts into the server environment, which is possible if attacker and victim share a web host.\n\n== Origins ==\nSession poisoning was first discussed as a (potentially new) vulnerability class in the Full disclosure mailing list.  Alla Bezroutchko inquired if \"Session data pollution vulnerabilities in web applications\" was a new problem in January 2006. However, this was an old vulnerability previously noted by others: \"this is a classic state management issue\" - Yvan Boily; \"This is not new\" - /someone.Earlier examples of these vulnerabilities can be found in major security resources/archives such as Bugtraq, e.g.\n\nJuly 2001, Serious security hole in Mambo Site Server version 3.0.X by Ismael Peinado Palomo of reverseonline.com\nSeptember 2005, PHP Session modification by unknown (from uw-team) and adam_iSession pollution has also been covered in some articles, such as PHP Session Security, Przemek Sobstel, 2007.\n\n== Attack examples ==\n\n\n*** Trivial attack scenario ***\nAn example code vulnerable to this problem is:\n\nSession(\"Login\")"
    }
  },
  {
    "instruction": "Zombie Zero\n\n==Introduction==\nZombie Zero is an attack vector where a cyber attacker utilized malware that was clandestinely embedded in new barcode readers which were manufactured overseas.  \nIt remains unknown if this attack was promulgated by organized crime or a nation state. Clearly there was significant planning and investment in order to design the malware, and then embed it into the hardware within the barcode scanner. Internet of things (IoT) devices may be similarly preinstalled with malware that can capture the network passwords and then open a backdoor to attackers. Given the high volume of these devices manufactured overseas high caution is to be exercised before placing these devices on corporate or government networks.\n\n\n\n== Detailed data on the attack ==\nA malware embedded scanner was installed on a wireless network.  An attack against the internal network initiated automatically using a server message block protocol. \nThe stolen data which was scanned included every piece of information about the item, destination address, source and more.  This was sent clandestinely to a command and control connection back to a botnet in China.  This botnet connected to the Lanxiang Vocational School located in the China Unicom network for Shandong province. This school in China has been connected to previous attacks, including Google and the Operation Aurora attack. The manufacturer of the scanner was located just a few blocks away from the school.\nThe botnet then downloaded a second payload that broadened the command and control which now extended to the target company's corporate servers in finance. The attackers were looking for logistics data on all shipping on a worldwide basis, and the attackers had succeeded in obtaining detailed financial data on all customers and shipments.\n\n== Detection ==\nZombie Zero can be detected using deception technology.\n\nBased on the above text, answer a question. What type of technology can be used to detect Zombie Zero?",
    "context": "",
    "output": "Deception technology can be used to detect Zombie Zero.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What type of technology can be used to detect Zombie Zero?",
      "answer": "Deception technology can be used to detect Zombie Zero.",
      "context": "Zombie Zero\n\n==Introduction==\nZombie Zero is an attack vector where a cyber attacker utilized malware that was clandestinely embedded in new barcode readers which were manufactured overseas.  \nIt remains unknown if this attack was promulgated by organized crime or a nation state. Clearly there was significant planning and investment in order to design the malware, and then embed it into the hardware within the barcode scanner. Internet of things (IoT) devices may be similarly preinstalled with malware that can capture the network passwords and then open a backdoor to attackers. Given the high volume of these devices manufactured overseas high caution is to be exercised before placing these devices on corporate or government networks.\n\n\n\n== Detailed data on the attack ==\nA malware embedded scanner was installed on a wireless network.  An attack against the internal network initiated automatically using a server message block protocol. \nThe stolen data which was scanned included every piece of information about the item, destination address, source and more.  This was sent clandestinely to a command and control connection back to a botnet in China.  This botnet connected to the Lanxiang Vocational School located in the China Unicom network for Shandong province. This school in China has been connected to previous attacks, including Google and the Operation Aurora attack. The manufacturer of the scanner was located just a few blocks away from the school.\nThe botnet then downloaded a second payload that broadened the command and control which now extended to the target company's corporate servers in finance. The attackers were looking for logistics data on all shipping on a worldwide basis, and the attackers had succeeded in obtaining detailed financial data on all customers and shipments.\n\n== Detection ==\nZombie Zero can be detected using deception technology."
    }
  },
  {
    "instruction": "Write an answer to the following question: What was the response to the report released by the President's Commission on Enhancing National Cybersecurity?",
    "context": "",
    "output": "Some criticized the commission's work as lacking an understanding of cybersecurity and not being cognizant of \"cyber reality\" and the cost of some of the action items. However, others found the report constructive and meaningful.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was the response to the report released by the President's Commission on Enhancing National Cybersecurity?",
      "answer": "Some criticized the commission's work as lacking an understanding of cybersecurity and not being cognizant of \"cyber reality\" and the cost of some of the action items. However, others found the report constructive and meaningful."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the watermarking attack differ from the use of block ciphers in electronic codebook (ECB) mode?",
    "context": "",
    "output": "The watermarking attack is similar to the use of block ciphers in electronic codebook (ECB) mode, but instead of whole blocks, only the first block in different sectors are identical. In ECB mode, identical plaintext blocks result in identical ciphertext blocks, making it vulnerable to pattern detection. Similarly, in a watermarking attack, the use of predictable IVs results in identical ciphertext blocks, allowing an attacker to detect the presence of encrypted data.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the watermarking attack differ from the use of block ciphers in electronic codebook (ECB) mode?",
      "answer": "The watermarking attack is similar to the use of block ciphers in electronic codebook (ECB) mode, but instead of whole blocks, only the first block in different sectors are identical. In ECB mode, identical plaintext blocks result in identical ciphertext blocks, making it vulnerable to pattern detection. Similarly, in a watermarking attack, the use of predictable IVs results in identical ciphertext blocks, allowing an attacker to detect the presence of encrypted data."
    }
  },
  {
    "instruction": "Write an answer to the following question: What charge did ESET release a public tool to decrypt affected computers after TeslaCrypt was shut down?",
    "context": "",
    "output": "After TeslaCrypt was shut down, ESET released a public tool to decrypt affected computers at no charge.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What charge did ESET release a public tool to decrypt affected computers after TeslaCrypt was shut down?",
      "answer": "After TeslaCrypt was shut down, ESET released a public tool to decrypt affected computers at no charge."
    }
  },
  {
    "instruction": "Espionage\n\n==Introduction==\nEspionage, spying, or intelligence gathering is the act of obtaining secret or confidential information (intelligence). A person who commits espionage is called an espionage agent or spy. Any individual or spy ring (a cooperating group of spies), in the service of a government, company, criminal organization, or independent operation, can commit espionage. The practice is clandestine, as it is by definition unwelcome. In some circumstances, it may be a legal tool of law enforcement and in others, it may be illegal and punishable by law.\nEspionage is often part of an institutional effort by a government or commercial concern. However, the term tends to be associated with state spying on potential or actual enemies for military purposes. Spying involving corporations is known as industrial espionage.\nOne way to gather data and information about a targeted organization is by infiltrating its ranks. Spies can then return information such as the size and strength of enemy forces. They can also find dissidents within the organization and influence them to provide further information or to defect. In times of crisis, spies steal technology and sabotage the enemy in various ways. Counterintelligence is the practice of thwarting enemy espionage and intelligence-gathering. Almost all sovereign states have strict laws concerning espionage, including those who practice espionage in other countries, and the penalties for being caught are often severe.\n\n\n\n== Today ==\nToday, spy agencies target the illegal drug trade and terrorists as well as state actors. Between 2008 and 2011, the United States charged at least 57 defendants for attempting to spy for China.Intelligence services value certain intelligence collection techniques over others. The former Soviet Union, for example, preferred human sources over research in open sources, while the United States has tended to emphasize technological methods such as SIGINT and IMINT. In the Soviet Union, both political (KGB) and military intelligence (GRU) officers were judged by the number of agents they recruited.\n\n== Targets of espionage ==\nEspionage agents are usually trained experts in a targeted field so they can differentiate mundane information from targets of value to their own organizational development. Correct identification of the target at its execution is the sole purpose of the espionage operation.Broad areas of espionage targeting expertise include:\nNatural resources: strategic production identification and assessment (food, energy, materials). Agents are usually found among bureaucrats who administer these resources in their own countries\nPopular sentiment towards domestic and foreign policies (popular, middle class, elites). Agents often recruited from field journalistic crews, exchange postgraduate students and sociology researchers\nStrategic economic strengths (production, research, manufacture, infrastructure). Agents recruited from science and technology academia, commercial enterprises, and more rarely from among military technologists\nMilitary capability intelligence (offensive, defensive, manoeuvre, naval, air, space). Agents are trained by military espionage education facilities and posted to an area of operation with covert identities to minimize prosecution\nCounterintelligence operations targeting opponents' intelligence services themselves, such as breaching the confidentiality of communications, and recruiting defectors or moles\n\n== Methods and terminology ==\nAlthough the news media may speak of \"spy satellites\" and the like, espionage is not a synonym for all intelligence-gathering disciplines. It is a specific form of human source intelligence (HUMINT). Codebreaking (cryptanalysis or COMINT), aircraft or satellite photography (IMINT), and analysis of publicly available data sources (OSINT) are all intelligence gathering disciplines, but none of them is considered espionage. Many HUMINT activities, such as prisoner interrogation, reports from military reconnaissance patrols and from diplomats, etc., are not considered espionage.  Espionage is the disclosure of sensitive information (classified) to people who are not cleared for that information or access to that sensitive information.\nUnlike other forms of intelligence collection disciplines, espionage usually involves accessing the place where the desired information is stored or accessing the people who know the information and will divulge it through some kind of subterfuge. There are exceptions to physical meetings, such as the Oslo Report, or the insistence of Robert Hanssen in never meeting the people who bought his information.\n\nThe US defines espionage towards itself as \"the act of obtaining, delivering, transmitting, communicating, or receiving information about the national defence with an intent, or reason to believe, that the information may be used to the injury of the United States or to the advantage of any foreign nation\". Black's Law Dictionary (1990) defines espionage as: \"... gathering, transmitting, or losing ... information related to the national defense\". Espionage is a violation of United States law, 18 U.S.C. \u00a7\u00a7 792\u2013798 and Article 106a of the Uniform Code of Military Justice. The United States, like most nations, conducts espionage against other nations, under the control of the National Clandestine Service. Britain's espionage activities are controlled by the Secret Intelligence Service.\n\n\n*** Technology and techniques ***\n\nSource:\n\n== Organization ==\n\nA spy is a person employed to seek out top secret information from a source. Within the United States Intelligence Community, \"asset\" is more common usage. A case officer or Special Agent, who may have diplomatic status (i.e., official cover or non-official cover), supports and directs the human collector. Cut-outs are couriers who do not know the agent or case officer but transfer messages. A safe house is a refuge for spies. Spies often seek to obtain secret information from another source.\nIn larger networks, the organization can be complex with many methods to avoid detection, including clandestine cell systems.  Often the players have never met. Case officers are stationed in foreign countries to recruit and supervise intelligence agents, who in turn spy on targets in the countries where they are assigned. A spy need not be a citizen of the target country and hence does not automatically commit treason when operating within it. While the more common practice is to recruit a person already trusted with access to sensitive information, sometimes a person with a well-prepared synthetic identity (cover background), called a legend in tradecraft, may attempt to infiltrate a target organization.\nThese agents can be moles (who are recruited before they get access to secrets), defectors (who are recruited after they get access to secrets and leave their country) or defectors in place (who get access but do not leave).\nA legend is also employed for an individual who is not an illegal agent, but is an ordinary citizen who is \"relocated\", for example, a \"protected witness\". Nevertheless, such a non-agent very likely will also have a case officer who will act as a controller. As in most, if not all synthetic identity schemes, for whatever purpose (illegal or legal), the assistance of a controller is required.\nSpies may also be used to spread disinformation in the organization in which they are planted, such as giving false reports about their country's military movements, or about a competing company's ability to bring a product to market. Spies may be given other roles that also require infiltration, such as sabotage.\nMany governments spy on their allies as well as their enemies, although they typically maintain a policy of not commenting on this. Governments also employ private companies to collect information on their behalf such as SCG International Risk, International Intelligence Limited and others.\nMany organizations, both national and non-national, conduct espionage operations. It should not be assumed that espionage is always directed at the most secret operations of a target country.  National and terrorist organizations and other groups are also targeted. This is because governments want to retrieve information that they can use to be proactive in protecting their nation from potential terrorist attacks.\nCommunications both are necessary to espionage and clandestine operations, and also a great vulnerability when the adversary has sophisticated SIGINT detection and interception capability. Spies rely on COVCOM or covert communication through technically advanced spy devices. Agents must also transfer money securely.\n\n== Industrial espionage ==\n\nReportedly Canada is losing $12 billion and German companies are estimated to be losing about \u20ac50 billion ($87 billion) and 30,000 jobs to industrial espionage every year.\n\n== Agents in espionage ==\nIn espionage jargon, an \"agent\" is the person who does the spying.  They may be a citizen of a country recruited by that country to spy on another; a citizen of a country recruited by that country to carry out false flag assignments disrupting his own country; a citizen of one country who is recruited by a second country to spy on or work against his own country or a third country, and more.\nIn popular usage, this term is sometimes confused with an intelligence officer, intelligence operative, or case officer who recruits and handles agents.\nAmong the most common forms of agent are:\n\nAgent provocateur: instigates trouble or provides information to gather as many people as possible into one location for an arrest.\nIntelligence agent: provides access to sensitive information through the use of special privileges. If used in corporate intelligence gathering, this may include gathering information of a corporate business venture or stock portfolio. In economic intelligence, \"Economic Analysts may use their specialized skills to analyze and interpret economic trends and developments, assess and track foreign financial activities, and develop new econometric and modelling methodologies.\" This may also include information of trade or tariff.\nAgent-of-influence: provides political influence in an area of interest, possibly including publications needed to further an intelligence service agenda. The use of the media to print a story to mislead a foreign service into action, exposing their operations while under surveillance.\nDouble agent: engages in clandestine activity for two intelligence or security services (or more in joint operations), who provides information about one or about each to the other, and who wittingly withholds significant information from one on the instructions of the other or is unwittingly manipulated by one so that significant facts are withheld from the adversary. Peddlers, fabricators, and others who work for themselves rather than a service are not double agents because they are not agents. The fact that double agents have an agent relationship with both sides distinguishes them from penetrations, who normally are placed with the target service in a staff or officer capacity.\"Redoubled agent: forced to mislead the foreign intelligence service after being caught as a double agent.\nUnwitting double agent: offers or is forced to recruit as a double or redoubled agent and in the process is recruited by either a third-party intelligence service or his own government without the knowledge of the intended target intelligence service or the agent. This can be useful in capturing important information from an agent that is attempting to seek allegiance with another country. The double agent usually has knowledge of both intelligence services and can identify operational techniques of both, thus making third-party recruitment difficult or impossible. The knowledge of operational techniques can also affect the relationship between the operations officer (or case officer) and the agent if the case is transferred by an operational targeting officer] to a new operations officer, leaving the new officer vulnerable to attack. This type of transfer may occur when an officer has completed his term of service or when his cover is blown.\nSleeper agent: recruited to wake up and perform a specific set of tasks or functions while living undercover in an area of interest. This type of agent is not the same as a deep cover operative, who continually contacts a case officer to file intelligence reports. A sleeper agent is not in contact with anyone until activated.\nTriple agent: works for three intelligence services.Less common or lesser known forms of agent include:\n\nAccess agent: provides access to other potential agents by providing offender profiling information that can help lead to recruitment into an intelligence service.\nConfusion agent: provides misleading information to an enemy intelligence service or attempts to discredit the operations of the target in an operation.\nFacilities agent: provides access to buildings, such as garages or offices used for staging operations, resupply, etc.\nIllegal agent: lives in another country under false credentials and does not report to a local station. A nonofficial cover operative can be dubbed an \"illegal\" when working in another country without diplomatic protection.\nPrincipal agent: functions as a handler for an established network of agents, usually considered \"blue chip\".\n\n== Law ==\nEspionage against a nation is a crime under the legal code of many nations. In the United States, it is covered by the Espionage Act of 1917. The risks of espionage vary. A spy violating the host country's laws may be deported, imprisoned, or even executed. A spy violating its own country's laws can be imprisoned for espionage or/and treason (which in the United States and some other jurisdictions can only occur if they take up arms or aids the enemy against their own country during wartime), or even executed, as the Rosenbergs were. For example, when Aldrich Ames handed a stack of dossiers of U.S. Central Intelligence Agency (CIA) agents in the Eastern Bloc to his KGB-officer \"handler\", the KGB \"rolled up\" several networks, and at least ten people were secretly shot. When Ames was arrested by the U.S. Federal Bureau of Investigation (FBI), he faced life in prison; his contact, who had diplomatic immunity, was declared persona non grata and taken to the airport. Ames' wife was threatened with life imprisonment if her husband did not cooperate; he did, and she was given a five-year sentence. Hugh Francis Redmond, a CIA officer in China, spent nineteen years in a Chinese prison for espionage\u2014and died there\u2014as he was operating without diplomatic cover and immunity.In United States law, treason, espionage, and spying are separate crimes.  Treason and espionage have graduated punishment levels.\nThe United States in World War I passed the Espionage Act of 1917. Over the years, many spies, such as the Soble spy ring, Robert Lee Johnson, the Rosenberg ring, Aldrich Hazen Ames, Robert Philip Hanssen, Jonathan Pollard, John Anthony Walker, James Hall III, and others have been prosecuted under this law.\n\n\n*** History of espionage laws ***\nFrom ancient times, the penalty for espionage in many countries was execution. This was true right up until the era of World War II; for example, Josef Jakobs was a Nazi spy who parachuted into Great Britain in 1941 and was executed for espionage.\nIn modern times, many people convicted of espionage have been given penal sentences rather than execution. For example, Aldrich Hazen Ames is an American CIA analyst, turned KGB mole, who was convicted of espionage in 1994; he is serving a life sentence without the possibility of parole in the high-security Allenwood U.S. Penitentiary. Ames was formerly a 31-year CIA counterintelligence officer and analyst who committed espionage against his country by spying for the Soviet Union and Russia. So far as it is known, Ames compromised the second-largest number of CIA agents, second only to Robert Hanssen, who is also serving a prison sentence.\n\n\n*** Use against non-spies ***\nEspionage laws are also used to prosecute non-spies. In the United States, the Espionage Act of 1917 was used against socialist politician Eugene V. Debs (at that time the Act had much stricter guidelines and amongst other things banned speech against military recruiting). The law was later used to suppress publication of periodicals, for example of Father Coughlin in World War II. In the early 21st century, the act was used to prosecute whistleblowers such as Thomas Andrews Drake, John Kiriakou, and Edward Snowden, as well as officials who communicated with journalists for innocuous reasons, such as Stephen Jin-Woo Kim.As of 2012, India and Pakistan were holding several hundred prisoners of each other's country for minor violations like trespass or visa overstay, often with accusations of espionage attached. Some of these include cases where Pakistan and India both deny citizenship to these people, leaving them stateless. The BBC reported in 2012 on one such case, that of Mohammed Idrees, who was held under Indian police control for approximately 13 years for overstaying his 15-day visa by 2\u20133 days after seeing his ill parents in 1999. Much of the 13 years were spent in prison waiting for a hearing, and more time was spent homeless or living with generous families. The Indian People's Union for Civil Liberties and Human Rights Law Network both decried his treatment. The BBC attributed some of the problems to tensions caused by the Kashmir conflict.\n\n\n*** Espionage laws in the UK ***\nEspionage is illegal in the UK under the Official Secrets Acts of 1911 and 1920. The UK law under this legislation considers espionage as \"concerning those who intend to help an enemy and deliberately harm the security of the nation\". According to MI5, a person commits the offence of 'spying' if they, \"for any purpose prejudicial to the safety or interests of the State\": approaches, enters or inspects a prohibited area; makes documents such as plans that are intended, calculated, or could directly or indirectly be of use to an enemy; or \"obtains, collects, records, or publishes, or communicates to any other person any secret official code word, or password, or any sketch, plan, model, article, or note, or other document which is calculated to be or might be or is intended to be directly or indirectly useful to an enemy\". The illegality of espionage also includes any action which may be considered 'preparatory to' spying, or encouraging or aiding another to spy.Under the penal codes of the UK, those found guilty of espionage are liable to imprisonment for a term of up to 14 years, although multiple sentences can be issued.\n\n\n**** Government intelligence laws and its distinction from espionage ****\nGovernment intelligence is very much distinct from espionage, and is not illegal in the UK, providing that the organisations of individuals are registered, often with the ICO, and are acting within the restrictions of the Regulation of Investigatory Powers Act (RIPA). 'Intelligence' is considered legally as \"information of all sorts gathered by a government or organisation to guide its decisions. It includes information that may be both public and private, obtained from much different public or secret sources. It could consist entirely of information from either publicly available or secret sources, or be a combination of the two.\"However, espionage and intelligence can be linked. According to the MI5 website, \"foreign intelligence officers acting in the UK under diplomatic cover may enjoy immunity from prosecution. Such persons can only be tried for spying (or, indeed, any criminal offence) if diplomatic immunity is waived beforehand. Those officers operating without diplomatic cover have no such immunity from prosecution\".\nThere are also laws surrounding government and organisational intelligence and surveillance. Generally, the body involved should be issued with some form of warrant or permission from the government and should be enacting their procedures in the interest of protecting national security or the safety of public citizens. Those carrying out intelligence missions should act within not only RIPA but also the Data Protection Act and Human Rights Act. However, there are spy equipment laws and legal requirements around intelligence methods that vary for each form of intelligence enacted.\n\n\n*** War ***\n\nIn war, espionage is considered permissible as many nations recognize the inevitability of opposing sides seeking intelligence each about the dispositions of the other. To make the mission easier and successful, combatants wear disguises to conceal their true identity from the enemy while penetrating enemy lines for intelligence gathering. However, if they are caught behind enemy lines in disguises, they are not entitled to prisoner-of-war status and subject to prosecution and punishment\u2014including execution.\nThe Hague Convention of 1907 addresses the status of wartime spies, specifically within \"Laws and Customs of War on Land\" (Hague IV); October 18, 1907: CHAPTER II Spies\". Article 29 states that a person is considered a spy who, acts clandestinely or on false pretences, infiltrates enemy lines with the intention of acquiring intelligence about the enemy and communicate it to the belligerent during times of war. Soldiers who penetrate enemy lines in proper uniforms for the purpose of acquiring intelligence are not considered spies but are lawful combatants entitled to be treated as prisoners of war upon capture by the enemy. Article 30 states that a spy captured behind enemy lines may only be punished following a trial. However, Article 31 provides that if a spy successfully rejoined his own military and is then captured by the enemy as a lawful combatant, he cannot be punished for his previous acts of espionage and must be treated as a prisoner of war. Note that this provision does not apply to citizens who committed treason against their own country or co-belligerents of that country and may be captured and prosecuted at any place or any time regardless whether he rejoined the military to which he belongs or not or during or after the war.The ones that are excluded from being treated as spies while behind enemy lines are escaping prisoners of war and downed airmen as international law distinguishes between a disguised spy and a disguised escaper. It is permissible for these groups to wear enemy uniforms or civilian clothes in order to facilitate their escape back to friendly lines so long as they do not attack enemy forces, collect military intelligence, or engage in similar military operations while so disguised. Soldiers who are wearing enemy uniforms or civilian clothes simply for the sake of warmth along with other purposes rather than engaging in espionage or similar military operations while so attired are also excluded from being treated as unlawful combatants.Saboteurs are treated as spies as they too wear disguises behind enemy lines for the purpose of waging destruction on an enemy's vital targets in addition to intelligence gathering. For example, during World War II, eight German agents entered the U.S. in June 1942 as part of Operation Pastorius, a sabotage mission against U.S. economic targets. Two weeks later, all were arrested in civilian clothes by the FBI thanks to two German agents betraying the mission to the U.S. Under the Hague Convention of 1907, these Germans were classified as spies and tried by a military tribunal in Washington D.C. On August 3, 1942, all eight were found guilty and sentenced to death. Five days later, six were executed by electric chair at the District of Columbia jail. Two who had given evidence against the others had their sentences reduced by President Franklin D. Roosevelt to prison terms. In 1948, they were released by President Harry S. Truman and deported to the American Zone of occupied Germany.\nThe U.S. codification of enemy spies is Article 106 of the Uniform Code of Military Justice. This provides a mandatory death sentence if a person captured in the act is proven to be \"lurking as a spy or acting as a spy in or about any place, vessel, or aircraft, within the control or jurisdiction of any of the armed forces, or in or about any shipyard, any manufacturing or industrial plant, or any other place or institution engaged in work in aid of the prosecution of the war by the United States, or elsewhere\".\n\n== Spy fiction ==\n\nSpies have long been favorite topics for novelists and filmmakers.  An early example of espionage literature is Kim by the English novelist Rudyard Kipling, with a description of the training of an intelligence agent in the Great Game between the UK and Russia in 19th century Central Asia. An even earlier work was James Fenimore Cooper's classic novel, The Spy, written in 1821, about an American spy in New York during the Revolutionary War.\nDuring the many 20th-century spy scandals, much information became publicly known about national spy agencies and dozens of real-life secret agents. These sensational stories piqued public interest in a profession largely off-limits to human interest news reporting, a natural consequence of the secrecy inherent in their work. To fill in the blanks, the popular conception of the secret agent has been formed largely by 20th and 21st-century fiction and film. Attractive and sociable real-life agents such as Valerie Plame find little employment in serious fiction, however.  The fictional secret agent is more often a loner, sometimes amoral\u2014an existential hero operating outside the everyday constraints of society. Loner spy personalities may have been a stereotype of convenience for authors who already knew how to write loner private investigator characters that sold well from the 1920s to the present.Johnny Fedora achieved popularity as a fictional agent of early Cold War espionage, but James Bond is the most commercially successful of the many spy characters created by intelligence insiders during that struggle. Other fictional agents include Le Carr\u00e9's George Smiley, and Harry Palmer as played by Michael Caine.\nJumping on the spy bandwagon, other writers also started writing about spy fiction featuring female spies as protagonists, such as  The Baroness, which has more graphic action and sex, as compared to other novels featuring male protagonists.\nSpy fiction has permeated the video game world as well, in games such as Perfect Dark, GoldenEye 007, No One Lives Forever, and the Metal Gear series.\nEspionage has also made its way into comedy depictions.  The 1960s TV series Get Smart, the 1983 Finnish film Agent 000 and the Deadly Curves, and Johnny English film trilogy portrays an inept spy, while the 1985 movie Spies Like Us depicts a pair of none-too-bright men sent to the Soviet Union to investigate a missile.\nThe historical novel The Emperor and the Spy highlights the adventurous life of U.S. Colonel Sidney Forrester Mashbir, who during the 1920s and 1930s attempted to prevent war with Japan, and when war did erupt, he became General MacArthur's top advisor in the Pacific Theater of World War Two.Black Widow is also a fictional agent who was introduced as a Russian spy, an antagonist of the superhero Iron Man. She later became an agent of the fictional spy agency S.H.I.E.L.D. and a member of the superhero team the Avengers.\n\nBased on the above text, answer a question. How do espionage agents specialize in different areas of expertise for targeting?",
    "context": "",
    "output": "Espionage agents are usually trained experts in a targeted field, such as natural resources, popular sentiment, strategic economic strengths, military capability, or counterintelligence operations. This specialization allows them to differentiate mundane information from targets of value to their own organizational development.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do espionage agents specialize in different areas of expertise for targeting?",
      "answer": "Espionage agents are usually trained experts in a targeted field, such as natural resources, popular sentiment, strategic economic strengths, military capability, or counterintelligence operations. This specialization allows them to differentiate mundane information from targets of value to their own organizational development.",
      "context": "Espionage\n\n==Introduction==\nEspionage, spying, or intelligence gathering is the act of obtaining secret or confidential information (intelligence). A person who commits espionage is called an espionage agent or spy. Any individual or spy ring (a cooperating group of spies), in the service of a government, company, criminal organization, or independent operation, can commit espionage. The practice is clandestine, as it is by definition unwelcome. In some circumstances, it may be a legal tool of law enforcement and in others, it may be illegal and punishable by law.\nEspionage is often part of an institutional effort by a government or commercial concern. However, the term tends to be associated with state spying on potential or actual enemies for military purposes. Spying involving corporations is known as industrial espionage.\nOne way to gather data and information about a targeted organization is by infiltrating its ranks. Spies can then return information such as the size and strength of enemy forces. They can also find dissidents within the organization and influence them to provide further information or to defect. In times of crisis, spies steal technology and sabotage the enemy in various ways. Counterintelligence is the practice of thwarting enemy espionage and intelligence-gathering. Almost all sovereign states have strict laws concerning espionage, including those who practice espionage in other countries, and the penalties for being caught are often severe.\n\n\n\n== Today ==\nToday, spy agencies target the illegal drug trade and terrorists as well as state actors. Between 2008 and 2011, the United States charged at least 57 defendants for attempting to spy for China.Intelligence services value certain intelligence collection techniques over others. The former Soviet Union, for example, preferred human sources over research in open sources, while the United States has tended to emphasize technological methods such as SIGINT and IMINT. In the Soviet Union, both political (KGB) and military intelligence (GRU) officers were judged by the number of agents they recruited.\n\n== Targets of espionage ==\nEspionage agents are usually trained experts in a targeted field so they can differentiate mundane information from targets of value to their own organizational development. Correct identification of the target at its execution is the sole purpose of the espionage operation.Broad areas of espionage targeting expertise include:\nNatural resources: strategic production identification and assessment (food, energy, materials). Agents are usually found among bureaucrats who administer these resources in their own countries\nPopular sentiment towards domestic and foreign policies (popular, middle class, elites). Agents often recruited from field journalistic crews, exchange postgraduate students and sociology researchers\nStrategic economic strengths (production, research, manufacture, infrastructure). Agents recruited from science and technology academia, commercial enterprises, and more rarely from among military technologists\nMilitary capability intelligence (offensive, defensive, manoeuvre, naval, air, space). Agents are trained by military espionage education facilities and posted to an area of operation with covert identities to minimize prosecution\nCounterintelligence operations targeting opponents' intelligence services themselves, such as breaching the confidentiality of communications, and recruiting defectors or moles\n\n== Methods and terminology ==\nAlthough the news media may speak of \"spy satellites\" and the like, espionage is not a synonym for all intelligence-gathering disciplines. It is a specific form of human source intelligence (HUMINT). Codebreaking (cryptanalysis or COMINT), aircraft or satellite photography (IMINT), and analysis of publicly available data sources (OSINT) are all intelligence gathering disciplines, but none of them is considered espionage. Many HUMINT activities, such as prisoner interrogation, reports from military reconnaissance patrols and from diplomats, etc., are not considered espionage.  Espionage is the disclosure of sensitive information (classified) to people who are not cleared for that information or access to that sensitive information.\nUnlike other forms of intelligence collection disciplines, espionage usually involves accessing the place where the desired information is stored or accessing the people who know the information and will divulge it through some kind of subterfuge. There are exceptions to physical meetings, such as the Oslo Report, or the insistence of Robert Hanssen in never meeting the people who bought his information.\n\nThe US defines espionage towards itself as \"the act of obtaining, delivering, transmitting, communicating, or receiving information about the national defence with an intent, or reason to believe, that the information may be used to the injury of the United States or to the advantage of any foreign nation\". Black's Law Dictionary (1990) defines espionage as: \"... gathering, transmitting, or losing ... information related to the national defense\". Espionage is a violation of United States law, 18 U.S.C. \u00a7\u00a7 792\u2013798 and Article 106a of the Uniform Code of Military Justice. The United States, like most nations, conducts espionage against other nations, under the control of the National Clandestine Service. Britain's espionage activities are controlled by the Secret Intelligence Service.\n\n\n*** Technology and techniques ***\n\nSource:\n\n== Organization ==\n\nA spy is a person employed to seek out top secret information from a source. Within the United States Intelligence Community, \"asset\" is more common usage. A case officer or Special Agent, who may have diplomatic status (i.e., official cover or non-official cover), supports and directs the human collector. Cut-outs are couriers who do not know the agent or case officer but transfer messages. A safe house is a refuge for spies. Spies often seek to obtain secret information from another source.\nIn larger networks, the organization can be complex with many methods to avoid detection, including clandestine cell systems.  Often the players have never met. Case officers are stationed in foreign countries to recruit and supervise intelligence agents, who in turn spy on targets in the countries where they are assigned. A spy need not be a citizen of the target country and hence does not automatically commit treason when operating within it. While the more common practice is to recruit a person already trusted with access to sensitive information, sometimes a person with a well-prepared synthetic identity (cover background), called a legend in tradecraft, may attempt to infiltrate a target organization.\nThese agents can be moles (who are recruited before they get access to secrets), defectors (who are recruited after they get access to secrets and leave their country) or defectors in place (who get access but do not leave).\nA legend is also employed for an individual who is not an illegal agent, but is an ordinary citizen who is \"relocated\", for example, a \"protected witness\". Nevertheless, such a non-agent very likely will also have a case officer who will act as a controller. As in most, if not all synthetic identity schemes, for whatever purpose (illegal or legal), the assistance of a controller is required.\nSpies may also be used to spread disinformation in the organization in which they are planted, such as giving false reports about their country's military movements, or about a competing company's ability to bring a product to market. Spies may be given other roles that also require infiltration, such as sabotage.\nMany governments spy on their allies as well as their enemies, although they typically maintain a policy of not commenting on this. Governments also employ private companies to collect information on their behalf such as SCG International Risk, International Intelligence Limited and others.\nMany organizations, both national and non-national, conduct espionage operations. It should not be assumed that espionage is always directed at the most secret operations of a target country.  National and terrorist organizations and other groups are also targeted. This is because governments want to retrieve information that they can use to be proactive in protecting their nation from potential terrorist attacks.\nCommunications both are necessary to espionage and clandestine operations, and also a great vulnerability when the adversary has sophisticated SIGINT detection and interception capability. Spies rely on COVCOM or covert communication through technically advanced spy devices. Agents must also transfer money securely.\n\n== Industrial espionage ==\n\nReportedly Canada is losing $12 billion and German companies are estimated to be losing about \u20ac50 billion ($87 billion) and 30,000 jobs to industrial espionage every year.\n\n== Agents in espionage ==\nIn espionage jargon, an \"agent\" is the person who does the spying.  They may be a citizen of a country recruited by that country to spy on another; a citizen of a country recruited by that country to carry out false flag assignments disrupting his own country; a citizen of one country who is recruited by a second country to spy on or work against his own country or a third country, and more.\nIn popular usage, this term is sometimes confused with an intelligence officer, intelligence operative, or case officer who recruits and handles agents.\nAmong the most common forms of agent are:\n\nAgent provocateur: instigates trouble or provides information to gather as many people as possible into one location for an arrest.\nIntelligence agent: provides access to sensitive information through the use of special privileges. If used in corporate intelligence gathering, this may include gathering information of a corporate business venture or stock portfolio. In economic intelligence, \"Economic Analysts may use their specialized skills to analyze and interpret economic trends and developments, assess and track foreign financial activities, and develop new econometric and modelling methodologies.\" This may also include information of trade or tariff.\nAgent-of-influence: provides political influence in an area of interest, possibly including publications needed to further an intelligence service agenda. The use of the media to print a story to mislead a foreign service into action, exposing their operations while under surveillance.\nDouble agent: engages in clandestine activity for two intelligence or security services (or more in joint operations), who provides information about one or about each to the other, and who wittingly withholds significant information from one on the instructions of the other or is unwittingly manipulated by one so that significant facts are withheld from the adversary. Peddlers, fabricators, and others who work for themselves rather than a service are not double agents because they are not agents. The fact that double agents have an agent relationship with both sides distinguishes them from penetrations, who normally are placed with the target service in a staff or officer capacity.\"Redoubled agent: forced to mislead the foreign intelligence service after being caught as a double agent.\nUnwitting double agent: offers or is forced to recruit as a double or redoubled agent and in the process is recruited by either a third-party intelligence service or his own government without the knowledge of the intended target intelligence service or the agent. This can be useful in capturing important information from an agent that is attempting to seek allegiance with another country. The double agent usually has knowledge of both intelligence services and can identify operational techniques of both, thus making third-party recruitment difficult or impossible. The knowledge of operational techniques can also affect the relationship between the operations officer (or case officer) and the agent if the case is transferred by an operational targeting officer] to a new operations officer, leaving the new officer vulnerable to attack. This type of transfer may occur when an officer has completed his term of service or when his cover is blown.\nSleeper agent: recruited to wake up and perform a specific set of tasks or functions while living undercover in an area of interest. This type of agent is not the same as a deep cover operative, who continually contacts a case officer to file intelligence reports. A sleeper agent is not in contact with anyone until activated.\nTriple agent: works for three intelligence services.Less common or lesser known forms of agent include:\n\nAccess agent: provides access to other potential agents by providing offender profiling information that can help lead to recruitment into an intelligence service.\nConfusion agent: provides misleading information to an enemy intelligence service or attempts to discredit the operations of the target in an operation.\nFacilities agent: provides access to buildings, such as garages or offices used for staging operations, resupply, etc.\nIllegal agent: lives in another country under false credentials and does not report to a local station. A nonofficial cover operative can be dubbed an \"illegal\" when working in another country without diplomatic protection.\nPrincipal agent: functions as a handler for an established network of agents, usually considered \"blue chip\".\n\n== Law ==\nEspionage against a nation is a crime under the legal code of many nations. In the United States, it is covered by the Espionage Act of 1917. The risks of espionage vary. A spy violating the host country's laws may be deported, imprisoned, or even executed. A spy violating its own country's laws can be imprisoned for espionage or/and treason (which in the United States and some other jurisdictions can only occur if they take up arms or aids the enemy against their own country during wartime), or even executed, as the Rosenbergs were. For example, when Aldrich Ames handed a stack of dossiers of U.S. Central Intelligence Agency (CIA) agents in the Eastern Bloc to his KGB-officer \"handler\", the KGB \"rolled up\" several networks, and at least ten people were secretly shot. When Ames was arrested by the U.S. Federal Bureau of Investigation (FBI), he faced life in prison; his contact, who had diplomatic immunity, was declared persona non grata and taken to the airport. Ames' wife was threatened with life imprisonment if her husband did not cooperate; he did, and she was given a five-year sentence. Hugh Francis Redmond, a CIA officer in China, spent nineteen years in a Chinese prison for espionage\u2014and died there\u2014as he was operating without diplomatic cover and immunity.In United States law, treason, espionage, and spying are separate crimes.  Treason and espionage have graduated punishment levels.\nThe United States in World War I passed the Espionage Act of 1917. Over the years, many spies, such as the Soble spy ring, Robert Lee Johnson, the Rosenberg ring, Aldrich Hazen Ames, Robert Philip Hanssen, Jonathan Pollard, John Anthony Walker, James Hall III, and others have been prosecuted under this law.\n\n\n*** History of espionage laws ***\nFrom ancient times, the penalty for espionage in many countries was execution. This was true right up until the era of World War II; for example, Josef Jakobs was a Nazi spy who parachuted into Great Britain in 1941 and was executed for espionage.\nIn modern times, many people convicted of espionage have been given penal sentences rather than execution. For example, Aldrich Hazen Ames is an American CIA analyst, turned KGB mole, who was convicted of espionage in 1994; he is serving a life sentence without the possibility of parole in the high-security Allenwood U.S. Penitentiary. Ames was formerly a 31-year CIA counterintelligence officer and analyst who committed espionage against his country by spying for the Soviet Union and Russia. So far as it is known, Ames compromised the second-largest number of CIA agents, second only to Robert Hanssen, who is also serving a prison sentence.\n\n\n*** Use against non-spies ***\nEspionage laws are also used to prosecute non-spies. In the United States, the Espionage Act of 1917 was used against socialist politician Eugene V. Debs (at that time the Act had much stricter guidelines and amongst other things banned speech against military recruiting). The law was later used to suppress publication of periodicals, for example of Father Coughlin in World War II. In the early 21st century, the act was used to prosecute whistleblowers such as Thomas Andrews Drake, John Kiriakou, and Edward Snowden, as well as officials who communicated with journalists for innocuous reasons, such as Stephen Jin-Woo Kim.As of 2012, India and Pakistan were holding several hundred prisoners of each other's country for minor violations like trespass or visa overstay, often with accusations of espionage attached. Some of these include cases where Pakistan and India both deny citizenship to these people, leaving them stateless. The BBC reported in 2012 on one such case, that of Mohammed Idrees, who was held under Indian police control for approximately 13 years for overstaying his 15-day visa by 2\u20133 days after seeing his ill parents in 1999. Much of the 13 years were spent in prison waiting for a hearing, and more time was spent homeless or living with generous families. The Indian People's Union for Civil Liberties and Human Rights Law Network both decried his treatment. The BBC attributed some of the problems to tensions caused by the Kashmir conflict.\n\n\n*** Espionage laws in the UK ***\nEspionage is illegal in the UK under the Official Secrets Acts of 1911 and 1920. The UK law under this legislation considers espionage as \"concerning those who intend to help an enemy and deliberately harm the security of the nation\". According to MI5, a person commits the offence of 'spying' if they, \"for any purpose prejudicial to the safety or interests of the State\": approaches, enters or inspects a prohibited area; makes documents such as plans that are intended, calculated, or could directly or indirectly be of use to an enemy; or \"obtains, collects, records, or publishes, or communicates to any other person any secret official code word, or password, or any sketch, plan, model, article, or note, or other document which is calculated to be or might be or is intended to be directly or indirectly useful to an enemy\". The illegality of espionage also includes any action which may be considered 'preparatory to' spying, or encouraging or aiding another to spy.Under the penal codes of the UK, those found guilty of espionage are liable to imprisonment for a term of up to 14 years, although multiple sentences can be issued.\n\n\n**** Government intelligence laws and its distinction from espionage ****\nGovernment intelligence is very much distinct from espionage, and is not illegal in the UK, providing that the organisations of individuals are registered, often with the ICO, and are acting within the restrictions of the Regulation of Investigatory Powers Act (RIPA). 'Intelligence' is considered legally as \"information of all sorts gathered by a government or organisation to guide its decisions. It includes information that may be both public and private, obtained from much different public or secret sources. It could consist entirely of information from either publicly available or secret sources, or be a combination of the two.\"However, espionage and intelligence can be linked. According to the MI5 website, \"foreign intelligence officers acting in the UK under diplomatic cover may enjoy immunity from prosecution. Such persons can only be tried for spying (or, indeed, any criminal offence) if diplomatic immunity is waived beforehand. Those officers operating without diplomatic cover have no such immunity from prosecution\".\nThere are also laws surrounding government and organisational intelligence and surveillance. Generally, the body involved should be issued with some form of warrant or permission from the government and should be enacting their procedures in the interest of protecting national security or the safety of public citizens. Those carrying out intelligence missions should act within not only RIPA but also the Data Protection Act and Human Rights Act. However, there are spy equipment laws and legal requirements around intelligence methods that vary for each form of intelligence enacted.\n\n\n*** War ***\n\nIn war, espionage is considered permissible as many nations recognize the inevitability of opposing sides seeking intelligence each about the dispositions of the other. To make the mission easier and successful, combatants wear disguises to conceal their true identity from the enemy while penetrating enemy lines for intelligence gathering. However, if they are caught behind enemy lines in disguises, they are not entitled to prisoner-of-war status and subject to prosecution and punishment\u2014including execution.\nThe Hague Convention of 1907 addresses the status of wartime spies, specifically within \"Laws and Customs of War on Land\" (Hague IV); October 18, 1907: CHAPTER II Spies\". Article 29 states that a person is considered a spy who, acts clandestinely or on false pretences, infiltrates enemy lines with the intention of acquiring intelligence about the enemy and communicate it to the belligerent during times of war. Soldiers who penetrate enemy lines in proper uniforms for the purpose of acquiring intelligence are not considered spies but are lawful combatants entitled to be treated as prisoners of war upon capture by the enemy. Article 30 states that a spy captured behind enemy lines may only be punished following a trial. However, Article 31 provides that if a spy successfully rejoined his own military and is then captured by the enemy as a lawful combatant, he cannot be punished for his previous acts of espionage and must be treated as a prisoner of war. Note that this provision does not apply to citizens who committed treason against their own country or co-belligerents of that country and may be captured and prosecuted at any place or any time regardless whether he rejoined the military to which he belongs or not or during or after the war.The ones that are excluded from being treated as spies while behind enemy lines are escaping prisoners of war and downed airmen as international law distinguishes between a disguised spy and a disguised escaper. It is permissible for these groups to wear enemy uniforms or civilian clothes in order to facilitate their escape back to friendly lines so long as they do not attack enemy forces, collect military intelligence, or engage in similar military operations while so disguised. Soldiers who are wearing enemy uniforms or civilian clothes simply for the sake of warmth along with other purposes rather than engaging in espionage or similar military operations while so attired are also excluded from being treated as unlawful combatants.Saboteurs are treated as spies as they too wear disguises behind enemy lines for the purpose of waging destruction on an enemy's vital targets in addition to intelligence gathering. For example, during World War II, eight German agents entered the U.S. in June 1942 as part of Operation Pastorius, a sabotage mission against U.S. economic targets. Two weeks later, all were arrested in civilian clothes by the FBI thanks to two German agents betraying the mission to the U.S. Under the Hague Convention of 1907, these Germans were classified as spies and tried by a military tribunal in Washington D.C. On August 3, 1942, all eight were found guilty and sentenced to death. Five days later, six were executed by electric chair at the District of Columbia jail. Two who had given evidence against the others had their sentences reduced by President Franklin D. Roosevelt to prison terms. In 1948, they were released by President Harry S. Truman and deported to the American Zone of occupied Germany.\nThe U.S. codification of enemy spies is Article 106 of the Uniform Code of Military Justice. This provides a mandatory death sentence if a person captured in the act is proven to be \"lurking as a spy or acting as a spy in or about any place, vessel, or aircraft, within the control or jurisdiction of any of the armed forces, or in or about any shipyard, any manufacturing or industrial plant, or any other place or institution engaged in work in aid of the prosecution of the war by the United States, or elsewhere\".\n\n== Spy fiction ==\n\nSpies have long been favorite topics for novelists and filmmakers.  An early example of espionage literature is Kim by the English novelist Rudyard Kipling, with a description of the training of an intelligence agent in the Great Game between the UK and Russia in 19th century Central Asia. An even earlier work was James Fenimore Cooper's classic novel, The Spy, written in 1821, about an American spy in New York during the Revolutionary War.\nDuring the many 20th-century spy scandals, much information became publicly known about national spy agencies and dozens of real-life secret agents. These sensational stories piqued public interest in a profession largely off-limits to human interest news reporting, a natural consequence of the secrecy inherent in their work. To fill in the blanks, the popular conception of the secret agent has been formed largely by 20th and 21st-century fiction and film. Attractive and sociable real-life agents such as Valerie Plame find little employment in serious fiction, however.  The fictional secret agent is more often a loner, sometimes amoral\u2014an existential hero operating outside the everyday constraints of society. Loner spy personalities may have been a stereotype of convenience for authors who already knew how to write loner private investigator characters that sold well from the 1920s to the present.Johnny Fedora achieved popularity as a fictional agent of early Cold War espionage, but James Bond is the most commercially successful of the many spy characters created by intelligence insiders during that struggle. Other fictional agents include Le Carr\u00e9's George Smiley, and Harry Palmer as played by Michael Caine.\nJumping on the spy bandwagon, other writers also started writing about spy fiction featuring female spies as protagonists, such as  The Baroness, which has more graphic action and sex, as compared to other novels featuring male protagonists.\nSpy fiction has permeated the video game world as well, in games such as Perfect Dark, GoldenEye 007, No One Lives Forever, and the Metal Gear series.\nEspionage has also made its way into comedy depictions.  The 1960s TV series Get Smart, the 1983 Finnish film Agent 000 and the Deadly Curves, and Johnny English film trilogy portrays an inept spy, while the 1985 movie Spies Like Us depicts a pair of none-too-bright men sent to the Soviet Union to investigate a missile.\nThe historical novel The Emperor and the Spy highlights the adventurous life of U.S. Colonel Sidney Forrester Mashbir, who during the 1920s and 1930s attempted to prevent war with Japan, and when war did erupt, he became General MacArthur's top advisor in the Pacific Theater of World War Two.Black Widow is also a fictional agent who was introduced as a Russian spy, an antagonist of the superhero Iron Man. She later became an agent of the fictional spy agency S.H.I.E.L.D. and a member of the superhero team the Avengers."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the purpose of the BadBunny worm's macro?",
    "context": "",
    "output": "The purpose of the BadBunny worm's macro is to display a message and load one of four different scripts on the user's system.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the purpose of the BadBunny worm's macro?",
      "answer": "The purpose of the BadBunny worm's macro is to display a message and load one of four different scripts on the user's system."
    }
  },
  {
    "instruction": "Write an answer to the following question: What security measures can be used for authentication in a friend-to-friend network?",
    "context": "",
    "output": "Passwords or digital signatures are used for authentication in a friend-to-friend network.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What security measures can be used for authentication in a friend-to-friend network?",
      "answer": "Passwords or digital signatures are used for authentication in a friend-to-friend network."
    }
  },
  {
    "instruction": "Context: Firewalld\n\n==Introduction==\nfirewalld is a firewall management tool for Linux operating systems. It provides firewall features by acting as a front-end for the Linux kernel's netfilter framework. firewalld's current default backend is nftables. Prior to v0.6.0, iptables was the default backend. Through its abstractions, firewalld acts as an alternative to nft and iptables command line programs. The name firewalld adheres to the Unix convention of naming system daemons by appending the letter \"d\".firewalld is written in Python. It was intended to be ported to C++, but the porting project was abandoned in January 2015.\n\n== Features ==\nfirewalld supports both IPv4 and IPv6 networks and can administer separate firewall zones with varying degrees of trust as defined in zone profiles. Administrators can configure Network Manager to automatically switch zone profiles based on known Wi-Fi (wireless) and Ethernet (wired) networks, but firewalld cannot do this on its own.Services and applications can use the D-Bus interface to query and configure the firewall. firewalld supports timed rules, meaning the number of connections (or \"hits\") to a service can be limited globally. There is no support for hit-counting and subsequent connection rejection per source IP; a common technique deployed to limit the impact of  brute-force  hacking and distributed denial-of-service attacks.firewalld's command syntax is similar to but more verbose than other iptables front-ends like Ubuntu's Uncomplicated Firewall (ufw). The command-line interface allows managing firewall rulesets for protocol, ports, source and destination; or predefined services by name.\nServices are defined as XML files containing port- and protocol-mappings, and optionally extra information like specifying subnets and listing required Kernel helper modules.\nThe syntax resembles that of systemd's service files. A simple service file for a web server listening on TCP port 443 might look like this:\n\n== Forward and output filtering ==\nfirewalld v0.9.0 added native support for forward and output forwarding via policy objects. This allows filtering traffic flowing between zones. Policies support most firewalld primitives available to zones: services, ports, forward-ports, masquerade, rich rules, etc.\n\n== Limitations ==\nBy default firewalld does not block outbound traffic as required by standards such as NIST 800-171 and 800-53. However, an outbound block can be added with a policy.\n\n== Graphical front-ends (GUIs) ==\nfirewall-config is a graphical front-end that is optionally included with firewalld, with support for most of its features.\nfirewall-applet is a small status indicator utility that is optionally included with firewalld. It can provide firewall event log notifications as well as a quick way to open firewall-config. firewall-applet was ported from the GTK+ to the Qt framework in the summer of 2015 following the GNOME Desktop\u2019s deprecation of system tray icons.\n\n== Adoption ==\nfirewalld ships by default on the following Linux distributions:\nCentOS 7 and newer\nFedora 18 and newer\nOpenSUSE Leap 15 and newer\nRed Hat Enterprise Linux 7 and newer\nSUSE Linux Enterprise 15 and newer\nEndeavourOS Apollo and newerfirewalld is enabled by default in all of these distributions. firewalld is also available as one of many firewall options in the package repository of many other popular distributions such as Debian or Ubuntu.\n\nQuestion: What is the role of the D-Bus interface in firewalld, and how can services and applications use it?\n\nAnswer:",
    "context": "",
    "output": "The D-Bus interface in firewalld allows services and applications to query and configure the firewall. It is a message bus system that allows communication between different processes on the same machine.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of the D-Bus interface in firewalld, and how can services and applications use it?",
      "answer": "The D-Bus interface in firewalld allows services and applications to query and configure the firewall. It is a message bus system that allows communication between different processes on the same machine.",
      "context": "Firewalld\n\n==Introduction==\nfirewalld is a firewall management tool for Linux operating systems. It provides firewall features by acting as a front-end for the Linux kernel's netfilter framework. firewalld's current default backend is nftables. Prior to v0.6.0, iptables was the default backend. Through its abstractions, firewalld acts as an alternative to nft and iptables command line programs. The name firewalld adheres to the Unix convention of naming system daemons by appending the letter \"d\".firewalld is written in Python. It was intended to be ported to C++, but the porting project was abandoned in January 2015.\n\n== Features ==\nfirewalld supports both IPv4 and IPv6 networks and can administer separate firewall zones with varying degrees of trust as defined in zone profiles. Administrators can configure Network Manager to automatically switch zone profiles based on known Wi-Fi (wireless) and Ethernet (wired) networks, but firewalld cannot do this on its own.Services and applications can use the D-Bus interface to query and configure the firewall. firewalld supports timed rules, meaning the number of connections (or \"hits\") to a service can be limited globally. There is no support for hit-counting and subsequent connection rejection per source IP; a common technique deployed to limit the impact of  brute-force  hacking and distributed denial-of-service attacks.firewalld's command syntax is similar to but more verbose than other iptables front-ends like Ubuntu's Uncomplicated Firewall (ufw). The command-line interface allows managing firewall rulesets for protocol, ports, source and destination; or predefined services by name.\nServices are defined as XML files containing port- and protocol-mappings, and optionally extra information like specifying subnets and listing required Kernel helper modules.\nThe syntax resembles that of systemd's service files. A simple service file for a web server listening on TCP port 443 might look like this:\n\n== Forward and output filtering ==\nfirewalld v0.9.0 added native support for forward and output forwarding via policy objects. This allows filtering traffic flowing between zones. Policies support most firewalld primitives available to zones: services, ports, forward-ports, masquerade, rich rules, etc.\n\n== Limitations ==\nBy default firewalld does not block outbound traffic as required by standards such as NIST 800-171 and 800-53. However, an outbound block can be added with a policy.\n\n== Graphical front-ends (GUIs) ==\nfirewall-config is a graphical front-end that is optionally included with firewalld, with support for most of its features.\nfirewall-applet is a small status indicator utility that is optionally included with firewalld. It can provide firewall event log notifications as well as a quick way to open firewall-config. firewall-applet was ported from the GTK+ to the Qt framework in the summer of 2015 following the GNOME Desktop\u2019s deprecation of system tray icons.\n\n== Adoption ==\nfirewalld ships by default on the following Linux distributions:\nCentOS 7 and newer\nFedora 18 and newer\nOpenSUSE Leap 15 and newer\nRed Hat Enterprise Linux 7 and newer\nSUSE Linux Enterprise 15 and newer\nEndeavourOS Apollo and newerfirewalld is enabled by default in all of these distributions. firewalld is also available as one of many firewall options in the package repository of many other popular distributions such as Debian or Ubuntu."
    }
  },
  {
    "instruction": "Context: Hacking of consumer electronics\n\n==Introduction==\nThe hacking of consumer electronics is an increasingly common practice which users perform in order to customize and modify their devices beyond what is typically possible. This activity has a long history, dating from the days of early computer, programming, and electronics hobbyists.\nA notable case of the hacking of consumer electronics is jailbreaking of Apple iOS devices or the rooting of Android phones, although many other electronics such as video game consoles are regularly hacked. While these methods allow unrestricted modification of an existing operating system installation, some third-party operating systems have been developed as a replacement to a device's default OS, such as Replicant and postmarketOS on cellphones, or DD-WRT and tomato on routers.\nThe process of consumer electronics hacking is usually accomplished through modification of the system software, either an operating system or firmware, but hardware modifications are not uncommon.\nThe legality of hacking consumer electronics has been challenged over the years, with an example of this being the cracking of encryption keys used in High-bandwidth Digital Content Protection, where detractors have been threatened under the basis of legal action. However, some companies have encouraged hardware hacking, such as Google's Nexus and Pixel series of smartphones.\n\n== Overview ==\nMany modern consumer electronics run either an operating system or firmware. When this is stored in a mutable storage device, these files can be modified to add functionality to the operating system, or to replace it entirely.\n\n== Method ==\nMultiple methods are used in order to successfully hack the target device, such as gaining shell access, gathering information about the device hardware and software, before using the obtained information to manipulate the operating system.\n\n\n*** Shell access ***\nGetting access to a shell allows the user to run commands to interact with the operating system. Typically, a root shell is aimed for, which grants administrative privileges, to let the user modify operating system files.\nRoot access can be obtained through the use of software exploits (i.e. bugs), through the bootloader console, or over a serial port embedded in the device, such as a JTAG or UART interface.In the case of gaining root privileges on an Android device, the process is known as rooting.\n\n\n*** Unlocking the bootloader ***\n\nOn some Android devices, the bootloader is locked for security to prevent installation of other operating systems. Unlocking it is required before another OS can be installed.\nOn Android devices, Fastboot (Odin mode on Samsung devices) allows flashing of operating systems onto storage.Das U-Boot is a bootloader commonly used in embedded devices such as routers and Chromebooks.\n\n\n*** Getting information ***\nGetting information on the device's hardware and software is vital because exploits can be identified, which is subsequently used to either gain shell access, port an operating system to the device, etc.\n\n== Manufacturer use of open source software ==\nA lot of device manufacturers include open source software in their products. When the software used is licensed under a copyleft license, a manufacturer is obliged to provide the source code of the open source components. An instance of this was when Naomi Wu requested the GPLv2 licensed source code of the Linux Kernel branch of a smartphone vendor.A good share of consumer devices run on a modified Linux kernel, which is forked before applying device-specific changes. Android is an example of OS which makes use of the Linux kernel.\n\n== Countermeasures ==\nDevice manufacturers often include countermeasures to hinder hardware hacking, one of which is the use of cryptography to prevent unauthorized code from being executed. For example, Nvidia graphics cards have signed firmware to prevent tampering or hacking.\n\n== Devices ==\n\n\n*** Smartphones ***\n\n\n**** Hardware device removal ****\nWhistleblower Edward Snowden showed Wired correspondent Shane Smith how to remove the cameras and microphones from a smartphone.\n\n\n**** Modifying default operating systems ****\nOne of the reasons hacking is done is to add or unlock features in an operating system.\nExamples include:\n\nWindows Phone\nApple iOS (jailbreaking)\nGoogle Android (rooting)\nPalm webOS (developer mode)\nSymbian OS (executing unsigned code)\nJio phone (Enabling WhatsApp to be installed)\n\n\n**** Installing a third-party operating system ****\nAnother reason hacking is done is to allow unsupported operating systems to be installed.\n\nReplicant\npostmarketOS\nFirefox OS (defunct)\n\n\n*** General purpose computers ***\nA general purpose computer has historically been open by design.\nHowever, Apple's Apple silicon based Mac hardware is based on the ARM architecture, making it difficult to install a third-party operating system.\n\nAsahi Linux allows a Linux-based operating system to be installed on M1-based Macs.\n\n\n*** Multimedia devices and video game systems ***\nThere are many reasons video game consoles may be hacked.\nGame consoles are often restricted in a way that may disallow unofficial games to be run on it (see Video game console#Licensing), and hacking is undertaken to allow unlicensed games to run on it, including pirated games.\nAnother reason is to allow features to be added, such as using the console as a multimedia player. An example of this is Xbox Media Player, which was made to allow pictures and movies to be shown on an Xbox.\n\nMicrosoft\nXbox\nXbox 360\nXbox One\nXbox Series X/S\nNintendo\nGameCube\nGame Boy Advance\nNintendo DS\nNintendo 3DS (Homebrew)\nWii\nWii homebrew\nWii U\nNintendo Switch\nSony\nPlayStation Portable\nPlayStation 2\nPlayStation 3\nPlayStation Vita\nOthers\nTiVo\nDVD player - to remove regional restrictions, user operation prohibition flag (fast forward disabled in advertising clip etc.) and Macrovision (video copy is flashing after copying to protect analog hole)\nBlu-ray players - to remove regional restrictions\nAny non-smart mobile phone.  To remove operator lock or SIM lock restriction.\n\n\n*** Other devices ***\nGraphing calculators\nTexas Instruments signing key controversy\nVideo cards\nRouters\nDD-WRT\nOpenWRT\nOscilloscopes\nThermographic cameras\nGPS devices\nCanon Digital cameras\nNikon Digital cameras.\n\n== Devices allowing for hacking ==\n\nSome devices\u2014most commonly open source\u2014are built for homebrew purposes, and encourage hacking as an integral part of their existence.\n\nPandora (console)\nSamsung\nTekno\n\nChumby\nOuya\nNokia N900\nAndroid Dev Phone\nNexus One\nNexus S\nGalaxy Nexus, currently one of the phones recommended by the Android Open Source Project for software development\nZTE Open\nMany wireless routers' firmware upgrade functions are not limited to accepting updates that have been signed by the device's manufacturer. As a result, open-source firmware replacements have been created for many devices, such as OpenWrt and DD-WRT.\n\n== Legality ==\niOS jailbreaking was often considered illegal in the United States until a recent ruling by the U.S. Copyright Office declaring that jailbreaking an iPhone or other mobile device would no longer violate copyright law.  However, simultaneously, there is ongoing prosecution against hackers of videogame consoles under anti-circumvention violations of the DMCA. A main complication, in many cases, is the profiting from selling jailbroken or rooted equipment as a value-added service. At least some accused deny these charges and claim only to be making back-ups of legally purchased games.In around 2010, the High-bandwidth Digital Content Protection encryption system, which encrypts data running between cable boxes, Blu-ray players, and other similar devices and displays was cracked, and a copy of the master key needed to decrypt HDCP protected streams was posted on the internet.  Intel, which created and now licenses HDCP technology, has stated that HDCP is sufficient to keep most users from circumventing it, but indicated that it may threaten legal action against more determined users under the DMCA.Also in around 2010, on the issue of the hacking of its then new interactive game controller the Kinect, Microsoft initially condemned and threatened legal action against those who hacked it, but soon after, it reversed this position and instead stated that it had intentionally left the device open, and would in fact not prosecute those who modified it.\n\nQuestion: What is the legality of hacking consumer electronics and what are some examples of legal challenges?\n\nAnswer:",
    "context": "",
    "output": "The legality of hacking consumer electronics has been challenged over the years, with examples including the cracking of encryption keys used in High-bandwidth Digital Content Protection, where detractors have been threatened under the basis of legal action.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the legality of hacking consumer electronics and what are some examples of legal challenges?",
      "answer": "The legality of hacking consumer electronics has been challenged over the years, with examples including the cracking of encryption keys used in High-bandwidth Digital Content Protection, where detractors have been threatened under the basis of legal action.",
      "context": "Hacking of consumer electronics\n\n==Introduction==\nThe hacking of consumer electronics is an increasingly common practice which users perform in order to customize and modify their devices beyond what is typically possible. This activity has a long history, dating from the days of early computer, programming, and electronics hobbyists.\nA notable case of the hacking of consumer electronics is jailbreaking of Apple iOS devices or the rooting of Android phones, although many other electronics such as video game consoles are regularly hacked. While these methods allow unrestricted modification of an existing operating system installation, some third-party operating systems have been developed as a replacement to a device's default OS, such as Replicant and postmarketOS on cellphones, or DD-WRT and tomato on routers.\nThe process of consumer electronics hacking is usually accomplished through modification of the system software, either an operating system or firmware, but hardware modifications are not uncommon.\nThe legality of hacking consumer electronics has been challenged over the years, with an example of this being the cracking of encryption keys used in High-bandwidth Digital Content Protection, where detractors have been threatened under the basis of legal action. However, some companies have encouraged hardware hacking, such as Google's Nexus and Pixel series of smartphones.\n\n== Overview ==\nMany modern consumer electronics run either an operating system or firmware. When this is stored in a mutable storage device, these files can be modified to add functionality to the operating system, or to replace it entirely.\n\n== Method ==\nMultiple methods are used in order to successfully hack the target device, such as gaining shell access, gathering information about the device hardware and software, before using the obtained information to manipulate the operating system.\n\n\n*** Shell access ***\nGetting access to a shell allows the user to run commands to interact with the operating system. Typically, a root shell is aimed for, which grants administrative privileges, to let the user modify operating system files.\nRoot access can be obtained through the use of software exploits (i.e. bugs), through the bootloader console, or over a serial port embedded in the device, such as a JTAG or UART interface.In the case of gaining root privileges on an Android device, the process is known as rooting.\n\n\n*** Unlocking the bootloader ***\n\nOn some Android devices, the bootloader is locked for security to prevent installation of other operating systems. Unlocking it is required before another OS can be installed.\nOn Android devices, Fastboot (Odin mode on Samsung devices) allows flashing of operating systems onto storage.Das U-Boot is a bootloader commonly used in embedded devices such as routers and Chromebooks.\n\n\n*** Getting information ***\nGetting information on the device's hardware and software is vital because exploits can be identified, which is subsequently used to either gain shell access, port an operating system to the device, etc.\n\n== Manufacturer use of open source software ==\nA lot of device manufacturers include open source software in their products. When the software used is licensed under a copyleft license, a manufacturer is obliged to provide the source code of the open source components. An instance of this was when Naomi Wu requested the GPLv2 licensed source code of the Linux Kernel branch of a smartphone vendor.A good share of consumer devices run on a modified Linux kernel, which is forked before applying device-specific changes. Android is an example of OS which makes use of the Linux kernel.\n\n== Countermeasures ==\nDevice manufacturers often include countermeasures to hinder hardware hacking, one of which is the use of cryptography to prevent unauthorized code from being executed. For example, Nvidia graphics cards have signed firmware to prevent tampering or hacking.\n\n== Devices ==\n\n\n*** Smartphones ***\n\n\n**** Hardware device removal ****\nWhistleblower Edward Snowden showed Wired correspondent Shane Smith how to remove the cameras and microphones from a smartphone.\n\n\n**** Modifying default operating systems ****\nOne of the reasons hacking is done is to add or unlock features in an operating system.\nExamples include:\n\nWindows Phone\nApple iOS (jailbreaking)\nGoogle Android (rooting)\nPalm webOS (developer mode)\nSymbian OS (executing unsigned code)\nJio phone (Enabling WhatsApp to be installed)\n\n\n**** Installing a third-party operating system ****\nAnother reason hacking is done is to allow unsupported operating systems to be installed.\n\nReplicant\npostmarketOS\nFirefox OS (defunct)\n\n\n*** General purpose computers ***\nA general purpose computer has historically been open by design.\nHowever, Apple's Apple silicon based Mac hardware is based on the ARM architecture, making it difficult to install a third-party operating system.\n\nAsahi Linux allows a Linux-based operating system to be installed on M1-based Macs.\n\n\n*** Multimedia devices and video game systems ***\nThere are many reasons video game consoles may be hacked.\nGame consoles are often restricted in a way that may disallow unofficial games to be run on it (see Video game console#Licensing), and hacking is undertaken to allow unlicensed games to run on it, including pirated games.\nAnother reason is to allow features to be added, such as using the console as a multimedia player. An example of this is Xbox Media Player, which was made to allow pictures and movies to be shown on an Xbox.\n\nMicrosoft\nXbox\nXbox 360\nXbox One\nXbox Series X/S\nNintendo\nGameCube\nGame Boy Advance\nNintendo DS\nNintendo 3DS (Homebrew)\nWii\nWii homebrew\nWii U\nNintendo Switch\nSony\nPlayStation Portable\nPlayStation 2\nPlayStation 3\nPlayStation Vita\nOthers\nTiVo\nDVD player - to remove regional restrictions, user operation prohibition flag (fast forward disabled in advertising clip etc.) and Macrovision (video copy is flashing after copying to protect analog hole)\nBlu-ray players - to remove regional restrictions\nAny non-smart mobile phone.  To remove operator lock or SIM lock restriction.\n\n\n*** Other devices ***\nGraphing calculators\nTexas Instruments signing key controversy\nVideo cards\nRouters\nDD-WRT\nOpenWRT\nOscilloscopes\nThermographic cameras\nGPS devices\nCanon Digital cameras\nNikon Digital cameras.\n\n== Devices allowing for hacking ==\n\nSome devices\u2014most commonly open source\u2014are built for homebrew purposes, and encourage hacking as an integral part of their existence.\n\nPandora (console)\nSamsung\nTekno\n\nChumby\nOuya\nNokia N900\nAndroid Dev Phone\nNexus One\nNexus S\nGalaxy Nexus, currently one of the phones recommended by the Android Open Source Project for software development\nZTE Open\nMany wireless routers' firmware upgrade functions are not limited to accepting updates that have been signed by the device's manufacturer. As a result, open-source firmware replacements have been created for many devices, such as OpenWrt and DD-WRT.\n\n== Legality ==\niOS jailbreaking was often considered illegal in the United States until a recent ruling by the U.S. Copyright Office declaring that jailbreaking an iPhone or other mobile device would no longer violate copyright law.  However, simultaneously, there is ongoing prosecution against hackers of videogame consoles under anti-circumvention violations of the DMCA. A main complication, in many cases, is the profiting from selling jailbroken or rooted equipment as a value-added service. At least some accused deny these charges and claim only to be making back-ups of legally purchased games.In around 2010, the High-bandwidth Digital Content Protection encryption system, which encrypts data running between cable boxes, Blu-ray players, and other similar devices and displays was cracked, and a copy of the master key needed to decrypt HDCP protected streams was posted on the internet.  Intel, which created and now licenses HDCP technology, has stated that HDCP is sufficient to keep most users from circumventing it, but indicated that it may threaten legal action against more determined users under the DMCA.Also in around 2010, on the issue of the hacking of its then new interactive game controller the Kinect, Microsoft initially condemned and threatened legal action against those who hacked it, but soon after, it reversed this position and instead stated that it had intentionally left the device open, and would in fact not prosecute those who modified it."
    }
  },
  {
    "instruction": "Cisco ASA\n\n==Introduction==\nIn computer networking, Cisco ASA 5500 Series Adaptive Security Appliances, or simply Cisco ASA, is Cisco's line of network security devices introduced in May 2005. It succeeded three existing lines of popular Cisco products:\n\nCisco PIX, which provided firewall and network address translation (NAT) functions, ended its sale on July 28, 2008.\nCisco's IPS 4200 Series worked as intrusion prevention systems (IPS).\nCisco VPN 3000 Series Concentrators, which provided virtual private networking (VPN).The Cisco ASA is a unified threat management device, combining several network security functions in one box.\n\n\n\n== Reception and criticism ==\nCisco ASA has become one of the most widely used firewall/VPN solutions for small to medium businesses. Early reviews indicated the Cisco GUI tools for managing the device were lacking.A security flaw was identified when users customized the Clientless SSL VPN option of their ASA's but was rectified in 2015.\nAnother flaw in a WebVPN feature was fixed in 2018.In 2017 The Shadow Brokers revealed the existence of two privilege escalation exploits against the ASA called EPICBANANA and EXTRABACON. A code insertion implant called BANANAGLEE,  was made persistent by JETPLOW.\n\n== Features ==\nThe 5506W-X has a WiFi point included.\n\n== Architecture ==\nThe ASA software is based on Linux. It runs a single Executable and Linkable Format program called lina.  This schedules processes internally rather than using the Linux facilities. In the boot sequence a boot loader called ROMMON (ROM monitor) starts, loads a Linux kernel, which then loads the lina_monitor, which then loads lina. The ROMMON also has a command line that can be used to load or select other software images and configurations. The names of firmware files includes a version indicator, -smp means it is for a symmetrical multiprocessor (and 64 bit architecture), and different parts also indicate if 3DES or AES is supported or not.The ASA software has a similar interface to the Cisco IOS software on routers. There is a command line interface (CLI) that can be used to query operate or configure the device. In config mode the configuration statements are entered. The configuration is initially in memory as a running-config but would normally be saved to flash memory.\n\n== Options ==\nThe 5512-X, 5515-X, 5525-X, 5545-X and 5555-X can have an extra interface card added.The 5585-X has options for SSP. SSP stands for security services processor. These range in processing power by a factor of 10, from SSP-10 SSP-20, SSP-40 and SSP-60. The ASA 5585-X has a slot for an I/O module.  This slot can be subdivided into two half width modules.On the low end models, some features are limited, and uncrippling happens with installation of a Security Plus License.  This enables more VLANs, or VPN peers, and also high availability. Cisco AnyConnect is an extra licensable feature which operates IPSec or SSL tunnels to clients on PCs, iPhones or iPads.\n\n== Models ==\nThe 5505 introduced in 2010 was a desktop unit designed for small enterprises or branch offices. It included features to reduce the need for other equipment, such as an inbuilt switch, and power over Ethernet ports.\nThe 5585-X is a higher powered unit for datacenters introduced in 2010. It runs in 32 bit mode on an Intel architecture Atom chip.\nCisco determined that most of the low end devices had too little capacity to include the features needed, such as anti-virus, or sandboxing, and so introduced a new line called next generation firewall. These run in 64 bit mode.Models as of 2018.\n\nWhat is the architecture of the Cisco ASA 5500 Series devices?",
    "context": "",
    "output": "A: The Cisco ASA 5500 Series devices are based on Linux and use a single Executable and Linkable Format program called lina to manage processes. The boot sequence involves a boot loader (ROMMON) loading a Linux kernel, followed by the lina\\_monitor, and finally lina.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the architecture of the Cisco ASA 5500 Series devices?",
      "answer": "The Cisco ASA 5500 Series devices are based on Linux and use a single Executable and Linkable Format program called lina to manage processes. The boot sequence involves a boot loader (ROMMON) loading a Linux kernel, followed by the lina\\_monitor, and finally lina.",
      "context": "Cisco ASA\n\n==Introduction==\nIn computer networking, Cisco ASA 5500 Series Adaptive Security Appliances, or simply Cisco ASA, is Cisco's line of network security devices introduced in May 2005. It succeeded three existing lines of popular Cisco products:\n\nCisco PIX, which provided firewall and network address translation (NAT) functions, ended its sale on July 28, 2008.\nCisco's IPS 4200 Series worked as intrusion prevention systems (IPS).\nCisco VPN 3000 Series Concentrators, which provided virtual private networking (VPN).The Cisco ASA is a unified threat management device, combining several network security functions in one box.\n\n\n\n== Reception and criticism ==\nCisco ASA has become one of the most widely used firewall/VPN solutions for small to medium businesses. Early reviews indicated the Cisco GUI tools for managing the device were lacking.A security flaw was identified when users customized the Clientless SSL VPN option of their ASA's but was rectified in 2015.\nAnother flaw in a WebVPN feature was fixed in 2018.In 2017 The Shadow Brokers revealed the existence of two privilege escalation exploits against the ASA called EPICBANANA and EXTRABACON. A code insertion implant called BANANAGLEE,  was made persistent by JETPLOW.\n\n== Features ==\nThe 5506W-X has a WiFi point included.\n\n== Architecture ==\nThe ASA software is based on Linux. It runs a single Executable and Linkable Format program called lina.  This schedules processes internally rather than using the Linux facilities. In the boot sequence a boot loader called ROMMON (ROM monitor) starts, loads a Linux kernel, which then loads the lina_monitor, which then loads lina. The ROMMON also has a command line that can be used to load or select other software images and configurations. The names of firmware files includes a version indicator, -smp means it is for a symmetrical multiprocessor (and 64 bit architecture), and different parts also indicate if 3DES or AES is supported or not.The ASA software has a similar interface to the Cisco IOS software on routers. There is a command line interface (CLI) that can be used to query operate or configure the device. In config mode the configuration statements are entered. The configuration is initially in memory as a running-config but would normally be saved to flash memory.\n\n== Options ==\nThe 5512-X, 5515-X, 5525-X, 5545-X and 5555-X can have an extra interface card added.The 5585-X has options for SSP. SSP stands for security services processor. These range in processing power by a factor of 10, from SSP-10 SSP-20, SSP-40 and SSP-60. The ASA 5585-X has a slot for an I/O module.  This slot can be subdivided into two half width modules.On the low end models, some features are limited, and uncrippling happens with installation of a Security Plus License.  This enables more VLANs, or VPN peers, and also high availability. Cisco AnyConnect is an extra licensable feature which operates IPSec or SSL tunnels to clients on PCs, iPhones or iPads.\n\n== Models ==\nThe 5505 introduced in 2010 was a desktop unit designed for small enterprises or branch offices. It included features to reduce the need for other equipment, such as an inbuilt switch, and power over Ethernet ports.\nThe 5585-X is a higher powered unit for datacenters introduced in 2010. It runs in 32 bit mode on an Intel architecture Atom chip.\nCisco determined that most of the low end devices had too little capacity to include the features needed, such as anti-virus, or sandboxing, and so introduced a new line called next generation firewall. These run in 64 bit mode.Models as of 2018."
    }
  },
  {
    "instruction": "Write an answer to the following question: How are hash functions used in digital signatures?",
    "context": "",
    "output": "Hash functions are used in digital signatures to provide strong data integrity and confidentiality. A hash function is applied to the data being signed, and the resulting hash value is then encrypted using the sender's private key. The encrypted hash value, along with the original data, is then transmitted or stored. When the data is received, the recipient can decrypt the hash value using the sender's public key, and then apply the same hash function to the data to verify that it has not been tampered with.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How are hash functions used in digital signatures?",
      "answer": "Hash functions are used in digital signatures to provide strong data integrity and confidentiality. A hash function is applied to the data being signed, and the resulting hash value is then encrypted using the sender's private key. The encrypted hash value, along with the original data, is then transmitted or stored. When the data is received, the recipient can decrypt the hash value using the sender's public key, and then apply the same hash function to the data to verify that it has not been tampered with."
    }
  },
  {
    "instruction": "Forensic disk controller\n\n==Introduction==\nA forensic disk controller or hardware write-block device is a specialized type of computer hard disk controller made for the purpose of gaining read-only access to computer hard drives without the risk of damaging the drive's contents.  The device is named forensic because its most common application is for use in investigations where a computer hard drive may contain evidence. Such a controller historically has been made in the form of a dongle that fits between a computer and an IDE or SCSI hard drive, but with the advent of USB and SATA, forensic disk controllers supporting these newer technologies have become widespread. Steve Bress and Mark Menz invented hard drive write blocking (US Patent 6,813,682). A device which is installed between a storage media under investigation and an investigator's computer is called a \"bridge kit\".  The bridge kit has one connector for the storage media and another connector the investigator's computer.  It allows the investigator to read, but not alter the device under investigation.The United States National Institute of Justice operates a Computer Forensics Tool Testing (CFTT) program which formally identifies the following top-level tool requirements:\n\nA hardware write block (HWB) device shall not transmit a command to a protected storage device that modifies the data on the storage device.\nAn HWB device shall return the data requested by a read operation.\nAn HWB device shall return without modification any access-significant information requested from the drive.\n\nAny error condition reported by the storage device to the HWB device shall be reported to the host.\n\n== Description ==\nForensic disk controllers intercept write commands from the host operating system, preventing them from reaching the drive. Whenever the host bus architecture supports it the controller reports that the drive is read-only. The disk controller can either deny all writes to the disk and report them as failures, or use on-board memory to cache the writes for the duration of the session.\nA disk controller that caches writes in memory presents the appearance to the operating system that the drive is writable, and uses the memory to ensure that the operating system sees changes to the individual disk sectors it attempted to overwrite.  It does this by retrieving sectors from the disk if the operating system hasn't attempted to change them, and retrieving the changed version from memory for sectors that have been changed.\n\n== Uses ==\nForensic disk controllers are most commonly associated with the process of creating a disk image, or acquisition, during forensic analysis. Their use is to prevent inadvertent modification of evidence.\nUsing hardware to protect the hard drive from writes is very important for several reasons.  First, many operating systems, including Windows, may write to any hard disk that is connected to the system.  At the very least, Windows will update the access time for any file accessed, and may write things to the disk unexpectedly - such as creating hidden folders for the recycle bin or saved hardware configuration.  Virus infections or malware on the system used for analysis may attempt to infect the disk being inspected.  Additionally, the NTFS file system may attempt to commit or rollback unfinished transactions, and/or change flags on the volume to mark it as \"in use\".  At the worst, undesired files may allocate and overwrite deleted space on the hard disk which may potentially destroy evidence in the form of previously deleted files.\nProtecting an evidence drive from writes during investigation is also important to counter potential allegations that the contents of the drive were altered during the investigation. Of course, this can be alleged anyway, but in the absence of technology to protect a drive from writes, there is no way for such an allegation to be refuted.\nQuestion: How can hidden folders be created on a hard disk?",
    "context": "",
    "output": "Answer: Hidden folders can be created on a hard disk by the operating system, such as when the recycle bin or saved hardware configuration is stored.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can hidden folders be created on a hard disk?",
      "answer": "Hidden folders can be created on a hard disk by the operating system, such as when the recycle bin or saved hardware configuration is stored.",
      "context": "Forensic disk controller\n\n==Introduction==\nA forensic disk controller or hardware write-block device is a specialized type of computer hard disk controller made for the purpose of gaining read-only access to computer hard drives without the risk of damaging the drive's contents.  The device is named forensic because its most common application is for use in investigations where a computer hard drive may contain evidence. Such a controller historically has been made in the form of a dongle that fits between a computer and an IDE or SCSI hard drive, but with the advent of USB and SATA, forensic disk controllers supporting these newer technologies have become widespread. Steve Bress and Mark Menz invented hard drive write blocking (US Patent 6,813,682). A device which is installed between a storage media under investigation and an investigator's computer is called a \"bridge kit\".  The bridge kit has one connector for the storage media and another connector the investigator's computer.  It allows the investigator to read, but not alter the device under investigation.The United States National Institute of Justice operates a Computer Forensics Tool Testing (CFTT) program which formally identifies the following top-level tool requirements:\n\nA hardware write block (HWB) device shall not transmit a command to a protected storage device that modifies the data on the storage device.\nAn HWB device shall return the data requested by a read operation.\nAn HWB device shall return without modification any access-significant information requested from the drive.\n\nAny error condition reported by the storage device to the HWB device shall be reported to the host.\n\n== Description ==\nForensic disk controllers intercept write commands from the host operating system, preventing them from reaching the drive. Whenever the host bus architecture supports it the controller reports that the drive is read-only. The disk controller can either deny all writes to the disk and report them as failures, or use on-board memory to cache the writes for the duration of the session.\nA disk controller that caches writes in memory presents the appearance to the operating system that the drive is writable, and uses the memory to ensure that the operating system sees changes to the individual disk sectors it attempted to overwrite.  It does this by retrieving sectors from the disk if the operating system hasn't attempted to change them, and retrieving the changed version from memory for sectors that have been changed.\n\n== Uses ==\nForensic disk controllers are most commonly associated with the process of creating a disk image, or acquisition, during forensic analysis. Their use is to prevent inadvertent modification of evidence.\nUsing hardware to protect the hard drive from writes is very important for several reasons.  First, many operating systems, including Windows, may write to any hard disk that is connected to the system.  At the very least, Windows will update the access time for any file accessed, and may write things to the disk unexpectedly - such as creating hidden folders for the recycle bin or saved hardware configuration.  Virus infections or malware on the system used for analysis may attempt to infect the disk being inspected.  Additionally, the NTFS file system may attempt to commit or rollback unfinished transactions, and/or change flags on the volume to mark it as \"in use\".  At the worst, undesired files may allocate and overwrite deleted space on the hard disk which may potentially destroy evidence in the form of previously deleted files.\nProtecting an evidence drive from writes during investigation is also important to counter potential allegations that the contents of the drive were altered during the investigation. Of course, this can be alleged anyway, but in the absence of technology to protect a drive from writes, there is no way for such an allegation to be refuted."
    }
  },
  {
    "instruction": "GNUnet\n\n==Introduction==\nGNUnet is a software framework for decentralized, peer-to-peer networking and an official GNU package. The framework offers link encryption, peer discovery, resource allocation, communication over many transports (such as TCP, UDP, HTTP, HTTPS, WLAN and Bluetooth) and various basic peer-to-peer algorithms for routing, multicast and network size estimation.GNUnet's basic network topology is that of a mesh network. GNUnet includes a distributed hash table (DHT) which is a randomized variant of Kademlia that can still efficiently route in small-world networks. GNUnet offers a \"F2F topology\" option for restricting connections to only the users' trusted friends. The users' friends' own friends (and so on) can then indirectly exchange files with the users' computer, never using its IP address directly.\nGNUnet uses Uniform resource identifiers (not approved by IANA, although an application has been made). GNUnet URIs consist of two major parts: the module and the module specific identifier. A GNUnet URI is of form gnunet://module/identifier where module is the module name and identifier is a module specific string.\nThe primary codebase is written in C, but there are  bindings in other languages to produce an API for developing extensions in those languages. GNUnet is part of the GNU Project. It has gained interest in the hacker community after the PRISM revelations.GNUnet consists of several subsystems, of which essential ones are Transport and Core subsystems. Transport subsystem provides insecure link-layer communications, while Core provides peer discovery and encryption. On top of the core subsystem various applications are built.\nGNUnet includes various P2P applications in the main distribution of the framework, including filesharing, chat and VPN; additionally, a few external projects (such as secushare) are also extending the GNUnet infrastructure.\nGNUnet is unrelated to the older Gnutella P2P protocol. Gnutella is not an official GNU project, while GNUnet is.\n\n== Transport ==\nOriginally, GNUnet used UDP for underlying transport. Now GNUnet transport subsystem provides multiple options, such as TCP and SMTP.The communication port, officially registered at IANA, is 2086 (tcp + udp).\n\n== Trust system ==\nGNUnet provides trust system based on an excess-based economic model. The idea of employing an economic system is taken from the MojoNation network.GNUnet network has no trusted entities so it is impossible to maintain a global reputation. Instead, each peer maintains its own trust for each of its local links.\nWhen resources, such as bandwidth and CPU time, are in excess, the peer provides them to all requesting neighbors without reducing trust or otherwise charging them. When a node is under stress it drops requests from its neighbor nodes having lower internal trust value. However, when the peer has less resources than enough to fulfill everyone's requests, it denies requests of those neighbors that it trusts less and charges others by reducing their trust.\n\n== File sharing ==\nThe primary application at this point is anonymous, censorship-resistant file-sharing, allowing users to anonymously publish or retrieve information of all kinds. The GNUnet protocol which provides anonymity is called GAP (GNUnet anonymity protocol). GNUnet FS can additionally make use of GNU libextractor to automatically annotate shared files with metadata.\n\n\n*** File encoding ***\nFiles shared with GNUnet are ECRS (An Encoding for Censorship-Resistant Sharing) coded.All content is represented as GBlocks. Each GBlock contains 1024 bytes. There are several types of GBlocks, each of them serves a particular purpose. Any GBlock \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n   is uniquely identified by its RIPEMD-160 hash \n  \n    \n      \n        H\n        (\n        B\n        )\n      \n    \n    {\\displaystyle H(B)}\n  .\nDBlocks store actual file contents and nothing else. File is split at 1024 byte boundaries and resulting chunks are stored in DBlocks. DBlocks are linked together into Merkle tree by means of IBlocks that store DBlock identifiers.\nBlocks are encrypted with a symmetric key derived from \n  \n    \n      \n        H\n        (\n        B\n        )\n      \n    \n    {\\displaystyle H(B)}\n   when they are stored in the network.\n\n\n*** Queries and replies ***\nGNUnet Anonymity Protocol consists of queries and replies. Depending on load of the forwarding node, messages are forwarded to zero or more nodes.\nQueries are used to search for content and request data blocks.\nQuery contains resource identifier, reply address, priority and TTL (Time-to-Live).\nResource identifier of datum \n  \n    \n      \n        Q\n      \n    \n    {\\displaystyle Q}\n   is a triple-hash \n  \n    \n      \n        H\n        (\n        H\n        (\n        H\n        (\n        Q\n        )\n        )\n        )\n      \n    \n    {\\displaystyle H(H(H(Q)))}\n  . Peer that replies to query provides \n  \n    \n      \n        H\n        (\n        H\n        (\n        Q\n        )\n        )\n      \n    \n    {\\displaystyle H(H(Q))}\n  to prove that it indeed has the requested resource without providing \n  \n    \n      \n        H\n        (\n        Q\n        )\n      \n    \n    {\\displaystyle H(Q)}\n   to intermediate nodes, so intermediate nodes can't decrypt \n  \n    \n      \n        Q\n      \n    \n    {\\displaystyle Q}\n  .\nReply address is the major difference compared to Freenet protocol. While in Freenet reply always propagates back using the same path as the query, in GNUnet the path may be shorter. Peer receiving a query may drop it, forward it without rewriting reply address or indirect it by replacing reply address with its own address. By indirecting queries peer provides cover traffic for its own queries, while by forwarding them peer avoids being a link in reply propagation and preserves its bandwidth. This feature allows the user to trade anonymity for efficiency. User can specify an anonymity level for each publish, search and download operation. An anonymity level of zero can be used to select non-anonymous file-sharing. GNUnet's DHT infrastructure is only used if non-anonymous file-sharing is specified. The anonymity level determines how much cover traffic a peer must have to hide the user's own actions.\nPriority specifies how much of its trust user wants to spend in case of a resource shortage.\nTTL is used to prevent queries from staying in the network for too long.\n\n\n*** File sharing URIs ***\nThe fs module identifier consists of either chk, sks, ksk or loc followed by a slash and a category specific value. Most URIs contain hashes, which are encoded in base32hex.\nchk identifies files, typically: gnunet://fs/chk/[file hash].[query hash].[file size in bytes]File hash is the hash of the plaintext file, which allows decrypting it once it is downloaded. Query hash is the hash of topmost GBlock which allows downloading the whole tree of GBlocks that contain encrypted file. File size is required to determine the shape of the tree.sks identifies files within namespaces, typically: gnunet://fs/sks/NAMESPACE/IDENTIFIER\nksk identifies search queries, typically: gnunet://fs/ksk/KEYWORD[+KEYWORD]*\nloc identifies a datum on a specific machine, typically: gnunet://fs/loc/PEER/QUERY.TYPE.KEY.SIZE\n\n\n**** Examples ****\nA type of GNUnet filesharing URI pointing to a specific copy of GNU GPL license text:\n\ngnunet://fs/chk/9E4MDN4VULE8KJG6U1C8FKH5HA8C5CHSJTILRTTPGK8MJ6VHORERHE68JU8Q0FDTOH1DGLUJ3NLE99N0ML0N9PIBAGKG7MNPBTT6UKG.1I823C58O3LKS24LLI9KB384LH82LGF9GUQRJHACCUINSCQH36SI4NF88CMAET3T3BHI93D4S0M5CC6MVDL1K8GFKVBN69Q6T307U6O.17992\nAnother type of GNUnet filesharing URI, pointing to the search results of a search with keyword \"gpl\":\n\ngnunet://fs/ksk/gpl\n\n== GNU Name System ==\nGNUnet includes an implementation of the GNU Name System (GNS), a decentralized and censorship-resistant replacement for DNS. In GNS, each user manages their own zones and can delegate subdomains to zones managed by other users. Lookups of records defined by other users are performed using GNUnet's DHT.\n\n== Protocol translation ==\nGNUnet can tunnel IP traffic over the peer-to-peer network. If necessary, GNUnet can perform IPv4-IPv6 protocol translation in the process. GNUnet provides a DNS Application-level gateway to proxy DNS requests and map addresses to the desired address family as necessary. This way, GNUnet offers a possible technology to facilitate IPv6 transition. Furthermore, in combination with GNS, GNUnet's protocol translation system can be used to access hidden services \u2014 IP-based services that run locally at some peer in the network and which can only be accessed by resolving a GNS name.\n\n== Social API ==\nGabor X Toth published in early September 2013 a thesis to present the design of a social messaging service for the GNUnet peer-to-peer framework that offers scalability, extensibility, and end-to-end encrypted communication. The scalability property is achieved through multicast message delivery, while extensibility is made possible by using PSYC (Protocol for SYnchronous Conferencing), which provides an extensible RPC (Remote Procedure Call) syntax that can evolve over time without having to upgrade the software on all nodes in the network. Another key feature provided by the PSYC layer are stateful multicast channels, which are used to store e.g. user profiles. End-to-end encrypted communication is provided by the mesh service of GNUnet, upon which the multicast channels are built. Pseudonymous users and social places in the system have cryptographical identities \u2014 identified by their public key \u2014 these are mapped to human memorable names using GNS (GNU Name System), where each pseudonym has a zone pointing to its places.\nThat is the required building block for turning the GNUnet framework into a fully peer-to-peer social networking platform.\n\n== Chat ==\nA chat has been implemented in the CADET module, for which a GTK interface for GNOME exists, specifically designed for the emerging Linux phones (such as the Librem 5 or the PinePhone).\n\n== Further references ==\n\nQ: How does GNUnet ensure resource allocation and communication over multiple transports?",
    "context": "",
    "output": "A: GNUnet offers link encryption, peer discovery, resource allocation, and communication over many transports, such as TCP, UDP, HTTP, HTTPS, WLAN, and Bluetooth.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does GNUnet ensure resource allocation and communication over multiple transports?",
      "answer": "GNUnet offers link encryption, peer discovery, resource allocation, and communication over many transports, such as TCP, UDP, HTTP, HTTPS, WLAN, and Bluetooth.",
      "context": "GNUnet\n\n==Introduction==\nGNUnet is a software framework for decentralized, peer-to-peer networking and an official GNU package. The framework offers link encryption, peer discovery, resource allocation, communication over many transports (such as TCP, UDP, HTTP, HTTPS, WLAN and Bluetooth) and various basic peer-to-peer algorithms for routing, multicast and network size estimation.GNUnet's basic network topology is that of a mesh network. GNUnet includes a distributed hash table (DHT) which is a randomized variant of Kademlia that can still efficiently route in small-world networks. GNUnet offers a \"F2F topology\" option for restricting connections to only the users' trusted friends. The users' friends' own friends (and so on) can then indirectly exchange files with the users' computer, never using its IP address directly.\nGNUnet uses Uniform resource identifiers (not approved by IANA, although an application has been made). GNUnet URIs consist of two major parts: the module and the module specific identifier. A GNUnet URI is of form gnunet://module/identifier where module is the module name and identifier is a module specific string.\nThe primary codebase is written in C, but there are  bindings in other languages to produce an API for developing extensions in those languages. GNUnet is part of the GNU Project. It has gained interest in the hacker community after the PRISM revelations.GNUnet consists of several subsystems, of which essential ones are Transport and Core subsystems. Transport subsystem provides insecure link-layer communications, while Core provides peer discovery and encryption. On top of the core subsystem various applications are built.\nGNUnet includes various P2P applications in the main distribution of the framework, including filesharing, chat and VPN; additionally, a few external projects (such as secushare) are also extending the GNUnet infrastructure.\nGNUnet is unrelated to the older Gnutella P2P protocol. Gnutella is not an official GNU project, while GNUnet is.\n\n== Transport ==\nOriginally, GNUnet used UDP for underlying transport. Now GNUnet transport subsystem provides multiple options, such as TCP and SMTP.The communication port, officially registered at IANA, is 2086 (tcp + udp).\n\n== Trust system ==\nGNUnet provides trust system based on an excess-based economic model. The idea of employing an economic system is taken from the MojoNation network.GNUnet network has no trusted entities so it is impossible to maintain a global reputation. Instead, each peer maintains its own trust for each of its local links.\nWhen resources, such as bandwidth and CPU time, are in excess, the peer provides them to all requesting neighbors without reducing trust or otherwise charging them. When a node is under stress it drops requests from its neighbor nodes having lower internal trust value. However, when the peer has less resources than enough to fulfill everyone's requests, it denies requests of those neighbors that it trusts less and charges others by reducing their trust.\n\n== File sharing ==\nThe primary application at this point is anonymous, censorship-resistant file-sharing, allowing users to anonymously publish or retrieve information of all kinds. The GNUnet protocol which provides anonymity is called GAP (GNUnet anonymity protocol). GNUnet FS can additionally make use of GNU libextractor to automatically annotate shared files with metadata.\n\n\n*** File encoding ***\nFiles shared with GNUnet are ECRS (An Encoding for Censorship-Resistant Sharing) coded.All content is represented as GBlocks. Each GBlock contains 1024 bytes. There are several types of GBlocks, each of them serves a particular purpose. Any GBlock \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n   is uniquely identified by its RIPEMD-160 hash \n  \n    \n      \n        H\n        (\n        B\n        )\n      \n    \n    {\\displaystyle H(B)}\n  .\nDBlocks store actual file contents and nothing else. File is split at 1024 byte boundaries and resulting chunks are stored in DBlocks. DBlocks are linked together into Merkle tree by means of IBlocks that store DBlock identifiers.\nBlocks are encrypted with a symmetric key derived from \n  \n    \n      \n        H\n        (\n        B\n        )\n      \n    \n    {\\displaystyle H(B)}\n   when they are stored in the network.\n\n\n*** Queries and replies ***\nGNUnet Anonymity Protocol consists of queries and replies. Depending on load of the forwarding node, messages are forwarded to zero or more nodes.\nQueries are used to search for content and request data blocks.\nQuery contains resource identifier, reply address, priority and TTL (Time-to-Live).\nResource identifier of datum \n  \n    \n      \n        Q\n      \n    \n    {\\displaystyle Q}\n   is a triple-hash \n  \n    \n      \n        H\n        (\n        H\n        (\n        H\n        (\n        Q\n        )\n        )\n        )\n      \n    \n    {\\displaystyle H(H(H(Q)))}\n  . Peer that replies to query provides \n  \n    \n      \n        H\n        (\n        H\n        (\n        Q\n        )\n        )\n      \n    \n    {\\displaystyle H(H(Q))}\n  to prove that it indeed has the requested resource without providing \n  \n    \n      \n        H\n        (\n        Q\n        )\n      \n    \n    {\\displaystyle H(Q)}\n   to intermediate nodes, so intermediate nodes can't decrypt \n  \n    \n      \n        Q\n      \n    \n    {\\displaystyle Q}\n  .\nReply address is the major difference compared to Freenet protocol. While in Freenet reply always propagates back using the same path as the query, in GNUnet the path may be shorter. Peer receiving a query may drop it, forward it without rewriting reply address or indirect it by replacing reply address with its own address. By indirecting queries peer provides cover traffic for its own queries, while by forwarding them peer avoids being a link in reply propagation and preserves its bandwidth. This feature allows the user to trade anonymity for efficiency. User can specify an anonymity level for each publish, search and download operation. An anonymity level of zero can be used to select non-anonymous file-sharing. GNUnet's DHT infrastructure is only used if non-anonymous file-sharing is specified. The anonymity level determines how much cover traffic a peer must have to hide the user's own actions.\nPriority specifies how much of its trust user wants to spend in case of a resource shortage.\nTTL is used to prevent queries from staying in the network for too long.\n\n\n*** File sharing URIs ***\nThe fs module identifier consists of either chk, sks, ksk or loc followed by a slash and a category specific value. Most URIs contain hashes, which are encoded in base32hex.\nchk identifies files, typically: gnunet://fs/chk/[file hash].[query hash].[file size in bytes]File hash is the hash of the plaintext file, which allows decrypting it once it is downloaded. Query hash is the hash of topmost GBlock which allows downloading the whole tree of GBlocks that contain encrypted file. File size is required to determine the shape of the tree.sks identifies files within namespaces, typically: gnunet://fs/sks/NAMESPACE/IDENTIFIER\nksk identifies search queries, typically: gnunet://fs/ksk/KEYWORD[+KEYWORD]*\nloc identifies a datum on a specific machine, typically: gnunet://fs/loc/PEER/QUERY.TYPE.KEY.SIZE\n\n\n**** Examples ****\nA type of GNUnet filesharing URI pointing to a specific copy of GNU GPL license text:\n\ngnunet://fs/chk/9E4MDN4VULE8KJG6U1C8FKH5HA8C5CHSJTILRTTPGK8MJ6VHORERHE68JU8Q0FDTOH1DGLUJ3NLE99N0ML0N9PIBAGKG7MNPBTT6UKG.1I823C58O3LKS24LLI9KB384LH82LGF9GUQRJHACCUINSCQH36SI4NF88CMAET3T3BHI93D4S0M5CC6MVDL1K8GFKVBN69Q6T307U6O.17992\nAnother type of GNUnet filesharing URI, pointing to the search results of a search with keyword \"gpl\":\n\ngnunet://fs/ksk/gpl\n\n== GNU Name System ==\nGNUnet includes an implementation of the GNU Name System (GNS), a decentralized and censorship-resistant replacement for DNS. In GNS, each user manages their own zones and can delegate subdomains to zones managed by other users. Lookups of records defined by other users are performed using GNUnet's DHT.\n\n== Protocol translation ==\nGNUnet can tunnel IP traffic over the peer-to-peer network. If necessary, GNUnet can perform IPv4-IPv6 protocol translation in the process. GNUnet provides a DNS Application-level gateway to proxy DNS requests and map addresses to the desired address family as necessary. This way, GNUnet offers a possible technology to facilitate IPv6 transition. Furthermore, in combination with GNS, GNUnet's protocol translation system can be used to access hidden services \u2014 IP-based services that run locally at some peer in the network and which can only be accessed by resolving a GNS name.\n\n== Social API ==\nGabor X Toth published in early September 2013 a thesis to present the design of a social messaging service for the GNUnet peer-to-peer framework that offers scalability, extensibility, and end-to-end encrypted communication. The scalability property is achieved through multicast message delivery, while extensibility is made possible by using PSYC (Protocol for SYnchronous Conferencing), which provides an extensible RPC (Remote Procedure Call) syntax that can evolve over time without having to upgrade the software on all nodes in the network. Another key feature provided by the PSYC layer are stateful multicast channels, which are used to store e.g. user profiles. End-to-end encrypted communication is provided by the mesh service of GNUnet, upon which the multicast channels are built. Pseudonymous users and social places in the system have cryptographical identities \u2014 identified by their public key \u2014 these are mapped to human memorable names using GNS (GNU Name System), where each pseudonym has a zone pointing to its places.\nThat is the required building block for turning the GNUnet framework into a fully peer-to-peer social networking platform.\n\n== Chat ==\nA chat has been implemented in the CADET module, for which a GTK interface for GNOME exists, specifically designed for the emerging Linux phones (such as the Librem 5 or the PinePhone).\n\n== Further references =="
    }
  },
  {
    "instruction": "TCP Gender Changer\n\n==Introduction==\nTCP Gender Changer is a method in computer networking for making an internal TCP/IP based network server accessible beyond its protective firewall. \n\n\n\n== Mechanism ==\nIt consists of two nodes, one resides on the internal the local area network where it can access the desired server, and the other node runs outside of the local area network, where the client can access it. These nodes are respectively called CC (Connect-Connect) and LL (Listen-Listen).\nThe reason behind naming the nodes are the fact that Connect-Connect node initiates two connections one to the Listen-Listen node and one to the actual server. The Listen-Listen node, however, passively Listens on two TCP/IP ports, one to receive a connection from CC and the other one for an incoming connection from the client.\nThe CC node, which runs inside the network will establish a control connection to the LL, and waiting for LL's signal to open a \nconnection to the internal server. Upon receiving a client connection LL will signal the CC node to connect the server, once done CC will let LL know of the result and if successful LL will keep the client connection and thus the client and server can communicate while CC and LL both relay the data back and forth.\n\n== Use cases ==\nOne of the cases where it can be very useful is to connect to a desktop machine behind a firewall running VNC, which would make the desktop remotely accessible over the network and beyond the firewall. Another useful scenario would be to create a VPN using PPP over SSH, or even simply using SSH to connect to an internal Unix based server.\n\nBased on the above text, answer a question. How does the TCP Gender Changer method enable communication between a client outside a firewall and a server inside a local area network (LAN)?",
    "context": "",
    "output": "The TCP Gender Changer method uses two nodes, CC and LL, to facilitate communication between a client outside the LAN and a server inside the LAN. CC runs inside the LAN and establishes a control connection with LL, which listens on two TCP/IP ports for connections from CC and the client. When the client connects to LL, CC opens a connection to the internal server, and the data is relayed back and forth between the client and server through LL and CC.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the TCP Gender Changer method enable communication between a client outside a firewall and a server inside a local area network (LAN)?",
      "answer": "The TCP Gender Changer method uses two nodes, CC and LL, to facilitate communication between a client outside the LAN and a server inside the LAN. CC runs inside the LAN and establishes a control connection with LL, which listens on two TCP/IP ports for connections from CC and the client. When the client connects to LL, CC opens a connection to the internal server, and the data is relayed back and forth between the client and server through LL and CC.",
      "context": "TCP Gender Changer\n\n==Introduction==\nTCP Gender Changer is a method in computer networking for making an internal TCP/IP based network server accessible beyond its protective firewall. \n\n\n\n== Mechanism ==\nIt consists of two nodes, one resides on the internal the local area network where it can access the desired server, and the other node runs outside of the local area network, where the client can access it. These nodes are respectively called CC (Connect-Connect) and LL (Listen-Listen).\nThe reason behind naming the nodes are the fact that Connect-Connect node initiates two connections one to the Listen-Listen node and one to the actual server. The Listen-Listen node, however, passively Listens on two TCP/IP ports, one to receive a connection from CC and the other one for an incoming connection from the client.\nThe CC node, which runs inside the network will establish a control connection to the LL, and waiting for LL's signal to open a \nconnection to the internal server. Upon receiving a client connection LL will signal the CC node to connect the server, once done CC will let LL know of the result and if successful LL will keep the client connection and thus the client and server can communicate while CC and LL both relay the data back and forth.\n\n== Use cases ==\nOne of the cases where it can be very useful is to connect to a desktop machine behind a firewall running VNC, which would make the desktop remotely accessible over the network and beyond the firewall. Another useful scenario would be to create a VPN using PPP over SSH, or even simply using SSH to connect to an internal Unix based server."
    }
  },
  {
    "instruction": "Context: WS-SecurityPolicy\n\n==Introduction==\nWS-SecurityPolicy is a web services specification, created by IBM and 12 co-authors, that has become an OASIS standard as of version 1.2. It extends the fundamental security protocols specified by the WS-Security, WS-Trust and WS-SecureConversation by offering mechanisms to represent the capabilities and requirements of web services as policies. Security policy assertions are based on the WS-Policy framework. \nPolicy assertions can be used to require more generic security attributes like transport layer security <TransportBinding>, message level security <AsymmetricBinding> or timestamps, and specific attributes like token types. \nMost policy assertion can be found in following categories:\n\nProtection assertions identify the elements of a message that are required to be signed, encrypted or existent.\nToken assertions specify allowed token formats (SAML, X509, Username etc.).\nSecurity binding assertions control basic security safeguards like transport and message level security, cryptographic algorithm suite and required timestamps.\nSupporting token assertions add functions like user sign-on using a username token.Policies can be used to drive development tools to generate code with certain capabilities, or may be used at runtime to negotiate the security aspects of web service communication. Policies may be attached to WSDL elements such as service, port, operation and message, as defined in WS Policy Attachment.\n\n\n\n== Sample Policies ==\nNamespaces used by the following XML-snippets:\n\n<p:Policy \n   xmlns:p\n\n== Other WS policy languages ==\nThe term Web Services Security Policy Language is used for two different XML-based languages:\n\nAs described above, based on the WS-Policy framework, as defined in, published as version 1.3 in Feb. 2009\nWSPL, based on XACML profile for Web-services, but that was not finalized.\nAnswer this question: How does WS-SecurityPolicy extend the security protocols specified by WS-Security, WS-Trust, and WS-SecureConversation?",
    "context": "",
    "output": "WS-SecurityPolicy extends the fundamental security protocols specified by WS-Security, WS-Trust, and WS-SecureConversation by offering mechanisms to represent the capabilities and requirements of web services as policies. These policies are based on the WS-Policy framework and provide a way to enforce security measures such as transport layer security, message level security, cryptographic algorithm suite, and required timestamps.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does WS-SecurityPolicy extend the security protocols specified by WS-Security, WS-Trust, and WS-SecureConversation?",
      "answer": "WS-SecurityPolicy extends the fundamental security protocols specified by WS-Security, WS-Trust, and WS-SecureConversation by offering mechanisms to represent the capabilities and requirements of web services as policies. These policies are based on the WS-Policy framework and provide a way to enforce security measures such as transport layer security, message level security, cryptographic algorithm suite, and required timestamps.",
      "context": "WS-SecurityPolicy\n\n==Introduction==\nWS-SecurityPolicy is a web services specification, created by IBM and 12 co-authors, that has become an OASIS standard as of version 1.2. It extends the fundamental security protocols specified by the WS-Security, WS-Trust and WS-SecureConversation by offering mechanisms to represent the capabilities and requirements of web services as policies. Security policy assertions are based on the WS-Policy framework. \nPolicy assertions can be used to require more generic security attributes like transport layer security <TransportBinding>, message level security <AsymmetricBinding> or timestamps, and specific attributes like token types. \nMost policy assertion can be found in following categories:\n\nProtection assertions identify the elements of a message that are required to be signed, encrypted or existent.\nToken assertions specify allowed token formats (SAML, X509, Username etc.).\nSecurity binding assertions control basic security safeguards like transport and message level security, cryptographic algorithm suite and required timestamps.\nSupporting token assertions add functions like user sign-on using a username token.Policies can be used to drive development tools to generate code with certain capabilities, or may be used at runtime to negotiate the security aspects of web service communication. Policies may be attached to WSDL elements such as service, port, operation and message, as defined in WS Policy Attachment.\n\n\n\n== Sample Policies ==\nNamespaces used by the following XML-snippets:\n\n<p:Policy \n   xmlns:p\n\n== Other WS policy languages ==\nThe term Web Services Security Policy Language is used for two different XML-based languages:\n\nAs described above, based on the WS-Policy framework, as defined in, published as version 1.3 in Feb. 2009\nWSPL, based on XACML profile for Web-services, but that was not finalized."
    }
  },
  {
    "instruction": "Security event manager\n\n==Introduction==\nSecurity event management (SEM), and the related SIM and SIEM, are computer security disciplines that use data inspection tools to centralize the storage and interpretation of logs or events generated by other software running on a network.\n\n== Overview ==\nThe acronyms SEM, SIM and SIEM have sometimes been used interchangeably, but generally refer to the different primary focus of products:\n\nLog management: Focus on simple collection and storage of log messages and audit trails\nSecurity information management (SIM): Long-term storage as well as analysis and reporting of log data.\nSecurity event manager (SEM): Real-time monitoring, correlation of events, notifications and console views.\nSecurity information and event management (SIEM): Combines SIM and SEM and provides real-time analysis of security alerts generated by network hardware and applications.\n\n== Event logs ==\nMany systems and applications which run on a computer network generate events which are kept in event logs. These logs are essentially lists of activities that occurred, with records of new events being appended to the end of the logs as they occur. Protocols, such as syslog and SNMP, can be used to transport these events, as they occur, to logging software that is not on the same host on which the events are generated. The better SEMs provide a flexible array of supported communication protocols to allow for the broadest range of event collection.\nIt is beneficial to send all events to a centralized SEM system for the following reasons:\n\nAccess to all logs can be provided through a consistent central interface.\nThe SEM can provide secure, forensically sound storage and archival of event logs (this is also a classic log management function).\nPowerful reporting tools can be run on the SEM to mine the logs for useful information.\nEvents can be parsed as they hit the SEM for significance, and alerts and notifications can be immediately sent out to interested parties as warranted.\nRelated events which occur on multiple systems can be detected which would be very difficult to detect if each system had a separate log.\nEvents which are sent from a system to a SEM remain on the SEM even if the sending system fails or the logs on it are accidentally or intentionally erased.\n\n== Security analysis ==\nAlthough centralised logging has existed for long time, SEMs are a relatively new idea, pioneered in 1999 by a small company called E-Security, and are still evolving rapidly. The key feature of a Security Event Management tool is the ability to analyse the collected logs to highlight events or behaviors of interest, for example an Administrator or Super User logon, outside of normal business hours. This may include attaching contextual information, such as host information (value, owner, location, etc.), identity information (user info related to accounts referenced in the event like first/last name, workforce ID, manager's name, etc.), and so forth. This contextual information can be leveraged to provide better correlation and reporting capabilities and is often referred to as Meta-data. Products may also integrate with external remediation, ticketing, and workflow tools to assist with the process of incident resolution. The better SEMs will provide a flexible, extensible set of integration capabilities to ensure that the SEM will work with most customer environments.\n\n== Regulatory requirements ==\nSEMs are often sold to help satisfy U.S. regulatory requirements such as those of Sarbanes\u2013Oxley, PCI-DSS, GLBA.\n\n== Standardization ==\nOne of the major problems in the SEM space is the difficulty in consistently analyzing event data. Every vendor, and indeed in many cases different products by one vendor, uses a different proprietary event data format and delivery method. Even in cases where a \"standard\" is used for some part of the chain, like Syslog, the standards don't typically contain enough guidance to assist developers in how to generate events, administrators in how to gather them correctly and reliably, and consumers to analyze them effectively.\nAs an attempt to combat this problem, a couple parallel standardization efforts are underway. First, The Open Group is updating their circa 1997 XDAS standard, which never made it past draft status. This new effort, dubbed XDAS v2, will attempt to formalize an event format including which data should be included in events and how it should be expressed. The XDAS v2 standard will not include event delivery standards but other standards in development by the Distributed Management Task Force may provide a wrapper.\nIn addition, MITRE developed efforts to unify event reporting with the Common Event Expression (CEE) which was somewhat broader in scope as it attempted to define an event structure as well as delivery methods. The project, however, ran out of funding in 2014.\n\nQ: How does Security Information and Event Management (SIEM) combine SIM and SEM?",
    "context": "",
    "output": "A: SIEM combines the long-term storage, analysis, and reporting capabilities of SIM with the real-time monitoring and correlation features of SEM.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does Security Information and Event Management (SIEM) combine SIM and SEM?",
      "answer": "SIEM combines the long-term storage, analysis, and reporting capabilities of SIM with the real-time monitoring and correlation features of SEM.",
      "context": "Security event manager\n\n==Introduction==\nSecurity event management (SEM), and the related SIM and SIEM, are computer security disciplines that use data inspection tools to centralize the storage and interpretation of logs or events generated by other software running on a network.\n\n== Overview ==\nThe acronyms SEM, SIM and SIEM have sometimes been used interchangeably, but generally refer to the different primary focus of products:\n\nLog management: Focus on simple collection and storage of log messages and audit trails\nSecurity information management (SIM): Long-term storage as well as analysis and reporting of log data.\nSecurity event manager (SEM): Real-time monitoring, correlation of events, notifications and console views.\nSecurity information and event management (SIEM): Combines SIM and SEM and provides real-time analysis of security alerts generated by network hardware and applications.\n\n== Event logs ==\nMany systems and applications which run on a computer network generate events which are kept in event logs. These logs are essentially lists of activities that occurred, with records of new events being appended to the end of the logs as they occur. Protocols, such as syslog and SNMP, can be used to transport these events, as they occur, to logging software that is not on the same host on which the events are generated. The better SEMs provide a flexible array of supported communication protocols to allow for the broadest range of event collection.\nIt is beneficial to send all events to a centralized SEM system for the following reasons:\n\nAccess to all logs can be provided through a consistent central interface.\nThe SEM can provide secure, forensically sound storage and archival of event logs (this is also a classic log management function).\nPowerful reporting tools can be run on the SEM to mine the logs for useful information.\nEvents can be parsed as they hit the SEM for significance, and alerts and notifications can be immediately sent out to interested parties as warranted.\nRelated events which occur on multiple systems can be detected which would be very difficult to detect if each system had a separate log.\nEvents which are sent from a system to a SEM remain on the SEM even if the sending system fails or the logs on it are accidentally or intentionally erased.\n\n== Security analysis ==\nAlthough centralised logging has existed for long time, SEMs are a relatively new idea, pioneered in 1999 by a small company called E-Security, and are still evolving rapidly. The key feature of a Security Event Management tool is the ability to analyse the collected logs to highlight events or behaviors of interest, for example an Administrator or Super User logon, outside of normal business hours. This may include attaching contextual information, such as host information (value, owner, location, etc.), identity information (user info related to accounts referenced in the event like first/last name, workforce ID, manager's name, etc.), and so forth. This contextual information can be leveraged to provide better correlation and reporting capabilities and is often referred to as Meta-data. Products may also integrate with external remediation, ticketing, and workflow tools to assist with the process of incident resolution. The better SEMs will provide a flexible, extensible set of integration capabilities to ensure that the SEM will work with most customer environments.\n\n== Regulatory requirements ==\nSEMs are often sold to help satisfy U.S. regulatory requirements such as those of Sarbanes\u2013Oxley, PCI-DSS, GLBA.\n\n== Standardization ==\nOne of the major problems in the SEM space is the difficulty in consistently analyzing event data. Every vendor, and indeed in many cases different products by one vendor, uses a different proprietary event data format and delivery method. Even in cases where a \"standard\" is used for some part of the chain, like Syslog, the standards don't typically contain enough guidance to assist developers in how to generate events, administrators in how to gather them correctly and reliably, and consumers to analyze them effectively.\nAs an attempt to combat this problem, a couple parallel standardization efforts are underway. First, The Open Group is updating their circa 1997 XDAS standard, which never made it past draft status. This new effort, dubbed XDAS v2, will attempt to formalize an event format including which data should be included in events and how it should be expressed. The XDAS v2 standard will not include event delivery standards but other standards in development by the Distributed Management Task Force may provide a wrapper.\nIn addition, MITRE developed efforts to unify event reporting with the Common Event Expression (CEE) which was somewhat broader in scope as it attempted to define an event structure as well as delivery methods. The project, however, ran out of funding in 2014."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the role of the private sector in ensuring digital supply chain security?",
    "context": "",
    "output": "The private sector plays a significant role in ensuring digital supply chain security through frameworks such as SLSA (Supply-chain Levels for Software Artifacts). SLSA is an end-to-end framework for ensuring the integrity of software artifacts throughout the software supply chain.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of the private sector in ensuring digital supply chain security?",
      "answer": "The private sector plays a significant role in ensuring digital supply chain security through frameworks such as SLSA (Supply-chain Levels for Software Artifacts). SLSA is an end-to-end framework for ensuring the integrity of software artifacts throughout the software supply chain."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is mandatory certificate transparency, and which browsers enforce it?",
    "context": "",
    "output": "Mandatory certificate transparency requires TLS certificates to have proof of being logged with CT, enforced by some browsers either through SCTs embedded into the certificate, an extension during the TLS handshake, or through OCSP. Currently, Google Chrome and Mozilla Firefox enforce this requirement.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is mandatory certificate transparency, and which browsers enforce it?",
      "answer": "Mandatory certificate transparency requires TLS certificates to have proof of being logged with CT, enforced by some browsers either through SCTs embedded into the certificate, an extension during the TLS handshake, or through OCSP. Currently, Google Chrome and Mozilla Firefox enforce this requirement."
    }
  },
  {
    "instruction": "Write an answer to the following question: Why did Platte cease trading in the UK, according to Martin Horwood MP?",
    "context": "",
    "output": "Platte ceased trading in the UK following a protracted letterwriting campaign and questions raised in the House of Commons. The company stated that its decision was related to its original marketing and business model and possible non-payment of VAT.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Why did Platte cease trading in the UK, according to Martin Horwood MP?",
      "answer": "Platte ceased trading in the UK following a protracted letterwriting campaign and questions raised in the House of Commons. The company stated that its decision was related to its original marketing and business model and possible non-payment of VAT."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is port triggering and how does it differ from port forwarding?",
    "context": "",
    "output": "Port triggering is a configuration option on a NAT-enabled router that allows communication between internal and external host machines in an IP network, similar to port forwarding. However, unlike port forwarding where the forwarded port is open permanently, port triggering only enables incoming traffic to be forwarded to a specific internal host machine for a certain period of time, and the target internal host machine is chosen dynamically based on a predefined triggering event.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is port triggering and how does it differ from port forwarding?",
      "answer": "Port triggering is a configuration option on a NAT-enabled router that allows communication between internal and external host machines in an IP network, similar to port forwarding. However, unlike port forwarding where the forwarded port is open permanently, port triggering only enables incoming traffic to be forwarded to a specific internal host machine for a certain period of time, and the target internal host machine is chosen dynamically based on a predefined triggering event."
    }
  },
  {
    "instruction": "Write an answer to the following question: How were the Axis powers' ciphers broken using frequency analysis during World War II?",
    "context": "",
    "output": "Some of the consular ciphers used by the Japanese during World War II were breakable using frequency analysis, demonstrating the vulnerabilities of such encryption methods.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How were the Axis powers' ciphers broken using frequency analysis during World War II?",
      "answer": "Some of the consular ciphers used by the Japanese during World War II were breakable using frequency analysis, demonstrating the vulnerabilities of such encryption methods."
    }
  },
  {
    "instruction": "Answer based on context:\n\nUsher (software)\n\n==Introduction==\nUsher is an enterprise security platform released by Microstrategy, Inc. in 2015. The technology is designed to replace user-entered passwords with biometric identity and multi-step authentication methods, and features digital badges and geo-fencing administration options. The service takes the form of a mobile application that allows users to access both physical and digital space based on more passive identification methods (facial recognition, Bluetooth discovery, etc).\n\n\n\n== Overview ==\nUsher has been positioned as a \"password killer\" that is based on moving towards security credentials more tied to identity and place. Applications that can be managed via Usher include Salesforce.com, Google Apps, and select Microsoft software.The security features of the product are backed up by Usher Analytics, which allows administrators to assess data in real time to identify threats and behavioral abnormalities.\n\n== Clients ==\nOrganizations that use Usher include: \n\nGeorgetown University\n1776\nSaudi Arabia Ministry of Foreign Affairs\nBlackbox BI Consultancy\n\nWhat are the passive identification methods used by the Usher platform for user authentication?",
    "context": "",
    "output": "The Usher platform uses facial recognition and Bluetooth discovery as passive identification methods for user authentication.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are the passive identification methods used by the Usher platform for user authentication?",
      "answer": "The Usher platform uses facial recognition and Bluetooth discovery as passive identification methods for user authentication.",
      "context": "Usher (software)\n\n==Introduction==\nUsher is an enterprise security platform released by Microstrategy, Inc. in 2015. The technology is designed to replace user-entered passwords with biometric identity and multi-step authentication methods, and features digital badges and geo-fencing administration options. The service takes the form of a mobile application that allows users to access both physical and digital space based on more passive identification methods (facial recognition, Bluetooth discovery, etc).\n\n\n\n== Overview ==\nUsher has been positioned as a \"password killer\" that is based on moving towards security credentials more tied to identity and place. Applications that can be managed via Usher include Salesforce.com, Google Apps, and select Microsoft software.The security features of the product are backed up by Usher Analytics, which allows administrators to assess data in real time to identify threats and behavioral abnormalities.\n\n== Clients ==\nOrganizations that use Usher include: \n\nGeorgetown University\n1776\nSaudi Arabia Ministry of Foreign Affairs\nBlackbox BI Consultancy"
    }
  },
  {
    "instruction": "Write an answer to the following question: How does a canary trap help in identifying an information leak and what is the role of unique language in this method?",
    "context": "",
    "output": "A canary trap is a method for detecting information leaks by releasing different versions of a sensitive document to suspects and observing which version gets leaked. It typically involves adding unique language or a false statement to each version, making it more likely that the suspect will repeat it verbatim if they leak the information. This repetition of unique language can help in identifying the version of the document that was leaked and, thereby, the suspect who leaked it.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does a canary trap help in identifying an information leak and what is the role of unique language in this method?",
      "answer": "A canary trap is a method for detecting information leaks by releasing different versions of a sensitive document to suspects and observing which version gets leaked. It typically involves adding unique language or a false statement to each version, making it more likely that the suspect will repeat it verbatim if they leak the information. This repetition of unique language can help in identifying the version of the document that was leaked and, thereby, the suspect who leaked it."
    }
  },
  {
    "instruction": "Integrated Windows Authentication\n\n==Introduction==\nIntegrated Windows Authentication (IWA)\nis a term associated with Microsoft products that refers to the SPNEGO, Kerberos, and NTLMSSP authentication protocols with respect to SSPI functionality introduced with Microsoft Windows 2000 and included with later Windows NT-based operating systems. The term is used more commonly for the automatically authenticated connections between Microsoft Internet Information Services, Internet Explorer, and other Active Directory aware applications.\nIWA is also known by several names like HTTP Negotiate authentication, NT Authentication, NTLM Authentication, Domain authentication, Windows Integrated Authentication, Windows NT Challenge/Response authentication, or simply Windows Authentication.\n\n\n\n== Overview ==\n\nIntegrated Windows Authentication uses the security features of Windows clients and servers. Unlike Basic Authentication or Digest Authentication, initially, it does not prompt users for a user name and password. The current Windows user information on the client computer is supplied by the web browser through a cryptographic exchange involving hashing with the Web server. If the authentication exchange initially fails to identify the user, the web browser will prompt the user for a Windows user account user name and password.\nIntegrated Windows Authentication itself is not a standard or an authentication protocol. When IWA is selected as an option of a program (e.g. within the Directory Security tab of the IIS site properties dialog) this implies that underlying security mechanisms should be used in a preferential order. If the Kerberos provider is functional and a Kerberos ticket can be obtained for the target, and any associated settings permit Kerberos authentication to occur (e.g. Intranet sites settings in Internet Explorer), the Kerberos 5 protocol will be attempted. Otherwise NTLMSSP authentication is attempted. Similarly, if Kerberos authentication is attempted, yet it fails, then NTLMSSP is attempted. IWA uses SPNEGO to allow initiators and acceptors to negotiate either Kerberos or NTLMSSP.  Third party utilities have extended the Integrated Windows Authentication paradigm to UNIX, Linux and Mac systems.\n\n== Supported web browsers ==\nIntegrated Windows Authentication works with most modern web browsers, but does not work over some HTTP proxy servers. Therefore, it is best for use in intranets where all the clients are within a single domain.  It may work with other web browsers if they have been configured to pass the user's logon credentials to the server that is requesting authentication.  Where a proxy itself requires NTLM authentication, some applications like Java may not work because the protocol is not described in RFC-2069 for proxy authentication.\n\nInternet Explorer 2 and later versions.\nIn Mozilla Firefox on Windows operating systems, the names of the domains/websites to which the authentication  is to be passed can be entered (comma delimited for multiple domains) for the \"network.negotiate-auth.trusted-uris\" (for Kerberos) or in the \"network.automatic-ntlm-auth.trusted-uris\" (NTLM) Preference Name on the about:config page. On the Macintosh operating systems this works if you have a kerberos ticket (use negotiate). Some websites may also require configuring the \"network.negotiate-auth.delegation-uris\".\nOpera 9.01 and later versions can use NTLM/Negotiate, but will use Basic or Digest authentication if that is offered by the server.\nGoogle Chrome works as of 8.0.\nSafari works, once you have a Kerberos ticket.\nMicrosoft Edge 77 and later.\n\n== Supported mobile browsers ==\nBitzer Secure Browser supports Kerberos and NTLM SSO from iOS and Android. Both KINIT and PKINIT are supported.\nQuestion: How does Integrated Windows Authentication handle authentication failures?",
    "context": "",
    "output": "Answer: If the authentication exchange initially fails to identify the user, the web browser will prompt the user for a Windows user account user name and password.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does Integrated Windows Authentication handle authentication failures?",
      "answer": "If the authentication exchange initially fails to identify the user, the web browser will prompt the user for a Windows user account user name and password.",
      "context": "Integrated Windows Authentication\n\n==Introduction==\nIntegrated Windows Authentication (IWA)\nis a term associated with Microsoft products that refers to the SPNEGO, Kerberos, and NTLMSSP authentication protocols with respect to SSPI functionality introduced with Microsoft Windows 2000 and included with later Windows NT-based operating systems. The term is used more commonly for the automatically authenticated connections between Microsoft Internet Information Services, Internet Explorer, and other Active Directory aware applications.\nIWA is also known by several names like HTTP Negotiate authentication, NT Authentication, NTLM Authentication, Domain authentication, Windows Integrated Authentication, Windows NT Challenge/Response authentication, or simply Windows Authentication.\n\n\n\n== Overview ==\n\nIntegrated Windows Authentication uses the security features of Windows clients and servers. Unlike Basic Authentication or Digest Authentication, initially, it does not prompt users for a user name and password. The current Windows user information on the client computer is supplied by the web browser through a cryptographic exchange involving hashing with the Web server. If the authentication exchange initially fails to identify the user, the web browser will prompt the user for a Windows user account user name and password.\nIntegrated Windows Authentication itself is not a standard or an authentication protocol. When IWA is selected as an option of a program (e.g. within the Directory Security tab of the IIS site properties dialog) this implies that underlying security mechanisms should be used in a preferential order. If the Kerberos provider is functional and a Kerberos ticket can be obtained for the target, and any associated settings permit Kerberos authentication to occur (e.g. Intranet sites settings in Internet Explorer), the Kerberos 5 protocol will be attempted. Otherwise NTLMSSP authentication is attempted. Similarly, if Kerberos authentication is attempted, yet it fails, then NTLMSSP is attempted. IWA uses SPNEGO to allow initiators and acceptors to negotiate either Kerberos or NTLMSSP.  Third party utilities have extended the Integrated Windows Authentication paradigm to UNIX, Linux and Mac systems.\n\n== Supported web browsers ==\nIntegrated Windows Authentication works with most modern web browsers, but does not work over some HTTP proxy servers. Therefore, it is best for use in intranets where all the clients are within a single domain.  It may work with other web browsers if they have been configured to pass the user's logon credentials to the server that is requesting authentication.  Where a proxy itself requires NTLM authentication, some applications like Java may not work because the protocol is not described in RFC-2069 for proxy authentication.\n\nInternet Explorer 2 and later versions.\nIn Mozilla Firefox on Windows operating systems, the names of the domains/websites to which the authentication  is to be passed can be entered (comma delimited for multiple domains) for the \"network.negotiate-auth.trusted-uris\" (for Kerberos) or in the \"network.automatic-ntlm-auth.trusted-uris\" (NTLM) Preference Name on the about:config page. On the Macintosh operating systems this works if you have a kerberos ticket (use negotiate). Some websites may also require configuring the \"network.negotiate-auth.delegation-uris\".\nOpera 9.01 and later versions can use NTLM/Negotiate, but will use Basic or Digest authentication if that is offered by the server.\nGoogle Chrome works as of 8.0.\nSafari works, once you have a Kerberos ticket.\nMicrosoft Edge 77 and later.\n\n== Supported mobile browsers ==\nBitzer Secure Browser supports Kerberos and NTLM SSO from iOS and Android. Both KINIT and PKINIT are supported."
    }
  },
  {
    "instruction": "Answer based on context:\n\nEmployee monitoring software\n\n==Introduction==\nEmployee monitoring software is a means of employee monitoring, and allows company administrators to monitor and supervise all their employee computers from a central location. It is normally deployed over a business network and allows for easy centralized log viewing via one central networked PC. Sometimes, companies opt to monitor their employees using remote desktop software instead.\n\n\n\n== Purpose ==\nEmployee monitoring software is used to supervise employees' performance, prevent illegal activities, avoid confidential info leakage, and catch insider threats. Nowadays employee monitoring software is widely used in technology companies.\n\n== Features ==\nAn employee monitoring program can monitor almost everything on a computer, such as keystrokes and passwords inputted, websites visited, chats in Facebook Messenger, Skype and other social chats. A piece of monitoring software can also capture screenshots of mobile activities. E-mail monitoring includes employers having access to records of employee\u2019s e-mails that are sent through the company\u2019s servers. Companies may use keyword searches to natural language processing to analyze e-mails. The administrator can view the logs through a cloud panel, or receive the logs by email.\n\n== Criticism ==\nBossware, also known as tattleware, is software that allows supervisors to automatically monitor the productivity of their employees. Common features of bossware include activity monitoring, screenshotting and/or screen recording, keystroke logging, webcam and/or microphone activation, and \"invisible\" monitoring. Bossware has been called a form of spyware. During the COVID-19 pandemic, the use of bossware by companies to monitor their employees increased.The Electronic Frontier Foundation (EFF) denounced bossware as a violation of privacy. The Center for Democracy and Technology (CDT) denounced bossware as a threat to the safety and health of employees.During the COVID-19 pandemic, members of the r/antiwork subreddit shared various mouse jiggler strategies to combat bossware intended to monitor the productivity of remote workers.A study by Reports and Data predicts that the global market for employee remote monitoring software will hit $1.3 billion by 2027.\n\nWhat are some of the reasons why companies use employee monitoring software?",
    "context": "",
    "output": "Companies use employee monitoring software to supervise employees' performance, prevent illegal activities, avoid confidential info leakage, and catch insider threats.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are some of the reasons why companies use employee monitoring software?",
      "answer": "Companies use employee monitoring software to supervise employees' performance, prevent illegal activities, avoid confidential info leakage, and catch insider threats.",
      "context": "Employee monitoring software\n\n==Introduction==\nEmployee monitoring software is a means of employee monitoring, and allows company administrators to monitor and supervise all their employee computers from a central location. It is normally deployed over a business network and allows for easy centralized log viewing via one central networked PC. Sometimes, companies opt to monitor their employees using remote desktop software instead.\n\n\n\n== Purpose ==\nEmployee monitoring software is used to supervise employees' performance, prevent illegal activities, avoid confidential info leakage, and catch insider threats. Nowadays employee monitoring software is widely used in technology companies.\n\n== Features ==\nAn employee monitoring program can monitor almost everything on a computer, such as keystrokes and passwords inputted, websites visited, chats in Facebook Messenger, Skype and other social chats. A piece of monitoring software can also capture screenshots of mobile activities. E-mail monitoring includes employers having access to records of employee\u2019s e-mails that are sent through the company\u2019s servers. Companies may use keyword searches to natural language processing to analyze e-mails. The administrator can view the logs through a cloud panel, or receive the logs by email.\n\n== Criticism ==\nBossware, also known as tattleware, is software that allows supervisors to automatically monitor the productivity of their employees. Common features of bossware include activity monitoring, screenshotting and/or screen recording, keystroke logging, webcam and/or microphone activation, and \"invisible\" monitoring. Bossware has been called a form of spyware. During the COVID-19 pandemic, the use of bossware by companies to monitor their employees increased.The Electronic Frontier Foundation (EFF) denounced bossware as a violation of privacy. The Center for Democracy and Technology (CDT) denounced bossware as a threat to the safety and health of employees.During the COVID-19 pandemic, members of the r/antiwork subreddit shared various mouse jiggler strategies to combat bossware intended to monitor the productivity of remote workers.A study by Reports and Data predicts that the global market for employee remote monitoring software will hit $1.3 billion by 2027."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does LightBasin communicate with attackers' IP addresses?",
    "context": "",
    "output": "LightBasin communicates with attackers' IP addresses using TinyShell, which is a Python command shell used to control and execute commands through HTTP requests to a web shell.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does LightBasin communicate with attackers' IP addresses?",
      "answer": "LightBasin communicates with attackers' IP addresses using TinyShell, which is a Python command shell used to control and execute commands through HTTP requests to a web shell."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the impact of the Fluhrer, Mantin and Shamir attack on SSL (TLS) that uses RC4 encryption?",
    "context": "",
    "output": "The Fluhrer, Mantin and Shamir attack does not apply in general to RC4-based SSL (TLS), since SSL generates the encryption keys it uses for RC4 by hashing, meaning that different SSL sessions have unrelated keys. However, the closely related bar mitzvah attack, based on the same research and revealed in 2015, does exploit those cases where weak keys are generated by the SSL keying process.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the impact of the Fluhrer, Mantin and Shamir attack on SSL (TLS) that uses RC4 encryption?",
      "answer": "The Fluhrer, Mantin and Shamir attack does not apply in general to RC4-based SSL (TLS), since SSL generates the encryption keys it uses for RC4 by hashing, meaning that different SSL sessions have unrelated keys. However, the closely related bar mitzvah attack, based on the same research and revealed in 2015, does exploit those cases where weak keys are generated by the SSL keying process."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the ICANN's Registrar Transfer Dispute Resolution Policy and how is it used in cases of domain hijacking?",
    "context": "",
    "output": "ICANN's Registrar Transfer Dispute Resolution Policy is a policy used to seek the return of a domain name that has been transferred to another registrar. It can be invoked by the losing registrar in cases of domain hijacking.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the ICANN's Registrar Transfer Dispute Resolution Policy and how is it used in cases of domain hijacking?",
      "answer": "ICANN's Registrar Transfer Dispute Resolution Policy is a policy used to seek the return of a domain name that has been transferred to another registrar. It can be invoked by the losing registrar in cases of domain hijacking."
    }
  },
  {
    "instruction": "Write an answer to the following question: What types of events and activities are typically hosted at HackerspaceSG, and how can members get involved in hosting these events?",
    "context": "",
    "output": "HackerspaceSG hosts a range of events from technology classes to biology, computer hardware, and manufacturing. Members can get involved in hosting these events by proposing and organizing them through the monthly plenums.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What types of events and activities are typically hosted at HackerspaceSG, and how can members get involved in hosting these events?",
      "answer": "HackerspaceSG hosts a range of events from technology classes to biology, computer hardware, and manufacturing. Members can get involved in hosting these events by proposing and organizing them through the monthly plenums."
    }
  },
  {
    "instruction": "Client honeypot\n\n==Introduction==\nHoneypots are security devices whose value lie in being probed and compromised. Traditional honeypots are servers (or devices that expose server services) that wait passively to be attacked. Client Honeypots are active security devices in search of malicious servers that attack clients. The client honeypot poses as a client and interacts with the server to examine whether an attack has occurred. Often the focus of client honeypots is on web browsers, but any client that interacts with servers can be part of a client honeypot (for example ftp, ssh, email, etc.).\nThere are several terms that are used to describe client honeypots. Besides client honeypot, which is the generic classification, honeyclient is the other term that is generally used and accepted. However, there is a subtlety here, as \"honeyclient\" is actually a homograph that could also refer to the first known open source client honeypot implementation (see below), although this should be clear from the context.\n\n\n\n== Architecture ==\nA client honeypot is composed of three components. The first component, a queuer, is responsible for creating a list of servers for the client to visit. This list can be created, for example, through crawling. The second component is the client itself, which is able to make a requests to servers identified by the queuer. After the interaction with the server has taken place, the third component, an analysis engine, is responsible for determining whether an attack has taken place on the client honeypot.\nIn addition to these components, client honeypots are usually equipped with some sort of containment strategy to prevent successful attacks from spreading beyond the client honeypot. This is usually achieved through the use of firewalls and virtual machine sandboxes.\nAnalogous to traditional server honeypots, client honeypots are mainly classified by their interaction level: high or low; which denotes the level of functional interaction the server can utilize on the client honeypot. In addition to this there are also newly hybrid approaches which denotes the usage of both high and low interaction detection techniques.\n\n== High interaction ==\nHigh interaction client honeypots are fully functional systems comparable to real systems with real clients. As such, no functional limitations (besides the containment strategy) exist on high interaction client honeypots. Attacks on high interaction client honeypots are detected via inspection of the state of the system after a server has been interacted with. The detection of changes to the client honeypot may indicate the occurrence of an attack against that has exploited a vulnerability of the client. An example of such a change is the presence of a new or altered file.\nHigh interaction client honeypots are very effective at detecting unknown attacks on clients. However, the tradeoff for this accuracy is a performance hit from the amount of system state that has to be monitored to make an attack assessment. Also, this detection mechanism is prone to various forms of evasion by the exploit. For example, an attack could delay the exploit from immediately triggering (time bombs) or could trigger upon a particular set of conditions or actions (logic bombs). Since no immediate, detectable state change occurred, the client honeypot is likely to incorrectly classify the server as safe even though it did successfully perform its attack on the client. Finally, if the client honeypots are running in virtual machines, then an exploit may try to detect the presence of the virtual environment and cease from triggering or behave differently.\n\n\n*** Capture-HPC ***\nCapture [1] is a high interaction client honeypot developed by researchers at Victoria University of Wellington, NZ. Capture differs from existing client honeypots in various ways. First, it is designed to be fast. State changes are being detected using an event based model allowing to react to state changes as they occur. Second, Capture is designed to be scalable. A central Capture server is able to control numerous clients across a network. Third, Capture is supposed to be a framework that allows to utilize different clients. The initial version of Capture supports Internet Explorer, but the current version supports all major browsers (Internet Explorer, Firefox, Opera, Safari) as well as other HTTP aware client applications, such as office applications and media players.\n\n\n*** HoneyClient ***\nHoneyClient [2] is a web browser based (IE/FireFox) high interaction client honeypot designed by Kathy Wang in 2004 and subsequently developed at MITRE. It was the first open source client honeypot and is a mix of Perl, C++, and Ruby. HoneyClient is state-based and detects attacks on Windows clients by monitoring files, process events, and registry entries. It has integrated the Capture-HPC real-time integrity checker to perform this detection. HoneyClient also contains a crawler, so it can be seeded with a list of initial URLs from which to start and can then continue to traverse web sites in search of client-side malware.\n\n\n*** HoneyMonkey (dead since 2010) ***\n\nHoneyMonkey [3] is a web browser based (IE) high interaction client honeypot implemented by Microsoft in 2005. It is not available for download. HoneyMonkey is state based and detects attacks on clients by monitoring files, registry, and processes. A unique characteristic of HoneyMonkey is its layered approach to interacting with servers in order to identify zero-day exploits. HoneyMonkey initially crawls the web with a vulnerable configuration. Once an attack has been identified, the server is reexamined with a fully patched configuration. If the attack is still detected, one can conclude that the attack utilizes an exploit for which no patch has been publicly released yet and therefore is quite dangerous.\n\n\n*** SHELIA (dead since 2009) ***\nShelia [4] is a high interaction client honeypot developed by Joan Robert Rocaspana at Vrije Universiteit Amsterdam. It integrates with an email reader and processes each email it receives (URLs & attachments). Depending on the type of URL or attachment received, it opens a different client application (e.g. browser, office application, etc.) It monitors whether executable instructions are executed in data area of memory (which would indicate a buffer overflow exploit has been triggered). With such an approach, SHELIA is not only able to detect exploits, but is able to actually ward off exploits from triggering.\n\n\n*** UW Spycrawler ***\nThe Spycrawler [5] developed at the University of Washington is yet another browser based (Mozilla) high interaction client honeypot developed by Moshchuk et al. in 2005. This client honeypot is not available for download. The Spycrawler is state based and detects attacks on clients by monitoring files, processes, registry, and browser crashes. Spycrawlers detection mechanism is event based. Further, it increases the passage of time of the virtual machine the Spycrawler is operating in to overcome (or rather reduce the impact of) time bombs.\n\n\n*** Web Exploit Finder ***\nWEF [6] is an implementation of an automatic drive-by-download \u2013 detection in a virtualized environment, developed by Thomas M\u00fcller, Benjamin Mack and Mehmet Arziman, three students from the Hochschule der Medien (HdM), Stuttgart during the summer term in 2006. WEF can be used as an active HoneyNet with a complete virtualization architecture underneath for rollbacks of compromised virtualized machines.\n\n== Low interaction ==\nLow interaction client honeypots differ from high interaction client honeypots in that they do not utilize an entire real system, but rather use lightweight or simulated clients to interact with the server. (in the browser world, they are similar to web crawlers). Responses from servers are examined directly to assess whether an attack has taken place. This could be done, for example, by examining the response for the presence of malicious strings.\nLow interaction client honeypots are easier to deploy and operate than high interaction client honeypots and also perform better. However, they are likely to have a lower detection rate since attacks have to be known to the client honeypot in order for it to detect them; new attacks are likely to go unnoticed. They also suffer from the problem of evasion by exploits, which may be exacerbated due to their simplicity, thus making it easier for an exploit to detect the presence of the client honeypot.\n\n\n*** HoneyC ***\nHoneyC [7] is a low interaction client honeypot developed at Victoria University of Wellington by Christian Seifert in 2006. HoneyC is a platform independent open source framework written in Ruby. It currently concentrates driving a web browser simulator to interact with servers. Malicious servers are detected by statically examining the web server's response for malicious strings through the usage of Snort signatures.\n\n\n*** Monkey-Spider (dead since 2008) ***\nMonkey-Spider [8] is a low-interaction client honeypot initially developed at the University of Mannheim by Ali Ikinci. Monkey-Spider is a crawler based client honeypot initially utilizing anti-virus solutions to detect malware. It is claimed to be fast and expandable with other detection mechanisms. The work has started as a diploma thesis and is continued and released as Free Software under the GPL.\n\n\n*** PhoneyC (dead since 2015) ***\nPhoneyC [9] is a low-interaction client developed by Jose Nazario. PhoneyC mimics legitimate web browsers and can understand dynamic content by de-obfuscating malicious content for detection. Furthermore, PhoneyC emulates specific vulnerabilities to pinpoint the attack vector. PhoneyC is a modular framework that enables the study of malicious HTTP pages and understands modern vulnerabilities and attacker techniques.\n\n\n*** SpyBye ***\nSpyBye [10] is a low interaction client honeypot developed by Niels Provos. SpyBye allows a web master to determine whether a web site is malicious by a set of heuristics and scanning of content against the ClamAV engine.\n\n\n*** Thug ***\nThug [11] is a low-interaction client honeypot developed by Angelo Dell'Aera. Thug emulates the behaviour of a web browser and is focused on detection of malicious web pages. The tool uses Google V8 Javascript engine and implements its own Document Object Model (DOM). The most important and unique features of Thug are: the ActiveX controls handling module (vulnerability module), and static + dynamic\nanalysis capabilities (using Abstract Syntax Tree and Libemu shellcode analyser). Thug is written in Python under GNU General Public License.\n\n\n*** YALIH ***\nYALIH (Yet Another Low Interaction Honeyclient) [12] is a low Interaction Client honeypot developed by Masood Mansoori from the honeynet chapter of the Victoria University of Wellington, New Zealand and designed to detect malicious websites through signature and pattern matching techniques. YALIH has the capability to collect suspicious URLs from malicious website databases, Bing API, inbox and SPAM folder through POP3 and IMAP protocol. It can perform Javascript extraction, de-obfuscation and de-minification of scripts embedded within a website and can emulate referrer, browser agents and handle redirection, cookies and sessions. Its visitor agent is capable of fetching a website from multiple locations to bypass geo-location and IP cloaking attacks. YALIH can also generate automated signatures to detect variations of an attack. YALIH is available as an open source project.\n\n\n*** miniC ***\nminiC [13] is a low interaction client honeypot based on wget retriever and Yara engine. It is designed to be light, fast and suitable for retrieval of a large number of websites. miniC allows to set and simulate referrer, user-agent, accept_language and few other variables. miniC was designed at New Zealand Honeynet chapter of the Victoria University of Wellington.\n\n== Hybrid Client Honeypots ==\nHybrid client honeypots combine both low and high interaction client honeypots to gain from the advantages of both approaches.\n\n\n*** HoneySpider (dead since 2013) ***\nThe HoneySpider [14] network is a hybrid client honeypot developed as a joint venture between NASK/CERT Polska, GOVCERT.NL and SURFnet.  The projects goal is to develop a complete client honeypot system, based on existing client honeypot solutions and a crawler specially for the bulk processing of URLs.\n\n== Literature ==\nJan G\u00f6bel, Andreas Dewald, Client-Honeypots: Exploring Malicious Websites, Oldenbourg Verlag 2010, ISBN 978-3-486-70526-3, This book at Amazon\n\n== Papers ==\nM. Egele, P. Wurzinger, C. Kruegel, and E. Kirda, Defending Browsers against Drive-by Downloads: Mitigating Heap-spraying Code Injection Attacks, Secure Systems Lab, 2009, p. Available from iseclab.org, accessed May 15, 2009.\nFeinstein, Ben. Caffeine Monkey: Automated Collection, Detection and Analysis of JavaScript. BlackHat USA. Las Vegas, 2007.\nIkinci, A, Holz, T., Freiling, F.C. : Monkey-Spider: Detecting Malicious Websites with Low-Interaction Honeyclients.  Sicherheit 2008: 407-421 Archived 2013-01-02 at the Wayback Machine,\nMoshchuk, A., Bragin, T., Gribble, S.D. and Levy, H.M. A Crawler-based Study of Spyware on the Web. In 13th Annual Network and Distributed System Security Symposium (NDSS). San Diego, 2006. The Internet Society.\nProvos, N., Holz, T. Virtual Honeypots: From Botnet Tracking to Intrusion Detection. Addison-Wesley. Boston, 2007.\nProvos, N., Mavrommatis, P., Abu Rajab, M., Monrose, F. All Your iFRAMEs Point to Us. Google Technical Report. Google, Inc., 2008.\nProvos, N., McNamee, D., Mavrommatis, P., Wang, K., Modadugu, N. The Ghost In The Browser: Analysis of Web-based Malware. Proceedings of the 2007 HotBots. Cambridge, April 2007. USENIX.\nSeifert, C., Endicott-Popovsky, B., Frincke, D., Komisarczuk, P., Muschevici, R. and Welch, I., Justifying the Need for Forensically Ready Protocols: A Case Study of Identifying Malicious Web Servers Using Client Honeypots. in 4th Annual IFIP WG 11.9 International Conference on Digital Forensics, Kyoto, 2008.\nSeifert, C. Know Your Enemy: Behind The Scenes Of Malicious Web Servers. The Honeynet Project. 2007.\nSeifert, C., Komisarczuk, P. and Welch, I. Application of divide-and-conquer algorithm paradigm to improve the detection speed of high interaction client honeypots. 23rd Annual ACM Symposium on Applied Computing. Ceara, Brazil, 2008.\nSeifert, C., Steenson, R., Holz, T., Yuan, B., Davis, M. A. Know Your Enemy: Malicious Web Servers. The Honeynet Project. 2007. (available at honeynet.org)\nSeifert, C., Welch, I. and Komisarczuk, P. HoneyC: The Low-Interaction Client Honeypot. Proceedings of the 2007 NZCSRCS. University of Waikato, Hamilton, New Zealand. April 2007.\nC. Seifert, V. Delwadia, P. Komisarczuk, D. Stirling, and I. Welch, Measurement Study on Malicious Web Servers in the.nz Domain, in 14th Australasian Conference on Information Security and Privacy (ACISP), Brisbane, 2009.\nC. Seifert, P. Komisarczuk, and I. Welch, True Positive Cost Curve: A Cost-Based Evaluation Method for High-Interaction Client Honeypots, in SECURWARE, Athens, 2009.\nC. Seifert, P. Komisarczuk, and I. Welch, Identification of Malicious Web Pages with Static Heuristics, in Austalasian Telecommunication Networks and Applications Conference, Adelaide, 2008.\nStuurman, Thijs, Verduin, Alex. Honeyclients - Low interaction detection method. Technical Report. University of Amsterdam. February 2008.\nWang, Y.-M., Beck, D., Jiang, X., Roussev, R., Verbowski, C., Chen, S. and King, S. Automated Web Patrol with Strider HoneyMonkeys: Finding Web Sites That Exploit Browser Vulnerabilities. In 13th Annual Network and Distributed System Security Symposium (NDSS). San Diego, 2006. The Internet Society.\nZhuge, Jianwei, Holz, Thorsten, Guo, Jinpeng, Han, Xinhui, Zou, Wei. Studying Malicious Websites and the Underground Economy on the Chinese Web. Proceedings of the 2008 Workshop on the Economics of Information Security. Hanover, June 2008.\n\n== Presentations ==\nPresentation by Websense on their Honeyclient infrastructure and the next generation of Honeyclients they are currently working; April 2008 at RSA-2008\nThe Honeynet Project\nVirtuelle Leimrouten (in German)\nVideo of Michael Davis' Client Honeypot Presentation at HITB 2006\nVideo of Kathy Wang's Presentation of HoneyClient at Recon 2005\nVideo of Wolfgarten's presentation at CCC conference\n\n== Sites ==\n^  https://web.archive.org/web/20100131222145/https://projects.honeynet.org/capture-hpc\n^  https://web.archive.org/web/20071204172932/http://handlers.dshield.org/rdanford/pub/2nd_generation_honeyclients.ppt\n^  https://web.archive.org/web/20100131222101/https://projects.honeynet.org/honeyc/\n^  https://archive.today/20070410162806/http://www.honeyclient.org/trac\n^  https://web.archive.org/web/20180430012758/http://www.honeyspider.net/\n^  http://monkeyspider.sourceforge.net/\n^  https://code.google.com/p/phoneyc/\n^  https://github.com/buffer/thug\n^  http://www.cs.vu.nl/~herbertb/misc/shelia/\n^  http://www.spybye.org/\n^  https://web.archive.org/web/20070322205829/http://www.xnos.org/security/overview.html\n^  https://web.archive.org/web/20100220013531/http://code.mwcollect.org/\n^  http://nz-honeynet.org\n^  https://github.com/masood-m/yalih\n^  https://github.com/Masood-M/miniC\n\nBased on the above text, answer a question. What is an example of an evasion technique used by exploits to avoid detection by high interaction client honeypots?",
    "context": "",
    "output": "An example of an evasion technique used by exploits to avoid detection by high interaction client honeypots is delaying the exploit from immediately triggering (time bombs) or triggering upon a particular set of conditions or actions (logic bombs). This can cause the client honeypot to incorrectly classify the server as safe.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is an example of an evasion technique used by exploits to avoid detection by high interaction client honeypots?",
      "answer": "An example of an evasion technique used by exploits to avoid detection by high interaction client honeypots is delaying the exploit from immediately triggering (time bombs) or triggering upon a particular set of conditions or actions (logic bombs). This can cause the client honeypot to incorrectly classify the server as safe.",
      "context": "Client honeypot\n\n==Introduction==\nHoneypots are security devices whose value lie in being probed and compromised. Traditional honeypots are servers (or devices that expose server services) that wait passively to be attacked. Client Honeypots are active security devices in search of malicious servers that attack clients. The client honeypot poses as a client and interacts with the server to examine whether an attack has occurred. Often the focus of client honeypots is on web browsers, but any client that interacts with servers can be part of a client honeypot (for example ftp, ssh, email, etc.).\nThere are several terms that are used to describe client honeypots. Besides client honeypot, which is the generic classification, honeyclient is the other term that is generally used and accepted. However, there is a subtlety here, as \"honeyclient\" is actually a homograph that could also refer to the first known open source client honeypot implementation (see below), although this should be clear from the context.\n\n\n\n== Architecture ==\nA client honeypot is composed of three components. The first component, a queuer, is responsible for creating a list of servers for the client to visit. This list can be created, for example, through crawling. The second component is the client itself, which is able to make a requests to servers identified by the queuer. After the interaction with the server has taken place, the third component, an analysis engine, is responsible for determining whether an attack has taken place on the client honeypot.\nIn addition to these components, client honeypots are usually equipped with some sort of containment strategy to prevent successful attacks from spreading beyond the client honeypot. This is usually achieved through the use of firewalls and virtual machine sandboxes.\nAnalogous to traditional server honeypots, client honeypots are mainly classified by their interaction level: high or low; which denotes the level of functional interaction the server can utilize on the client honeypot. In addition to this there are also newly hybrid approaches which denotes the usage of both high and low interaction detection techniques.\n\n== High interaction ==\nHigh interaction client honeypots are fully functional systems comparable to real systems with real clients. As such, no functional limitations (besides the containment strategy) exist on high interaction client honeypots. Attacks on high interaction client honeypots are detected via inspection of the state of the system after a server has been interacted with. The detection of changes to the client honeypot may indicate the occurrence of an attack against that has exploited a vulnerability of the client. An example of such a change is the presence of a new or altered file.\nHigh interaction client honeypots are very effective at detecting unknown attacks on clients. However, the tradeoff for this accuracy is a performance hit from the amount of system state that has to be monitored to make an attack assessment. Also, this detection mechanism is prone to various forms of evasion by the exploit. For example, an attack could delay the exploit from immediately triggering (time bombs) or could trigger upon a particular set of conditions or actions (logic bombs). Since no immediate, detectable state change occurred, the client honeypot is likely to incorrectly classify the server as safe even though it did successfully perform its attack on the client. Finally, if the client honeypots are running in virtual machines, then an exploit may try to detect the presence of the virtual environment and cease from triggering or behave differently.\n\n\n*** Capture-HPC ***\nCapture [1] is a high interaction client honeypot developed by researchers at Victoria University of Wellington, NZ. Capture differs from existing client honeypots in various ways. First, it is designed to be fast. State changes are being detected using an event based model allowing to react to state changes as they occur. Second, Capture is designed to be scalable. A central Capture server is able to control numerous clients across a network. Third, Capture is supposed to be a framework that allows to utilize different clients. The initial version of Capture supports Internet Explorer, but the current version supports all major browsers (Internet Explorer, Firefox, Opera, Safari) as well as other HTTP aware client applications, such as office applications and media players.\n\n\n*** HoneyClient ***\nHoneyClient [2] is a web browser based (IE/FireFox) high interaction client honeypot designed by Kathy Wang in 2004 and subsequently developed at MITRE. It was the first open source client honeypot and is a mix of Perl, C++, and Ruby. HoneyClient is state-based and detects attacks on Windows clients by monitoring files, process events, and registry entries. It has integrated the Capture-HPC real-time integrity checker to perform this detection. HoneyClient also contains a crawler, so it can be seeded with a list of initial URLs from which to start and can then continue to traverse web sites in search of client-side malware.\n\n\n*** HoneyMonkey (dead since 2010) ***\n\nHoneyMonkey [3] is a web browser based (IE) high interaction client honeypot implemented by Microsoft in 2005. It is not available for download. HoneyMonkey is state based and detects attacks on clients by monitoring files, registry, and processes. A unique characteristic of HoneyMonkey is its layered approach to interacting with servers in order to identify zero-day exploits. HoneyMonkey initially crawls the web with a vulnerable configuration. Once an attack has been identified, the server is reexamined with a fully patched configuration. If the attack is still detected, one can conclude that the attack utilizes an exploit for which no patch has been publicly released yet and therefore is quite dangerous.\n\n\n*** SHELIA (dead since 2009) ***\nShelia [4] is a high interaction client honeypot developed by Joan Robert Rocaspana at Vrije Universiteit Amsterdam. It integrates with an email reader and processes each email it receives (URLs & attachments). Depending on the type of URL or attachment received, it opens a different client application (e.g. browser, office application, etc.) It monitors whether executable instructions are executed in data area of memory (which would indicate a buffer overflow exploit has been triggered). With such an approach, SHELIA is not only able to detect exploits, but is able to actually ward off exploits from triggering.\n\n\n*** UW Spycrawler ***\nThe Spycrawler [5] developed at the University of Washington is yet another browser based (Mozilla) high interaction client honeypot developed by Moshchuk et al. in 2005. This client honeypot is not available for download. The Spycrawler is state based and detects attacks on clients by monitoring files, processes, registry, and browser crashes. Spycrawlers detection mechanism is event based. Further, it increases the passage of time of the virtual machine the Spycrawler is operating in to overcome (or rather reduce the impact of) time bombs.\n\n\n*** Web Exploit Finder ***\nWEF [6] is an implementation of an automatic drive-by-download \u2013 detection in a virtualized environment, developed by Thomas M\u00fcller, Benjamin Mack and Mehmet Arziman, three students from the Hochschule der Medien (HdM), Stuttgart during the summer term in 2006. WEF can be used as an active HoneyNet with a complete virtualization architecture underneath for rollbacks of compromised virtualized machines.\n\n== Low interaction ==\nLow interaction client honeypots differ from high interaction client honeypots in that they do not utilize an entire real system, but rather use lightweight or simulated clients to interact with the server. (in the browser world, they are similar to web crawlers). Responses from servers are examined directly to assess whether an attack has taken place. This could be done, for example, by examining the response for the presence of malicious strings.\nLow interaction client honeypots are easier to deploy and operate than high interaction client honeypots and also perform better. However, they are likely to have a lower detection rate since attacks have to be known to the client honeypot in order for it to detect them; new attacks are likely to go unnoticed. They also suffer from the problem of evasion by exploits, which may be exacerbated due to their simplicity, thus making it easier for an exploit to detect the presence of the client honeypot.\n\n\n*** HoneyC ***\nHoneyC [7] is a low interaction client honeypot developed at Victoria University of Wellington by Christian Seifert in 2006. HoneyC is a platform independent open source framework written in Ruby. It currently concentrates driving a web browser simulator to interact with servers. Malicious servers are detected by statically examining the web server's response for malicious strings through the usage of Snort signatures.\n\n\n*** Monkey-Spider (dead since 2008) ***\nMonkey-Spider [8] is a low-interaction client honeypot initially developed at the University of Mannheim by Ali Ikinci. Monkey-Spider is a crawler based client honeypot initially utilizing anti-virus solutions to detect malware. It is claimed to be fast and expandable with other detection mechanisms. The work has started as a diploma thesis and is continued and released as Free Software under the GPL.\n\n\n*** PhoneyC (dead since 2015) ***\nPhoneyC [9] is a low-interaction client developed by Jose Nazario. PhoneyC mimics legitimate web browsers and can understand dynamic content by de-obfuscating malicious content for detection. Furthermore, PhoneyC emulates specific vulnerabilities to pinpoint the attack vector. PhoneyC is a modular framework that enables the study of malicious HTTP pages and understands modern vulnerabilities and attacker techniques.\n\n\n*** SpyBye ***\nSpyBye [10] is a low interaction client honeypot developed by Niels Provos. SpyBye allows a web master to determine whether a web site is malicious by a set of heuristics and scanning of content against the ClamAV engine.\n\n\n*** Thug ***\nThug [11] is a low-interaction client honeypot developed by Angelo Dell'Aera. Thug emulates the behaviour of a web browser and is focused on detection of malicious web pages. The tool uses Google V8 Javascript engine and implements its own Document Object Model (DOM). The most important and unique features of Thug are: the ActiveX controls handling module (vulnerability module), and static + dynamic\nanalysis capabilities (using Abstract Syntax Tree and Libemu shellcode analyser). Thug is written in Python under GNU General Public License.\n\n\n*** YALIH ***\nYALIH (Yet Another Low Interaction Honeyclient) [12] is a low Interaction Client honeypot developed by Masood Mansoori from the honeynet chapter of the Victoria University of Wellington, New Zealand and designed to detect malicious websites through signature and pattern matching techniques. YALIH has the capability to collect suspicious URLs from malicious website databases, Bing API, inbox and SPAM folder through POP3 and IMAP protocol. It can perform Javascript extraction, de-obfuscation and de-minification of scripts embedded within a website and can emulate referrer, browser agents and handle redirection, cookies and sessions. Its visitor agent is capable of fetching a website from multiple locations to bypass geo-location and IP cloaking attacks. YALIH can also generate automated signatures to detect variations of an attack. YALIH is available as an open source project.\n\n\n*** miniC ***\nminiC [13] is a low interaction client honeypot based on wget retriever and Yara engine. It is designed to be light, fast and suitable for retrieval of a large number of websites. miniC allows to set and simulate referrer, user-agent, accept_language and few other variables. miniC was designed at New Zealand Honeynet chapter of the Victoria University of Wellington.\n\n== Hybrid Client Honeypots ==\nHybrid client honeypots combine both low and high interaction client honeypots to gain from the advantages of both approaches.\n\n\n*** HoneySpider (dead since 2013) ***\nThe HoneySpider [14] network is a hybrid client honeypot developed as a joint venture between NASK/CERT Polska, GOVCERT.NL and SURFnet.  The projects goal is to develop a complete client honeypot system, based on existing client honeypot solutions and a crawler specially for the bulk processing of URLs.\n\n== Literature ==\nJan G\u00f6bel, Andreas Dewald, Client-Honeypots: Exploring Malicious Websites, Oldenbourg Verlag 2010, ISBN 978-3-486-70526-3, This book at Amazon\n\n== Papers ==\nM. Egele, P. Wurzinger, C. Kruegel, and E. Kirda, Defending Browsers against Drive-by Downloads: Mitigating Heap-spraying Code Injection Attacks, Secure Systems Lab, 2009, p. Available from iseclab.org, accessed May 15, 2009.\nFeinstein, Ben. Caffeine Monkey: Automated Collection, Detection and Analysis of JavaScript. BlackHat USA. Las Vegas, 2007.\nIkinci, A, Holz, T., Freiling, F.C. : Monkey-Spider: Detecting Malicious Websites with Low-Interaction Honeyclients.  Sicherheit 2008: 407-421 Archived 2013-01-02 at the Wayback Machine,\nMoshchuk, A., Bragin, T., Gribble, S.D. and Levy, H.M. A Crawler-based Study of Spyware on the Web. In 13th Annual Network and Distributed System Security Symposium (NDSS). San Diego, 2006. The Internet Society.\nProvos, N., Holz, T. Virtual Honeypots: From Botnet Tracking to Intrusion Detection. Addison-Wesley. Boston, 2007.\nProvos, N., Mavrommatis, P., Abu Rajab, M., Monrose, F. All Your iFRAMEs Point to Us. Google Technical Report. Google, Inc., 2008.\nProvos, N., McNamee, D., Mavrommatis, P., Wang, K., Modadugu, N. The Ghost In The Browser: Analysis of Web-based Malware. Proceedings of the 2007 HotBots. Cambridge, April 2007. USENIX.\nSeifert, C., Endicott-Popovsky, B., Frincke, D., Komisarczuk, P., Muschevici, R. and Welch, I., Justifying the Need for Forensically Ready Protocols: A Case Study of Identifying Malicious Web Servers Using Client Honeypots. in 4th Annual IFIP WG 11.9 International Conference on Digital Forensics, Kyoto, 2008.\nSeifert, C. Know Your Enemy: Behind The Scenes Of Malicious Web Servers. The Honeynet Project. 2007.\nSeifert, C., Komisarczuk, P. and Welch, I. Application of divide-and-conquer algorithm paradigm to improve the detection speed of high interaction client honeypots. 23rd Annual ACM Symposium on Applied Computing. Ceara, Brazil, 2008.\nSeifert, C., Steenson, R., Holz, T., Yuan, B., Davis, M. A. Know Your Enemy: Malicious Web Servers. The Honeynet Project. 2007. (available at honeynet.org)\nSeifert, C., Welch, I. and Komisarczuk, P. HoneyC: The Low-Interaction Client Honeypot. Proceedings of the 2007 NZCSRCS. University of Waikato, Hamilton, New Zealand. April 2007.\nC. Seifert, V. Delwadia, P. Komisarczuk, D. Stirling, and I. Welch, Measurement Study on Malicious Web Servers in the.nz Domain, in 14th Australasian Conference on Information Security and Privacy (ACISP), Brisbane, 2009.\nC. Seifert, P. Komisarczuk, and I. Welch, True Positive Cost Curve: A Cost-Based Evaluation Method for High-Interaction Client Honeypots, in SECURWARE, Athens, 2009.\nC. Seifert, P. Komisarczuk, and I. Welch, Identification of Malicious Web Pages with Static Heuristics, in Austalasian Telecommunication Networks and Applications Conference, Adelaide, 2008.\nStuurman, Thijs, Verduin, Alex. Honeyclients - Low interaction detection method. Technical Report. University of Amsterdam. February 2008.\nWang, Y.-M., Beck, D., Jiang, X., Roussev, R., Verbowski, C., Chen, S. and King, S. Automated Web Patrol with Strider HoneyMonkeys: Finding Web Sites That Exploit Browser Vulnerabilities. In 13th Annual Network and Distributed System Security Symposium (NDSS). San Diego, 2006. The Internet Society.\nZhuge, Jianwei, Holz, Thorsten, Guo, Jinpeng, Han, Xinhui, Zou, Wei. Studying Malicious Websites and the Underground Economy on the Chinese Web. Proceedings of the 2008 Workshop on the Economics of Information Security. Hanover, June 2008.\n\n== Presentations ==\nPresentation by Websense on their Honeyclient infrastructure and the next generation of Honeyclients they are currently working; April 2008 at RSA-2008\nThe Honeynet Project\nVirtuelle Leimrouten (in German)\nVideo of Michael Davis' Client Honeypot Presentation at HITB 2006\nVideo of Kathy Wang's Presentation of HoneyClient at Recon 2005\nVideo of Wolfgarten's presentation at CCC conference\n\n== Sites ==\n^  https://web.archive.org/web/20100131222145/https://projects.honeynet.org/capture-hpc\n^  https://web.archive.org/web/20071204172932/http://handlers.dshield.org/rdanford/pub/2nd_generation_honeyclients.ppt\n^  https://web.archive.org/web/20100131222101/https://projects.honeynet.org/honeyc/\n^  https://archive.today/20070410162806/http://www.honeyclient.org/trac\n^  https://web.archive.org/web/20180430012758/http://www.honeyspider.net/\n^  http://monkeyspider.sourceforge.net/\n^  https://code.google.com/p/phoneyc/\n^  https://github.com/buffer/thug\n^  http://www.cs.vu.nl/~herbertb/misc/shelia/\n^  http://www.spybye.org/\n^  https://web.archive.org/web/20070322205829/http://www.xnos.org/security/overview.html\n^  https://web.archive.org/web/20100220013531/http://code.mwcollect.org/\n^  http://nz-honeynet.org\n^  https://github.com/masood-m/yalih\n^  https://github.com/Masood-M/miniC"
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the market size and growth rate of home security systems?",
    "context": "",
    "output": "The market size of home security systems reached $4.8 billion in 2018 and had a compound annual growth rate of 22.4% between 2011 and 2018.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the market size and growth rate of home security systems?",
      "answer": "The market size of home security systems reached $4.8 billion in 2018 and had a compound annual growth rate of 22.4% between 2011 and 2018."
    }
  },
  {
    "instruction": "Write an answer to the following question: How are decisions made about whether to disclose or restrict a vulnerability in the Vulnerabilities Equities Process (VEP)?",
    "context": "",
    "output": "Decisions about whether to disclose or restrict a vulnerability in the Vulnerabilities Equities Process (VEP) are made quickly, in full consultation with all concerned agencies, and based on rational, objective methodologies that take into account factors such as prevalence, reliance, and severity. If consensus cannot be reached, a preliminary determination is made and can be contested by any agency with an equity.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How are decisions made about whether to disclose or restrict a vulnerability in the Vulnerabilities Equities Process (VEP)?",
      "answer": "Decisions about whether to disclose or restrict a vulnerability in the Vulnerabilities Equities Process (VEP) are made quickly, in full consultation with all concerned agencies, and based on rational, objective methodologies that take into account factors such as prevalence, reliance, and severity. If consensus cannot be reached, a preliminary determination is made and can be contested by any agency with an equity."
    }
  },
  {
    "instruction": "Write an answer to the following question: Which hacker group is linked to NTC Vulkan through a software contract and what is the software used for?",
    "context": "",
    "output": "NTC Vulkan is linked to the GRU run hacker group Sandworm through a software contract for Scan-V. Scan-V is used to support searching for weak spots in systems to be targeted.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Which hacker group is linked to NTC Vulkan through a software contract and what is the software used for?",
      "answer": "NTC Vulkan is linked to the GRU run hacker group Sandworm through a software contract for Scan-V. Scan-V is used to support searching for weak spots in systems to be targeted."
    }
  },
  {
    "instruction": "Write an answer to the following question: How can ambiguities in TCP or IP protocols be exploited for IDS evasion?",
    "context": "",
    "output": "Attackers can deliberately manipulate TCP or IP protocols in a way the target computer will handle differently from the IDS, such as handling the TCP urgent pointer differently on different operating systems. If the IDS doesn't handle these protocol violations consistently with its end hosts, it is vulnerable to insertion and evasion techniques.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can ambiguities in TCP or IP protocols be exploited for IDS evasion?",
      "answer": "Attackers can deliberately manipulate TCP or IP protocols in a way the target computer will handle differently from the IDS, such as handling the TCP urgent pointer differently on different operating systems. If the IDS doesn't handle these protocol violations consistently with its end hosts, it is vulnerable to insertion and evasion techniques."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the weakness in WPA2 that allows for the KRACK attack?",
    "context": "",
    "output": "The weakness in WPA2 that allows for the KRACK attack is that it does not require a different key to be used in reconnection, which can be manipulated by an attacker to gradually learn the full keychain used to encrypt the traffic.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the weakness in WPA2 that allows for the KRACK attack?",
      "answer": "The weakness in WPA2 that allows for the KRACK attack is that it does not require a different key to be used in reconnection, which can be manipulated by an attacker to gradually learn the full keychain used to encrypt the traffic."
    }
  },
  {
    "instruction": "Context: Thunderspy\n\n==Introduction==\nThunderspy is a type of security vulnerability, based on the Intel Thunderbolt port, first reported publicly on 10 May 2020, that can result in an evil maid (ie, attacker of an unattended device) attack gaining full access to a computer's information in about five minutes, and may affect millions of Apple, Linux and Windows computers, as well as any computers manufactured before 2019, and some after that. According to Bj\u00f6rn Ruytenberg, the discoverer of the vulnerability, \"All the evil maid needs to do is unscrew the backplate, attach a device momentarily, reprogram the firmware, reattach the backplate, and the evil maid gets full access to the laptop. All of this can be done in under five minutes.\"\n\n\n\n== Impact ==\nThe security vulnerability affects millions of Apple, Linux and Windows computers, as well as all computers manufactured before 2019, and some after that. However, this impact is restricted mainly to how precise a bad actor would have to be to execute the attack. Physical access to a machine with a vulnerable Thunderbolt controller is necessary, as well as a writable ROM chip for the Thunderbolt controller's firmware. Additionally, part of Thunderspy, specifically the portion involving re-writing the firmware of the controller, requires the device to be in sleep, or at least in some sort of powered-on state, to be effective. Machines that force power-off when the case is open may assist in resisting this attack to the extent that the feature (switch) itself resists tampering.\nDue to the nature of attacks that require extended physical access to hardware, it's unlikely the attack will affect users outside of a business or government environment.\n\n== Mitigation ==\nThe researchers claim there is no easy software solution, and may only be mitigated by disabling the Thunderbolt port altogether. However, the impacts of this attack (reading kernel level memory without the machine needing to be powered off) are largely mitigated by anti-intrusion features provided by many business machines. Intel claims enabling such features would substantially restrict the effectiveness of the attack. Microsoft's official security recommendations recommend disabling sleep mode while using BitLocker. Using hibernation in place of sleep mode turns the device off, mitigating potential risks of attack on encrypted data.\nAnswer this question: Can Thunderspy affect users outside of a business or government environment?",
    "context": "",
    "output": "Due to the nature of attacks that require extended physical access to hardware, it's unlikely that the attack will affect users outside of a business or government environment.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Can Thunderspy affect users outside of a business or government environment?",
      "answer": "Due to the nature of attacks that require extended physical access to hardware, it's unlikely that the attack will affect users outside of a business or government environment.",
      "context": "Thunderspy\n\n==Introduction==\nThunderspy is a type of security vulnerability, based on the Intel Thunderbolt port, first reported publicly on 10 May 2020, that can result in an evil maid (ie, attacker of an unattended device) attack gaining full access to a computer's information in about five minutes, and may affect millions of Apple, Linux and Windows computers, as well as any computers manufactured before 2019, and some after that. According to Bj\u00f6rn Ruytenberg, the discoverer of the vulnerability, \"All the evil maid needs to do is unscrew the backplate, attach a device momentarily, reprogram the firmware, reattach the backplate, and the evil maid gets full access to the laptop. All of this can be done in under five minutes.\"\n\n\n\n== Impact ==\nThe security vulnerability affects millions of Apple, Linux and Windows computers, as well as all computers manufactured before 2019, and some after that. However, this impact is restricted mainly to how precise a bad actor would have to be to execute the attack. Physical access to a machine with a vulnerable Thunderbolt controller is necessary, as well as a writable ROM chip for the Thunderbolt controller's firmware. Additionally, part of Thunderspy, specifically the portion involving re-writing the firmware of the controller, requires the device to be in sleep, or at least in some sort of powered-on state, to be effective. Machines that force power-off when the case is open may assist in resisting this attack to the extent that the feature (switch) itself resists tampering.\nDue to the nature of attacks that require extended physical access to hardware, it's unlikely the attack will affect users outside of a business or government environment.\n\n== Mitigation ==\nThe researchers claim there is no easy software solution, and may only be mitigated by disabling the Thunderbolt port altogether. However, the impacts of this attack (reading kernel level memory without the machine needing to be powered off) are largely mitigated by anti-intrusion features provided by many business machines. Intel claims enabling such features would substantially restrict the effectiveness of the attack. Microsoft's official security recommendations recommend disabling sleep mode while using BitLocker. Using hibernation in place of sleep mode turns the device off, mitigating potential risks of attack on encrypted data."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are the two chaotic oscillators required for implementing chaos communications?",
    "context": "",
    "output": "The two chaotic oscillators required for implementing chaos communications are a transmitter (or master) and a receiver (or slave).",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are the two chaotic oscillators required for implementing chaos communications?",
      "answer": "The two chaotic oscillators required for implementing chaos communications are a transmitter (or master) and a receiver (or slave)."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is a brute force attack, and how can it be used to guess the session key in the context of BAC?",
    "context": "",
    "output": "A brute force attack is a type of attack in which an attacker attempts to guess the correct key or password by trying all possible combinations. In the context of BAC, a brute force attack can be used to guess the session key by trying all possible combinations of the data used to encrypt the communication.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is a brute force attack, and how can it be used to guess the session key in the context of BAC?",
      "answer": "A brute force attack is a type of attack in which an attacker attempts to guess the correct key or password by trying all possible combinations. In the context of BAC, a brute force attack can be used to guess the session key by trying all possible combinations of the data used to encrypt the communication."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the Otway-Rees protocol ensure the authenticity of the communicating parties?",
    "context": "",
    "output": "The Otway-Rees protocol ensures the authenticity of the communicating parties by requiring that each message be encrypted using a shared key between the sender and the server. By decrypting and verifying the contents of these messages, each party can confirm that the other party is who they claim to be.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the Otway-Rees protocol ensure the authenticity of the communicating parties?",
      "answer": "The Otway-Rees protocol ensures the authenticity of the communicating parties by requiring that each message be encrypted using a shared key between the sender and the server. By decrypting and verifying the contents of these messages, each party can confirm that the other party is who they claim to be."
    }
  },
  {
    "instruction": "Noisy-storage model\n\n==Introduction==\nThe noisy-storage model  refers to a cryptographic model employed in quantum cryptography. It assumes that the quantum memory device of an attacker (adversary) trying to break the protocol is imperfect (noisy). \nThe main goal of this model is to enable the secure implementation of two-party cryptographic primitives, such as bit commitment, oblivious transfer and secure identification.\n\n== Motivation ==\nQuantum communication has proven to be extremely useful when it comes to distributing encryption keys. It allows two distant parties Alice and Bob to expand a small initial secret key into an arbitrarily long secret key by sending qubits (quantum bits) to each other. Most importantly, it can be shown that any eavesdropper trying to listen into their communication cannot intercept any information about the long key. This is known as quantum key distribution (QKD).\nYet, it has been shown that even quantum communication does not allow the secure implementation of many other two-party cryptographic tasks. These all form instances of secure function evaluation. An example is oblivious transfer. What sets these tasks apart from key distribution is that they aim to solve problems between two parties, Alice and Bob, who do not trust each other. That is, there is no outside party like an eavesdropper, only Alice and Bob. Intuitively, it is this lack of trust that makes the problem hard. Unlike in quantum key distribution, Alice and Bob cannot collaborate to try and detect any eavesdropping activity. Instead, each party has to fend for himself.\nSince tasks like secure identification are of practical interest, one is willing to make assumptions on how powerful the adversary can be. Security then holds as long as these assumptions are satisfied. In classical cryptography, i.e., without the use of quantum tools, most of these are computational assumptions. Such assumptions consists of two parts. First, one assumes that a particular problem is difficult to solve. For example, one might assume that it is hard to factor a large integer into its prime factors (e.g. 15\n\n== Assumption ==\nThe assumption of the noisy-storage model is that during waiting times \n  \n    \n      \n        \u0394\n        t\n      \n    \n    {\\displaystyle \\Delta t}\n   introduced into the protocol, the adversary can only store quantum information in his noisy memory device. Such a device is simply a quantum channel \n  \n    \n      \n        \n          \n            F\n          \n        \n        :\n        \n          \n            S\n          \n        \n        (\n        \n          \n            \n              H\n            \n          \n          \n            \n              i\n              n\n            \n          \n        \n        )\n        \u2192\n        \n          \n            S\n          \n        \n        (\n        \n          \n            \n              H\n            \n          \n          \n            \n              o\n              u\n              t\n            \n          \n        \n        )\n      \n    \n    {\\displaystyle {\\mathcal {F}}:{\\mathcal {S}}({\\mathcal {H}}_{\\rm {in}})\\rightarrow {\\mathcal {S}}({\\mathcal {H}}_{\\rm {out}})}\n   that takes input states \n  \n    \n      \n        \n          \u03c1\n          \n            \n              i\n              n\n            \n          \n        \n        \u2208\n        \n          \n            S\n          \n        \n        (\n        \n          \n            \n              H\n            \n          \n          \n            \n              i\n              n\n            \n          \n        \n        )\n      \n    \n    {\\displaystyle \\rho _{\\rm {in}}\\in {\\mathcal {S}}({\\mathcal {H}}_{\\rm {in}})}\n   to some noisy output states \n  \n    \n      \n        \n          \u03c1\n          \n            \n              o\n              u\n              t\n            \n          \n        \n        \u2208\n        \n          \n            S\n          \n        \n        (\n        \n          \n            \n              H\n            \n          \n          \n            \n              o\n              u\n              t\n            \n          \n        \n        )\n      \n    \n    {\\displaystyle \\rho _{\\rm {out}}\\in {\\mathcal {S}}({\\mathcal {H}}_{\\rm {out}})}\n  . Otherwise, the adversary is all powerful. For example, he can store an unlimited amount of classical information and perform any computation instantaneously.\n\nThe latter assumption also implies that he can perform any form of error correcting encoding before and after using the noisy memory device, even if it is computationally very difficult to do (i.e., it requires a long time). In this context, this is generally referred to as an encoding attack \n  \n    \n      \n        \n          \n            E\n          \n        \n      \n    \n    {\\displaystyle {\\mathcal {E}}}\n   and a decoding attack \n  \n    \n      \n        \n          \n            D\n          \n        \n      \n    \n    {\\displaystyle {\\mathcal {D}}}\n  . Since the adversary's classical memory can be arbitrarily large, the encoding \n  \n    \n      \n        \n          \n            E\n          \n        \n      \n    \n    {\\displaystyle {\\mathcal {E}}}\n   may not only generate some quantum state as input to the storage device \n  \n    \n      \n        \n          \n            F\n          \n        \n      \n    \n    {\\displaystyle {\\mathcal {F}}}\n   but also output classical information. The adversary's decoding attack \n  \n    \n      \n        \n          \n            D\n          \n        \n      \n    \n    {\\displaystyle {\\mathcal {D}}}\n   can make use of this extra classical information, as well as any additional information that the adversary may gain after the waiting time has passed.\nIn practise, one often considers storage devices that consist of \n  \n    \n      \n        N\n      \n    \n    {\\displaystyle N}\n   memory cells, each of which is subject to noise. In information-theoretic terms, this means that the device has the form \n  \n    \n      \n        \n          \n            F\n\n== Protocols ==\nMost protocols proceed in two steps. First, Alice and Bob exchange \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n   qubits encoded in two or three mutually unbiased bases. These are the same encodings which are used in the BB84 or six-state protocols of quantum key distribution. Typically, this takes the form of Alice sending such qubits to Bob, and Bob measuring them immediately on arrival. This has the advantage that Alice and Bob need no quantum storage to execute the protocol. It is furthermore experimentally relatively easy to create such qubits, making it possible to implement such protocols using currently available technology.The second step is to perform classical post-processing of the measurement data obtained in step one. Techniques used depend on the protocol in question and include privacy amplification, error-correcting codes, min-entropy sampling, and interactive hashing.\n\n\n*** General ***\nTo demonstrate that all two-party cryptographic tasks can be implemented securely, a common approach is to show that a simple cryptographic primitive can be implemented that is known to be universal for secure function evaluation. That is, once one manages to build a protocol for such a cryptographic primitive all other tasks can be implemented by using this primitive as a basic building block. One such primitive is oblivious transfer. In turn, oblivious transfer can be constructed from an even simpler building block known as weak string erasure in combination with cryptographic techniques such as privacy amplification.\nAll protocols proposed to date allow one of the parties (Alice) to have even an unlimited amount of noise-free quantum memory. I.e., the noisy-storage assumption is applied to only one of the parties (Bob).  For storage devices of the form \n  \n    \n      \n        \n          \n            F\n\n== Noisy-storage and QKD ==\nThe assumption of bounded-quantum-storage has also been applied outside the realm of secure function evaluation. In particular, it has been shown that if the eavesdropper in quantum key distribution is memory bounded, higher bit error rates can be tolerated in an experimental implementation.\n\nBased on the above text, answer a question. What is an encoding attack and a decoding attack in the context of the noisy-storage model?",
    "context": "",
    "output": "An encoding attack is a form of error correcting encoding performed by the adversary before using the noisy memory device, and a decoding attack is a form of error correcting decoding performed after using the noisy memory device. The adversary's decoding attack can make use of any additional information gained after the waiting time has passed.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is an encoding attack and a decoding attack in the context of the noisy-storage model?",
      "answer": "An encoding attack is a form of error correcting encoding performed by the adversary before using the noisy memory device, and a decoding attack is a form of error correcting decoding performed after using the noisy memory device. The adversary's decoding attack can make use of any additional information gained after the waiting time has passed.",
      "context": "Noisy-storage model\n\n==Introduction==\nThe noisy-storage model  refers to a cryptographic model employed in quantum cryptography. It assumes that the quantum memory device of an attacker (adversary) trying to break the protocol is imperfect (noisy). \nThe main goal of this model is to enable the secure implementation of two-party cryptographic primitives, such as bit commitment, oblivious transfer and secure identification.\n\n== Motivation ==\nQuantum communication has proven to be extremely useful when it comes to distributing encryption keys. It allows two distant parties Alice and Bob to expand a small initial secret key into an arbitrarily long secret key by sending qubits (quantum bits) to each other. Most importantly, it can be shown that any eavesdropper trying to listen into their communication cannot intercept any information about the long key. This is known as quantum key distribution (QKD).\nYet, it has been shown that even quantum communication does not allow the secure implementation of many other two-party cryptographic tasks. These all form instances of secure function evaluation. An example is oblivious transfer. What sets these tasks apart from key distribution is that they aim to solve problems between two parties, Alice and Bob, who do not trust each other. That is, there is no outside party like an eavesdropper, only Alice and Bob. Intuitively, it is this lack of trust that makes the problem hard. Unlike in quantum key distribution, Alice and Bob cannot collaborate to try and detect any eavesdropping activity. Instead, each party has to fend for himself.\nSince tasks like secure identification are of practical interest, one is willing to make assumptions on how powerful the adversary can be. Security then holds as long as these assumptions are satisfied. In classical cryptography, i.e., without the use of quantum tools, most of these are computational assumptions. Such assumptions consists of two parts. First, one assumes that a particular problem is difficult to solve. For example, one might assume that it is hard to factor a large integer into its prime factors (e.g. 15\n\n== Assumption ==\nThe assumption of the noisy-storage model is that during waiting times \n  \n    \n      \n        \u0394\n        t\n      \n    \n    {\\displaystyle \\Delta t}\n   introduced into the protocol, the adversary can only store quantum information in his noisy memory device. Such a device is simply a quantum channel \n  \n    \n      \n        \n          \n            F\n          \n        \n        :\n        \n          \n            S\n          \n        \n        (\n        \n          \n            \n              H\n            \n          \n          \n            \n              i\n              n\n            \n          \n        \n        )\n        \u2192\n        \n          \n            S\n          \n        \n        (\n        \n          \n            \n              H\n            \n          \n          \n            \n              o\n              u\n              t\n            \n          \n        \n        )\n      \n    \n    {\\displaystyle {\\mathcal {F}}:{\\mathcal {S}}({\\mathcal {H}}_{\\rm {in}})\\rightarrow {\\mathcal {S}}({\\mathcal {H}}_{\\rm {out}})}\n   that takes input states \n  \n    \n      \n        \n          \u03c1\n          \n            \n              i\n              n\n            \n          \n        \n        \u2208\n        \n          \n            S\n          \n        \n        (\n        \n          \n            \n              H\n            \n          \n          \n            \n              i\n              n\n            \n          \n        \n        )\n      \n    \n    {\\displaystyle \\rho _{\\rm {in}}\\in {\\mathcal {S}}({\\mathcal {H}}_{\\rm {in}})}\n   to some noisy output states \n  \n    \n      \n        \n          \u03c1\n          \n            \n              o\n              u\n              t\n            \n          \n        \n        \u2208\n        \n          \n            S\n          \n        \n        (\n        \n          \n            \n              H\n            \n          \n          \n            \n              o\n              u\n              t\n            \n          \n        \n        )\n      \n    \n    {\\displaystyle \\rho _{\\rm {out}}\\in {\\mathcal {S}}({\\mathcal {H}}_{\\rm {out}})}\n  . Otherwise, the adversary is all powerful. For example, he can store an unlimited amount of classical information and perform any computation instantaneously.\n\nThe latter assumption also implies that he can perform any form of error correcting encoding before and after using the noisy memory device, even if it is computationally very difficult to do (i.e., it requires a long time). In this context, this is generally referred to as an encoding attack \n  \n    \n      \n        \n          \n            E\n          \n        \n      \n    \n    {\\displaystyle {\\mathcal {E}}}\n   and a decoding attack \n  \n    \n      \n        \n          \n            D\n          \n        \n      \n    \n    {\\displaystyle {\\mathcal {D}}}\n  . Since the adversary's classical memory can be arbitrarily large, the encoding \n  \n    \n      \n        \n          \n            E\n          \n        \n      \n    \n    {\\displaystyle {\\mathcal {E}}}\n   may not only generate some quantum state as input to the storage device \n  \n    \n      \n        \n          \n            F\n          \n        \n      \n    \n    {\\displaystyle {\\mathcal {F}}}\n   but also output classical information. The adversary's decoding attack \n  \n    \n      \n        \n          \n            D\n          \n        \n      \n    \n    {\\displaystyle {\\mathcal {D}}}\n   can make use of this extra classical information, as well as any additional information that the adversary may gain after the waiting time has passed.\nIn practise, one often considers storage devices that consist of \n  \n    \n      \n        N\n      \n    \n    {\\displaystyle N}\n   memory cells, each of which is subject to noise. In information-theoretic terms, this means that the device has the form \n  \n    \n      \n        \n          \n            F\n\n== Protocols ==\nMost protocols proceed in two steps. First, Alice and Bob exchange \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n   qubits encoded in two or three mutually unbiased bases. These are the same encodings which are used in the BB84 or six-state protocols of quantum key distribution. Typically, this takes the form of Alice sending such qubits to Bob, and Bob measuring them immediately on arrival. This has the advantage that Alice and Bob need no quantum storage to execute the protocol. It is furthermore experimentally relatively easy to create such qubits, making it possible to implement such protocols using currently available technology.The second step is to perform classical post-processing of the measurement data obtained in step one. Techniques used depend on the protocol in question and include privacy amplification, error-correcting codes, min-entropy sampling, and interactive hashing.\n\n\n*** General ***\nTo demonstrate that all two-party cryptographic tasks can be implemented securely, a common approach is to show that a simple cryptographic primitive can be implemented that is known to be universal for secure function evaluation. That is, once one manages to build a protocol for such a cryptographic primitive all other tasks can be implemented by using this primitive as a basic building block. One such primitive is oblivious transfer. In turn, oblivious transfer can be constructed from an even simpler building block known as weak string erasure in combination with cryptographic techniques such as privacy amplification.\nAll protocols proposed to date allow one of the parties (Alice) to have even an unlimited amount of noise-free quantum memory. I.e., the noisy-storage assumption is applied to only one of the parties (Bob).  For storage devices of the form \n  \n    \n      \n        \n          \n            F\n\n== Noisy-storage and QKD ==\nThe assumption of bounded-quantum-storage has also been applied outside the realm of secure function evaluation. In particular, it has been shown that if the eavesdropper in quantum key distribution is memory bounded, higher bit error rates can be tolerated in an experimental implementation."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the performance of the Lane hash function compare to other hash functions in terms of cycles per byte, and on what hardware was this performance measured?",
    "context": "",
    "output": "The Lane hash function boasts a performance of up to 25.66 cycles per byte, which is a very high claim compared to other hash functions. This performance was measured on an Intel Core 2 Duo, demonstrating the function's efficiency on this specific hardware. This claim, however, should be taken in the context of the specific hardware used and the conditions under which the measurement was taken. The performance of a hash function can vary depending on the hardware and implementation, so it's important to consider these factors when comparing different hash functions.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the performance of the Lane hash function compare to other hash functions in terms of cycles per byte, and on what hardware was this performance measured?",
      "answer": "The Lane hash function boasts a performance of up to 25.66 cycles per byte, which is a very high claim compared to other hash functions. This performance was measured on an Intel Core 2 Duo, demonstrating the function's efficiency on this specific hardware. This claim, however, should be taken in the context of the specific hardware used and the conditions under which the measurement was taken. The performance of a hash function can vary depending on the hardware and implementation, so it's important to consider these factors when comparing different hash functions."
    }
  },
  {
    "instruction": "Write an answer to the following question: How do capacitors and coils emit acoustic noise during cryptographic operations?",
    "context": "",
    "output": "Capacitors and coils emit acoustic noise during cryptographic operations due to small movements caused by current surges passing through them. Capacitors change diameter slightly due to electrostatic attraction/repulsion or piezoelectric size change, while coils experience vibrations due to changes in magnetic fields. These microphonics can be analyzed to extract sensitive information.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do capacitors and coils emit acoustic noise during cryptographic operations?",
      "answer": "Capacitors and coils emit acoustic noise during cryptographic operations due to small movements caused by current surges passing through them. Capacitors change diameter slightly due to electrostatic attraction/repulsion or piezoelectric size change, while coils experience vibrations due to changes in magnetic fields. These microphonics can be analyzed to extract sensitive information."
    }
  },
  {
    "instruction": "Write an answer to the following question: In what types of systems are proofs of knowledge useful?",
    "context": "",
    "output": "Proofs of knowledge are useful in the construction of identification protocols, signature schemes, group signature systems, and anonymous digital credential systems.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "In what types of systems are proofs of knowledge useful?",
      "answer": "Proofs of knowledge are useful in the construction of identification protocols, signature schemes, group signature systems, and anonymous digital credential systems."
    }
  },
  {
    "instruction": "Write an answer to the following question: How can a security switch be used in a laptop that has been stolen?",
    "context": "",
    "output": "A security switch can be used in a laptop that has been stolen by disconnecting the screen, keyboard and other key components, rendering the laptop useless, with no possibility of recovery, even with a full format.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can a security switch be used in a laptop that has been stolen?",
      "answer": "A security switch can be used in a laptop that has been stolen by disconnecting the screen, keyboard and other key components, rendering the laptop useless, with no possibility of recovery, even with a full format."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is JTRIG and what was their role in online sockpuppetry during the Arab spring?",
    "context": "",
    "output": "JTRIG is a unit of GCHQ that was involved in online sockpuppetry during the Arab spring. They created a series of fake Twitter accounts and an URL shortener which was used as a honeypot for dissidents. Mustafa Al-Bassam, a volunteer for Privacy International, revealed this information in an article for Motherboard.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is JTRIG and what was their role in online sockpuppetry during the Arab spring?",
      "answer": "JTRIG is a unit of GCHQ that was involved in online sockpuppetry during the Arab spring. They created a series of fake Twitter accounts and an URL shortener which was used as a honeypot for dissidents. Mustafa Al-Bassam, a volunteer for Privacy International, revealed this information in an article for Motherboard."
    }
  },
  {
    "instruction": "Write an answer to the following question: What was the reason for the delay in implementing the proposed web censorship regulations?",
    "context": "",
    "output": "The proposed web censorship regulations were delayed pending a 12-month review into how refused classification content was rated.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was the reason for the delay in implementing the proposed web censorship regulations?",
      "answer": "The proposed web censorship regulations were delayed pending a 12-month review into how refused classification content was rated."
    }
  },
  {
    "instruction": "Write an answer to the following question: How do smart cards like the United States Department of Defense's Common Access Card (CAC) protect private keys for encryption and digital signatures?",
    "context": "",
    "output": "Smart cards like the CAC protect private keys for encryption and digital signatures by never letting the key leave the card. To use the card for these purposes, a person needs the personal identification number (PIN) code necessary to unlock it, ensuring that the private key is secure.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do smart cards like the United States Department of Defense's Common Access Card (CAC) protect private keys for encryption and digital signatures?",
      "answer": "Smart cards like the CAC protect private keys for encryption and digital signatures by never letting the key leave the card. To use the card for these purposes, a person needs the personal identification number (PIN) code necessary to unlock it, ensuring that the private key is secure."
    }
  },
  {
    "instruction": "Write an answer to the following question: What level of classification can OMNI handle for secure communications?",
    "context": "",
    "output": "OMNI is capable of handling communications up to Top Secret SCI (Sensitive Compartmented Information) level.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What level of classification can OMNI handle for secure communications?",
      "answer": "OMNI is capable of handling communications up to Top Secret SCI (Sensitive Compartmented Information) level."
    }
  },
  {
    "instruction": "Answer based on context:\n\nTunnelBear\n\n==Introduction==\nTunnelBear is a public VPN service based in Toronto, Canada. It was created by Daniel Kaldor and Ryan Dochuk in 2011. In March 2018, TunnelBear was acquired by McAfee.\n\n\n\n== Features ==\nA freeware TunnelBear client is available on Android, Windows, macOS and iOS. It also has browser extensions for Google Chrome and Opera. Alternatively, Linux distros can be configured to use TunnelBear.Like other public VPN services, TunnelBear has the ability to bypass content blocking in most countries.All TunnelBear clients use AES-256 encryption with the exception of the client for iOS 8 and earlier, which uses AES-128. When connected, the user's actual IP address will not be visible to the websites visited. Instead, the websites and/or computers would be able to see the spoofed IP address provided by the service.\nTunnelBear was among the first consumer VPNs to conduct and publicly release the results of an independent security audit. They record when their users connect to the service and publish annual reports on the number of times law enforcement has requested user information.\n\nDoes TunnelBear have a freeware client available for Android?",
    "context": "",
    "output": "Yes, TunnelBear has a freeware client available for Android.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Does TunnelBear have a freeware client available for Android?",
      "answer": "Yes, TunnelBear has a freeware client available for Android.",
      "context": "TunnelBear\n\n==Introduction==\nTunnelBear is a public VPN service based in Toronto, Canada. It was created by Daniel Kaldor and Ryan Dochuk in 2011. In March 2018, TunnelBear was acquired by McAfee.\n\n\n\n== Features ==\nA freeware TunnelBear client is available on Android, Windows, macOS and iOS. It also has browser extensions for Google Chrome and Opera. Alternatively, Linux distros can be configured to use TunnelBear.Like other public VPN services, TunnelBear has the ability to bypass content blocking in most countries.All TunnelBear clients use AES-256 encryption with the exception of the client for iOS 8 and earlier, which uses AES-128. When connected, the user's actual IP address will not be visible to the websites visited. Instead, the websites and/or computers would be able to see the spoofed IP address provided by the service.\nTunnelBear was among the first consumer VPNs to conduct and publicly release the results of an independent security audit. They record when their users connect to the service and publish annual reports on the number of times law enforcement has requested user information."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are the restrictions imposed by the British Library when supplying articles electronically through SED?",
    "context": "",
    "output": "The British Library imposes restrictions such as limiting access to 14 days, disabling copy-paste actions, and allowing printing only once when supplying articles electronically through SED.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are the restrictions imposed by the British Library when supplying articles electronically through SED?",
      "answer": "The British Library imposes restrictions such as limiting access to 14 days, disabling copy-paste actions, and allowing printing only once when supplying articles electronically through SED."
    }
  },
  {
    "instruction": "Write an answer to the following question: Which organizations participated in the 2016 Data Privacy and Protection Day?",
    "context": "",
    "output": "Some of the participating organizations in the 2016 Data Privacy and Protection Day included Anti-Phishing Working Group, Carnegie Mellon University, Cyber Data-Risk Managers, EDUCAUSE, Georgetown University, Federal Trade Commission (FTC), Federal Communications Commission (FCC), Federal Bureau of Investigation (FBI), Identity Theft Council, the Privacy Commissioner of Canada, New York State Attorney General Office, the UK Information Commissioner, and Data Security Council of India.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Which organizations participated in the 2016 Data Privacy and Protection Day?",
      "answer": "Some of the participating organizations in the 2016 Data Privacy and Protection Day included Anti-Phishing Working Group, Carnegie Mellon University, Cyber Data-Risk Managers, EDUCAUSE, Georgetown University, Federal Trade Commission (FTC), Federal Communications Commission (FCC), Federal Bureau of Investigation (FBI), Identity Theft Council, the Privacy Commissioner of Canada, New York State Attorney General Office, the UK Information Commissioner, and Data Security Council of India."
    }
  },
  {
    "instruction": "GTunnel\n\n==Introduction==\nGTunnel is a Windows application developed by Garden Networks which sets up a local HTTP or SOCKS proxy server which tunnels traffic through their server farm before it reaches its intended destination.\n\n== Features ==\nGTunnel protects Internet users' privacy and freedom of speech in these ways:\nUser's IP address is hidden and user's Internet privacy protected. The destination servers see GTunnel server addresses instead.\nTraffic content is encrypted with industry-strength algorithms between the user's PC and GTunnel servers so the local filtering/censorship systems will not see the content in clear-text format.GTunnel version 1.1 provides a standard mode, which is the main working mode and provides the best data transfer performance by connecting to the back-end servers directly, a Skype mode, and a Tor mode that go through computers in these P2P network. GTunnel also has an improved user interface which features real-time traffic graphs.\nGTunnel replaces the earlier Garden and G2 client software and becomes the main client software of Garden Networks.\nGTunnel works on Linux through Wine support.\n\n== A Diagram of GTunnel's Working Modes ==\n\nBased on the above text, answer a question. How does GTunnel protect users from local filtering and censorship systems?",
    "context": "",
    "output": "GTunnel protects users from local filtering and censorship systems by encrypting traffic content and routing traffic through its server farm, allowing users to bypass local filtering and censorship systems that may otherwise restrict their access to certain online content.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does GTunnel protect users from local filtering and censorship systems?",
      "answer": "GTunnel protects users from local filtering and censorship systems by encrypting traffic content and routing traffic through its server farm, allowing users to bypass local filtering and censorship systems that may otherwise restrict their access to certain online content.",
      "context": "GTunnel\n\n==Introduction==\nGTunnel is a Windows application developed by Garden Networks which sets up a local HTTP or SOCKS proxy server which tunnels traffic through their server farm before it reaches its intended destination.\n\n== Features ==\nGTunnel protects Internet users' privacy and freedom of speech in these ways:\nUser's IP address is hidden and user's Internet privacy protected. The destination servers see GTunnel server addresses instead.\nTraffic content is encrypted with industry-strength algorithms between the user's PC and GTunnel servers so the local filtering/censorship systems will not see the content in clear-text format.GTunnel version 1.1 provides a standard mode, which is the main working mode and provides the best data transfer performance by connecting to the back-end servers directly, a Skype mode, and a Tor mode that go through computers in these P2P network. GTunnel also has an improved user interface which features real-time traffic graphs.\nGTunnel replaces the earlier Garden and G2 client software and becomes the main client software of Garden Networks.\nGTunnel works on Linux through Wine support.\n\n== A Diagram of GTunnel's Working Modes =="
    }
  },
  {
    "instruction": "Context: Deep content inspection\n\n==Introduction==\nDeep content inspection (DCI) is a form of network filtering that examines an entire file or MIME object as it passes an inspection point, searching for viruses, spam, data loss, key words or other content level criteria. Deep Content Inspection is considered the evolution of Deep Packet Inspection with the ability to look at what the actual content contains instead of focusing on individual or multiple packets. Deep Content Inspection allows services to keep track of content across multiple packets so that the signatures they may be searching for can cross packet boundaries and yet they will still be found. An exhaustive form of network traffic inspection in which Internet traffic is examined across all the seven OSI ISO layers, and most importantly, the application layer.\n\n\n\n== Background ==\nTraditional inspection technologies are unable to keep up with the recent outbreaks of widespread attacks. Unlike shallow inspection methods such as Deep Packet Inspection (DPI), where only the data part (and possibly also the header) of a packet are inspected, Deep Content Inspection (DCI)-based systems are exhaustive, such that network traffic packets are reassembled into their constituting objects, un-encoded and/or decompressed as required, and finally presented to be inspected for malware, right-of-use, compliance, and understanding of the traffic's intent. If this reconstruction and comprehension can be done in real-time, then real-time policies can be applied to traffic, preventing the propagation of malware, spam and valuable data loss.  Further, with DCI, the correlation and comprehension of the digital objects transmitted in many communication sessions leads to new ways of network performance optimization and intelligence regardless of protocol or blended communication sessions.\nHistorically, DPI was developed to detect and prevent intrusion. It was then used to provide Quality of Service where the flow of network traffic can be prioritized such that latency-sensitive traffic types (e.g., Voice over IP) can be utilized to provide higher flow priority.\nNew generation of Network Content Security devices such as Unified Threat Management or Next Generation Firewalls (Garner RAS Core Research Note G00174908) use DPI to prevent attacks from a small percentage of viruses and worms; the signatures of these malware fit within the payload of a DPI's inspection scope.  However, the detection and prevention of a new generation of malware such as Conficker and Stuxnet is only possible through the exhaustive analysis provided by DCI.\n\n\n*** The evolution of DPI systems ***\nComputer networks send information across a network from one point to another; the data (sometimes referred to as the payload) is \u2018encapsulated\u2019 within an IP packet, which looks as follows:\n\n*The IP Header provides address information - the sender and destination addresses, while the TCP/UDP Header provided other pertinent information such as the port number, etc. As networks evolve, inspection techniques evolve; all attempting to understand the payload. Throughout the last decade there have been vast improvements including:\n\n\n*** Packet filtering ***\nHistorically, inspection technology examined only the IP Header and the TCP/UDP Header.  Dubbed as \u2018Packet Filtering\u2019, these devices would drop sequence packets, or packets that are not allowed on a network. This scheme of network traffic inspection was first used by firewalls to protect against packet attacks.\n\n\n*** Stateful packet inspection ***\nStateful packet inspection was developed to examine header information and the packet content to increase source and destination understanding. Instead of letting the packets through as a result of their addresses and ports, packets stayed on the network if the context was appropriate to the networks\u2019 current \u2018state\u2019. This scheme was first used by Check Point firewalls and eventually Intrusion Prevention/Detection Systems.\n\n\n*** Deep packet inspection ***\nDeep Packet Inspection is currently the predominant inspection tool used to analyze data packets passing through the network, including the headers and the data protocol structures. These technologies scan packet streams and look for offending patterns.\nTo be effective, Deep Packet Inspection Systems must \u2018string\u2019 match Packet Payloads to malware signatures and specification signatures (which dictate what the request/response should be like) at wire speeds.  To do so, FPGAs, or Field Programmable Gate Arrays, Network Processors, or even Graphics Processing Units (GPUs) are programmed to be hardwired with these signatures and, as a result, traffic that passes through such circuitry is quickly matched.\nWhile using hardware allows for quick and inline matches, DPI systems have the following limitations including;\nHardware limitations: Since DPI systems implement their pattern matching (or searches for \u2018offending\u2019 patterns) through hardware, these systems are typically limited by:\n\nThe number of circuits a high-end DPI chip can have; as of 2011, this of a high end DPI system can, optimally, process around 512 request/response per session.\nThe memory available for pattern matches; as of 2011, high-end DPI systems are capable of matches of up to 60,000 unique signaturesPayload limitations: Web applications communicate content using binary-to-text encoding, compression (zipped, archived, etc.), obfuscation and even encryption.  As such payload structure is becoming more complex such that straight \u2018string\u2019 matching of the signatures is no longer sufficient.  The common workaround is to have signatures be similarly \u2018encoded\u2019 or zipped which, given the above \u2018search limitations\u2019, cannot scale to support every application type, or nested zipped or archived files.\n\n== Deep content inspection ==\nParallel to the development of Deep Packet Inspection, the beginnings of Deep Content Inspection can be traced back as early as 1995 with the introduction of proxies that stopped malware or spam. Deep Content Inspection, can be seen as the third generation of Network Content Inspection, where network content is exhaustively examined,\n\n\n*** First generation \u2013 secure web gateway or proxy-based network content inspection ***\nProxies have been deployed to provide internet caching services to retrieve objects and then forward them.  Consequently, all network traffic is intercepted, and potentially stored. These graduated to what is now known as secure web gateways, proxy-based inspections retrieve and scans object, script, and images.\nProxies, which relies on a fetch the content first if it were not cached, then forwarding the content to the recipient introduced some form of file inspection as early as 1995 when MAILsweeper was released by Content Technologies (now Clearswift), which was then replaced by MIMEsweeper in 2005. 2006 saw the release of the open-source, cross-platform antivirus software ClamAV provided support for caching proxies, Squid and NetCache. Using the  Internet Content Adaptation Protocol (ICAP), a proxy will pass the downloaded content for scanning to an ICAP server running an anti-virus software. Since complete files or \u2018objects\u2019 were passed for scanning, proxy-based anti-virus solutions are considered the first generation of network content inspection.\nBlueCoat, WebWasher and Secure Computing Inc. (now McAfee, now a division of Intel), provided commercial implementations of proxies, eventually becoming a standard network element in most enterprise networks.\nLimitations:\nWhile proxies (or secure web gateways) provide in-depth network traffic inspection, their use is limited as they: \n\nrequire network reconfiguration which is accomplished through \u2013 a) end-devices to get their browsers to point to these proxies; or b) on the network routers to get traffic routed through these devices\nare limited to web (http) and ftp protocols; cannot scan other protocols such as e-mail\nand finally, proxy architectures which are typically built around Squid, which cannot scale with concurrent sessions, limiting their deployment to enterprises.\n\n\n*** Second generation \u2013 gateway/firewall-based network traffic proxy-assisted deep packet inspection ***\nThe Second generation of Network Traffic Inspection solutions were implemented in firewalls and/or UTMs.  Given that network traffic is choked through these devices, in addition to DPI inspection, proxy-like inspection is possible. This approach was first pioneered by  NetScreen Technologies Inc. (acquired by Juniper Networks Inc). However, given the expensive cost of such operation, this feature was applied in tandem with a DPI system and was only activated on a-per-need basis, or when content failed to be qualified through the DPI system.\n\n\n*** Third generation \u2013 transparent, application-aware network content inspection, or deep content inspection ***\nThe third, and current, generation of Network Content Inspection known as Deep Content Inspection solutions are implemented as fully transparent devices that perform full application level content inspection at wire speed.  In order to understand the communication session's intent \u2014in its entirety\u2014, a Deep Content Inspection System must scan both the handshake and payload. Once the digital objects (executables, images, JavaScript's, .pdfs, etc. also referred to as Data-In-Motion) carried within the payload are constructed, usability, compliance and threat analysis of this session and its payload can be achieved.  Given that the handshake sequence and complete payload of the session is available to the DCI system, unlike DPI systems where simple pattern matching and reputation search are only possible, exhaustive object analysis is possible.  The inspection provided by DCI systems can include signature matching, behavioral analysis, regulatory and compliance analysis, and correlation of the session under inspection to the history of previous sessions.  Because of the availability of the complete payload's objects, and these schemes of inspection, Deep Content Inspection Systems are typically deployed where high-grade Security and Compliance is required or where end-point security solutions are not possible such as in bring your own device, or Cloud installations.\nThis third generation approach of Deep Content Inspection was developed within the defence and intelligence community, first appearing in guard products such as SyBard, and later by Wedge Networks Inc..  Key-implementation highlights of this Company's approach can be deduced from their patent USPTO# 7,630,379The main differentiators of Deep Content Inspection are:\n\n\n**** Content ****\nDeep Content Inspection is Content-focused instead of analyzing packets or classifying traffic based on application types such as in Next Generation Firewalls. \"Understanding\" content and its intent is the highest level of intelligence to be gained from network traffic. This is important as information flow is moving away from Packet, towards Application, and ultimately to Content.\nExample inspection levels:\n\nPacket: Random Sample to get larger picture\nApplication: Group or application profiling. Certain applications, or areas of applications, are allowed / not allowed or scanned further.\nContent: Look at everything. Scan everything. Subject the content to rules of inspection (such as Compliance/Data Loss Prevention rules).  Understand the intent.\n\n\n**** Multi-services inspection ****\nBecause of the availability of the complete objects of that payload to a Deep Content Inspection system, some of the services/inspection examples can include:\n\nAnti Malware\nAnti-spam\nData Loss for Data In Motion\nZero-Day or Unknown Threats\nNetwork Traffic Vizualization and Analytics\nCode Attacks/Injection\nContent Manipulation\n\n== Applications of deep content inspection ==\nDCI is currently being adopted by enterprises, service providers and governments as a reaction to increasingly complex internet traffic with the benefits of understanding complete file types and their intent. Typically, these organizations have mission-critical applications with rigid requirements.\n\n== Obstacles to deep content inspection ==\n\n\n*** Network throughput ***\nThis type of inspection deals with real time protocols that only continue to increase in complexity and size. One of the key barriers for providing this level of inspection, that is looking at all content, is dealing with network throughput. Solutions must overcome this issue while not introducing latency into the network environment. They must also be able to effectively scale up to meet tomorrow's demands and the demands envisioned by the growing Cloud Computing trend.  One approach is to use selective scanning; however, to avoid compromising accuracy, the selection criteria should be based on recurrence.  The following patent USPTO# 7,630,379  provides a scheme as to how Deep Content Inspection can be carried out effectively using a recurrence selection scheme.  The novelty introduced by this patent is that it addresses issues such as content (E.g., an mp3 file) that could have been renamed before transmission.\n\n\n*** Accuracy of services ***\nDealing with the amount of traffic and information and then applying services requires very high speed look ups to be able to be effective. Need to compare against full services platforms or else having all traffic is not being utilized effectively. An example is often found in dealing with Viruses and Malicious content where solutions only compare content against a small virus database instead of a full and complete one.\n\nQuestion: How does the third generation of Network Content Inspection, Deep Content Inspection (DCI), differ from DPI?\n\nAnswer:",
    "context": "",
    "output": "DCI is a fully transparent device that performs full application-level content inspection at wire speed, providing exhaustive object analysis, signature matching, behavioral analysis, and correlation of sessions to history.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the third generation of Network Content Inspection, Deep Content Inspection (DCI), differ from DPI?",
      "answer": "DCI is a fully transparent device that performs full application-level content inspection at wire speed, providing exhaustive object analysis, signature matching, behavioral analysis, and correlation of sessions to history.",
      "context": "Deep content inspection\n\n==Introduction==\nDeep content inspection (DCI) is a form of network filtering that examines an entire file or MIME object as it passes an inspection point, searching for viruses, spam, data loss, key words or other content level criteria. Deep Content Inspection is considered the evolution of Deep Packet Inspection with the ability to look at what the actual content contains instead of focusing on individual or multiple packets. Deep Content Inspection allows services to keep track of content across multiple packets so that the signatures they may be searching for can cross packet boundaries and yet they will still be found. An exhaustive form of network traffic inspection in which Internet traffic is examined across all the seven OSI ISO layers, and most importantly, the application layer.\n\n\n\n== Background ==\nTraditional inspection technologies are unable to keep up with the recent outbreaks of widespread attacks. Unlike shallow inspection methods such as Deep Packet Inspection (DPI), where only the data part (and possibly also the header) of a packet are inspected, Deep Content Inspection (DCI)-based systems are exhaustive, such that network traffic packets are reassembled into their constituting objects, un-encoded and/or decompressed as required, and finally presented to be inspected for malware, right-of-use, compliance, and understanding of the traffic's intent. If this reconstruction and comprehension can be done in real-time, then real-time policies can be applied to traffic, preventing the propagation of malware, spam and valuable data loss.  Further, with DCI, the correlation and comprehension of the digital objects transmitted in many communication sessions leads to new ways of network performance optimization and intelligence regardless of protocol or blended communication sessions.\nHistorically, DPI was developed to detect and prevent intrusion. It was then used to provide Quality of Service where the flow of network traffic can be prioritized such that latency-sensitive traffic types (e.g., Voice over IP) can be utilized to provide higher flow priority.\nNew generation of Network Content Security devices such as Unified Threat Management or Next Generation Firewalls (Garner RAS Core Research Note G00174908) use DPI to prevent attacks from a small percentage of viruses and worms; the signatures of these malware fit within the payload of a DPI's inspection scope.  However, the detection and prevention of a new generation of malware such as Conficker and Stuxnet is only possible through the exhaustive analysis provided by DCI.\n\n\n*** The evolution of DPI systems ***\nComputer networks send information across a network from one point to another; the data (sometimes referred to as the payload) is \u2018encapsulated\u2019 within an IP packet, which looks as follows:\n\n*The IP Header provides address information - the sender and destination addresses, while the TCP/UDP Header provided other pertinent information such as the port number, etc. As networks evolve, inspection techniques evolve; all attempting to understand the payload. Throughout the last decade there have been vast improvements including:\n\n\n*** Packet filtering ***\nHistorically, inspection technology examined only the IP Header and the TCP/UDP Header.  Dubbed as \u2018Packet Filtering\u2019, these devices would drop sequence packets, or packets that are not allowed on a network. This scheme of network traffic inspection was first used by firewalls to protect against packet attacks.\n\n\n*** Stateful packet inspection ***\nStateful packet inspection was developed to examine header information and the packet content to increase source and destination understanding. Instead of letting the packets through as a result of their addresses and ports, packets stayed on the network if the context was appropriate to the networks\u2019 current \u2018state\u2019. This scheme was first used by Check Point firewalls and eventually Intrusion Prevention/Detection Systems.\n\n\n*** Deep packet inspection ***\nDeep Packet Inspection is currently the predominant inspection tool used to analyze data packets passing through the network, including the headers and the data protocol structures. These technologies scan packet streams and look for offending patterns.\nTo be effective, Deep Packet Inspection Systems must \u2018string\u2019 match Packet Payloads to malware signatures and specification signatures (which dictate what the request/response should be like) at wire speeds.  To do so, FPGAs, or Field Programmable Gate Arrays, Network Processors, or even Graphics Processing Units (GPUs) are programmed to be hardwired with these signatures and, as a result, traffic that passes through such circuitry is quickly matched.\nWhile using hardware allows for quick and inline matches, DPI systems have the following limitations including;\nHardware limitations: Since DPI systems implement their pattern matching (or searches for \u2018offending\u2019 patterns) through hardware, these systems are typically limited by:\n\nThe number of circuits a high-end DPI chip can have; as of 2011, this of a high end DPI system can, optimally, process around 512 request/response per session.\nThe memory available for pattern matches; as of 2011, high-end DPI systems are capable of matches of up to 60,000 unique signaturesPayload limitations: Web applications communicate content using binary-to-text encoding, compression (zipped, archived, etc.), obfuscation and even encryption.  As such payload structure is becoming more complex such that straight \u2018string\u2019 matching of the signatures is no longer sufficient.  The common workaround is to have signatures be similarly \u2018encoded\u2019 or zipped which, given the above \u2018search limitations\u2019, cannot scale to support every application type, or nested zipped or archived files.\n\n== Deep content inspection ==\nParallel to the development of Deep Packet Inspection, the beginnings of Deep Content Inspection can be traced back as early as 1995 with the introduction of proxies that stopped malware or spam. Deep Content Inspection, can be seen as the third generation of Network Content Inspection, where network content is exhaustively examined,\n\n\n*** First generation \u2013 secure web gateway or proxy-based network content inspection ***\nProxies have been deployed to provide internet caching services to retrieve objects and then forward them.  Consequently, all network traffic is intercepted, and potentially stored. These graduated to what is now known as secure web gateways, proxy-based inspections retrieve and scans object, script, and images.\nProxies, which relies on a fetch the content first if it were not cached, then forwarding the content to the recipient introduced some form of file inspection as early as 1995 when MAILsweeper was released by Content Technologies (now Clearswift), which was then replaced by MIMEsweeper in 2005. 2006 saw the release of the open-source, cross-platform antivirus software ClamAV provided support for caching proxies, Squid and NetCache. Using the  Internet Content Adaptation Protocol (ICAP), a proxy will pass the downloaded content for scanning to an ICAP server running an anti-virus software. Since complete files or \u2018objects\u2019 were passed for scanning, proxy-based anti-virus solutions are considered the first generation of network content inspection.\nBlueCoat, WebWasher and Secure Computing Inc. (now McAfee, now a division of Intel), provided commercial implementations of proxies, eventually becoming a standard network element in most enterprise networks.\nLimitations:\nWhile proxies (or secure web gateways) provide in-depth network traffic inspection, their use is limited as they: \n\nrequire network reconfiguration which is accomplished through \u2013 a) end-devices to get their browsers to point to these proxies; or b) on the network routers to get traffic routed through these devices\nare limited to web (http) and ftp protocols; cannot scan other protocols such as e-mail\nand finally, proxy architectures which are typically built around Squid, which cannot scale with concurrent sessions, limiting their deployment to enterprises.\n\n\n*** Second generation \u2013 gateway/firewall-based network traffic proxy-assisted deep packet inspection ***\nThe Second generation of Network Traffic Inspection solutions were implemented in firewalls and/or UTMs.  Given that network traffic is choked through these devices, in addition to DPI inspection, proxy-like inspection is possible. This approach was first pioneered by  NetScreen Technologies Inc. (acquired by Juniper Networks Inc). However, given the expensive cost of such operation, this feature was applied in tandem with a DPI system and was only activated on a-per-need basis, or when content failed to be qualified through the DPI system.\n\n\n*** Third generation \u2013 transparent, application-aware network content inspection, or deep content inspection ***\nThe third, and current, generation of Network Content Inspection known as Deep Content Inspection solutions are implemented as fully transparent devices that perform full application level content inspection at wire speed.  In order to understand the communication session's intent \u2014in its entirety\u2014, a Deep Content Inspection System must scan both the handshake and payload. Once the digital objects (executables, images, JavaScript's, .pdfs, etc. also referred to as Data-In-Motion) carried within the payload are constructed, usability, compliance and threat analysis of this session and its payload can be achieved.  Given that the handshake sequence and complete payload of the session is available to the DCI system, unlike DPI systems where simple pattern matching and reputation search are only possible, exhaustive object analysis is possible.  The inspection provided by DCI systems can include signature matching, behavioral analysis, regulatory and compliance analysis, and correlation of the session under inspection to the history of previous sessions.  Because of the availability of the complete payload's objects, and these schemes of inspection, Deep Content Inspection Systems are typically deployed where high-grade Security and Compliance is required or where end-point security solutions are not possible such as in bring your own device, or Cloud installations.\nThis third generation approach of Deep Content Inspection was developed within the defence and intelligence community, first appearing in guard products such as SyBard, and later by Wedge Networks Inc..  Key-implementation highlights of this Company's approach can be deduced from their patent USPTO# 7,630,379The main differentiators of Deep Content Inspection are:\n\n\n**** Content ****\nDeep Content Inspection is Content-focused instead of analyzing packets or classifying traffic based on application types such as in Next Generation Firewalls. \"Understanding\" content and its intent is the highest level of intelligence to be gained from network traffic. This is important as information flow is moving away from Packet, towards Application, and ultimately to Content.\nExample inspection levels:\n\nPacket: Random Sample to get larger picture\nApplication: Group or application profiling. Certain applications, or areas of applications, are allowed / not allowed or scanned further.\nContent: Look at everything. Scan everything. Subject the content to rules of inspection (such as Compliance/Data Loss Prevention rules).  Understand the intent.\n\n\n**** Multi-services inspection ****\nBecause of the availability of the complete objects of that payload to a Deep Content Inspection system, some of the services/inspection examples can include:\n\nAnti Malware\nAnti-spam\nData Loss for Data In Motion\nZero-Day or Unknown Threats\nNetwork Traffic Vizualization and Analytics\nCode Attacks/Injection\nContent Manipulation\n\n== Applications of deep content inspection ==\nDCI is currently being adopted by enterprises, service providers and governments as a reaction to increasingly complex internet traffic with the benefits of understanding complete file types and their intent. Typically, these organizations have mission-critical applications with rigid requirements.\n\n== Obstacles to deep content inspection ==\n\n\n*** Network throughput ***\nThis type of inspection deals with real time protocols that only continue to increase in complexity and size. One of the key barriers for providing this level of inspection, that is looking at all content, is dealing with network throughput. Solutions must overcome this issue while not introducing latency into the network environment. They must also be able to effectively scale up to meet tomorrow's demands and the demands envisioned by the growing Cloud Computing trend.  One approach is to use selective scanning; however, to avoid compromising accuracy, the selection criteria should be based on recurrence.  The following patent USPTO# 7,630,379  provides a scheme as to how Deep Content Inspection can be carried out effectively using a recurrence selection scheme.  The novelty introduced by this patent is that it addresses issues such as content (E.g., an mp3 file) that could have been renamed before transmission.\n\n\n*** Accuracy of services ***\nDealing with the amount of traffic and information and then applying services requires very high speed look ups to be able to be effective. Need to compare against full services platforms or else having all traffic is not being utilized effectively. An example is often found in dealing with Viruses and Malicious content where solutions only compare content against a small virus database instead of a full and complete one."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the maximum data transmission speed of the KIV-7?",
    "context": "",
    "output": "The KIV-7 has a maximum data transmission speed of 512 kbit/s.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the maximum data transmission speed of the KIV-7?",
      "answer": "The KIV-7 has a maximum data transmission speed of 512 kbit/s."
    }
  },
  {
    "instruction": "Write an answer to the following question: What disadvantages are associated with relaying mail through an acknowledged ISP?",
    "context": "",
    "output": "Relaying mail through an acknowledged ISP prevents users from publishing a proper SPF policy, and it may be incompatible with fine-grained IP address blocking. If the ISP's email relay is blocked due to spam, it affects all users, potentially disrupting email delivery.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What disadvantages are associated with relaying mail through an acknowledged ISP?",
      "answer": "Relaying mail through an acknowledged ISP prevents users from publishing a proper SPF policy, and it may be incompatible with fine-grained IP address blocking. If the ISP's email relay is blocked due to spam, it affects all users, potentially disrupting email delivery."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are the two names by which the TLS and SSL protocols implementation is known?",
    "context": "",
    "output": "The two names are Mbed TLS and PolarSSL.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are the two names by which the TLS and SSL protocols implementation is known?",
      "answer": "The two names are Mbed TLS and PolarSSL."
    }
  },
  {
    "instruction": "Write an answer to the following question: Why is information-theoretic cryptography considered quantum-safe?",
    "context": "",
    "output": "Information-theoretic cryptography is considered quantum-safe because it is not dependent on the computational difficulty of solving mathematical problems, which could be affected by the development of quantum computers.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Why is information-theoretic cryptography considered quantum-safe?",
      "answer": "Information-theoretic cryptography is considered quantum-safe because it is not dependent on the computational difficulty of solving mathematical problems, which could be affected by the development of quantum computers."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are some common automated techniques for discovering buffer overflows?",
    "context": "",
    "output": "Some common automated techniques for discovering buffer overflows include fuzzing, edge case testing, and static analysis. These techniques can help uncover potential buffer overflows in software that is in development, but may not be as useful for legacy software that is no longer maintained or supported.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are some common automated techniques for discovering buffer overflows?",
      "answer": "Some common automated techniques for discovering buffer overflows include fuzzing, edge case testing, and static analysis. These techniques can help uncover potential buffer overflows in software that is in development, but may not be as useful for legacy software that is no longer maintained or supported."
    }
  },
  {
    "instruction": "Comparison of OTP applications\n\n==Introduction==\nThe following is a general comparison of OTP applications that are used to generate one-time passwords for two-factor authentication (2FA) systems using the time-based one-time password (TOTP) or the HMAC-based one-time password (HOTP) algorithms.\n\n\n\n== Authenticated implementations ==\nQuestion: What are some of the potential future developments in TOTP and HOTP algorithms for 2FA systems?",
    "context": "",
    "output": "Answer: Potential future developments in TOTP and HOTP algorithms for 2FA systems include the use of advanced cryptographic techniques, such as elliptic curve cryptography, and the integration with biometric authentication methods, such as fingerprint or facial recognition. Additionally, there may be further research into making TOTP and HOTP algorithms more user-friendly and resistant to attacks.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are some of the potential future developments in TOTP and HOTP algorithms for 2FA systems?",
      "answer": "Potential future developments in TOTP and HOTP algorithms for 2FA systems include the use of advanced cryptographic techniques, such as elliptic curve cryptography, and the integration with biometric authentication methods, such as fingerprint or facial recognition. Additionally, there may be further research into making TOTP and HOTP algorithms more user-friendly and resistant to attacks.",
      "context": "Comparison of OTP applications\n\n==Introduction==\nThe following is a general comparison of OTP applications that are used to generate one-time passwords for two-factor authentication (2FA) systems using the time-based one-time password (TOTP) or the HMAC-based one-time password (HOTP) algorithms.\n\n\n\n== Authenticated implementations =="
    }
  },
  {
    "instruction": "Write an answer to the following question: What are the potential consequences of failing to protect classified information from unauthorized disclosure during and after employment in the US?",
    "context": "",
    "output": "Failing to protect classified information from unauthorized disclosure during and after employment in the US can result in criminal, civil, and administrative sanctions. Those who have access to Special Operational Information are held to a higher standard and the release of such information is punishable by law, under section 17(2) of the Security of Information Act, liable to imprisonment for life. Section 750(3) of the Criminal Code states that no person convicted of an offence under certain sections concerning frauds on the Government, selling or purchasing office, fraud directed against His Majesty, or selling defective stores to His Majesty, has the capacity to contract with His Majesty or to receive any benefits under a contract between His Majesty and any other person or to hold office under His Majesty unless a pardon has been granted. This effectively prohibits granting of a Reliability Status to any such individual.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are the potential consequences of failing to protect classified information from unauthorized disclosure during and after employment in the US?",
      "answer": "Failing to protect classified information from unauthorized disclosure during and after employment in the US can result in criminal, civil, and administrative sanctions. Those who have access to Special Operational Information are held to a higher standard and the release of such information is punishable by law, under section 17(2) of the Security of Information Act, liable to imprisonment for life. Section 750(3) of the Criminal Code states that no person convicted of an offence under certain sections concerning frauds on the Government, selling or purchasing office, fraud directed against His Majesty, or selling defective stores to His Majesty, has the capacity to contract with His Majesty or to receive any benefits under a contract between His Majesty and any other person or to hold office under His Majesty unless a pardon has been granted. This effectively prohibits granting of a Reliability Status to any such individual."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does OCSP checking work in Internet Explorer, Firefox, Safari, and Opera?",
    "context": "",
    "output": "Internet Explorer supports OCSP checking starting with version 7 on Windows Vista, Firefox enables OCSP checking by default, Safari on macOS supports OCSP checking and is enabled by default as of Mac OS X 10.7, and versions of Opera from 8.0 to the current version support OCSP checking.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does OCSP checking work in Internet Explorer, Firefox, Safari, and Opera?",
      "answer": "Internet Explorer supports OCSP checking starting with version 7 on Windows Vista, Firefox enables OCSP checking by default, Safari on macOS supports OCSP checking and is enabled by default as of Mac OS X 10.7, and versions of Opera from 8.0 to the current version support OCSP checking."
    }
  },
  {
    "instruction": "Write an answer to the following question: What did the Treasury Department say about John Solomon's role in spreading disinformation about Biden?",
    "context": "",
    "output": "The Treasury Department said that journalists like John Solomon, a contributor to Fox News, were pivotal for the dissemination of disinformation about Biden and aided Giuliani and Derkach's efforts to spread anti-Biden material during Trump's impeachment.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What did the Treasury Department say about John Solomon's role in spreading disinformation about Biden?",
      "answer": "The Treasury Department said that journalists like John Solomon, a contributor to Fox News, were pivotal for the dissemination of disinformation about Biden and aided Giuliani and Derkach's efforts to spread anti-Biden material during Trump's impeachment."
    }
  },
  {
    "instruction": "Write an answer to the following question: How was the breach of Kaspersky Lab in 2014 significant in the context of international negotiations with Iran over its nuclear program and economic sanctions?",
    "context": "",
    "output": "The breach of Kaspersky Lab in 2014 was significant in the context of international negotiations with Iran as the malware, Duqu 2.0, was found on computers in hotels in Austria and Switzerland hosting the negotiations. This breach potentially allowed for the retrieval of sensitive data related to the negotiations. The New York Times alleges that this incident enabled Israel to inform the US of Russian hackers using Kaspersky software to collect confidential information, which could have influenced the negotiations.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How was the breach of Kaspersky Lab in 2014 significant in the context of international negotiations with Iran over its nuclear program and economic sanctions?",
      "answer": "The breach of Kaspersky Lab in 2014 was significant in the context of international negotiations with Iran as the malware, Duqu 2.0, was found on computers in hotels in Austria and Switzerland hosting the negotiations. This breach potentially allowed for the retrieval of sensitive data related to the negotiations. The New York Times alleges that this incident enabled Israel to inform the US of Russian hackers using Kaspersky software to collect confidential information, which could have influenced the negotiations."
    }
  },
  {
    "instruction": "Write an answer to the following question: What was the media coverage about Hajime in April 2017?",
    "context": "",
    "output": "In April 2017, Hajime received large media coverage due to its competition with Mirai and its similar purpose to Linux.Wifatch.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was the media coverage about Hajime in April 2017?",
      "answer": "In April 2017, Hajime received large media coverage due to its competition with Mirai and its similar purpose to Linux.Wifatch."
    }
  },
  {
    "instruction": "Nitrokey\n\n==Introduction==\nNitrokey is an open-source USB key used to enable the secure encryption and signing of data. The secret keys are always stored inside the Nitrokey which protects against malware (such as computer viruses) and attackers. A user-chosen PIN and a tamper-proof smart card protect the Nitrokey in case of loss and theft. The hardware and software of Nitrokey are open-source. The free software and open hardware enables independent parties to verify the security of the device. Nitrokey is supported on Microsoft Windows, macOS, Linux, and BSD.\n\n\n\n== Technical features ==\nSeveral Nitrokey models exist and the Nitrokey Pro is the flagship model. It contains the following features:\n\nA secure key storage to support OpenPGP (popular with individuals) and S/MIME (popular with businesses) email encryption standards. Nitrokey can also be used with various 3rd party applications such as TrueCrypt and VeraCrypt for disk encryption.\nOne-time passwords (which are similar to TANs and used as a secondary security measure in addition to ordinary passwords). It supports the HMAC-based One-time Password Algorithm (HOTP, RFC 4226) and Time-based One-time Password Algorithm (TOTP, RFC 6238), which are compatible with Google Authenticator.\nClient Certificate Authentication is used to administrate servers securely via SSH, access Virtual Private Networks via OpenVPN.\nPassword Safe stores encrypted static passwords inside the Nitrokey.The upcoming Nitrokey Storage provides the same features as the Nitrokey Pro and additionally contains an encrypted mass storage.\n\n== Characteristics ==\nNitrokey's secret keys are stored securely internally.\nA user-chosen PIN protects in case of loss and theft.\nNitrokey's tamper-proof design protects it from sophisticated physical attacks.\nRSA keys of up to 4096 bit and AES-256 are supported.\nIt is supported for Microsoft Windows, macOS, Linux, and BSD.\nIt is compatible with many popular software like Microsoft Outlook, Mozilla Thunderbird, and OpenSSH.\nThe secure implementation of the Nitrokey is published as open source and open hardware to enable independent reviews of the source code and hardware layout and to ensure the absence of back doors and other security flaws.\nNitrokey's security is not dependent upon secret keys stored centrally with the device manufacturer.\nNitrokey is published as open source software, free software, and open hardware.\n\n== Devices ==\nNitrokey Start \nNitrokey HSM \nNitrokey Pro \nNitrokey Storage 16GB \nNitrokey Storage 32GB \nNitrokey Storage 64GB \nNitrokey FIDO U2F \nNitrokey FIDO2\n\n== Philosophy ==\nNitrokey's developers believe that proprietary systems cannot provide strong security and that security systems need to be open source. For instance there have been cases in which NSA intercepts security devices being shipped and implanted backdoors into it. In 2011 RSA was hacked and secret keys of securID tokens been stolen which allowed hackers to circumvent their authentication. As revealed in 2010, many FIPS 140-2 Level 2 certified USB storage devices from various manufacturers could easily be cracked by using a default password. Nitrokey, because of being open source and because of its transparency, wants to provide high secure system and avoid security issues which its proprietary rivals were facing. Nitrokey's mission is to provide the best Open Source security key to protect the digital lives of its users.\n\nHow does the Nitrokey's centralized key storage differ from its proprietary rivals?",
    "context": "",
    "output": "The Nitrokey's security is not dependent upon secret keys stored centrally with the device manufacturer, unlike many proprietary systems. This means that the Nitrokey is less vulnerable to attacks that target the device manufacturer's centralized key storage, and provides users with greater control over their own security.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the Nitrokey's centralized key storage differ from its proprietary rivals?",
      "answer": "The Nitrokey's security is not dependent upon secret keys stored centrally with the device manufacturer, unlike many proprietary systems. This means that the Nitrokey is less vulnerable to attacks that target the device manufacturer's centralized key storage, and provides users with greater control over their own security.",
      "context": "Nitrokey\n\n==Introduction==\nNitrokey is an open-source USB key used to enable the secure encryption and signing of data. The secret keys are always stored inside the Nitrokey which protects against malware (such as computer viruses) and attackers. A user-chosen PIN and a tamper-proof smart card protect the Nitrokey in case of loss and theft. The hardware and software of Nitrokey are open-source. The free software and open hardware enables independent parties to verify the security of the device. Nitrokey is supported on Microsoft Windows, macOS, Linux, and BSD.\n\n\n\n== Technical features ==\nSeveral Nitrokey models exist and the Nitrokey Pro is the flagship model. It contains the following features:\n\nA secure key storage to support OpenPGP (popular with individuals) and S/MIME (popular with businesses) email encryption standards. Nitrokey can also be used with various 3rd party applications such as TrueCrypt and VeraCrypt for disk encryption.\nOne-time passwords (which are similar to TANs and used as a secondary security measure in addition to ordinary passwords). It supports the HMAC-based One-time Password Algorithm (HOTP, RFC 4226) and Time-based One-time Password Algorithm (TOTP, RFC 6238), which are compatible with Google Authenticator.\nClient Certificate Authentication is used to administrate servers securely via SSH, access Virtual Private Networks via OpenVPN.\nPassword Safe stores encrypted static passwords inside the Nitrokey.The upcoming Nitrokey Storage provides the same features as the Nitrokey Pro and additionally contains an encrypted mass storage.\n\n== Characteristics ==\nNitrokey's secret keys are stored securely internally.\nA user-chosen PIN protects in case of loss and theft.\nNitrokey's tamper-proof design protects it from sophisticated physical attacks.\nRSA keys of up to 4096 bit and AES-256 are supported.\nIt is supported for Microsoft Windows, macOS, Linux, and BSD.\nIt is compatible with many popular software like Microsoft Outlook, Mozilla Thunderbird, and OpenSSH.\nThe secure implementation of the Nitrokey is published as open source and open hardware to enable independent reviews of the source code and hardware layout and to ensure the absence of back doors and other security flaws.\nNitrokey's security is not dependent upon secret keys stored centrally with the device manufacturer.\nNitrokey is published as open source software, free software, and open hardware.\n\n== Devices ==\nNitrokey Start \nNitrokey HSM \nNitrokey Pro \nNitrokey Storage 16GB \nNitrokey Storage 32GB \nNitrokey Storage 64GB \nNitrokey FIDO U2F \nNitrokey FIDO2\n\n== Philosophy ==\nNitrokey's developers believe that proprietary systems cannot provide strong security and that security systems need to be open source. For instance there have been cases in which NSA intercepts security devices being shipped and implanted backdoors into it. In 2011 RSA was hacked and secret keys of securID tokens been stolen which allowed hackers to circumvent their authentication. As revealed in 2010, many FIPS 140-2 Level 2 certified USB storage devices from various manufacturers could easily be cracked by using a default password. Nitrokey, because of being open source and because of its transparency, wants to provide high secure system and avoid security issues which its proprietary rivals were facing. Nitrokey's mission is to provide the best Open Source security key to protect the digital lives of its users."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are coordinated vulnerability platforms, and how are they used in application security?",
    "context": "",
    "output": "Coordinated vulnerability platforms are hacker-powered application security solutions that allow individuals to report bugs and receive recognition and compensation. They help developers find and fix security vulnerabilities in their applications.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are coordinated vulnerability platforms, and how are they used in application security?",
      "answer": "Coordinated vulnerability platforms are hacker-powered application security solutions that allow individuals to report bugs and receive recognition and compensation. They help developers find and fix security vulnerabilities in their applications."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the purpose of the device mapper (dm) infrastructure in dm-crypt?",
    "context": "",
    "output": "The device mapper (dm) infrastructure in dm-crypt is used for creating, deleting, and managing logical volumes on a block device. It provides a way to map physical devices to virtual ones, enabling manipulation of data storage in a flexible and powerful way.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the purpose of the device mapper (dm) infrastructure in dm-crypt?",
      "answer": "The device mapper (dm) infrastructure in dm-crypt is used for creating, deleting, and managing logical volumes on a block device. It provides a way to map physical devices to virtual ones, enabling manipulation of data storage in a flexible and powerful way."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the difference between the trust levels provided by the different solutions to the end node problem?",
    "context": "",
    "output": "The trust levels provided by the different solutions to the end node problem depend on the level of control and validation exercised over the end nodes, with the highest level of trust provided by immutable, tamper-resistant clients and the lowest level provided by allowing any hardware to connect with strong user authentication.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the difference between the trust levels provided by the different solutions to the end node problem?",
      "answer": "The trust levels provided by the different solutions to the end node problem depend on the level of control and validation exercised over the end nodes, with the highest level of trust provided by immutable, tamper-resistant clients and the lowest level provided by allowing any hardware to connect with strong user authentication."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the role of miners in a cryptocurrency network and how are they compensated?",
    "context": "",
    "output": "Miners in a cryptocurrency network are responsible for validating and timestamping transactions, adding them to the blockchain ledger, and maintaining the security and integrity of the network. They are compensated with new units of the cryptocurrency as a block reward, as well as transaction fees.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of miners in a cryptocurrency network and how are they compensated?",
      "answer": "Miners in a cryptocurrency network are responsible for validating and timestamping transactions, adding them to the blockchain ledger, and maintaining the security and integrity of the network. They are compensated with new units of the cryptocurrency as a block reward, as well as transaction fees."
    }
  },
  {
    "instruction": "Context: SpamBayes\n\n==Introduction==\nSpamBayes is a Bayesian spam filter written in Python which uses techniques laid out by Paul Graham in his essay \"A Plan for Spam\". It has subsequently been improved by Gary Robinson and Tim Peters, among others.\nThe most notable difference between a conventional Bayesian filter and the filter used by SpamBayes is that there are three classifications rather than two: spam, non-spam (called ham in SpamBayes), and unsure. The user trains a message as being either ham or spam; when filtering a message, the spam filters generate one score for ham and another for spam.\nIf the spam score is high and the ham score is low, the message will be classified as spam.\nIf the spam score is low and the ham score is high, the message will be classified as ham.\nIf the scores are both high or both low, the message will be classified as unsure.\nThis approach leads to a low number of false positives and false negatives, but it may result in a number of unsures which need a human decision.\n\n== Web filtering ==\nSome work has gone into applying SpamBayes to filter internet content via a proxy web server.\nAnswer this question: What is the role of the user in SpamBayes classification process?",
    "context": "",
    "output": "The user plays an important role in SpamBayes classification process by training messages as ham or spam, and making a decision for messages classified as unsure.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of the user in SpamBayes classification process?",
      "answer": "The user plays an important role in SpamBayes classification process by training messages as ham or spam, and making a decision for messages classified as unsure.",
      "context": "SpamBayes\n\n==Introduction==\nSpamBayes is a Bayesian spam filter written in Python which uses techniques laid out by Paul Graham in his essay \"A Plan for Spam\". It has subsequently been improved by Gary Robinson and Tim Peters, among others.\nThe most notable difference between a conventional Bayesian filter and the filter used by SpamBayes is that there are three classifications rather than two: spam, non-spam (called ham in SpamBayes), and unsure. The user trains a message as being either ham or spam; when filtering a message, the spam filters generate one score for ham and another for spam.\nIf the spam score is high and the ham score is low, the message will be classified as spam.\nIf the spam score is low and the ham score is high, the message will be classified as ham.\nIf the scores are both high or both low, the message will be classified as unsure.\nThis approach leads to a low number of false positives and false negatives, but it may result in a number of unsures which need a human decision.\n\n== Web filtering ==\nSome work has gone into applying SpamBayes to filter internet content via a proxy web server."
    }
  },
  {
    "instruction": "Justniffer\n\n==Introduction==\nJustniffer is a TCP packet sniffer. It can log network traffic in a 'standard' (web server-like) or in a customized way. It can also log response times, useful for tracking network services performances (e.g. web server, application server, etc.).\nThe output format of the traffic can be easily customized. An example written in Python (delivered with the official package) stores the transferred contents in an output directory separated by domains. This means that the transferred files like html, css, javascript, images, sounds, etc. can be saved to a directory.\n\n\n\n== Overview ==\njustniffer was born to help in troubleshooting performance in network TCP-based services: HTTP, RTSP, SIP, SMTP, IMAP, POP, LDAP, Telnet etc.\nIt can collect low and high level protocol and performance information, reconstructing the TCP flow in a reliable way using portions of the Linux kernel code. It uses a slightly modified version of the libnids libraries that already include a modified version of Linux kernel code in a more reusable way.\nIt can be extended with external scripts (bash, Python, or any executable) and generate logs in a customizable way\nThe man page for justniffer explains all the options.\n\n== Examples ==\nExamples\n\n== Grab http traffic and observe ==\nGrab Http traffic\nQ: How can Justniffer be used to monitor the performance of a web server?",
    "context": "",
    "output": "Justniffer can log response times, which is useful for tracking network services performances such as a web server.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can Justniffer be used to monitor the performance of a web server?",
      "answer": "Justniffer can log response times, which is useful for tracking network services performances such as a web server.",
      "context": "Justniffer\n\n==Introduction==\nJustniffer is a TCP packet sniffer. It can log network traffic in a 'standard' (web server-like) or in a customized way. It can also log response times, useful for tracking network services performances (e.g. web server, application server, etc.).\nThe output format of the traffic can be easily customized. An example written in Python (delivered with the official package) stores the transferred contents in an output directory separated by domains. This means that the transferred files like html, css, javascript, images, sounds, etc. can be saved to a directory.\n\n\n\n== Overview ==\njustniffer was born to help in troubleshooting performance in network TCP-based services: HTTP, RTSP, SIP, SMTP, IMAP, POP, LDAP, Telnet etc.\nIt can collect low and high level protocol and performance information, reconstructing the TCP flow in a reliable way using portions of the Linux kernel code. It uses a slightly modified version of the libnids libraries that already include a modified version of Linux kernel code in a more reusable way.\nIt can be extended with external scripts (bash, Python, or any executable) and generate logs in a customizable way\nThe man page for justniffer explains all the options.\n\n== Examples ==\nExamples\n\n== Grab http traffic and observe ==\nGrab Http traffic"
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the StingRay use GSM Active Key Extraction to obtain the target device's stored encryption key?",
    "context": "",
    "output": "The StingRay uses GSM Active Key Extraction to obtain the target device's stored encryption key by instructing the target device to use the weaker A5/2 encryption cypher, collecting A5/2 encrypted signals from the target device, and performing cryptanalysis of the A5/2 signals to quickly recover the underlying stored encryption key.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the StingRay use GSM Active Key Extraction to obtain the target device's stored encryption key?",
      "answer": "The StingRay uses GSM Active Key Extraction to obtain the target device's stored encryption key by instructing the target device to use the weaker A5/2 encryption cypher, collecting A5/2 encrypted signals from the target device, and performing cryptanalysis of the A5/2 signals to quickly recover the underlying stored encryption key."
    }
  },
  {
    "instruction": "Xceedium\n\n==Introduction==\nXceedium, Inc., was a network security software company providing privileged identity and access management solutions which was subsequently acquired by CA Technologies. Their software is used to control and manage the risks that privileged users, privileged accounts (admin, root, etc.) and privileged credentials (passwords, certificates, digital keys, etc.) pose to systems and data.\n\n\n\n== Products ==\nXceedium Gatekeeper was the first product designed by the company, initially built with out-of-band and in-band KVM for remote IT control. The GateKeeper software was updated to provide network-based access control and session recording/playback.  Later, GateKeeper and Cloakware Password Authority (a product acquired from Irdeto) were integrated to form Xceedium Xsuite.\nThe main capabilities of Xceedium Xsuite were: role-based access control, command filtering (white/black list), user containment (prevents SSH based leapfrogging or RDP hopping to unauthorized nodes), session monitoring/policy violation alerting, session recording and playback and privileged password vaulting and management. The Xceedium Xsuite platform enabled organizations to apply the principle of least privilege, which holds that systems and individuals should only be granted access to the resources and commands that are absolutely necessary for the required task. According to the company, Xsuite limited access for privileged users to the systems and commands for which they are explicitly authorized (Role-based access control). It also monitored the activities of privileged users and sent alerts when individuals attempted to violate a policy. The system recorded privileged user sessions such as telnet, RDP, SSH, and VNC and provided a mechanism to replay recorded session for investigations and forensics.\nXsuite Cloud for Amazon Web Services (AWS) was introduced as an extension to the Xsuite platform. It provided privileged identity and access management for standalone AWS implementations or hybrid architectures that can include infrastructure nodes (e.g., servers, network devices, storage devices, security systems) running on: AWS Amazon Elastic Compute Cloud (EC2), private clouds, as virtual machines or traditional single OS/hardware scenariosFollowing the acquisition of Xceedium by CA, Xceedium Xsuite was integrated into the CA product range as CA Privileged Access Manager.\n\nAnswer this question based on the above context: How did Xceedium's Gatekeeper software evolve over time, and what were its main capabilities?",
    "context": "",
    "output": "Xceedium's Gatekeeper software was initially built with out-of-band and in-band KVM for remote IT control. Later, it was updated to provide network-based access control and session recording/playback. When integrated with Cloakware Password Authority, it formed Xceedium Xsuite, which offered role-based access control, command filtering, user containment, session monitoring/policy violation alerting, session recording and playback, and privileged password vaulting and management.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How did Xceedium's Gatekeeper software evolve over time, and what were its main capabilities?",
      "answer": "Xceedium's Gatekeeper software was initially built with out-of-band and in-band KVM for remote IT control. Later, it was updated to provide network-based access control and session recording/playback. When integrated with Cloakware Password Authority, it formed Xceedium Xsuite, which offered role-based access control, command filtering, user containment, session monitoring/policy violation alerting, session recording and playback, and privileged password vaulting and management.",
      "context": "Xceedium\n\n==Introduction==\nXceedium, Inc., was a network security software company providing privileged identity and access management solutions which was subsequently acquired by CA Technologies. Their software is used to control and manage the risks that privileged users, privileged accounts (admin, root, etc.) and privileged credentials (passwords, certificates, digital keys, etc.) pose to systems and data.\n\n\n\n== Products ==\nXceedium Gatekeeper was the first product designed by the company, initially built with out-of-band and in-band KVM for remote IT control. The GateKeeper software was updated to provide network-based access control and session recording/playback.  Later, GateKeeper and Cloakware Password Authority (a product acquired from Irdeto) were integrated to form Xceedium Xsuite.\nThe main capabilities of Xceedium Xsuite were: role-based access control, command filtering (white/black list), user containment (prevents SSH based leapfrogging or RDP hopping to unauthorized nodes), session monitoring/policy violation alerting, session recording and playback and privileged password vaulting and management. The Xceedium Xsuite platform enabled organizations to apply the principle of least privilege, which holds that systems and individuals should only be granted access to the resources and commands that are absolutely necessary for the required task. According to the company, Xsuite limited access for privileged users to the systems and commands for which they are explicitly authorized (Role-based access control). It also monitored the activities of privileged users and sent alerts when individuals attempted to violate a policy. The system recorded privileged user sessions such as telnet, RDP, SSH, and VNC and provided a mechanism to replay recorded session for investigations and forensics.\nXsuite Cloud for Amazon Web Services (AWS) was introduced as an extension to the Xsuite platform. It provided privileged identity and access management for standalone AWS implementations or hybrid architectures that can include infrastructure nodes (e.g., servers, network devices, storage devices, security systems) running on: AWS Amazon Elastic Compute Cloud (EC2), private clouds, as virtual machines or traditional single OS/hardware scenariosFollowing the acquisition of Xceedium by CA, Xceedium Xsuite was integrated into the CA product range as CA Privileged Access Manager."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the purpose of a code access demand in .NET Code Access Security?",
    "context": "",
    "output": "The purpose of a code access demand is to make the CLR walk the call stack and for each method to ensure that the demanded permissions are in the method's assembly's granted permissions. If the permission is not granted, a security exception is thrown.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the purpose of a code access demand in .NET Code Access Security?",
      "answer": "The purpose of a code access demand is to make the CLR walk the call stack and for each method to ensure that the demanded permissions are in the method's assembly's granted permissions. If the permission is not granted, a security exception is thrown."
    }
  },
  {
    "instruction": "AusCERT\n\n==Introduction==\nAusCERT is a non-profit organisation founded in 1993, that provides advice and solutions to cybersecurity threats and vulnerabilities. The organisation covers their costs through member subscriptions, attendees to the annual AusCERT conference and service contracts.\n\n== Services ==\nAusCERT covers their costs by selling member subscriptions and service contracts to individuals and businesses. The organisation boasts its 24/7 support and incident management against cyber threats. Other services include phishing take-down, security bulletins, incident notifications, sensitive information alerts, early warning SMS, and malicious URL feeds.Engaged and active within the incident response teams at a global level; AusCERT is a charter member of APCERT  as well as a member of the Forum of Incident Response and Security Teams (FIRST).\n\n== AusCERT Annual Conference ==\nAusCERT has been hosting cybersecurity conferences in Australia since 2002. The conference takes place every year with presentations and hands-on tutorials for industry professionals. The AusCERT Conference is the oldest information security conference in Australia and was once the biggest conference in the country.\nOver the last few years, the conference has attracted approximately 800 participants, 50 sponsors and more than 50 speakers. The four-day program generally includes tutorials, keynote speakers, a gala dinner and Australian Information Security Awards, and a speed debate.In 2020, due to the COVID-19 pandemic, AusCERT hosted their first virtual conference with over a 1000 delegates registering. The conference MC was Adam Spencer and featured speakers Julie Inman (eSafety Commission), Kana Shinoda (Code Blue), and Lukasz Gogolkiewicz (Seek).\n\n== Additional Activities ==\nThe organisation currently supports and shares cybersecurity techniques opening with the following groups:\n\nThe Australian Access Federation,\nCyber Security threat annual surveys with BDO,\nInternational Training with APNIC,\nTraining and support with KrCERT, and\nCouncil of Australian University Directors of Information Technology (CAUDIT).\nRead the text above and answer this question: How does AusCERT support and share cybersecurity techniques with other organizations?",
    "context": "",
    "output": "AusCERT supports and shares cybersecurity techniques with organizations such as the Australian Access Federation, BDO, APNIC, KrCERT, and CAUDIT.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does AusCERT support and share cybersecurity techniques with other organizations?",
      "answer": "AusCERT supports and shares cybersecurity techniques with organizations such as the Australian Access Federation, BDO, APNIC, KrCERT, and CAUDIT.",
      "context": "AusCERT\n\n==Introduction==\nAusCERT is a non-profit organisation founded in 1993, that provides advice and solutions to cybersecurity threats and vulnerabilities. The organisation covers their costs through member subscriptions, attendees to the annual AusCERT conference and service contracts.\n\n== Services ==\nAusCERT covers their costs by selling member subscriptions and service contracts to individuals and businesses. The organisation boasts its 24/7 support and incident management against cyber threats. Other services include phishing take-down, security bulletins, incident notifications, sensitive information alerts, early warning SMS, and malicious URL feeds.Engaged and active within the incident response teams at a global level; AusCERT is a charter member of APCERT  as well as a member of the Forum of Incident Response and Security Teams (FIRST).\n\n== AusCERT Annual Conference ==\nAusCERT has been hosting cybersecurity conferences in Australia since 2002. The conference takes place every year with presentations and hands-on tutorials for industry professionals. The AusCERT Conference is the oldest information security conference in Australia and was once the biggest conference in the country.\nOver the last few years, the conference has attracted approximately 800 participants, 50 sponsors and more than 50 speakers. The four-day program generally includes tutorials, keynote speakers, a gala dinner and Australian Information Security Awards, and a speed debate.In 2020, due to the COVID-19 pandemic, AusCERT hosted their first virtual conference with over a 1000 delegates registering. The conference MC was Adam Spencer and featured speakers Julie Inman (eSafety Commission), Kana Shinoda (Code Blue), and Lukasz Gogolkiewicz (Seek).\n\n== Additional Activities ==\nThe organisation currently supports and shares cybersecurity techniques opening with the following groups:\n\nThe Australian Access Federation,\nCyber Security threat annual surveys with BDO,\nInternational Training with APNIC,\nTraining and support with KrCERT, and\nCouncil of Australian University Directors of Information Technology (CAUDIT)."
    }
  },
  {
    "instruction": "Fiat\u2013Shamir heuristic\n\n==Introduction==\nIn cryptography, the Fiat\u2013Shamir heuristic is a technique for taking an interactive proof of knowledge and creating a digital signature based on it. This way, some fact (for example, knowledge of a certain secret number) can be publicly proven without revealing underlying information. The technique is due to Amos Fiat and Adi Shamir (1986).\nFor the method to work, the original interactive proof must have the property of being public-coin, i.e. verifier's random coins are made public throughout the proof protocol.\nThe heuristic was originally presented without a proof of security; later, Pointcheval and Stern proved its security against chosen message attacks in the random oracle model, that is, assuming random oracles exist. This result was generalized to the quantum-accessible random oracle (QROM) by Don, Fehr, Majenz and Schaffner, and concurrently by Liu and Zhandry. In the case that random oracles do not exist, the Fiat\u2013Shamir heuristic has been proven insecure by Shafi Goldwasser and Yael Tauman Kalai. The Fiat\u2013Shamir heuristic thus demonstrates a major application of random oracles. \nMore generally, the Fiat\u2013Shamir heuristic may also be viewed as converting a public-coin interactive proof of knowledge into a non-interactive proof of knowledge. If the interactive proof is used as an identification tool, then the non-interactive version can be used directly as a digital signature by using the message as part of the input to the random oracle.\n\n\n\n== Example ==\nFor the algorithm specified below, readers should be familiar with the multiplicative groups \n  \n    \n      \n        \n          \n            Z\n          \n          \n            q\n          \n          \n            \u2217\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {Z} _{q}^{*}}\n  , where q is a prime number, and Euler's totient theorem on the Euler's totient function \u03c6.\nHere is an interactive proof of knowledge of a discrete logarithm in \n  \n    \n      \n        \n          \n            Z\n          \n          \n            q\n          \n          \n            \u2217\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {Z} _{q}^{*}}\n  , based on Schnorr signature. The public values are \n  \n    \n      \n        y\n        \u2208\n        \n          \n            Z\n          \n          \n            q\n          \n          \n            \u2217\n          \n        \n      \n    \n    {\\displaystyle y\\in \\mathbb {Z} _{q}^{*}}\n   and a generator g of  \n  \n    \n      \n        \n          \n            Z\n          \n          \n            q\n          \n          \n            \u2217\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {Z} _{q}^{*}}\n  , while the secret value is the discrete logarithm of y to the base g.\n\nPeggy wants to prove to Victor, the verifier, that she knows \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n   satisfying \n  \n    \n      \n        y\n        \u2261\n        \n          g\n          \n            x\n          \n        \n      \n    \n    {\\displaystyle y\\equiv g^{x}}\n   without revealing \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  .\nShe picks a random \n  \n    \n      \n        v\n        \u2208\n        \n          \n            Z\n          \n          \n            q\n          \n          \n            \u2217\n          \n        \n      \n    \n    {\\displaystyle v\\in \\mathbb {Z} _{q}^{*}}\n  , computes \n  \n    \n      \n        t\n\n== Extension of this method ==\nAs long as a fixed random generator can be constructed with the data known to both parties, then any interactive protocol can be transformed into a non-interactive one.\n\nBased on the above text, answer a question. What is the Fiat-Shamir heuristic and how does it work?",
    "context": "",
    "output": "The Fiat-Shamir heuristic is a technique for converting an interactive proof of knowledge into a digital signature. It is used to prove a fact without revealing the underlying information. This technique works by taking an interactive proof with the property of being public-coin and creating a digital signature based on it. The signature can then be used to prove the fact publicly.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the Fiat-Shamir heuristic and how does it work?",
      "answer": "The Fiat-Shamir heuristic is a technique for converting an interactive proof of knowledge into a digital signature. It is used to prove a fact without revealing the underlying information. This technique works by taking an interactive proof with the property of being public-coin and creating a digital signature based on it. The signature can then be used to prove the fact publicly.",
      "context": "Fiat\u2013Shamir heuristic\n\n==Introduction==\nIn cryptography, the Fiat\u2013Shamir heuristic is a technique for taking an interactive proof of knowledge and creating a digital signature based on it. This way, some fact (for example, knowledge of a certain secret number) can be publicly proven without revealing underlying information. The technique is due to Amos Fiat and Adi Shamir (1986).\nFor the method to work, the original interactive proof must have the property of being public-coin, i.e. verifier's random coins are made public throughout the proof protocol.\nThe heuristic was originally presented without a proof of security; later, Pointcheval and Stern proved its security against chosen message attacks in the random oracle model, that is, assuming random oracles exist. This result was generalized to the quantum-accessible random oracle (QROM) by Don, Fehr, Majenz and Schaffner, and concurrently by Liu and Zhandry. In the case that random oracles do not exist, the Fiat\u2013Shamir heuristic has been proven insecure by Shafi Goldwasser and Yael Tauman Kalai. The Fiat\u2013Shamir heuristic thus demonstrates a major application of random oracles. \nMore generally, the Fiat\u2013Shamir heuristic may also be viewed as converting a public-coin interactive proof of knowledge into a non-interactive proof of knowledge. If the interactive proof is used as an identification tool, then the non-interactive version can be used directly as a digital signature by using the message as part of the input to the random oracle.\n\n\n\n== Example ==\nFor the algorithm specified below, readers should be familiar with the multiplicative groups \n  \n    \n      \n        \n          \n            Z\n          \n          \n            q\n          \n          \n            \u2217\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {Z} _{q}^{*}}\n  , where q is a prime number, and Euler's totient theorem on the Euler's totient function \u03c6.\nHere is an interactive proof of knowledge of a discrete logarithm in \n  \n    \n      \n        \n          \n            Z\n          \n          \n            q\n          \n          \n            \u2217\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {Z} _{q}^{*}}\n  , based on Schnorr signature. The public values are \n  \n    \n      \n        y\n        \u2208\n        \n          \n            Z\n          \n          \n            q\n          \n          \n            \u2217\n          \n        \n      \n    \n    {\\displaystyle y\\in \\mathbb {Z} _{q}^{*}}\n   and a generator g of  \n  \n    \n      \n        \n          \n            Z\n          \n          \n            q\n          \n          \n            \u2217\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {Z} _{q}^{*}}\n  , while the secret value is the discrete logarithm of y to the base g.\n\nPeggy wants to prove to Victor, the verifier, that she knows \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n   satisfying \n  \n    \n      \n        y\n        \u2261\n        \n          g\n          \n            x\n          \n        \n      \n    \n    {\\displaystyle y\\equiv g^{x}}\n   without revealing \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  .\nShe picks a random \n  \n    \n      \n        v\n        \u2208\n        \n          \n            Z\n          \n          \n            q\n          \n          \n            \u2217\n          \n        \n      \n    \n    {\\displaystyle v\\in \\mathbb {Z} _{q}^{*}}\n  , computes \n  \n    \n      \n        t\n\n== Extension of this method ==\nAs long as a fixed random generator can be constructed with the data known to both parties, then any interactive protocol can be transformed into a non-interactive one."
    }
  },
  {
    "instruction": "DDoS attacks on Dyn\n\n==Introduction==\nOn October 21, 2016, three consecutive distributed denial-of-service attacks were launched against the Domain Name System (DNS) provider Dyn. The attack caused major Internet platforms and services to be unavailable to large swathes of users in Europe and North America. The groups Anonymous and New World Hackers claimed responsibility for the attack, but scant evidence was provided.As a DNS provider, Dyn provides to end-users the service of mapping an Internet domain name\u2014when, for instance, entered into a web browser\u2014to its corresponding IP address. The distributed denial-of-service (DDoS) attack was accomplished through numerous DNS lookup requests from tens of millions of IP addresses. The activities are believed to have been executed through a botnet consisting of many Internet-connected devices\u2014such as printers, IP cameras, residential gateways and baby monitors\u2014that had been infected with the Mirai malware.\n\n== Affected services ==\nServices affected by the attack included:\n\n== Investigation ==\n\nThe US Department of Homeland Security started an investigation into the attacks, according to a White House source. No group of hackers claimed responsibility during or in the immediate aftermath of the attack. Dyn's chief strategist said in an interview that the assaults on the company's servers were very complex and unlike everyday DDoS attacks. Barbara Simons, a member of the advisory board of the United States Election Assistance Commission, said such attacks could affect electronic voting for overseas military or civilians.Dyn disclosed that, according to business risk intelligence firm FlashPoint and Akamai Technologies, the attack was a botnet coordinated through numerous Internet of Things-enabled (IoT) devices, including cameras, residential gateways, and baby monitors, that had been infected with Mirai malware. The attribution of the attack to the Mirai botnet had been previously reported by BackConnect Inc., another security firm. Dyn stated that they were receiving malicious requests from tens of millions of IP addresses. Mirai is designed to brute-force the security on an IoT device, allowing it to be controlled remotely.\nCybersecurity investigator Brian Krebs noted that the source code for Mirai had been released onto the Internet in an open-source manner some weeks prior, which made the investigation of the perpetrator more difficult.On 25 October 2016, US President Obama stated that the investigators still had no idea who carried out the cyberattack.On 13 December 2017, the Justice Department announced that three men (Paras Jha, 21, Josiah White, 20, and Dalton Norman, 21) had entered guilty pleas in cybercrime cases relating to the Mirai and clickfraud botnets.\n\n== Perpetrators ==\nIn correspondence with the website Politico, hacktivist groups SpainSquad, Anonymous, and New World Hackers claimed responsibility for the attack in retaliation against Ecuador's rescinding Internet access to WikiLeaks founder Julian Assange, at their embassy in London, where he had been granted asylum. This claim has yet to be confirmed. WikiLeaks alluded to the attack on Twitter, tweeting \"Mr. Assange is still alive and WikiLeaks is still publishing. We ask supporters to stop taking down the US internet. You proved your point.\" New World Hackers has claimed responsibility in the past for similar attacks targeting sites like BBC and ESPN.com.On October 26, FlashPoint stated that the attack was most likely done by script kiddies.A November 17, 2016, a Forbes article reported that the attack was likely carried out by \"an angry gamer\".A September 20, 2018, a WeLiveSecurity article stated that its three creators meant it as a way of gaining an advantage in fierce competition surrounding the computer game Minecraft \u2013 by preventing players from using competitors\u2019 servers and driving them to their own servers in order to ultimately make money off them.On December 9, 2020, one of the perpetrators pleaded guilty to taking part in the attack. The perpetrator's name was withheld due to his or her age.\n\nWhat is the significance of the release of the Mirai source code and its impact on the investigation of the Dyn attack?",
    "context": "",
    "output": "A: The release of the Mirai source code made it widely available for anyone to use, making the investigation of the perpetrator more difficult. This also highlights the potential risks associated with open-source software and the importance of securing such software to prevent misuse.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the significance of the release of the Mirai source code and its impact on the investigation of the Dyn attack?",
      "answer": "The release of the Mirai source code made it widely available for anyone to use, making the investigation of the perpetrator more difficult. This also highlights the potential risks associated with open-source software and the importance of securing such software to prevent misuse.",
      "context": "DDoS attacks on Dyn\n\n==Introduction==\nOn October 21, 2016, three consecutive distributed denial-of-service attacks were launched against the Domain Name System (DNS) provider Dyn. The attack caused major Internet platforms and services to be unavailable to large swathes of users in Europe and North America. The groups Anonymous and New World Hackers claimed responsibility for the attack, but scant evidence was provided.As a DNS provider, Dyn provides to end-users the service of mapping an Internet domain name\u2014when, for instance, entered into a web browser\u2014to its corresponding IP address. The distributed denial-of-service (DDoS) attack was accomplished through numerous DNS lookup requests from tens of millions of IP addresses. The activities are believed to have been executed through a botnet consisting of many Internet-connected devices\u2014such as printers, IP cameras, residential gateways and baby monitors\u2014that had been infected with the Mirai malware.\n\n== Affected services ==\nServices affected by the attack included:\n\n== Investigation ==\n\nThe US Department of Homeland Security started an investigation into the attacks, according to a White House source. No group of hackers claimed responsibility during or in the immediate aftermath of the attack. Dyn's chief strategist said in an interview that the assaults on the company's servers were very complex and unlike everyday DDoS attacks. Barbara Simons, a member of the advisory board of the United States Election Assistance Commission, said such attacks could affect electronic voting for overseas military or civilians.Dyn disclosed that, according to business risk intelligence firm FlashPoint and Akamai Technologies, the attack was a botnet coordinated through numerous Internet of Things-enabled (IoT) devices, including cameras, residential gateways, and baby monitors, that had been infected with Mirai malware. The attribution of the attack to the Mirai botnet had been previously reported by BackConnect Inc., another security firm. Dyn stated that they were receiving malicious requests from tens of millions of IP addresses. Mirai is designed to brute-force the security on an IoT device, allowing it to be controlled remotely.\nCybersecurity investigator Brian Krebs noted that the source code for Mirai had been released onto the Internet in an open-source manner some weeks prior, which made the investigation of the perpetrator more difficult.On 25 October 2016, US President Obama stated that the investigators still had no idea who carried out the cyberattack.On 13 December 2017, the Justice Department announced that three men (Paras Jha, 21, Josiah White, 20, and Dalton Norman, 21) had entered guilty pleas in cybercrime cases relating to the Mirai and clickfraud botnets.\n\n== Perpetrators ==\nIn correspondence with the website Politico, hacktivist groups SpainSquad, Anonymous, and New World Hackers claimed responsibility for the attack in retaliation against Ecuador's rescinding Internet access to WikiLeaks founder Julian Assange, at their embassy in London, where he had been granted asylum. This claim has yet to be confirmed. WikiLeaks alluded to the attack on Twitter, tweeting \"Mr. Assange is still alive and WikiLeaks is still publishing. We ask supporters to stop taking down the US internet. You proved your point.\" New World Hackers has claimed responsibility in the past for similar attacks targeting sites like BBC and ESPN.com.On October 26, FlashPoint stated that the attack was most likely done by script kiddies.A November 17, 2016, a Forbes article reported that the attack was likely carried out by \"an angry gamer\".A September 20, 2018, a WeLiveSecurity article stated that its three creators meant it as a way of gaining an advantage in fierce competition surrounding the computer game Minecraft \u2013 by preventing players from using competitors\u2019 servers and driving them to their own servers in order to ultimately make money off them.On December 9, 2020, one of the perpetrators pleaded guilty to taking part in the attack. The perpetrator's name was withheld due to his or her age."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does ARC solve the problem of legitimate emails being blocked by a strict DMARC policy in ARC implementation?",
    "context": "",
    "output": "ARC solves this problem by giving intermediate servers a way to sign the original message's validation results, allowing a receiving service to validate the ARC chain and accept the email even if the SPF and DKIM checks fail.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does ARC solve the problem of legitimate emails being blocked by a strict DMARC policy in ARC implementation?",
      "answer": "ARC solves this problem by giving intermediate servers a way to sign the original message's validation results, allowing a receiving service to validate the ARC chain and accept the email even if the SPF and DKIM checks fail."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the md5deep software package handle the creation of cryptographic digests for files, and what types of digest algorithms are supported?",
    "context": "",
    "output": "The md5deep software package is capable of creating cryptographic digests for large numbers of files using several different digest algorithms. These algorithms include MD5, SHA-1, SHA-256, Tiger192, and Whirlpool. Each digest type is named by the algorithm followed by the word \"deep\".",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the md5deep software package handle the creation of cryptographic digests for files, and what types of digest algorithms are supported?",
      "answer": "The md5deep software package is capable of creating cryptographic digests for large numbers of files using several different digest algorithms. These algorithms include MD5, SHA-1, SHA-256, Tiger192, and Whirlpool. Each digest type is named by the algorithm followed by the word \"deep\"."
    }
  },
  {
    "instruction": "Write an answer to the following question: How did Facebook respond to criticism for not taking further action against fraudulent news in addition to revoking advertising revenues from fraudulent news providers?",
    "context": "",
    "output": "After negative media coverage and assertions that fraudulent news gave the 2016 U.S. presidential election to Trump, Facebook decided to engage in assisting the government of China with a version of its software in the country to allow increased censorship by the government.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How did Facebook respond to criticism for not taking further action against fraudulent news in addition to revoking advertising revenues from fraudulent news providers?",
      "answer": "After negative media coverage and assertions that fraudulent news gave the 2016 U.S. presidential election to Trump, Facebook decided to engage in assisting the government of China with a version of its software in the country to allow increased censorship by the government."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the most common password and what does it suggest about internet users' password priorities?",
    "context": "",
    "output": "The most common password is Password1, which suggests that convenience over security is a priority for many internet users.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the most common password and what does it suggest about internet users' password priorities?",
      "answer": "The most common password is Password1, which suggests that convenience over security is a priority for many internet users."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does Sculpt handle device detection and configuration?",
    "context": "",
    "output": "Sculpt has automatic device detection and configuration.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does Sculpt handle device detection and configuration?",
      "answer": "Sculpt has automatic device detection and configuration."
    }
  },
  {
    "instruction": "Pseudorandom permutation\n\n==Introduction==\nIn cryptography, a pseudorandom permutation (PRP) is a function that cannot be distinguished from a random permutation (that is, a permutation selected at random with uniform probability, from the family of all permutations on the function's domain) with practical effort.\n\n== Definition ==\nLet F be a mapping \n  \n    \n      \n        \n          \n            {\n            \n              0\n              ,\n              1\n            \n            }\n          \n          \n            n\n          \n        \n        \u00d7\n        \n          \n            {\n            \n              0\n              ,\n              1\n            \n            }\n          \n          \n            s\n          \n        \n        \u2192\n        \n          \n            {\n            \n              0\n              ,\n              1\n            \n            }\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\left\\{0,1\\right\\}^{n}\\times \\left\\{0,1\\right\\}^{s}\\rightarrow \\left\\{0,1\\right\\}^{n}}\n  . F is a PRP if and only if\n\nFor any \n  \n    \n      \n        K\n        \u2208\n        \n          \n            {\n            \n              0\n              ,\n              1\n            \n            }\n          \n          \n            s\n          \n        \n      \n    \n    {\\displaystyle K\\in \\left\\{0,1\\right\\}^{s}}\n  , \n  \n    \n      \n        \n          F\n          \n            K\n          \n        \n      \n    \n    {\\displaystyle F_{K}}\n   is a bijection from \n  \n    \n      \n        \n          \n            {\n            \n              0\n              ,\n              1\n            \n            }\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\left\\{0,1\\right\\}^{n}}\n   to \n  \n    \n      \n        \n          \n            {\n            \n              0\n              ,\n              1\n            \n            }\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\left\\{0,1\\right\\}^{n}}\n  , where \n  \n    \n      \n        \n          F\n          \n            K\n          \n        \n        (\n        x\n        )\n\n== The model of block ciphers ==\nThe idealized abstraction of a (keyed) block cipher is a truly random permutation on the mappings between plaintext and ciphertext.  If a distinguishing algorithm exists that achieves significant advantage with less effort than specified by the block cipher's security parameter (this usually means the effort required should be about the same as a brute force search through the cipher's key space), then the cipher is considered broken at least in a certificational sense, even if such a break doesn't immediately lead to a practical security failure.Modern ciphers are expected to have super pseudorandomness.\nThat is, the cipher should be indistinguishable from a randomly chosen permutation on the same message space, even if the adversary has black-box access to the forward and inverse directions of the cipher.\n\n== Connections with pseudorandom function ==\nMichael Luby and Charles Rackoff showed that a \"strong\" pseudorandom permutation can be built from a pseudorandom function using a Luby\u2013Rackoff construction which is built using a Feistel cipher.\n\n== Related concepts ==\n\n\n*** Unpredictable permutation ***\nAn unpredictable permutation (UP) Fk is a permutation whose values cannot be predicted by a fast randomized algorithm. Unpredictable permutations may be used as a cryptographic primitive, a building block for cryptographic systems with more complex properties.\nAn adversary for an unpredictable permutation is defined to be an algorithm that is given access to an oracle for both forward and inverse permutation operations. The adversary is given a challenge input k and is asked to predict the value of Fk. It is allowed to make a series of queries to the oracle to help it make this prediction, but is not allowed to query the value of k itself.A randomized algorithm for generating permutations generates an unpredictable permutation if its outputs are permutations on a set of items (described by length-n binary strings)  that cannot be predicted with accuracy significantly better than random by an adversary that makes a polynomial (in n) number of queries to the oracle prior to the challenge round, whose running time is polynomial in n, and whose error probability is less than 1/2 for all instances. That is, it cannot be predicted in the complexity class PP, relativized by the oracle for the permutation.\n\n\n**** Properties of unpredictable permutations ****\nIt can be shown that a function Fk is not a secure message authentication code (MAC) if it satisfies only the unpredictability requirement. It can also be shown that one cannot build an efficient variable input length MAC from a block cipher which is modelled as a UP of n bits. It has been shown that the output of a k\n\n== Applications ==\nDESK x X \u2192 X \u2200  X\n\nBased on the above text, answer a question. What is the definition of a randomized algorithm for generating permutations that generates an unpredictable permutation?",
    "context": "",
    "output": "A randomized algorithm for generating permutations generates an unpredictable permutation if its outputs are permutations on a set of items (described by length-n binary strings) that cannot be predicted with accuracy significantly better than random by an adversary that makes a polynomial (in n) number of queries to the oracle prior to the challenge round, whose running time is polynomial in n, and whose error probability is less than 1/2 for all instances.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the definition of a randomized algorithm for generating permutations that generates an unpredictable permutation?",
      "answer": "A randomized algorithm for generating permutations generates an unpredictable permutation if its outputs are permutations on a set of items (described by length-n binary strings) that cannot be predicted with accuracy significantly better than random by an adversary that makes a polynomial (in n) number of queries to the oracle prior to the challenge round, whose running time is polynomial in n, and whose error probability is less than 1/2 for all instances.",
      "context": "Pseudorandom permutation\n\n==Introduction==\nIn cryptography, a pseudorandom permutation (PRP) is a function that cannot be distinguished from a random permutation (that is, a permutation selected at random with uniform probability, from the family of all permutations on the function's domain) with practical effort.\n\n== Definition ==\nLet F be a mapping \n  \n    \n      \n        \n          \n            {\n            \n              0\n              ,\n              1\n            \n            }\n          \n          \n            n\n          \n        \n        \u00d7\n        \n          \n            {\n            \n              0\n              ,\n              1\n            \n            }\n          \n          \n            s\n          \n        \n        \u2192\n        \n          \n            {\n            \n              0\n              ,\n              1\n            \n            }\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\left\\{0,1\\right\\}^{n}\\times \\left\\{0,1\\right\\}^{s}\\rightarrow \\left\\{0,1\\right\\}^{n}}\n  . F is a PRP if and only if\n\nFor any \n  \n    \n      \n        K\n        \u2208\n        \n          \n            {\n            \n              0\n              ,\n              1\n            \n            }\n          \n          \n            s\n          \n        \n      \n    \n    {\\displaystyle K\\in \\left\\{0,1\\right\\}^{s}}\n  , \n  \n    \n      \n        \n          F\n          \n            K\n          \n        \n      \n    \n    {\\displaystyle F_{K}}\n   is a bijection from \n  \n    \n      \n        \n          \n            {\n            \n              0\n              ,\n              1\n            \n            }\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\left\\{0,1\\right\\}^{n}}\n   to \n  \n    \n      \n        \n          \n            {\n            \n              0\n              ,\n              1\n            \n            }\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\left\\{0,1\\right\\}^{n}}\n  , where \n  \n    \n      \n        \n          F\n          \n            K\n          \n        \n        (\n        x\n        )\n\n== The model of block ciphers ==\nThe idealized abstraction of a (keyed) block cipher is a truly random permutation on the mappings between plaintext and ciphertext.  If a distinguishing algorithm exists that achieves significant advantage with less effort than specified by the block cipher's security parameter (this usually means the effort required should be about the same as a brute force search through the cipher's key space), then the cipher is considered broken at least in a certificational sense, even if such a break doesn't immediately lead to a practical security failure.Modern ciphers are expected to have super pseudorandomness.\nThat is, the cipher should be indistinguishable from a randomly chosen permutation on the same message space, even if the adversary has black-box access to the forward and inverse directions of the cipher.\n\n== Connections with pseudorandom function ==\nMichael Luby and Charles Rackoff showed that a \"strong\" pseudorandom permutation can be built from a pseudorandom function using a Luby\u2013Rackoff construction which is built using a Feistel cipher.\n\n== Related concepts ==\n\n\n*** Unpredictable permutation ***\nAn unpredictable permutation (UP) Fk is a permutation whose values cannot be predicted by a fast randomized algorithm. Unpredictable permutations may be used as a cryptographic primitive, a building block for cryptographic systems with more complex properties.\nAn adversary for an unpredictable permutation is defined to be an algorithm that is given access to an oracle for both forward and inverse permutation operations. The adversary is given a challenge input k and is asked to predict the value of Fk. It is allowed to make a series of queries to the oracle to help it make this prediction, but is not allowed to query the value of k itself.A randomized algorithm for generating permutations generates an unpredictable permutation if its outputs are permutations on a set of items (described by length-n binary strings)  that cannot be predicted with accuracy significantly better than random by an adversary that makes a polynomial (in n) number of queries to the oracle prior to the challenge round, whose running time is polynomial in n, and whose error probability is less than 1/2 for all instances. That is, it cannot be predicted in the complexity class PP, relativized by the oracle for the permutation.\n\n\n**** Properties of unpredictable permutations ****\nIt can be shown that a function Fk is not a secure message authentication code (MAC) if it satisfies only the unpredictability requirement. It can also be shown that one cannot build an efficient variable input length MAC from a block cipher which is modelled as a UP of n bits. It has been shown that the output of a k\n\n== Applications ==\nDESK x X \u2192 X \u2200  X"
    }
  },
  {
    "instruction": "Context: 2017 Macron e-mail leaks\n\n==Introduction==\nThe 2017 Macron e-mail leaks were leaks of more than 20,000 e-mails related to the campaign of Emmanuel Macron during the 2017 French presidential elections, two days before the final vote. The leaks garnered an abundance of media attention due to how quickly news of the leak spread throughout the Internet, aided in large part by bots and spammers and drew accusations that the government of Russia under Vladimir Putin was responsible. The e-mails were shared by WikiLeaks and several American alt-right activists through social media sites like Twitter, Facebook, and 4chan.Originally posted on a filesharing site called PasteBin, the e-mails had little to no effect on the final vote as they were dumped just hours before a 44-hour media blackout that is legally required by French electoral law.The campaign said the e-mails had been \"fraudulently obtained\" and that false documents were mingled with genuine ones in order \"to create confusion and misinformation.\" Numerama, an online publication focusing on digital life, described the leaked material as \"utterly mundane\", consisting of \"the contents of a hard drive and several emails of co-workers and En Marche political officials.\" United States Senator from Virginia, Mark Warner cited the e-mail leak as a reinforcement of the cause behind the U.S. Senate Intelligence Committee's investigation into Russian interference in the 2016 United States elections. Nonetheless, the Russian government denied all allegations of foreign electoral intervention.\n\n== Background ==\n\nAfter the first round of the 2017 French presidential election produced no majority winner, the top two candidates proceeded to a runoff election to be held on 7 May of that year. Emmanuel Macron of the En Marche! party and Marine Le Pen of the National Front both began campaigning across France on their competing points of view. The election was characterized by widespread dissatisfaction with the administration of President Fran\u00e7ois Hollande and the French governmental establishment as a whole.The election was widely regarded as a referendum between the internationalist centrism of Macron and the populist far-right ideology of Le Pen. After a slew of events considered to be detrimental to globalization and a triumph of nationalism and isolationism, such as the Brexit referendum, and the election of Donald Trump, many international observers viewed the French election as another possible trendsetting event for Western politics. Le Pen's anti-immigration, anti-NATO, and anti-European Union stances attracted her the widespread support of far-right politicians and activists as far as the United States, like Donald Trump, and raised questions about possible appeasement of Russia. Russia-funded media outlets such as Russia Today and Sputnik News consistently portrayed Le Pen in a positive light, and her campaign had even secured millions of Euros from a Russian lender in 2014.In the United States, Le Pen was praised by President Donald Trump on several occasions, and she saw widespread support and praise by large numbers of online conservative trolls and Internet alt-right activists on social media platforms like Twitter, Facebook, Reddit, and 4chan, who simultaneously attacked Macron.\nThese trolls used spamming of Internet memes and misinformation as tactics to assail Macron; accusing him of being a \"globalist puppet\" and a supporter of Islamic immigration. This was not a new strategy, it had been executed to much success during the 2016 United States presidential election. Legions of pro-Trump Internet users and bots had spammed social media and rapidly spread anti-Clinton news releases and leaks across the web as was the case with the Democratic National Committee leaks and the John Podesta e-mail leaks, allegedly with aid from the Kremlin. Prior to the election, American national security officials warned the French government of the high probability of Russian digital meddling in the election, according to the Director of the National Security Agency, Mike Rogers.\n\n== E-mail leaks ==\nOn Friday 5 May 2017, two days before the scheduled vote in the presidential election, the campaign of Emmanuel Macron claimed that it had been the target of a \"massive hack\". At the same time at least 9 gigabytes of data were dumped on an anonymous file sharing site called Pastebin using a profile called 'EMLEAKS'. The drop was made just hours before an election media blackout was due to take place in advance of Sunday's elections, as legally mandated under French electoral law which prevented Macron from issuing an effective response but also limited media coverage of the hack and subsequent leak. The e-mails, totaling 21,075, along with other data was quickly posted to the anonymous message board, 4chan, where it was shared by alt-right activists, notably Jack Posobiec, on Twitter  who had them translated by the Qu\u00e9b\u00e9cois wing of right-wing outlet The Rebel Media. It has been remarked that at that time, Rebel Media's Qu\u00e9b\u00e9cois wing consisted solely of radio personality \u00c9ric Duhaime.The e-mail leak spread swiftly under the hashtag #MacronLeaks on Twitter and Facebook. Within three and a half hours of first being used, #MacronLeaks had reached 47,000 tweets. On Jack Posobiec's Twitter, the hashtag was retweeted 87 times within five minutes, likely pointing to the use of bots. WikiLeaks mentioned the leaks in subsequent tweets 15 times, contributing the most to the news' spread. Within a short period of time, #MacronLeaks was trending in France and was on a banner on the Drudge Report homepage. In another sign of bot use the ten most active accounts using the #MacronLeaks hashtag posted over 1,300 tweets in just over three hours. One particular account, posted 294 tweets in a span of two hours. Analysis shows that the hashtag was mentioned more times by American accounts than French ones, but posts concerning them were, by a slim margin, written more often in French than English.The leaked e-mails were claimed to show evidence of criminal wrongdoing by Macron and his campaign including the committing of tax evasion and election fraud. A less suggestive examination of the e-mails by Numerama, a French online publication focusing on technological news, described the leaked emails as \"utterly mundane\", consisting of \"the contents of a hard drive and several emails of co-workers and En Marche political officials.\" Leaked documents included \"memos, bills, loans for amounts that are hardly over-the-top, recommendations and other reservations, amidst, of course, exchanges that are strictly personal and private \u2014 personal notes on the rain and sunshine, a confirmation email for the publishing of a book, reservation of a table for friends, etc.\"\n\n\n*** Reaction ***\nIn response to the attack, Emmanuel Macron said it was \"democratic destabilisation, like that seen during the last presidential campaign in the United States\" and said the hackers had mixed falsified documents with genuine ones, \"in order to sow doubt and disinformation.\" Vice President of the National Front Florian Philippot and Le Pen adviser said in a tweet, \"Will #MacronLeaks teach us something that investigative journalism has deliberately killed?\" The French election commission warned media in the country that publishing the e-mails or discussing them so close to the election would be a violation of the law and issued a statement that in part read, \"On the eve of the most important election for our institutions, the commission calls on everyone present on internet sites and social networks, primarily the media, but also all citizens, to show responsibility and not to pass on this content, so as not to distort the sincerity of the ballot.\" The leak did not appear to have any impact on the French presidential election which continued as scheduled and ended with a Macron victory by a margin of 32%. Despite this, French security officials commenced an investigation into the hacking shortly after the election.Shortly after the alt-right media boosted the leak, chief of Macron's campaign Mounir Mahjoubi stated that they have been watching GRU hacking attempts since February, and let them steal a carefully prepared cache of trivial and forged documents. After this was confirmed against the leaks contents, its credibility was seriously undermined.In the United States, U.S. Senator from Virginia and ranking member of the Senate Intelligence Committee, Mark Warner said the hacking and subsequent leak only emboldened his committee's investigation, and former Secretary of State and Democratic presidential candidate Hillary Clinton said in a tweet, \"Victory for Macron, for France, the EU, & the world. Defeat to those interfering w/democracy. (But the media says I can't talk about that).\"\n\n== Perpetrators ==\n\nAn assessment by Flashpoint, an American cybersecurity firm, stated that they determined with \"moderate confidence\" that the group behind the hacking and leak was APT28, better known as 'Fancy Bear', a hacking group with ties to Russian military intelligence. Metadata pulled from the dump revealed the name 'Georgy Petrovich Roshka', likely an alias, which has ties to a Moscow-based intelligence contractor. Many similarities, including the use of social media bots in an attempt to scrub metadata, also pointed to Fancy Bear. However, on 1 June 2017, Guillaume Poupard, the head of France's premier cybersecurity agency said in an interview with the Associated Press the hack, \"was so generic and simple that it could have been practically anyone\". On 9 May, two days after the election, Mike Rogers, head of the NSA, said in sworn testimony with the United States Senate he had been made aware of Russian attempts to hack French election infrastructure, though he did not mention anything related to the identities of those behind the Macron email hacking. This followed a French announcement that electronic voting for France's overseas citizens would be discontinued in light of cybersecurity threats.According to the Le Monde newspaper and with the work based on non-public rapport of Google and FireEye, the GRU is responsible.Vladimir Putin has denied claims of election interference, claiming Russia has also been targeted.\n\nQuestion: What was the response of the French election commission to the 2017 Macron e-mail leaks?\n\nAnswer:",
    "context": "",
    "output": "The French election commission warned media in the country that publishing the e-mails or discussing them so close to the election would be a violation of the law and issued a statement that in part read, \"On the eve of the most important election for our institutions, the commission calls on everyone present on internet sites and social networks, primarily the media, but also all citizens, to show responsibility and not to pass on this content, so as not to distort the sincerity of the ballot.\"",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was the response of the French election commission to the 2017 Macron e-mail leaks?",
      "answer": "The French election commission warned media in the country that publishing the e-mails or discussing them so close to the election would be a violation of the law and issued a statement that in part read, \"On the eve of the most important election for our institutions, the commission calls on everyone present on internet sites and social networks, primarily the media, but also all citizens, to show responsibility and not to pass on this content, so as not to distort the sincerity of the ballot.\"",
      "context": "2017 Macron e-mail leaks\n\n==Introduction==\nThe 2017 Macron e-mail leaks were leaks of more than 20,000 e-mails related to the campaign of Emmanuel Macron during the 2017 French presidential elections, two days before the final vote. The leaks garnered an abundance of media attention due to how quickly news of the leak spread throughout the Internet, aided in large part by bots and spammers and drew accusations that the government of Russia under Vladimir Putin was responsible. The e-mails were shared by WikiLeaks and several American alt-right activists through social media sites like Twitter, Facebook, and 4chan.Originally posted on a filesharing site called PasteBin, the e-mails had little to no effect on the final vote as they were dumped just hours before a 44-hour media blackout that is legally required by French electoral law.The campaign said the e-mails had been \"fraudulently obtained\" and that false documents were mingled with genuine ones in order \"to create confusion and misinformation.\" Numerama, an online publication focusing on digital life, described the leaked material as \"utterly mundane\", consisting of \"the contents of a hard drive and several emails of co-workers and En Marche political officials.\" United States Senator from Virginia, Mark Warner cited the e-mail leak as a reinforcement of the cause behind the U.S. Senate Intelligence Committee's investigation into Russian interference in the 2016 United States elections. Nonetheless, the Russian government denied all allegations of foreign electoral intervention.\n\n== Background ==\n\nAfter the first round of the 2017 French presidential election produced no majority winner, the top two candidates proceeded to a runoff election to be held on 7 May of that year. Emmanuel Macron of the En Marche! party and Marine Le Pen of the National Front both began campaigning across France on their competing points of view. The election was characterized by widespread dissatisfaction with the administration of President Fran\u00e7ois Hollande and the French governmental establishment as a whole.The election was widely regarded as a referendum between the internationalist centrism of Macron and the populist far-right ideology of Le Pen. After a slew of events considered to be detrimental to globalization and a triumph of nationalism and isolationism, such as the Brexit referendum, and the election of Donald Trump, many international observers viewed the French election as another possible trendsetting event for Western politics. Le Pen's anti-immigration, anti-NATO, and anti-European Union stances attracted her the widespread support of far-right politicians and activists as far as the United States, like Donald Trump, and raised questions about possible appeasement of Russia. Russia-funded media outlets such as Russia Today and Sputnik News consistently portrayed Le Pen in a positive light, and her campaign had even secured millions of Euros from a Russian lender in 2014.In the United States, Le Pen was praised by President Donald Trump on several occasions, and she saw widespread support and praise by large numbers of online conservative trolls and Internet alt-right activists on social media platforms like Twitter, Facebook, Reddit, and 4chan, who simultaneously attacked Macron.\nThese trolls used spamming of Internet memes and misinformation as tactics to assail Macron; accusing him of being a \"globalist puppet\" and a supporter of Islamic immigration. This was not a new strategy, it had been executed to much success during the 2016 United States presidential election. Legions of pro-Trump Internet users and bots had spammed social media and rapidly spread anti-Clinton news releases and leaks across the web as was the case with the Democratic National Committee leaks and the John Podesta e-mail leaks, allegedly with aid from the Kremlin. Prior to the election, American national security officials warned the French government of the high probability of Russian digital meddling in the election, according to the Director of the National Security Agency, Mike Rogers.\n\n== E-mail leaks ==\nOn Friday 5 May 2017, two days before the scheduled vote in the presidential election, the campaign of Emmanuel Macron claimed that it had been the target of a \"massive hack\". At the same time at least 9 gigabytes of data were dumped on an anonymous file sharing site called Pastebin using a profile called 'EMLEAKS'. The drop was made just hours before an election media blackout was due to take place in advance of Sunday's elections, as legally mandated under French electoral law which prevented Macron from issuing an effective response but also limited media coverage of the hack and subsequent leak. The e-mails, totaling 21,075, along with other data was quickly posted to the anonymous message board, 4chan, where it was shared by alt-right activists, notably Jack Posobiec, on Twitter  who had them translated by the Qu\u00e9b\u00e9cois wing of right-wing outlet The Rebel Media. It has been remarked that at that time, Rebel Media's Qu\u00e9b\u00e9cois wing consisted solely of radio personality \u00c9ric Duhaime.The e-mail leak spread swiftly under the hashtag #MacronLeaks on Twitter and Facebook. Within three and a half hours of first being used, #MacronLeaks had reached 47,000 tweets. On Jack Posobiec's Twitter, the hashtag was retweeted 87 times within five minutes, likely pointing to the use of bots. WikiLeaks mentioned the leaks in subsequent tweets 15 times, contributing the most to the news' spread. Within a short period of time, #MacronLeaks was trending in France and was on a banner on the Drudge Report homepage. In another sign of bot use the ten most active accounts using the #MacronLeaks hashtag posted over 1,300 tweets in just over three hours. One particular account, posted 294 tweets in a span of two hours. Analysis shows that the hashtag was mentioned more times by American accounts than French ones, but posts concerning them were, by a slim margin, written more often in French than English.The leaked e-mails were claimed to show evidence of criminal wrongdoing by Macron and his campaign including the committing of tax evasion and election fraud. A less suggestive examination of the e-mails by Numerama, a French online publication focusing on technological news, described the leaked emails as \"utterly mundane\", consisting of \"the contents of a hard drive and several emails of co-workers and En Marche political officials.\" Leaked documents included \"memos, bills, loans for amounts that are hardly over-the-top, recommendations and other reservations, amidst, of course, exchanges that are strictly personal and private \u2014 personal notes on the rain and sunshine, a confirmation email for the publishing of a book, reservation of a table for friends, etc.\"\n\n\n*** Reaction ***\nIn response to the attack, Emmanuel Macron said it was \"democratic destabilisation, like that seen during the last presidential campaign in the United States\" and said the hackers had mixed falsified documents with genuine ones, \"in order to sow doubt and disinformation.\" Vice President of the National Front Florian Philippot and Le Pen adviser said in a tweet, \"Will #MacronLeaks teach us something that investigative journalism has deliberately killed?\" The French election commission warned media in the country that publishing the e-mails or discussing them so close to the election would be a violation of the law and issued a statement that in part read, \"On the eve of the most important election for our institutions, the commission calls on everyone present on internet sites and social networks, primarily the media, but also all citizens, to show responsibility and not to pass on this content, so as not to distort the sincerity of the ballot.\" The leak did not appear to have any impact on the French presidential election which continued as scheduled and ended with a Macron victory by a margin of 32%. Despite this, French security officials commenced an investigation into the hacking shortly after the election.Shortly after the alt-right media boosted the leak, chief of Macron's campaign Mounir Mahjoubi stated that they have been watching GRU hacking attempts since February, and let them steal a carefully prepared cache of trivial and forged documents. After this was confirmed against the leaks contents, its credibility was seriously undermined.In the United States, U.S. Senator from Virginia and ranking member of the Senate Intelligence Committee, Mark Warner said the hacking and subsequent leak only emboldened his committee's investigation, and former Secretary of State and Democratic presidential candidate Hillary Clinton said in a tweet, \"Victory for Macron, for France, the EU, & the world. Defeat to those interfering w/democracy. (But the media says I can't talk about that).\"\n\n== Perpetrators ==\n\nAn assessment by Flashpoint, an American cybersecurity firm, stated that they determined with \"moderate confidence\" that the group behind the hacking and leak was APT28, better known as 'Fancy Bear', a hacking group with ties to Russian military intelligence. Metadata pulled from the dump revealed the name 'Georgy Petrovich Roshka', likely an alias, which has ties to a Moscow-based intelligence contractor. Many similarities, including the use of social media bots in an attempt to scrub metadata, also pointed to Fancy Bear. However, on 1 June 2017, Guillaume Poupard, the head of France's premier cybersecurity agency said in an interview with the Associated Press the hack, \"was so generic and simple that it could have been practically anyone\". On 9 May, two days after the election, Mike Rogers, head of the NSA, said in sworn testimony with the United States Senate he had been made aware of Russian attempts to hack French election infrastructure, though he did not mention anything related to the identities of those behind the Macron email hacking. This followed a French announcement that electronic voting for France's overseas citizens would be discontinued in light of cybersecurity threats.According to the Le Monde newspaper and with the work based on non-public rapport of Google and FireEye, the GRU is responsible.Vladimir Putin has denied claims of election interference, claiming Russia has also been targeted."
    }
  },
  {
    "instruction": "Cyber and Information Domain Service\n\n==Introduction==\nThe Cyber and Information Domain Service (German: Cyber- und Informationsraum, German pronunciation: [\u02c8sa\u026a\u032fb\u0250 \u028ant \u026anf\u0254\u0281ma\u02c8t\u0361si\u032fo\u02d0ns\u02cc\u0281a\u028a\u032fm] (listen); CIR) is the youngest branch of Germany's military, the Bundeswehr. The decision to form a new  military branch was presented by Defense Minister Ursula von der Leyen on 26 April 2016, becoming operational on 1 April 2017. The headquarter of the Cyber and Information Domain Service is Bonn.\n\n== Organisation ==\nThe CIDS is commanded by the Chief of the Cyber and Information Domain Service (Inspekteur des Cyber- und Informationsraum) (InspCIR), a three-star general position, based in Bonn.\nChief CIDS and Commander CIDS HQ\nDeputy Commander CIDS HQ and Chief of Staff\nCommand Staff\nOperations Staff\nPlanning Staff\n Cyber and Information Domain Service Command (Kommando Cyber- und Informationsraum KdoCIR), in Bonn\n Strategic Reconnaissance Command (Kommando Strategische Aufkl\u00e4rung KSA), in Gelsdorf\n 911th Electronic Warfare Battalion\n 912th Electronic Warfare Battalion, mans the Oste-class SIGINT/ELINT and reconnaissance ships\n 931st Electronic Warfare Battalion\n 932nd Electronic Warfare Battalion, provides airborne troops for operations in enemy territory\n Bundeswehr Strategic Reconnaissance School\nBundeswehr Operational Communications Center\nCyber-Operations Center\nElectronic Warfare Analysis Center\nCentral Imaging Reconnaissance, operating the SAR-Lupe satellites\n Central Bundeswehr Investigation Authority for Technical Reconnaissance\n Bundeswehr Geoinformation Centre (Zentrum f\u00fcr Geoinformationswesen der Bundeswehr), in Euskirchen\n Information Technology Command (Kommando Informationstechnik der Bundeswehr), in Bonn\n Bundeswehr IT Operations Center\n Bundeswehr Information Technology School\n 281st Information Technology Battalion\n 282nd Information Technology Battalion\n 292nd Information Technology Battalion\n 293rd Information Technology Battalion\n 381st Information Technology Battalion\n 383rd Information Technology Battalion\nBundeswehr Cyber-Security Center\nBundeswehr Software Competence Center\nQ: What is the role of the Planning Staff in the CIDS organization?",
    "context": "",
    "output": "The Planning Staff is responsible for developing and implementing long-term strategies for the CIDS, working closely with the Operations Staff to ensure that the organization is prepared for future challenges.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of the Planning Staff in the CIDS organization?",
      "answer": "The Planning Staff is responsible for developing and implementing long-term strategies for the CIDS, working closely with the Operations Staff to ensure that the organization is prepared for future challenges.",
      "context": "Cyber and Information Domain Service\n\n==Introduction==\nThe Cyber and Information Domain Service (German: Cyber- und Informationsraum, German pronunciation: [\u02c8sa\u026a\u032fb\u0250 \u028ant \u026anf\u0254\u0281ma\u02c8t\u0361si\u032fo\u02d0ns\u02cc\u0281a\u028a\u032fm] (listen); CIR) is the youngest branch of Germany's military, the Bundeswehr. The decision to form a new  military branch was presented by Defense Minister Ursula von der Leyen on 26 April 2016, becoming operational on 1 April 2017. The headquarter of the Cyber and Information Domain Service is Bonn.\n\n== Organisation ==\nThe CIDS is commanded by the Chief of the Cyber and Information Domain Service (Inspekteur des Cyber- und Informationsraum) (InspCIR), a three-star general position, based in Bonn.\nChief CIDS and Commander CIDS HQ\nDeputy Commander CIDS HQ and Chief of Staff\nCommand Staff\nOperations Staff\nPlanning Staff\n Cyber and Information Domain Service Command (Kommando Cyber- und Informationsraum KdoCIR), in Bonn\n Strategic Reconnaissance Command (Kommando Strategische Aufkl\u00e4rung KSA), in Gelsdorf\n 911th Electronic Warfare Battalion\n 912th Electronic Warfare Battalion, mans the Oste-class SIGINT/ELINT and reconnaissance ships\n 931st Electronic Warfare Battalion\n 932nd Electronic Warfare Battalion, provides airborne troops for operations in enemy territory\n Bundeswehr Strategic Reconnaissance School\nBundeswehr Operational Communications Center\nCyber-Operations Center\nElectronic Warfare Analysis Center\nCentral Imaging Reconnaissance, operating the SAR-Lupe satellites\n Central Bundeswehr Investigation Authority for Technical Reconnaissance\n Bundeswehr Geoinformation Centre (Zentrum f\u00fcr Geoinformationswesen der Bundeswehr), in Euskirchen\n Information Technology Command (Kommando Informationstechnik der Bundeswehr), in Bonn\n Bundeswehr IT Operations Center\n Bundeswehr Information Technology School\n 281st Information Technology Battalion\n 282nd Information Technology Battalion\n 292nd Information Technology Battalion\n 293rd Information Technology Battalion\n 381st Information Technology Battalion\n 383rd Information Technology Battalion\nBundeswehr Cyber-Security Center\nBundeswehr Software Competence Center"
    }
  },
  {
    "instruction": "Write an answer to the following question: What is Standard HPP in server-side HPP?",
    "context": "",
    "output": "Standard HPP in server-side HPP refers to the injection of encoded query string delimiters in already existing parameters on the server-side without proper encoding.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is Standard HPP in server-side HPP?",
      "answer": "Standard HPP in server-side HPP refers to the injection of encoded query string delimiters in already existing parameters on the server-side without proper encoding."
    }
  },
  {
    "instruction": "Write an answer to the following question: Who is the individual that led and named the Night Dragon Operation and Operation Aurora cyberespionage intrusion investigations, and also reported Operation Shady RAT in 2011?",
    "context": "",
    "output": "Dmitri Alperovitch, who was the Vice President of Threat Research at Internet security company McAfee at that time.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Who is the individual that led and named the Night Dragon Operation and Operation Aurora cyberespionage intrusion investigations, and also reported Operation Shady RAT in 2011?",
      "answer": "Dmitri Alperovitch, who was the Vice President of Threat Research at Internet security company McAfee at that time."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is \"micro-perimeterisation\" and how does it differ from \"macro-perimeterisation\"?",
    "context": "",
    "output": "\"Micro-perimeterisation\" is the act of moving the security perimeter to surround the data itself, while \"macro-perimeterisation\" refers to moving the security perimeter to a higher level, such as the cloud.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is \"micro-perimeterisation\" and how does it differ from \"macro-perimeterisation\"?",
      "answer": "\"Micro-perimeterisation\" is the act of moving the security perimeter to surround the data itself, while \"macro-perimeterisation\" refers to moving the security perimeter to a higher level, such as the cloud."
    }
  },
  {
    "instruction": "Authentication and Key Agreement\n\n==Introduction==\nAuthentication and Key Agreement (AKA) is a security protocol used in 3G networks. AKA is also used for one-time password generation mechanism for digest access authentication. AKA is a challenge\u2013response based mechanism that uses symmetric cryptography.\n\n\n\n== AKA in CDMA ==\nAKA \u2013 Authentication and Key Agreement a.k.a. 3G Authentication, Enhanced Subscriber Authorization (ESA).\nThe basis for the 3G authentication mechanism, defined as a successor to CAVE-based authentication, AKA provides procedures for mutual authentication of the Mobile Station (MS) and serving system. The successful execution of AKA results in the establishment of a security association (i.e., set of security data) between the MS and serving system that enables a set of security services to be provided.\nMajor advantages of AKA over CAVE-based authentication include:\n\nLarger authentication keys (128-bit )\nStronger hash function (SHA-1)\nSupport for mutual authentication\nSupport for signaling message data integrity\nSupport for signaling information encryption\nSupport for user data encryption\nProtection from rogue MS when dealing with R-UIMAKA is not yet implemented in CDMA2000 networks, although it is expected to be used for IMS. To ensure interoperability with current devices and partner networks, support for AKA in CDMA networks and handsets will likely be in addition to CAVE-based authentication. \nAir interface support for AKA is included in all releases following CDMA2000 Rev C. \nTIA-41 MAP support for AKA was defined in TIA-945 (3GPP2 X.S0006), which has been integrated into TIA-41 (3GPP2 X.S0004). \nFor information on AKA in roaming, see CDG Reference Document #138.\n\n== AKA in UMTS ==\nAKA a mechanism which performs authentication and session key distribution in Universal Mobile Telecommunications System (UMTS) networks. AKA is a challenge\u2013response based mechanism that uses symmetric cryptography. AKA is typically run in a UMTS IP Multimedia Services Identity Module (ISIM), which is an application on a UICC (Universal Integrated Circuit Card). AKA is defined in RFC 3310.\n\n== Security ==\nAn attack against all variants of AKA has been reported, including 5G.\n\nQ: What is TIA-41 MAP support for AKA in CDMA networks?",
    "context": "",
    "output": "A: TIA-41 MAP support for AKA in CDMA networks is defined in TIA-945 (3GPP2 X.S0006), which has been integrated into TIA-41 (3GPP2 X.S0004).",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is TIA-41 MAP support for AKA in CDMA networks?",
      "answer": "TIA-41 MAP support for AKA in CDMA networks is defined in TIA-945 (3GPP2 X.S0006), which has been integrated into TIA-41 (3GPP2 X.S0004).",
      "context": "Authentication and Key Agreement\n\n==Introduction==\nAuthentication and Key Agreement (AKA) is a security protocol used in 3G networks. AKA is also used for one-time password generation mechanism for digest access authentication. AKA is a challenge\u2013response based mechanism that uses symmetric cryptography.\n\n\n\n== AKA in CDMA ==\nAKA \u2013 Authentication and Key Agreement a.k.a. 3G Authentication, Enhanced Subscriber Authorization (ESA).\nThe basis for the 3G authentication mechanism, defined as a successor to CAVE-based authentication, AKA provides procedures for mutual authentication of the Mobile Station (MS) and serving system. The successful execution of AKA results in the establishment of a security association (i.e., set of security data) between the MS and serving system that enables a set of security services to be provided.\nMajor advantages of AKA over CAVE-based authentication include:\n\nLarger authentication keys (128-bit )\nStronger hash function (SHA-1)\nSupport for mutual authentication\nSupport for signaling message data integrity\nSupport for signaling information encryption\nSupport for user data encryption\nProtection from rogue MS when dealing with R-UIMAKA is not yet implemented in CDMA2000 networks, although it is expected to be used for IMS. To ensure interoperability with current devices and partner networks, support for AKA in CDMA networks and handsets will likely be in addition to CAVE-based authentication. \nAir interface support for AKA is included in all releases following CDMA2000 Rev C. \nTIA-41 MAP support for AKA was defined in TIA-945 (3GPP2 X.S0006), which has been integrated into TIA-41 (3GPP2 X.S0004). \nFor information on AKA in roaming, see CDG Reference Document #138.\n\n== AKA in UMTS ==\nAKA a mechanism which performs authentication and session key distribution in Universal Mobile Telecommunications System (UMTS) networks. AKA is a challenge\u2013response based mechanism that uses symmetric cryptography. AKA is typically run in a UMTS IP Multimedia Services Identity Module (ISIM), which is an application on a UICC (Universal Integrated Circuit Card). AKA is defined in RFC 3310.\n\n== Security ==\nAn attack against all variants of AKA has been reported, including 5G."
    }
  },
  {
    "instruction": "Markus Hess\n\n==Introduction==\nMarkus Hess, a German citizen, is best known for his endeavours as a hacker in the late 1980s. Alongside fellow hackers Dirk Brzezinski and Peter Carl, Hess hacked into networks of military and industrial computers based in the United States, Europe and East Asia, and sold the information to the Soviet KGB for US$54,000. During his time working for the KGB, Hess is estimated to have broken into 400 U.S. military computers. The hacked material included \"sensitive semiconductor, satellite, space, and aircraft technologies\".\n\n\n\n== Lawrence Berkeley Laboratory ==\nHess's hacking activities were discovered in 1986 by Clifford Stoll, an astronomer turned system administrator of the computer center of the Lawrence Berkeley Laboratory (LBL) in California. Stoll's first job duty was to track a 75-cent accounting error in the LBL system. Early in his investigation, Stoll discovered that the LBL computer system was compromised and that the hacker had obtained root, or system privileges. Such a security compromise was more important than the accounting error. Stoll eventually discovered how the hacker broke in and identified the hacker's activities on the system. LBL management considered attempting to seal off the system from this hacker, but Stoll and his colleagues convinced LBL's management that this would not be effective. Ultimately, they installed a honeypot to ensnare the hacker.\n\n\n*** Getting in ***\nHess' initial activities started at the University of Bremen in Germany through the German Datex-P network via satellite link or transatlantic cable to the Tymnet International Gateway. Tymnet was a \"gateway\" service that a user called into that routed them to any one of a number of computer systems that also used the service. Tymnet was one of a number of services available that provided local telephone numbers, where directly accessing the computer would have been a long-distance call. Users normally used packet switching services like Tymnet for their lower costs. Once he accessed Tymnet, Hess branched out to the Jet Propulsion Laboratory in Pasadena, California, and to the Tymnet Switching System. It was through this switching system that he accessed the LBL computers.Hess was able to attack 400 U.S. military computers by using LBL to \"piggyback\" to ARPANET and MILNET. ARPANET was a civilian wide area network created by the Department of Defense, which would later become what is now known as the Internet. MILNET was its military counterpart.\n\n\n*** Targets ***\nThe facilities that Hess breached included:\nSRI International \u2014 Menlo Park, California, U.S.\nU.S. Army Darcom \u2014 Seckenheim, West Germany\nFort Buckner, Camp Foster \u2014 Okinawa Prefecture, Japan\nU.S. Army 24th Infantry \u2014 Fort Stewart, Georgia, U.S.\nU.S. Navy Coastal Systems Computer \u2014 Panama City, Florida, U.S.\nU.S. Air Force \u2014 Ramstein Air Base, West Germany\nMassachusetts Institute of Technology MX Computer, Cambridge, Massachusetts, U.S.\nOPTIMIS Database \u2014 The Pentagon, U.S.\nUnited States Air Force Systems Command \u2014 El Segundo, California, U.S.\nAnniston Army Depot \u2014 Anniston, Alabama, U.S.\n\n\n*** Tracking Hess and his capture ***\nStoll, with the help of local authorities, traced the call to a Tymnet switch in Oakland, California. Because the call came from Oakland rather than Berkeley, it was obvious that the hacker was not working local to the university. Tymnet officials helped LBL trace the various calls, even though the hacker attempted to conceal their origin. Enlisting the aid of AT&T and the Federal Bureau of Investigation (FBI), Stoll eventually determined that the calls were being \"piggybacked\" across the United States, but originating from Hanover, Germany.Stoll trapped Hess by creating records of a bogus military project conducted on LBL computers; according to The Cuckoo's Egg, he and his girlfriend conceived this plan while showering, giving it the unofficial name of \"Operation Showerhead\". While the bogus information was convincing, the primary goal was simply to keep the hacker connected long enough to trace his connection, and with the hope that the hacker might send a written request for further information listed as available in hard copy. This simple technique worked: a request for the additional information was received from a Pittsburgh, Pennsylvania address.At the time, this type of hacking was new, and it was a considerable challenge to get the cooperation of the FBI and the West German government. Eventually, the German authorities were able to break in and arrest Hess. Hess went to trial in 1990, and Stoll testified against him. Hess was found guilty of espionage and was given a 20-month suspended sentence.\n\n== Literature and films ==\nAfter Hess's capture, Stoll wrote about his efforts to track and locate Hess in a technical paper \"Stalking the Wily Hacker\" for the journal Communications of the ACM\nand a book\nThe Cuckoo's Egg for the general public.\nThe Cuckoo's Egg was adapted into a 1990 Nova episode \"The KGB, The Computer, and Me\".\"23\", a semi-fictional 1998 German movie about the incident, merges Hess with another hacker into a single character, David.\nRead the text above and answer this question: Why did LBL's management consider sealing off the system from the hacker ineffective?",
    "context": "",
    "output": "LBL's management considered sealing off the system from the hacker ineffective because it would not prevent the hacker from gaining access in the future, and it would not provide any information about the hacker's identity or location.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Why did LBL's management consider sealing off the system from the hacker ineffective?",
      "answer": "LBL's management considered sealing off the system from the hacker ineffective because it would not prevent the hacker from gaining access in the future, and it would not provide any information about the hacker's identity or location.",
      "context": "Markus Hess\n\n==Introduction==\nMarkus Hess, a German citizen, is best known for his endeavours as a hacker in the late 1980s. Alongside fellow hackers Dirk Brzezinski and Peter Carl, Hess hacked into networks of military and industrial computers based in the United States, Europe and East Asia, and sold the information to the Soviet KGB for US$54,000. During his time working for the KGB, Hess is estimated to have broken into 400 U.S. military computers. The hacked material included \"sensitive semiconductor, satellite, space, and aircraft technologies\".\n\n\n\n== Lawrence Berkeley Laboratory ==\nHess's hacking activities were discovered in 1986 by Clifford Stoll, an astronomer turned system administrator of the computer center of the Lawrence Berkeley Laboratory (LBL) in California. Stoll's first job duty was to track a 75-cent accounting error in the LBL system. Early in his investigation, Stoll discovered that the LBL computer system was compromised and that the hacker had obtained root, or system privileges. Such a security compromise was more important than the accounting error. Stoll eventually discovered how the hacker broke in and identified the hacker's activities on the system. LBL management considered attempting to seal off the system from this hacker, but Stoll and his colleagues convinced LBL's management that this would not be effective. Ultimately, they installed a honeypot to ensnare the hacker.\n\n\n*** Getting in ***\nHess' initial activities started at the University of Bremen in Germany through the German Datex-P network via satellite link or transatlantic cable to the Tymnet International Gateway. Tymnet was a \"gateway\" service that a user called into that routed them to any one of a number of computer systems that also used the service. Tymnet was one of a number of services available that provided local telephone numbers, where directly accessing the computer would have been a long-distance call. Users normally used packet switching services like Tymnet for their lower costs. Once he accessed Tymnet, Hess branched out to the Jet Propulsion Laboratory in Pasadena, California, and to the Tymnet Switching System. It was through this switching system that he accessed the LBL computers.Hess was able to attack 400 U.S. military computers by using LBL to \"piggyback\" to ARPANET and MILNET. ARPANET was a civilian wide area network created by the Department of Defense, which would later become what is now known as the Internet. MILNET was its military counterpart.\n\n\n*** Targets ***\nThe facilities that Hess breached included:\nSRI International \u2014 Menlo Park, California, U.S.\nU.S. Army Darcom \u2014 Seckenheim, West Germany\nFort Buckner, Camp Foster \u2014 Okinawa Prefecture, Japan\nU.S. Army 24th Infantry \u2014 Fort Stewart, Georgia, U.S.\nU.S. Navy Coastal Systems Computer \u2014 Panama City, Florida, U.S.\nU.S. Air Force \u2014 Ramstein Air Base, West Germany\nMassachusetts Institute of Technology MX Computer, Cambridge, Massachusetts, U.S.\nOPTIMIS Database \u2014 The Pentagon, U.S.\nUnited States Air Force Systems Command \u2014 El Segundo, California, U.S.\nAnniston Army Depot \u2014 Anniston, Alabama, U.S.\n\n\n*** Tracking Hess and his capture ***\nStoll, with the help of local authorities, traced the call to a Tymnet switch in Oakland, California. Because the call came from Oakland rather than Berkeley, it was obvious that the hacker was not working local to the university. Tymnet officials helped LBL trace the various calls, even though the hacker attempted to conceal their origin. Enlisting the aid of AT&T and the Federal Bureau of Investigation (FBI), Stoll eventually determined that the calls were being \"piggybacked\" across the United States, but originating from Hanover, Germany.Stoll trapped Hess by creating records of a bogus military project conducted on LBL computers; according to The Cuckoo's Egg, he and his girlfriend conceived this plan while showering, giving it the unofficial name of \"Operation Showerhead\". While the bogus information was convincing, the primary goal was simply to keep the hacker connected long enough to trace his connection, and with the hope that the hacker might send a written request for further information listed as available in hard copy. This simple technique worked: a request for the additional information was received from a Pittsburgh, Pennsylvania address.At the time, this type of hacking was new, and it was a considerable challenge to get the cooperation of the FBI and the West German government. Eventually, the German authorities were able to break in and arrest Hess. Hess went to trial in 1990, and Stoll testified against him. Hess was found guilty of espionage and was given a 20-month suspended sentence.\n\n== Literature and films ==\nAfter Hess's capture, Stoll wrote about his efforts to track and locate Hess in a technical paper \"Stalking the Wily Hacker\" for the journal Communications of the ACM\nand a book\nThe Cuckoo's Egg for the general public.\nThe Cuckoo's Egg was adapted into a 1990 Nova episode \"The KGB, The Computer, and Me\".\"23\", a semi-fictional 1998 German movie about the incident, merges Hess with another hacker into a single character, David."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the LARIAT platform allow for the testing of intrusion detection methods and software?",
    "context": "",
    "output": "The LARIAT platform allows for the testing of intrusion detection methods and software by simulating a realistic simulation of an active network of users that can then be targeted for malicious attacks to test the effectiveness of the attacks against network defenses, while also testing the effectiveness of intrusion detection methods and software in a simulated real-world environment with actual users in amongst the malicious traffic on the network.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the LARIAT platform allow for the testing of intrusion detection methods and software?",
      "answer": "The LARIAT platform allows for the testing of intrusion detection methods and software by simulating a realistic simulation of an active network of users that can then be targeted for malicious attacks to test the effectiveness of the attacks against network defenses, while also testing the effectiveness of intrusion detection methods and software in a simulated real-world environment with actual users in amongst the malicious traffic on the network."
    }
  },
  {
    "instruction": "Write an answer to the following question: Can IDOR vulnerabilities be used to gain unauthorized access to all records in a database?",
    "context": "",
    "output": "Yes, IDOR vulnerabilities can be used to gain unauthorized access to all records in a database, potentially exposing sensitive information. This is why IDOR is a significant concern in digital security.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Can IDOR vulnerabilities be used to gain unauthorized access to all records in a database?",
      "answer": "Yes, IDOR vulnerabilities can be used to gain unauthorized access to all records in a database, potentially exposing sensitive information. This is why IDOR is a significant concern in digital security."
    }
  },
  {
    "instruction": "Context: Woo\u2013Lam\n\n==Introduction==\nIn cryptography, Woo\u2013Lam refers to various computer network authentication protocols designed by Simon S. Lam and Thomas Woo. The protocols enable two communicating parties to authenticate each other's identity and to exchange session keys, and involve the use of a trusted key distribution center (KDC) to negotiate between the parties. Both symmetric-key and public-key variants have been described. However, the protocols suffer from various security flaws, and in part have been described as being inefficient compared to alternative authentication protocols.\n\n== Public-key protocol ==\n\n\n*** Notation ***\nThe following notation is used to describe the algorithm:\n\n  \n    \n      \n        A\n        ,\n        B\n      \n    \n    {\\displaystyle A,B}\n   - network nodes.\n\n  \n    \n      \n        K\n        \n          U\n          \n            x\n          \n        \n      \n    \n    {\\displaystyle KU_{x}}\n   - public key of node \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  .\n\n  \n    \n      \n        K\n        \n          R\n          \n            x\n          \n        \n      \n    \n    {\\displaystyle KR_{x}}\n   - private key of \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  .\n\n  \n    \n      \n        \n          N\n          \n            x\n          \n        \n      \n    \n    {\\displaystyle N_{x}}\n   - nonce chosen by \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  .\n\n  \n    \n      \n        I\n        \n          D\n          \n            x\n          \n        \n      \n    \n    {\\displaystyle ID_{x}}\n   - unique identifier of \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  .\n\n  \n    \n      \n        \n          E\n          \n            k\n          \n        \n      \n    \n    {\\displaystyle E_{k}}\n   - public-key encryption using key \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  .\n\n  \n    \n      \n        \n          S\n          \n            k\n          \n        \n      \n    \n    {\\displaystyle S_{k}}\n   - digital signature using key \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  .\n\n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n   - random session key chosen by the KDC.\n\n  \n    \n      \n        \n          |\n        \n        \n          |\n        \n      \n    \n    {\\displaystyle ||}\n   - concatenation.It is assumed that all parties know the KDC's public key.\n\n\n*** Message exchange ***\n\n  \n    \n      \n        1\n        )\n        A\n        \u2192\n        K\n        D\n        C\n        :\n        I\n        \n          D\n          \n            A\n          \n        \n        \n          |\n        \n        \n          |\n        \n        I\n        \n          D\n          \n            B\n          \n        \n      \n    \n    {\\displaystyle 1)A\\rightarrow KDC:ID_{A}||ID_{B}}\n  \n  \n    \n      \n        2\n        )\n        K\n        D\n        C\n        \u2192\n        A\n        :\n        \n          S\n          \n            K\n            \n              R\n              \n                K\n                D\n                C\n              \n            \n          \n        \n        [\n        I\n        \n          D\n          \n            B\n          \n        \n        \n          |\n        \n        \n          |\n        \n        K\n        \n          U\n          \n            B\n          \n        \n        ]\n      \n    \n    {\\displaystyle 2)KDC\\rightarrow A:S_{KR_{KDC}}[ID_{B}||KU_{B}]}\n  \n  \n    \n      \n        3\n        )\n        A\n        \u2192\n        B\n        :\n        \n          E\n          \n            K\n            \n              U\n              \n                B\n              \n            \n          \n        \n        [\n        \n          N\n          \n            A\n          \n        \n        \n          |\n        \n        \n          |\n        \n        I\n        \n          D\n          \n            A\n          \n        \n        ]\n      \n    \n    {\\displaystyle 3)A\\rightarrow B:E_{KU_{B}}[N_{A}||ID_{A}]}\n  \n  \n    \n      \n        4\n        )\n        B\n        \u2192\n        K\n        D\n        C\n        :\n        I\n        \n          D\n          \n            B\n          \n        \n        \n          |\n        \n        \n          |\n        \n        I\n        \n          D\n          \n            A\n          \n        \n        \n          |\n        \n        \n          |\n        \n        \n          E\n          \n            K\n            \n              U\n              \n                K\n                D\n                C\n              \n            \n          \n        \n        [\n        \n          N\n          \n            A\n          \n        \n        ]\n      \n    \n    {\\displaystyle 4)B\\rightarrow KDC:ID_{B}||ID_{A}||E_{KU_{KDC}}[N_{A}]}\n  \n  \n    \n      \n        5\n        )\n        K\n        D\n        C\n        \u2192\n        B\n        :\n        \n          S\n          \n            K\n            \n              R\n              \n                K\n                D\n                C\n              \n            \n          \n        \n        [\n        I\n        \n          D\n          \n            A\n          \n        \n        \n          |\n        \n        \n          |\n        \n        K\n        \n          U\n          \n            A\n          \n        \n        ]\n        \n          |\n        \n        \n          |\n        \n        \n          E\n          \n            K\n            \n              U\n              \n                B\n              \n            \n          \n        \n        [\n        \n          S\n          \n            K\n            \n              R\n              \n                K\n                D\n                C\n              \n            \n          \n        \n        [\n        \n          N\n          \n            A\n          \n        \n        \n          |\n        \n        \n          |\n        \n        K\n        \n          |\n        \n        \n          |\n        \n        I\n        \n          D\n          \n            B\n          \n        \n        \n          |\n        \n        \n          |\n        \n        I\n        \n          D\n          \n            A\n          \n        \n        ]\n        ]\n      \n    \n    {\\displaystyle 5)KDC\\rightarrow B:S_{KR_{KDC}}[ID_{A}||KU_{A}]||E_{KU_{B}}[S_{KR_{KDC}}[N_{A}||K||ID_{B}||ID_{A}]]}\n  \n  \n    \n      \n        6\n        )\n        B\n        \u2192\n        A\n        :\n        \n          E\n          \n            K\n            \n              U\n              \n                A\n              \n            \n          \n        \n        [\n        \n          S\n          \n            K\n            \n              R\n              \n                K\n                D\n                C\n              \n            \n          \n        \n        [\n        \n          N\n          \n            A\n          \n        \n        \n          |\n        \n        \n          |\n        \n        K\n        ]\n        \n          |\n        \n        \n          |\n        \n        \n          N\n          \n            B\n          \n        \n        ]\n      \n    \n    {\\displaystyle 6)B\\rightarrow A:E_{KU_{A}}[S_{KR_{KDC}}[N_{A}||K]||N_{B}]}\n  \n  \n    \n      \n        7\n        )\n        A\n        \u2192\n        B\n        :\n        \n          E\n          \n            K\n          \n        \n        [\n        \n          N\n          \n            B\n          \n        \n        ]\n      \n    \n    {\\displaystyle 7)A\\rightarrow B:E_{K}[N_{B}]}\n  The original version of the protocol had the identifier \n  \n    \n      \n        I\n        \n          D\n          \n            A\n          \n        \n      \n    \n    {\\displaystyle ID_{A}}\n   omitted from lines 5 and 6, which did not account for the fact that \n  \n    \n      \n        \n          N\n          \n            A\n          \n        \n      \n    \n    {\\displaystyle N_{A}}\n   is unique only among nonces generated by A and not by other parties. The protocol was revised after the authors themselves spotted a flaw in the algorithm.\nAnswer this question: How is the session key generated in the Woo-Lam public-key protocol?",
    "context": "",
    "output": "The session key is generated randomly by the KDC, who then securely transmits it to each party in the protocol.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How is the session key generated in the Woo-Lam public-key protocol?",
      "answer": "The session key is generated randomly by the KDC, who then securely transmits it to each party in the protocol.",
      "context": "Woo\u2013Lam\n\n==Introduction==\nIn cryptography, Woo\u2013Lam refers to various computer network authentication protocols designed by Simon S. Lam and Thomas Woo. The protocols enable two communicating parties to authenticate each other's identity and to exchange session keys, and involve the use of a trusted key distribution center (KDC) to negotiate between the parties. Both symmetric-key and public-key variants have been described. However, the protocols suffer from various security flaws, and in part have been described as being inefficient compared to alternative authentication protocols.\n\n== Public-key protocol ==\n\n\n*** Notation ***\nThe following notation is used to describe the algorithm:\n\n  \n    \n      \n        A\n        ,\n        B\n      \n    \n    {\\displaystyle A,B}\n   - network nodes.\n\n  \n    \n      \n        K\n        \n          U\n          \n            x\n          \n        \n      \n    \n    {\\displaystyle KU_{x}}\n   - public key of node \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  .\n\n  \n    \n      \n        K\n        \n          R\n          \n            x\n          \n        \n      \n    \n    {\\displaystyle KR_{x}}\n   - private key of \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  .\n\n  \n    \n      \n        \n          N\n          \n            x\n          \n        \n      \n    \n    {\\displaystyle N_{x}}\n   - nonce chosen by \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  .\n\n  \n    \n      \n        I\n        \n          D\n          \n            x\n          \n        \n      \n    \n    {\\displaystyle ID_{x}}\n   - unique identifier of \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  .\n\n  \n    \n      \n        \n          E\n          \n            k\n          \n        \n      \n    \n    {\\displaystyle E_{k}}\n   - public-key encryption using key \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  .\n\n  \n    \n      \n        \n          S\n          \n            k\n          \n        \n      \n    \n    {\\displaystyle S_{k}}\n   - digital signature using key \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  .\n\n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n   - random session key chosen by the KDC.\n\n  \n    \n      \n        \n          |\n        \n        \n          |\n        \n      \n    \n    {\\displaystyle ||}\n   - concatenation.It is assumed that all parties know the KDC's public key.\n\n\n*** Message exchange ***\n\n  \n    \n      \n        1\n        )\n        A\n        \u2192\n        K\n        D\n        C\n        :\n        I\n        \n          D\n          \n            A\n          \n        \n        \n          |\n        \n        \n          |\n        \n        I\n        \n          D\n          \n            B\n          \n        \n      \n    \n    {\\displaystyle 1)A\\rightarrow KDC:ID_{A}||ID_{B}}\n  \n  \n    \n      \n        2\n        )\n        K\n        D\n        C\n        \u2192\n        A\n        :\n        \n          S\n          \n            K\n            \n              R\n              \n                K\n                D\n                C\n              \n            \n          \n        \n        [\n        I\n        \n          D\n          \n            B\n          \n        \n        \n          |\n        \n        \n          |\n        \n        K\n        \n          U\n          \n            B\n          \n        \n        ]\n      \n    \n    {\\displaystyle 2)KDC\\rightarrow A:S_{KR_{KDC}}[ID_{B}||KU_{B}]}\n  \n  \n    \n      \n        3\n        )\n        A\n        \u2192\n        B\n        :\n        \n          E\n          \n            K\n            \n              U\n              \n                B\n              \n            \n          \n        \n        [\n        \n          N\n          \n            A\n          \n        \n        \n          |\n        \n        \n          |\n        \n        I\n        \n          D\n          \n            A\n          \n        \n        ]\n      \n    \n    {\\displaystyle 3)A\\rightarrow B:E_{KU_{B}}[N_{A}||ID_{A}]}\n  \n  \n    \n      \n        4\n        )\n        B\n        \u2192\n        K\n        D\n        C\n        :\n        I\n        \n          D\n          \n            B\n          \n        \n        \n          |\n        \n        \n          |\n        \n        I\n        \n          D\n          \n            A\n          \n        \n        \n          |\n        \n        \n          |\n        \n        \n          E\n          \n            K\n            \n              U\n              \n                K\n                D\n                C\n              \n            \n          \n        \n        [\n        \n          N\n          \n            A\n          \n        \n        ]\n      \n    \n    {\\displaystyle 4)B\\rightarrow KDC:ID_{B}||ID_{A}||E_{KU_{KDC}}[N_{A}]}\n  \n  \n    \n      \n        5\n        )\n        K\n        D\n        C\n        \u2192\n        B\n        :\n        \n          S\n          \n            K\n            \n              R\n              \n                K\n                D\n                C\n              \n            \n          \n        \n        [\n        I\n        \n          D\n          \n            A\n          \n        \n        \n          |\n        \n        \n          |\n        \n        K\n        \n          U\n          \n            A\n          \n        \n        ]\n        \n          |\n        \n        \n          |\n        \n        \n          E\n          \n            K\n            \n              U\n              \n                B\n              \n            \n          \n        \n        [\n        \n          S\n          \n            K\n            \n              R\n              \n                K\n                D\n                C\n              \n            \n          \n        \n        [\n        \n          N\n          \n            A\n          \n        \n        \n          |\n        \n        \n          |\n        \n        K\n        \n          |\n        \n        \n          |\n        \n        I\n        \n          D\n          \n            B\n          \n        \n        \n          |\n        \n        \n          |\n        \n        I\n        \n          D\n          \n            A\n          \n        \n        ]\n        ]\n      \n    \n    {\\displaystyle 5)KDC\\rightarrow B:S_{KR_{KDC}}[ID_{A}||KU_{A}]||E_{KU_{B}}[S_{KR_{KDC}}[N_{A}||K||ID_{B}||ID_{A}]]}\n  \n  \n    \n      \n        6\n        )\n        B\n        \u2192\n        A\n        :\n        \n          E\n          \n            K\n            \n              U\n              \n                A\n              \n            \n          \n        \n        [\n        \n          S\n          \n            K\n            \n              R\n              \n                K\n                D\n                C\n              \n            \n          \n        \n        [\n        \n          N\n          \n            A\n          \n        \n        \n          |\n        \n        \n          |\n        \n        K\n        ]\n        \n          |\n        \n        \n          |\n        \n        \n          N\n          \n            B\n          \n        \n        ]\n      \n    \n    {\\displaystyle 6)B\\rightarrow A:E_{KU_{A}}[S_{KR_{KDC}}[N_{A}||K]||N_{B}]}\n  \n  \n    \n      \n        7\n        )\n        A\n        \u2192\n        B\n        :\n        \n          E\n          \n            K\n          \n        \n        [\n        \n          N\n          \n            B\n          \n        \n        ]\n      \n    \n    {\\displaystyle 7)A\\rightarrow B:E_{K}[N_{B}]}\n  The original version of the protocol had the identifier \n  \n    \n      \n        I\n        \n          D\n          \n            A\n          \n        \n      \n    \n    {\\displaystyle ID_{A}}\n   omitted from lines 5 and 6, which did not account for the fact that \n  \n    \n      \n        \n          N\n          \n            A\n          \n        \n      \n    \n    {\\displaystyle N_{A}}\n   is unique only among nonces generated by A and not by other parties. The protocol was revised after the authors themselves spotted a flaw in the algorithm."
    }
  },
  {
    "instruction": "Tor Mail\n\n==Introduction==\nTor Mail was a Tor hidden service that went offline in August 2013 after an FBI raid on Freedom Hosting. The service allowed users to send and receive email anonymously to email addresses inside and outside the Tor network.\n\n\n\nWhat was the significance of Tor Mail's relationship with Freedom Hosting, and how did this connection impact the service's security and anonymity?",
    "context": "",
    "output": "Tor Mail relied on Freedom Hosting, a popular provider of hidden services on the Tor network, for hosting its platform. When Freedom Hosting was raided by the FBI in August 2013, Tor Mail went offline, impacting the security and anonymity of its users. This incident underscores the vulnerabilities that can arise from dependence on a single hosting provider in the context of maintaining user anonymity and security in a hidden service like Tor Mail.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was the significance of Tor Mail's relationship with Freedom Hosting, and how did this connection impact the service's security and anonymity?",
      "answer": "Tor Mail relied on Freedom Hosting, a popular provider of hidden services on the Tor network, for hosting its platform. When Freedom Hosting was raided by the FBI in August 2013, Tor Mail went offline, impacting the security and anonymity of its users. This incident underscores the vulnerabilities that can arise from dependence on a single hosting provider in the context of maintaining user anonymity and security in a hidden service like Tor Mail.",
      "context": "Tor Mail\n\n==Introduction==\nTor Mail was a Tor hidden service that went offline in August 2013 after an FBI raid on Freedom Hosting. The service allowed users to send and receive email anonymously to email addresses inside and outside the Tor network.\n\n"
    }
  },
  {
    "instruction": "Write an answer to the following question: How did Google's management react to domain fronting gaining popular attention?",
    "context": "",
    "output": "After domain fronting gained popular attention, Google's management came to question whether they wanted to act as a front for sites and services entire nation states wanted to block. As a result, using fronting in a circumvention tool became largely non-viable in the countries it was needed.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How did Google's management react to domain fronting gaining popular attention?",
      "answer": "After domain fronting gained popular attention, Google's management came to question whether they wanted to act as a front for sites and services entire nation states wanted to block. As a result, using fronting in a circumvention tool became largely non-viable in the countries it was needed."
    }
  },
  {
    "instruction": "Write an answer to the following question: How did ShinyHunters announce the Mashable data breach, and what was the size of the leaked database?",
    "context": "",
    "output": "ShinyHunters leaked 5.22GB worth of the Mashable database on a prominent hacker forum. The method of announcing the data breach is not specified in the given text.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How did ShinyHunters announce the Mashable data breach, and what was the size of the leaked database?",
      "answer": "ShinyHunters leaked 5.22GB worth of the Mashable database on a prominent hacker forum. The method of announcing the data breach is not specified in the given text."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the role of the Control Layer in generating protections in SDP?",
    "context": "",
    "output": "The Control Layer generates protections based on repositories of data that include knowledge of the organization and its information systems, knowledge of data assets and their classifications, and knowledge of threats. Through systematic mapping of protective controls to the associated risk for each segment and its assets within the Enforcement Layer, organizations can deliver multi-layer protection against attacks.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of the Control Layer in generating protections in SDP?",
      "answer": "The Control Layer generates protections based on repositories of data that include knowledge of the organization and its information systems, knowledge of data assets and their classifications, and knowledge of threats. Through systematic mapping of protective controls to the associated risk for each segment and its assets within the Enforcement Layer, organizations can deliver multi-layer protection against attacks."
    }
  },
  {
    "instruction": "Write an answer to the following question: How did the collapse of the Soviet Union impact the geopolitical landscape of Europe?",
    "context": "",
    "output": "The collapse of the Soviet Union had a significant impact on the geopolitical landscape of Europe, as it marked the end of the Cold War and the beginning of a new era in international relations. The Soviet Union's former satellite states in Eastern Europe gained independence and the region underwent significant political and economic changes.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How did the collapse of the Soviet Union impact the geopolitical landscape of Europe?",
      "answer": "The collapse of the Soviet Union had a significant impact on the geopolitical landscape of Europe, as it marked the end of the Cold War and the beginning of a new era in international relations. The Soviet Union's former satellite states in Eastern Europe gained independence and the region underwent significant political and economic changes."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are the benefits of using the Morningstar model for comparing the security of open-source and closed-source projects?",
    "context": "",
    "output": "The Morningstar model provides a standardized rating system for open-source and closed-source projects, enabling users to compare security practices and vulnerabilities between them. By using statistics, the model can also measure the overall effectiveness of one group over the other.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are the benefits of using the Morningstar model for comparing the security of open-source and closed-source projects?",
      "answer": "The Morningstar model provides a standardized rating system for open-source and closed-source projects, enabling users to compare security practices and vulnerabilities between them. By using statistics, the model can also measure the overall effectiveness of one group over the other."
    }
  },
  {
    "instruction": "Write an answer to the following question: Is the GateKeeper system compatible with all operating systems?",
    "context": "",
    "output": "The GateKeeper system is compatible with Windows operating systems only.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Is the GateKeeper system compatible with all operating systems?",
      "answer": "The GateKeeper system is compatible with Windows operating systems only."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the Streisand effect and how has it played a role in brandjacking incidents?",
    "context": "",
    "output": "The Streisand effect refers to the phenomenon where attempting to suppress or censor information online often results in increased publicity and awareness. This effect has been seen in brandjacking incidents, such as when Nestl\u00e9 tried to remove a Greenpeace video criticizing its unsustainable business practices. Greenpeace quickly reposted the video, and Nestl\u00e9's attempts to constrain user activity on its Facebook page further fueled the controversy.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the Streisand effect and how has it played a role in brandjacking incidents?",
      "answer": "The Streisand effect refers to the phenomenon where attempting to suppress or censor information online often results in increased publicity and awareness. This effect has been seen in brandjacking incidents, such as when Nestl\u00e9 tried to remove a Greenpeace video criticizing its unsustainable business practices. Greenpeace quickly reposted the video, and Nestl\u00e9's attempts to constrain user activity on its Facebook page further fueled the controversy."
    }
  },
  {
    "instruction": "Privoxy\n\n==Introduction==\nPrivoxy is a free non-caching web proxy with filtering capabilities for enhancing privacy, manipulating cookies and modifying web page data and HTTP headers before the page is rendered by the browser. Privoxy is a \"privacy enhancing proxy\", filtering web pages and removing advertisements. Privoxy can be customized by users, for both stand-alone systems and multi-user networks. Privoxy can be chained to other proxies and is frequently used in combination with Squid among others and can be used to bypass Internet censorship.\n\n\n\n\n\nHow does Privoxy manipulate cookies and HTTP headers?",
    "context": "",
    "output": "A: Privoxy can modify cookies and HTTP headers before a web page is rendered by the browser, allowing users to control the information that is sent to and received from web servers. For example, users can configure Privoxy to block certain types of cookies, modify HTTP headers to obscure their IP address or other identifying information, or even add custom headers to requests. This level of control can help users protect their privacy and enhance their security online.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does Privoxy manipulate cookies and HTTP headers?",
      "answer": "Privoxy can modify cookies and HTTP headers before a web page is rendered by the browser, allowing users to control the information that is sent to and received from web servers. For example, users can configure Privoxy to block certain types of cookies, modify HTTP headers to obscure their IP address or other identifying information, or even add custom headers to requests. This level of control can help users protect their privacy and enhance their security online.",
      "context": "Privoxy\n\n==Introduction==\nPrivoxy is a free non-caching web proxy with filtering capabilities for enhancing privacy, manipulating cookies and modifying web page data and HTTP headers before the page is rendered by the browser. Privoxy is a \"privacy enhancing proxy\", filtering web pages and removing advertisements. Privoxy can be customized by users, for both stand-alone systems and multi-user networks. Privoxy can be chained to other proxies and is frequently used in combination with Squid among others and can be used to bypass Internet censorship.\n\n\n\n"
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the primary function of Network Address Translation (NAT)?",
    "context": "",
    "output": "Network Address Translation (NAT) is a technique used in computer networking to allow the use of private IP addresses on private networks behind routers with a single public IP address facing the Internet. It enables internal network devices to communicate with hosts on the external network by changing the source address of outgoing requests to that of the NAT device and relaying replies back to the originating device.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the primary function of Network Address Translation (NAT)?",
      "answer": "Network Address Translation (NAT) is a technique used in computer networking to allow the use of private IP addresses on private networks behind routers with a single public IP address facing the Internet. It enables internal network devices to communicate with hosts on the external network by changing the source address of outgoing requests to that of the NAT device and relaying replies back to the originating device."
    }
  },
  {
    "instruction": "Write an answer to the following question: How many employees does Bitdefender have worldwide as of 2020?",
    "context": "",
    "output": "As of 2020, Bitdefender employed more than 1,600 people worldwide.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How many employees does Bitdefender have worldwide as of 2020?",
      "answer": "As of 2020, Bitdefender employed more than 1,600 people worldwide."
    }
  },
  {
    "instruction": "Forking lemma\n\n==Introduction==\nThe forking lemma is any of a number of related lemmas in cryptography research.  The lemma states that if an adversary (typically a probabilistic Turing machine), on inputs drawn from some distribution, produces an output that has some property with non-negligible probability, then with non-negligible probability, if the adversary is re-run on new inputs but with the same random tape, its second output will also have the property.\nThis concept was first used by David Pointcheval and Jacques Stern in \"Security proofs for signature schemes,\" published in the proceedings of Eurocrypt 1996.  In their paper, the forking lemma is specified in terms of an adversary that attacks a digital signature scheme instantiated in the random oracle model.  They show that if an adversary can forge a signature with non-negligible probability, then there is a non-negligible probability that the same adversary with the same random tape can create a second forgery in an attack with a different random oracle.  The forking lemma was later generalized by Mihir Bellare and Gregory Neven. The forking lemma has been used and further generalized to prove the security of a variety of digital signature schemes and other random-oracle based cryptographic constructions.\n\n== Statement of the lemma ==\nThe generalized version of the lemma is stated as follows.  Let A be a probabilistic algorithm, with inputs (x, h1, ..., hq; r) that outputs a pair (J, y), where r refers to the random tape of A (that is, the random choices A will make).  Suppose further that IG is a probability distribution from which x is drawn, and that H is a set of size h from which each of the hi values are drawn according to the uniform distribution.  Let acc be the probability that on inputs distributed as described, the J output by A is greater than or equal to 1.\nWe can then define a \"forking algorithm\" FA that proceeds as follows, on input x:\n\nPick a random tape r for A.\nPick h1, ..., hq uniformly from H.\nRun A on input (x, h1, ..., hq; r) to produce (J, y).\nIf J\n\n== Known issues with application of forking lemma ==\nThe reduction provided by the forking lemma is not tight. Pointcheval and Stern proposed security arguments for Digital Signatures and Blind Signature using Forking Lemma. Claus P. Schnorr provided an attack on blind Schnorr signatures schemes, with more than \n  \n    \n      \n        p\n        o\n        l\n        y\n        l\n        o\n        g\n        (\n        n\n        )\n      \n    \n    {\\displaystyle polylog(n)}\n   concurrent executions (the case studied and proven secure by Pointcheval and Stern). A polynomial-time attack, for \n  \n    \n      \n        \u03a9\n        (\n        n\n        )\n      \n    \n    {\\displaystyle \\Omega (n)}\n   concurrent executions, was shown in 2020 by Benhamouda, Lepoint, Raykova, and Orr\u00f9.\nSchnorr also suggested enhancements for securing blind signatures schemes based on discrete logarithm problem.\nQ: What is the forking lemma used to prove?",
    "context": "",
    "output": "The forking lemma is used to prove the security of a variety of digital signature schemes and other random-oracle based cryptographic constructions.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the forking lemma used to prove?",
      "answer": "The forking lemma is used to prove the security of a variety of digital signature schemes and other random-oracle based cryptographic constructions.",
      "context": "Forking lemma\n\n==Introduction==\nThe forking lemma is any of a number of related lemmas in cryptography research.  The lemma states that if an adversary (typically a probabilistic Turing machine), on inputs drawn from some distribution, produces an output that has some property with non-negligible probability, then with non-negligible probability, if the adversary is re-run on new inputs but with the same random tape, its second output will also have the property.\nThis concept was first used by David Pointcheval and Jacques Stern in \"Security proofs for signature schemes,\" published in the proceedings of Eurocrypt 1996.  In their paper, the forking lemma is specified in terms of an adversary that attacks a digital signature scheme instantiated in the random oracle model.  They show that if an adversary can forge a signature with non-negligible probability, then there is a non-negligible probability that the same adversary with the same random tape can create a second forgery in an attack with a different random oracle.  The forking lemma was later generalized by Mihir Bellare and Gregory Neven. The forking lemma has been used and further generalized to prove the security of a variety of digital signature schemes and other random-oracle based cryptographic constructions.\n\n== Statement of the lemma ==\nThe generalized version of the lemma is stated as follows.  Let A be a probabilistic algorithm, with inputs (x, h1, ..., hq; r) that outputs a pair (J, y), where r refers to the random tape of A (that is, the random choices A will make).  Suppose further that IG is a probability distribution from which x is drawn, and that H is a set of size h from which each of the hi values are drawn according to the uniform distribution.  Let acc be the probability that on inputs distributed as described, the J output by A is greater than or equal to 1.\nWe can then define a \"forking algorithm\" FA that proceeds as follows, on input x:\n\nPick a random tape r for A.\nPick h1, ..., hq uniformly from H.\nRun A on input (x, h1, ..., hq; r) to produce (J, y).\nIf J\n\n== Known issues with application of forking lemma ==\nThe reduction provided by the forking lemma is not tight. Pointcheval and Stern proposed security arguments for Digital Signatures and Blind Signature using Forking Lemma. Claus P. Schnorr provided an attack on blind Schnorr signatures schemes, with more than \n  \n    \n      \n        p\n        o\n        l\n        y\n        l\n        o\n        g\n        (\n        n\n        )\n      \n    \n    {\\displaystyle polylog(n)}\n   concurrent executions (the case studied and proven secure by Pointcheval and Stern). A polynomial-time attack, for \n  \n    \n      \n        \u03a9\n        (\n        n\n        )\n      \n    \n    {\\displaystyle \\Omega (n)}\n   concurrent executions, was shown in 2020 by Benhamouda, Lepoint, Raykova, and Orr\u00f9.\nSchnorr also suggested enhancements for securing blind signatures schemes based on discrete logarithm problem."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is egg-hunt shellcode?",
    "context": "",
    "output": "This is a form of staged shellcode, which is used if an attacker can inject a larger shellcode into the process but cannot determine where in the process it will end up. Small egg-hunt shellcode is injected into the process at a predictable location and executed, which then searches the process's address space for the larger shellcode (the egg) and executes it.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is egg-hunt shellcode?",
      "answer": "This is a form of staged shellcode, which is used if an attacker can inject a larger shellcode into the process but cannot determine where in the process it will end up. Small egg-hunt shellcode is injected into the process at a predictable location and executed, which then searches the process's address space for the larger shellcode (the egg) and executes it."
    }
  },
  {
    "instruction": "Write an answer to the following question: In what type of setting is an identity-based cryptographic system used?",
    "context": "",
    "output": "In an identity-based cryptographic system, the public key of a user can be any unique string of bits that identifies them, such as an email address or phone number. The corresponding private key is generated and issued by a key generation center (KGC), rather than by the user themselves.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "In what type of setting is an identity-based cryptographic system used?",
      "answer": "In an identity-based cryptographic system, the public key of a user can be any unique string of bits that identifies them, such as an email address or phone number. The corresponding private key is generated and issued by a key generation center (KGC), rather than by the user themselves."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is a trapdoor one-way function or trapdoor permutation?",
    "context": "",
    "output": "A trapdoor one-way function or trapdoor permutation is a special kind of one-way function that is hard to invert unless some secret information, called the trapdoor, is known.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is a trapdoor one-way function or trapdoor permutation?",
      "answer": "A trapdoor one-way function or trapdoor permutation is a special kind of one-way function that is hard to invert unless some secret information, called the trapdoor, is known."
    }
  },
  {
    "instruction": "Software-defined protection\n\n==Introduction==\nSoftware-defined protection (SDP) is a computer network security architecture and methodology that combines network security devices and defensive protections which leverage both internal and external intelligence sources. An SDP infrastructure is designed to be modular, scalable, and secure. The SDP architecture partitions the security infrastructure into three interconnected layers. The Enforcement Layer inspects traffic and enforces protection within well-defined network segments. The Control Layer generates security policies and deploys those protections to enforcement points. The Management Layer orchestrates the infrastructure and integrates security with business processes. The SDP architecture supports traditional network security and access control policy requirements, as well as the threat prevention required for enterprises implementing technologies such as mobile computing and software-defined Networking (SDN).\n\n\n\n== Enforcement Layer ==\nThe Enforcement Layer of SDP enables organizations to design segmented networks, implement physical and virtual security enforcement points based upon that segmentation, and execute the protection logic for the prescribed network segments.\nSDP incorporates the principal of segmentation into the Enforcement Layer. Segmentation divides a network into compartments that have different security characteristics. Based upon segment requirements, security controls are established for threat containment and recovery. Enforcement points, or platforms for executing protections, must then be implemented at the boundaries of the segments to enforce the defined protection logic. Enforcement points may be implemented as network security gateways, host-based software, mobile device applications, or virtual machines in the cloud.\n\n== Control Layer ==\nThe Control Layer is the core of the SDP architecture. Its role is to generate protections and deploy them for execution at the appropriate enforcement points within the Enforcement Layer. To develop the appropriate protections, the Control Layer relies upon repositories of data that include knowledge of the organization and its information systems (Access Control), knowledge of data assets and their classifications (data protection) and knowledge of threats (threat prevention). Security Solutions commonly implemented within the Control layer include firewall, anti-virus, application control, threat emulation, anti-bot, anti-spam and email security, data loss prevention (DLP), and intrusion prevention systems (IPS). Through systematic mapping of these protective controls to the associated risk for each segment and its assets within the Enforcement Layer, organizations can deliver multi-layer protection against attacks.\n\n== Management Layer ==\nThe Management Layer serves as the interface between network administrators and the other two layers of the SDP infrastructure. This layer supports the enterprise segmentation and enables the definition of access and data control policies and the activation of threat prevention separately. The Management Layer also provides the ability to delegate management to specific administrators who can work with them simultaneously. The Management Layer provides visibility into what is happening in the network, supports proactive incident response, and provides the intelligence required to tailor security controls for the organization.\n\nBased on the above text, answer a question. How does SDP architecture support access control policy requirements?",
    "context": "",
    "output": "SDP architecture supports access control policy requirements by implementing security controls for threat containment and recovery and enforcing the defined protection logic at the boundaries of the segments.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does SDP architecture support access control policy requirements?",
      "answer": "SDP architecture supports access control policy requirements by implementing security controls for threat containment and recovery and enforcing the defined protection logic at the boundaries of the segments.",
      "context": "Software-defined protection\n\n==Introduction==\nSoftware-defined protection (SDP) is a computer network security architecture and methodology that combines network security devices and defensive protections which leverage both internal and external intelligence sources. An SDP infrastructure is designed to be modular, scalable, and secure. The SDP architecture partitions the security infrastructure into three interconnected layers. The Enforcement Layer inspects traffic and enforces protection within well-defined network segments. The Control Layer generates security policies and deploys those protections to enforcement points. The Management Layer orchestrates the infrastructure and integrates security with business processes. The SDP architecture supports traditional network security and access control policy requirements, as well as the threat prevention required for enterprises implementing technologies such as mobile computing and software-defined Networking (SDN).\n\n\n\n== Enforcement Layer ==\nThe Enforcement Layer of SDP enables organizations to design segmented networks, implement physical and virtual security enforcement points based upon that segmentation, and execute the protection logic for the prescribed network segments.\nSDP incorporates the principal of segmentation into the Enforcement Layer. Segmentation divides a network into compartments that have different security characteristics. Based upon segment requirements, security controls are established for threat containment and recovery. Enforcement points, or platforms for executing protections, must then be implemented at the boundaries of the segments to enforce the defined protection logic. Enforcement points may be implemented as network security gateways, host-based software, mobile device applications, or virtual machines in the cloud.\n\n== Control Layer ==\nThe Control Layer is the core of the SDP architecture. Its role is to generate protections and deploy them for execution at the appropriate enforcement points within the Enforcement Layer. To develop the appropriate protections, the Control Layer relies upon repositories of data that include knowledge of the organization and its information systems (Access Control), knowledge of data assets and their classifications (data protection) and knowledge of threats (threat prevention). Security Solutions commonly implemented within the Control layer include firewall, anti-virus, application control, threat emulation, anti-bot, anti-spam and email security, data loss prevention (DLP), and intrusion prevention systems (IPS). Through systematic mapping of these protective controls to the associated risk for each segment and its assets within the Enforcement Layer, organizations can deliver multi-layer protection against attacks.\n\n== Management Layer ==\nThe Management Layer serves as the interface between network administrators and the other two layers of the SDP infrastructure. This layer supports the enterprise segmentation and enables the definition of access and data control policies and the activation of threat prevention separately. The Management Layer also provides the ability to delegate management to specific administrators who can work with them simultaneously. The Management Layer provides visibility into what is happening in the network, supports proactive incident response, and provides the intelligence required to tailor security controls for the organization."
    }
  },
  {
    "instruction": "Context: NaCl (software)\n\n==Introduction==\nNaCl (pronounced \"salt\") is an abbreviation for \"Networking and Cryptography library\", a public domain \"...high-speed software library for network communication, encryption, decryption, signatures, etc\".NaCl was created by the mathematician and programmer Daniel J. Bernstein who is best known for the creation of qmail and Curve25519. The core team also includes Tanja Lange and Peter Schwabe. The main goal while creating NaCl, according to the paper, was to \"avoid various types of cryptographic disasters suffered by previous cryptographic libraries\".\n\n== Basic functions ==\n\n\n*** Public-key cryptography ***\nSignatures using Ed25519.\nKey agreement using X25519.\n\n\n*** Secret-key cryptography ***\nAuthenticated encryption using Salsa20-Poly1305.\nEncryption using Salsa20 or AES.\nAuthentication using HMAC-SHA-512-256.\nOne-time authentication using Poly1305.\n\n\n*** Low-level functions ***\nHashing using SHA-512 or SHA-256 or BLAKE2 using libsodiumString comparison.\n\n\n*** Key derivation function (only libsodium) ***\nPassword hashing using argon2\n\n== Implementations ==\nReference implementation is written in C, often with several inline assembler. C++ and Python are handled as wrappers.NaCl has a variety of programming language bindings such as PHP, and forms the basis for Libsodium, a cross-platform cryptography library created in 2013 which is API compatible with NaCl.\n\n\n*** Alternative implementations ***\nLibsodium \u2014 a portable, cross-compilable, installable, packageable, API-compatible version of NaCl.\ndryoc \u2014 a pure-Rust implementation of libsodium/NaCl, with support for protected memory.\nNaCl Pharo \u2014 a Pharo Smalltalk Extension.\nTweetNaCl \u2014 a tiny C library, which fits in just 100 tweets (140 symbols each), but supports all NaCl functions.\nNaCl for Tcl \u2014 a port to the Tcl language.\nNaCl for JavaScript \u2014 a port of TweetNaCl/NaCl cryptographic library to the JavaScript language.\nTweetNaCl for Java \u2014 a port of TweetNaCl/NaCl cryptographic library to the Java language.\nSPARKNaCl \u2014 A re-write of TweetNaCl in the SPARK Ada subset, with formal and fully automatic proofs of type safety and some correctness properties.\nCrypt::NaCl::Sodium Perl 5 binding to libsodium\nMonocypher\n\nQuestion: Which alternative implementation of NaCl is a Pharo Smalltalk Extension?\n\nAnswer:",
    "context": "",
    "output": "NaCl Pharo is an alternative implementation of NaCl that is a Pharo Smalltalk Extension.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Which alternative implementation of NaCl is a Pharo Smalltalk Extension?",
      "answer": "NaCl Pharo is an alternative implementation of NaCl that is a Pharo Smalltalk Extension.",
      "context": "NaCl (software)\n\n==Introduction==\nNaCl (pronounced \"salt\") is an abbreviation for \"Networking and Cryptography library\", a public domain \"...high-speed software library for network communication, encryption, decryption, signatures, etc\".NaCl was created by the mathematician and programmer Daniel J. Bernstein who is best known for the creation of qmail and Curve25519. The core team also includes Tanja Lange and Peter Schwabe. The main goal while creating NaCl, according to the paper, was to \"avoid various types of cryptographic disasters suffered by previous cryptographic libraries\".\n\n== Basic functions ==\n\n\n*** Public-key cryptography ***\nSignatures using Ed25519.\nKey agreement using X25519.\n\n\n*** Secret-key cryptography ***\nAuthenticated encryption using Salsa20-Poly1305.\nEncryption using Salsa20 or AES.\nAuthentication using HMAC-SHA-512-256.\nOne-time authentication using Poly1305.\n\n\n*** Low-level functions ***\nHashing using SHA-512 or SHA-256 or BLAKE2 using libsodiumString comparison.\n\n\n*** Key derivation function (only libsodium) ***\nPassword hashing using argon2\n\n== Implementations ==\nReference implementation is written in C, often with several inline assembler. C++ and Python are handled as wrappers.NaCl has a variety of programming language bindings such as PHP, and forms the basis for Libsodium, a cross-platform cryptography library created in 2013 which is API compatible with NaCl.\n\n\n*** Alternative implementations ***\nLibsodium \u2014 a portable, cross-compilable, installable, packageable, API-compatible version of NaCl.\ndryoc \u2014 a pure-Rust implementation of libsodium/NaCl, with support for protected memory.\nNaCl Pharo \u2014 a Pharo Smalltalk Extension.\nTweetNaCl \u2014 a tiny C library, which fits in just 100 tweets (140 symbols each), but supports all NaCl functions.\nNaCl for Tcl \u2014 a port to the Tcl language.\nNaCl for JavaScript \u2014 a port of TweetNaCl/NaCl cryptographic library to the JavaScript language.\nTweetNaCl for Java \u2014 a port of TweetNaCl/NaCl cryptographic library to the Java language.\nSPARKNaCl \u2014 A re-write of TweetNaCl in the SPARK Ada subset, with formal and fully automatic proofs of type safety and some correctness properties.\nCrypt::NaCl::Sodium Perl 5 binding to libsodium\nMonocypher"
    }
  },
  {
    "instruction": "Protocol for Carrying Authentication for Network Access\n\n==Introduction==\nPANA (Protocol for Carrying Authentication for Network Access) is an IP-based protocol that allows a device to authenticate itself with a network to be granted access. PANA will not define any new authentication protocol, key distribution, key agreement or key derivation protocols. For these purposes, the Extensible Authentication Protocol (EAP) will be used, and PANA will carry the EAP payload. PANA allows dynamic service provider selection, supports various authentication methods, is suitable for roaming users, and is independent from the link layer mechanisms.\nPANA is an Internet Engineering Task Force (IETF) protocol and described in RFC 5191.\n\n== Architecture's elements ==\nPaC (PANA Client)\nThe PaC is the client part of the protocol. This element is located in the node that wants to reach the access network.\nPAA (PANA Authentication Agent)\nThis entity represents the server part of the PANA protocol. Its main task is the message exchange with the PaC for authenticating and authorizing it for network access. In addition, in some scenarios, the PAA entity has to do other message exchange with the AAA server in order to offer the PaC credentials to it. In this case, EAP is configured as pass-through and the AAA server is placed physically in a different place than the PAA.\nAS (Authentication Server)\nThis element contains the information needed to check the PaC's credentials. To this end this node receives the PaC's credentials from the PAA, performs a credential check, and sends a packet with the result of the credential check. If the credential check was successful, that packet contains access parameters, such as allowed bandwidth or IP configuration. At this point, a session between PAA and PaC has been established. This session has a session lifetime. When the session expires, a re-authentication process is required for the PaC to regain network access.\nEP (Enforcement Point) It works as a filter of the packets which source is an authenticated PaC. Basically, an EP is a network node which drops packets according to some parameters provided as results of the authentication processes. Typically, this function is applied by a communication device as an access point or a router. When an authentication process is done successfully, a key is installed in EP and PaC, establishing a session between EP and PaC. While this session is active (hasn't expired), the PaC can access network services for which it has been authorised. When the session expires, the PaC will have to indicate this situation to the PAA in order to perform re-authentication.\n\nHow does PANA support network access for devices with varying authentication methods?",
    "context": "",
    "output": "PANA supports network access for devices with varying authentication methods by relying on the Extensible Authentication Protocol (EAP), which supports various authentication methods. This allows roaming users to connect to different networks using their preferred authentication method.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does PANA support network access for devices with varying authentication methods?",
      "answer": "PANA supports network access for devices with varying authentication methods by relying on the Extensible Authentication Protocol (EAP), which supports various authentication methods. This allows roaming users to connect to different networks using their preferred authentication method.",
      "context": "Protocol for Carrying Authentication for Network Access\n\n==Introduction==\nPANA (Protocol for Carrying Authentication for Network Access) is an IP-based protocol that allows a device to authenticate itself with a network to be granted access. PANA will not define any new authentication protocol, key distribution, key agreement or key derivation protocols. For these purposes, the Extensible Authentication Protocol (EAP) will be used, and PANA will carry the EAP payload. PANA allows dynamic service provider selection, supports various authentication methods, is suitable for roaming users, and is independent from the link layer mechanisms.\nPANA is an Internet Engineering Task Force (IETF) protocol and described in RFC 5191.\n\n== Architecture's elements ==\nPaC (PANA Client)\nThe PaC is the client part of the protocol. This element is located in the node that wants to reach the access network.\nPAA (PANA Authentication Agent)\nThis entity represents the server part of the PANA protocol. Its main task is the message exchange with the PaC for authenticating and authorizing it for network access. In addition, in some scenarios, the PAA entity has to do other message exchange with the AAA server in order to offer the PaC credentials to it. In this case, EAP is configured as pass-through and the AAA server is placed physically in a different place than the PAA.\nAS (Authentication Server)\nThis element contains the information needed to check the PaC's credentials. To this end this node receives the PaC's credentials from the PAA, performs a credential check, and sends a packet with the result of the credential check. If the credential check was successful, that packet contains access parameters, such as allowed bandwidth or IP configuration. At this point, a session between PAA and PaC has been established. This session has a session lifetime. When the session expires, a re-authentication process is required for the PaC to regain network access.\nEP (Enforcement Point) It works as a filter of the packets which source is an authenticated PaC. Basically, an EP is a network node which drops packets according to some parameters provided as results of the authentication processes. Typically, this function is applied by a communication device as an access point or a router. When an authentication process is done successfully, a key is installed in EP and PaC, establishing a session between EP and PaC. While this session is active (hasn't expired), the PaC can access network services for which it has been authorised. When the session expires, the PaC will have to indicate this situation to the PAA in order to perform re-authentication."
    }
  },
  {
    "instruction": "DNS rebinding\n\n==Introduction==\nDNS rebinding is a method of manipulating resolution of domain names that is commonly used as a form of computer attack. In this attack, a malicious web page causes visitors to run a client-side script that attacks machines elsewhere on the network. In theory, the same-origin policy prevents this from happening: client-side scripts are only allowed to access content on the same host that served the script. Comparing domain names is an essential part of enforcing this policy, so DNS rebinding circumvents this protection by abusing the Domain Name System (DNS).\nThis attack can be used to breach a private network by causing the victim's web browser to access computers at private IP addresses and return the results to the attacker. It can also be employed to use the victim machine for spamming, distributed denial-of-service attacks, or other malicious activities.\n\n== How DNS rebinding works ==\nThe attacker registers a domain (such as attacker.com) and delegates it to a DNS server that is under the attacker's control. The server is configured to respond with a very short time to live (TTL) record, preventing the DNS response from being cached. When the victim browses to the malicious domain, the attacker's DNS server first responds with the IP address of a server hosting the malicious client-side code. For instance, they could point the victim's browser to a website that contains malicious JavaScript or Flash scripts that are intended to execute on the victim's computer.\nThe malicious client-side code makes additional accesses to the original domain name (such as attacker.com). These are permitted by the same-origin policy. However, when the victim's browser runs the script it makes a new DNS request for the domain, and the attacker replies with a new IP address. For instance, they could reply with an internal IP address or the IP address of a target somewhere else on the Internet.\n\n== Protection ==\nThe following techniques attempt to prevent DNS rebinding attacks:\nDNS servers in the chain can filter out private IP addresses and loopback IP addresses:\nExternal public DNS servers (e.g. OpenDNS) can implement DNS filtering.\nLocal system administrators can configure the organization's local nameserver(s) to block the resolution of external names into internal IP addresses. (This has the downside of allowing an attacker to map the internal address ranges in use.)\nA firewall (e.g. dnswall), in the gateway or in the local pc, can filter DNS replies that pass through it, discarding local addresses.\nWeb browsers can resist DNS rebinding:\nWeb browsers can implement DNS pinning: the IP address is locked to the value received in the first DNS response. This technique may block some legitimate uses of Dynamic DNS, and may not work against all attacks. However, it is important to fail-safe (stop rendering) if the IP address does change, because using an IP address past the TTL expiration can open the opposite vulnerability when the IP address has legitimately changed and the expired IP address may now be controlled by an attacker.\nThe NoScript extension for Firefox includes ABE, a firewall-like feature inside the browser which in its default configuration prevents attacks on the local network by preventing external webpages from accessing local IP addresses.\nWeb servers can reject HTTP requests with an unrecognized Host header.\n\nQ: What is the role of the NoScript extension for Firefox in preventing DNS rebinding attacks?",
    "context": "",
    "output": "A: The NoScript extension for Firefox includes a firewall-like feature called ABE (Application Boundaries Enforcer) that helps prevent DNS rebinding attacks on the local network. By default, ABE prevents external webpages from accessing local IP addresses, thereby protecting the network from unauthorized access.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of the NoScript extension for Firefox in preventing DNS rebinding attacks?",
      "answer": "The NoScript extension for Firefox includes a firewall-like feature called ABE (Application Boundaries Enforcer) that helps prevent DNS rebinding attacks on the local network. By default, ABE prevents external webpages from accessing local IP addresses, thereby protecting the network from unauthorized access.",
      "context": "DNS rebinding\n\n==Introduction==\nDNS rebinding is a method of manipulating resolution of domain names that is commonly used as a form of computer attack. In this attack, a malicious web page causes visitors to run a client-side script that attacks machines elsewhere on the network. In theory, the same-origin policy prevents this from happening: client-side scripts are only allowed to access content on the same host that served the script. Comparing domain names is an essential part of enforcing this policy, so DNS rebinding circumvents this protection by abusing the Domain Name System (DNS).\nThis attack can be used to breach a private network by causing the victim's web browser to access computers at private IP addresses and return the results to the attacker. It can also be employed to use the victim machine for spamming, distributed denial-of-service attacks, or other malicious activities.\n\n== How DNS rebinding works ==\nThe attacker registers a domain (such as attacker.com) and delegates it to a DNS server that is under the attacker's control. The server is configured to respond with a very short time to live (TTL) record, preventing the DNS response from being cached. When the victim browses to the malicious domain, the attacker's DNS server first responds with the IP address of a server hosting the malicious client-side code. For instance, they could point the victim's browser to a website that contains malicious JavaScript or Flash scripts that are intended to execute on the victim's computer.\nThe malicious client-side code makes additional accesses to the original domain name (such as attacker.com). These are permitted by the same-origin policy. However, when the victim's browser runs the script it makes a new DNS request for the domain, and the attacker replies with a new IP address. For instance, they could reply with an internal IP address or the IP address of a target somewhere else on the Internet.\n\n== Protection ==\nThe following techniques attempt to prevent DNS rebinding attacks:\nDNS servers in the chain can filter out private IP addresses and loopback IP addresses:\nExternal public DNS servers (e.g. OpenDNS) can implement DNS filtering.\nLocal system administrators can configure the organization's local nameserver(s) to block the resolution of external names into internal IP addresses. (This has the downside of allowing an attacker to map the internal address ranges in use.)\nA firewall (e.g. dnswall), in the gateway or in the local pc, can filter DNS replies that pass through it, discarding local addresses.\nWeb browsers can resist DNS rebinding:\nWeb browsers can implement DNS pinning: the IP address is locked to the value received in the first DNS response. This technique may block some legitimate uses of Dynamic DNS, and may not work against all attacks. However, it is important to fail-safe (stop rendering) if the IP address does change, because using an IP address past the TTL expiration can open the opposite vulnerability when the IP address has legitimately changed and the expired IP address may now be controlled by an attacker.\nThe NoScript extension for Firefox includes ABE, a firewall-like feature inside the browser which in its default configuration prevents attacks on the local network by preventing external webpages from accessing local IP addresses.\nWeb servers can reject HTTP requests with an unrecognized Host header."
    }
  },
  {
    "instruction": "Context: Social engineering (security)\n\n==Introduction==\nIn the context of information security, social engineering is the psychological manipulation of people into performing actions or divulging confidential information. A type of confidence trick for the purpose of information gathering, fraud, or system access, it differs from a traditional \"con\" in that it is often one of many steps in a more complex fraud scheme. It has also been defined as \"any act that influences a person to take an action that may or may not be in their best interests.\"An example of social engineering is an attacker calling a help desk, impersonating someone else, and claiming to have forgotten their password. If the help desk worker resets the password, it grants the attacker full access to the account.\n\n== Information security culture ==\nEmployee behaviour can have a big impact on information security in organizations. Cultural concepts can help different segments of the organization work effectively or work against effectiveness towards information security within an organization. \"Exploring the Relationship between Organizational Culture and Information Security Culture\" provides the following definition of information security culture: \"ISC is the totality of patterns of behavior in an organization that contribute to the protection of information of all kinds.\"Andersson and Reimers (2014) found that employees often do not see themselves as part of the organization Information Security \"effort\" and often take actions that ignore organizational information security best interests. Research shows Information security culture needs to be improved continuously. In \"Information Security Culture from Analysis to Change,\" authors commented that \"it's a never ending process, a cycle of evaluation and change or maintenance.\" They suggest that to manage information security culture, five steps should be taken: Pre-evaluation, strategic planning, operative planning, implementation, and post-evaluation.\nPre-Evaluation: to identify the awareness of information security within employees and to analyse current security policy.\nStrategic Planning: to come up with a better awareness-program, we need to set clear targets. Clustering people is helpful to achieve it.\nOperative Planning: set a good security culture based on internal communication, management-buy-in, and security awareness and training program.\nImplementation: four stages should be used to implement the information security culture. They are commitment of the management, communication with organizational members, courses for all organizational members, and commitment of the employees.\n\n== Techniques and terms ==\nAll social engineering techniques are based on specific attributes of human decision-making known as cognitive biases. These biases, sometimes called \"bugs in the human hardware,\u201d are exploited in various combinations to create attack techniques, some of which are listed below. The attacks used in social engineering can be used to steal employees' confidential information. The most common type of social engineering happens over the phone. Other examples of social engineering attacks are criminals posing as exterminators, fire marshals and technicians to go unnoticed as they steal company secrets.\nOne example of social engineering is an individual who walks into a building and posts an official-looking announcement to the company bulletin that says the number for the help desk has changed. So, when employees call for help the individual asks them for their passwords and IDs thereby gaining the ability to access the company's private information.\nAnother example of social engineering would be that the hacker contacts the target on a social networking site and starts a conversation with the target. Gradually the hacker gains the trust of the target and then uses that trust to get access to sensitive information like password or bank account details.Social engineering relies heavily on the six principles of influence established by Robert Cialdini. Cialdini's theory of influence is based on six key principles: reciprocity, commitment and consistency, social proof, authority, liking, scarcity.\n\n\n*** Six key principles ***\n\n\n**** Authority ****\nIn social engineering, the attacker may pose as authority to increase the likelihood of adherence from the victim.\n\n\n**** Intimidation ****\n\nAttacker (potentially disguised) informs or implies that there will be negative consequences if certain actions are not performed. Consequences could include subtle intimidation phrases such as \"I'll tell your manager\" to much worse.\n\n\n**** Consensus / Social proof ****\n\nPeople will do things that they see other people are doing. For example, in one experiment, one or more confederates would look up into the sky; bystanders would then look up into the sky to see what they were missing. At one point this experiment was aborted, as so many people were looking up that they stopped traffic. See conformity, and the Asch conformity experiments.\n\n\n**** Scarcity ****\n\nPerceived scarcity will generate demand. The common advertising phrase \"while supplies last\" capitalizes on a sense of scarcity. \n\n\n**** Urgency ****\nLinked to scarcity, attackers use urgency as a time-based psychological principle of social engineering. For example, saying offers are available for a \"limited time only\" encourages sales through a sense of urgency.\n\n\n**** Familiarity / Liking ****\n\nPeople are easily persuaded by other people whom they like. Cialdini cites the marketing of Tupperware in what might now be called viral marketing. People were more likely to buy if they liked the person selling it to them. Some of the many biases favoring more attractive people are discussed. See physical attractiveness stereotype.\n\n\n*** Four social engineering vectors ***\n\n\n**** Vishing ****\nVishing, otherwise known as \"voice phishing\", is the criminal practice of using social engineering over a telephone system to gain access to private personal and financial information from the public for the purpose of financial reward. It is also employed by attackers for reconnaissance purposes to gather more detailed intelligence on a target organization.\n\n\n**** Phishing ****\n\nPhishing is a technique of fraudulently obtaining private information. Typically, the phisher sends an e-mail that appears to come from a legitimate business\u2014a bank, or credit card company\u2014requesting \"verification\" of information and warning of some dire consequence if it is not provided. The e-mail usually contains a link to a fraudulent web page that seems legitimate\u2014with company logos and content\u2014and has a form requesting everything from a home address to an ATM card's PIN or a credit card number. For example, in 2003, there was a phishing scam in which users received emails supposedly from eBay claiming that the user's account was about to be suspended unless a link provided was clicked to update a credit card (information that the genuine eBay already had). By mimicking a legitimate organization's HTML code and logos, it is relatively simple to make a fake Website look authentic. The scam tricked some people into thinking that eBay was requiring them to update their account information by clicking on the link provided. By indiscriminately spamming extremely large groups of people, the \"phisher\" counted on gaining sensitive financial information from the small percentage (yet large number) of recipients who already have eBay accounts and also fall prey to the scam.\n\n\n**** Smishing ****\nThe act of using SMS text messaging to lure victims into a specific course of action, also known as \"smishing\". Like phishing it can be clicking on a malicious link or divulging information. Examples are text messages that claim to be from a common carrier (like FedEx) stating a package is in transit, with a link provided.\n\n\n**** Impersonation ****\nPretending or pretexting to be another person with the goal of gaining access physically to a system or building. Impersonation is used in the \"SIM swap scam\" fraud.\n\n== Other concepts ==\n\n\n*** Pretexting ***\n\nPretexting (adj. pretextual) is the act of creating and using an invented scenario (the pretext) to engage a targeted victim in a manner that increases the chance the victim will divulge information or perform actions that would be unlikely in ordinary circumstances. An elaborate lie, it most often involves some prior research or setup and the use of this information for impersonation (e.g., date of birth, Social Security number, last bill amount) to establish legitimacy in the mind of the target. As a background, pretexting can be interpreted as the first evolution of social engineering, and continued to develop as social engineering incorporated current-day technologies. Current and past examples of pretexting demonstrate this development.\nThis technique can be used to fool a business into disclosing customer information as well as by private investigators to obtain telephone records, utility records, banking records and other information directly from company service representatives. The information can then be used to establish even greater legitimacy under tougher questioning with a manager, e.g., to make account changes, get specific balances, etc.\nPretexting can also be used to impersonate co-workers, police, bank, tax authorities, clergy, insurance investigators\u2014or any other individual who could have perceived authority or right-to-know in the mind of the targeted victim. The pretexter must simply prepare answers to questions that might be asked by the victim. In some cases, all that is needed is a voice that sounds authoritative, an earnest tone, and an ability to think on one's feet to create a pretextual scenario.\n\n\n*** Vishing ***\n\nPhone phishing (or \"vishing\") uses a rogue interactive voice response (IVR) system to recreate a legitimate-sounding copy of a bank or other institution's IVR system. The victim is prompted (typically via a phishing e-mail) to call in to the \"bank\" via a (ideally toll free) number provided in order to \"verify\" information. A typical \"vishing\" system will reject log-ins continually, ensuring the victim enters PINs or passwords multiple times, often disclosing several different passwords. More advanced systems transfer the victim to the attacker/defrauder, who poses as a customer service agent or security expert for further questioning of the victim.\n\n\n*** Spear phishing ***\n\nAlthough similar to \"phishing\", spear phishing is a technique that fraudulently obtains private information by sending highly customized emails to few end users. It is the main difference between phishing attacks because phishing campaigns focus on sending out high volumes of generalized emails with the expectation that only a few people will respond. On the other hand, spear-phishing emails require the attacker to perform additional research on their targets in order to \"trick\" end users into performing requested activities. The success rate of spear-phishing attacks is considerably higher than phishing attacks with people opening roughly 3% of phishing emails when compared to roughly 70% of potential attempts. When users actually open the emails phishing emails have a relatively modest 5% success rate to have the link or attachment clicked when compared to a spear-phishing attack's 50% success rate.Spear-phishing success is heavily dependent on the amount and quality of OSINT (open-source intelligence) that the attacker can obtain. Social media account activity is one example of a source of OSINT.\n\n\n*** Water holing ***\n\nWater holing is a targeted social engineering strategy that capitalizes on the trust users have in websites they regularly visit. The victim feels safe to do things they would not do in a different situation. A wary person might, for example, purposefully avoid clicking a link in an unsolicited email, but the same person would not hesitate to follow a link on a website they often visit. So, the attacker prepares a trap for the unwary prey at a favored watering hole. This strategy has been successfully used to gain access to some (supposedly) very secure systems.The attacker may set out by identifying a group or individuals to target. The preparation involves gathering information about websites the targets often visit from the secure system. The information gathering confirms that the targets visit the websites and that the system allows such visits. The attacker then tests these websites for vulnerabilities to inject code that may infect a visitor's system with malware. The injected code trap and malware may be tailored to the specific target group and the specific systems they use. In time, one or more members of the target group will get infected and the attacker can gain access to the secure system.\n\n\n*** Baiting ***\nBaiting is like the real-world Trojan horse that uses physical media and relies on the curiosity or greed of the victim. In this attack, attackers leave malware-infected floppy disks, CD-ROMs, or USB flash drives in locations people will find them (bathrooms, elevators, sidewalks, parking lots, etc.), give them legitimate and curiosity-piquing labels, and wait for victims.\nFor example, an attacker may create a disk featuring a corporate logo, available from the target's website, and label it \"Executive Salary Summary Q2 2012\". The attacker then leaves the disk on the floor of an elevator or somewhere in the lobby of the target company. An unknowing employee may find it and insert the disk into a computer to satisfy their curiosity, or a good Samaritan may find it and return it to the company. In any case, just inserting the disk into a computer installs malware, giving attackers access to the victim's PC and, perhaps, the target company's internal computer network.\nUnless computer controls block infections, insertion compromises PCs \"auto-running\" media. Hostile devices can also be used. For instance, a \"lucky winner\" is sent a free digital audio player compromising any computer it is plugged to. A \"road apple\" (the colloquial term for horse manure, suggesting the device's undesirable nature) is any removable media with malicious software left in opportunistic or conspicuous places. It may be a CD, DVD, or USB flash drive, among other media. Curious people take it and plug it into a computer, infecting the host and any attached networks. Again, hackers may give them enticing labels, such as \"Employee Salaries\" or \"Confidential\".One study done in 2016 had researchers drop 297 USB drives around the campus of the University of Illinois. The drives contained files on them that linked to webpages owned by the researchers. The researchers were able to see how many of the drives had files on them opened, but not how many were inserted into a computer without having a file opened. Of the 297 drives that were dropped, 290 (98%) of them were picked up and 135 (45%) of them \"called home\".\n\n\n*** Quid pro quo ***\nQuid pro quo means something for something:\n\nAn attacker calls random numbers at a company, claiming to be calling back from technical support. Eventually this person will hit someone with a legitimate problem, grateful that someone is calling back to help them. The attacker will \"help\" solve the problem and, in the process, have the user type commands that give the attacker access or launch malware.\nIn a 2003 information security survey, 91% of office workers gave researchers what they claimed was their password in answer to a survey question in exchange for a cheap pen. Similar surveys in later years obtained similar results using chocolates and other cheap lures, although they made no attempt to validate the passwords.\n\n\n*** Tailgating ***\n\nAn attacker, seeking entry to a restricted area secured by unattended, electronic access control, e.g. by RFID card, simply walks in behind a person who has legitimate access. Following common courtesy, the legitimate person will usually hold the door open for the attacker or the attackers themselves may ask the employee to hold it open for them. The attacker will often purport to be on a phone call using a mobile to prevent questioning by an employee. The legitimate person may fail to ask for identification for any of several reasons, or may accept an assertion that the attacker has forgotten or lost the appropriate identity token. The attacker may also fake the action of presenting an identity token. \n\n\n*** Other types ***\nCommon confidence tricksters or fraudsters also could be considered \"social engineers\" in the wider sense, in that they deliberately deceive and manipulate people, exploiting human weaknesses to obtain personal benefit. They may, for example, use social engineering techniques as part of an IT fraud.\nAs of the early 2000s, another type of social engineering technique includes spoofing or hacking IDs of people having popular e-mail IDs such as Yahoo!, Gmail, or Hotmail. Additionally, some spoofing attempts included emails from major online service providers, like PayPal. This led to the \"proposed standard\" of Sender Policy Framework RFC 7208 dated April 2014, in combination with DMARC, as means to combat spoofing. Among the many motivations for this deception are:\n\nPhishing credit-card account numbers and their passwords.\nCracking private e-mails and chat histories, and manipulating them by using common editing techniques before using them to extort money and creating distrust among individuals.\nCracking websites of companies or organizations and destroying their reputation.\nComputer virus hoaxes\nConvincing users to run malicious code within the web browser via self-XSS attack to allow access to their web accountAnother type is to read sensitive information of unshielded or unprotected Displays and input devices, called Shoulder surfing.\n\n\n*** Countermeasures ***\nOrganizations reduce their security risks by:\nTraining to Employees: Training employees in security protocols relevant to their position. (e.g., in situations such as tailgating, if a person's identity cannot be verified, then employees must be trained to politely refuse.)\nStandard Framework: Establishing frameworks of trust on an employee/personnel level (i.e., specify and train personnel when/where/why/how sensitive information should be handled)\nScrutinizing Information: Identifying which information is sensitive and evaluating its exposure to social engineering and breakdowns in security systems (building, computer system, etc.)\nSecurity Protocols: Establishing security protocols, policies, and procedures for handling sensitive information.\nEvent Test: Performing unannounced, periodic tests of the security framework.\nInoculation: Preventing social engineering and other fraudulent tricks or traps by instilling a resistance to persuasion attempts through exposure to similar or related attempts.Review: Reviewing the above steps regularly: no solutions to information integrity are perfect.Waste Management: Using a waste management service that has dumpsters with locks on them, with keys to them limited only to the waste management company and the cleaning staff. Locating the dumpster either in view of employees so that trying to access it carries a risk of being seen or caught, or behind a locked gate or fence where the person must trespass before they can attempt to access the dumpster.\n\n== The lifecycle of social engineering ==\nInformation gathering: Information gathering is the first and foremost step of the lifecycle. It requires much patience and keenly watching habits of the victim. This step gathering data about the victim's interests, personal information. It determines the success rate of the overall attack.\nEngaging with victim: After gathering required amount of information, the attacker opens a conversation with the victim smoothly without the victim finding anything inappropriate.\nAttacking: This step generally occurs after a long period of engaging with the target and during this information from the target is retrieved by using social engineering. In phase, the attacker gets the results from the target.\nClosing interaction: This is the last step which includes slowly shutting down the communication by the attacker without arising any suspicion in the victim. In this way, the motive is fulfilled as well as the victim rarely realizes the attack even happened.\n\n== Notable social engineers ==\n\n\n*** Frank Abagnale Jr. ***\nFrank Abagnale Jr. is an American security consultant known for his background as a former con man, check forger, and impostor while he was between the ages of 15 and 21. He became one of the most notorious impostors, claiming to have assumed no fewer than eight identities, including an airline pilot, a physician, a U.S. Bureau of Prisons agent, and a lawyer. Abagnale escaped from police custody twice (once from a taxiing airliner and once from a U.S. federal penitentiary) before turning 22 years old. The popular Steven Spielberg movie Catch Me If You Can is based on his life.\n\n\n*** Kevin Mitnick ***\nKevin Mitnick is an American computer security consultant, author and hacker, best known for his high-profile 1995 arrest and later five-year conviction for various computer and communications-related crimes.\n\n\n*** Susan Headley ***\nSusan Headley was an American hacker active during the late 1970s and early 1980s widely respected for her expertise in social engineering, pretexting, and psychological subversion. She was known for her specialty in breaking into military computer systems, which often involved going to bed with military personnel and going through their clothes for usernames and passwords while they slept. She became heavily involved in phreaking with Kevin Mitnick and Lewis de Payne in Los Angeles, but later framed them for erasing the system files at US Leasing after a falling out, leading to Mitnick's first conviction. She retired to professional poker.\n\n\n*** James Linton ***\nJames Linton is a British hacker and social engineer who in 2017 used OSINT and spear phishing techniques to trick a variety of targets over email including the CEOs of Major Banks, and members of the Trump White House Administration. He then went to work in email security where he socially engineered BEC (Business Email Compromise) threat actors to collect specific threat intelligence.\n\n\n*** Mike Ridpath ***\nMike Ridpath Security consultant, published author, and speaker. Previous member of w00w00. Emphasizes techniques and tactics for social engineering cold calling. Became notable after his talks where he would play recorded calls and explain his thought process on what he was doing to get passwords through the phone and his live demonstrations. As a child Ridpath was connected with Badir Brothers and was widely known within the phreaking and hacking community for his articles with popular underground ezines, such as, Phrack, B4B0 and 9x on modifying Oki 900s, blueboxing, satellite hacking and RCMAC.\n\n\n*** Badir Brothers ***\nBrothers Ramy, Muzher, and Shadde Badir\u2014all of whom were blind from birth\u2014managed to set up an extensive phone and computer fraud scheme in Israel in the 1990s using social engineering, voice impersonation, and Braille-display computers.\n\n\n*** Christopher J. Hadnagy ***\nChristopher J. Hadnagy is an American social engineer and information technology security consultant.  He is best known as an author of 4 books on social engineering and cyber security and founder of Innocent Lives Foundation, an organization that helps tracking and identifying child trafficking using various security techniques such as seeking the assistance of information security specialists, utilizing data from open-source intelligence (OSINT) and collaborating with law enforcement.\n\n== Law ==\nIn common law, pretexting is an invasion of privacy tort of appropriation.\n\n\n*** Pretexting of telephone records ***\nIn December 2006, United States Congress approved a Senate sponsored bill making the pretexting of telephone records a federal felony with fines of up to $250,000 and ten years in prison for individuals (or fines of up to $500,000 for companies). It was signed by President George W. Bush on 12 January 2007.\n\n\n*** Federal legislation ***\nThe 1999 \"GLBA\" is a U.S. Federal law that specifically addresses pretexting of banking records as an illegal act punishable under federal statutes. When a business entity such as a private investigator, SIU insurance investigator, or an adjuster conducts any type of deception, it falls under the authority of the Federal Trade Commission (FTC). This federal agency has the obligation and authority to ensure that consumers are not subjected to any unfair or deceptive business practices. US Federal Trade Commission Act, Section 5 of the FTCA states, in part:\n\"Whenever the Commission shall have reason to believe that any such person, partnership, or corporation has been or is using any unfair method of competition or unfair or deceptive act or practice in or affecting commerce, and if it shall appear to the Commission that a proceeding by it in respect thereof would be to the interest of the public, it shall issue and serve upon such person, partnership, or corporation a complaint stating its charges in that respect.\"\nThe statute states that when someone obtains any personal, non-public information from a financial institution or the consumer, their action is subject to the statute. It relates to the consumer's relationship with the financial institution. For example, a pretexter using false pretenses either to get a consumer's address from the consumer's bank, or to get a consumer to disclose the name of their bank, would be covered. The determining principle is that pretexting only occurs when information is obtained through false pretenses.\nWhile the sale of cell telephone records has gained significant media attention, and telecommunications records are the focus of the two bills currently before the United States Senate, many other types of private records are being bought and sold in the public market. Alongside many advertisements for cell phone records, wireline records and the records associated with calling cards are advertised. As individuals shift to VoIP telephones, it is safe to assume that those records will be offered for sale as well. Currently, it is legal to sell telephone records, but illegal to obtain them.\n\n\n*** 1st Source Information Specialists ***\nU.S. Rep. Fred Upton (R-Kalamazoo, Michigan), chairman of the Energy and Commerce Subcommittee on Telecommunications and the Internet, expressed concern over the easy access to personal mobile phone records on the Internet during a House Energy & Commerce Committee hearing on \"Phone Records For Sale: Why Aren't Phone Records Safe From Pretexting?\" Illinois became the first state to sue an online records broker when Attorney General Lisa Madigan sued 1st Source Information Specialists, Inc. A spokeswoman for Madigan's office said. The Florida-based company operates several Web sites that sell mobile telephone records, according to a copy of the suit. The attorneys general of Florida and Missouri quickly followed Madigan's lead, filing suits respectively, against 1st Source Information Specialists and, in Missouri's case, one other records broker \u2013 First Data Solutions, Inc.\nSeveral wireless providers, including T-Mobile, Verizon, and Cingular filed earlier lawsuits against records brokers, with Cingular winning an injunction against First Data Solutions and 1st Source Information Specialists. U.S. Senator Charles Schumer (D-New York) introduced legislation in February 2006 aimed at curbing the practice. The Consumer Telephone Records Protection Act of 2006 would create felony criminal penalties for stealing and selling the records of mobile phone, landline, and Voice over Internet Protocol (VoIP) subscribers.\n\n\n*** Hewlett Packard ***\nPatricia Dunn, former chairwoman of Hewlett Packard, reported that the HP board hired a private investigation company to delve into who was responsible for leaks within the board. Dunn acknowledged that the company used the practice of pretexting to solicit the telephone records of board members and journalists. Chairman Dunn later apologized for this act and offered to step down from the board if it was desired by board members. Unlike Federal law, California law specifically forbids such pretexting. The four felony charges brought on Dunn were dismissed.\n\n== Preventive measures ==\nTaking some precautions reduces the risk of being a victim of social engineering frauds. The precautions that can be made are as follows:\n\nBe aware of offers that seem  \"Too good to be true\".\nUse multifactor authentication.\nAvoid clicking on attachments from unknown sources.\nNot giving out personal or financial information (such as credit card information, Social Security Numbers, or bank account information) to anyone via email, phone, or text messages.\nUse of spam filter software.\nAvoid befriending people that you do not know in real life.\nTeach kids to contact a trusted adult in case they are being bullied over the internet (cyberbullying) or feel threatened by anything online.\nDon't make instant decisions, but when possible take 5 minutes to evaluate the information presented.\nAnswer this question: Why is pretexting considered an invasion of privacy tort of appropriation in common law?",
    "context": "",
    "output": "Pretexting is considered an invasion of privacy tort of appropriation in common law because it involves using false pretenses to obtain personal, non-public information from a financial institution or the consumer, which then falls under the authority of the Federal Trade Commission (FTC).",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Why is pretexting considered an invasion of privacy tort of appropriation in common law?",
      "answer": "Pretexting is considered an invasion of privacy tort of appropriation in common law because it involves using false pretenses to obtain personal, non-public information from a financial institution or the consumer, which then falls under the authority of the Federal Trade Commission (FTC).",
      "context": "Social engineering (security)\n\n==Introduction==\nIn the context of information security, social engineering is the psychological manipulation of people into performing actions or divulging confidential information. A type of confidence trick for the purpose of information gathering, fraud, or system access, it differs from a traditional \"con\" in that it is often one of many steps in a more complex fraud scheme. It has also been defined as \"any act that influences a person to take an action that may or may not be in their best interests.\"An example of social engineering is an attacker calling a help desk, impersonating someone else, and claiming to have forgotten their password. If the help desk worker resets the password, it grants the attacker full access to the account.\n\n== Information security culture ==\nEmployee behaviour can have a big impact on information security in organizations. Cultural concepts can help different segments of the organization work effectively or work against effectiveness towards information security within an organization. \"Exploring the Relationship between Organizational Culture and Information Security Culture\" provides the following definition of information security culture: \"ISC is the totality of patterns of behavior in an organization that contribute to the protection of information of all kinds.\"Andersson and Reimers (2014) found that employees often do not see themselves as part of the organization Information Security \"effort\" and often take actions that ignore organizational information security best interests. Research shows Information security culture needs to be improved continuously. In \"Information Security Culture from Analysis to Change,\" authors commented that \"it's a never ending process, a cycle of evaluation and change or maintenance.\" They suggest that to manage information security culture, five steps should be taken: Pre-evaluation, strategic planning, operative planning, implementation, and post-evaluation.\nPre-Evaluation: to identify the awareness of information security within employees and to analyse current security policy.\nStrategic Planning: to come up with a better awareness-program, we need to set clear targets. Clustering people is helpful to achieve it.\nOperative Planning: set a good security culture based on internal communication, management-buy-in, and security awareness and training program.\nImplementation: four stages should be used to implement the information security culture. They are commitment of the management, communication with organizational members, courses for all organizational members, and commitment of the employees.\n\n== Techniques and terms ==\nAll social engineering techniques are based on specific attributes of human decision-making known as cognitive biases. These biases, sometimes called \"bugs in the human hardware,\u201d are exploited in various combinations to create attack techniques, some of which are listed below. The attacks used in social engineering can be used to steal employees' confidential information. The most common type of social engineering happens over the phone. Other examples of social engineering attacks are criminals posing as exterminators, fire marshals and technicians to go unnoticed as they steal company secrets.\nOne example of social engineering is an individual who walks into a building and posts an official-looking announcement to the company bulletin that says the number for the help desk has changed. So, when employees call for help the individual asks them for their passwords and IDs thereby gaining the ability to access the company's private information.\nAnother example of social engineering would be that the hacker contacts the target on a social networking site and starts a conversation with the target. Gradually the hacker gains the trust of the target and then uses that trust to get access to sensitive information like password or bank account details.Social engineering relies heavily on the six principles of influence established by Robert Cialdini. Cialdini's theory of influence is based on six key principles: reciprocity, commitment and consistency, social proof, authority, liking, scarcity.\n\n\n*** Six key principles ***\n\n\n**** Authority ****\nIn social engineering, the attacker may pose as authority to increase the likelihood of adherence from the victim.\n\n\n**** Intimidation ****\n\nAttacker (potentially disguised) informs or implies that there will be negative consequences if certain actions are not performed. Consequences could include subtle intimidation phrases such as \"I'll tell your manager\" to much worse.\n\n\n**** Consensus / Social proof ****\n\nPeople will do things that they see other people are doing. For example, in one experiment, one or more confederates would look up into the sky; bystanders would then look up into the sky to see what they were missing. At one point this experiment was aborted, as so many people were looking up that they stopped traffic. See conformity, and the Asch conformity experiments.\n\n\n**** Scarcity ****\n\nPerceived scarcity will generate demand. The common advertising phrase \"while supplies last\" capitalizes on a sense of scarcity. \n\n\n**** Urgency ****\nLinked to scarcity, attackers use urgency as a time-based psychological principle of social engineering. For example, saying offers are available for a \"limited time only\" encourages sales through a sense of urgency.\n\n\n**** Familiarity / Liking ****\n\nPeople are easily persuaded by other people whom they like. Cialdini cites the marketing of Tupperware in what might now be called viral marketing. People were more likely to buy if they liked the person selling it to them. Some of the many biases favoring more attractive people are discussed. See physical attractiveness stereotype.\n\n\n*** Four social engineering vectors ***\n\n\n**** Vishing ****\nVishing, otherwise known as \"voice phishing\", is the criminal practice of using social engineering over a telephone system to gain access to private personal and financial information from the public for the purpose of financial reward. It is also employed by attackers for reconnaissance purposes to gather more detailed intelligence on a target organization.\n\n\n**** Phishing ****\n\nPhishing is a technique of fraudulently obtaining private information. Typically, the phisher sends an e-mail that appears to come from a legitimate business\u2014a bank, or credit card company\u2014requesting \"verification\" of information and warning of some dire consequence if it is not provided. The e-mail usually contains a link to a fraudulent web page that seems legitimate\u2014with company logos and content\u2014and has a form requesting everything from a home address to an ATM card's PIN or a credit card number. For example, in 2003, there was a phishing scam in which users received emails supposedly from eBay claiming that the user's account was about to be suspended unless a link provided was clicked to update a credit card (information that the genuine eBay already had). By mimicking a legitimate organization's HTML code and logos, it is relatively simple to make a fake Website look authentic. The scam tricked some people into thinking that eBay was requiring them to update their account information by clicking on the link provided. By indiscriminately spamming extremely large groups of people, the \"phisher\" counted on gaining sensitive financial information from the small percentage (yet large number) of recipients who already have eBay accounts and also fall prey to the scam.\n\n\n**** Smishing ****\nThe act of using SMS text messaging to lure victims into a specific course of action, also known as \"smishing\". Like phishing it can be clicking on a malicious link or divulging information. Examples are text messages that claim to be from a common carrier (like FedEx) stating a package is in transit, with a link provided.\n\n\n**** Impersonation ****\nPretending or pretexting to be another person with the goal of gaining access physically to a system or building. Impersonation is used in the \"SIM swap scam\" fraud.\n\n== Other concepts ==\n\n\n*** Pretexting ***\n\nPretexting (adj. pretextual) is the act of creating and using an invented scenario (the pretext) to engage a targeted victim in a manner that increases the chance the victim will divulge information or perform actions that would be unlikely in ordinary circumstances. An elaborate lie, it most often involves some prior research or setup and the use of this information for impersonation (e.g., date of birth, Social Security number, last bill amount) to establish legitimacy in the mind of the target. As a background, pretexting can be interpreted as the first evolution of social engineering, and continued to develop as social engineering incorporated current-day technologies. Current and past examples of pretexting demonstrate this development.\nThis technique can be used to fool a business into disclosing customer information as well as by private investigators to obtain telephone records, utility records, banking records and other information directly from company service representatives. The information can then be used to establish even greater legitimacy under tougher questioning with a manager, e.g., to make account changes, get specific balances, etc.\nPretexting can also be used to impersonate co-workers, police, bank, tax authorities, clergy, insurance investigators\u2014or any other individual who could have perceived authority or right-to-know in the mind of the targeted victim. The pretexter must simply prepare answers to questions that might be asked by the victim. In some cases, all that is needed is a voice that sounds authoritative, an earnest tone, and an ability to think on one's feet to create a pretextual scenario.\n\n\n*** Vishing ***\n\nPhone phishing (or \"vishing\") uses a rogue interactive voice response (IVR) system to recreate a legitimate-sounding copy of a bank or other institution's IVR system. The victim is prompted (typically via a phishing e-mail) to call in to the \"bank\" via a (ideally toll free) number provided in order to \"verify\" information. A typical \"vishing\" system will reject log-ins continually, ensuring the victim enters PINs or passwords multiple times, often disclosing several different passwords. More advanced systems transfer the victim to the attacker/defrauder, who poses as a customer service agent or security expert for further questioning of the victim.\n\n\n*** Spear phishing ***\n\nAlthough similar to \"phishing\", spear phishing is a technique that fraudulently obtains private information by sending highly customized emails to few end users. It is the main difference between phishing attacks because phishing campaigns focus on sending out high volumes of generalized emails with the expectation that only a few people will respond. On the other hand, spear-phishing emails require the attacker to perform additional research on their targets in order to \"trick\" end users into performing requested activities. The success rate of spear-phishing attacks is considerably higher than phishing attacks with people opening roughly 3% of phishing emails when compared to roughly 70% of potential attempts. When users actually open the emails phishing emails have a relatively modest 5% success rate to have the link or attachment clicked when compared to a spear-phishing attack's 50% success rate.Spear-phishing success is heavily dependent on the amount and quality of OSINT (open-source intelligence) that the attacker can obtain. Social media account activity is one example of a source of OSINT.\n\n\n*** Water holing ***\n\nWater holing is a targeted social engineering strategy that capitalizes on the trust users have in websites they regularly visit. The victim feels safe to do things they would not do in a different situation. A wary person might, for example, purposefully avoid clicking a link in an unsolicited email, but the same person would not hesitate to follow a link on a website they often visit. So, the attacker prepares a trap for the unwary prey at a favored watering hole. This strategy has been successfully used to gain access to some (supposedly) very secure systems.The attacker may set out by identifying a group or individuals to target. The preparation involves gathering information about websites the targets often visit from the secure system. The information gathering confirms that the targets visit the websites and that the system allows such visits. The attacker then tests these websites for vulnerabilities to inject code that may infect a visitor's system with malware. The injected code trap and malware may be tailored to the specific target group and the specific systems they use. In time, one or more members of the target group will get infected and the attacker can gain access to the secure system.\n\n\n*** Baiting ***\nBaiting is like the real-world Trojan horse that uses physical media and relies on the curiosity or greed of the victim. In this attack, attackers leave malware-infected floppy disks, CD-ROMs, or USB flash drives in locations people will find them (bathrooms, elevators, sidewalks, parking lots, etc.), give them legitimate and curiosity-piquing labels, and wait for victims.\nFor example, an attacker may create a disk featuring a corporate logo, available from the target's website, and label it \"Executive Salary Summary Q2 2012\". The attacker then leaves the disk on the floor of an elevator or somewhere in the lobby of the target company. An unknowing employee may find it and insert the disk into a computer to satisfy their curiosity, or a good Samaritan may find it and return it to the company. In any case, just inserting the disk into a computer installs malware, giving attackers access to the victim's PC and, perhaps, the target company's internal computer network.\nUnless computer controls block infections, insertion compromises PCs \"auto-running\" media. Hostile devices can also be used. For instance, a \"lucky winner\" is sent a free digital audio player compromising any computer it is plugged to. A \"road apple\" (the colloquial term for horse manure, suggesting the device's undesirable nature) is any removable media with malicious software left in opportunistic or conspicuous places. It may be a CD, DVD, or USB flash drive, among other media. Curious people take it and plug it into a computer, infecting the host and any attached networks. Again, hackers may give them enticing labels, such as \"Employee Salaries\" or \"Confidential\".One study done in 2016 had researchers drop 297 USB drives around the campus of the University of Illinois. The drives contained files on them that linked to webpages owned by the researchers. The researchers were able to see how many of the drives had files on them opened, but not how many were inserted into a computer without having a file opened. Of the 297 drives that were dropped, 290 (98%) of them were picked up and 135 (45%) of them \"called home\".\n\n\n*** Quid pro quo ***\nQuid pro quo means something for something:\n\nAn attacker calls random numbers at a company, claiming to be calling back from technical support. Eventually this person will hit someone with a legitimate problem, grateful that someone is calling back to help them. The attacker will \"help\" solve the problem and, in the process, have the user type commands that give the attacker access or launch malware.\nIn a 2003 information security survey, 91% of office workers gave researchers what they claimed was their password in answer to a survey question in exchange for a cheap pen. Similar surveys in later years obtained similar results using chocolates and other cheap lures, although they made no attempt to validate the passwords.\n\n\n*** Tailgating ***\n\nAn attacker, seeking entry to a restricted area secured by unattended, electronic access control, e.g. by RFID card, simply walks in behind a person who has legitimate access. Following common courtesy, the legitimate person will usually hold the door open for the attacker or the attackers themselves may ask the employee to hold it open for them. The attacker will often purport to be on a phone call using a mobile to prevent questioning by an employee. The legitimate person may fail to ask for identification for any of several reasons, or may accept an assertion that the attacker has forgotten or lost the appropriate identity token. The attacker may also fake the action of presenting an identity token. \n\n\n*** Other types ***\nCommon confidence tricksters or fraudsters also could be considered \"social engineers\" in the wider sense, in that they deliberately deceive and manipulate people, exploiting human weaknesses to obtain personal benefit. They may, for example, use social engineering techniques as part of an IT fraud.\nAs of the early 2000s, another type of social engineering technique includes spoofing or hacking IDs of people having popular e-mail IDs such as Yahoo!, Gmail, or Hotmail. Additionally, some spoofing attempts included emails from major online service providers, like PayPal. This led to the \"proposed standard\" of Sender Policy Framework RFC 7208 dated April 2014, in combination with DMARC, as means to combat spoofing. Among the many motivations for this deception are:\n\nPhishing credit-card account numbers and their passwords.\nCracking private e-mails and chat histories, and manipulating them by using common editing techniques before using them to extort money and creating distrust among individuals.\nCracking websites of companies or organizations and destroying their reputation.\nComputer virus hoaxes\nConvincing users to run malicious code within the web browser via self-XSS attack to allow access to their web accountAnother type is to read sensitive information of unshielded or unprotected Displays and input devices, called Shoulder surfing.\n\n\n*** Countermeasures ***\nOrganizations reduce their security risks by:\nTraining to Employees: Training employees in security protocols relevant to their position. (e.g., in situations such as tailgating, if a person's identity cannot be verified, then employees must be trained to politely refuse.)\nStandard Framework: Establishing frameworks of trust on an employee/personnel level (i.e., specify and train personnel when/where/why/how sensitive information should be handled)\nScrutinizing Information: Identifying which information is sensitive and evaluating its exposure to social engineering and breakdowns in security systems (building, computer system, etc.)\nSecurity Protocols: Establishing security protocols, policies, and procedures for handling sensitive information.\nEvent Test: Performing unannounced, periodic tests of the security framework.\nInoculation: Preventing social engineering and other fraudulent tricks or traps by instilling a resistance to persuasion attempts through exposure to similar or related attempts.Review: Reviewing the above steps regularly: no solutions to information integrity are perfect.Waste Management: Using a waste management service that has dumpsters with locks on them, with keys to them limited only to the waste management company and the cleaning staff. Locating the dumpster either in view of employees so that trying to access it carries a risk of being seen or caught, or behind a locked gate or fence where the person must trespass before they can attempt to access the dumpster.\n\n== The lifecycle of social engineering ==\nInformation gathering: Information gathering is the first and foremost step of the lifecycle. It requires much patience and keenly watching habits of the victim. This step gathering data about the victim's interests, personal information. It determines the success rate of the overall attack.\nEngaging with victim: After gathering required amount of information, the attacker opens a conversation with the victim smoothly without the victim finding anything inappropriate.\nAttacking: This step generally occurs after a long period of engaging with the target and during this information from the target is retrieved by using social engineering. In phase, the attacker gets the results from the target.\nClosing interaction: This is the last step which includes slowly shutting down the communication by the attacker without arising any suspicion in the victim. In this way, the motive is fulfilled as well as the victim rarely realizes the attack even happened.\n\n== Notable social engineers ==\n\n\n*** Frank Abagnale Jr. ***\nFrank Abagnale Jr. is an American security consultant known for his background as a former con man, check forger, and impostor while he was between the ages of 15 and 21. He became one of the most notorious impostors, claiming to have assumed no fewer than eight identities, including an airline pilot, a physician, a U.S. Bureau of Prisons agent, and a lawyer. Abagnale escaped from police custody twice (once from a taxiing airliner and once from a U.S. federal penitentiary) before turning 22 years old. The popular Steven Spielberg movie Catch Me If You Can is based on his life.\n\n\n*** Kevin Mitnick ***\nKevin Mitnick is an American computer security consultant, author and hacker, best known for his high-profile 1995 arrest and later five-year conviction for various computer and communications-related crimes.\n\n\n*** Susan Headley ***\nSusan Headley was an American hacker active during the late 1970s and early 1980s widely respected for her expertise in social engineering, pretexting, and psychological subversion. She was known for her specialty in breaking into military computer systems, which often involved going to bed with military personnel and going through their clothes for usernames and passwords while they slept. She became heavily involved in phreaking with Kevin Mitnick and Lewis de Payne in Los Angeles, but later framed them for erasing the system files at US Leasing after a falling out, leading to Mitnick's first conviction. She retired to professional poker.\n\n\n*** James Linton ***\nJames Linton is a British hacker and social engineer who in 2017 used OSINT and spear phishing techniques to trick a variety of targets over email including the CEOs of Major Banks, and members of the Trump White House Administration. He then went to work in email security where he socially engineered BEC (Business Email Compromise) threat actors to collect specific threat intelligence.\n\n\n*** Mike Ridpath ***\nMike Ridpath Security consultant, published author, and speaker. Previous member of w00w00. Emphasizes techniques and tactics for social engineering cold calling. Became notable after his talks where he would play recorded calls and explain his thought process on what he was doing to get passwords through the phone and his live demonstrations. As a child Ridpath was connected with Badir Brothers and was widely known within the phreaking and hacking community for his articles with popular underground ezines, such as, Phrack, B4B0 and 9x on modifying Oki 900s, blueboxing, satellite hacking and RCMAC.\n\n\n*** Badir Brothers ***\nBrothers Ramy, Muzher, and Shadde Badir\u2014all of whom were blind from birth\u2014managed to set up an extensive phone and computer fraud scheme in Israel in the 1990s using social engineering, voice impersonation, and Braille-display computers.\n\n\n*** Christopher J. Hadnagy ***\nChristopher J. Hadnagy is an American social engineer and information technology security consultant.  He is best known as an author of 4 books on social engineering and cyber security and founder of Innocent Lives Foundation, an organization that helps tracking and identifying child trafficking using various security techniques such as seeking the assistance of information security specialists, utilizing data from open-source intelligence (OSINT) and collaborating with law enforcement.\n\n== Law ==\nIn common law, pretexting is an invasion of privacy tort of appropriation.\n\n\n*** Pretexting of telephone records ***\nIn December 2006, United States Congress approved a Senate sponsored bill making the pretexting of telephone records a federal felony with fines of up to $250,000 and ten years in prison for individuals (or fines of up to $500,000 for companies). It was signed by President George W. Bush on 12 January 2007.\n\n\n*** Federal legislation ***\nThe 1999 \"GLBA\" is a U.S. Federal law that specifically addresses pretexting of banking records as an illegal act punishable under federal statutes. When a business entity such as a private investigator, SIU insurance investigator, or an adjuster conducts any type of deception, it falls under the authority of the Federal Trade Commission (FTC). This federal agency has the obligation and authority to ensure that consumers are not subjected to any unfair or deceptive business practices. US Federal Trade Commission Act, Section 5 of the FTCA states, in part:\n\"Whenever the Commission shall have reason to believe that any such person, partnership, or corporation has been or is using any unfair method of competition or unfair or deceptive act or practice in or affecting commerce, and if it shall appear to the Commission that a proceeding by it in respect thereof would be to the interest of the public, it shall issue and serve upon such person, partnership, or corporation a complaint stating its charges in that respect.\"\nThe statute states that when someone obtains any personal, non-public information from a financial institution or the consumer, their action is subject to the statute. It relates to the consumer's relationship with the financial institution. For example, a pretexter using false pretenses either to get a consumer's address from the consumer's bank, or to get a consumer to disclose the name of their bank, would be covered. The determining principle is that pretexting only occurs when information is obtained through false pretenses.\nWhile the sale of cell telephone records has gained significant media attention, and telecommunications records are the focus of the two bills currently before the United States Senate, many other types of private records are being bought and sold in the public market. Alongside many advertisements for cell phone records, wireline records and the records associated with calling cards are advertised. As individuals shift to VoIP telephones, it is safe to assume that those records will be offered for sale as well. Currently, it is legal to sell telephone records, but illegal to obtain them.\n\n\n*** 1st Source Information Specialists ***\nU.S. Rep. Fred Upton (R-Kalamazoo, Michigan), chairman of the Energy and Commerce Subcommittee on Telecommunications and the Internet, expressed concern over the easy access to personal mobile phone records on the Internet during a House Energy & Commerce Committee hearing on \"Phone Records For Sale: Why Aren't Phone Records Safe From Pretexting?\" Illinois became the first state to sue an online records broker when Attorney General Lisa Madigan sued 1st Source Information Specialists, Inc. A spokeswoman for Madigan's office said. The Florida-based company operates several Web sites that sell mobile telephone records, according to a copy of the suit. The attorneys general of Florida and Missouri quickly followed Madigan's lead, filing suits respectively, against 1st Source Information Specialists and, in Missouri's case, one other records broker \u2013 First Data Solutions, Inc.\nSeveral wireless providers, including T-Mobile, Verizon, and Cingular filed earlier lawsuits against records brokers, with Cingular winning an injunction against First Data Solutions and 1st Source Information Specialists. U.S. Senator Charles Schumer (D-New York) introduced legislation in February 2006 aimed at curbing the practice. The Consumer Telephone Records Protection Act of 2006 would create felony criminal penalties for stealing and selling the records of mobile phone, landline, and Voice over Internet Protocol (VoIP) subscribers.\n\n\n*** Hewlett Packard ***\nPatricia Dunn, former chairwoman of Hewlett Packard, reported that the HP board hired a private investigation company to delve into who was responsible for leaks within the board. Dunn acknowledged that the company used the practice of pretexting to solicit the telephone records of board members and journalists. Chairman Dunn later apologized for this act and offered to step down from the board if it was desired by board members. Unlike Federal law, California law specifically forbids such pretexting. The four felony charges brought on Dunn were dismissed.\n\n== Preventive measures ==\nTaking some precautions reduces the risk of being a victim of social engineering frauds. The precautions that can be made are as follows:\n\nBe aware of offers that seem  \"Too good to be true\".\nUse multifactor authentication.\nAvoid clicking on attachments from unknown sources.\nNot giving out personal or financial information (such as credit card information, Social Security Numbers, or bank account information) to anyone via email, phone, or text messages.\nUse of spam filter software.\nAvoid befriending people that you do not know in real life.\nTeach kids to contact a trusted adult in case they are being bullied over the internet (cyberbullying) or feel threatened by anything online.\nDon't make instant decisions, but when possible take 5 minutes to evaluate the information presented."
    }
  },
  {
    "instruction": "Context: Common Criteria Testing Laboratory\n\n==Introduction==\nThe Common Criteria model provides for the separation of the roles of evaluator and certifier. Product certificates are awarded by national schemes on the basis of evaluations carried by independent testing laboratories.\nA Common Criteria testing laboratory is a third-party commercial security testing facility that is accredited to conduct security evaluations for conformance to the Common Criteria international standard.  Such facility must be accredited according to ISO/IEC 17025 with its national certification body.\n\n\n\n== Examples ==\nList of laboratory designations by country:\n\nIn the US they are called Common Criteria Testing Laboratory (CCTL)\nIn Canada they are called Common Criteria Evaluation Facility (CCEF)\nIn the UK they are called Commercial Evaluation Facilities (CLEF)\nIn France they are called Centres d\u2019Evaluation de la S\u00e9curit\u00e9 des Technologies de l\u2019Information (CESTI)\nIn Germany they are called IT Security Evaluation Facility (ITSEF)\n\n== Common Criteria Recognition Arrangement ==\nCommon Criteria Recognition Arrangement (CCRA) or Common Criteria Mutual Recognition Arrangement (MRA) \n is an international agreement that recognizes evaluations against the Common Criteria standard performed in all participating countries. \n\nIt is mutually understood that, in respect of IT products and protection profiles, the Participants plan to recognise the Common Criteria certificates which have been authorised by any other certificate authorising Participant in accordance with the terms of this Arrangement and in accordance with the applicable laws and regulations of each Participant.\nThere are some limitations to this agreement and, in the past, only evaluations up to EAL4+ were recognized. With on-going transition away from EAL levels and the introduction of NDPP evaluations that \u201cmap\u201d to up to EAL4 assurance components continue to be recognized.\n\n== United States ==\nIn the United States the National Institute of Standards and Technology (NIST) National Voluntary Laboratory Accreditation Program (NVLAP) accredits CCTLs to meet National Information Assurance Partnership (NIAP) Common Criteria Evaluation and Validation Scheme requirements and conduct IT security evaluations for conformance to the Common Criteria.\n\n\n*** CCTL requirements ***\nThese laboratories must meet the following requirements:\n\nNIST Handbook 150, NVLAP Procedures and General Requirements\nNIST Handbook 150-20, NVLAP Information Technology Security Testing \u2014 Common Criteria\nNIAP specific criteria for IT security evaluations and other NIAP defined requirementsCCTLs enter into contractual agreements with sponsors to conduct security evaluations of IT products and Protection Profiles which use the CCEVS, other NIAP approved test methods derived from the Common Criteria, Common Methodology and other technology based sources. CCTLs must observe the highest standards of impartiality, integrity and commercial confidentiality. CCTLs must operate within the guidelines established by the CCEVS.\nTo become a CCTL, a testing laboratory must go through a series of steps that involve both the NIAP Validation Body and NVLAP. NVLAP accreditation is the primary requirement for achieving CCTL status. Some scheme requirements that cannot be satisfied by NVLAP accreditation are addressed by the NIAP Validation Body. At present, there are only three scheme-specific requirements imposed by the Validation Body. \nNIAP approved CCTLs must agree to the following:\n\nLocated in the U.S. and be a legal entity, duly organized and incorporated, validly existing and in good standing under the laws of the state where the laboratory intends to do business\nAccept U.S. Government technical oversight and validation of evaluation-related activities in accordance with the policies and procedures established by the CCEVS\nAccept U.S. Government participants in selected Common Criteria evaluations.\n\n\n*** CCTL accreditation ***\nA testing laboratory becomes a CCTL when the laboratory is approved by the NIAP Validation Body and is listed on the Approved Laboratories List.\nTo avoid unnecessary expense and delay in becoming a NIAP-approved testing laboratory, it is strongly recommended that prospective CCTLs ensure that they are able to satisfy the scheme-specific requirements prior to seeking accreditation from NVLAP. This can be accomplished by sending a letter of intent to the NIAP prior to entering the NVLAP process.\nAdditional laboratory-related information can be found in CCEVS publications:\n\n#1 Common Criteria Evaluation and Validation Scheme for Information Technology Security \u2014 Organization, Management, and Concept of Operations and Scheme Publication\n#4 Common Criteria Evaluation and Validation Scheme for Information Technology Security \u2014 Guidance to Common Criteria Testing Laboratories\n\n== Canada ==\nIn Canada the Communications Security Establishment Canada (CSEC) Canadian Common Criteria Scheme (CCCS) oversees Common Criteria Evaluation Facilities (CCEF). Accreditation is performed by Standards Council of Canada (SCC) under its Program for the Accreditation of Laboratories \u2013 Canada (PALCAN) according to CAN-P-1591, the SCC\u2019s adaptation of ISO/IEC 17025-2005 for ITSET Laboratories. Approval is performed by the CCS Certification Body, a body within the CSEC, and is the verification of the applicant's ability to perform competent Common Criteria evaluations.\nAnswer this question: What is the role of the Standards Council of Canada (SCC) in Canada?",
    "context": "",
    "output": "The SCC is responsible for accrediting CCEFs in Canada under its Program for the Accreditation of Laboratories \u2013 Canada (PALCAN) according to CAN-P-1591, the SCC\u2019s adaptation of ISO/IEC 17025-2005 for ITSET Laboratories. This accreditation ensures that CCEFs have the competence to perform Common Criteria evaluations.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of the Standards Council of Canada (SCC) in Canada?",
      "answer": "The SCC is responsible for accrediting CCEFs in Canada under its Program for the Accreditation of Laboratories \u2013 Canada (PALCAN) according to CAN-P-1591, the SCC\u2019s adaptation of ISO/IEC 17025-2005 for ITSET Laboratories. This accreditation ensures that CCEFs have the competence to perform Common Criteria evaluations.",
      "context": "Common Criteria Testing Laboratory\n\n==Introduction==\nThe Common Criteria model provides for the separation of the roles of evaluator and certifier. Product certificates are awarded by national schemes on the basis of evaluations carried by independent testing laboratories.\nA Common Criteria testing laboratory is a third-party commercial security testing facility that is accredited to conduct security evaluations for conformance to the Common Criteria international standard.  Such facility must be accredited according to ISO/IEC 17025 with its national certification body.\n\n\n\n== Examples ==\nList of laboratory designations by country:\n\nIn the US they are called Common Criteria Testing Laboratory (CCTL)\nIn Canada they are called Common Criteria Evaluation Facility (CCEF)\nIn the UK they are called Commercial Evaluation Facilities (CLEF)\nIn France they are called Centres d\u2019Evaluation de la S\u00e9curit\u00e9 des Technologies de l\u2019Information (CESTI)\nIn Germany they are called IT Security Evaluation Facility (ITSEF)\n\n== Common Criteria Recognition Arrangement ==\nCommon Criteria Recognition Arrangement (CCRA) or Common Criteria Mutual Recognition Arrangement (MRA) \n is an international agreement that recognizes evaluations against the Common Criteria standard performed in all participating countries. \n\nIt is mutually understood that, in respect of IT products and protection profiles, the Participants plan to recognise the Common Criteria certificates which have been authorised by any other certificate authorising Participant in accordance with the terms of this Arrangement and in accordance with the applicable laws and regulations of each Participant.\nThere are some limitations to this agreement and, in the past, only evaluations up to EAL4+ were recognized. With on-going transition away from EAL levels and the introduction of NDPP evaluations that \u201cmap\u201d to up to EAL4 assurance components continue to be recognized.\n\n== United States ==\nIn the United States the National Institute of Standards and Technology (NIST) National Voluntary Laboratory Accreditation Program (NVLAP) accredits CCTLs to meet National Information Assurance Partnership (NIAP) Common Criteria Evaluation and Validation Scheme requirements and conduct IT security evaluations for conformance to the Common Criteria.\n\n\n*** CCTL requirements ***\nThese laboratories must meet the following requirements:\n\nNIST Handbook 150, NVLAP Procedures and General Requirements\nNIST Handbook 150-20, NVLAP Information Technology Security Testing \u2014 Common Criteria\nNIAP specific criteria for IT security evaluations and other NIAP defined requirementsCCTLs enter into contractual agreements with sponsors to conduct security evaluations of IT products and Protection Profiles which use the CCEVS, other NIAP approved test methods derived from the Common Criteria, Common Methodology and other technology based sources. CCTLs must observe the highest standards of impartiality, integrity and commercial confidentiality. CCTLs must operate within the guidelines established by the CCEVS.\nTo become a CCTL, a testing laboratory must go through a series of steps that involve both the NIAP Validation Body and NVLAP. NVLAP accreditation is the primary requirement for achieving CCTL status. Some scheme requirements that cannot be satisfied by NVLAP accreditation are addressed by the NIAP Validation Body. At present, there are only three scheme-specific requirements imposed by the Validation Body. \nNIAP approved CCTLs must agree to the following:\n\nLocated in the U.S. and be a legal entity, duly organized and incorporated, validly existing and in good standing under the laws of the state where the laboratory intends to do business\nAccept U.S. Government technical oversight and validation of evaluation-related activities in accordance with the policies and procedures established by the CCEVS\nAccept U.S. Government participants in selected Common Criteria evaluations.\n\n\n*** CCTL accreditation ***\nA testing laboratory becomes a CCTL when the laboratory is approved by the NIAP Validation Body and is listed on the Approved Laboratories List.\nTo avoid unnecessary expense and delay in becoming a NIAP-approved testing laboratory, it is strongly recommended that prospective CCTLs ensure that they are able to satisfy the scheme-specific requirements prior to seeking accreditation from NVLAP. This can be accomplished by sending a letter of intent to the NIAP prior to entering the NVLAP process.\nAdditional laboratory-related information can be found in CCEVS publications:\n\n#1 Common Criteria Evaluation and Validation Scheme for Information Technology Security \u2014 Organization, Management, and Concept of Operations and Scheme Publication\n#4 Common Criteria Evaluation and Validation Scheme for Information Technology Security \u2014 Guidance to Common Criteria Testing Laboratories\n\n== Canada ==\nIn Canada the Communications Security Establishment Canada (CSEC) Canadian Common Criteria Scheme (CCCS) oversees Common Criteria Evaluation Facilities (CCEF). Accreditation is performed by Standards Council of Canada (SCC) under its Program for the Accreditation of Laboratories \u2013 Canada (PALCAN) according to CAN-P-1591, the SCC\u2019s adaptation of ISO/IEC 17025-2005 for ITSET Laboratories. Approval is performed by the CCS Certification Body, a body within the CSEC, and is the verification of the applicant's ability to perform competent Common Criteria evaluations."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are some examples of CAATTs data extraction and analysis software?",
    "context": "",
    "output": "Examples of CAATTs data extraction and analysis software include data analysis and extraction tools, spreadsheets such as Excel, databases such as Access, statistical analysis software such as SAS, generalized audit software such as ACL, Arbutus, and EAS, and business intelligence software such as Crystal Reports and Business Objects.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are some examples of CAATTs data extraction and analysis software?",
      "answer": "Examples of CAATTs data extraction and analysis software include data analysis and extraction tools, spreadsheets such as Excel, databases such as Access, statistical analysis software such as SAS, generalized audit software such as ACL, Arbutus, and EAS, and business intelligence software such as Crystal Reports and Business Objects."
    }
  },
  {
    "instruction": "OpenSSL\n\n==Introduction==\nOpenSSL is a software library for applications that provide secure communications over computer networks against eavesdropping, and identify the party at the other end. It is widely used by Internet servers, including the majority of HTTPS websites.\nOpenSSL contains an open-source implementation of the SSL and TLS protocols.  The core library, written in the C programming language, implements basic cryptographic functions and provides various utility functions. Wrappers allowing the use of the OpenSSL library in a variety of computer languages are available.\nThe OpenSSL Software Foundation (OSF) represents the OpenSSL project in most legal capacities including contributor license agreements, managing donations, and so on. OpenSSL Software Services (OSS) also represents the OpenSSL project for support contracts.\nOpenSSL is available for most Unix-like operating systems (including Linux, macOS, and BSD), Microsoft Windows and OpenVMS.\n\n\n\n== Project history ==\nThe OpenSSL project was founded in 1998 to provide a free set of encryption tools for the code used on the Internet. It is based on a fork of SSLeay by Eric Andrew Young and Tim Hudson, which unofficially ended development on December 17, 1998, when Young and Hudson both went to work for RSA Security.  The initial founding members were Mark Cox, Ralf Engelschall, Stephen Henson, Ben Laurie, and Paul Sutton.As of May 2019, the OpenSSL management committee consisted of seven people and there are seventeen developers with commit access (many of whom are also part of the OpenSSL management committee). There are only two full-time employees (fellows) and the remainder are volunteers.\nThe project has a budget of less than $1 million USD per year and relies primarily on donations. Development of TLS 1.3 was sponsored by Akamai.\n\n== Major version releases ==\n\n== Algorithms ==\nOpenSSL supports a number of different cryptographic algorithms:\n\nCiphers\n\nAES, Blowfish, Camellia, Chacha20, Poly1305,  SEED, CAST-128, DES, IDEA, RC2, RC4, RC5, Triple DES, GOST 28147-89, SM4\nCryptographic hash functions\n\nMD5, MD4, MD2, SHA-1, SHA-2, SHA-3, RIPEMD-160, MDC-2, GOST R 34.11-94, BLAKE2, Whirlpool, SM3\nPublic-key cryptography\n\nRSA, DSA, Diffie\u2013Hellman key exchange,  Elliptic curve, X25519, Ed25519, X448, Ed448, GOST R 34.10-2001, SM2(Perfect forward secrecy is supported using elliptic curve Diffie\u2013Hellman since version 1.0.)\n\n== FIPS 140 validation ==\nFIPS 140 is a U.S. Federal program for the testing and certification of cryptographic modules. An early FIPS 140-1 certificate for OpenSSL's FOM 1.0 was revoked in July 2006 \"when questions were raised about the validated module's interaction with outside software.\" The module was re-certified in February 2007 before giving way to FIPS 140-2. OpenSSL 1.0.2 supported the use of the OpenSSL FIPS Object Module (FOM), which was built to deliver FIPS approved algorithms in a FIPS 140-2 validated environment. OpenSSL controversially decided to categorize the 1.0.2 architecture as 'end of life' or 'EOL', effective December 31, 2019, despite objections that it was the only version of OpenSSL that was currently available with support for FIPS mode. As a result of the EOL, many users were unable to properly deploy the FOM 2.0 and fell out of compliance because they did not secure extended support for the 1.0.2 architecture, although the FOM itself remained validated for eight months further.\nThe FIPS Object Module 2.0 remained FIPS 140-2 validated in several formats until September 1, 2020, when NIST deprecated the usage of FIPS 186-2 for Digital Signature Standard and designated all non-compliant modules as 'Historical'. This designation includes a caution to federal agencies that they should not include the module in any new procurements. All three of the OpenSSL validations were included in the deprecation \u2013 the OpenSSL FIPS Object Module (certificate #1747), OpenSSL FIPS Object Module SE (certificate #2398), and OpenSSL FIPS Object Module RE (certificate #2473). Many 'private label' OpenSSL-based validations and clones created by consultants were also moved to the Historical List, although some FIPS validated modules with replacement compatibility avoided the deprecation, such as BoringCrypto from Google and CryptoComply from SafeLogic.The OpenSSL Management Committee announced a change in the versioning scheme.\nDue to this change, the major number of the next major version would have been doubled, since the OpenSSL FIPS module already occupied this number. Therefore the decision was made to skip the OpenSSL 2.0 version number and continue with OpenSSL 3.0 .\nOpenSSL 3.0 restored FIPS mode and underwent FIPS 140-2 testing, but with significant delays: The effort was first kicked off in 2016 with support from SafeLogic and further support from Oracle in 2017, but the process has been challenging.\nOn October 20, 2020, the OpenSSL FIPS Provider 3.0 was added to the CMVP Implementation Under Test List, which reflected an official engagement with a testing lab to proceed with a FIPS 140-2 validation. This resulted in a slew of certifications in the following months.\n\n== Licensing ==\nOpenSSL was dual-licensed under the OpenSSL License and the SSLeay License, which means that the terms of either licenses can be used. The OpenSSL License is Apache License 1.0 and SSLeay License bears some similarity to a 4-clause BSD License.\nAs the OpenSSL License was Apache License 1.0, but not Apache License 2.0, it requires the phrase \"this product includes software developed by the OpenSSL Project for use in the OpenSSL Toolkit\" to appear in advertising material and any redistributions (Sections 3 and 6 of the OpenSSL License). Due to this restriction, the OpenSSL License and the Apache License 1.0 are incompatible with the GNU GPL.\nSome GPL developers have added an OpenSSL exception to their licenses that specifically permits using OpenSSL with their system. GNU Wget and climm both use such exceptions. Some packages (like Deluge) explicitly modify the GPL license by adding an extra section at the beginning of the license documenting the exception. Other packages use the LGPL-licensed GnuTLS, BSD-licensed Botan, or MPL-licensed NSS, which perform the same task.\nOpenSSL announced in August 2015 that it would require most contributors to sign a Contributor License Agreement (CLA), and that OpenSSL would eventually be relicensed under the terms of Apache License 2.0. This process commenced in March 2017, and was complete in 2018.On 7 September 2021, OpenSSL 3.0.0 was released under the Apache License 2.0.\n\n== Notable vulnerabilities ==\n\n\n*** Denial of service: ASN.1 parsing ***\nOpenSSL 0.9.6k has a bug where certain ASN.1 sequences triggered a large number of recursions on Windows machines, discovered on November 4, 2003. Windows could not handle large recursions correctly, so OpenSSL would crash as a result. Being able to send arbitrary large numbers of ASN.1 sequences would cause OpenSSL to crash as a result.\n\n\n*** OCSP stapling vulnerability ***\nWhen creating a handshake, the client could send an incorrectly formatted ClientHello message, leading to OpenSSL parsing more than the end of the message. Assigned the identifier CVE-2011-0014 by the CVE project, this affected all OpenSSL versions 0.9.8h to 0.9.8q and OpenSSL 1.0.0 to 1.0.0c. Since the parsing could lead to a read on an incorrect memory address, it was possible for the attacker to cause a DoS. It was also possible that some applications expose the contents of parsed OCSP extensions, leading to an attacker being able to read the contents of memory that came after the ClientHello.\n\n\n*** ASN.1 BIO vulnerability ***\nWhen using Basic Input/Output (BIO) or FILE based functions to read untrusted DER format data, OpenSSL is vulnerable. This vulnerability was discovered on April 19, 2012, and was assigned the CVE identifier CVE-2012-2110. While not directly affecting the SSL/TLS code of OpenSSL, any application that was using ASN.1 functions (particularly d2i_X509 and d2i_PKCS12) were also not affected.\n\n\n*** SSL, TLS and DTLS plaintext recovery attack ***\nIn handling CBC cipher-suites in SSL, TLS, and DTLS, OpenSSL was found vulnerable to a timing attack during the MAC processing. Nadhem Alfardan and Kenny Paterson discovered the problem, and published their findings on February 5, 2013. The vulnerability was assigned the CVE identifier CVE-2013-0169.\n\n\n*** Predictable private keys (Debian-specific) ***\nOpenSSL's pseudo-random number generator acquires entropy using complex programming methods. To keep the Valgrind analysis tool from issuing associated warnings, a maintainer of the Debian distribution applied a patch to Debian's variant of the OpenSSL suite, which inadvertently broke its random number generator by limiting the overall number of private keys it could generate to 32,768. The broken version was included in the Debian release of September 17, 2006 (version 0.9.8c-1), also compromising other Debian-based distributions, for example Ubuntu. Ready-to-use exploits are easily available.The error was reported by Debian on May 13, 2008. On the Debian 4.0 distribution (etch), these problems were fixed in version 0.9.8c-4etch3, while fixes for the Debian 5.0 distribution (lenny) were provided in version 0.9.8g-9.\n\n\n*** Heartbleed ***\n\nOpenSSL versions 1.0.1 through 1.0.1f have a severe memory handling bug in their implementation of the TLS Heartbeat Extension that could be used to reveal up to 64 KB of the application's memory with every heartbeat (CVE-2014-0160). By reading the memory of the web server, attackers could access sensitive data, including the server's private key. This could allow attackers to decode earlier eavesdropped communications if the encryption protocol used does not ensure perfect forward secrecy. Knowledge of the private key could also allow an attacker to mount a man-in-the-middle attack against any future communications. The vulnerability might also reveal unencrypted parts of other users' sensitive requests and responses, including session cookies and passwords, which might allow attackers to hijack the identity of another user of the service.At its disclosure on April 7, 2014, around 17% or half a million of the Internet's secure web servers certified by trusted authorities were believed to have been vulnerable to the attack. However, Heartbleed can affect both the server and client.\n\n\n*** CCS injection vulnerability ***\nThe CCS Injection Vulnerability (CVE-2014-0224) is a security bypass vulnerability that results from a weakness in OpenSSL methods used for keying material.This vulnerability can be exploited through the use of a man-in-the-middle attack, where an attacker may be able to decrypt and modify traffic in transit. A remote unauthenticated attacker could exploit this vulnerability by using a specially crafted handshake to force the use of weak keying material. Successful exploitation could lead to a security bypass condition where an attacker could gain access to potentially sensitive information. The attack can only be performed between a vulnerable client and server.\nOpenSSL clients are vulnerable in all versions of OpenSSL before the versions 0.9.8za, 1.0.0m and 1.0.1h. Servers are only known to be vulnerable in OpenSSL 1.0.1 and 1.0.2-beta1. Users of OpenSSL servers earlier than 1.0.1 are advised to upgrade as a precaution.\n\n\n*** ClientHello sigalgs DoS ***\nThis vulnerability (CVE-2015-0291) allows anyone to take a certificate, read its contents and modify it accurately to abuse the vulnerability causing a certificate to crash a client or server. If a client connects to an OpenSSL 1.0.2 server and renegotiates with an invalid signature algorithms extension, a null-pointer dereference occurs. This can cause a DoS attack against the server.\nA Stanford Security researcher, David Ramos, had a private exploit and presented it to the OpenSSL team, which then patched the issue.\nOpenSSL classified the bug as a high-severity issue, noting version 1.0.2 was found vulnerable.\n\n\n*** Key recovery attack on Diffie\u2013Hellman small subgroups ***\nThis vulnerability (CVE-2016-0701) allows, when some particular circumstances are met, to recover the OpenSSL server's private Diffie\u2013Hellman key. An Adobe System Security researcher, Antonio Sanso, privately reported the vulnerability.\nOpenSSL classified the bug as a high-severity issue, noting only version 1.0.2 was found vulnerable.\n\n== Forks ==\n\n\n*** Agglomerated SSL ***\nIn 2009, after frustrations with the original OpenSSL API, Marco Peereboom, an OpenBSD developer at the time, forked the original API by creating Agglomerated SSL (assl), which reuses OpenSSL API under the hood, but provides a much simpler external interface.  It has since been deprecated in light of the LibreSSL fork circa 2016.\n\n\n*** LibreSSL ***\n\nIn April 2014 in the wake of Heartbleed, members of the OpenBSD project forked OpenSSL starting with the 1.0.1g branch, to create a project named LibreSSL. In the first week of pruning the OpenSSL's codebase, more than 90,000 lines of C code had been removed from the fork.\n\n\n*** BoringSSL ***\nIn June 2014, Google announced its own fork of OpenSSL dubbed BoringSSL. Google plans to co-operate with OpenSSL and LibreSSL developers. Google has since developed a new library, Tink, based on BoringSSL.\n\n== Criticisms ==\n\n\n*** Backwards compatibility ***\nAmong developers communities, OpenSSL is often cited for coming with a bit of API compatibility breakage with each new major version, which requires software adaptations that tend to delay new version adoptions. This, combined with the fact that previous releases are generally maintained for no more than two years after a new major one is emitted tends to force some vendors to anticipate software migrations very early while still having little time left to update to a new release, sometimes at the risk of losing some compatibility with existing software or risking regressions.\n\n\n*** Delay between releases ***\nWhile LTS (long term supported) releases are maintained for 5 years, accumulated delays in release time frames tend to force operating system vendors to stay on the last supported release longer, leaving less margin when the new version is available. For example OpenSSL 3.0 was initially expected for Q4 2019 and was finally issued 21 months later without extending the expected end of support for previously supported version 1.1.1, and this despite the significant changes that required adaptations to existing software.\n\n\n*** Significant performance regressions ***\nThe reduced support delay of version 1.1.1 mentioned above causes further concerns to users whose workloads are sensitive to performance. Some time after general availability of 3.0, some users started to report serious performance regressions affecting this version in multi-threaded environments, many citing the inefficient use of locks in frequent low-level operations, citing slowdowns from 80 to 400 times. The OpenSSL team has created a meta-issue to try to centralize reports of such massive performance regressions. About half of these reporters indicate the impossibility for them to upgrade to 3.0 from earlier versions, adding to the trouble caused by the limited support time left on previous version 1.1.1.\n\n\n*** Consideration for users' requirements ***\nWhile the QUIC transport layer was being worked on to support the third version of the HTTP protocol, it was proposed to use TLS to provide security, and identified that some adaptations to TLS libraries would be needed. Such modifications were brought to BoringSSL which was the library being primarily used by QUIC developers by then, and later ported to other libraries. A port of this work was quickly proposed to OpenSSL. While some discussion started the same day, it quickly stalled and was first blocked on license considerations, then kept on hold once these concerns were cleared. Finally 10 months later the OpenSSL Management Committee announced on a blog post that this patch set would not be adopted for 3.0 on the fear that the API would change over time. Finally more than one year after planned release of 3.0 which was still not coming, a team of volunteers from Akamai and Microsoft decided to fork the project as QuicTLS and support these patches on top of the OpenSSL code in order to unblock QUIC development. This action was generally welcome by the community. Finally after OpenSSL 3.0 was finally released, the QUIC patch set was reconsidered and decided against, causing tens to hundreds of reactions of disappointment among the community. The pull request was closed, while users felt the need to publicly express their disappointment, or beg operating system vendors to support the alternative QuicTLS fork, or seek for alternative solutions. Finally Rich Salz, co-founder of the QuicTLS fork, announced his interest in seeing an Apache project forked from QuicTLS. As of 25 February 2023 there is still no QUIC-compatible long-term supported TLS library available by default in operating systems without requiring end-users to rebuild it themselves from sources.\n\nAnswer this question based on the above context: Who reported the Key recovery attack on Diffie\u2013Hellman small subgroups vulnerability (CVE-2016-0701) in OpenSSL?",
    "context": "",
    "output": "The Key recovery attack on Diffie\u2013Hellman small subgroups vulnerability (CVE-2016-0701) in OpenSSL was reported by an Adobe System Security researcher, Antonio Sanso.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Who reported the Key recovery attack on Diffie\u2013Hellman small subgroups vulnerability (CVE-2016-0701) in OpenSSL?",
      "answer": "The Key recovery attack on Diffie\u2013Hellman small subgroups vulnerability (CVE-2016-0701) in OpenSSL was reported by an Adobe System Security researcher, Antonio Sanso.",
      "context": "OpenSSL\n\n==Introduction==\nOpenSSL is a software library for applications that provide secure communications over computer networks against eavesdropping, and identify the party at the other end. It is widely used by Internet servers, including the majority of HTTPS websites.\nOpenSSL contains an open-source implementation of the SSL and TLS protocols.  The core library, written in the C programming language, implements basic cryptographic functions and provides various utility functions. Wrappers allowing the use of the OpenSSL library in a variety of computer languages are available.\nThe OpenSSL Software Foundation (OSF) represents the OpenSSL project in most legal capacities including contributor license agreements, managing donations, and so on. OpenSSL Software Services (OSS) also represents the OpenSSL project for support contracts.\nOpenSSL is available for most Unix-like operating systems (including Linux, macOS, and BSD), Microsoft Windows and OpenVMS.\n\n\n\n== Project history ==\nThe OpenSSL project was founded in 1998 to provide a free set of encryption tools for the code used on the Internet. It is based on a fork of SSLeay by Eric Andrew Young and Tim Hudson, which unofficially ended development on December 17, 1998, when Young and Hudson both went to work for RSA Security.  The initial founding members were Mark Cox, Ralf Engelschall, Stephen Henson, Ben Laurie, and Paul Sutton.As of May 2019, the OpenSSL management committee consisted of seven people and there are seventeen developers with commit access (many of whom are also part of the OpenSSL management committee). There are only two full-time employees (fellows) and the remainder are volunteers.\nThe project has a budget of less than $1 million USD per year and relies primarily on donations. Development of TLS 1.3 was sponsored by Akamai.\n\n== Major version releases ==\n\n== Algorithms ==\nOpenSSL supports a number of different cryptographic algorithms:\n\nCiphers\n\nAES, Blowfish, Camellia, Chacha20, Poly1305,  SEED, CAST-128, DES, IDEA, RC2, RC4, RC5, Triple DES, GOST 28147-89, SM4\nCryptographic hash functions\n\nMD5, MD4, MD2, SHA-1, SHA-2, SHA-3, RIPEMD-160, MDC-2, GOST R 34.11-94, BLAKE2, Whirlpool, SM3\nPublic-key cryptography\n\nRSA, DSA, Diffie\u2013Hellman key exchange,  Elliptic curve, X25519, Ed25519, X448, Ed448, GOST R 34.10-2001, SM2(Perfect forward secrecy is supported using elliptic curve Diffie\u2013Hellman since version 1.0.)\n\n== FIPS 140 validation ==\nFIPS 140 is a U.S. Federal program for the testing and certification of cryptographic modules. An early FIPS 140-1 certificate for OpenSSL's FOM 1.0 was revoked in July 2006 \"when questions were raised about the validated module's interaction with outside software.\" The module was re-certified in February 2007 before giving way to FIPS 140-2. OpenSSL 1.0.2 supported the use of the OpenSSL FIPS Object Module (FOM), which was built to deliver FIPS approved algorithms in a FIPS 140-2 validated environment. OpenSSL controversially decided to categorize the 1.0.2 architecture as 'end of life' or 'EOL', effective December 31, 2019, despite objections that it was the only version of OpenSSL that was currently available with support for FIPS mode. As a result of the EOL, many users were unable to properly deploy the FOM 2.0 and fell out of compliance because they did not secure extended support for the 1.0.2 architecture, although the FOM itself remained validated for eight months further.\nThe FIPS Object Module 2.0 remained FIPS 140-2 validated in several formats until September 1, 2020, when NIST deprecated the usage of FIPS 186-2 for Digital Signature Standard and designated all non-compliant modules as 'Historical'. This designation includes a caution to federal agencies that they should not include the module in any new procurements. All three of the OpenSSL validations were included in the deprecation \u2013 the OpenSSL FIPS Object Module (certificate #1747), OpenSSL FIPS Object Module SE (certificate #2398), and OpenSSL FIPS Object Module RE (certificate #2473). Many 'private label' OpenSSL-based validations and clones created by consultants were also moved to the Historical List, although some FIPS validated modules with replacement compatibility avoided the deprecation, such as BoringCrypto from Google and CryptoComply from SafeLogic.The OpenSSL Management Committee announced a change in the versioning scheme.\nDue to this change, the major number of the next major version would have been doubled, since the OpenSSL FIPS module already occupied this number. Therefore the decision was made to skip the OpenSSL 2.0 version number and continue with OpenSSL 3.0 .\nOpenSSL 3.0 restored FIPS mode and underwent FIPS 140-2 testing, but with significant delays: The effort was first kicked off in 2016 with support from SafeLogic and further support from Oracle in 2017, but the process has been challenging.\nOn October 20, 2020, the OpenSSL FIPS Provider 3.0 was added to the CMVP Implementation Under Test List, which reflected an official engagement with a testing lab to proceed with a FIPS 140-2 validation. This resulted in a slew of certifications in the following months.\n\n== Licensing ==\nOpenSSL was dual-licensed under the OpenSSL License and the SSLeay License, which means that the terms of either licenses can be used. The OpenSSL License is Apache License 1.0 and SSLeay License bears some similarity to a 4-clause BSD License.\nAs the OpenSSL License was Apache License 1.0, but not Apache License 2.0, it requires the phrase \"this product includes software developed by the OpenSSL Project for use in the OpenSSL Toolkit\" to appear in advertising material and any redistributions (Sections 3 and 6 of the OpenSSL License). Due to this restriction, the OpenSSL License and the Apache License 1.0 are incompatible with the GNU GPL.\nSome GPL developers have added an OpenSSL exception to their licenses that specifically permits using OpenSSL with their system. GNU Wget and climm both use such exceptions. Some packages (like Deluge) explicitly modify the GPL license by adding an extra section at the beginning of the license documenting the exception. Other packages use the LGPL-licensed GnuTLS, BSD-licensed Botan, or MPL-licensed NSS, which perform the same task.\nOpenSSL announced in August 2015 that it would require most contributors to sign a Contributor License Agreement (CLA), and that OpenSSL would eventually be relicensed under the terms of Apache License 2.0. This process commenced in March 2017, and was complete in 2018.On 7 September 2021, OpenSSL 3.0.0 was released under the Apache License 2.0.\n\n== Notable vulnerabilities ==\n\n\n*** Denial of service: ASN.1 parsing ***\nOpenSSL 0.9.6k has a bug where certain ASN.1 sequences triggered a large number of recursions on Windows machines, discovered on November 4, 2003. Windows could not handle large recursions correctly, so OpenSSL would crash as a result. Being able to send arbitrary large numbers of ASN.1 sequences would cause OpenSSL to crash as a result.\n\n\n*** OCSP stapling vulnerability ***\nWhen creating a handshake, the client could send an incorrectly formatted ClientHello message, leading to OpenSSL parsing more than the end of the message. Assigned the identifier CVE-2011-0014 by the CVE project, this affected all OpenSSL versions 0.9.8h to 0.9.8q and OpenSSL 1.0.0 to 1.0.0c. Since the parsing could lead to a read on an incorrect memory address, it was possible for the attacker to cause a DoS. It was also possible that some applications expose the contents of parsed OCSP extensions, leading to an attacker being able to read the contents of memory that came after the ClientHello.\n\n\n*** ASN.1 BIO vulnerability ***\nWhen using Basic Input/Output (BIO) or FILE based functions to read untrusted DER format data, OpenSSL is vulnerable. This vulnerability was discovered on April 19, 2012, and was assigned the CVE identifier CVE-2012-2110. While not directly affecting the SSL/TLS code of OpenSSL, any application that was using ASN.1 functions (particularly d2i_X509 and d2i_PKCS12) were also not affected.\n\n\n*** SSL, TLS and DTLS plaintext recovery attack ***\nIn handling CBC cipher-suites in SSL, TLS, and DTLS, OpenSSL was found vulnerable to a timing attack during the MAC processing. Nadhem Alfardan and Kenny Paterson discovered the problem, and published their findings on February 5, 2013. The vulnerability was assigned the CVE identifier CVE-2013-0169.\n\n\n*** Predictable private keys (Debian-specific) ***\nOpenSSL's pseudo-random number generator acquires entropy using complex programming methods. To keep the Valgrind analysis tool from issuing associated warnings, a maintainer of the Debian distribution applied a patch to Debian's variant of the OpenSSL suite, which inadvertently broke its random number generator by limiting the overall number of private keys it could generate to 32,768. The broken version was included in the Debian release of September 17, 2006 (version 0.9.8c-1), also compromising other Debian-based distributions, for example Ubuntu. Ready-to-use exploits are easily available.The error was reported by Debian on May 13, 2008. On the Debian 4.0 distribution (etch), these problems were fixed in version 0.9.8c-4etch3, while fixes for the Debian 5.0 distribution (lenny) were provided in version 0.9.8g-9.\n\n\n*** Heartbleed ***\n\nOpenSSL versions 1.0.1 through 1.0.1f have a severe memory handling bug in their implementation of the TLS Heartbeat Extension that could be used to reveal up to 64 KB of the application's memory with every heartbeat (CVE-2014-0160). By reading the memory of the web server, attackers could access sensitive data, including the server's private key. This could allow attackers to decode earlier eavesdropped communications if the encryption protocol used does not ensure perfect forward secrecy. Knowledge of the private key could also allow an attacker to mount a man-in-the-middle attack against any future communications. The vulnerability might also reveal unencrypted parts of other users' sensitive requests and responses, including session cookies and passwords, which might allow attackers to hijack the identity of another user of the service.At its disclosure on April 7, 2014, around 17% or half a million of the Internet's secure web servers certified by trusted authorities were believed to have been vulnerable to the attack. However, Heartbleed can affect both the server and client.\n\n\n*** CCS injection vulnerability ***\nThe CCS Injection Vulnerability (CVE-2014-0224) is a security bypass vulnerability that results from a weakness in OpenSSL methods used for keying material.This vulnerability can be exploited through the use of a man-in-the-middle attack, where an attacker may be able to decrypt and modify traffic in transit. A remote unauthenticated attacker could exploit this vulnerability by using a specially crafted handshake to force the use of weak keying material. Successful exploitation could lead to a security bypass condition where an attacker could gain access to potentially sensitive information. The attack can only be performed between a vulnerable client and server.\nOpenSSL clients are vulnerable in all versions of OpenSSL before the versions 0.9.8za, 1.0.0m and 1.0.1h. Servers are only known to be vulnerable in OpenSSL 1.0.1 and 1.0.2-beta1. Users of OpenSSL servers earlier than 1.0.1 are advised to upgrade as a precaution.\n\n\n*** ClientHello sigalgs DoS ***\nThis vulnerability (CVE-2015-0291) allows anyone to take a certificate, read its contents and modify it accurately to abuse the vulnerability causing a certificate to crash a client or server. If a client connects to an OpenSSL 1.0.2 server and renegotiates with an invalid signature algorithms extension, a null-pointer dereference occurs. This can cause a DoS attack against the server.\nA Stanford Security researcher, David Ramos, had a private exploit and presented it to the OpenSSL team, which then patched the issue.\nOpenSSL classified the bug as a high-severity issue, noting version 1.0.2 was found vulnerable.\n\n\n*** Key recovery attack on Diffie\u2013Hellman small subgroups ***\nThis vulnerability (CVE-2016-0701) allows, when some particular circumstances are met, to recover the OpenSSL server's private Diffie\u2013Hellman key. An Adobe System Security researcher, Antonio Sanso, privately reported the vulnerability.\nOpenSSL classified the bug as a high-severity issue, noting only version 1.0.2 was found vulnerable.\n\n== Forks ==\n\n\n*** Agglomerated SSL ***\nIn 2009, after frustrations with the original OpenSSL API, Marco Peereboom, an OpenBSD developer at the time, forked the original API by creating Agglomerated SSL (assl), which reuses OpenSSL API under the hood, but provides a much simpler external interface.  It has since been deprecated in light of the LibreSSL fork circa 2016.\n\n\n*** LibreSSL ***\n\nIn April 2014 in the wake of Heartbleed, members of the OpenBSD project forked OpenSSL starting with the 1.0.1g branch, to create a project named LibreSSL. In the first week of pruning the OpenSSL's codebase, more than 90,000 lines of C code had been removed from the fork.\n\n\n*** BoringSSL ***\nIn June 2014, Google announced its own fork of OpenSSL dubbed BoringSSL. Google plans to co-operate with OpenSSL and LibreSSL developers. Google has since developed a new library, Tink, based on BoringSSL.\n\n== Criticisms ==\n\n\n*** Backwards compatibility ***\nAmong developers communities, OpenSSL is often cited for coming with a bit of API compatibility breakage with each new major version, which requires software adaptations that tend to delay new version adoptions. This, combined with the fact that previous releases are generally maintained for no more than two years after a new major one is emitted tends to force some vendors to anticipate software migrations very early while still having little time left to update to a new release, sometimes at the risk of losing some compatibility with existing software or risking regressions.\n\n\n*** Delay between releases ***\nWhile LTS (long term supported) releases are maintained for 5 years, accumulated delays in release time frames tend to force operating system vendors to stay on the last supported release longer, leaving less margin when the new version is available. For example OpenSSL 3.0 was initially expected for Q4 2019 and was finally issued 21 months later without extending the expected end of support for previously supported version 1.1.1, and this despite the significant changes that required adaptations to existing software.\n\n\n*** Significant performance regressions ***\nThe reduced support delay of version 1.1.1 mentioned above causes further concerns to users whose workloads are sensitive to performance. Some time after general availability of 3.0, some users started to report serious performance regressions affecting this version in multi-threaded environments, many citing the inefficient use of locks in frequent low-level operations, citing slowdowns from 80 to 400 times. The OpenSSL team has created a meta-issue to try to centralize reports of such massive performance regressions. About half of these reporters indicate the impossibility for them to upgrade to 3.0 from earlier versions, adding to the trouble caused by the limited support time left on previous version 1.1.1.\n\n\n*** Consideration for users' requirements ***\nWhile the QUIC transport layer was being worked on to support the third version of the HTTP protocol, it was proposed to use TLS to provide security, and identified that some adaptations to TLS libraries would be needed. Such modifications were brought to BoringSSL which was the library being primarily used by QUIC developers by then, and later ported to other libraries. A port of this work was quickly proposed to OpenSSL. While some discussion started the same day, it quickly stalled and was first blocked on license considerations, then kept on hold once these concerns were cleared. Finally 10 months later the OpenSSL Management Committee announced on a blog post that this patch set would not be adopted for 3.0 on the fear that the API would change over time. Finally more than one year after planned release of 3.0 which was still not coming, a team of volunteers from Akamai and Microsoft decided to fork the project as QuicTLS and support these patches on top of the OpenSSL code in order to unblock QUIC development. This action was generally welcome by the community. Finally after OpenSSL 3.0 was finally released, the QUIC patch set was reconsidered and decided against, causing tens to hundreds of reactions of disappointment among the community. The pull request was closed, while users felt the need to publicly express their disappointment, or beg operating system vendors to support the alternative QuicTLS fork, or seek for alternative solutions. Finally Rich Salz, co-founder of the QuicTLS fork, announced his interest in seeing an Apache project forked from QuicTLS. As of 25 February 2023 there is still no QUIC-compatible long-term supported TLS library available by default in operating systems without requiring end-users to rebuild it themselves from sources."
    }
  },
  {
    "instruction": "Write an answer to the following question: How can juice jacking be mitigated according to the given text?",
    "context": "",
    "output": "Juice jacking can be mitigated by charging a device via a trusted AC adapter, battery backup device, or by utilizing a USB cable with only power wires and no data wires present. A USB data blocker (sometimes referred to as a USB Condom) can also be used to connect between a device and charging port to disallow a data connection.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can juice jacking be mitigated according to the given text?",
      "answer": "Juice jacking can be mitigated by charging a device via a trusted AC adapter, battery backup device, or by utilizing a USB cable with only power wires and no data wires present. A USB data blocker (sometimes referred to as a USB Condom) can also be used to connect between a device and charging port to disallow a data connection."
    }
  },
  {
    "instruction": "Kr00k\n\n==Introduction==\nKr00k (also written as Kr\u00d8\u00d8k) is a security vulnerability that allows some WPA2 encrypted WiFi traffic to be decrypted. The vulnerability was originally discovered by security company ESET in 2019 and assigned CVE-2019-15126 on August 17, 2019. ESET estimates that this vulnerability affects over a billion devices.\n\n\n\n== Discovery ==\nKr00k was discovered by ESET Experimental Research and Detection Team, most prominently ESET security researcher Milo\u0161 \u010cerm\u00e1k.It was named Kr00k by Robert Lipovsky and Stefan Svorencik. It was discovered when trying variations of the KRACK attack.Initially found in chips made by Broadcom and Cypress, similar vulnerabilities have been found in other implementations, including those by Qualcomm and MediaTek.\n\n== Patches ==\nThe vulnerability is known to be patched in:\n\niOS 13.2 and iPadOS 13.2 - October 28, 2019 \nmacOS Catalina 10.15.1, Security Update 2019\u2013001, and Security Update 2019-006 - October 29, 2019\n\n== Vulnerable devices ==\nDuring their research, ESET confirmed over a dozen popular devices were vulnerable.Cisco has found several of their devices to be vulnerable and are working on patches. They are tracking the issue with advisory id cisco-sa-20200226-wi-fi-info-disclosure.Known vulnerable devices include:\n\nAmazon Echo 2nd gen\nAmazon Kindle 8th gen\nApple iPad mini 2\nApple iPhone 6, 6S, 8, XR\nApple MacBook Air Retina 13-inch 2018\nAsus wireless routers (RT-AC1200G+, RT-AC68U), but fixed in firmware Version 3.0.0.4.382.5161220 during March 2020\nGoogle Nexus 5\nGoogle Nexus 6\nGoogle Nexus 6P\nRaspberry Pi 3\nSamsung Galaxy S4 (GT-I9505)\nSamsung Galaxy S8\nXiaomi Redmi 3S\n\nBased on the above text, answer a question. How does the Kr00k vulnerability affect wireless routers, such as those made by Asus?",
    "context": "",
    "output": "The Kr00k vulnerability affects certain Asus wireless routers, such as the RT-AC1200G+ and RT-AC68U. However, Asus has fixed the vulnerability in firmware Version 3.0.0.4.382.5161220 during March 2020.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the Kr00k vulnerability affect wireless routers, such as those made by Asus?",
      "answer": "The Kr00k vulnerability affects certain Asus wireless routers, such as the RT-AC1200G+ and RT-AC68U. However, Asus has fixed the vulnerability in firmware Version 3.0.0.4.382.5161220 during March 2020.",
      "context": "Kr00k\n\n==Introduction==\nKr00k (also written as Kr\u00d8\u00d8k) is a security vulnerability that allows some WPA2 encrypted WiFi traffic to be decrypted. The vulnerability was originally discovered by security company ESET in 2019 and assigned CVE-2019-15126 on August 17, 2019. ESET estimates that this vulnerability affects over a billion devices.\n\n\n\n== Discovery ==\nKr00k was discovered by ESET Experimental Research and Detection Team, most prominently ESET security researcher Milo\u0161 \u010cerm\u00e1k.It was named Kr00k by Robert Lipovsky and Stefan Svorencik. It was discovered when trying variations of the KRACK attack.Initially found in chips made by Broadcom and Cypress, similar vulnerabilities have been found in other implementations, including those by Qualcomm and MediaTek.\n\n== Patches ==\nThe vulnerability is known to be patched in:\n\niOS 13.2 and iPadOS 13.2 - October 28, 2019 \nmacOS Catalina 10.15.1, Security Update 2019\u2013001, and Security Update 2019-006 - October 29, 2019\n\n== Vulnerable devices ==\nDuring their research, ESET confirmed over a dozen popular devices were vulnerable.Cisco has found several of their devices to be vulnerable and are working on patches. They are tracking the issue with advisory id cisco-sa-20200226-wi-fi-info-disclosure.Known vulnerable devices include:\n\nAmazon Echo 2nd gen\nAmazon Kindle 8th gen\nApple iPad mini 2\nApple iPhone 6, 6S, 8, XR\nApple MacBook Air Retina 13-inch 2018\nAsus wireless routers (RT-AC1200G+, RT-AC68U), but fixed in firmware Version 3.0.0.4.382.5161220 during March 2020\nGoogle Nexus 5\nGoogle Nexus 6\nGoogle Nexus 6P\nRaspberry Pi 3\nSamsung Galaxy S4 (GT-I9505)\nSamsung Galaxy S8\nXiaomi Redmi 3S"
    }
  },
  {
    "instruction": "Context: Secure Real-time Transport Protocol\n\n==Introduction==\nThe Secure Real-time Transport Protocol (SRTP) is a profile for Real-time Transport Protocol (RTP) intended to provide encryption, message authentication and integrity, and replay attack protection to the RTP data in both unicast and multicast applications. It was developed by a small team of Internet Protocol and cryptographic experts from Cisco and Ericsson. It was first published by the IETF in March 2004 as RFC 3711.\nSince RTP is accompanied by the RTP Control Protocol (RTCP) which is used to control an RTP session, SRTP has a sister protocol, called Secure RTCP (SRTCP); it securely provides the same functions to SRTP as the ones provided by RTCP to RTP.\nUtilization of SRTP or SRTCP is optional in RTP or RTCP applications; but even if SRTP or SRTCP are used, all provided features (such as encryption and authentication) are optional and can be separately enabled or disabled. The only exception is the message authentication feature which is indispensable and required when using SRTCP.\n\n\n\n== Data flow encryption ==\nSRTP and SRTCP use Advanced Encryption Standard (AES) as the default cipher. There are two cipher modes defined which allow the AES block cipher to be used as a stream cipher:\n\nSegmented Integer Counter Mode\nA typical counter mode, which allows random access to any blocks, which is essential for RTP traffic running over unreliable network with possible loss of packets. In the general case, almost any function can be used in the role of counter, assuming that this function does not repeat for a large number of iterations.  But the standard for encryption of RTP data is just a usual integer incremental counter. AES running in this mode is the default encryption algorithm, with a default key size of 128 bits and a default session salt key length of 112 bits.\nf8-mode\nA variation of output feedback mode, enhanced to be seekable and with an altered initialization function. The default values of the encryption key and salt key are the same as for AES in counter mode. (AES running in this mode has been chosen to be used in 3G mobile networks.)Besides the AES cipher, SRTP allows the ability to disable encryption outright, using the so-called NULL cipher, which can be assumed as an alternate supported cipher. In fact, the NULL cipher does not perform any encryption; The encryption algorithm functions as the identity function, and copies the input stream to the output stream without any changes.  It is mandatory for this cipher mode to be implemented in any SRTP-compatible system.  As such, it can be used when the confidentiality guarantees ensured by SRTP are not required, while other SRTP features, such as authentication and message integrity, may be used.\nThrough SRTP can easily accommodate new encryption algorithms, the SRTP standard states that new encryption algorithms may only be introduced through publication of a new companion standard track RFC which must clearly define the new algorithm.\n\n== Authentication, integrity and replay protection ==\nThe above-listed encryption algorithms do not alone secure message integrity, an attacker will not be able to decrypt data but may be able to forge or replay previously transmitted data. Hence the SRTP standard also provides the means to secure the integrity of data and safety from replay.\nTo authenticate the message and protect its integrity, the HMAC-SHA1 algorithm is used. This produces a 160-bit result, which is then truncated to 80 or 32 bits to become the authentication tag appended to each packet.  The HMAC is calculated over the packet payload and material from the packet header, including the packet sequence number. To protect against replay attacks, the receiver maintains the sequence numbers of previously received messages, compares them with the sequence number in each new received message and admits the new message only if it has not been previously received.  This approach relies on the integrity protection to make it impossible to modify the sequence number without detection.\n\n== Key derivation ==\nA key derivation function is used to derive the different keys used in a crypto context (SRTP and SRTCP encryption keys and salts, SRTP and SRTCP authentication keys) from one single master key in a cryptographically secure way. Thus, the key management protocol needs to exchange only one master key, all the necessary session keys are generated by applying the key derivation function.\nPeriodic application of the key derivation function prevents an attacker from collecting large amounts of ciphertext encrypted with one single session key. This provides protection against certain attacks which are easier to carry out when a large amount of ciphertext is available. Furthermore, multiple applications of the key derivation function provides backwards and forward security in the sense that a compromised session key does not compromise other session keys derived from the same master key.  This means that even if an attacker managed to recover a session key, he is not able to decrypt messages secured with previous and later session keys derived from the same master key. (Note that, of course, a leaked master key reveals all the session keys derived from it.)\nSRTP relies on an external key management protocol to set up the initial master key. Two protocols specifically designed to be used with SRTP are ZRTP and MIKEY. There are also other methods to negotiate the SRTP keys. There are several vendors which offer products that use the SDES key exchange method.\n\n== Interoperability and applications ==\nSee Comparison of VoIP software \u00a7 Secure VoIP software for phones, servers and applications supporting SRTP.\n\n\n*** Telephony (VoIP) ***\nAsterisk (PBX)\n\n\n*** Web browser support ***\n\nKnown browsers with SRTP support of some kind\n\nBlink (browser engine) family\nChromium (web browser) supporting (but not universally) SRTP experimentally since 2016\nOpera (web browser)\nVivaldi (web browser)Web browser families with some level of SRTP in the mainline updating branches from the core rendering system\n\nGecko (software)\nMSHTML (superseded, but minimal support existed at time of expiration)\nWebKitSo far no known SRTP support exists for text based web browsers. Although SRTP could be used to operate in a VPN, in conjunction with web browsers, no VPN networks are known to be using it.\n\n== Standards documents ==\nRFC 3711, Proposed Standard, The Secure Real-time Transport Protocol (SRTP)\nRFC 4771, Proposed Standard, Integrity Transform Carrying Roll-Over Counter for the Secure Real-time Transport Protocol (SRTP)\nRFC 3551, Standard 65, RTP Profile for Audio and Video Conferences with Minimal Control\nRFC 3550, Standard 64, RTP: A Transport Protocol for Real-Time Applications\nRFC 2104, Informational, HMAC: Keyed-Hashing for Message Authentication\nRFC 7714, Proposed Standard, AES-GCM Authenticated Encryption in the Secure Real-time Transport Protocol (SRTP)\n\nQuestion: Which web browsers support SRTP in some capacity?\n\nAnswer:",
    "context": "",
    "output": "The Blink engine family, including Chromium and Opera, support SRTP experimentally, while Gecko, MSHTML, and WebKit also have some level of SRTP support.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Which web browsers support SRTP in some capacity?",
      "answer": "The Blink engine family, including Chromium and Opera, support SRTP experimentally, while Gecko, MSHTML, and WebKit also have some level of SRTP support.",
      "context": "Secure Real-time Transport Protocol\n\n==Introduction==\nThe Secure Real-time Transport Protocol (SRTP) is a profile for Real-time Transport Protocol (RTP) intended to provide encryption, message authentication and integrity, and replay attack protection to the RTP data in both unicast and multicast applications. It was developed by a small team of Internet Protocol and cryptographic experts from Cisco and Ericsson. It was first published by the IETF in March 2004 as RFC 3711.\nSince RTP is accompanied by the RTP Control Protocol (RTCP) which is used to control an RTP session, SRTP has a sister protocol, called Secure RTCP (SRTCP); it securely provides the same functions to SRTP as the ones provided by RTCP to RTP.\nUtilization of SRTP or SRTCP is optional in RTP or RTCP applications; but even if SRTP or SRTCP are used, all provided features (such as encryption and authentication) are optional and can be separately enabled or disabled. The only exception is the message authentication feature which is indispensable and required when using SRTCP.\n\n\n\n== Data flow encryption ==\nSRTP and SRTCP use Advanced Encryption Standard (AES) as the default cipher. There are two cipher modes defined which allow the AES block cipher to be used as a stream cipher:\n\nSegmented Integer Counter Mode\nA typical counter mode, which allows random access to any blocks, which is essential for RTP traffic running over unreliable network with possible loss of packets. In the general case, almost any function can be used in the role of counter, assuming that this function does not repeat for a large number of iterations.  But the standard for encryption of RTP data is just a usual integer incremental counter. AES running in this mode is the default encryption algorithm, with a default key size of 128 bits and a default session salt key length of 112 bits.\nf8-mode\nA variation of output feedback mode, enhanced to be seekable and with an altered initialization function. The default values of the encryption key and salt key are the same as for AES in counter mode. (AES running in this mode has been chosen to be used in 3G mobile networks.)Besides the AES cipher, SRTP allows the ability to disable encryption outright, using the so-called NULL cipher, which can be assumed as an alternate supported cipher. In fact, the NULL cipher does not perform any encryption; The encryption algorithm functions as the identity function, and copies the input stream to the output stream without any changes.  It is mandatory for this cipher mode to be implemented in any SRTP-compatible system.  As such, it can be used when the confidentiality guarantees ensured by SRTP are not required, while other SRTP features, such as authentication and message integrity, may be used.\nThrough SRTP can easily accommodate new encryption algorithms, the SRTP standard states that new encryption algorithms may only be introduced through publication of a new companion standard track RFC which must clearly define the new algorithm.\n\n== Authentication, integrity and replay protection ==\nThe above-listed encryption algorithms do not alone secure message integrity, an attacker will not be able to decrypt data but may be able to forge or replay previously transmitted data. Hence the SRTP standard also provides the means to secure the integrity of data and safety from replay.\nTo authenticate the message and protect its integrity, the HMAC-SHA1 algorithm is used. This produces a 160-bit result, which is then truncated to 80 or 32 bits to become the authentication tag appended to each packet.  The HMAC is calculated over the packet payload and material from the packet header, including the packet sequence number. To protect against replay attacks, the receiver maintains the sequence numbers of previously received messages, compares them with the sequence number in each new received message and admits the new message only if it has not been previously received.  This approach relies on the integrity protection to make it impossible to modify the sequence number without detection.\n\n== Key derivation ==\nA key derivation function is used to derive the different keys used in a crypto context (SRTP and SRTCP encryption keys and salts, SRTP and SRTCP authentication keys) from one single master key in a cryptographically secure way. Thus, the key management protocol needs to exchange only one master key, all the necessary session keys are generated by applying the key derivation function.\nPeriodic application of the key derivation function prevents an attacker from collecting large amounts of ciphertext encrypted with one single session key. This provides protection against certain attacks which are easier to carry out when a large amount of ciphertext is available. Furthermore, multiple applications of the key derivation function provides backwards and forward security in the sense that a compromised session key does not compromise other session keys derived from the same master key.  This means that even if an attacker managed to recover a session key, he is not able to decrypt messages secured with previous and later session keys derived from the same master key. (Note that, of course, a leaked master key reveals all the session keys derived from it.)\nSRTP relies on an external key management protocol to set up the initial master key. Two protocols specifically designed to be used with SRTP are ZRTP and MIKEY. There are also other methods to negotiate the SRTP keys. There are several vendors which offer products that use the SDES key exchange method.\n\n== Interoperability and applications ==\nSee Comparison of VoIP software \u00a7 Secure VoIP software for phones, servers and applications supporting SRTP.\n\n\n*** Telephony (VoIP) ***\nAsterisk (PBX)\n\n\n*** Web browser support ***\n\nKnown browsers with SRTP support of some kind\n\nBlink (browser engine) family\nChromium (web browser) supporting (but not universally) SRTP experimentally since 2016\nOpera (web browser)\nVivaldi (web browser)Web browser families with some level of SRTP in the mainline updating branches from the core rendering system\n\nGecko (software)\nMSHTML (superseded, but minimal support existed at time of expiration)\nWebKitSo far no known SRTP support exists for text based web browsers. Although SRTP could be used to operate in a VPN, in conjunction with web browsers, no VPN networks are known to be using it.\n\n== Standards documents ==\nRFC 3711, Proposed Standard, The Secure Real-time Transport Protocol (SRTP)\nRFC 4771, Proposed Standard, Integrity Transform Carrying Roll-Over Counter for the Secure Real-time Transport Protocol (SRTP)\nRFC 3551, Standard 65, RTP Profile for Audio and Video Conferences with Minimal Control\nRFC 3550, Standard 64, RTP: A Transport Protocol for Real-Time Applications\nRFC 2104, Informational, HMAC: Keyed-Hashing for Message Authentication\nRFC 7714, Proposed Standard, AES-GCM Authenticated Encryption in the Secure Real-time Transport Protocol (SRTP)"
    }
  },
  {
    "instruction": "CCID (protocol)\n\n==Introduction==\nCCID (chip card interface device) protocol is a USB protocol that allows a smartcard to be connected to a computer via a card reader using a standard USB interface, without the need for each manufacturer of smartcards to provide its own reader or protocol. This allows the smartcard to be used as a security token for authentication and data encryption, such as that used in BitLocker. Chip card interface devices come in a variety of forms. The smallest CCID form is a standard USB dongle and may contain a SIM card or Secure Digital card inside the USB dongle. Another popular interface is a USB smart card reader keyboard, which in addition to being a standard USB keyboard, has an built-in slot for accepting a smartcard. However, not all CCID compliant devices accept removable smartcards, for example, select Yubikey hardware authentication devices support CCID, where they play the role of both the card reader and the smartcard itself.\n\n\n\n== Hardware implementation ==\nAccording to the CCID specification by the USB standards work group, a CCID exchanges information through a host computer over USB by using a CCID message that consists of a 10-byte header followed by message-specific data. The standard defines fourteen commands that the host computer can use to send data and status and control information in messages. Every command requires at least one response message from the CCID.\n\n== Software driver ==\nCCID driver support has been natively supported by Microsoft beginning with Windows 2000. Apple has included some form of native CCID support since Mac OS X, with support evolving alongside Common Access Card and Personal Identity Verification specifications set by the US Federal Government. On Linux and other Unixes, CCID and CT-API devices are usually accessed with user-space drivers, for which no special kernel adaptation is required.\n\n== List of CCID providers ==\nAdvanced Card Systems\nActivIdentity\nBaltech\nBit4id\nBlutronics srl\nElyctis\nGemalto\nGiesecke & Devrient\nHID Global\nJaCarta\nrf IDEAS\nSafeNet\nSecuTech Solutions\nSpringCard\nVerisign\nYubico\nReiner Kartenleseger\u00e4te\nDUALi\nQuestion: How has Microsoft supported CCID in its operating systems?",
    "context": "",
    "output": "Answer: Microsoft has natively supported CCID in its Windows operating systems, beginning with Windows 2000, allowing users to easily connect smartcards and use them as security tokens for authentication and data encryption.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How has Microsoft supported CCID in its operating systems?",
      "answer": "Microsoft has natively supported CCID in its Windows operating systems, beginning with Windows 2000, allowing users to easily connect smartcards and use them as security tokens for authentication and data encryption.",
      "context": "CCID (protocol)\n\n==Introduction==\nCCID (chip card interface device) protocol is a USB protocol that allows a smartcard to be connected to a computer via a card reader using a standard USB interface, without the need for each manufacturer of smartcards to provide its own reader or protocol. This allows the smartcard to be used as a security token for authentication and data encryption, such as that used in BitLocker. Chip card interface devices come in a variety of forms. The smallest CCID form is a standard USB dongle and may contain a SIM card or Secure Digital card inside the USB dongle. Another popular interface is a USB smart card reader keyboard, which in addition to being a standard USB keyboard, has an built-in slot for accepting a smartcard. However, not all CCID compliant devices accept removable smartcards, for example, select Yubikey hardware authentication devices support CCID, where they play the role of both the card reader and the smartcard itself.\n\n\n\n== Hardware implementation ==\nAccording to the CCID specification by the USB standards work group, a CCID exchanges information through a host computer over USB by using a CCID message that consists of a 10-byte header followed by message-specific data. The standard defines fourteen commands that the host computer can use to send data and status and control information in messages. Every command requires at least one response message from the CCID.\n\n== Software driver ==\nCCID driver support has been natively supported by Microsoft beginning with Windows 2000. Apple has included some form of native CCID support since Mac OS X, with support evolving alongside Common Access Card and Personal Identity Verification specifications set by the US Federal Government. On Linux and other Unixes, CCID and CT-API devices are usually accessed with user-space drivers, for which no special kernel adaptation is required.\n\n== List of CCID providers ==\nAdvanced Card Systems\nActivIdentity\nBaltech\nBit4id\nBlutronics srl\nElyctis\nGemalto\nGiesecke & Devrient\nHID Global\nJaCarta\nrf IDEAS\nSafeNet\nSecuTech Solutions\nSpringCard\nVerisign\nYubico\nReiner Kartenleseger\u00e4te\nDUALi"
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the management console snap-in named in Windows Vista's improved firewall?",
    "context": "",
    "output": "The management console snap-in named in Windows Vista's improved firewall is Windows Firewall with Advanced Security.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the management console snap-in named in Windows Vista's improved firewall?",
      "answer": "The management console snap-in named in Windows Vista's improved firewall is Windows Firewall with Advanced Security."
    }
  },
  {
    "instruction": "Social engineering (security)\n\n==Introduction==\nIn the context of information security, social engineering is the psychological manipulation of people into performing actions or divulging confidential information. A type of confidence trick for the purpose of information gathering, fraud, or system access, it differs from a traditional \"con\" in that it is often one of many steps in a more complex fraud scheme. It has also been defined as \"any act that influences a person to take an action that may or may not be in their best interests.\"An example of social engineering is an attacker calling a help desk, impersonating someone else, and claiming to have forgotten their password. If the help desk worker resets the password, it grants the attacker full access to the account.\n\n== Information security culture ==\nEmployee behaviour can have a big impact on information security in organizations. Cultural concepts can help different segments of the organization work effectively or work against effectiveness towards information security within an organization. \"Exploring the Relationship between Organizational Culture and Information Security Culture\" provides the following definition of information security culture: \"ISC is the totality of patterns of behavior in an organization that contribute to the protection of information of all kinds.\"Andersson and Reimers (2014) found that employees often do not see themselves as part of the organization Information Security \"effort\" and often take actions that ignore organizational information security best interests. Research shows Information security culture needs to be improved continuously. In \"Information Security Culture from Analysis to Change,\" authors commented that \"it's a never ending process, a cycle of evaluation and change or maintenance.\" They suggest that to manage information security culture, five steps should be taken: Pre-evaluation, strategic planning, operative planning, implementation, and post-evaluation.\nPre-Evaluation: to identify the awareness of information security within employees and to analyse current security policy.\nStrategic Planning: to come up with a better awareness-program, we need to set clear targets. Clustering people is helpful to achieve it.\nOperative Planning: set a good security culture based on internal communication, management-buy-in, and security awareness and training program.\nImplementation: four stages should be used to implement the information security culture. They are commitment of the management, communication with organizational members, courses for all organizational members, and commitment of the employees.\n\n== Techniques and terms ==\nAll social engineering techniques are based on specific attributes of human decision-making known as cognitive biases. These biases, sometimes called \"bugs in the human hardware,\u201d are exploited in various combinations to create attack techniques, some of which are listed below. The attacks used in social engineering can be used to steal employees' confidential information. The most common type of social engineering happens over the phone. Other examples of social engineering attacks are criminals posing as exterminators, fire marshals and technicians to go unnoticed as they steal company secrets.\nOne example of social engineering is an individual who walks into a building and posts an official-looking announcement to the company bulletin that says the number for the help desk has changed. So, when employees call for help the individual asks them for their passwords and IDs thereby gaining the ability to access the company's private information.\nAnother example of social engineering would be that the hacker contacts the target on a social networking site and starts a conversation with the target. Gradually the hacker gains the trust of the target and then uses that trust to get access to sensitive information like password or bank account details.Social engineering relies heavily on the six principles of influence established by Robert Cialdini. Cialdini's theory of influence is based on six key principles: reciprocity, commitment and consistency, social proof, authority, liking, scarcity.\n\n\n*** Six key principles ***\n\n\n**** Authority ****\nIn social engineering, the attacker may pose as authority to increase the likelihood of adherence from the victim.\n\n\n**** Intimidation ****\n\nAttacker (potentially disguised) informs or implies that there will be negative consequences if certain actions are not performed. Consequences could include subtle intimidation phrases such as \"I'll tell your manager\" to much worse.\n\n\n**** Consensus / Social proof ****\n\nPeople will do things that they see other people are doing. For example, in one experiment, one or more confederates would look up into the sky; bystanders would then look up into the sky to see what they were missing. At one point this experiment was aborted, as so many people were looking up that they stopped traffic. See conformity, and the Asch conformity experiments.\n\n\n**** Scarcity ****\n\nPerceived scarcity will generate demand. The common advertising phrase \"while supplies last\" capitalizes on a sense of scarcity. \n\n\n**** Urgency ****\nLinked to scarcity, attackers use urgency as a time-based psychological principle of social engineering. For example, saying offers are available for a \"limited time only\" encourages sales through a sense of urgency.\n\n\n**** Familiarity / Liking ****\n\nPeople are easily persuaded by other people whom they like. Cialdini cites the marketing of Tupperware in what might now be called viral marketing. People were more likely to buy if they liked the person selling it to them. Some of the many biases favoring more attractive people are discussed. See physical attractiveness stereotype.\n\n\n*** Four social engineering vectors ***\n\n\n**** Vishing ****\nVishing, otherwise known as \"voice phishing\", is the criminal practice of using social engineering over a telephone system to gain access to private personal and financial information from the public for the purpose of financial reward. It is also employed by attackers for reconnaissance purposes to gather more detailed intelligence on a target organization.\n\n\n**** Phishing ****\n\nPhishing is a technique of fraudulently obtaining private information. Typically, the phisher sends an e-mail that appears to come from a legitimate business\u2014a bank, or credit card company\u2014requesting \"verification\" of information and warning of some dire consequence if it is not provided. The e-mail usually contains a link to a fraudulent web page that seems legitimate\u2014with company logos and content\u2014and has a form requesting everything from a home address to an ATM card's PIN or a credit card number. For example, in 2003, there was a phishing scam in which users received emails supposedly from eBay claiming that the user's account was about to be suspended unless a link provided was clicked to update a credit card (information that the genuine eBay already had). By mimicking a legitimate organization's HTML code and logos, it is relatively simple to make a fake Website look authentic. The scam tricked some people into thinking that eBay was requiring them to update their account information by clicking on the link provided. By indiscriminately spamming extremely large groups of people, the \"phisher\" counted on gaining sensitive financial information from the small percentage (yet large number) of recipients who already have eBay accounts and also fall prey to the scam.\n\n\n**** Smishing ****\nThe act of using SMS text messaging to lure victims into a specific course of action, also known as \"smishing\". Like phishing it can be clicking on a malicious link or divulging information. Examples are text messages that claim to be from a common carrier (like FedEx) stating a package is in transit, with a link provided.\n\n\n**** Impersonation ****\nPretending or pretexting to be another person with the goal of gaining access physically to a system or building. Impersonation is used in the \"SIM swap scam\" fraud.\n\n== Other concepts ==\n\n\n*** Pretexting ***\n\nPretexting (adj. pretextual) is the act of creating and using an invented scenario (the pretext) to engage a targeted victim in a manner that increases the chance the victim will divulge information or perform actions that would be unlikely in ordinary circumstances. An elaborate lie, it most often involves some prior research or setup and the use of this information for impersonation (e.g., date of birth, Social Security number, last bill amount) to establish legitimacy in the mind of the target. As a background, pretexting can be interpreted as the first evolution of social engineering, and continued to develop as social engineering incorporated current-day technologies. Current and past examples of pretexting demonstrate this development.\nThis technique can be used to fool a business into disclosing customer information as well as by private investigators to obtain telephone records, utility records, banking records and other information directly from company service representatives. The information can then be used to establish even greater legitimacy under tougher questioning with a manager, e.g., to make account changes, get specific balances, etc.\nPretexting can also be used to impersonate co-workers, police, bank, tax authorities, clergy, insurance investigators\u2014or any other individual who could have perceived authority or right-to-know in the mind of the targeted victim. The pretexter must simply prepare answers to questions that might be asked by the victim. In some cases, all that is needed is a voice that sounds authoritative, an earnest tone, and an ability to think on one's feet to create a pretextual scenario.\n\n\n*** Vishing ***\n\nPhone phishing (or \"vishing\") uses a rogue interactive voice response (IVR) system to recreate a legitimate-sounding copy of a bank or other institution's IVR system. The victim is prompted (typically via a phishing e-mail) to call in to the \"bank\" via a (ideally toll free) number provided in order to \"verify\" information. A typical \"vishing\" system will reject log-ins continually, ensuring the victim enters PINs or passwords multiple times, often disclosing several different passwords. More advanced systems transfer the victim to the attacker/defrauder, who poses as a customer service agent or security expert for further questioning of the victim.\n\n\n*** Spear phishing ***\n\nAlthough similar to \"phishing\", spear phishing is a technique that fraudulently obtains private information by sending highly customized emails to few end users. It is the main difference between phishing attacks because phishing campaigns focus on sending out high volumes of generalized emails with the expectation that only a few people will respond. On the other hand, spear-phishing emails require the attacker to perform additional research on their targets in order to \"trick\" end users into performing requested activities. The success rate of spear-phishing attacks is considerably higher than phishing attacks with people opening roughly 3% of phishing emails when compared to roughly 70% of potential attempts. When users actually open the emails phishing emails have a relatively modest 5% success rate to have the link or attachment clicked when compared to a spear-phishing attack's 50% success rate.Spear-phishing success is heavily dependent on the amount and quality of OSINT (open-source intelligence) that the attacker can obtain. Social media account activity is one example of a source of OSINT.\n\n\n*** Water holing ***\n\nWater holing is a targeted social engineering strategy that capitalizes on the trust users have in websites they regularly visit. The victim feels safe to do things they would not do in a different situation. A wary person might, for example, purposefully avoid clicking a link in an unsolicited email, but the same person would not hesitate to follow a link on a website they often visit. So, the attacker prepares a trap for the unwary prey at a favored watering hole. This strategy has been successfully used to gain access to some (supposedly) very secure systems.The attacker may set out by identifying a group or individuals to target. The preparation involves gathering information about websites the targets often visit from the secure system. The information gathering confirms that the targets visit the websites and that the system allows such visits. The attacker then tests these websites for vulnerabilities to inject code that may infect a visitor's system with malware. The injected code trap and malware may be tailored to the specific target group and the specific systems they use. In time, one or more members of the target group will get infected and the attacker can gain access to the secure system.\n\n\n*** Baiting ***\nBaiting is like the real-world Trojan horse that uses physical media and relies on the curiosity or greed of the victim. In this attack, attackers leave malware-infected floppy disks, CD-ROMs, or USB flash drives in locations people will find them (bathrooms, elevators, sidewalks, parking lots, etc.), give them legitimate and curiosity-piquing labels, and wait for victims.\nFor example, an attacker may create a disk featuring a corporate logo, available from the target's website, and label it \"Executive Salary Summary Q2 2012\". The attacker then leaves the disk on the floor of an elevator or somewhere in the lobby of the target company. An unknowing employee may find it and insert the disk into a computer to satisfy their curiosity, or a good Samaritan may find it and return it to the company. In any case, just inserting the disk into a computer installs malware, giving attackers access to the victim's PC and, perhaps, the target company's internal computer network.\nUnless computer controls block infections, insertion compromises PCs \"auto-running\" media. Hostile devices can also be used. For instance, a \"lucky winner\" is sent a free digital audio player compromising any computer it is plugged to. A \"road apple\" (the colloquial term for horse manure, suggesting the device's undesirable nature) is any removable media with malicious software left in opportunistic or conspicuous places. It may be a CD, DVD, or USB flash drive, among other media. Curious people take it and plug it into a computer, infecting the host and any attached networks. Again, hackers may give them enticing labels, such as \"Employee Salaries\" or \"Confidential\".One study done in 2016 had researchers drop 297 USB drives around the campus of the University of Illinois. The drives contained files on them that linked to webpages owned by the researchers. The researchers were able to see how many of the drives had files on them opened, but not how many were inserted into a computer without having a file opened. Of the 297 drives that were dropped, 290 (98%) of them were picked up and 135 (45%) of them \"called home\".\n\n\n*** Quid pro quo ***\nQuid pro quo means something for something:\n\nAn attacker calls random numbers at a company, claiming to be calling back from technical support. Eventually this person will hit someone with a legitimate problem, grateful that someone is calling back to help them. The attacker will \"help\" solve the problem and, in the process, have the user type commands that give the attacker access or launch malware.\nIn a 2003 information security survey, 91% of office workers gave researchers what they claimed was their password in answer to a survey question in exchange for a cheap pen. Similar surveys in later years obtained similar results using chocolates and other cheap lures, although they made no attempt to validate the passwords.\n\n\n*** Tailgating ***\n\nAn attacker, seeking entry to a restricted area secured by unattended, electronic access control, e.g. by RFID card, simply walks in behind a person who has legitimate access. Following common courtesy, the legitimate person will usually hold the door open for the attacker or the attackers themselves may ask the employee to hold it open for them. The attacker will often purport to be on a phone call using a mobile to prevent questioning by an employee. The legitimate person may fail to ask for identification for any of several reasons, or may accept an assertion that the attacker has forgotten or lost the appropriate identity token. The attacker may also fake the action of presenting an identity token. \n\n\n*** Other types ***\nCommon confidence tricksters or fraudsters also could be considered \"social engineers\" in the wider sense, in that they deliberately deceive and manipulate people, exploiting human weaknesses to obtain personal benefit. They may, for example, use social engineering techniques as part of an IT fraud.\nAs of the early 2000s, another type of social engineering technique includes spoofing or hacking IDs of people having popular e-mail IDs such as Yahoo!, Gmail, or Hotmail. Additionally, some spoofing attempts included emails from major online service providers, like PayPal. This led to the \"proposed standard\" of Sender Policy Framework RFC 7208 dated April 2014, in combination with DMARC, as means to combat spoofing. Among the many motivations for this deception are:\n\nPhishing credit-card account numbers and their passwords.\nCracking private e-mails and chat histories, and manipulating them by using common editing techniques before using them to extort money and creating distrust among individuals.\nCracking websites of companies or organizations and destroying their reputation.\nComputer virus hoaxes\nConvincing users to run malicious code within the web browser via self-XSS attack to allow access to their web accountAnother type is to read sensitive information of unshielded or unprotected Displays and input devices, called Shoulder surfing.\n\n\n*** Countermeasures ***\nOrganizations reduce their security risks by:\nTraining to Employees: Training employees in security protocols relevant to their position. (e.g., in situations such as tailgating, if a person's identity cannot be verified, then employees must be trained to politely refuse.)\nStandard Framework: Establishing frameworks of trust on an employee/personnel level (i.e., specify and train personnel when/where/why/how sensitive information should be handled)\nScrutinizing Information: Identifying which information is sensitive and evaluating its exposure to social engineering and breakdowns in security systems (building, computer system, etc.)\nSecurity Protocols: Establishing security protocols, policies, and procedures for handling sensitive information.\nEvent Test: Performing unannounced, periodic tests of the security framework.\nInoculation: Preventing social engineering and other fraudulent tricks or traps by instilling a resistance to persuasion attempts through exposure to similar or related attempts.Review: Reviewing the above steps regularly: no solutions to information integrity are perfect.Waste Management: Using a waste management service that has dumpsters with locks on them, with keys to them limited only to the waste management company and the cleaning staff. Locating the dumpster either in view of employees so that trying to access it carries a risk of being seen or caught, or behind a locked gate or fence where the person must trespass before they can attempt to access the dumpster.\n\n== The lifecycle of social engineering ==\nInformation gathering: Information gathering is the first and foremost step of the lifecycle. It requires much patience and keenly watching habits of the victim. This step gathering data about the victim's interests, personal information. It determines the success rate of the overall attack.\nEngaging with victim: After gathering required amount of information, the attacker opens a conversation with the victim smoothly without the victim finding anything inappropriate.\nAttacking: This step generally occurs after a long period of engaging with the target and during this information from the target is retrieved by using social engineering. In phase, the attacker gets the results from the target.\nClosing interaction: This is the last step which includes slowly shutting down the communication by the attacker without arising any suspicion in the victim. In this way, the motive is fulfilled as well as the victim rarely realizes the attack even happened.\n\n== Notable social engineers ==\n\n\n*** Frank Abagnale Jr. ***\nFrank Abagnale Jr. is an American security consultant known for his background as a former con man, check forger, and impostor while he was between the ages of 15 and 21. He became one of the most notorious impostors, claiming to have assumed no fewer than eight identities, including an airline pilot, a physician, a U.S. Bureau of Prisons agent, and a lawyer. Abagnale escaped from police custody twice (once from a taxiing airliner and once from a U.S. federal penitentiary) before turning 22 years old. The popular Steven Spielberg movie Catch Me If You Can is based on his life.\n\n\n*** Kevin Mitnick ***\nKevin Mitnick is an American computer security consultant, author and hacker, best known for his high-profile 1995 arrest and later five-year conviction for various computer and communications-related crimes.\n\n\n*** Susan Headley ***\nSusan Headley was an American hacker active during the late 1970s and early 1980s widely respected for her expertise in social engineering, pretexting, and psychological subversion. She was known for her specialty in breaking into military computer systems, which often involved going to bed with military personnel and going through their clothes for usernames and passwords while they slept. She became heavily involved in phreaking with Kevin Mitnick and Lewis de Payne in Los Angeles, but later framed them for erasing the system files at US Leasing after a falling out, leading to Mitnick's first conviction. She retired to professional poker.\n\n\n*** James Linton ***\nJames Linton is a British hacker and social engineer who in 2017 used OSINT and spear phishing techniques to trick a variety of targets over email including the CEOs of Major Banks, and members of the Trump White House Administration. He then went to work in email security where he socially engineered BEC (Business Email Compromise) threat actors to collect specific threat intelligence.\n\n\n*** Mike Ridpath ***\nMike Ridpath Security consultant, published author, and speaker. Previous member of w00w00. Emphasizes techniques and tactics for social engineering cold calling. Became notable after his talks where he would play recorded calls and explain his thought process on what he was doing to get passwords through the phone and his live demonstrations. As a child Ridpath was connected with Badir Brothers and was widely known within the phreaking and hacking community for his articles with popular underground ezines, such as, Phrack, B4B0 and 9x on modifying Oki 900s, blueboxing, satellite hacking and RCMAC.\n\n\n*** Badir Brothers ***\nBrothers Ramy, Muzher, and Shadde Badir\u2014all of whom were blind from birth\u2014managed to set up an extensive phone and computer fraud scheme in Israel in the 1990s using social engineering, voice impersonation, and Braille-display computers.\n\n\n*** Christopher J. Hadnagy ***\nChristopher J. Hadnagy is an American social engineer and information technology security consultant.  He is best known as an author of 4 books on social engineering and cyber security and founder of Innocent Lives Foundation, an organization that helps tracking and identifying child trafficking using various security techniques such as seeking the assistance of information security specialists, utilizing data from open-source intelligence (OSINT) and collaborating with law enforcement.\n\n== Law ==\nIn common law, pretexting is an invasion of privacy tort of appropriation.\n\n\n*** Pretexting of telephone records ***\nIn December 2006, United States Congress approved a Senate sponsored bill making the pretexting of telephone records a federal felony with fines of up to $250,000 and ten years in prison for individuals (or fines of up to $500,000 for companies). It was signed by President George W. Bush on 12 January 2007.\n\n\n*** Federal legislation ***\nThe 1999 \"GLBA\" is a U.S. Federal law that specifically addresses pretexting of banking records as an illegal act punishable under federal statutes. When a business entity such as a private investigator, SIU insurance investigator, or an adjuster conducts any type of deception, it falls under the authority of the Federal Trade Commission (FTC). This federal agency has the obligation and authority to ensure that consumers are not subjected to any unfair or deceptive business practices. US Federal Trade Commission Act, Section 5 of the FTCA states, in part:\n\"Whenever the Commission shall have reason to believe that any such person, partnership, or corporation has been or is using any unfair method of competition or unfair or deceptive act or practice in or affecting commerce, and if it shall appear to the Commission that a proceeding by it in respect thereof would be to the interest of the public, it shall issue and serve upon such person, partnership, or corporation a complaint stating its charges in that respect.\"\nThe statute states that when someone obtains any personal, non-public information from a financial institution or the consumer, their action is subject to the statute. It relates to the consumer's relationship with the financial institution. For example, a pretexter using false pretenses either to get a consumer's address from the consumer's bank, or to get a consumer to disclose the name of their bank, would be covered. The determining principle is that pretexting only occurs when information is obtained through false pretenses.\nWhile the sale of cell telephone records has gained significant media attention, and telecommunications records are the focus of the two bills currently before the United States Senate, many other types of private records are being bought and sold in the public market. Alongside many advertisements for cell phone records, wireline records and the records associated with calling cards are advertised. As individuals shift to VoIP telephones, it is safe to assume that those records will be offered for sale as well. Currently, it is legal to sell telephone records, but illegal to obtain them.\n\n\n*** 1st Source Information Specialists ***\nU.S. Rep. Fred Upton (R-Kalamazoo, Michigan), chairman of the Energy and Commerce Subcommittee on Telecommunications and the Internet, expressed concern over the easy access to personal mobile phone records on the Internet during a House Energy & Commerce Committee hearing on \"Phone Records For Sale: Why Aren't Phone Records Safe From Pretexting?\" Illinois became the first state to sue an online records broker when Attorney General Lisa Madigan sued 1st Source Information Specialists, Inc. A spokeswoman for Madigan's office said. The Florida-based company operates several Web sites that sell mobile telephone records, according to a copy of the suit. The attorneys general of Florida and Missouri quickly followed Madigan's lead, filing suits respectively, against 1st Source Information Specialists and, in Missouri's case, one other records broker \u2013 First Data Solutions, Inc.\nSeveral wireless providers, including T-Mobile, Verizon, and Cingular filed earlier lawsuits against records brokers, with Cingular winning an injunction against First Data Solutions and 1st Source Information Specialists. U.S. Senator Charles Schumer (D-New York) introduced legislation in February 2006 aimed at curbing the practice. The Consumer Telephone Records Protection Act of 2006 would create felony criminal penalties for stealing and selling the records of mobile phone, landline, and Voice over Internet Protocol (VoIP) subscribers.\n\n\n*** Hewlett Packard ***\nPatricia Dunn, former chairwoman of Hewlett Packard, reported that the HP board hired a private investigation company to delve into who was responsible for leaks within the board. Dunn acknowledged that the company used the practice of pretexting to solicit the telephone records of board members and journalists. Chairman Dunn later apologized for this act and offered to step down from the board if it was desired by board members. Unlike Federal law, California law specifically forbids such pretexting. The four felony charges brought on Dunn were dismissed.\n\n== Preventive measures ==\nTaking some precautions reduces the risk of being a victim of social engineering frauds. The precautions that can be made are as follows:\n\nBe aware of offers that seem  \"Too good to be true\".\nUse multifactor authentication.\nAvoid clicking on attachments from unknown sources.\nNot giving out personal or financial information (such as credit card information, Social Security Numbers, or bank account information) to anyone via email, phone, or text messages.\nUse of spam filter software.\nAvoid befriending people that you do not know in real life.\nTeach kids to contact a trusted adult in case they are being bullied over the internet (cyberbullying) or feel threatened by anything online.\nDon't make instant decisions, but when possible take 5 minutes to evaluate the information presented.\n\nHow do tailgating attacks exploit unattended electronic access control systems?",
    "context": "",
    "output": "Tailgating attacks occur when an attacker seeks entry to a restricted area secured by unattended electronic access control, such as RFID card systems. The attacker follows a person who has legitimate access, often pretending to be on a phone call or presenting a fake identity token to gain entry.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do tailgating attacks exploit unattended electronic access control systems?",
      "answer": "Tailgating attacks occur when an attacker seeks entry to a restricted area secured by unattended electronic access control, such as RFID card systems. The attacker follows a person who has legitimate access, often pretending to be on a phone call or presenting a fake identity token to gain entry.",
      "context": "Social engineering (security)\n\n==Introduction==\nIn the context of information security, social engineering is the psychological manipulation of people into performing actions or divulging confidential information. A type of confidence trick for the purpose of information gathering, fraud, or system access, it differs from a traditional \"con\" in that it is often one of many steps in a more complex fraud scheme. It has also been defined as \"any act that influences a person to take an action that may or may not be in their best interests.\"An example of social engineering is an attacker calling a help desk, impersonating someone else, and claiming to have forgotten their password. If the help desk worker resets the password, it grants the attacker full access to the account.\n\n== Information security culture ==\nEmployee behaviour can have a big impact on information security in organizations. Cultural concepts can help different segments of the organization work effectively or work against effectiveness towards information security within an organization. \"Exploring the Relationship between Organizational Culture and Information Security Culture\" provides the following definition of information security culture: \"ISC is the totality of patterns of behavior in an organization that contribute to the protection of information of all kinds.\"Andersson and Reimers (2014) found that employees often do not see themselves as part of the organization Information Security \"effort\" and often take actions that ignore organizational information security best interests. Research shows Information security culture needs to be improved continuously. In \"Information Security Culture from Analysis to Change,\" authors commented that \"it's a never ending process, a cycle of evaluation and change or maintenance.\" They suggest that to manage information security culture, five steps should be taken: Pre-evaluation, strategic planning, operative planning, implementation, and post-evaluation.\nPre-Evaluation: to identify the awareness of information security within employees and to analyse current security policy.\nStrategic Planning: to come up with a better awareness-program, we need to set clear targets. Clustering people is helpful to achieve it.\nOperative Planning: set a good security culture based on internal communication, management-buy-in, and security awareness and training program.\nImplementation: four stages should be used to implement the information security culture. They are commitment of the management, communication with organizational members, courses for all organizational members, and commitment of the employees.\n\n== Techniques and terms ==\nAll social engineering techniques are based on specific attributes of human decision-making known as cognitive biases. These biases, sometimes called \"bugs in the human hardware,\u201d are exploited in various combinations to create attack techniques, some of which are listed below. The attacks used in social engineering can be used to steal employees' confidential information. The most common type of social engineering happens over the phone. Other examples of social engineering attacks are criminals posing as exterminators, fire marshals and technicians to go unnoticed as they steal company secrets.\nOne example of social engineering is an individual who walks into a building and posts an official-looking announcement to the company bulletin that says the number for the help desk has changed. So, when employees call for help the individual asks them for their passwords and IDs thereby gaining the ability to access the company's private information.\nAnother example of social engineering would be that the hacker contacts the target on a social networking site and starts a conversation with the target. Gradually the hacker gains the trust of the target and then uses that trust to get access to sensitive information like password or bank account details.Social engineering relies heavily on the six principles of influence established by Robert Cialdini. Cialdini's theory of influence is based on six key principles: reciprocity, commitment and consistency, social proof, authority, liking, scarcity.\n\n\n*** Six key principles ***\n\n\n**** Authority ****\nIn social engineering, the attacker may pose as authority to increase the likelihood of adherence from the victim.\n\n\n**** Intimidation ****\n\nAttacker (potentially disguised) informs or implies that there will be negative consequences if certain actions are not performed. Consequences could include subtle intimidation phrases such as \"I'll tell your manager\" to much worse.\n\n\n**** Consensus / Social proof ****\n\nPeople will do things that they see other people are doing. For example, in one experiment, one or more confederates would look up into the sky; bystanders would then look up into the sky to see what they were missing. At one point this experiment was aborted, as so many people were looking up that they stopped traffic. See conformity, and the Asch conformity experiments.\n\n\n**** Scarcity ****\n\nPerceived scarcity will generate demand. The common advertising phrase \"while supplies last\" capitalizes on a sense of scarcity. \n\n\n**** Urgency ****\nLinked to scarcity, attackers use urgency as a time-based psychological principle of social engineering. For example, saying offers are available for a \"limited time only\" encourages sales through a sense of urgency.\n\n\n**** Familiarity / Liking ****\n\nPeople are easily persuaded by other people whom they like. Cialdini cites the marketing of Tupperware in what might now be called viral marketing. People were more likely to buy if they liked the person selling it to them. Some of the many biases favoring more attractive people are discussed. See physical attractiveness stereotype.\n\n\n*** Four social engineering vectors ***\n\n\n**** Vishing ****\nVishing, otherwise known as \"voice phishing\", is the criminal practice of using social engineering over a telephone system to gain access to private personal and financial information from the public for the purpose of financial reward. It is also employed by attackers for reconnaissance purposes to gather more detailed intelligence on a target organization.\n\n\n**** Phishing ****\n\nPhishing is a technique of fraudulently obtaining private information. Typically, the phisher sends an e-mail that appears to come from a legitimate business\u2014a bank, or credit card company\u2014requesting \"verification\" of information and warning of some dire consequence if it is not provided. The e-mail usually contains a link to a fraudulent web page that seems legitimate\u2014with company logos and content\u2014and has a form requesting everything from a home address to an ATM card's PIN or a credit card number. For example, in 2003, there was a phishing scam in which users received emails supposedly from eBay claiming that the user's account was about to be suspended unless a link provided was clicked to update a credit card (information that the genuine eBay already had). By mimicking a legitimate organization's HTML code and logos, it is relatively simple to make a fake Website look authentic. The scam tricked some people into thinking that eBay was requiring them to update their account information by clicking on the link provided. By indiscriminately spamming extremely large groups of people, the \"phisher\" counted on gaining sensitive financial information from the small percentage (yet large number) of recipients who already have eBay accounts and also fall prey to the scam.\n\n\n**** Smishing ****\nThe act of using SMS text messaging to lure victims into a specific course of action, also known as \"smishing\". Like phishing it can be clicking on a malicious link or divulging information. Examples are text messages that claim to be from a common carrier (like FedEx) stating a package is in transit, with a link provided.\n\n\n**** Impersonation ****\nPretending or pretexting to be another person with the goal of gaining access physically to a system or building. Impersonation is used in the \"SIM swap scam\" fraud.\n\n== Other concepts ==\n\n\n*** Pretexting ***\n\nPretexting (adj. pretextual) is the act of creating and using an invented scenario (the pretext) to engage a targeted victim in a manner that increases the chance the victim will divulge information or perform actions that would be unlikely in ordinary circumstances. An elaborate lie, it most often involves some prior research or setup and the use of this information for impersonation (e.g., date of birth, Social Security number, last bill amount) to establish legitimacy in the mind of the target. As a background, pretexting can be interpreted as the first evolution of social engineering, and continued to develop as social engineering incorporated current-day technologies. Current and past examples of pretexting demonstrate this development.\nThis technique can be used to fool a business into disclosing customer information as well as by private investigators to obtain telephone records, utility records, banking records and other information directly from company service representatives. The information can then be used to establish even greater legitimacy under tougher questioning with a manager, e.g., to make account changes, get specific balances, etc.\nPretexting can also be used to impersonate co-workers, police, bank, tax authorities, clergy, insurance investigators\u2014or any other individual who could have perceived authority or right-to-know in the mind of the targeted victim. The pretexter must simply prepare answers to questions that might be asked by the victim. In some cases, all that is needed is a voice that sounds authoritative, an earnest tone, and an ability to think on one's feet to create a pretextual scenario.\n\n\n*** Vishing ***\n\nPhone phishing (or \"vishing\") uses a rogue interactive voice response (IVR) system to recreate a legitimate-sounding copy of a bank or other institution's IVR system. The victim is prompted (typically via a phishing e-mail) to call in to the \"bank\" via a (ideally toll free) number provided in order to \"verify\" information. A typical \"vishing\" system will reject log-ins continually, ensuring the victim enters PINs or passwords multiple times, often disclosing several different passwords. More advanced systems transfer the victim to the attacker/defrauder, who poses as a customer service agent or security expert for further questioning of the victim.\n\n\n*** Spear phishing ***\n\nAlthough similar to \"phishing\", spear phishing is a technique that fraudulently obtains private information by sending highly customized emails to few end users. It is the main difference between phishing attacks because phishing campaigns focus on sending out high volumes of generalized emails with the expectation that only a few people will respond. On the other hand, spear-phishing emails require the attacker to perform additional research on their targets in order to \"trick\" end users into performing requested activities. The success rate of spear-phishing attacks is considerably higher than phishing attacks with people opening roughly 3% of phishing emails when compared to roughly 70% of potential attempts. When users actually open the emails phishing emails have a relatively modest 5% success rate to have the link or attachment clicked when compared to a spear-phishing attack's 50% success rate.Spear-phishing success is heavily dependent on the amount and quality of OSINT (open-source intelligence) that the attacker can obtain. Social media account activity is one example of a source of OSINT.\n\n\n*** Water holing ***\n\nWater holing is a targeted social engineering strategy that capitalizes on the trust users have in websites they regularly visit. The victim feels safe to do things they would not do in a different situation. A wary person might, for example, purposefully avoid clicking a link in an unsolicited email, but the same person would not hesitate to follow a link on a website they often visit. So, the attacker prepares a trap for the unwary prey at a favored watering hole. This strategy has been successfully used to gain access to some (supposedly) very secure systems.The attacker may set out by identifying a group or individuals to target. The preparation involves gathering information about websites the targets often visit from the secure system. The information gathering confirms that the targets visit the websites and that the system allows such visits. The attacker then tests these websites for vulnerabilities to inject code that may infect a visitor's system with malware. The injected code trap and malware may be tailored to the specific target group and the specific systems they use. In time, one or more members of the target group will get infected and the attacker can gain access to the secure system.\n\n\n*** Baiting ***\nBaiting is like the real-world Trojan horse that uses physical media and relies on the curiosity or greed of the victim. In this attack, attackers leave malware-infected floppy disks, CD-ROMs, or USB flash drives in locations people will find them (bathrooms, elevators, sidewalks, parking lots, etc.), give them legitimate and curiosity-piquing labels, and wait for victims.\nFor example, an attacker may create a disk featuring a corporate logo, available from the target's website, and label it \"Executive Salary Summary Q2 2012\". The attacker then leaves the disk on the floor of an elevator or somewhere in the lobby of the target company. An unknowing employee may find it and insert the disk into a computer to satisfy their curiosity, or a good Samaritan may find it and return it to the company. In any case, just inserting the disk into a computer installs malware, giving attackers access to the victim's PC and, perhaps, the target company's internal computer network.\nUnless computer controls block infections, insertion compromises PCs \"auto-running\" media. Hostile devices can also be used. For instance, a \"lucky winner\" is sent a free digital audio player compromising any computer it is plugged to. A \"road apple\" (the colloquial term for horse manure, suggesting the device's undesirable nature) is any removable media with malicious software left in opportunistic or conspicuous places. It may be a CD, DVD, or USB flash drive, among other media. Curious people take it and plug it into a computer, infecting the host and any attached networks. Again, hackers may give them enticing labels, such as \"Employee Salaries\" or \"Confidential\".One study done in 2016 had researchers drop 297 USB drives around the campus of the University of Illinois. The drives contained files on them that linked to webpages owned by the researchers. The researchers were able to see how many of the drives had files on them opened, but not how many were inserted into a computer without having a file opened. Of the 297 drives that were dropped, 290 (98%) of them were picked up and 135 (45%) of them \"called home\".\n\n\n*** Quid pro quo ***\nQuid pro quo means something for something:\n\nAn attacker calls random numbers at a company, claiming to be calling back from technical support. Eventually this person will hit someone with a legitimate problem, grateful that someone is calling back to help them. The attacker will \"help\" solve the problem and, in the process, have the user type commands that give the attacker access or launch malware.\nIn a 2003 information security survey, 91% of office workers gave researchers what they claimed was their password in answer to a survey question in exchange for a cheap pen. Similar surveys in later years obtained similar results using chocolates and other cheap lures, although they made no attempt to validate the passwords.\n\n\n*** Tailgating ***\n\nAn attacker, seeking entry to a restricted area secured by unattended, electronic access control, e.g. by RFID card, simply walks in behind a person who has legitimate access. Following common courtesy, the legitimate person will usually hold the door open for the attacker or the attackers themselves may ask the employee to hold it open for them. The attacker will often purport to be on a phone call using a mobile to prevent questioning by an employee. The legitimate person may fail to ask for identification for any of several reasons, or may accept an assertion that the attacker has forgotten or lost the appropriate identity token. The attacker may also fake the action of presenting an identity token. \n\n\n*** Other types ***\nCommon confidence tricksters or fraudsters also could be considered \"social engineers\" in the wider sense, in that they deliberately deceive and manipulate people, exploiting human weaknesses to obtain personal benefit. They may, for example, use social engineering techniques as part of an IT fraud.\nAs of the early 2000s, another type of social engineering technique includes spoofing or hacking IDs of people having popular e-mail IDs such as Yahoo!, Gmail, or Hotmail. Additionally, some spoofing attempts included emails from major online service providers, like PayPal. This led to the \"proposed standard\" of Sender Policy Framework RFC 7208 dated April 2014, in combination with DMARC, as means to combat spoofing. Among the many motivations for this deception are:\n\nPhishing credit-card account numbers and their passwords.\nCracking private e-mails and chat histories, and manipulating them by using common editing techniques before using them to extort money and creating distrust among individuals.\nCracking websites of companies or organizations and destroying their reputation.\nComputer virus hoaxes\nConvincing users to run malicious code within the web browser via self-XSS attack to allow access to their web accountAnother type is to read sensitive information of unshielded or unprotected Displays and input devices, called Shoulder surfing.\n\n\n*** Countermeasures ***\nOrganizations reduce their security risks by:\nTraining to Employees: Training employees in security protocols relevant to their position. (e.g., in situations such as tailgating, if a person's identity cannot be verified, then employees must be trained to politely refuse.)\nStandard Framework: Establishing frameworks of trust on an employee/personnel level (i.e., specify and train personnel when/where/why/how sensitive information should be handled)\nScrutinizing Information: Identifying which information is sensitive and evaluating its exposure to social engineering and breakdowns in security systems (building, computer system, etc.)\nSecurity Protocols: Establishing security protocols, policies, and procedures for handling sensitive information.\nEvent Test: Performing unannounced, periodic tests of the security framework.\nInoculation: Preventing social engineering and other fraudulent tricks or traps by instilling a resistance to persuasion attempts through exposure to similar or related attempts.Review: Reviewing the above steps regularly: no solutions to information integrity are perfect.Waste Management: Using a waste management service that has dumpsters with locks on them, with keys to them limited only to the waste management company and the cleaning staff. Locating the dumpster either in view of employees so that trying to access it carries a risk of being seen or caught, or behind a locked gate or fence where the person must trespass before they can attempt to access the dumpster.\n\n== The lifecycle of social engineering ==\nInformation gathering: Information gathering is the first and foremost step of the lifecycle. It requires much patience and keenly watching habits of the victim. This step gathering data about the victim's interests, personal information. It determines the success rate of the overall attack.\nEngaging with victim: After gathering required amount of information, the attacker opens a conversation with the victim smoothly without the victim finding anything inappropriate.\nAttacking: This step generally occurs after a long period of engaging with the target and during this information from the target is retrieved by using social engineering. In phase, the attacker gets the results from the target.\nClosing interaction: This is the last step which includes slowly shutting down the communication by the attacker without arising any suspicion in the victim. In this way, the motive is fulfilled as well as the victim rarely realizes the attack even happened.\n\n== Notable social engineers ==\n\n\n*** Frank Abagnale Jr. ***\nFrank Abagnale Jr. is an American security consultant known for his background as a former con man, check forger, and impostor while he was between the ages of 15 and 21. He became one of the most notorious impostors, claiming to have assumed no fewer than eight identities, including an airline pilot, a physician, a U.S. Bureau of Prisons agent, and a lawyer. Abagnale escaped from police custody twice (once from a taxiing airliner and once from a U.S. federal penitentiary) before turning 22 years old. The popular Steven Spielberg movie Catch Me If You Can is based on his life.\n\n\n*** Kevin Mitnick ***\nKevin Mitnick is an American computer security consultant, author and hacker, best known for his high-profile 1995 arrest and later five-year conviction for various computer and communications-related crimes.\n\n\n*** Susan Headley ***\nSusan Headley was an American hacker active during the late 1970s and early 1980s widely respected for her expertise in social engineering, pretexting, and psychological subversion. She was known for her specialty in breaking into military computer systems, which often involved going to bed with military personnel and going through their clothes for usernames and passwords while they slept. She became heavily involved in phreaking with Kevin Mitnick and Lewis de Payne in Los Angeles, but later framed them for erasing the system files at US Leasing after a falling out, leading to Mitnick's first conviction. She retired to professional poker.\n\n\n*** James Linton ***\nJames Linton is a British hacker and social engineer who in 2017 used OSINT and spear phishing techniques to trick a variety of targets over email including the CEOs of Major Banks, and members of the Trump White House Administration. He then went to work in email security where he socially engineered BEC (Business Email Compromise) threat actors to collect specific threat intelligence.\n\n\n*** Mike Ridpath ***\nMike Ridpath Security consultant, published author, and speaker. Previous member of w00w00. Emphasizes techniques and tactics for social engineering cold calling. Became notable after his talks where he would play recorded calls and explain his thought process on what he was doing to get passwords through the phone and his live demonstrations. As a child Ridpath was connected with Badir Brothers and was widely known within the phreaking and hacking community for his articles with popular underground ezines, such as, Phrack, B4B0 and 9x on modifying Oki 900s, blueboxing, satellite hacking and RCMAC.\n\n\n*** Badir Brothers ***\nBrothers Ramy, Muzher, and Shadde Badir\u2014all of whom were blind from birth\u2014managed to set up an extensive phone and computer fraud scheme in Israel in the 1990s using social engineering, voice impersonation, and Braille-display computers.\n\n\n*** Christopher J. Hadnagy ***\nChristopher J. Hadnagy is an American social engineer and information technology security consultant.  He is best known as an author of 4 books on social engineering and cyber security and founder of Innocent Lives Foundation, an organization that helps tracking and identifying child trafficking using various security techniques such as seeking the assistance of information security specialists, utilizing data from open-source intelligence (OSINT) and collaborating with law enforcement.\n\n== Law ==\nIn common law, pretexting is an invasion of privacy tort of appropriation.\n\n\n*** Pretexting of telephone records ***\nIn December 2006, United States Congress approved a Senate sponsored bill making the pretexting of telephone records a federal felony with fines of up to $250,000 and ten years in prison for individuals (or fines of up to $500,000 for companies). It was signed by President George W. Bush on 12 January 2007.\n\n\n*** Federal legislation ***\nThe 1999 \"GLBA\" is a U.S. Federal law that specifically addresses pretexting of banking records as an illegal act punishable under federal statutes. When a business entity such as a private investigator, SIU insurance investigator, or an adjuster conducts any type of deception, it falls under the authority of the Federal Trade Commission (FTC). This federal agency has the obligation and authority to ensure that consumers are not subjected to any unfair or deceptive business practices. US Federal Trade Commission Act, Section 5 of the FTCA states, in part:\n\"Whenever the Commission shall have reason to believe that any such person, partnership, or corporation has been or is using any unfair method of competition or unfair or deceptive act or practice in or affecting commerce, and if it shall appear to the Commission that a proceeding by it in respect thereof would be to the interest of the public, it shall issue and serve upon such person, partnership, or corporation a complaint stating its charges in that respect.\"\nThe statute states that when someone obtains any personal, non-public information from a financial institution or the consumer, their action is subject to the statute. It relates to the consumer's relationship with the financial institution. For example, a pretexter using false pretenses either to get a consumer's address from the consumer's bank, or to get a consumer to disclose the name of their bank, would be covered. The determining principle is that pretexting only occurs when information is obtained through false pretenses.\nWhile the sale of cell telephone records has gained significant media attention, and telecommunications records are the focus of the two bills currently before the United States Senate, many other types of private records are being bought and sold in the public market. Alongside many advertisements for cell phone records, wireline records and the records associated with calling cards are advertised. As individuals shift to VoIP telephones, it is safe to assume that those records will be offered for sale as well. Currently, it is legal to sell telephone records, but illegal to obtain them.\n\n\n*** 1st Source Information Specialists ***\nU.S. Rep. Fred Upton (R-Kalamazoo, Michigan), chairman of the Energy and Commerce Subcommittee on Telecommunications and the Internet, expressed concern over the easy access to personal mobile phone records on the Internet during a House Energy & Commerce Committee hearing on \"Phone Records For Sale: Why Aren't Phone Records Safe From Pretexting?\" Illinois became the first state to sue an online records broker when Attorney General Lisa Madigan sued 1st Source Information Specialists, Inc. A spokeswoman for Madigan's office said. The Florida-based company operates several Web sites that sell mobile telephone records, according to a copy of the suit. The attorneys general of Florida and Missouri quickly followed Madigan's lead, filing suits respectively, against 1st Source Information Specialists and, in Missouri's case, one other records broker \u2013 First Data Solutions, Inc.\nSeveral wireless providers, including T-Mobile, Verizon, and Cingular filed earlier lawsuits against records brokers, with Cingular winning an injunction against First Data Solutions and 1st Source Information Specialists. U.S. Senator Charles Schumer (D-New York) introduced legislation in February 2006 aimed at curbing the practice. The Consumer Telephone Records Protection Act of 2006 would create felony criminal penalties for stealing and selling the records of mobile phone, landline, and Voice over Internet Protocol (VoIP) subscribers.\n\n\n*** Hewlett Packard ***\nPatricia Dunn, former chairwoman of Hewlett Packard, reported that the HP board hired a private investigation company to delve into who was responsible for leaks within the board. Dunn acknowledged that the company used the practice of pretexting to solicit the telephone records of board members and journalists. Chairman Dunn later apologized for this act and offered to step down from the board if it was desired by board members. Unlike Federal law, California law specifically forbids such pretexting. The four felony charges brought on Dunn were dismissed.\n\n== Preventive measures ==\nTaking some precautions reduces the risk of being a victim of social engineering frauds. The precautions that can be made are as follows:\n\nBe aware of offers that seem  \"Too good to be true\".\nUse multifactor authentication.\nAvoid clicking on attachments from unknown sources.\nNot giving out personal or financial information (such as credit card information, Social Security Numbers, or bank account information) to anyone via email, phone, or text messages.\nUse of spam filter software.\nAvoid befriending people that you do not know in real life.\nTeach kids to contact a trusted adult in case they are being bullied over the internet (cyberbullying) or feel threatened by anything online.\nDon't make instant decisions, but when possible take 5 minutes to evaluate the information presented."
    }
  },
  {
    "instruction": "Write an answer to the following question: How did the FBI use psychological warfare during COINTELPRO?",
    "context": "",
    "output": "During COINTELPRO, the FBI used psychological warfare by planting false media stories, publishing bogus leaflets and other publications in the name of targeted groups, forging correspondence, sending anonymous letters and making anonymous telephone calls, spreading misinformation about meetings and events, setting up pseudo movement groups run by government agents, and manipulating or strong-arming parents, employers, landlords, school officials, and others to cause trouble for activists.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How did the FBI use psychological warfare during COINTELPRO?",
      "answer": "During COINTELPRO, the FBI used psychological warfare by planting false media stories, publishing bogus leaflets and other publications in the name of targeted groups, forging correspondence, sending anonymous letters and making anonymous telephone calls, spreading misinformation about meetings and events, setting up pseudo movement groups run by government agents, and manipulating or strong-arming parents, employers, landlords, school officials, and others to cause trouble for activists."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does SEP aid in preventing exploits in the Application and Device control driver?",
    "context": "",
    "output": "In 2014, Offensive Security discovered an exploit in the Application and Device control driver of SEP during a penetration test of a financial services organization. The exploit allowed a logged-in user to get system access, but it was patched in August of the same year.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does SEP aid in preventing exploits in the Application and Device control driver?",
      "answer": "In 2014, Offensive Security discovered an exploit in the Application and Device control driver of SEP during a penetration test of a financial services organization. The exploit allowed a logged-in user to get system access, but it was patched in August of the same year."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is one method of physical piggybacking?",
    "context": "",
    "output": "One method of physical piggybacking is surreptitiously following an individual authorized to enter a location, giving the appearance of being legitimately escorted.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is one method of physical piggybacking?",
      "answer": "One method of physical piggybacking is surreptitiously following an individual authorized to enter a location, giving the appearance of being legitimately escorted."
    }
  },
  {
    "instruction": "Hacker culture\n\n==Introduction==\nThe hacker culture is a subculture of individuals who enjoy\u2014often in collective effort\u2014the intellectual challenge of creatively overcoming the limitations of software systems or electronic hardware (mostly digital electronics), to achieve novel and clever outcomes. The act of engaging in activities (such as programming or other media) in a spirit of playfulness and exploration is termed hacking. However, the defining characteristic of a hacker is not the activities performed themselves (e.g. programming), but how it is done and whether it is exciting and meaningful. Activities of playful cleverness can be said to have \"hack value\" and therefore the term \"hacks\" came about, with early examples including pranks at MIT done by students to demonstrate their technical aptitude and cleverness. The hacker culture originally emerged in academia in the 1960s around the Massachusetts Institute of Technology (MIT)'s Tech Model Railroad Club (TMRC) and MIT Artificial Intelligence Laboratory. Hacking originally involved entering restricted areas in a clever way without causing any major damage. Some famous hacks at the Massachusetts Institute of Technology were placing of a campus police cruiser on the roof of the Great Dome and converting the Great Dome into R2-D2.Richard Stallman explains about hackers who program:\n\nWhat they had in common was mainly love of excellence and programming. They wanted to make their programs that they used be as good as they could. They also wanted to make them do neat things. They wanted to be able to do something in a more exciting way than anyone believed possible and show \"Look how wonderful this is. I bet you didn't believe this could be done.\"\nHackers from this subculture tend to emphatically differentiate themselves from what they pejoratively call \"crackers\"; those who are generally referred to by media and members of the general public using the term \"hacker\", and whose primary focus\u200d\u2014\u200cbe it to malign or for malevolent purposes\u200d\u2014\u200clies in exploiting weaknesses in computer security.\n\n\n\n== Definition ==\nThe Jargon File, an influential but not universally accepted compendium of hacker slang, defines hacker as \"A person who enjoys exploring the details of programmable systems and stretching their capabilities, as opposed to most users, who prefer to learn only the minimum necessary.\" The Request for Comments (RFC) 1392, the Internet Users' Glossary, amplifies this meaning as \"A person who delights in having an intimate understanding of the internal workings of a system, computers and computer networks in particular.\"As documented in the Jargon File, these hackers are disappointed by the mass media and general public's usage of the word hacker to refer to security breakers, calling them \"crackers\" instead. This includes both \"good\" crackers (\"white hat hackers\"), who use their computer security-related skills and knowledge to learn more about how systems and networks work and to help to discover and fix security holes, as well as those more \"evil\" crackers (\"black hat hackers\"), who use the same skills to author harmful software (such as viruses or trojans) and illegally infiltrate secure systems with the intention of doing harm to the system. The programmer subculture of hackers, in contrast to the cracker community, generally sees computer security-related activities as contrary to the ideals of the original and true meaning of the hacker term, that instead related to playful cleverness.\n\n== Ethics and principles ==\n\nMany of the values and tenets of the free and open source software movement stem from the hacker ethics that originated at MIT and at the Homebrew Computer Club. The hacker ethics were chronicled by Steven Levy in Hackers: Heroes of the Computer Revolution and in other texts in which Levy formulates and summarizes general hacker attitudes:\n\nAccess to computers-and anything that might teach you something about the way the world works-should be unlimited and total.\nAll information should be free.\nHackers should be judged by their hacking, not bogus criteria such as degrees, age, race, or position.\nYou can create art and beauty on a computer.\nComputers can change your life for the better.Hacker ethics are concerned primarily with sharing, openness, collaboration, and engaging in the hands-on imperative.Linus Torvalds, one of the leaders of the open source movement (known primarily for developing the Linux kernel), has noted in the book The Hacker Ethic that these principles have evolved from the known Protestant ethics and incorporates the spirits of capitalism, as introduced in the early 20th century by Max Weber.\nHack value is the notion used by hackers to express that something is worth doing or is interesting. This is something that hackers often feel intuitively about a problem or solution.\nAn aspect of hack value is performing feats for the sake of showing that they can be done, even if others think it is difficult. Using things in a unique way outside their intended purpose is often perceived as having hack value. Examples are using a dot matrix impact printer to produce musical notes, using a flatbed scanner to take ultra-high-resolution photographs or using an optical mouse as barcode reader.\nA solution or feat has \"hack value\" if it is done in a way that has finesse, cleverness or brilliance, which makes creativity an essential part of the meaning. For example, picking a difficult lock has hack value; smashing it does not. As another example, proving Fermat's Last Theorem by linking together most of modern mathematics has hack value; solving a combinatorial problem by exhaustively trying all possibilities does not. Hacking is not using process of elimination to find a solution; it's the process of finding a clever solution to a problem.\n\n== Uses ==\nWhile using hacker to refer to someone who enjoys playful cleverness is most often applied to computer programmers, it is sometimes used for people who apply the same attitude to other fields. For example, Richard Stallman describes the silent composition 4\u203233\u2033 by John Cage and the 14th-century palindromic three-part piece \"Ma Fin Est Mon Commencement\" by Guillaume de Machaut as hacks. According to the Jargon File, the word hacker was used in a similar sense among radio amateurs in the 1950s, predating the software hacking community.\n\n\n*** Programming ***\nThe Boston Globe in 1984 defined \"hackers\" as \"computer nuts\". In their programmer subculture, a hacker is a person who follows a spirit of playful cleverness and loves programming. It is found in an originally academic movement unrelated to computer security and most visibly associated with free software, open source and demoscene. It also has a hacker ethic, based on the idea that writing software and sharing the result on a voluntary basis is a good idea, and that information should be free, but that it's not up to the hacker to make it free by breaking into private computer systems. This hacker ethic was publicized and perhaps originated in Steven Levy's Hackers: Heroes of the Computer Revolution (1984). It contains a codification of its principles.\nThe programmer subculture of hackers disassociates from the mass media's pejorative use of the word 'hacker' referring to computer security, and usually prefer the term 'cracker' for that meaning. Complaints about supposed mainstream misuse started as early as 1983, when media used \"hacker\" to refer to the computer criminals involved in The 414s case.In the programmer subculture of hackers, a computer hacker is a person who enjoys designing software and building programs with a sense for aesthetics and playful cleverness. The term hack in this sense can be traced back to \"describe the elaborate college pranks that...students would regularly devise\" (Levy, 1984 p. 10). To be considered a 'hack' was an honor among like-minded peers as \"to qualify as a hack, the feat must be imbued with innovation, style and technical virtuosity\" (Levy, 1984 p. 10) The MIT Tech Model Railroad Club Dictionary defined hack in 1959 (not yet in a computer context) as \"1) an article or project without constructive end; 2) a project undertaken on bad self-advice; 3) an entropy booster; 4) to produce, or attempt to produce, a hack(3)\", and \"hacker\" was defined as \"one who hacks, or makes them\". Much of TMRC's jargon was later imported into early computing culture, because the club started using a DEC PDP-1 and applied its local model railroad slang in this computing context. Initially incomprehensible to outsiders, the slang also became popular in MIT's computing environments beyond the club. Other examples of jargon imported from the club are 'losing' (\"when a piece of equipment is not working\") and 'munged' (\"when a piece of equipment is ruined\").Others did not always view hackers with approval. MIT living groups in 1989 avoided advertising their sophisticated Project Athena workstations to prospective members because they wanted residents who were interested in people, not computers, with one fraternity member stating that \"We were worried about the hacker subculture\".According to Eric S. Raymond, the Open Source and Free Software hacker subculture developed in the 1960s among 'academic hackers' working on early minicomputers in computer science environments in the United States.\nHackers were influenced by and absorbed many ideas of key technological developments and the people associated with them. Most notable is the technical culture of the pioneers of the ARPANET, starting in 1969. The PDP-10 AI machine at MIT, running the ITS operating system and connected to the ARPANET, provided an early hacker meeting point. After 1980 the subculture coalesced with the culture of Unix. Since the mid-1990s, it has been largely coincident with what is now called the free software and open source movement.\nMany programmers have been labeled \"great hackers\", but the specifics of who that label applies to is a matter of opinion. Certainly major contributors to computer science such as Edsger Dijkstra and Donald Knuth, as well as the inventors of popular software such as Linus Torvalds (Linux), and Ken Thompson and Dennis Ritchie (Unix and C programming language) are likely to be included in any such list; see also List of programmers. People primarily known for their contributions to the consciousness of the programmer subculture of hackers include Richard Stallman, the founder of the free software movement and the GNU project, president of the Free Software Foundation and author of the famous Emacs text editor as well as the GNU Compiler Collection (GCC), and Eric S. Raymond, one of the founders of the Open Source Initiative and writer of the famous text The Cathedral and the Bazaar and many other essays, maintainer of the Jargon File (which was previously maintained by Guy L. Steele, Jr.).\nWithin the computer programmer subculture of hackers, the term hacker is also used for a programmer who reaches a goal by employing a series of modifications to extend existing code or resources. In this sense, it can have a negative connotation of using inelegant kludges to accomplish programming tasks that are quick, but ugly, inelegant, difficult to extend, hard to maintain and inefficient. This derogatory form of the noun \"hack\" derives from the everyday English sense \"to cut or shape by or as if by crude or ruthless strokes\" [Merriam-Webster] and is even used among users of the positive sense of \"hacker\" who produces \"cool\" or \"neat\" hacks. In other words, to \"hack\" at an original creation, as if with an axe, is to force-fit it into being usable for a task not intended by the original creator, and a \"hacker\" would be someone who does this habitually. (The original creator and the hacker may be the same person.) This usage is common in both programming, engineering and building. In programming, hacking in this sense appears to be tolerated and seen as a necessary compromise in many situations. Some argue that it should not be, due to this negative meaning; others argue that some kludges can, for all their ugliness and imperfection, still have \"hack value\".\nIn non-software engineering, the culture is less tolerant of unmaintainable solutions, even when intended to be temporary, and describing someone as a \"hacker\" might imply that they lack professionalism. In this sense, the term has no real positive connotations, except for the idea that the hacker is capable of doing modifications that allow a system to work in the short term, and so has some sort of marketable skills. However, there is always the understanding that a more skillful or technical logician could have produced successful modifications that would not be considered a \"hack-job\". The definition is similar to other, non-computer based uses of the term \"hack-job\". For instance, a professional modification of a production sports car into a racing machine would not be considered a hack-job, but a cobbled together backyard mechanic's result could be. Even though the outcome of a race of the two machines could not be assumed, a quick inspection would instantly reveal the difference in the level of professionalism of the designers. The adjective associated with hacker is \"hackish\" (see the Jargon file).\nIn a very universal sense, hacker also means someone who makes things work beyond perceived limits in a clever way in general, without necessarily referring to computers, especially at MIT. That is, people who apply the creative attitude of software hackers in fields other than computing. This includes even activities that predate computer hacking, for example reality hackers or urban spelunkers (exploring undocumented or unauthorized areas in buildings). One specific example is clever pranks traditionally perpetrated by MIT students, with the perpetrator being called hacker. For example, when MIT students surreptitiously put a fake police car atop the dome on MIT's Building 10, that was a hack in this sense, and the students involved were therefore hackers. Other types of hacking are reality hackers, wetware hackers (\"hack your brain\"), and media hackers (\"hack your reputation\"). In a similar vein, a \"hack\" may refer to a math hack, that is, a clever solution to a mathematical problem. All of these uses have spread beyond MIT.\n\n\n*** Home computing enthusiasts ***\n\nIn yet another context, a hacker is a computer hobbyist who pushes the limits of software or hardware. The home computer hacking subculture relates to the hobbyist home computing of the late 1970s, beginning with the availability of MITS Altair. An influential organization was the Homebrew Computer Club. However, its roots go back further to amateur radio enthusiasts. The amateur radio slang referred to creatively tinkering to improve performance as \"hacking\" already in the 1950s.A large overlaps between hobbyist hackers and the programmer subculture hackers existed during the Homebrew Club's days, but the interests and values of both communities somewhat diverged. Today, the hobbyists focus on commercial computer and video games, software cracking and exceptional computer programming (demo scene). Also of interest to some members of this group is the modification of computer hardware and other electronic devices, see modding.\n\nElectronics hobbyists working on machines other than computers also fall into this category. This includes people who do simple modifications to graphing calculators, video game consoles, electronic musical keyboards or other device (see CueCat for a notorious example) to expose or add functionality to a device that was unintended for use by end users by the company who created it. A number of techno musicians have modified 1980s-era Casio SK-1 sampling keyboards to create unusual sounds by doing circuit bending: connecting wires to different leads of the integrated circuit chips. The results of these DIY experiments range from opening up previously inaccessible features that were part of the chip design to producing the strange, dis-harmonic digital tones that became part of the techno music style.\nCompanies take different attitudes towards such practices, ranging from open acceptance (such as Texas Instruments for its graphing calculators and Lego for its Lego Mindstorms robotics gear) to outright hostility (such as Microsoft's attempts to lock out Xbox hackers or the DRM routines on Blu-ray Disc players designed to sabotage compromised players.)\nIn this context, a \"hack\" refers to a program that (sometimes illegally) modifies another program, often a video game, giving the user access to features otherwise inaccessible to them. As an example of this use, for Palm OS users (until the 4th iteration of this operating system), a \"hack\" refers to an extension of the operating system which provides additional functionality. Term also refers to those people who cheat on video games using special software. This can also refer to the jailbreaking of iPhones.\n\n\n*** Hacker artists ***\n\nHacker artists create art by hacking on technology as an artistic medium. This has extended the definition of the term and what it means to be a hacker. Such artists may work with graphics, computer hardware, sculpture, music and other audio, animation, video, software, simulations, mathematics, reactive sensory systems, text, poetry, literature, or any combination thereof.\nDartmouth College musician Larry Polansky states:\n\nTechnology and art are inextricably related. Many musicians, video artists, graphic artists, and even poets who work with technology\u2014whether designing it or using it\u2014consider themselves to be part of the 'hacker community.' Computer artists, like non-art hackers, often find themselves on society's fringes, developing strange, innovative uses of existing technology. There is an empathetic relationship between those, for example, who design experimental music software and hackers who write communications freeware.\nAnother description is offered by Jenny Marketou: \n\nHacker artists operate as culture hackers who manipulate existing techno-semiotic structures towards a different end, to get inside cultural systems on the net and make them do things they were never intended to do.\nA successful software and hardware hacker artist is Mark Lottor (mkl), who has created the 3-D light art projects entitled the Cubatron, and the Big Round Cubatron. This art is made using custom computer technology, with specially designed circuit boards and programming for microprocessor chips to manipulate the LED lights.\n\nDon Hopkins is a software hacker artist well known for his artistic cellular automata. This art, created by a cellular automata computer program, generates objects which randomly bump into each other and in turn create more objects and designs, similar to a lava lamp, except that the parts change color and form through interaction. Hopkins Says: Cellular automata are simple rules that are applied to a grid of cells, or the pixel values of an image. The same rule is applied to every cell, to determine its next state, based on the previous state of that cell and its neighboring cells. There are many interesting cellular automata rules, and they all look very different, with amazing animated dynamic effects. 'Life' is a widely known cellular automata rule, but many other lesser known rules are much more interesting.\nSome hacker artists create art by writing computer code, and others, by developing hardware. Some create with existing software tools such as Adobe Photoshop or GIMP.\nThe creative process of hacker artists can be more abstract than artists using non-technological media. For example, mathematicians have produced visually stunning graphic presentations of fractals, which hackers have further enhanced, often producing detailed and intricate graphics and animations from simple mathematical formulas.\n\n\t\t\n\t\t\n\t\t\n\t\t\n\n\n**** Art ****\n\n\n**** Hacker art mentions ****\n\"Vector in Open Space\" by Gerfried Stocker 1996.\nSwitch|Journal Jun 14 1998.\nEye Weekly \"Tag \u2013 who's it?\" by Ingrid Hein, July 16, 1998.\nLinux Today Archived 2011-07-09 at the Wayback Machine \"Playing the Open Source Game\" by Shawn Hargreaves, Jul 5, 1999.\nCanterbury Christ Church University Library Resources by Subject \u2013 Art & Design, 2001.\nSuperCollider Workshop / Seminar Joel Ryan describes collaboration with hacker artists of Silicon Valley. 21 March 2002\nAnthony Barker's Weblog on Linux, Technology and the Economy \"Why Geeks Love Linux\", Sept 2003.\nLive Art Research Gesture and Response in Field-Based Performance by Sha Xin Wei & Satinder Gill, 2005.\nHackers, Who Are They \"The Hackers Identity\", October 2014.\nRead the text above and answer this question: What is the origin of the term \"hackers\" in the context of computer security?",
    "context": "",
    "output": "The term \"hackers\" in the context of computer security was originally used in the mass media to refer to the computer criminals involved in The 414s case in 1983.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the origin of the term \"hackers\" in the context of computer security?",
      "answer": "The term \"hackers\" in the context of computer security was originally used in the mass media to refer to the computer criminals involved in The 414s case in 1983.",
      "context": "Hacker culture\n\n==Introduction==\nThe hacker culture is a subculture of individuals who enjoy\u2014often in collective effort\u2014the intellectual challenge of creatively overcoming the limitations of software systems or electronic hardware (mostly digital electronics), to achieve novel and clever outcomes. The act of engaging in activities (such as programming or other media) in a spirit of playfulness and exploration is termed hacking. However, the defining characteristic of a hacker is not the activities performed themselves (e.g. programming), but how it is done and whether it is exciting and meaningful. Activities of playful cleverness can be said to have \"hack value\" and therefore the term \"hacks\" came about, with early examples including pranks at MIT done by students to demonstrate their technical aptitude and cleverness. The hacker culture originally emerged in academia in the 1960s around the Massachusetts Institute of Technology (MIT)'s Tech Model Railroad Club (TMRC) and MIT Artificial Intelligence Laboratory. Hacking originally involved entering restricted areas in a clever way without causing any major damage. Some famous hacks at the Massachusetts Institute of Technology were placing of a campus police cruiser on the roof of the Great Dome and converting the Great Dome into R2-D2.Richard Stallman explains about hackers who program:\n\nWhat they had in common was mainly love of excellence and programming. They wanted to make their programs that they used be as good as they could. They also wanted to make them do neat things. They wanted to be able to do something in a more exciting way than anyone believed possible and show \"Look how wonderful this is. I bet you didn't believe this could be done.\"\nHackers from this subculture tend to emphatically differentiate themselves from what they pejoratively call \"crackers\"; those who are generally referred to by media and members of the general public using the term \"hacker\", and whose primary focus\u200d\u2014\u200cbe it to malign or for malevolent purposes\u200d\u2014\u200clies in exploiting weaknesses in computer security.\n\n\n\n== Definition ==\nThe Jargon File, an influential but not universally accepted compendium of hacker slang, defines hacker as \"A person who enjoys exploring the details of programmable systems and stretching their capabilities, as opposed to most users, who prefer to learn only the minimum necessary.\" The Request for Comments (RFC) 1392, the Internet Users' Glossary, amplifies this meaning as \"A person who delights in having an intimate understanding of the internal workings of a system, computers and computer networks in particular.\"As documented in the Jargon File, these hackers are disappointed by the mass media and general public's usage of the word hacker to refer to security breakers, calling them \"crackers\" instead. This includes both \"good\" crackers (\"white hat hackers\"), who use their computer security-related skills and knowledge to learn more about how systems and networks work and to help to discover and fix security holes, as well as those more \"evil\" crackers (\"black hat hackers\"), who use the same skills to author harmful software (such as viruses or trojans) and illegally infiltrate secure systems with the intention of doing harm to the system. The programmer subculture of hackers, in contrast to the cracker community, generally sees computer security-related activities as contrary to the ideals of the original and true meaning of the hacker term, that instead related to playful cleverness.\n\n== Ethics and principles ==\n\nMany of the values and tenets of the free and open source software movement stem from the hacker ethics that originated at MIT and at the Homebrew Computer Club. The hacker ethics were chronicled by Steven Levy in Hackers: Heroes of the Computer Revolution and in other texts in which Levy formulates and summarizes general hacker attitudes:\n\nAccess to computers-and anything that might teach you something about the way the world works-should be unlimited and total.\nAll information should be free.\nHackers should be judged by their hacking, not bogus criteria such as degrees, age, race, or position.\nYou can create art and beauty on a computer.\nComputers can change your life for the better.Hacker ethics are concerned primarily with sharing, openness, collaboration, and engaging in the hands-on imperative.Linus Torvalds, one of the leaders of the open source movement (known primarily for developing the Linux kernel), has noted in the book The Hacker Ethic that these principles have evolved from the known Protestant ethics and incorporates the spirits of capitalism, as introduced in the early 20th century by Max Weber.\nHack value is the notion used by hackers to express that something is worth doing or is interesting. This is something that hackers often feel intuitively about a problem or solution.\nAn aspect of hack value is performing feats for the sake of showing that they can be done, even if others think it is difficult. Using things in a unique way outside their intended purpose is often perceived as having hack value. Examples are using a dot matrix impact printer to produce musical notes, using a flatbed scanner to take ultra-high-resolution photographs or using an optical mouse as barcode reader.\nA solution or feat has \"hack value\" if it is done in a way that has finesse, cleverness or brilliance, which makes creativity an essential part of the meaning. For example, picking a difficult lock has hack value; smashing it does not. As another example, proving Fermat's Last Theorem by linking together most of modern mathematics has hack value; solving a combinatorial problem by exhaustively trying all possibilities does not. Hacking is not using process of elimination to find a solution; it's the process of finding a clever solution to a problem.\n\n== Uses ==\nWhile using hacker to refer to someone who enjoys playful cleverness is most often applied to computer programmers, it is sometimes used for people who apply the same attitude to other fields. For example, Richard Stallman describes the silent composition 4\u203233\u2033 by John Cage and the 14th-century palindromic three-part piece \"Ma Fin Est Mon Commencement\" by Guillaume de Machaut as hacks. According to the Jargon File, the word hacker was used in a similar sense among radio amateurs in the 1950s, predating the software hacking community.\n\n\n*** Programming ***\nThe Boston Globe in 1984 defined \"hackers\" as \"computer nuts\". In their programmer subculture, a hacker is a person who follows a spirit of playful cleverness and loves programming. It is found in an originally academic movement unrelated to computer security and most visibly associated with free software, open source and demoscene. It also has a hacker ethic, based on the idea that writing software and sharing the result on a voluntary basis is a good idea, and that information should be free, but that it's not up to the hacker to make it free by breaking into private computer systems. This hacker ethic was publicized and perhaps originated in Steven Levy's Hackers: Heroes of the Computer Revolution (1984). It contains a codification of its principles.\nThe programmer subculture of hackers disassociates from the mass media's pejorative use of the word 'hacker' referring to computer security, and usually prefer the term 'cracker' for that meaning. Complaints about supposed mainstream misuse started as early as 1983, when media used \"hacker\" to refer to the computer criminals involved in The 414s case.In the programmer subculture of hackers, a computer hacker is a person who enjoys designing software and building programs with a sense for aesthetics and playful cleverness. The term hack in this sense can be traced back to \"describe the elaborate college pranks that...students would regularly devise\" (Levy, 1984 p. 10). To be considered a 'hack' was an honor among like-minded peers as \"to qualify as a hack, the feat must be imbued with innovation, style and technical virtuosity\" (Levy, 1984 p. 10) The MIT Tech Model Railroad Club Dictionary defined hack in 1959 (not yet in a computer context) as \"1) an article or project without constructive end; 2) a project undertaken on bad self-advice; 3) an entropy booster; 4) to produce, or attempt to produce, a hack(3)\", and \"hacker\" was defined as \"one who hacks, or makes them\". Much of TMRC's jargon was later imported into early computing culture, because the club started using a DEC PDP-1 and applied its local model railroad slang in this computing context. Initially incomprehensible to outsiders, the slang also became popular in MIT's computing environments beyond the club. Other examples of jargon imported from the club are 'losing' (\"when a piece of equipment is not working\") and 'munged' (\"when a piece of equipment is ruined\").Others did not always view hackers with approval. MIT living groups in 1989 avoided advertising their sophisticated Project Athena workstations to prospective members because they wanted residents who were interested in people, not computers, with one fraternity member stating that \"We were worried about the hacker subculture\".According to Eric S. Raymond, the Open Source and Free Software hacker subculture developed in the 1960s among 'academic hackers' working on early minicomputers in computer science environments in the United States.\nHackers were influenced by and absorbed many ideas of key technological developments and the people associated with them. Most notable is the technical culture of the pioneers of the ARPANET, starting in 1969. The PDP-10 AI machine at MIT, running the ITS operating system and connected to the ARPANET, provided an early hacker meeting point. After 1980 the subculture coalesced with the culture of Unix. Since the mid-1990s, it has been largely coincident with what is now called the free software and open source movement.\nMany programmers have been labeled \"great hackers\", but the specifics of who that label applies to is a matter of opinion. Certainly major contributors to computer science such as Edsger Dijkstra and Donald Knuth, as well as the inventors of popular software such as Linus Torvalds (Linux), and Ken Thompson and Dennis Ritchie (Unix and C programming language) are likely to be included in any such list; see also List of programmers. People primarily known for their contributions to the consciousness of the programmer subculture of hackers include Richard Stallman, the founder of the free software movement and the GNU project, president of the Free Software Foundation and author of the famous Emacs text editor as well as the GNU Compiler Collection (GCC), and Eric S. Raymond, one of the founders of the Open Source Initiative and writer of the famous text The Cathedral and the Bazaar and many other essays, maintainer of the Jargon File (which was previously maintained by Guy L. Steele, Jr.).\nWithin the computer programmer subculture of hackers, the term hacker is also used for a programmer who reaches a goal by employing a series of modifications to extend existing code or resources. In this sense, it can have a negative connotation of using inelegant kludges to accomplish programming tasks that are quick, but ugly, inelegant, difficult to extend, hard to maintain and inefficient. This derogatory form of the noun \"hack\" derives from the everyday English sense \"to cut or shape by or as if by crude or ruthless strokes\" [Merriam-Webster] and is even used among users of the positive sense of \"hacker\" who produces \"cool\" or \"neat\" hacks. In other words, to \"hack\" at an original creation, as if with an axe, is to force-fit it into being usable for a task not intended by the original creator, and a \"hacker\" would be someone who does this habitually. (The original creator and the hacker may be the same person.) This usage is common in both programming, engineering and building. In programming, hacking in this sense appears to be tolerated and seen as a necessary compromise in many situations. Some argue that it should not be, due to this negative meaning; others argue that some kludges can, for all their ugliness and imperfection, still have \"hack value\".\nIn non-software engineering, the culture is less tolerant of unmaintainable solutions, even when intended to be temporary, and describing someone as a \"hacker\" might imply that they lack professionalism. In this sense, the term has no real positive connotations, except for the idea that the hacker is capable of doing modifications that allow a system to work in the short term, and so has some sort of marketable skills. However, there is always the understanding that a more skillful or technical logician could have produced successful modifications that would not be considered a \"hack-job\". The definition is similar to other, non-computer based uses of the term \"hack-job\". For instance, a professional modification of a production sports car into a racing machine would not be considered a hack-job, but a cobbled together backyard mechanic's result could be. Even though the outcome of a race of the two machines could not be assumed, a quick inspection would instantly reveal the difference in the level of professionalism of the designers. The adjective associated with hacker is \"hackish\" (see the Jargon file).\nIn a very universal sense, hacker also means someone who makes things work beyond perceived limits in a clever way in general, without necessarily referring to computers, especially at MIT. That is, people who apply the creative attitude of software hackers in fields other than computing. This includes even activities that predate computer hacking, for example reality hackers or urban spelunkers (exploring undocumented or unauthorized areas in buildings). One specific example is clever pranks traditionally perpetrated by MIT students, with the perpetrator being called hacker. For example, when MIT students surreptitiously put a fake police car atop the dome on MIT's Building 10, that was a hack in this sense, and the students involved were therefore hackers. Other types of hacking are reality hackers, wetware hackers (\"hack your brain\"), and media hackers (\"hack your reputation\"). In a similar vein, a \"hack\" may refer to a math hack, that is, a clever solution to a mathematical problem. All of these uses have spread beyond MIT.\n\n\n*** Home computing enthusiasts ***\n\nIn yet another context, a hacker is a computer hobbyist who pushes the limits of software or hardware. The home computer hacking subculture relates to the hobbyist home computing of the late 1970s, beginning with the availability of MITS Altair. An influential organization was the Homebrew Computer Club. However, its roots go back further to amateur radio enthusiasts. The amateur radio slang referred to creatively tinkering to improve performance as \"hacking\" already in the 1950s.A large overlaps between hobbyist hackers and the programmer subculture hackers existed during the Homebrew Club's days, but the interests and values of both communities somewhat diverged. Today, the hobbyists focus on commercial computer and video games, software cracking and exceptional computer programming (demo scene). Also of interest to some members of this group is the modification of computer hardware and other electronic devices, see modding.\n\nElectronics hobbyists working on machines other than computers also fall into this category. This includes people who do simple modifications to graphing calculators, video game consoles, electronic musical keyboards or other device (see CueCat for a notorious example) to expose or add functionality to a device that was unintended for use by end users by the company who created it. A number of techno musicians have modified 1980s-era Casio SK-1 sampling keyboards to create unusual sounds by doing circuit bending: connecting wires to different leads of the integrated circuit chips. The results of these DIY experiments range from opening up previously inaccessible features that were part of the chip design to producing the strange, dis-harmonic digital tones that became part of the techno music style.\nCompanies take different attitudes towards such practices, ranging from open acceptance (such as Texas Instruments for its graphing calculators and Lego for its Lego Mindstorms robotics gear) to outright hostility (such as Microsoft's attempts to lock out Xbox hackers or the DRM routines on Blu-ray Disc players designed to sabotage compromised players.)\nIn this context, a \"hack\" refers to a program that (sometimes illegally) modifies another program, often a video game, giving the user access to features otherwise inaccessible to them. As an example of this use, for Palm OS users (until the 4th iteration of this operating system), a \"hack\" refers to an extension of the operating system which provides additional functionality. Term also refers to those people who cheat on video games using special software. This can also refer to the jailbreaking of iPhones.\n\n\n*** Hacker artists ***\n\nHacker artists create art by hacking on technology as an artistic medium. This has extended the definition of the term and what it means to be a hacker. Such artists may work with graphics, computer hardware, sculpture, music and other audio, animation, video, software, simulations, mathematics, reactive sensory systems, text, poetry, literature, or any combination thereof.\nDartmouth College musician Larry Polansky states:\n\nTechnology and art are inextricably related. Many musicians, video artists, graphic artists, and even poets who work with technology\u2014whether designing it or using it\u2014consider themselves to be part of the 'hacker community.' Computer artists, like non-art hackers, often find themselves on society's fringes, developing strange, innovative uses of existing technology. There is an empathetic relationship between those, for example, who design experimental music software and hackers who write communications freeware.\nAnother description is offered by Jenny Marketou: \n\nHacker artists operate as culture hackers who manipulate existing techno-semiotic structures towards a different end, to get inside cultural systems on the net and make them do things they were never intended to do.\nA successful software and hardware hacker artist is Mark Lottor (mkl), who has created the 3-D light art projects entitled the Cubatron, and the Big Round Cubatron. This art is made using custom computer technology, with specially designed circuit boards and programming for microprocessor chips to manipulate the LED lights.\n\nDon Hopkins is a software hacker artist well known for his artistic cellular automata. This art, created by a cellular automata computer program, generates objects which randomly bump into each other and in turn create more objects and designs, similar to a lava lamp, except that the parts change color and form through interaction. Hopkins Says: Cellular automata are simple rules that are applied to a grid of cells, or the pixel values of an image. The same rule is applied to every cell, to determine its next state, based on the previous state of that cell and its neighboring cells. There are many interesting cellular automata rules, and they all look very different, with amazing animated dynamic effects. 'Life' is a widely known cellular automata rule, but many other lesser known rules are much more interesting.\nSome hacker artists create art by writing computer code, and others, by developing hardware. Some create with existing software tools such as Adobe Photoshop or GIMP.\nThe creative process of hacker artists can be more abstract than artists using non-technological media. For example, mathematicians have produced visually stunning graphic presentations of fractals, which hackers have further enhanced, often producing detailed and intricate graphics and animations from simple mathematical formulas.\n\n\t\t\n\t\t\n\t\t\n\t\t\n\n\n**** Art ****\n\n\n**** Hacker art mentions ****\n\"Vector in Open Space\" by Gerfried Stocker 1996.\nSwitch|Journal Jun 14 1998.\nEye Weekly \"Tag \u2013 who's it?\" by Ingrid Hein, July 16, 1998.\nLinux Today Archived 2011-07-09 at the Wayback Machine \"Playing the Open Source Game\" by Shawn Hargreaves, Jul 5, 1999.\nCanterbury Christ Church University Library Resources by Subject \u2013 Art & Design, 2001.\nSuperCollider Workshop / Seminar Joel Ryan describes collaboration with hacker artists of Silicon Valley. 21 March 2002\nAnthony Barker's Weblog on Linux, Technology and the Economy \"Why Geeks Love Linux\", Sept 2003.\nLive Art Research Gesture and Response in Field-Based Performance by Sha Xin Wei & Satinder Gill, 2005.\nHackers, Who Are They \"The Hackers Identity\", October 2014."
    }
  },
  {
    "instruction": "Write an answer to the following question: How do hardware random number generators increase the amplitude of random fluctuations to a measurable level?",
    "context": "",
    "output": "Hardware random number generators use an amplifier and other electronic circuitry to increase the amplitude of random fluctuations to a measurable level.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do hardware random number generators increase the amplitude of random fluctuations to a measurable level?",
      "answer": "Hardware random number generators use an amplifier and other electronic circuitry to increase the amplitude of random fluctuations to a measurable level."
    }
  },
  {
    "instruction": "Aurora Generator Test\n\n==Introduction==\nIdaho National Laboratory ran the Aurora Generator Test in 2007 to demonstrate how a cyberattack could destroy physical components of the electric grid. The experiment used a computer program to rapidly open and close a diesel generator's circuit breakers out of phase from the rest of the grid, thereby subjecting the engine to abnormal torques and ultimately causing it to explode. This vulnerability is referred to as the Aurora Vulnerability.\nThis vulnerability is especially a concern because most grid equipment supports using Modbus and other legacy communications protocols that were designed without security in mind. As such, they do not support authentication, confidentiality, or replay protection.  This means that any attacker that can communicate with the device can control it and use the Aurora Vulnerability to destroy it.\n\n\n\n== Experiment ==\nTo prepare for the experiment, the researchers procured and installed a 2.25 MW (3000 horsepower) generator and connected it to the substation. They also needed access to a programmable digital relay or another device capable of controlling the breaker. Although such access can be through a mechanical or digital interface, in this case the latter was used.A generator unit consists of a diesel engine mechanically linked to an alternator.  In many commercial-industrial settings, multiple generators need to operate together in tandem, in order to provide power to the desired load.  A generator that is operating normally is synchronized with either the power grid or with one or more additional generators (for example in an \"islanded\" independent power network as might be used in a remote location or for emergency backup power).  When generators are operating in synchronicity, effectively their alternators are magnetically locked together.In the Aurora experiment, the researchers used a cyberattack to open and close the breakers out of sync, in order to deliberately maximize the stress. Each time the breakers were closed, the torque induced in the alternator (as a result of the out-of-synchrony connection) caused the entire generator to bounce and shake.  The generator used in the experiment was equipped with a resilient rubber rotating coupling (located between the diesel engine and the alternator, thus indirectly connecting the engine's steel crankshaft to the alternator's steel shaft).During the initial steps of the attack, black rubber pieces were ejected as the rotating coupling was incrementally destroyed (as a result of the extremely abnormal torques induced by the out-of-synchronization alternator on the diesel engine's crankshaft).  The rotating rubber coupling was soon destroyed outright, whereupon the diesel engine itself was then quickly ripped apart, with parts sent flying off. Some parts of the generator landed as far as 80 feet away from the generator. In addition to the massive and obvious mechanical damage to the diesel engine itself, evidence of overheating of the alternator was later observed (upon subsequent disassembly of the unit).In this attack, the generator unit was destroyed in roughly three minutes. However, this process took three minutes only because the researchers assessed the damage from each iteration of the attack. A real attack could have destroyed the unit much more quickly.  For example, a generator built without a rotating rubber coupling between the diesel engine and the alternator would experience the crankshaft-destroying abnormal forces in its diesel engine immediately, given the absence of a shock-absorbing material between these two rotating components.  A generator unit assembled in this way could see its diesel engine ruined by a single out-of-synchrony connection of the alternator.The Aurora experiment was designated as unclassified, for official use only. On September 27, 2007, CNN published an article based on the information and video DHS released to them, and on July 3, 2014, DHS released many of the documents related to the experiment as part of an unrelated FOIA request.\n\n== Vulnerability ==\nThe Aurora vulnerability is caused by the out-of-sync closing of the protective relays.\"A close, but imperfect, analogy would be to imagine the effect of shifting a car into Reverse while it is being driven on a highway, or the effect of revving the engine up while the car is in neutral and then shifting it into Drive.\"\"The Aurora attack is designed to open a circuit breaker, wait for the system or generator to slip out of synchronism, and reclose the breaker, all before the protection system recognizes and responds to the attack... Traditional generator protection elements typically actuate and block reclosing in about 15 cycles. Many variables affect this time, and every system needs to be analyzed to determine its specific vulnerability to the Aurora attack... Although the main focus of the Aurora attack is the potential 15-cycle window of opportunity immediately after the target breaker is opened, the overriding issue is how fast the generator moves away from system synchronism.\"\n\n== Potential impact ==\n\nThe failure of even a single generator could cause widespread outages and possibly cascading failure of the entire power grid as occurred in the Northeast blackout of 2003. Additionally, even if there are no outages from the removal of a single component (N-1 resilience), there is a large window for a second attack or failure as it could take more than a year to replace a destroyed generator, because many generators and transformers are custom-built.\n\n== Mitigations ==\nThe Aurora vulnerability can be mitigated by preventing the out-of-phase opening and closing of the breakers. Some suggested methods include adding functionality in protective relays to ensure synchronism and adding a time delay for closing breakers.One mitigation technique is to add a synchronism-check function to all protective relays that potentially connect two systems together. To implement this, the function must prevent the relay from closing unless the voltage and frequency are within a pre-set range.\nDevices such as the IEEE 25 Sync-Check relay and IEEE 50 can be used to prevent out-of-phase opening and closing of the breakers.Diesel engines can also be equipped with independent sensors that detect abnormal vibration signatures.  It is possible to design such a sensor to immediately trigger a complete shutdown of the generator upon detection of a single major excursion from the vibration signature of a normally operating engine.  However, the damage from that single excursion might already be substantial, particularly if a resilient rubber coupling between the engine and the alternator is not present.\n\n== Criticisms ==\nThere was some discussion as to whether Aurora hardware mitigation devices (HMD) can cause other failures. In May 2011, Quanta Technology published an article that used RTDS (Real Time Digital Simulator) testing to examine the \"performance of multiple commercial relay devices available\" of Aurora HMDs. To quote: \"The relays were subject to different test categories to find out if their performance is dependable when they need to operate, and secure in response to typical power system transients such as faults, power swing and load switching... In general, there were technical shortcomings in the protection scheme\u2019s design that were identified and documented using the real time testing results. RTDS testing showed that there is, as yet, no single solution that can be widely applied to any case, and that can present the required reliability level.\" A presentation from Quanta Technology and Dominion succinctly stated in their reliability assessment \"HMDs are not dependable, nor secure.\"Joe Weiss, a cybersecurity and control system professional, disputed the findings from this report and claimed that it has misled utilities. He wrote: \"This report has done a great deal of damage by implying that the Aurora mitigation devices will cause grid issues. Several utilities have used the Quanta report as a basis for not installing any Aurora mitigation devices. Unfortunately, the report has several very questionable assumptions. They include applying initial conditions that the hardware mitigation was not designed to address such as slower developing faults, or off nominal grid frequencies. Existing protection will address \u201cslower\u201d developing faults and off nominal grid frequencies (<59 Hz or >61 Hz). The Aurora hardware mitigation devices are for the very fast out-of-phase condition faults that are currently gaps in protection (i.e., not protected by any other device) of the grid.\"\n\n== Timeline ==\nOn March 4, 2007, Idaho National Laboratory demonstrated the Aurora vulnerability.On June 21, 2007, NERC notified industry about the Aurora vulnerability.On September 27, 2007, CNN released a previously classified demonstration video of the Aurora attack on their homepage. That video can be downloaded from here.\nOn October 13, 2010, NERC released a recommendation to industry on the Aurora vulnerability.On July 3, 2014, the US Department of Homeland Security released 840 pages of documents related to Aurora.\n\nAnswer this question based on the above context: How is the alternator affected by the Aurora attack?",
    "context": "",
    "output": "The alternator is affected by the Aurora attack through the extremely abnormal torques induced by the out-of-synchronization alternator on the diesel engine's crankshaft, which can cause overheating and damage.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How is the alternator affected by the Aurora attack?",
      "answer": "The alternator is affected by the Aurora attack through the extremely abnormal torques induced by the out-of-synchronization alternator on the diesel engine's crankshaft, which can cause overheating and damage.",
      "context": "Aurora Generator Test\n\n==Introduction==\nIdaho National Laboratory ran the Aurora Generator Test in 2007 to demonstrate how a cyberattack could destroy physical components of the electric grid. The experiment used a computer program to rapidly open and close a diesel generator's circuit breakers out of phase from the rest of the grid, thereby subjecting the engine to abnormal torques and ultimately causing it to explode. This vulnerability is referred to as the Aurora Vulnerability.\nThis vulnerability is especially a concern because most grid equipment supports using Modbus and other legacy communications protocols that were designed without security in mind. As such, they do not support authentication, confidentiality, or replay protection.  This means that any attacker that can communicate with the device can control it and use the Aurora Vulnerability to destroy it.\n\n\n\n== Experiment ==\nTo prepare for the experiment, the researchers procured and installed a 2.25 MW (3000 horsepower) generator and connected it to the substation. They also needed access to a programmable digital relay or another device capable of controlling the breaker. Although such access can be through a mechanical or digital interface, in this case the latter was used.A generator unit consists of a diesel engine mechanically linked to an alternator.  In many commercial-industrial settings, multiple generators need to operate together in tandem, in order to provide power to the desired load.  A generator that is operating normally is synchronized with either the power grid or with one or more additional generators (for example in an \"islanded\" independent power network as might be used in a remote location or for emergency backup power).  When generators are operating in synchronicity, effectively their alternators are magnetically locked together.In the Aurora experiment, the researchers used a cyberattack to open and close the breakers out of sync, in order to deliberately maximize the stress. Each time the breakers were closed, the torque induced in the alternator (as a result of the out-of-synchrony connection) caused the entire generator to bounce and shake.  The generator used in the experiment was equipped with a resilient rubber rotating coupling (located between the diesel engine and the alternator, thus indirectly connecting the engine's steel crankshaft to the alternator's steel shaft).During the initial steps of the attack, black rubber pieces were ejected as the rotating coupling was incrementally destroyed (as a result of the extremely abnormal torques induced by the out-of-synchronization alternator on the diesel engine's crankshaft).  The rotating rubber coupling was soon destroyed outright, whereupon the diesel engine itself was then quickly ripped apart, with parts sent flying off. Some parts of the generator landed as far as 80 feet away from the generator. In addition to the massive and obvious mechanical damage to the diesel engine itself, evidence of overheating of the alternator was later observed (upon subsequent disassembly of the unit).In this attack, the generator unit was destroyed in roughly three minutes. However, this process took three minutes only because the researchers assessed the damage from each iteration of the attack. A real attack could have destroyed the unit much more quickly.  For example, a generator built without a rotating rubber coupling between the diesel engine and the alternator would experience the crankshaft-destroying abnormal forces in its diesel engine immediately, given the absence of a shock-absorbing material between these two rotating components.  A generator unit assembled in this way could see its diesel engine ruined by a single out-of-synchrony connection of the alternator.The Aurora experiment was designated as unclassified, for official use only. On September 27, 2007, CNN published an article based on the information and video DHS released to them, and on July 3, 2014, DHS released many of the documents related to the experiment as part of an unrelated FOIA request.\n\n== Vulnerability ==\nThe Aurora vulnerability is caused by the out-of-sync closing of the protective relays.\"A close, but imperfect, analogy would be to imagine the effect of shifting a car into Reverse while it is being driven on a highway, or the effect of revving the engine up while the car is in neutral and then shifting it into Drive.\"\"The Aurora attack is designed to open a circuit breaker, wait for the system or generator to slip out of synchronism, and reclose the breaker, all before the protection system recognizes and responds to the attack... Traditional generator protection elements typically actuate and block reclosing in about 15 cycles. Many variables affect this time, and every system needs to be analyzed to determine its specific vulnerability to the Aurora attack... Although the main focus of the Aurora attack is the potential 15-cycle window of opportunity immediately after the target breaker is opened, the overriding issue is how fast the generator moves away from system synchronism.\"\n\n== Potential impact ==\n\nThe failure of even a single generator could cause widespread outages and possibly cascading failure of the entire power grid as occurred in the Northeast blackout of 2003. Additionally, even if there are no outages from the removal of a single component (N-1 resilience), there is a large window for a second attack or failure as it could take more than a year to replace a destroyed generator, because many generators and transformers are custom-built.\n\n== Mitigations ==\nThe Aurora vulnerability can be mitigated by preventing the out-of-phase opening and closing of the breakers. Some suggested methods include adding functionality in protective relays to ensure synchronism and adding a time delay for closing breakers.One mitigation technique is to add a synchronism-check function to all protective relays that potentially connect two systems together. To implement this, the function must prevent the relay from closing unless the voltage and frequency are within a pre-set range.\nDevices such as the IEEE 25 Sync-Check relay and IEEE 50 can be used to prevent out-of-phase opening and closing of the breakers.Diesel engines can also be equipped with independent sensors that detect abnormal vibration signatures.  It is possible to design such a sensor to immediately trigger a complete shutdown of the generator upon detection of a single major excursion from the vibration signature of a normally operating engine.  However, the damage from that single excursion might already be substantial, particularly if a resilient rubber coupling between the engine and the alternator is not present.\n\n== Criticisms ==\nThere was some discussion as to whether Aurora hardware mitigation devices (HMD) can cause other failures. In May 2011, Quanta Technology published an article that used RTDS (Real Time Digital Simulator) testing to examine the \"performance of multiple commercial relay devices available\" of Aurora HMDs. To quote: \"The relays were subject to different test categories to find out if their performance is dependable when they need to operate, and secure in response to typical power system transients such as faults, power swing and load switching... In general, there were technical shortcomings in the protection scheme\u2019s design that were identified and documented using the real time testing results. RTDS testing showed that there is, as yet, no single solution that can be widely applied to any case, and that can present the required reliability level.\" A presentation from Quanta Technology and Dominion succinctly stated in their reliability assessment \"HMDs are not dependable, nor secure.\"Joe Weiss, a cybersecurity and control system professional, disputed the findings from this report and claimed that it has misled utilities. He wrote: \"This report has done a great deal of damage by implying that the Aurora mitigation devices will cause grid issues. Several utilities have used the Quanta report as a basis for not installing any Aurora mitigation devices. Unfortunately, the report has several very questionable assumptions. They include applying initial conditions that the hardware mitigation was not designed to address such as slower developing faults, or off nominal grid frequencies. Existing protection will address \u201cslower\u201d developing faults and off nominal grid frequencies (<59 Hz or >61 Hz). The Aurora hardware mitigation devices are for the very fast out-of-phase condition faults that are currently gaps in protection (i.e., not protected by any other device) of the grid.\"\n\n== Timeline ==\nOn March 4, 2007, Idaho National Laboratory demonstrated the Aurora vulnerability.On June 21, 2007, NERC notified industry about the Aurora vulnerability.On September 27, 2007, CNN released a previously classified demonstration video of the Aurora attack on their homepage. That video can be downloaded from here.\nOn October 13, 2010, NERC released a recommendation to industry on the Aurora vulnerability.On July 3, 2014, the US Department of Homeland Security released 840 pages of documents related to Aurora."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is a weakness of PBKDF2 in terms of brute-force attacks?",
    "context": "",
    "output": "One weakness of PBKDF2 is that it can be implemented with a small circuit and very little RAM, making brute-force attacks using application-specific integrated circuits or graphics processing units relatively cheap.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is a weakness of PBKDF2 in terms of brute-force attacks?",
      "answer": "One weakness of PBKDF2 is that it can be implemented with a small circuit and very little RAM, making brute-force attacks using application-specific integrated circuits or graphics processing units relatively cheap."
    }
  },
  {
    "instruction": "Anonymous veto network\n\n==Introduction==\nIn cryptography, the anonymous veto network (or AV-net) is a multi-party secure computation protocol to compute the boolean-OR function. It was first proposed by Feng Hao and Piotr Zieli\u0144ski in 2006. This protocol presents an efficient solution to the Dining cryptographers problem.\nA related protocol that securely computes a boolean-count function is open vote network (or OV-net).\n\n\n\n== Description ==\nAll participants agree on a group \n  \n    \n      \n        \n          G\n        \n      \n    \n    {\\displaystyle \\scriptstyle G}\n   with a generator \n  \n    \n      \n        \n          g\n        \n      \n    \n    {\\displaystyle \\scriptstyle g}\n   of prime order \n  \n    \n      \n        \n          q\n        \n      \n    \n    {\\displaystyle \\scriptstyle q}\n   in which the discrete logarithm problem is hard. For example, a Schnorr group can be used.  For a group of \n  \n    \n      \n        \n          n\n        \n      \n    \n    {\\displaystyle \\scriptstyle n}\n   participants, the protocol executes in two rounds.\nRound 1: each participant \n  \n    \n      \n        \n          i\n        \n      \n    \n    {\\displaystyle \\scriptstyle i}\n   selects a random value \n  \n    \n      \n        \n          \n            x\n            \n              i\n            \n          \n          \n          \n            \u2208\n            \n              R\n            \n          \n          \n          \n            \n              Z\n            \n            \n              q\n            \n          \n        \n      \n    \n    {\\displaystyle \\scriptstyle x_{i}\\,\\in _{R}\\,\\mathbb {Z} _{q}}\n   and publishes the ephemeral public key \n  \n    \n      \n        \n          \n            g\n            \n              \n                x\n                \n                  i\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\scriptstyle g^{x_{i}}}\n   together with a zero-knowledge proof for the proof of the exponent \n  \n    \n      \n        \n          \n            x\n            \n              i\n            \n          \n        \n      \n    \n    {\\displaystyle \\scriptstyle x_{i}}\n  . A detailed description of a method for such proofs is found in RFC 8235.\nAfter this round, each participant computes:\n\n  \n    \n      \n        \n          g\n          \n            \n              y\n              \n                i\n\n== The protocol design ==\nThe protocol is designed by combining random public keys in such a structured way to achieve a vanishing effect. In this case, \n  \n    \n      \n        \n          \u2211\n          \n            \n              x\n              \n                i\n              \n            \n            \u22c5\n            \n              y\n              \n                i\n\nWhat is a Schnorr group and why is it a suitable choice for the AV-net?",
    "context": "",
    "output": "A: A Schnorr group is a group with a generator g of prime order q, where the discrete logarithm problem is hard. It is a suitable choice for the AV-net as it ensures the security of the protocol by making it difficult to derive the secret value xi from the published ephemeral public key.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is a Schnorr group and why is it a suitable choice for the AV-net?",
      "answer": "A Schnorr group is a group with a generator g of prime order q, where the discrete logarithm problem is hard. It is a suitable choice for the AV-net as it ensures the security of the protocol by making it difficult to derive the secret value xi from the published ephemeral public key.",
      "context": "Anonymous veto network\n\n==Introduction==\nIn cryptography, the anonymous veto network (or AV-net) is a multi-party secure computation protocol to compute the boolean-OR function. It was first proposed by Feng Hao and Piotr Zieli\u0144ski in 2006. This protocol presents an efficient solution to the Dining cryptographers problem.\nA related protocol that securely computes a boolean-count function is open vote network (or OV-net).\n\n\n\n== Description ==\nAll participants agree on a group \n  \n    \n      \n        \n          G\n        \n      \n    \n    {\\displaystyle \\scriptstyle G}\n   with a generator \n  \n    \n      \n        \n          g\n        \n      \n    \n    {\\displaystyle \\scriptstyle g}\n   of prime order \n  \n    \n      \n        \n          q\n        \n      \n    \n    {\\displaystyle \\scriptstyle q}\n   in which the discrete logarithm problem is hard. For example, a Schnorr group can be used.  For a group of \n  \n    \n      \n        \n          n\n        \n      \n    \n    {\\displaystyle \\scriptstyle n}\n   participants, the protocol executes in two rounds.\nRound 1: each participant \n  \n    \n      \n        \n          i\n        \n      \n    \n    {\\displaystyle \\scriptstyle i}\n   selects a random value \n  \n    \n      \n        \n          \n            x\n            \n              i\n            \n          \n          \n          \n            \u2208\n            \n              R\n            \n          \n          \n          \n            \n              Z\n            \n            \n              q\n            \n          \n        \n      \n    \n    {\\displaystyle \\scriptstyle x_{i}\\,\\in _{R}\\,\\mathbb {Z} _{q}}\n   and publishes the ephemeral public key \n  \n    \n      \n        \n          \n            g\n            \n              \n                x\n                \n                  i\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\scriptstyle g^{x_{i}}}\n   together with a zero-knowledge proof for the proof of the exponent \n  \n    \n      \n        \n          \n            x\n            \n              i\n            \n          \n        \n      \n    \n    {\\displaystyle \\scriptstyle x_{i}}\n  . A detailed description of a method for such proofs is found in RFC 8235.\nAfter this round, each participant computes:\n\n  \n    \n      \n        \n          g\n          \n            \n              y\n              \n                i\n\n== The protocol design ==\nThe protocol is designed by combining random public keys in such a structured way to achieve a vanishing effect. In this case, \n  \n    \n      \n        \n          \u2211\n          \n            \n              x\n              \n                i\n              \n            \n            \u22c5\n            \n              y\n              \n                i"
    }
  },
  {
    "instruction": "Panda Cloud Antivirus\n\n==Introduction==\nPanda Cloud Antivirus is an antivirus software developed by Panda Security, a free and a paid version are available. It is cloud-based in the sense that files are scanned on a remote server without using processing power of the user's machine. The cloud technology is based on Panda's Collective Intelligence. It can run constantly, providing protection against viruses and malicious websites but slowing the system to some extent, or do a system scan.\n\n\n\n== Features ==\nAccording to Panda Security, Panda Cloud Antivirus is able to detect viruses, trojans, worms, spyware, dialers, hacking tools, hacker and other security risks.Panda Cloud Antivirus relies on its \"Collective Intelligence\" and  the cloud for up-to-date information. It normally uses an Internet connection to access up-to-date information; if the Internet cannot be accessed, it will use a local cache of \"the most common threats in circulation\".\n\n== Reviews ==\nAn April 2009 review found Panda Cloud Antivirus 1.0 to be clean, fast, simple, easy to use, and with good detection rates. The same review scored Panda 100.00% in malware detection and 100.0% in malicious URL detection. Its overall score was 100%, a strong protection factor considering it is software.When version 1.0 was released on November 10, 2009, PC Magazine reviewed Panda Cloud Antivirus and gave it an Editor's Choice Award for Best  AV.TechRadar's review states \"We think that Panda Cloud Antivirus is best viewed as a defense tool rather than a utility for cleaning up a system that's already riddled with infection.\"\n\n== License ==\nThe  free edition of Panda Cloud Antivirus is released under a license. Its usage is exclusively allowed for private households, state schools, non-governmental and non-profit organizations.\nQ: How does Panda Cloud Antivirus's local cache function when an Internet connection is not available?",
    "context": "",
    "output": "Panda Cloud Antivirus's local cache functions by providing access to a collection of the most common threats in circulation when an Internet connection is not available.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does Panda Cloud Antivirus's local cache function when an Internet connection is not available?",
      "answer": "Panda Cloud Antivirus's local cache functions by providing access to a collection of the most common threats in circulation when an Internet connection is not available.",
      "context": "Panda Cloud Antivirus\n\n==Introduction==\nPanda Cloud Antivirus is an antivirus software developed by Panda Security, a free and a paid version are available. It is cloud-based in the sense that files are scanned on a remote server without using processing power of the user's machine. The cloud technology is based on Panda's Collective Intelligence. It can run constantly, providing protection against viruses and malicious websites but slowing the system to some extent, or do a system scan.\n\n\n\n== Features ==\nAccording to Panda Security, Panda Cloud Antivirus is able to detect viruses, trojans, worms, spyware, dialers, hacking tools, hacker and other security risks.Panda Cloud Antivirus relies on its \"Collective Intelligence\" and  the cloud for up-to-date information. It normally uses an Internet connection to access up-to-date information; if the Internet cannot be accessed, it will use a local cache of \"the most common threats in circulation\".\n\n== Reviews ==\nAn April 2009 review found Panda Cloud Antivirus 1.0 to be clean, fast, simple, easy to use, and with good detection rates. The same review scored Panda 100.00% in malware detection and 100.0% in malicious URL detection. Its overall score was 100%, a strong protection factor considering it is software.When version 1.0 was released on November 10, 2009, PC Magazine reviewed Panda Cloud Antivirus and gave it an Editor's Choice Award for Best  AV.TechRadar's review states \"We think that Panda Cloud Antivirus is best viewed as a defense tool rather than a utility for cleaning up a system that's already riddled with infection.\"\n\n== License ==\nThe  free edition of Panda Cloud Antivirus is released under a license. Its usage is exclusively allowed for private households, state schools, non-governmental and non-profit organizations."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does a DID identify a subject?",
    "context": "",
    "output": "A DID identifies any subject, such as a person, organization, thing, data model, abstract entity, etc., that the controller of the DID decides that it identifies. DIDs are designed to enable the controller of a DID to prove control over it and to be implemented independently of any centralized registry, identity provider, or certificate authority.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does a DID identify a subject?",
      "answer": "A DID identifies any subject, such as a person, organization, thing, data model, abstract entity, etc., that the controller of the DID decides that it identifies. DIDs are designed to enable the controller of a DID to prove control over it and to be implemented independently of any centralized registry, identity provider, or certificate authority."
    }
  },
  {
    "instruction": "NordLayer\n\n==Introduction==\nNordLayer, formerly known as NordVPN Teams, is a network access security service with applications for Microsoft Windows, macOS, Linux, Android and iOS. The software is marketed as a privacy and security tool running on zero trust architecture providing protection on hybrid and multi-cloud cloud environments.It is developed by Nord Security (Nordsec Ltd), a company that creates cybersecurity software and was initially supported by the Lithuanian startup accelerator and business incubator Tesonet.\n\n\n\n== Products ==\nNordLayer is based on a cloud-based cybersecurity architecture, secure access service edge (SASE), which enables cloud-based platform for remote access to corporate networks.Nordlayer offers a Single Sign-On (SSO) login option to its users, allowing users to log into multiple applications using a single set of login credentials. SSO logins are currently supported through various providers, including Google SSO, Azure AD, Okta, and OneLogin. NordLayer supports various second-factor confirmation methods, including SMS authentication, Time-based One-Time Password (TOTP) authentication, and biometric authentication.NordLayer enforces  Zero Trust Network Access (ZTNA), which is based on the principle \"Never trust \u2013 always verify\".\nThis systems secure model uses continuous authentication and identity verification to grant access to network resources. NordLayer employs the Advanced Encryption Standard (AES) with 256-bit keys and the ChaCha20 stream cipher.It includes features such as two-factor (2FA), kill switch, IP whitelisting, DDoS protection and hardware firewall monitoring to detect botnet attacks.NordLayer's Cloud Firewall provides features such as application control, bandwidth management, and logging capabilities.\nThe NordLayer platform enables IT administrators to add, remove, or transfer user accounts, dedicated servers, or custom gateways \u2014 with static or dedicated IP addresses \u2014 for specific teams to remotely access a company's LAN. In addition, network administrators have the ability to monitor user activity and obtain information about the connection. This includes checking whether the devices being used comply with predefined security rules.Nordlayer's Secure Web Gateway (SWG) provides features for web security and access control such as web filtering, content filtering, application control, and identity management.Nordlayer currently has 33 global dedicated server locations.\n\n\n*** Global Remote Work Index ***\nIn 2022, NordLayer launched The Global Remote Work Index, an international index that provides data and insights to identify the best countries for remote work. It is based on the evaluation of more than 60 variables in 66 countries, including the availability of broadband internet, the cost of living, digital and physical infrastructure and the cost of labor.\n\nBased on the above text, answer a question. How does NordLayer's Global Remote Work Index provide data and insights for remote work?",
    "context": "",
    "output": "NordLayer's Global Remote Work Index provides data and insights for remote work by evaluating more than 60 variables in 66 countries, including the availability of broadband internet, the cost of living, digital and physical infrastructure and the cost of labor.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does NordLayer's Global Remote Work Index provide data and insights for remote work?",
      "answer": "NordLayer's Global Remote Work Index provides data and insights for remote work by evaluating more than 60 variables in 66 countries, including the availability of broadband internet, the cost of living, digital and physical infrastructure and the cost of labor.",
      "context": "NordLayer\n\n==Introduction==\nNordLayer, formerly known as NordVPN Teams, is a network access security service with applications for Microsoft Windows, macOS, Linux, Android and iOS. The software is marketed as a privacy and security tool running on zero trust architecture providing protection on hybrid and multi-cloud cloud environments.It is developed by Nord Security (Nordsec Ltd), a company that creates cybersecurity software and was initially supported by the Lithuanian startup accelerator and business incubator Tesonet.\n\n\n\n== Products ==\nNordLayer is based on a cloud-based cybersecurity architecture, secure access service edge (SASE), which enables cloud-based platform for remote access to corporate networks.Nordlayer offers a Single Sign-On (SSO) login option to its users, allowing users to log into multiple applications using a single set of login credentials. SSO logins are currently supported through various providers, including Google SSO, Azure AD, Okta, and OneLogin. NordLayer supports various second-factor confirmation methods, including SMS authentication, Time-based One-Time Password (TOTP) authentication, and biometric authentication.NordLayer enforces  Zero Trust Network Access (ZTNA), which is based on the principle \"Never trust \u2013 always verify\".\nThis systems secure model uses continuous authentication and identity verification to grant access to network resources. NordLayer employs the Advanced Encryption Standard (AES) with 256-bit keys and the ChaCha20 stream cipher.It includes features such as two-factor (2FA), kill switch, IP whitelisting, DDoS protection and hardware firewall monitoring to detect botnet attacks.NordLayer's Cloud Firewall provides features such as application control, bandwidth management, and logging capabilities.\nThe NordLayer platform enables IT administrators to add, remove, or transfer user accounts, dedicated servers, or custom gateways \u2014 with static or dedicated IP addresses \u2014 for specific teams to remotely access a company's LAN. In addition, network administrators have the ability to monitor user activity and obtain information about the connection. This includes checking whether the devices being used comply with predefined security rules.Nordlayer's Secure Web Gateway (SWG) provides features for web security and access control such as web filtering, content filtering, application control, and identity management.Nordlayer currently has 33 global dedicated server locations.\n\n\n*** Global Remote Work Index ***\nIn 2022, NordLayer launched The Global Remote Work Index, an international index that provides data and insights to identify the best countries for remote work. It is based on the evaluation of more than 60 variables in 66 countries, including the availability of broadband internet, the cost of living, digital and physical infrastructure and the cost of labor."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does NGSCB handle the complexity of the Windows API?",
    "context": "",
    "output": "NGSCB handles the complexity of the Windows API by splitting applications into two distinct parts, the NCA, a trusted module with access to a limited Application Programming Interface (API), and an untrusted portion, which has access to the full Windows API.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does NGSCB handle the complexity of the Windows API?",
      "answer": "NGSCB handles the complexity of the Windows API by splitting applications into two distinct parts, the NCA, a trusted module with access to a limited Application Programming Interface (API), and an untrusted portion, which has access to the full Windows API."
    }
  },
  {
    "instruction": "Write an answer to the following question: When was the first version of Kali Linux released and what is its version number?",
    "context": "",
    "output": "The first version of Kali Linux, version 1.0.0 \"moto\", was released in March 2013.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "When was the first version of Kali Linux released and what is its version number?",
      "answer": "The first version of Kali Linux, version 1.0.0 \"moto\", was released in March 2013."
    }
  },
  {
    "instruction": "Write an answer to the following question: How can key logging or acoustic cryptanalysis be used to guess or copy the master password?",
    "context": "",
    "output": "Key logging involves recording every keystroke made on a keyboard, which can be used to guess or copy the master password. Acoustic cryptanalysis involves using the sounds made by a keyboard to guess or copy the master password.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can key logging or acoustic cryptanalysis be used to guess or copy the master password?",
      "answer": "Key logging involves recording every keystroke made on a keyboard, which can be used to guess or copy the master password. Acoustic cryptanalysis involves using the sounds made by a keyboard to guess or copy the master password."
    }
  },
  {
    "instruction": "Captive portal\n\n==Introduction==\nA captive portal is a web page accessed with a web browser that is displayed to newly connected users of a Wi-Fi or wired network before they are granted broader access to network resources. Captive portals are commonly used to present a landing or log-in page which may require authentication, payment, acceptance of an end-user license agreement, acceptable use policy, survey completion, or other valid credentials that both the host and user agree to adhere by. Captive portals are used for a broad range of mobile and pedestrian broadband services \u2013 including cable and commercially provided Wi-Fi and home hotspots. A captive portal can also be used to provide access to enterprise or residential wired networks, such as apartment houses, hotel rooms, and business centers.\nThe captive portal is presented to the client and is stored either at the gateway or on a web server hosting the web page. Depending on the feature set of the gateway, websites or TCP ports can be white-listed so that the user would not have to interact with the captive portal in order to use them. The MAC address of attached clients can also be used to bypass the login process for specified devices.\nWISPr refers to this web browser-based authentication method as the Universal Access Method (UAM).\n\n\n\n== Uses ==\nCaptive portals are primarily used in open wireless networks where the users are shown a welcome message informing them of the conditions of access (allowed ports, liability, etc.). Administrators tend to do this so that their own users take responsibility for their actions and to avoid any legal responsibility. Whether this delegation of responsibility is legally valid is a matter of debate.Often captive portals are used for marketing and commercial communication purposes. Access to the Internet over open Wi-Fi is prohibited until the user exchanges personal data by filling out a web-based registration form in a web browser. The web-based form either automatically opens in a web browser, or appears when the user opens a web browser and tries to visit any web page. In other words, the user is \"captive\" - unable to access the Internet freely until the user is granted access to the Internet and has \"completed\" the captive portal. This allows the provider of this service to display or send advertisements to users who connect to the Wi-Fi access point. This type of service is also sometimes known as \"social Wi-Fi\", as they may ask for a social network account to login (such as Facebook). Over the past few years, such social Wi-Fi captive portals have become commonplace with various companies offering marketing centered around Wi-Fi data collection. \nThe user can find many types of content in the captive portal, and it's frequent to allow access to the Internet in exchange for viewing content or performing a certain action (often, providing personal data to enable commercial contact); thus, the marketing use of the captive portal is a tool for lead generation (business contacts or potential clients).\n\n== Implementation ==\nThere are various ways to implement a captive portal.\n\n\n*** HTTP redirect ***\nA common method is to direct all World Wide Web traffic to a web server, which returns an HTTP redirect to a captive portal. When a modern, Internet-enabled device first connects to a network, it sends out an HTTP request to a detection URL predefined by its vendor and expects an HTTP status code 200 OK or 204 No Content. If the device receives a HTTP 200 status code, it assumes it has unlimited internet access. Captive portal prompts are displayed when you are able to manipulate this first HTTP message to return a HTTP status code of 302 (redirect) to the captive portal of your choice. RFC 6585 specifies 511 Network Authentication Required code.\n\n\n*** ICMP redirect ***\nClient traffic can also be redirected using ICMP redirect on the layer 3 level.\n\n\n*** Redirect by DNS ***\nWhen a client requests a resource on a remote host by name, DNS is queried to resolve that hostname. In a captive portal, the firewall will make sure that only the DNS server(s) provided by the network's DHCP can be used by unauthenticated clients (or, alternatively, it will forward all DNS requests by unauthenticated clients to that DNS server). This DNS server will return the IP address of the captive portal page as a result of all DNS lookups.\nIn order to perform redirection by DNS the captive portal uses DNS hijacking to perform an action similar to a man-in-the-middle attack. To limit the impact of DNS poisoning, a TTL of 0 is typically used.\n\n== Detection ==\nCaptive portal detection URLs typically return a minimal, standardized response when not behind a captive portal. When the device receives the expected response, it concludes that it has direct internet access. If the response is different, the device assumes it is behind a captive portal and triggers the captive portal login process.\n\n== Limitations ==\n\n\n*** Security ***\nCaptive portals have been known to have incomplete firewall rule sets.\n\n\n**** DNS tunneling ****\nIn some deployments, the rule set will route DNS requests from clients to the Internet, or the provided DNS server will fulfill arbitrary DNS requests from the client. This allows a client to bypass the captive portal and access the open Internet by tunneling arbitrary traffic within DNS packets.\n\n\n**** Automatic submission ****\nSome captive portals may be configured to allow appropriately equipped user agents to detect the captive portal and automatically authenticate. User agents and supplemental applications such as Apple's Captive Portal Assistant can sometimes transparently bypass the display of captive portal content against the wishes of the service operator as long as they have access to correct credentials, or they may attempt to authenticate with incorrect or obsolete credentials, resulting in unintentional consequences such as accidental account locking.\n\n\n**** MAC spoofing ****\nA captive portal that uses MAC addresses to track connected devices can sometimes be circumvented by re-using the MAC address of a previously authenticated device. Once a device has been authenticated to the captive portal using valid credentials, the gateway adds that device's MAC address to its allowlist; since MAC addresses can easily be spoofed, any other device can pretend to be the authenticated device and bypass the captive portal. Once the IP and MAC addresses of other connecting computers are found to be authenticated, any machine can spoof the MAC address and Internet Protocol (IP) address of the authenticated target, and be allowed a route through the gateway. For this reason some captive portal solutions created extended authentication mechanisms to limit the risk for usurpation.\n\n\n*** Require Web Browser ***\nCaptive portals often require the use of a web browser; users who first use an email client or other application that relies on the Internet may find the connection not working without explanation, and will then need to open a web browser to validate. This may be problematic for users who do not have any web browser installed on their operating system. It is however sometimes possible to use email and other facilities that do not rely on DNS (e.g. if the application specifies the connection IP address rather than the hostname). A similar problem can occur if the client uses AJAX or joins the network with pages already loaded into its web browser, causing undefined behavior (for example, corrupt messages appear) when such a page tries HTTP requests to its origin server. \nSimilarly, as HTTPS connections cannot be redirected (at least not without triggering security warnings), a web browser that only attempts to access secure websites before being authorized by the captive portal will see those attempts fail without explanation (the usual symptom is that the intended website appears to be down or inaccessible).\nPlatforms that have Wi-Fi and a TCP/IP stack but do not have a web browser that supports HTTPS cannot use many captive portals. Such platforms include the Nintendo DS running a game that uses Nintendo Wi-Fi Connection. Non-browser authentication is possible using WISPr, an XML-based authentication protocol for this purpose, or MAC-based authentication or authentications based on other protocols.\nIt is also possible for a platform vendor to enter into a service contract with the operator of a large number of captive portal hotspots to allow free or discounted access to the platform vendor's servers via the hotspot's walled garden. For example, in 2005 Nintendo and Wayport partnered to provide free Wi-Fi access to Nintendo DS users at certain McDonald's restaurants. Also, VoIP SIP ports could be allowed to bypass the gateway to allow phones to work.\n\nHow does a captive portal function in terms of providing access to network resources?",
    "context": "",
    "output": "A captive portal functions as a web page that users must go through before being granted broader access to network resources. It typically presents a landing or log-in page that may require authentication, payment, or acceptance of an agreement. This method is commonly used in open wireless networks where the users are shown a welcome message informing them of the conditions of access.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does a captive portal function in terms of providing access to network resources?",
      "answer": "A captive portal functions as a web page that users must go through before being granted broader access to network resources. It typically presents a landing or log-in page that may require authentication, payment, or acceptance of an agreement. This method is commonly used in open wireless networks where the users are shown a welcome message informing them of the conditions of access.",
      "context": "Captive portal\n\n==Introduction==\nA captive portal is a web page accessed with a web browser that is displayed to newly connected users of a Wi-Fi or wired network before they are granted broader access to network resources. Captive portals are commonly used to present a landing or log-in page which may require authentication, payment, acceptance of an end-user license agreement, acceptable use policy, survey completion, or other valid credentials that both the host and user agree to adhere by. Captive portals are used for a broad range of mobile and pedestrian broadband services \u2013 including cable and commercially provided Wi-Fi and home hotspots. A captive portal can also be used to provide access to enterprise or residential wired networks, such as apartment houses, hotel rooms, and business centers.\nThe captive portal is presented to the client and is stored either at the gateway or on a web server hosting the web page. Depending on the feature set of the gateway, websites or TCP ports can be white-listed so that the user would not have to interact with the captive portal in order to use them. The MAC address of attached clients can also be used to bypass the login process for specified devices.\nWISPr refers to this web browser-based authentication method as the Universal Access Method (UAM).\n\n\n\n== Uses ==\nCaptive portals are primarily used in open wireless networks where the users are shown a welcome message informing them of the conditions of access (allowed ports, liability, etc.). Administrators tend to do this so that their own users take responsibility for their actions and to avoid any legal responsibility. Whether this delegation of responsibility is legally valid is a matter of debate.Often captive portals are used for marketing and commercial communication purposes. Access to the Internet over open Wi-Fi is prohibited until the user exchanges personal data by filling out a web-based registration form in a web browser. The web-based form either automatically opens in a web browser, or appears when the user opens a web browser and tries to visit any web page. In other words, the user is \"captive\" - unable to access the Internet freely until the user is granted access to the Internet and has \"completed\" the captive portal. This allows the provider of this service to display or send advertisements to users who connect to the Wi-Fi access point. This type of service is also sometimes known as \"social Wi-Fi\", as they may ask for a social network account to login (such as Facebook). Over the past few years, such social Wi-Fi captive portals have become commonplace with various companies offering marketing centered around Wi-Fi data collection. \nThe user can find many types of content in the captive portal, and it's frequent to allow access to the Internet in exchange for viewing content or performing a certain action (often, providing personal data to enable commercial contact); thus, the marketing use of the captive portal is a tool for lead generation (business contacts or potential clients).\n\n== Implementation ==\nThere are various ways to implement a captive portal.\n\n\n*** HTTP redirect ***\nA common method is to direct all World Wide Web traffic to a web server, which returns an HTTP redirect to a captive portal. When a modern, Internet-enabled device first connects to a network, it sends out an HTTP request to a detection URL predefined by its vendor and expects an HTTP status code 200 OK or 204 No Content. If the device receives a HTTP 200 status code, it assumes it has unlimited internet access. Captive portal prompts are displayed when you are able to manipulate this first HTTP message to return a HTTP status code of 302 (redirect) to the captive portal of your choice. RFC 6585 specifies 511 Network Authentication Required code.\n\n\n*** ICMP redirect ***\nClient traffic can also be redirected using ICMP redirect on the layer 3 level.\n\n\n*** Redirect by DNS ***\nWhen a client requests a resource on a remote host by name, DNS is queried to resolve that hostname. In a captive portal, the firewall will make sure that only the DNS server(s) provided by the network's DHCP can be used by unauthenticated clients (or, alternatively, it will forward all DNS requests by unauthenticated clients to that DNS server). This DNS server will return the IP address of the captive portal page as a result of all DNS lookups.\nIn order to perform redirection by DNS the captive portal uses DNS hijacking to perform an action similar to a man-in-the-middle attack. To limit the impact of DNS poisoning, a TTL of 0 is typically used.\n\n== Detection ==\nCaptive portal detection URLs typically return a minimal, standardized response when not behind a captive portal. When the device receives the expected response, it concludes that it has direct internet access. If the response is different, the device assumes it is behind a captive portal and triggers the captive portal login process.\n\n== Limitations ==\n\n\n*** Security ***\nCaptive portals have been known to have incomplete firewall rule sets.\n\n\n**** DNS tunneling ****\nIn some deployments, the rule set will route DNS requests from clients to the Internet, or the provided DNS server will fulfill arbitrary DNS requests from the client. This allows a client to bypass the captive portal and access the open Internet by tunneling arbitrary traffic within DNS packets.\n\n\n**** Automatic submission ****\nSome captive portals may be configured to allow appropriately equipped user agents to detect the captive portal and automatically authenticate. User agents and supplemental applications such as Apple's Captive Portal Assistant can sometimes transparently bypass the display of captive portal content against the wishes of the service operator as long as they have access to correct credentials, or they may attempt to authenticate with incorrect or obsolete credentials, resulting in unintentional consequences such as accidental account locking.\n\n\n**** MAC spoofing ****\nA captive portal that uses MAC addresses to track connected devices can sometimes be circumvented by re-using the MAC address of a previously authenticated device. Once a device has been authenticated to the captive portal using valid credentials, the gateway adds that device's MAC address to its allowlist; since MAC addresses can easily be spoofed, any other device can pretend to be the authenticated device and bypass the captive portal. Once the IP and MAC addresses of other connecting computers are found to be authenticated, any machine can spoof the MAC address and Internet Protocol (IP) address of the authenticated target, and be allowed a route through the gateway. For this reason some captive portal solutions created extended authentication mechanisms to limit the risk for usurpation.\n\n\n*** Require Web Browser ***\nCaptive portals often require the use of a web browser; users who first use an email client or other application that relies on the Internet may find the connection not working without explanation, and will then need to open a web browser to validate. This may be problematic for users who do not have any web browser installed on their operating system. It is however sometimes possible to use email and other facilities that do not rely on DNS (e.g. if the application specifies the connection IP address rather than the hostname). A similar problem can occur if the client uses AJAX or joins the network with pages already loaded into its web browser, causing undefined behavior (for example, corrupt messages appear) when such a page tries HTTP requests to its origin server. \nSimilarly, as HTTPS connections cannot be redirected (at least not without triggering security warnings), a web browser that only attempts to access secure websites before being authorized by the captive portal will see those attempts fail without explanation (the usual symptom is that the intended website appears to be down or inaccessible).\nPlatforms that have Wi-Fi and a TCP/IP stack but do not have a web browser that supports HTTPS cannot use many captive portals. Such platforms include the Nintendo DS running a game that uses Nintendo Wi-Fi Connection. Non-browser authentication is possible using WISPr, an XML-based authentication protocol for this purpose, or MAC-based authentication or authentications based on other protocols.\nIt is also possible for a platform vendor to enter into a service contract with the operator of a large number of captive portal hotspots to allow free or discounted access to the platform vendor's servers via the hotspot's walled garden. For example, in 2005 Nintendo and Wayport partnered to provide free Wi-Fi access to Nintendo DS users at certain McDonald's restaurants. Also, VoIP SIP ports could be allowed to bypass the gateway to allow phones to work."
    }
  },
  {
    "instruction": "Write an answer to the following question: How do random canaries protect against buffer overflow attacks?",
    "context": "",
    "output": "Random canaries are randomly generated and usually stored in a global variable padded by unmapped pages. This makes it difficult for an attacker to read the canary, as attempting to read it causes a segmentation fault. However, it may still be possible to read the canary if the attacker knows where it is or can get the program to read from the stack.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do random canaries protect against buffer overflow attacks?",
      "answer": "Random canaries are randomly generated and usually stored in a global variable padded by unmapped pages. This makes it difficult for an attacker to read the canary, as attempting to read it causes a segmentation fault. However, it may still be possible to read the canary if the attacker knows where it is or can get the program to read from the stack."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does Turla's use of multiple names and aliases affect organizations' ability to protect themselves from the threat?",
    "context": "",
    "output": "Turla's use of multiple names and aliases can make it more difficult for organizations to protect themselves from the threat, as it can be harder to track and identify the group's activities and tactics. However, organizations can stay informed about the latest threats and trends by following reputable cybersecurity news sources, participating in industry organizations and forums, and sharing information with other organizations and government agencies.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does Turla's use of multiple names and aliases affect organizations' ability to protect themselves from the threat?",
      "answer": "Turla's use of multiple names and aliases can make it more difficult for organizations to protect themselves from the threat, as it can be harder to track and identify the group's activities and tactics. However, organizations can stay informed about the latest threats and trends by following reputable cybersecurity news sources, participating in industry organizations and forums, and sharing information with other organizations and government agencies."
    }
  },
  {
    "instruction": "Answer based on context:\n\nOpen Bug Bounty\n\n==Introduction==\nOpen Bug Bounty is a non-profit bug bounty platform established in 2014. The responsible disclosure platform allows independent security researchers to report XSS and similar security vulnerabilities on any website they discover using non-intrusive security testing techniques. The researchers may choose to make the details of the vulnerabilities public in 90 days since vulnerability submission or to communicate them only to the website operators. The program's expectation is that the operators of the affected website will reward the researchers for making their reports.\n\n\n\n== Program ==\nUnlike commercial bug bounty programs, Open Bug Bounty is a non-profit project and does not require payment by either the researchers or the website operators. Any bounty is a matter of agreement between the researchers and the website operators. Heise.de identified the potential for the website to be a vehicle for blackmailing website operators with the threat of disclosing vulnerabilities if no bounty is paid, but reported that Open Bug Bounty prohibits this.Open Bug Bounty was launched by private security enthusiasts in 2014, and as of February 2017 had recorded 100,000 vulnerabilities, of which 35,000 had been fixed. It grew out of the website XSSPosed, an archive of cross-site scripting vulnerabilities.In February 2018, the platform had 100,000 fixed vulnerabilities using coordinated disclosure program based on ISO 29147 guidelines. Up to the end of 2019, the platform reported 272,020 fixed vulnerabilities using coordinated disclosure program based on ISO 29147 guidelines.\n\nWhat was the original website that Open Bug Bounty grew out of?",
    "context": "",
    "output": "Open Bug Bounty grew out of the website XSSPosed, an archive of cross-site scripting vulnerabilities.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was the original website that Open Bug Bounty grew out of?",
      "answer": "Open Bug Bounty grew out of the website XSSPosed, an archive of cross-site scripting vulnerabilities.",
      "context": "Open Bug Bounty\n\n==Introduction==\nOpen Bug Bounty is a non-profit bug bounty platform established in 2014. The responsible disclosure platform allows independent security researchers to report XSS and similar security vulnerabilities on any website they discover using non-intrusive security testing techniques. The researchers may choose to make the details of the vulnerabilities public in 90 days since vulnerability submission or to communicate them only to the website operators. The program's expectation is that the operators of the affected website will reward the researchers for making their reports.\n\n\n\n== Program ==\nUnlike commercial bug bounty programs, Open Bug Bounty is a non-profit project and does not require payment by either the researchers or the website operators. Any bounty is a matter of agreement between the researchers and the website operators. Heise.de identified the potential for the website to be a vehicle for blackmailing website operators with the threat of disclosing vulnerabilities if no bounty is paid, but reported that Open Bug Bounty prohibits this.Open Bug Bounty was launched by private security enthusiasts in 2014, and as of February 2017 had recorded 100,000 vulnerabilities, of which 35,000 had been fixed. It grew out of the website XSSPosed, an archive of cross-site scripting vulnerabilities.In February 2018, the platform had 100,000 fixed vulnerabilities using coordinated disclosure program based on ISO 29147 guidelines. Up to the end of 2019, the platform reported 272,020 fixed vulnerabilities using coordinated disclosure program based on ISO 29147 guidelines."
    }
  },
  {
    "instruction": "Security management\n\n==Introduction==\nSecurity management is the identification of an organization's assets (including people, buildings, machines, systems and information assets), followed by the development, documentation, and implementation of policies and procedures for protecting assets.\nAn organization uses such security management procedures for information classification, threat assessment, risk assessment, and risk analysis to identify threats, categorize assets, and rate system vulnerabilities.\n\n== Loss prevention ==\n\nLoss prevention focuses on what one's critical assets are and how they are going to protect them. A key component to loss prevention is assessing the potential threats to the successful achievement of the goal. This must include the potential opportunities that further the object (why take the risk unless there's an upside?) Balance probability and impact determine and implement measures to minimize or eliminate those threats.\n\n== Security risk management ==\nThe management of security risks applies the principles of risk management to the management of security threats. It consists of identifying threats (or risk causes), assessing the effectiveness of existing controls to face those threats, determining the risks' consequence(s), prioritizing the risks by rating the likelihood and impact, classifying the type of risk, and selecting an appropriate risk option or risk response. In 2016, a universal standard for managing risks was developed in The Netherlands. In 2017, it was updated and named: Universal Security Management Systems Standard 2017.\n\n\n*** Types of risks ***\n\n\n**** External ****\nStrategic: Competition and customer demand.\nOperational: Regulations, suppliers, and contract.\nFinancial: FX and credit.\nHazard: Natural disasters, cyber, and external criminal acts.\nCompliance: New regulatory or legal requirements are introduced, or existing ones are changed, exposing the organization to a non-compliance risk if measures are not taken to ensure compliance.\n\n\n**** Internal ****\nStrategic: R&D.\nOperational: Systems and processes (H&R, Payroll).\nFinancial: Liquidity and cash flow.\nHazard: Safety and security; employees and equipment.\nCompliance: Concrete or potential changes in an organization's systems, processes, suppliers, etc. may create exposure to a legal or regulatory non-compliance.\n\n\n*** Risk options ***\n\n\n**** Risk avoidance ****\nThe first choice to be considered is the possibility of eliminating the existence of criminal opportunity or avoiding the creation of such an opportunity. When additional considerations or factors are not created as a result of this action that would create a greater risk. For example, removing all the cash flow from a retail outlet would eliminate the opportunity for stealing the money, but it would also eliminate the ability to conduct business.\n\n\n**** Risk reduction ****\nWhen avoiding or eliminating the criminal opportunity conflicts with the ability to conduct business, the next step is reducing the opportunity of potential loss to the lowest level consistent with the function of the business. In the example above, the application of risk reduction might result in the business keeping only enough cash on hand for one day's operation.\n\n\n**** Risk spreading ****\nAssets that remain exposed after the application of reduction and avoidance are the subjects of risk spreading. This is the concept that limits loss or potential losses by exposing the perpetrator to the probability of detection and apprehension prior to the consummation of the crime through the application of perimeter lighting, barred windows, and intrusion detection systems. The idea is to reduce the time available for thieves to steal assets and escape without apprehension.\n\n\n**** Risk transfer ****\nThe two primary methods of accomplishing risk transfer is to insure the assets or raise prices to cover the loss in the event of a criminal act. Generally speaking, when the first three steps have been properly applied, the cost of transferring risks is much lower.\n\n\n**** Risk acceptance ****\nAll of the remaining risks must simply be assumed by the business as a part of doing business. Included with these accepted losses are deductibles, which have been made as part of the insurance coverage.\n\n== Security policy implementations ==\n\n\n*** Intrusion detection ***\nAlarm device.\n\n\n*** Access control ***\nLocks, simple or sophisticated, such as biometric authentication and keycard locks.\n\n\n*** Physical security ***\nEnvironmental elements (ex. Mountains, Trees, etc.).\nBarricade.\nSecurity guards (armed or unarmed) with wireless communication devices (e.g., two-way radio).\nSecurity lighting (spotlight, etc.).\nSecurity Cameras.\nMotion Detectors.\nIBNS containers for cash in transit.\n\n\n*** Procedures ***\nCoordination with law enforcement agencies.\nFraud management.\nRisk Management.\nCPTED.\nRisk Analysis.\nRisk Mitigation.\nContingency Planning.\n\nWhat is the process of security management and what are its main components?",
    "context": "",
    "output": "A: Security management is the process that involves identifying an organization's assets, developing and implementing policies and procedures to protect these assets, and conducting information classification, threat assessment, risk assessment, and risk analysis to identify and mitigate potential threats. The main components of security management include asset identification, policy and procedure development, information classification, threat assessment, risk assessment, and risk analysis.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the process of security management and what are its main components?",
      "answer": "Security management is the process that involves identifying an organization's assets, developing and implementing policies and procedures to protect these assets, and conducting information classification, threat assessment, risk assessment, and risk analysis to identify and mitigate potential threats. The main components of security management include asset identification, policy and procedure development, information classification, threat assessment, risk assessment, and risk analysis.",
      "context": "Security management\n\n==Introduction==\nSecurity management is the identification of an organization's assets (including people, buildings, machines, systems and information assets), followed by the development, documentation, and implementation of policies and procedures for protecting assets.\nAn organization uses such security management procedures for information classification, threat assessment, risk assessment, and risk analysis to identify threats, categorize assets, and rate system vulnerabilities.\n\n== Loss prevention ==\n\nLoss prevention focuses on what one's critical assets are and how they are going to protect them. A key component to loss prevention is assessing the potential threats to the successful achievement of the goal. This must include the potential opportunities that further the object (why take the risk unless there's an upside?) Balance probability and impact determine and implement measures to minimize or eliminate those threats.\n\n== Security risk management ==\nThe management of security risks applies the principles of risk management to the management of security threats. It consists of identifying threats (or risk causes), assessing the effectiveness of existing controls to face those threats, determining the risks' consequence(s), prioritizing the risks by rating the likelihood and impact, classifying the type of risk, and selecting an appropriate risk option or risk response. In 2016, a universal standard for managing risks was developed in The Netherlands. In 2017, it was updated and named: Universal Security Management Systems Standard 2017.\n\n\n*** Types of risks ***\n\n\n**** External ****\nStrategic: Competition and customer demand.\nOperational: Regulations, suppliers, and contract.\nFinancial: FX and credit.\nHazard: Natural disasters, cyber, and external criminal acts.\nCompliance: New regulatory or legal requirements are introduced, or existing ones are changed, exposing the organization to a non-compliance risk if measures are not taken to ensure compliance.\n\n\n**** Internal ****\nStrategic: R&D.\nOperational: Systems and processes (H&R, Payroll).\nFinancial: Liquidity and cash flow.\nHazard: Safety and security; employees and equipment.\nCompliance: Concrete or potential changes in an organization's systems, processes, suppliers, etc. may create exposure to a legal or regulatory non-compliance.\n\n\n*** Risk options ***\n\n\n**** Risk avoidance ****\nThe first choice to be considered is the possibility of eliminating the existence of criminal opportunity or avoiding the creation of such an opportunity. When additional considerations or factors are not created as a result of this action that would create a greater risk. For example, removing all the cash flow from a retail outlet would eliminate the opportunity for stealing the money, but it would also eliminate the ability to conduct business.\n\n\n**** Risk reduction ****\nWhen avoiding or eliminating the criminal opportunity conflicts with the ability to conduct business, the next step is reducing the opportunity of potential loss to the lowest level consistent with the function of the business. In the example above, the application of risk reduction might result in the business keeping only enough cash on hand for one day's operation.\n\n\n**** Risk spreading ****\nAssets that remain exposed after the application of reduction and avoidance are the subjects of risk spreading. This is the concept that limits loss or potential losses by exposing the perpetrator to the probability of detection and apprehension prior to the consummation of the crime through the application of perimeter lighting, barred windows, and intrusion detection systems. The idea is to reduce the time available for thieves to steal assets and escape without apprehension.\n\n\n**** Risk transfer ****\nThe two primary methods of accomplishing risk transfer is to insure the assets or raise prices to cover the loss in the event of a criminal act. Generally speaking, when the first three steps have been properly applied, the cost of transferring risks is much lower.\n\n\n**** Risk acceptance ****\nAll of the remaining risks must simply be assumed by the business as a part of doing business. Included with these accepted losses are deductibles, which have been made as part of the insurance coverage.\n\n== Security policy implementations ==\n\n\n*** Intrusion detection ***\nAlarm device.\n\n\n*** Access control ***\nLocks, simple or sophisticated, such as biometric authentication and keycard locks.\n\n\n*** Physical security ***\nEnvironmental elements (ex. Mountains, Trees, etc.).\nBarricade.\nSecurity guards (armed or unarmed) with wireless communication devices (e.g., two-way radio).\nSecurity lighting (spotlight, etc.).\nSecurity Cameras.\nMotion Detectors.\nIBNS containers for cash in transit.\n\n\n*** Procedures ***\nCoordination with law enforcement agencies.\nFraud management.\nRisk Management.\nCPTED.\nRisk Analysis.\nRisk Mitigation.\nContingency Planning."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the role of Apache CXF in Apache Fortress?",
    "context": "",
    "output": "Apache CXF is used in the Rest component of Apache Fortress to provide HTTP protocol wrappers of core APIs.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of Apache CXF in Apache Fortress?",
      "answer": "Apache CXF is used in the Rest component of Apache Fortress to provide HTTP protocol wrappers of core APIs."
    }
  },
  {
    "instruction": "Digital DawgPound\n\n==Introduction==\nThe Digital DawgPound (more commonly referred to as the \"DDP\") is a group of hackers, best known for a series of articles in hacker magazines such as 2600: The Hacker Quarterly and Make, the long-running webcast Binary Revolution Radio, and a very active set of forums with posts from high-profile hackers such as Strom Carlson, decoder, Phiber Optik and StankDawg. The stated mission of the DDP is to propagate a more positive image of hackers than the negative mass media stereotype.  The group welcomes new members who want to learn about hacking, and attempts to teach them more positive aspects and steer them away from the negative aspects, by reinforcing the hacker ethic.  Their goal is to show that hackers can, and regularly do, make positive contributions not only to technology, but to society as a whole.\n\n\n\n== Members ==\nOver the years, DDP membership has included several staff writers for 2600: The Hacker Quarterly and Blacklisted! 411 magazine including StankDawg and bland_inquisitor.  They frequently publish articles, provide content, and appear on many media sources across the global Interweb.  DDP members are also regular speakers at hacking conferences such as DEF CON, H.O.P.E., and Interzone.\nThe majority of DDP members are college graduates and have professional experience in the computer industry.  Some work for Fortune 500 companies, while others have been entrepreneurs who have created successful businesses.  They hold memberships in Mensa and the International High IQ society.\n\n== Binary Revolution ==\nThe best known of the DDP projects is that of Binary Revolution, or \"BinRev\".  This project was created in an attempt to bring the hacking community back together, working towards a common, positive goal of reclaiming the name of hackers.  The Binary Revolution emphasizes positive aspects of hacking and projects that help society.  It does this in a variety of outlets including monthly meetings, the weekly radio show Binary Revolution Radio(BRR), a video-based series of shows called HackTV, and very active message board forums.\nBinary Revolution Radio, often shortened to \"BRR\", is one small part of the binrev community.  It is common for people to discover BRR on one of the many podcast sites or applications out there and not realize that the \"Binary Revolution\" refers to a larger community than just the radio show.  When people refer to \"BinRev\" they should not be referring only to the radio show.  They should be referring to the community of projects as a whole, specifically focusing on the forums.\n\n== Recognition ==\nThe DDP maintains a blog \"which they refer to as a \"blawg\". Posts by DDP members have been featured on other technology-related sites such as those of Make Magazine,\nHackADay,\nHacked Gadgets, and others.\n\n== Works ==\n\n\n*** Printed ***\nNatas - \"Backspoofing 101\", Spring 2007, 2600 Magazine\nNatas - \"Ownage by AdSense\", Fall 2006, 2600 Magazine\nBlack Ratchet - \"Not Quite Dead Yet\", Spring 2006, 2600 Magazine\ndual_parallel - \"Port Knocking Simplified\", Winter 2005, Blacklisted411 Magazine\nStankDawg - \"The Art of Electronic Deduction\", Winter 2005, Blacklisted411 Magazine\ndual_parallel - \"Remote Encrypted Data Access\", Fall 2005, Blacklisted411 Magazine\nStankDawg - \"Stupid Webstats Tricks\", Fall 2005, 2600 Magazine\nStankDawg - \"Hacking Google AdWords\", Summer 2005, 2600 Magazine\nStankDawg - \"Disposable Email Vulnerabilities\", Spring 2005, 2600 Magazine\nStankDawg - \"0wning Universal Studios Florida\", Fall 2004, Blacklisted411 Magazine\nStankDawg - \"How to Hack The Lottery\", Fall 2004, 2600 Magazine\nStankDawg - \"Robots and Spiders\", Winter 2003, 2600 Magazine\nntheory - \"Backspoofing: Let the Telco Do the Walking\", July 2004, BR magazine Issue 2.1\nntheory - \"Packet8 IP Phone service\", July 2004, BR magazine Issue 2.1\ndual_parallel - \"White Hat Wi-Fi\", July 2004, BR magazine Issue 2.1\nhacnslash - \"An IR receiver for your PC\", July 2004, BR magazine Issue 2.1\nStankDawg - \"Hacking 101:  Directory Transversal\", July 2004, BR magazine Issue 2.1\nntheory - \"Hacking Coinstar\", September 2003, BR magazine Issue 1.2\nw1nt3rmut3 - \"Best buy insecurities: revisited\", September 2003, BR magazine Issue 1.2\nbland_inquisitor - \"Kismet on Knoppix HD install\", September 2003, BR magazine Issue 1.2\ndual_parallel - \"A Physical Security Primer for the Community\", September 2003, BR magazine Issue 1.2\nlogan5 - \"case modeling\", September 2003, BR magazine Issue 1.2\nvooduHAL - \"Insecurities in my cafe cup\", September 2003, BR magazine Issue 1.2\nStankDawg - \"Hacking 101:  Targeting Theory\", September 2003, BR magazine Issue 1.2\nbland_inquisitor - \"Denial of Service Attacks, Tools of the Tools\", May 2003, BR magazine and Fall 2003, 2600 Magazine Issue 1.1\nStankDawg - \"Hacking 101: Footprinting a system\", May 2003, BR magazine Issue 1.1\nevo_tech - \"Your rights and why you have already lost them\", May 2003, BR magazine Issue 1.1\nnick84 & StankDawg - \"2600 Secrets\", May 2003, BR magazine Issue 1.1\nnick84 - \"Watching the watchers\", May 2003, BR magazine Issue 1.1\ndual_parallel - \"Public TTYs: Description and Methodologies for Free Calling\", May 2003, BR magazine Issue 1.1\nbland_inquisitor - \"Cookies:  The good, the bad, and the ugly\", May 2003, BR magazine Issue 1.1\nStankDawg - \"A newbies guide to ghettodriving\", May 2003, BR magazine Issue 1.1\nw1nt3rmut3 - \"Phreaking Italy\", May 2003, BR magazine Issue 1.1\nw1nt3rmut3 - \"Best Buy Insecurities\", Spring 2003, 2600 Magazine\nbland_inquisitor - \"Honeypots: Building the Better Hacker\", Winter 2002, 2600 Magazine\nStankDawg - \"A History of 31337sp34k\", Fall 2002, 2600 Magazine\nbland_inquisitor - \"Telezapper, Telemarketers, and the TCPA\", Fall 2002, 2600 Magazine\ndual_parallel - \"Retail Hardware Revisited\", Spring 2002, 2600 Magazine\nStankDawg - \"Transaction Based Systems\", Spring 2002, 2600 Magazine\ndual_parallel - \"Hacking Retail Hardware\", Fall 2001, 2600 Magazine\nStankDawg - \"Batch vs. Interactive\", Summer 1999, 2600 Magazine\n\n\n*** Online ***\nStankDawg - \"Wardriving with Mickey\", October 2005\ndual_parallel & bland_inquisitor - \"Slackware 10.2 Tips\", September 2005\nlogan5 - \"The iPod: It's not just for music anymore\", January 2005\nbland_inquisitor - \"Kodak Picture Maker: In's and Out's\", December 2004\nStankDawg - \"Hackers Insomnia\", October 2004, Frequency zine\ndual_parallel & bland_inquisitor - \"Basic Slackware Security\", April 2004\nStankDawg - \"Scanning GO.MSN.COM\", May 2004, Radical Future zine Issue #5\nStankDawg - \"Fun with the dnL flipit chatbot\", December 2003, Outbreak zine issue #14\nStankDawg & bi0s - \"Inside Circuit City\", December 2003, Outbreak zine issue #14\nhacnslash - \"Dumpster Diving - Art or Science?\", September 23, 2003\nbland_inquisitor - \"Social Insecurity\", December 2003, Radical Future zine Issue #4\nntheory - \"Generating Millisecond Accurate, Multi-Frequency Wave Files in Perl\", July 2003\nStankDawg - \"DMCA vs googlefight.com\", December 2002, Outbreak zine issue #12\nStankDawg - \"Basic Directory Transversal\", November 2002, Outbreak zine issue #11\nStankDawg - \"Hacking Movies\", Winter 2002, Radical Future zine Issue #3\nStankDawg - \"AIM Transcript (Campaign For Freedom)\", Winter 2002, Radical Future zine Issue #3\n\n\n*** Presentations ***\nStankDawg - \"Binary Revolution Radio - Season 4 live!\", July 2006, H.O.P.E. Number Six\nStankDawg - \"The Art of Electronic Deduction\", March 2006, Interz0ne 5 and July 2006, H.O.P.E. Number Six\nStankDawg - \"Hacking Google AdWords\", July 2005, DEF CON 13\nBlack Ratchet (with Strom Carlson) - \"Be Your Own Telephone Company...With Asterisk\", July 2005, DEF CON 13\nStankDawg - \"Hacker Radio\", July 2004, The fifth H.O.P.E. (guest panelist)\nStankDawg - \"AS/400: Lifting the veil of obscurity\", July 2004, The fifth H.O.P.E.\nStankDawg - \"Disposable Email vulnerabilities\", March 2004, Interz0ne 4jagan rider twg - \"Binary Revolution Radio - Season 4 live!\", July 2006, H.O.P.E. Number Six\n\nStankDawg - \"The Art of Electronic Deduction\", March 2006, Interz0ne 5 and July 2006, H.O.P.E. Number Sixhe haker as the mobiltnfounsinsniuiuuyttyukkkuad\n\nQ: How does the DDP maintain a presence in the technology community and how have their posts been recognized?",
    "context": "",
    "output": "A: The DDP maintains a blog, referred to as a \"blawg\", and their posts have been featured on technology-related sites such as Make Magazine, HackADay, and Hacked Gadgets.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the DDP maintain a presence in the technology community and how have their posts been recognized?",
      "answer": "The DDP maintains a blog, referred to as a \"blawg\", and their posts have been featured on technology-related sites such as Make Magazine, HackADay, and Hacked Gadgets.",
      "context": "Digital DawgPound\n\n==Introduction==\nThe Digital DawgPound (more commonly referred to as the \"DDP\") is a group of hackers, best known for a series of articles in hacker magazines such as 2600: The Hacker Quarterly and Make, the long-running webcast Binary Revolution Radio, and a very active set of forums with posts from high-profile hackers such as Strom Carlson, decoder, Phiber Optik and StankDawg. The stated mission of the DDP is to propagate a more positive image of hackers than the negative mass media stereotype.  The group welcomes new members who want to learn about hacking, and attempts to teach them more positive aspects and steer them away from the negative aspects, by reinforcing the hacker ethic.  Their goal is to show that hackers can, and regularly do, make positive contributions not only to technology, but to society as a whole.\n\n\n\n== Members ==\nOver the years, DDP membership has included several staff writers for 2600: The Hacker Quarterly and Blacklisted! 411 magazine including StankDawg and bland_inquisitor.  They frequently publish articles, provide content, and appear on many media sources across the global Interweb.  DDP members are also regular speakers at hacking conferences such as DEF CON, H.O.P.E., and Interzone.\nThe majority of DDP members are college graduates and have professional experience in the computer industry.  Some work for Fortune 500 companies, while others have been entrepreneurs who have created successful businesses.  They hold memberships in Mensa and the International High IQ society.\n\n== Binary Revolution ==\nThe best known of the DDP projects is that of Binary Revolution, or \"BinRev\".  This project was created in an attempt to bring the hacking community back together, working towards a common, positive goal of reclaiming the name of hackers.  The Binary Revolution emphasizes positive aspects of hacking and projects that help society.  It does this in a variety of outlets including monthly meetings, the weekly radio show Binary Revolution Radio(BRR), a video-based series of shows called HackTV, and very active message board forums.\nBinary Revolution Radio, often shortened to \"BRR\", is one small part of the binrev community.  It is common for people to discover BRR on one of the many podcast sites or applications out there and not realize that the \"Binary Revolution\" refers to a larger community than just the radio show.  When people refer to \"BinRev\" they should not be referring only to the radio show.  They should be referring to the community of projects as a whole, specifically focusing on the forums.\n\n== Recognition ==\nThe DDP maintains a blog \"which they refer to as a \"blawg\". Posts by DDP members have been featured on other technology-related sites such as those of Make Magazine,\nHackADay,\nHacked Gadgets, and others.\n\n== Works ==\n\n\n*** Printed ***\nNatas - \"Backspoofing 101\", Spring 2007, 2600 Magazine\nNatas - \"Ownage by AdSense\", Fall 2006, 2600 Magazine\nBlack Ratchet - \"Not Quite Dead Yet\", Spring 2006, 2600 Magazine\ndual_parallel - \"Port Knocking Simplified\", Winter 2005, Blacklisted411 Magazine\nStankDawg - \"The Art of Electronic Deduction\", Winter 2005, Blacklisted411 Magazine\ndual_parallel - \"Remote Encrypted Data Access\", Fall 2005, Blacklisted411 Magazine\nStankDawg - \"Stupid Webstats Tricks\", Fall 2005, 2600 Magazine\nStankDawg - \"Hacking Google AdWords\", Summer 2005, 2600 Magazine\nStankDawg - \"Disposable Email Vulnerabilities\", Spring 2005, 2600 Magazine\nStankDawg - \"0wning Universal Studios Florida\", Fall 2004, Blacklisted411 Magazine\nStankDawg - \"How to Hack The Lottery\", Fall 2004, 2600 Magazine\nStankDawg - \"Robots and Spiders\", Winter 2003, 2600 Magazine\nntheory - \"Backspoofing: Let the Telco Do the Walking\", July 2004, BR magazine Issue 2.1\nntheory - \"Packet8 IP Phone service\", July 2004, BR magazine Issue 2.1\ndual_parallel - \"White Hat Wi-Fi\", July 2004, BR magazine Issue 2.1\nhacnslash - \"An IR receiver for your PC\", July 2004, BR magazine Issue 2.1\nStankDawg - \"Hacking 101:  Directory Transversal\", July 2004, BR magazine Issue 2.1\nntheory - \"Hacking Coinstar\", September 2003, BR magazine Issue 1.2\nw1nt3rmut3 - \"Best buy insecurities: revisited\", September 2003, BR magazine Issue 1.2\nbland_inquisitor - \"Kismet on Knoppix HD install\", September 2003, BR magazine Issue 1.2\ndual_parallel - \"A Physical Security Primer for the Community\", September 2003, BR magazine Issue 1.2\nlogan5 - \"case modeling\", September 2003, BR magazine Issue 1.2\nvooduHAL - \"Insecurities in my cafe cup\", September 2003, BR magazine Issue 1.2\nStankDawg - \"Hacking 101:  Targeting Theory\", September 2003, BR magazine Issue 1.2\nbland_inquisitor - \"Denial of Service Attacks, Tools of the Tools\", May 2003, BR magazine and Fall 2003, 2600 Magazine Issue 1.1\nStankDawg - \"Hacking 101: Footprinting a system\", May 2003, BR magazine Issue 1.1\nevo_tech - \"Your rights and why you have already lost them\", May 2003, BR magazine Issue 1.1\nnick84 & StankDawg - \"2600 Secrets\", May 2003, BR magazine Issue 1.1\nnick84 - \"Watching the watchers\", May 2003, BR magazine Issue 1.1\ndual_parallel - \"Public TTYs: Description and Methodologies for Free Calling\", May 2003, BR magazine Issue 1.1\nbland_inquisitor - \"Cookies:  The good, the bad, and the ugly\", May 2003, BR magazine Issue 1.1\nStankDawg - \"A newbies guide to ghettodriving\", May 2003, BR magazine Issue 1.1\nw1nt3rmut3 - \"Phreaking Italy\", May 2003, BR magazine Issue 1.1\nw1nt3rmut3 - \"Best Buy Insecurities\", Spring 2003, 2600 Magazine\nbland_inquisitor - \"Honeypots: Building the Better Hacker\", Winter 2002, 2600 Magazine\nStankDawg - \"A History of 31337sp34k\", Fall 2002, 2600 Magazine\nbland_inquisitor - \"Telezapper, Telemarketers, and the TCPA\", Fall 2002, 2600 Magazine\ndual_parallel - \"Retail Hardware Revisited\", Spring 2002, 2600 Magazine\nStankDawg - \"Transaction Based Systems\", Spring 2002, 2600 Magazine\ndual_parallel - \"Hacking Retail Hardware\", Fall 2001, 2600 Magazine\nStankDawg - \"Batch vs. Interactive\", Summer 1999, 2600 Magazine\n\n\n*** Online ***\nStankDawg - \"Wardriving with Mickey\", October 2005\ndual_parallel & bland_inquisitor - \"Slackware 10.2 Tips\", September 2005\nlogan5 - \"The iPod: It's not just for music anymore\", January 2005\nbland_inquisitor - \"Kodak Picture Maker: In's and Out's\", December 2004\nStankDawg - \"Hackers Insomnia\", October 2004, Frequency zine\ndual_parallel & bland_inquisitor - \"Basic Slackware Security\", April 2004\nStankDawg - \"Scanning GO.MSN.COM\", May 2004, Radical Future zine Issue #5\nStankDawg - \"Fun with the dnL flipit chatbot\", December 2003, Outbreak zine issue #14\nStankDawg & bi0s - \"Inside Circuit City\", December 2003, Outbreak zine issue #14\nhacnslash - \"Dumpster Diving - Art or Science?\", September 23, 2003\nbland_inquisitor - \"Social Insecurity\", December 2003, Radical Future zine Issue #4\nntheory - \"Generating Millisecond Accurate, Multi-Frequency Wave Files in Perl\", July 2003\nStankDawg - \"DMCA vs googlefight.com\", December 2002, Outbreak zine issue #12\nStankDawg - \"Basic Directory Transversal\", November 2002, Outbreak zine issue #11\nStankDawg - \"Hacking Movies\", Winter 2002, Radical Future zine Issue #3\nStankDawg - \"AIM Transcript (Campaign For Freedom)\", Winter 2002, Radical Future zine Issue #3\n\n\n*** Presentations ***\nStankDawg - \"Binary Revolution Radio - Season 4 live!\", July 2006, H.O.P.E. Number Six\nStankDawg - \"The Art of Electronic Deduction\", March 2006, Interz0ne 5 and July 2006, H.O.P.E. Number Six\nStankDawg - \"Hacking Google AdWords\", July 2005, DEF CON 13\nBlack Ratchet (with Strom Carlson) - \"Be Your Own Telephone Company...With Asterisk\", July 2005, DEF CON 13\nStankDawg - \"Hacker Radio\", July 2004, The fifth H.O.P.E. (guest panelist)\nStankDawg - \"AS/400: Lifting the veil of obscurity\", July 2004, The fifth H.O.P.E.\nStankDawg - \"Disposable Email vulnerabilities\", March 2004, Interz0ne 4jagan rider twg - \"Binary Revolution Radio - Season 4 live!\", July 2006, H.O.P.E. Number Six\n\nStankDawg - \"The Art of Electronic Deduction\", March 2006, Interz0ne 5 and July 2006, H.O.P.E. Number Sixhe haker as the mobiltnfounsinsniuiuuyttyukkkuad"
    }
  },
  {
    "instruction": "Write an answer to the following question: Who is Phineas Fisher and what was their role in the HackingTeam data breach?",
    "context": "",
    "output": "Phineas Fisher is a hacker who claimed responsibility for the HackingTeam data breach in 2015. They previously attacked spyware firm Gamma International and published a \"how-to\" guide in 2016 explaining the motivations behind the attack.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Who is Phineas Fisher and what was their role in the HackingTeam data breach?",
      "answer": "Phineas Fisher is a hacker who claimed responsibility for the HackingTeam data breach in 2015. They previously attacked spyware firm Gamma International and published a \"how-to\" guide in 2016 explaining the motivations behind the attack."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does PANA ensure secure network access?",
    "context": "",
    "output": "PANA ensures secure network access by using the Extensible Authentication Protocol (EAP) for authentication and key management, allowing dynamic service provider selection, and supporting various authentication methods suitable for roaming users.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does PANA ensure secure network access?",
      "answer": "PANA ensures secure network access by using the Extensible Authentication Protocol (EAP) for authentication and key management, allowing dynamic service provider selection, and supporting various authentication methods suitable for roaming users."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the xkcd comic 538: Security use humor to illustrate the dangers of rubber-hose cryptanalysis?",
    "context": "",
    "output": "The xkcd comic 538: Security uses humor to illustrate the dangers of rubber-hose cryptanalysis by showing the absurdity of a five-dollar wrench being used to defeat advanced encryption.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the xkcd comic 538: Security use humor to illustrate the dangers of rubber-hose cryptanalysis?",
      "answer": "The xkcd comic 538: Security uses humor to illustrate the dangers of rubber-hose cryptanalysis by showing the absurdity of a five-dollar wrench being used to defeat advanced encryption."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the CA/Browser Forum and when was it established?",
    "context": "",
    "output": "The CA/Browser Forum is an organization that facilitates communication among browser vendors and Certificate Authorities. It was established in 2004, around the same time that discussions for the inclusion of CAcert's root certificate in Mozilla Application Suite and Mozilla Firefox started.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the CA/Browser Forum and when was it established?",
      "answer": "The CA/Browser Forum is an organization that facilitates communication among browser vendors and Certificate Authorities. It was established in 2004, around the same time that discussions for the inclusion of CAcert's root certificate in Mozilla Application Suite and Mozilla Firefox started."
    }
  },
  {
    "instruction": "Answer based on context:\n\nPromiscuous mode\n\n==Introduction==\nIn computer networking, promiscuous mode is a mode for a wired network interface controller (NIC) or wireless network interface controller (WNIC) that causes the controller to pass all traffic it receives to the central processing unit (CPU) rather than passing only the frames that the controller is specifically programmed to receive.  This mode is normally used for packet sniffing that takes place on a router or on a computer connected to a wired network or one being part of a wireless LAN. Interfaces are placed into promiscuous mode by software bridges often used with hardware virtualization.\nIn IEEE 802 networks such as Ethernet or IEEE 802.11, each frame includes a destination MAC address.  In non-promiscuous mode, when a NIC receives a frame, it drops it unless the frame is addressed to that NIC's MAC address or is a broadcast or multicast addressed frame.  In promiscuous mode, however, the NIC allows all frames through, thus allowing the computer to read frames intended for other machines or network devices.\nMany operating systems require superuser privileges to enable promiscuous mode. A non-routing node in promiscuous mode can generally only monitor traffic to and from other nodes within the same broadcast domain (for Ethernet and IEEE 802.11) or ring (for Token Ring).  Computers attached to the same Ethernet hub satisfy this requirement, which is why network switches are used to combat malicious use of promiscuous mode. A router may monitor all traffic that it routes.\nPromiscuous mode is often used to diagnose network connectivity issues. There are programs that make use of this feature to show the user all the data being transferred over the network. Some protocols like FTP and Telnet transfer data and passwords in clear text, without encryption, and network scanners can see this data. Therefore, computer users are encouraged to stay away from insecure protocols like telnet and use more secure ones such as SSH.\n\n== Detection ==\nAs promiscuous mode can be used in a malicious way to capture private data in transit on a network, computer security professionals might be interested in detecting network devices that are in promiscuous mode. In promiscuous mode, some software might send responses to frames even though they were addressed to another machine. However, experienced sniffers can prevent this (e.g., using carefully designed firewall settings). An example is sending a ping (ICMP echo request) with the wrong MAC address but the right IP address. If an adapter is operating in normal mode, it will drop this frame, and the IP stack never sees or responds to it. If the adapter is in promiscuous mode, the frame will be passed on, and the IP stack on the machine (to which a MAC address has no meaning) will respond as it would to any other ping. The sniffer can prevent this by configuring a firewall to block ICMP traffic.\n\n== Some applications that use promiscuous mode ==\nThe following applications and applications classes use promiscuous mode.\n\nHow can promiscuous mode be used to diagnose network connectivity issues?",
    "context": "",
    "output": "Promiscuous mode can be used to diagnose network connectivity issues by allowing a computer to see all traffic on the network, including frames that are not specifically addressed to its MAC address.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can promiscuous mode be used to diagnose network connectivity issues?",
      "answer": "Promiscuous mode can be used to diagnose network connectivity issues by allowing a computer to see all traffic on the network, including frames that are not specifically addressed to its MAC address.",
      "context": "Promiscuous mode\n\n==Introduction==\nIn computer networking, promiscuous mode is a mode for a wired network interface controller (NIC) or wireless network interface controller (WNIC) that causes the controller to pass all traffic it receives to the central processing unit (CPU) rather than passing only the frames that the controller is specifically programmed to receive.  This mode is normally used for packet sniffing that takes place on a router or on a computer connected to a wired network or one being part of a wireless LAN. Interfaces are placed into promiscuous mode by software bridges often used with hardware virtualization.\nIn IEEE 802 networks such as Ethernet or IEEE 802.11, each frame includes a destination MAC address.  In non-promiscuous mode, when a NIC receives a frame, it drops it unless the frame is addressed to that NIC's MAC address or is a broadcast or multicast addressed frame.  In promiscuous mode, however, the NIC allows all frames through, thus allowing the computer to read frames intended for other machines or network devices.\nMany operating systems require superuser privileges to enable promiscuous mode. A non-routing node in promiscuous mode can generally only monitor traffic to and from other nodes within the same broadcast domain (for Ethernet and IEEE 802.11) or ring (for Token Ring).  Computers attached to the same Ethernet hub satisfy this requirement, which is why network switches are used to combat malicious use of promiscuous mode. A router may monitor all traffic that it routes.\nPromiscuous mode is often used to diagnose network connectivity issues. There are programs that make use of this feature to show the user all the data being transferred over the network. Some protocols like FTP and Telnet transfer data and passwords in clear text, without encryption, and network scanners can see this data. Therefore, computer users are encouraged to stay away from insecure protocols like telnet and use more secure ones such as SSH.\n\n== Detection ==\nAs promiscuous mode can be used in a malicious way to capture private data in transit on a network, computer security professionals might be interested in detecting network devices that are in promiscuous mode. In promiscuous mode, some software might send responses to frames even though they were addressed to another machine. However, experienced sniffers can prevent this (e.g., using carefully designed firewall settings). An example is sending a ping (ICMP echo request) with the wrong MAC address but the right IP address. If an adapter is operating in normal mode, it will drop this frame, and the IP stack never sees or responds to it. If the adapter is in promiscuous mode, the frame will be passed on, and the IP stack on the machine (to which a MAC address has no meaning) will respond as it would to any other ping. The sniffer can prevent this by configuring a firewall to block ICMP traffic.\n\n== Some applications that use promiscuous mode ==\nThe following applications and applications classes use promiscuous mode."
    }
  },
  {
    "instruction": "Context: DenyHosts\n\n==Introduction==\nDenyHosts is a log-based intrusion-prevention security tool for SSH servers written in Python. It is intended to prevent brute-force attacks on SSH servers by monitoring invalid login attempts in the authentication log and blocking the originating IP addresses. DenyHosts is developed by Phil Schwartz, who is also the developer of Kodos Python Regular Expression Debugger.\n\n\n\n== Operation ==\nDenyHosts checks the end of the authentication log for recent failed login attempts. It records information about their originating IP addresses and compares the number of invalid attempts to a user-specified threshold. If there have been too many invalid attempts it assumes a dictionary attack is occurring and prevents the IP address from making any further attempts by adding it to /etc/hosts.deny on the server. DenyHosts 2.0 and above support centralized synchronization, so that repeat offenders are blocked from many computers. The site denyhosts.net gathers statistics from computers running the software.\nDenyHosts is restricted to connections using IPv4. It does not work with IPv6.\nDenyHosts may be run manually, as a daemon, or as a cron job.\n\n== Discoveries ==\nIn July 2007, The Register reported that from May until July that year, \"compromised computers\" at Oracle UK were listed among the ten worst offenders for launching brute force SSH attacks on the Internet, according to public DenyHosts listings. After an investigation, Oracle denied suggestions that any of its computers had been compromised.\n\n== Vulnerabilities ==\nDaniel B. Cid wrote a paper showing that DenyHosts, as well the similar programs Fail2ban and BlockHosts, were vulnerable to remote log injection, an attack technique similar to SQL injection, in which a specially crafted user name is used to trigger a block against a site chosen by the attacker. This was fixed in version 2.6.\n\n== Forks and descendants ==\nSince there had been no further development by the original author Phil Schwartz after the release of version 2.6 (December 2006) and claimed version 2.7 (November 2008) for which no actual downloadable package is available, development was first continued in February 2012 by Matt Ruffalo in a GitHub repository. An independent and separate fork was started at the almost-identically named DenyHost SourceForge project site with the release of a different version 2.7 in May 2014. After version 2.9, the new SourceForge project has merged with the earlier GitHub repository, and newer versions are available via both means.\nThe software that runs the centralized synchronization server which DenyHosts versions 2.0 and above can use, has never been released. Independent synchronization server software has been developed by Jan-Pascal van Best since June 2015.\n\nQuestion: How can users run DenyHosts, and what are the available modes?\n\nAnswer:",
    "context": "",
    "output": "DenyHosts can be run manually, as a daemon, or as a cron job. These modes offer flexibility for users to manage and schedule the tool's operations.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can users run DenyHosts, and what are the available modes?",
      "answer": "DenyHosts can be run manually, as a daemon, or as a cron job. These modes offer flexibility for users to manage and schedule the tool's operations.",
      "context": "DenyHosts\n\n==Introduction==\nDenyHosts is a log-based intrusion-prevention security tool for SSH servers written in Python. It is intended to prevent brute-force attacks on SSH servers by monitoring invalid login attempts in the authentication log and blocking the originating IP addresses. DenyHosts is developed by Phil Schwartz, who is also the developer of Kodos Python Regular Expression Debugger.\n\n\n\n== Operation ==\nDenyHosts checks the end of the authentication log for recent failed login attempts. It records information about their originating IP addresses and compares the number of invalid attempts to a user-specified threshold. If there have been too many invalid attempts it assumes a dictionary attack is occurring and prevents the IP address from making any further attempts by adding it to /etc/hosts.deny on the server. DenyHosts 2.0 and above support centralized synchronization, so that repeat offenders are blocked from many computers. The site denyhosts.net gathers statistics from computers running the software.\nDenyHosts is restricted to connections using IPv4. It does not work with IPv6.\nDenyHosts may be run manually, as a daemon, or as a cron job.\n\n== Discoveries ==\nIn July 2007, The Register reported that from May until July that year, \"compromised computers\" at Oracle UK were listed among the ten worst offenders for launching brute force SSH attacks on the Internet, according to public DenyHosts listings. After an investigation, Oracle denied suggestions that any of its computers had been compromised.\n\n== Vulnerabilities ==\nDaniel B. Cid wrote a paper showing that DenyHosts, as well the similar programs Fail2ban and BlockHosts, were vulnerable to remote log injection, an attack technique similar to SQL injection, in which a specially crafted user name is used to trigger a block against a site chosen by the attacker. This was fixed in version 2.6.\n\n== Forks and descendants ==\nSince there had been no further development by the original author Phil Schwartz after the release of version 2.6 (December 2006) and claimed version 2.7 (November 2008) for which no actual downloadable package is available, development was first continued in February 2012 by Matt Ruffalo in a GitHub repository. An independent and separate fork was started at the almost-identically named DenyHost SourceForge project site with the release of a different version 2.7 in May 2014. After version 2.9, the new SourceForge project has merged with the earlier GitHub repository, and newer versions are available via both means.\nThe software that runs the centralized synchronization server which DenyHosts versions 2.0 and above can use, has never been released. Independent synchronization server software has been developed by Jan-Pascal van Best since June 2015."
    }
  },
  {
    "instruction": "Cybersquatting\n\n==Introduction==\nCybersquatting (also known as domain squatting) is the practice of registering, trafficking in, or using an Internet domain name, with a bad faith intent to profit from the goodwill of a trademark belonging to someone else.\nThe term is derived from \"squatting\", which is the act of occupying an abandoned or unoccupied space or building that the squatter does not own, rent, or otherwise have permission to use.\n\n== Terminology ==\nIn popular terms, \u201ccybersquatting\u201d is the term most frequently used to describe the deliberate, bad faith abusive registration of a domain name in violation of trademark rights. However, precisely because of its popular currency, the term has different meanings to different people. Some people, for example, include \u201cwarehousing,\u201d or the practice of registering a collection of domain names corresponding to trademarks with the intention of selling the registrations to the owners of the trademarks, within the notion of cybersquatting, while others distinguish between the two terms. In the former definition, the cybersquatter may offer to sell the domain to the person or company who owns a trademark contained within the name at an inflated price.\nSimilarly, some consider \u201ccyberpiracy\u201d to be interchangeable with \u201ccybersquatting,\u201d whereas others consider that the former term relates to violation of copyright in the content of websites, rather than to abusive domain name registrations.Because of the various interpretations of the term, World Intellectual Property Organization (WIPO), in a 1999 report, approved by its member states, considered it as the abusive registration of a domain name.\n\n== Legal resolution ==\n\n\n*** International ***\n\nSince 1999, the World Intellectual Property Organization (WIPO) has provided an administrative process wherein a trademark holder can attempt to claim a squatted site.\nTrademark owners in 2021 filed a record 5,128 cases under the Uniform Domain-Name Dispute-Resolution Policy (UDRP) with World Intellectual Property Organization (WIPO)\u2019s Arbitration and Mediation Center, eclipsing the 2020 level by 22%. The surge pushed WIPO cybersquatting cases to almost 56,000 and the total number of domain names covered past the 100,000 mark. As a matter of comparison, in 2006, there were 1823 complaints filed with WIPO, which was a 25% increase over the 2005 rate.The accelerating growth in cybersquatting cases filed with the WIPO Center has been largely attributed by the WIPO Center to trademark owners reinforcing their online presence to offer authentic content and trusted sales outlets, with a greater number of people spending more time online, especially during the COVID-19 pandemic. Representing 70% of WIPO's Generic top-level domain (gTLD) cases, .com demonstrated its continuing primacy.\nWIPO UDRP cases in 2021 involved parties from 132 countries. The top three business areas were Banking and Finance (13%), Internet and IT (13%), and Biotechnology and Pharmaceuticals (11%). The U.S., with 1,760 cases filed, France (938), the U.K. (450), Switzerland (326), and Germany (251) were the top five filing countries.In 2007 it was stated that 84% of the claims made since 1999 were decided in the complaining party's favor.\n\n\n*** In the United States of America ***\nSome countries have specific laws against cybersquatting beyond the normal rules of trademark law. For example, according to the United States federal law known as the Anticybersquatting Consumer Protection Act (ACPA), cybersquatting is registering, trafficking in, or using an Internet domain name with bad faith intent to profit from the goodwill of a trademark belonging to someone else. The United States adopted the U.S. Anticybersquatting Consumer Protection Act in 1999. This expansion of the Lanham (Trademark) Act (15 U.S.C.) is intended to provide protection against cybersquatting for individuals as well as owners of distinctive trademarked names. However, some notable personalities, including actor Kevin Spacey, failed to obtain control of their names on the internet because the US ACPA considers ownership of a website name \"fair use\" for which no permission is needed, unless there is an attempt to profit from the domain name by putting it up for sale.Jurisdiction is an issue, as shown in the case involving Kevin Spacey, in which Judge Gary A. Feess, of the United States District Court of the Central District of California, ruled that the actor would have to file a complaint in a Canadian court, where the current owner of kevinspacey.com resided. Spacey later won the domain through the Forum (alternative dispute resolution), formerly known as the National Arbitration Forum.\n\n\n*** In Spain ***\nIn relation to cybersquatting, the Spanish Supreme Court issued the first sentence on this practice, relating it to the crime of misappropriation (STS 358/2022, of April 7). An unprecedented fact that established the legal fit of this computer crime in Spanish jurisprudence.\nThe case revolves around four members of the religious association Alpha Education for Comprehensive Health. They created a web page (the Internet domain of which was www.alfatelevision.org) and opened a bank and PayPal account for donations made to the association.\nSome time later, there were some disagreements between the members of the association and the four defendants who opened a new website, changed the internet domain and changed the password of the accounts, which redirected all the donations from the followers. Later, the association dismissed the four members.\nThe general secretary of the association denounced the four members for a crime of misappropriation and they were sentenced by the Provincial Court of Guadalajara, understanding that the internet domain was an asset of the association.\nThis resolution was appealed to the Supreme Court through an appeal, which was upheld by the court. Finally, the Supreme Court acquitted the four accused, understanding that the proven facts do not fit the crime of misappropriation. In this sense, it highlights that there are elements that did not concur in this case and that the actions carried out by these individuals (creation of another domain, change of passwords...) occurred prior to their termination and that, therefore, they were in willingness to do it.\nIn addition, the sentence reflects cases in which cybersquatting could have criminal relevance. In the first place, if the conduct sought to harm the rights of a brand, it could constitute a crime against industrial or intellectual property. Secondly, if the intention was to use the domain name in a deceitful way to cause an error in the transfer of assets, the accused could face a crime of fraud. Finally, if cybersquatting were used to attack a domain name, the accused would be facing a crime of computer sabotage.\n\n== Notable cases ==\n\n\n*** With litigation ***\nJethro Tull vs. Denny Hammerton, 2000 (WIPO Case)\nMadonna vs. Parisi, 2000 (WIPO Case)\n Primedia Magazine Finance Inc. (Tiger Beat) vs Next Level Productions (Benny Doro).\n People for the Ethical Treatment of Animals v. Doughney, 2001\nLamparello v. Falwell, 2005\nLufthansa v. Future Media Architects, 2008\nMicrosoft vs. MikeRoweSoft\nDennis Toeppen v. Panavision\nNissan Motors vs. Nissan Computer\nVan Cleef & Arpels, S.A. v. Nexperian Holding Limited\nAviva Brands Limited v. Nexperian Holding Limited\nSwiss Arabian Perfumes Ind. Ltd. v. Nexperian Holding Limited\nMou Limited v. Nexperian Holding Limited\nPlanned Parenthood Federation of America, Inc. v. Bucci\u2019'\nSatyam Infoway Ltd. v. Sifynet Solutions Pvt. Ltd.\n\n\n*** Without litigation ***\nThe White House against Whitehouse.com and Whitehouse.org\n\n\n*** Accused of cybersquatting ***\nThe personal website of a NASA engineer, gail.com, could be accused of cybersquatting on a typo for Gmail. However, gail.com claims that the site was created after Gail's husband bought her the URL in 1996, eight years before Gmail was introduced, and Gail does not appear to profit from the site.\n\n== Social media ==\nWith the rise of social media websites such as Facebook and Twitter, a new form of cybersquatting involves registering trademark-protected brands or names of public figures on popular social media websites. Such cases are also being referred to as 'Username Squatting'\nOn June 5, 2009, Tony La Russa, the manager of the St. Louis Cardinals, filed a complaint against Twitter, accusing Twitter of cybersquatting. The dispute centered on a Twitter profile that used La Russa's name, had a picture of La Russa, and had a headline that said \"Hey there! Tony La Russa is now using Twitter.\" The profile encouraged users to \"join today to start receiving Tony La Russa's updates.\" According to La Russa, the status updates were vulgar and derogatory. La Russa argued that the author of the profile intended, in bad faith, to divert Internet traffic away from La Russa's website and make a profit from the injury to La Russa's mark. On June 26, 2009, La Russa filed a notice of voluntary dismissal after the parties settled the case.\n\n\n*** Efforts to curtail cybersquatting in social media ***\nSocial networking websites have attempted to curb cybersquatting, making cybersquatting a violation of their terms of service.\n\n\n**** Twitter ****\nTwitter's name squatting policy forbids the cybersquatting as seen in many domain name disputes, like \"username for sale\" accounts: \"Attempts to sell or extort other forms of payment in exchange for usernames will result in account suspension.\" Additionally, Twitter has an \"Impersonation Policy\" that forbids non-parody impersonation. An account may be guilty of impersonation if it confuses or misleads others; \"accounts with the clear intent to confuse or mislead may be permanently suspended.\" Twitter's standard for defining parody is whether a reasonable person would be aware that the fake profile is a joke.Soon after the La Russa suit was filed, Twitter took another step to prevent \"identity confusion\" caused by squatting by unveiling Twitter verification. Usernames stamped with the \"verified account\" insignia is intended to indicate that the accounts are real and authentic. \nHowever, after the acquisition of Twitter by Elon Musk the verification system was changed to make it easier for individuals to get verified through the Twitter Blue program, giving accounts to have \"Profile Labels\" instead - identifying ownership information such as whether the account is an individual, business, or a government.\n\n\n**** Facebook ****\nFacebook reserves the right to reclaim usernames on the website if they infringe on a trademark. Trademark owners are responsible for reporting any trademark infringement on a username infringement form Facebook provides. Furthermore, Facebook usernames require \"mobile phone authentication\". In order to obtain a username, the individual needs to verify the account by phone.\n\nHow does Facebook deal with trademark infringement on usernames and what measures have they taken to prevent cybersquatting?",
    "context": "",
    "output": "Facebook reserves the right to reclaim usernames on the website if they infringe on a trademark and provides a username infringement form for trademark owners to report any infringement. Furthermore, Facebook usernames require mobile phone authentication and Facebook has measures in place to prevent cybersquatting.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does Facebook deal with trademark infringement on usernames and what measures have they taken to prevent cybersquatting?",
      "answer": "Facebook reserves the right to reclaim usernames on the website if they infringe on a trademark and provides a username infringement form for trademark owners to report any infringement. Furthermore, Facebook usernames require mobile phone authentication and Facebook has measures in place to prevent cybersquatting.",
      "context": "Cybersquatting\n\n==Introduction==\nCybersquatting (also known as domain squatting) is the practice of registering, trafficking in, or using an Internet domain name, with a bad faith intent to profit from the goodwill of a trademark belonging to someone else.\nThe term is derived from \"squatting\", which is the act of occupying an abandoned or unoccupied space or building that the squatter does not own, rent, or otherwise have permission to use.\n\n== Terminology ==\nIn popular terms, \u201ccybersquatting\u201d is the term most frequently used to describe the deliberate, bad faith abusive registration of a domain name in violation of trademark rights. However, precisely because of its popular currency, the term has different meanings to different people. Some people, for example, include \u201cwarehousing,\u201d or the practice of registering a collection of domain names corresponding to trademarks with the intention of selling the registrations to the owners of the trademarks, within the notion of cybersquatting, while others distinguish between the two terms. In the former definition, the cybersquatter may offer to sell the domain to the person or company who owns a trademark contained within the name at an inflated price.\nSimilarly, some consider \u201ccyberpiracy\u201d to be interchangeable with \u201ccybersquatting,\u201d whereas others consider that the former term relates to violation of copyright in the content of websites, rather than to abusive domain name registrations.Because of the various interpretations of the term, World Intellectual Property Organization (WIPO), in a 1999 report, approved by its member states, considered it as the abusive registration of a domain name.\n\n== Legal resolution ==\n\n\n*** International ***\n\nSince 1999, the World Intellectual Property Organization (WIPO) has provided an administrative process wherein a trademark holder can attempt to claim a squatted site.\nTrademark owners in 2021 filed a record 5,128 cases under the Uniform Domain-Name Dispute-Resolution Policy (UDRP) with World Intellectual Property Organization (WIPO)\u2019s Arbitration and Mediation Center, eclipsing the 2020 level by 22%. The surge pushed WIPO cybersquatting cases to almost 56,000 and the total number of domain names covered past the 100,000 mark. As a matter of comparison, in 2006, there were 1823 complaints filed with WIPO, which was a 25% increase over the 2005 rate.The accelerating growth in cybersquatting cases filed with the WIPO Center has been largely attributed by the WIPO Center to trademark owners reinforcing their online presence to offer authentic content and trusted sales outlets, with a greater number of people spending more time online, especially during the COVID-19 pandemic. Representing 70% of WIPO's Generic top-level domain (gTLD) cases, .com demonstrated its continuing primacy.\nWIPO UDRP cases in 2021 involved parties from 132 countries. The top three business areas were Banking and Finance (13%), Internet and IT (13%), and Biotechnology and Pharmaceuticals (11%). The U.S., with 1,760 cases filed, France (938), the U.K. (450), Switzerland (326), and Germany (251) were the top five filing countries.In 2007 it was stated that 84% of the claims made since 1999 were decided in the complaining party's favor.\n\n\n*** In the United States of America ***\nSome countries have specific laws against cybersquatting beyond the normal rules of trademark law. For example, according to the United States federal law known as the Anticybersquatting Consumer Protection Act (ACPA), cybersquatting is registering, trafficking in, or using an Internet domain name with bad faith intent to profit from the goodwill of a trademark belonging to someone else. The United States adopted the U.S. Anticybersquatting Consumer Protection Act in 1999. This expansion of the Lanham (Trademark) Act (15 U.S.C.) is intended to provide protection against cybersquatting for individuals as well as owners of distinctive trademarked names. However, some notable personalities, including actor Kevin Spacey, failed to obtain control of their names on the internet because the US ACPA considers ownership of a website name \"fair use\" for which no permission is needed, unless there is an attempt to profit from the domain name by putting it up for sale.Jurisdiction is an issue, as shown in the case involving Kevin Spacey, in which Judge Gary A. Feess, of the United States District Court of the Central District of California, ruled that the actor would have to file a complaint in a Canadian court, where the current owner of kevinspacey.com resided. Spacey later won the domain through the Forum (alternative dispute resolution), formerly known as the National Arbitration Forum.\n\n\n*** In Spain ***\nIn relation to cybersquatting, the Spanish Supreme Court issued the first sentence on this practice, relating it to the crime of misappropriation (STS 358/2022, of April 7). An unprecedented fact that established the legal fit of this computer crime in Spanish jurisprudence.\nThe case revolves around four members of the religious association Alpha Education for Comprehensive Health. They created a web page (the Internet domain of which was www.alfatelevision.org) and opened a bank and PayPal account for donations made to the association.\nSome time later, there were some disagreements between the members of the association and the four defendants who opened a new website, changed the internet domain and changed the password of the accounts, which redirected all the donations from the followers. Later, the association dismissed the four members.\nThe general secretary of the association denounced the four members for a crime of misappropriation and they were sentenced by the Provincial Court of Guadalajara, understanding that the internet domain was an asset of the association.\nThis resolution was appealed to the Supreme Court through an appeal, which was upheld by the court. Finally, the Supreme Court acquitted the four accused, understanding that the proven facts do not fit the crime of misappropriation. In this sense, it highlights that there are elements that did not concur in this case and that the actions carried out by these individuals (creation of another domain, change of passwords...) occurred prior to their termination and that, therefore, they were in willingness to do it.\nIn addition, the sentence reflects cases in which cybersquatting could have criminal relevance. In the first place, if the conduct sought to harm the rights of a brand, it could constitute a crime against industrial or intellectual property. Secondly, if the intention was to use the domain name in a deceitful way to cause an error in the transfer of assets, the accused could face a crime of fraud. Finally, if cybersquatting were used to attack a domain name, the accused would be facing a crime of computer sabotage.\n\n== Notable cases ==\n\n\n*** With litigation ***\nJethro Tull vs. Denny Hammerton, 2000 (WIPO Case)\nMadonna vs. Parisi, 2000 (WIPO Case)\n Primedia Magazine Finance Inc. (Tiger Beat) vs Next Level Productions (Benny Doro).\n People for the Ethical Treatment of Animals v. Doughney, 2001\nLamparello v. Falwell, 2005\nLufthansa v. Future Media Architects, 2008\nMicrosoft vs. MikeRoweSoft\nDennis Toeppen v. Panavision\nNissan Motors vs. Nissan Computer\nVan Cleef & Arpels, S.A. v. Nexperian Holding Limited\nAviva Brands Limited v. Nexperian Holding Limited\nSwiss Arabian Perfumes Ind. Ltd. v. Nexperian Holding Limited\nMou Limited v. Nexperian Holding Limited\nPlanned Parenthood Federation of America, Inc. v. Bucci\u2019'\nSatyam Infoway Ltd. v. Sifynet Solutions Pvt. Ltd.\n\n\n*** Without litigation ***\nThe White House against Whitehouse.com and Whitehouse.org\n\n\n*** Accused of cybersquatting ***\nThe personal website of a NASA engineer, gail.com, could be accused of cybersquatting on a typo for Gmail. However, gail.com claims that the site was created after Gail's husband bought her the URL in 1996, eight years before Gmail was introduced, and Gail does not appear to profit from the site.\n\n== Social media ==\nWith the rise of social media websites such as Facebook and Twitter, a new form of cybersquatting involves registering trademark-protected brands or names of public figures on popular social media websites. Such cases are also being referred to as 'Username Squatting'\nOn June 5, 2009, Tony La Russa, the manager of the St. Louis Cardinals, filed a complaint against Twitter, accusing Twitter of cybersquatting. The dispute centered on a Twitter profile that used La Russa's name, had a picture of La Russa, and had a headline that said \"Hey there! Tony La Russa is now using Twitter.\" The profile encouraged users to \"join today to start receiving Tony La Russa's updates.\" According to La Russa, the status updates were vulgar and derogatory. La Russa argued that the author of the profile intended, in bad faith, to divert Internet traffic away from La Russa's website and make a profit from the injury to La Russa's mark. On June 26, 2009, La Russa filed a notice of voluntary dismissal after the parties settled the case.\n\n\n*** Efforts to curtail cybersquatting in social media ***\nSocial networking websites have attempted to curb cybersquatting, making cybersquatting a violation of their terms of service.\n\n\n**** Twitter ****\nTwitter's name squatting policy forbids the cybersquatting as seen in many domain name disputes, like \"username for sale\" accounts: \"Attempts to sell or extort other forms of payment in exchange for usernames will result in account suspension.\" Additionally, Twitter has an \"Impersonation Policy\" that forbids non-parody impersonation. An account may be guilty of impersonation if it confuses or misleads others; \"accounts with the clear intent to confuse or mislead may be permanently suspended.\" Twitter's standard for defining parody is whether a reasonable person would be aware that the fake profile is a joke.Soon after the La Russa suit was filed, Twitter took another step to prevent \"identity confusion\" caused by squatting by unveiling Twitter verification. Usernames stamped with the \"verified account\" insignia is intended to indicate that the accounts are real and authentic. \nHowever, after the acquisition of Twitter by Elon Musk the verification system was changed to make it easier for individuals to get verified through the Twitter Blue program, giving accounts to have \"Profile Labels\" instead - identifying ownership information such as whether the account is an individual, business, or a government.\n\n\n**** Facebook ****\nFacebook reserves the right to reclaim usernames on the website if they infringe on a trademark. Trademark owners are responsible for reporting any trademark infringement on a username infringement form Facebook provides. Furthermore, Facebook usernames require \"mobile phone authentication\". In order to obtain a username, the individual needs to verify the account by phone."
    }
  },
  {
    "instruction": "Context: Tails (operating system)\n\n==Introduction==\nTails, or \"The Amnesic Incognito Live System,\" is a security-focused Debian-based Linux distribution aimed at preserving privacy and anonymity. It connects to the Internet exclusively through the anonymity network Tor. The system is designed to be booted as a live DVD or live USB and leaves no digital footprint on the machine unless explicitly told to do so. It can also be run as a virtual machine, with some additional security risks. The Tor Project provided financial support for its development in the beginnings of the project, and continues to do so alongside numerous corporate and anonymous sponsors.\n\n== Features ==\nTails's pre-installed desktop environment is GNOME 3. The system includes essential software for functions such as reading and editing documents, image editing, video watching and printing. Other software from Debian can be installed at the user's behest.Tails includes a unique variety of software that handles the encryption of files and internet transmissions, cryptographic signing and hashing, and other functions important to security. It is pre-configured to use Tor with multiple connection options. It tries to force all connections to use Tor and blocks connection attempts outside Tor. For networking, it features a modified version of Tor Browser with the inclusion of uBlock Origin, instant messaging, email, file transmission and monitoring local network connections for security.By design, Tails is \"amnesic\". It runs in the computer's Random Access Memory (RAM) and does not write to a hard drive or other storage medium. The user may choose to keep files, applications or some settings on their Tails drive in \"Persistent Storage\". Though the Persistent Storage is encrypted by default, it is not hidden and detectable by forensic analysis. While shutting down, Tails overwrites most of the used RAM to avoid a cold boot attack.\n\n== Security incidents ==\nIn 2014 Das Erste reported that the NSA's XKeyscore surveillance system sets threat definitions for people who search for Tails using a search engine or visit the Tails website. A comment in XKeyscore's source code calls Tails \"a comsec [communications security] mechanism advocated by extremists on extremist forums\".In the same year, Der Spiegel published slides from an internal National Security Agency presentation dating to June 2012, in which the NSA deemed Tails on its own as a \"major threat\" to its mission and in conjunction with other privacy tools as \"catastrophic\".In 2017, the FBI used malicious code developed by Facebook, identifying sexual extortionist and Tails user Buster Hernandez through a zero-day vulnerability in the default video player. The exploit was never explained to or discovered by the Tails developers, but it is believed that the vulnerability was patched in a later release of Tails. Hernandez had eluded authorities for a long time; the FBI and Facebook had searched for him with no success, and resorted to developing the custom hacking tool.\n\nQuestion: What are the software options available in Tails for networking?\n\nAnswer:",
    "context": "",
    "output": "Tails includes a modified version of Tor Browser, uBlock Origin, instant messaging, email, file transmission, and local network monitoring for security.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are the software options available in Tails for networking?",
      "answer": "Tails includes a modified version of Tor Browser, uBlock Origin, instant messaging, email, file transmission, and local network monitoring for security.",
      "context": "Tails (operating system)\n\n==Introduction==\nTails, or \"The Amnesic Incognito Live System,\" is a security-focused Debian-based Linux distribution aimed at preserving privacy and anonymity. It connects to the Internet exclusively through the anonymity network Tor. The system is designed to be booted as a live DVD or live USB and leaves no digital footprint on the machine unless explicitly told to do so. It can also be run as a virtual machine, with some additional security risks. The Tor Project provided financial support for its development in the beginnings of the project, and continues to do so alongside numerous corporate and anonymous sponsors.\n\n== Features ==\nTails's pre-installed desktop environment is GNOME 3. The system includes essential software for functions such as reading and editing documents, image editing, video watching and printing. Other software from Debian can be installed at the user's behest.Tails includes a unique variety of software that handles the encryption of files and internet transmissions, cryptographic signing and hashing, and other functions important to security. It is pre-configured to use Tor with multiple connection options. It tries to force all connections to use Tor and blocks connection attempts outside Tor. For networking, it features a modified version of Tor Browser with the inclusion of uBlock Origin, instant messaging, email, file transmission and monitoring local network connections for security.By design, Tails is \"amnesic\". It runs in the computer's Random Access Memory (RAM) and does not write to a hard drive or other storage medium. The user may choose to keep files, applications or some settings on their Tails drive in \"Persistent Storage\". Though the Persistent Storage is encrypted by default, it is not hidden and detectable by forensic analysis. While shutting down, Tails overwrites most of the used RAM to avoid a cold boot attack.\n\n== Security incidents ==\nIn 2014 Das Erste reported that the NSA's XKeyscore surveillance system sets threat definitions for people who search for Tails using a search engine or visit the Tails website. A comment in XKeyscore's source code calls Tails \"a comsec [communications security] mechanism advocated by extremists on extremist forums\".In the same year, Der Spiegel published slides from an internal National Security Agency presentation dating to June 2012, in which the NSA deemed Tails on its own as a \"major threat\" to its mission and in conjunction with other privacy tools as \"catastrophic\".In 2017, the FBI used malicious code developed by Facebook, identifying sexual extortionist and Tails user Buster Hernandez through a zero-day vulnerability in the default video player. The exploit was never explained to or discovered by the Tails developers, but it is believed that the vulnerability was patched in a later release of Tails. Hernandez had eluded authorities for a long time; the FBI and Facebook had searched for him with no success, and resorted to developing the custom hacking tool."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the computational security parameter affect the hardness of a cryptographic scheme in the context of the hardness of a PRF?",
    "context": "",
    "output": "In the context of a PRF, the computational security parameter is used to set the size of the key space such that a brute-force search requires O(2^\u03ba) computational power, making the PRF key harder to guess for an adversary.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the computational security parameter affect the hardness of a cryptographic scheme in the context of the hardness of a PRF?",
      "answer": "In the context of a PRF, the computational security parameter is used to set the size of the key space such that a brute-force search requires O(2^\u03ba) computational power, making the PRF key harder to guess for an adversary."
    }
  },
  {
    "instruction": "Write an answer to the following question: How is the China Chopper web shell used to control web servers and what programming languages were used to develop its client and receiver host file?",
    "context": "",
    "output": "The China Chopper web shell is used to remotely control web servers through a client interface and a receiver host file on the compromised web server. The client is programmed in Microsoft Visual C++ 6.0, while the receiver host file is a file on the compromised web server.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How is the China Chopper web shell used to control web servers and what programming languages were used to develop its client and receiver host file?",
      "answer": "The China Chopper web shell is used to remotely control web servers through a client interface and a receiver host file on the compromised web server. The client is programmed in Microsoft Visual C++ 6.0, while the receiver host file is a file on the compromised web server."
    }
  },
  {
    "instruction": "Mobile identity management\n\n==Introduction==\nMobile identity is a development of online authentication and digital signatures, where the SIM card of one\u2019s mobile phone works as an identity tool. Mobile identity enables legally binding authentication and transaction signing for online banking, payment confirmation, corporate services, and consuming online content. The user's certificates are maintained on the telecom operator's SIM card and in order to use them, the user has to enter a personal, secret PIN code. When using mobile identity, no separate card reader is needed, as the phone itself already performs both functions.\nIn contrast to other approaches, the mobile phone in conjunction with a mobile signature-enabled SIM card aims to offer the same security and ease of use as for example smart cards in existing digital identity management systems. Smart card-based digital identities can only be used in conjunction with a card reader and a PC.  In addition, distributing and managing the cards can be logistically difficult, exacerbated by the lack of interoperability between services relying on such a digital identity.There are a number of private company stakeholders that have an inherent interest in setting up a mobile signature service infrastructure to offer mobile identity services. These stakeholders are mobile network operators and, to a certain extent, financial institutions or service providers with an existing large customer base, that could leverage the use of mobile signatures across several applications.\n\n== By country ==\n\n\n*** Finland ***\nThe Finnish government has supervised the deployment of a common derivative of the ETSI-based mobile signature service standard, thus allowing the Finnish mobile operators to offer mobile signature services. The Finnish government certificate authority (CA) also issues the certificates that link the digital keys on the SIM card to the person\u2019s real world identity.\n\n\n*** Islamic Republic of Iran ***\nThrough national mobile register program Iranian customs administration and ministry of ict registers database from IMEI of imported legally phones and allows Iranian citizens to only access full Iranian mobile phone operators national roaming network if they have linked their national ID to both Simcards and also non contraband/smuggled IMEI number.\n\n\n*** Sweden ***\nIn the Nordic region, governments, public sector and financial institutions are increasingly offering online and mobile channels to access their services. In Sweden the WPK consortium, owned by banks and mobile operators, specifies a mobile signature service infrastructure that is used by banks to authenticate online banking users.\nTelenor Sverige has provided technology for the company's mobile signature services in Sweden since 2009. Telenor enables its customers a secure login to online services using their mobile phone for authentication and digital signing.\n\n\n*** Estonia ***\nThe Estonian government issues all citizens with a smart card and digital identity called the Estonian ID card. Additionally, Sertifitseerimiskeskus, the certificate authority of Estonia issues special SIM cards to mobile phones which act as national personal identification method. The service is called m-id.\n\n\n*** Turkey ***\nIn 2007, the mobile operator Turkcell bought a mobile signature service infrastructure Gemalto and launched Mobillmza, the world's first mobile security solution. They have partnered up with over 200 businesses, including many banks to enable them to use mobile signatures for online user authentication.Other services relying on mobile signatures in Turkey include securing the withdrawal of small loans from an ATM, and processing custom work flow processes by enabling applicants to use mobile signatures.\n\n\n*** Austria ***\nThe Austrian government allows private sector companies to propose means for storing the government-controlled digital identity.  Since 2006, the Austrian government has explicitly mentioned mobile phones as one of the likely devices to be used for storing and managing a digital identity. Eight Austrian saving banks will launch a pilot allowing online user authentication with mobile signatures.\n\n\n*** Ukraine ***\nIn Ukraine, Mobile ID project started in 2015, and later declared as one of Government of Ukraine priorities supported by EU. At the beginning of 2018 Ukrainian cell operators are evaluating proposals and testing platforms from different local and foreign developers. Platform selection will be followed up by comprehensive certification process.\nUkrainian IT and cryptography around Mobile ID topic is mostly presented by Innovation Development HUB LLC with its own Mobile ID platform. This particular solution is the sole, having already passed the certification, and most likely will be implemented in Ukraine. \nAs of September 2019, all of 'big three' cell operators in Ukraine have launched Mobile ID service. \nVodafone - commercial launch in August 2018.\nKyivstar - commercial launch in December 2018.\nLifecell - commercial launch in August 2019.\nVodafone and Lifecell operators implemented Mobile ID solution of Ukrainian origin designed by Innovation Development HUB LLC.\nQuestion: How is the m-id service used in Estonia?",
    "context": "",
    "output": "Answer: The m-id service in Estonia is used as a national personal identification method for mobile phones. It is issued by the Estonian government and is used in conjunction with special SIM cards.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How is the m-id service used in Estonia?",
      "answer": "The m-id service in Estonia is used as a national personal identification method for mobile phones. It is issued by the Estonian government and is used in conjunction with special SIM cards.",
      "context": "Mobile identity management\n\n==Introduction==\nMobile identity is a development of online authentication and digital signatures, where the SIM card of one\u2019s mobile phone works as an identity tool. Mobile identity enables legally binding authentication and transaction signing for online banking, payment confirmation, corporate services, and consuming online content. The user's certificates are maintained on the telecom operator's SIM card and in order to use them, the user has to enter a personal, secret PIN code. When using mobile identity, no separate card reader is needed, as the phone itself already performs both functions.\nIn contrast to other approaches, the mobile phone in conjunction with a mobile signature-enabled SIM card aims to offer the same security and ease of use as for example smart cards in existing digital identity management systems. Smart card-based digital identities can only be used in conjunction with a card reader and a PC.  In addition, distributing and managing the cards can be logistically difficult, exacerbated by the lack of interoperability between services relying on such a digital identity.There are a number of private company stakeholders that have an inherent interest in setting up a mobile signature service infrastructure to offer mobile identity services. These stakeholders are mobile network operators and, to a certain extent, financial institutions or service providers with an existing large customer base, that could leverage the use of mobile signatures across several applications.\n\n== By country ==\n\n\n*** Finland ***\nThe Finnish government has supervised the deployment of a common derivative of the ETSI-based mobile signature service standard, thus allowing the Finnish mobile operators to offer mobile signature services. The Finnish government certificate authority (CA) also issues the certificates that link the digital keys on the SIM card to the person\u2019s real world identity.\n\n\n*** Islamic Republic of Iran ***\nThrough national mobile register program Iranian customs administration and ministry of ict registers database from IMEI of imported legally phones and allows Iranian citizens to only access full Iranian mobile phone operators national roaming network if they have linked their national ID to both Simcards and also non contraband/smuggled IMEI number.\n\n\n*** Sweden ***\nIn the Nordic region, governments, public sector and financial institutions are increasingly offering online and mobile channels to access their services. In Sweden the WPK consortium, owned by banks and mobile operators, specifies a mobile signature service infrastructure that is used by banks to authenticate online banking users.\nTelenor Sverige has provided technology for the company's mobile signature services in Sweden since 2009. Telenor enables its customers a secure login to online services using their mobile phone for authentication and digital signing.\n\n\n*** Estonia ***\nThe Estonian government issues all citizens with a smart card and digital identity called the Estonian ID card. Additionally, Sertifitseerimiskeskus, the certificate authority of Estonia issues special SIM cards to mobile phones which act as national personal identification method. The service is called m-id.\n\n\n*** Turkey ***\nIn 2007, the mobile operator Turkcell bought a mobile signature service infrastructure Gemalto and launched Mobillmza, the world's first mobile security solution. They have partnered up with over 200 businesses, including many banks to enable them to use mobile signatures for online user authentication.Other services relying on mobile signatures in Turkey include securing the withdrawal of small loans from an ATM, and processing custom work flow processes by enabling applicants to use mobile signatures.\n\n\n*** Austria ***\nThe Austrian government allows private sector companies to propose means for storing the government-controlled digital identity.  Since 2006, the Austrian government has explicitly mentioned mobile phones as one of the likely devices to be used for storing and managing a digital identity. Eight Austrian saving banks will launch a pilot allowing online user authentication with mobile signatures.\n\n\n*** Ukraine ***\nIn Ukraine, Mobile ID project started in 2015, and later declared as one of Government of Ukraine priorities supported by EU. At the beginning of 2018 Ukrainian cell operators are evaluating proposals and testing platforms from different local and foreign developers. Platform selection will be followed up by comprehensive certification process.\nUkrainian IT and cryptography around Mobile ID topic is mostly presented by Innovation Development HUB LLC with its own Mobile ID platform. This particular solution is the sole, having already passed the certification, and most likely will be implemented in Ukraine. \nAs of September 2019, all of 'big three' cell operators in Ukraine have launched Mobile ID service. \nVodafone - commercial launch in August 2018.\nKyivstar - commercial launch in December 2018.\nLifecell - commercial launch in August 2019.\nVodafone and Lifecell operators implemented Mobile ID solution of Ukrainian origin designed by Innovation Development HUB LLC."
    }
  },
  {
    "instruction": "Answer based on context:\n\nHardware security module\n\n==Introduction==\nA hardware security module (HSM) is a physical computing device that safeguards and manages secrets (most importantly digital keys), performs encryption and decryption functions for digital signatures, strong authentication and other cryptographic functions. These modules traditionally come in the form of a plug-in card or an external device that attaches directly to a computer or network server. A hardware security module contains one or more secure cryptoprocessor chips.\n\n== Design ==\nHSMs may have features that provide tamper evidence such as visible signs of tampering or logging and alerting, or tamper resistance which makes tampering difficult without making the HSM inoperable, or tamper responsiveness such as deleting keys upon tamper detection. Each module contains one or more secure cryptoprocessor chips to prevent tampering and bus probing, or a combination of chips in a module that is protected by the tamper evident, tamper resistant, or tamper responsive packaging.\nA vast majority of existing HSMs are designed mainly to manage secret keys. Many HSM systems have means to securely back up the keys they handle outside of the HSM. Keys may be backed up in wrapped form and stored on a computer disk or other media, or externally using a secure portable device like a smartcard or some other security token.HSMs are used for real time authorization and authentication in critical infrastructure thus are typically engineered to support standard high availability models including clustering, automated failover, and redundant field-replaceable components.\nA few of the HSMs available in the market have the capability to execute specially developed modules within the HSM's secure enclosure. Such an ability is useful, for example, in cases where special algorithms or business logic has to be executed in a secured and controlled environment. The modules can be developed in native C language, .NET, Java, or other programming languages. Further, upcoming next-generation HSMs can handle more complex tasks such as loading and running full operating systems and COTS software without requiring customization and reprogramming. Such unconventional designs overcome existing design and performance limitations of traditional HSMs while providing the benefit of securing application-specific code. These execution engines protect the status of an HSM's FIPS or Common Criteria validation.\n\n== Security ==\nDue to the critical role they play in securing applications and infrastructure, general purpose HSMs and/or the cryptographic modules are typically certified according to internationally recognized standards such as Common Criteria (e.g. using Protection Profile EN 419 221-5, \"Cryptographic Module for Trust Services\") or FIPS 140 (currently the 3rd version, often referred to as FIPS 140-3). Although the highest level of FIPS 140 security certification attainable is Security Level 4, most of the HSMs have Level 3 certification. In the Common Criteria system the highest EAL (Evaluation Assurance Level) is EAL7, most of the HSMs have EAL4+ certification. When used in financial payments applications, the security of an HSM is often validated against the HSM requirements defined by the Payment Card Industry Security Standards Council.\n\n== Uses ==\nA hardware security module can be employed in any application that uses digital keys. Typically, the keys would be of high value - meaning there would be a significant, negative impact to the owner of the key if it were compromised.\nThe functions of an HSM are:\n\nonboard secure cryptographic key generation\nonboard secure cryptographic key storage, at least for the top level and most sensitive keys, which are often called master keys\nkey management\nuse of cryptographic and sensitive data material, for example, performing decryption or digital signature functions\noffloading application servers for complete asymmetric and symmetric cryptography.HSMs are also deployed to manage transparent data encryption keys for databases and keys for storage devices such as disk or tape.\nHSMs provide both logical and physical protection of these materials, including cryptographic keys, from disclosure, non-authorized use, and potential adversaries.HSMs support both symmetric and asymmetric (public-key) cryptography. For some applications, such as certificate authorities and digital signing, the cryptographic material is asymmetric key pairs (and certificates) used in public-key cryptography. With other applications, such as data encryption or financial payment systems, the cryptographic material consists mainly of symmetric keys.Some HSM systems are also hardware cryptographic accelerators. They usually cannot beat the performance of hardware-only solutions for symmetric key operations. However, with performance ranges from 1 to 10,000 1024-bit RSA signs per second, HSMs can provide significant CPU offload for asymmetric key operations. Since the National Institute of Standards and Technology (NIST) is recommending the use of 2,048 bit RSA keys from year 2010, performance at longer key sizes has become more important. To address this issue, most HSMs now support elliptic curve cryptography (ECC), which delivers stronger encryption with shorter key lengths.\n\n\n*** PKI environment (CA HSMs) ***\nIn PKI environments, the HSMs may be used by certification authorities (CAs) and registration authorities (RAs) to generate, store, and handle asymmetric key pairs. In these cases, there are some fundamental features a device must have, namely:\n\nLogical and physical high-level protection\nMulti-part user authorization schema (see secret sharing)\nFull audit and log traces\nSecure key backupOn the other hand, device performance in a PKI environment is generally less important, in both online and offline operations, as Registration Authority procedures represent the performance bottleneck of the Infrastructure.\n\n\n*** Card payment system HSMs (bank HSMs) ***\nSpecialized HSMs are used in the payment card industry. HSMs support both general-purpose functions and specialized functions required to process transactions and comply with industry standards. They normally do not feature a standard API. \nTypical applications are transaction authorization and payment card personalization, requiring functions such as:\n\nverify that a user-entered PIN matches the reference PIN known to the card issuer\nverify credit/debit card transactions by checking card security codes or by performing host processing components of an EMV based transaction in conjunction with an ATM controller or POS terminal\nsupport a crypto-API with a smart card (such as an EMV)\nre-encrypt a PIN block to send it to another authorization host\nperform secure key management\nsupport a protocol of POS ATM network management\nsupport de facto standards of host-host key | data exchange API\ngenerate and print a \"PIN mailer\"\ngenerate data for a magnetic stripe card (PVV, CVV)\ngenerate a card keyset and support the personalization process for smart cardsThe major organizations that produce and maintain standards for HSMs on the banking market are the Payment Card Industry Security Standards Council, ANS X9, and ISO.\n\n\n*** SSL connection establishment ***\nPerformance-critical applications that have to use HTTPS (SSL/TLS), can benefit from the use of an SSL Acceleration HSM by moving the RSA operations, which typically requires several large integer multiplications, from the host CPU to the HSM device. Typical HSM devices can perform about 1 to 10,000 1024-bit RSA operations/second. Some performance at longer key sizes is becoming increasingly important. To address this issue, some HSMs  now support ECC. Specialized HSM devices can reach numbers as high as 20,000 operations per second.\n\n\n*** DNSSEC ***\nAn increasing number of registries use HSMs to store the key material that is used to sign large zonefiles. OpenDNSSEC is an open-source tool that manages signing DNS zone files.\nOn January 27, 2007, ICANN and Verisign, with support from the U.S. Department of Commerce, started deploying DNSSEC for DNS root zones. Root signature details can be found on the Root DNSSEC's website.\n\n\n*** Cryptocurrency wallet ***\nCryptocurrency private keys can be stored in a cryptocurrency wallet on a HSM.\n\n== Notes and references ==\n\nWhat are some organizations that produce and maintain standards for HSMs on the banking market?",
    "context": "",
    "output": "The Payment Card Industry Security Standards Council, ANS X9, and ISO are some of the major organizations that produce and maintain standards for HSMs on the banking market.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are some organizations that produce and maintain standards for HSMs on the banking market?",
      "answer": "The Payment Card Industry Security Standards Council, ANS X9, and ISO are some of the major organizations that produce and maintain standards for HSMs on the banking market.",
      "context": "Hardware security module\n\n==Introduction==\nA hardware security module (HSM) is a physical computing device that safeguards and manages secrets (most importantly digital keys), performs encryption and decryption functions for digital signatures, strong authentication and other cryptographic functions. These modules traditionally come in the form of a plug-in card or an external device that attaches directly to a computer or network server. A hardware security module contains one or more secure cryptoprocessor chips.\n\n== Design ==\nHSMs may have features that provide tamper evidence such as visible signs of tampering or logging and alerting, or tamper resistance which makes tampering difficult without making the HSM inoperable, or tamper responsiveness such as deleting keys upon tamper detection. Each module contains one or more secure cryptoprocessor chips to prevent tampering and bus probing, or a combination of chips in a module that is protected by the tamper evident, tamper resistant, or tamper responsive packaging.\nA vast majority of existing HSMs are designed mainly to manage secret keys. Many HSM systems have means to securely back up the keys they handle outside of the HSM. Keys may be backed up in wrapped form and stored on a computer disk or other media, or externally using a secure portable device like a smartcard or some other security token.HSMs are used for real time authorization and authentication in critical infrastructure thus are typically engineered to support standard high availability models including clustering, automated failover, and redundant field-replaceable components.\nA few of the HSMs available in the market have the capability to execute specially developed modules within the HSM's secure enclosure. Such an ability is useful, for example, in cases where special algorithms or business logic has to be executed in a secured and controlled environment. The modules can be developed in native C language, .NET, Java, or other programming languages. Further, upcoming next-generation HSMs can handle more complex tasks such as loading and running full operating systems and COTS software without requiring customization and reprogramming. Such unconventional designs overcome existing design and performance limitations of traditional HSMs while providing the benefit of securing application-specific code. These execution engines protect the status of an HSM's FIPS or Common Criteria validation.\n\n== Security ==\nDue to the critical role they play in securing applications and infrastructure, general purpose HSMs and/or the cryptographic modules are typically certified according to internationally recognized standards such as Common Criteria (e.g. using Protection Profile EN 419 221-5, \"Cryptographic Module for Trust Services\") or FIPS 140 (currently the 3rd version, often referred to as FIPS 140-3). Although the highest level of FIPS 140 security certification attainable is Security Level 4, most of the HSMs have Level 3 certification. In the Common Criteria system the highest EAL (Evaluation Assurance Level) is EAL7, most of the HSMs have EAL4+ certification. When used in financial payments applications, the security of an HSM is often validated against the HSM requirements defined by the Payment Card Industry Security Standards Council.\n\n== Uses ==\nA hardware security module can be employed in any application that uses digital keys. Typically, the keys would be of high value - meaning there would be a significant, negative impact to the owner of the key if it were compromised.\nThe functions of an HSM are:\n\nonboard secure cryptographic key generation\nonboard secure cryptographic key storage, at least for the top level and most sensitive keys, which are often called master keys\nkey management\nuse of cryptographic and sensitive data material, for example, performing decryption or digital signature functions\noffloading application servers for complete asymmetric and symmetric cryptography.HSMs are also deployed to manage transparent data encryption keys for databases and keys for storage devices such as disk or tape.\nHSMs provide both logical and physical protection of these materials, including cryptographic keys, from disclosure, non-authorized use, and potential adversaries.HSMs support both symmetric and asymmetric (public-key) cryptography. For some applications, such as certificate authorities and digital signing, the cryptographic material is asymmetric key pairs (and certificates) used in public-key cryptography. With other applications, such as data encryption or financial payment systems, the cryptographic material consists mainly of symmetric keys.Some HSM systems are also hardware cryptographic accelerators. They usually cannot beat the performance of hardware-only solutions for symmetric key operations. However, with performance ranges from 1 to 10,000 1024-bit RSA signs per second, HSMs can provide significant CPU offload for asymmetric key operations. Since the National Institute of Standards and Technology (NIST) is recommending the use of 2,048 bit RSA keys from year 2010, performance at longer key sizes has become more important. To address this issue, most HSMs now support elliptic curve cryptography (ECC), which delivers stronger encryption with shorter key lengths.\n\n\n*** PKI environment (CA HSMs) ***\nIn PKI environments, the HSMs may be used by certification authorities (CAs) and registration authorities (RAs) to generate, store, and handle asymmetric key pairs. In these cases, there are some fundamental features a device must have, namely:\n\nLogical and physical high-level protection\nMulti-part user authorization schema (see secret sharing)\nFull audit and log traces\nSecure key backupOn the other hand, device performance in a PKI environment is generally less important, in both online and offline operations, as Registration Authority procedures represent the performance bottleneck of the Infrastructure.\n\n\n*** Card payment system HSMs (bank HSMs) ***\nSpecialized HSMs are used in the payment card industry. HSMs support both general-purpose functions and specialized functions required to process transactions and comply with industry standards. They normally do not feature a standard API. \nTypical applications are transaction authorization and payment card personalization, requiring functions such as:\n\nverify that a user-entered PIN matches the reference PIN known to the card issuer\nverify credit/debit card transactions by checking card security codes or by performing host processing components of an EMV based transaction in conjunction with an ATM controller or POS terminal\nsupport a crypto-API with a smart card (such as an EMV)\nre-encrypt a PIN block to send it to another authorization host\nperform secure key management\nsupport a protocol of POS ATM network management\nsupport de facto standards of host-host key | data exchange API\ngenerate and print a \"PIN mailer\"\ngenerate data for a magnetic stripe card (PVV, CVV)\ngenerate a card keyset and support the personalization process for smart cardsThe major organizations that produce and maintain standards for HSMs on the banking market are the Payment Card Industry Security Standards Council, ANS X9, and ISO.\n\n\n*** SSL connection establishment ***\nPerformance-critical applications that have to use HTTPS (SSL/TLS), can benefit from the use of an SSL Acceleration HSM by moving the RSA operations, which typically requires several large integer multiplications, from the host CPU to the HSM device. Typical HSM devices can perform about 1 to 10,000 1024-bit RSA operations/second. Some performance at longer key sizes is becoming increasingly important. To address this issue, some HSMs  now support ECC. Specialized HSM devices can reach numbers as high as 20,000 operations per second.\n\n\n*** DNSSEC ***\nAn increasing number of registries use HSMs to store the key material that is used to sign large zonefiles. OpenDNSSEC is an open-source tool that manages signing DNS zone files.\nOn January 27, 2007, ICANN and Verisign, with support from the U.S. Department of Commerce, started deploying DNSSEC for DNS root zones. Root signature details can be found on the Root DNSSEC's website.\n\n\n*** Cryptocurrency wallet ***\nCryptocurrency private keys can be stored in a cryptocurrency wallet on a HSM.\n\n== Notes and references =="
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the Metrics Portal used for and who can benefit from it?",
    "context": "",
    "output": "The Metrics Portal provides detailed statistics about Tor, including graphs of its available bandwidth and estimated userbase. Researchers interested in detailed statistics about Tor can benefit from it.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the Metrics Portal used for and who can benefit from it?",
      "answer": "The Metrics Portal provides detailed statistics about Tor, including graphs of its available bandwidth and estimated userbase. Researchers interested in detailed statistics about Tor can benefit from it."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does Dorkbot steal user credentials?",
    "context": "",
    "output": "Dorkbot can steal user credentials through form grabbing, FTP, POP3, or by accessing cached login details in Internet Explorer and Firefox.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does Dorkbot steal user credentials?",
      "answer": "Dorkbot can steal user credentials through form grabbing, FTP, POP3, or by accessing cached login details in Internet Explorer and Firefox."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the client-to-gateway implementation of Software Defined Perimeter (SDP)?",
    "context": "",
    "output": "In the client-to-gateway implementation of Software Defined Perimeter (SDP), one or more servers are protected behind an Accepting SDP Host, which acts as a gateway between the clients and the protected servers. This implementation can be used inside an enterprise network to mitigate common lateral movement attacks, or on the Internet to isolate protected servers from unauthorized users.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the client-to-gateway implementation of Software Defined Perimeter (SDP)?",
      "answer": "In the client-to-gateway implementation of Software Defined Perimeter (SDP), one or more servers are protected behind an Accepting SDP Host, which acts as a gateway between the clients and the protected servers. This implementation can be used inside an enterprise network to mitigate common lateral movement attacks, or on the Internet to isolate protected servers from unauthorized users."
    }
  },
  {
    "instruction": "Context: Teleport (software)\n\n==Introduction==\nTeleport is an open-source tool for providing zero trust access to servers and cloud applications using SSH, Kubernetes and HTTPS. It can eliminate the need for VPNs by providing a single gateway to access computing infrastructure via SSH, Kubernetes clusters, and cloud applications via a built-in proxy.Teleport started as an open source library used by the Gravity project to enable secure software deployments into restricted and regulated environments. Teleport was open sourced as a standalone tool by Gravitational Inc. in 2016. It is currently deployed in production by Samsung, NASDAQ, IBM, Ticketmaster, Epic Games and others. It has been publicly audited by technology security companies like Cure 53 and Doyensec.Alternatives to Teleport include a bastion host and strongDM.\n\n\n\n== Features ==\nTeleport provides the following features, as detailed on GitHub:\n\n\n*** Access Proxy ***\nTeleport proxy provides SSH and HTTPs access to servers, applications, and Kubernetes clusters across multiple data centers, cloud providers, and edge devices. Teleport proxy is identity-aware, i.e. it only allows certificate-based authentication by integrating with an identity manager such as GitHub, Google Apps, Okta or Active Directory, and others.\n\n\n*** Audit Log ***\nTeleport collects system events across all servers it is installed on and stores them in an audit log for compliance purposes. Auditable events include authentication attempts, file transfers, network connections, and file system changes made during an SSH session. The audit log can be stored on an encrypted file system, in Amazon DynamoDB and other cloud data stores.\n\n\n*** Session Recording ***\nTeleport records interactive user sessions for SSH and Kubernetes protocols and stores them in the audit log. Stored sessions can be replayed via a built-in session player.\n\n\n*** IoT Access ***\nServers running Teleport can be accessed by clients regardless of their physical location, even when they are using a cellular connection.\n\n\n*** Dynamic Authorization ***\nTeleport users can request a one-time elevation of permissions to complete a privileged task. Such requests can be approved or denied via chat ops tools such as Slack, Mattermost, or a custom workflow, implemented via Teleport API.\n\n\n*** Web UI ***\nTeleport Proxy offers a web-based client for configuration, accessing servers via SSH and Kubernetes and for accessing the audit log.\nTeleport requires at least 1GB of virtual memory to be built and compiled.\n\n== Architecture ==\nTeleport is written in Go programming language, and runs on UNIX-compatible operating systems, including Linux, macOS, and several BSD variants. Teleport consists of two executables: tsh (command line client) and teleport (server daemon).\nThe teleport server daemon can run in the following modes:\nNode. In this mode, the daemon is providing SSH and Kubernetes access to the server it is running on.\nProxy. In this mode, the daemon is acting as an identity-aware proxy for all protocols supported by Teleport. Currently, this includes SSH, HTTPS, and Kubernetes API.\nAuth Server. In this mode, the daemon is acting as a certificate authority that all other daemons must authenticate with. The auth server is issuing certificates for users and for servers and stores the audit log.\nAnswer this question: What is the role of the Auth Server mode in Teleport?",
    "context": "",
    "output": "In Auth Server mode, the daemon is acting as a certificate authority that all other daemons must authenticate with. The auth server is issuing certificates for users and for servers and stores the audit log.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of the Auth Server mode in Teleport?",
      "answer": "In Auth Server mode, the daemon is acting as a certificate authority that all other daemons must authenticate with. The auth server is issuing certificates for users and for servers and stores the audit log.",
      "context": "Teleport (software)\n\n==Introduction==\nTeleport is an open-source tool for providing zero trust access to servers and cloud applications using SSH, Kubernetes and HTTPS. It can eliminate the need for VPNs by providing a single gateway to access computing infrastructure via SSH, Kubernetes clusters, and cloud applications via a built-in proxy.Teleport started as an open source library used by the Gravity project to enable secure software deployments into restricted and regulated environments. Teleport was open sourced as a standalone tool by Gravitational Inc. in 2016. It is currently deployed in production by Samsung, NASDAQ, IBM, Ticketmaster, Epic Games and others. It has been publicly audited by technology security companies like Cure 53 and Doyensec.Alternatives to Teleport include a bastion host and strongDM.\n\n\n\n== Features ==\nTeleport provides the following features, as detailed on GitHub:\n\n\n*** Access Proxy ***\nTeleport proxy provides SSH and HTTPs access to servers, applications, and Kubernetes clusters across multiple data centers, cloud providers, and edge devices. Teleport proxy is identity-aware, i.e. it only allows certificate-based authentication by integrating with an identity manager such as GitHub, Google Apps, Okta or Active Directory, and others.\n\n\n*** Audit Log ***\nTeleport collects system events across all servers it is installed on and stores them in an audit log for compliance purposes. Auditable events include authentication attempts, file transfers, network connections, and file system changes made during an SSH session. The audit log can be stored on an encrypted file system, in Amazon DynamoDB and other cloud data stores.\n\n\n*** Session Recording ***\nTeleport records interactive user sessions for SSH and Kubernetes protocols and stores them in the audit log. Stored sessions can be replayed via a built-in session player.\n\n\n*** IoT Access ***\nServers running Teleport can be accessed by clients regardless of their physical location, even when they are using a cellular connection.\n\n\n*** Dynamic Authorization ***\nTeleport users can request a one-time elevation of permissions to complete a privileged task. Such requests can be approved or denied via chat ops tools such as Slack, Mattermost, or a custom workflow, implemented via Teleport API.\n\n\n*** Web UI ***\nTeleport Proxy offers a web-based client for configuration, accessing servers via SSH and Kubernetes and for accessing the audit log.\nTeleport requires at least 1GB of virtual memory to be built and compiled.\n\n== Architecture ==\nTeleport is written in Go programming language, and runs on UNIX-compatible operating systems, including Linux, macOS, and several BSD variants. Teleport consists of two executables: tsh (command line client) and teleport (server daemon).\nThe teleport server daemon can run in the following modes:\nNode. In this mode, the daemon is providing SSH and Kubernetes access to the server it is running on.\nProxy. In this mode, the daemon is acting as an identity-aware proxy for all protocols supported by Teleport. Currently, this includes SSH, HTTPS, and Kubernetes API.\nAuth Server. In this mode, the daemon is acting as a certificate authority that all other daemons must authenticate with. The auth server is issuing certificates for users and for servers and stores the audit log."
    }
  },
  {
    "instruction": "Chaos Computer Club\n\n==Introduction==\nThe Chaos Computer Club (CCC) is Europe's largest association of hackers with 7,700 registered members. Founded in 1981, the association is incorporated as an eingetragener Verein in Germany, with local chapters (called Erfa-Kreise) in various cities in Germany and the surrounding countries, particularly where there are German-speaking communities.\nSince 1985, some chapters in Switzerland have organized an independent sister association called the Chaos Computer Club Schweiz (CCC-CH) instead.\nThe CCC describes itself as \"a galactic community of life forms, independent of age, sex, race or societal orientation, which strives across borders for freedom of information\u2026\". In general, the CCC advocates more transparency in government, freedom of information, and the human right to communication. Supporting the principles of the hacker ethic, the club also fights for free universal access to computers and technological infrastructure as well as the use of open-source software. The CCC spreads an entrepreneurial vision refusing capitalist control. It has been characterised as \"\u2026one of the most influential digital organisations anywhere, the centre of German digital culture, hacker culture, hacktivism, and the intersection of any discussion of democratic and digital rights\".Members of the CCC have demonstrated and publicized a number of important information security problems.\nThe CCC frequently criticizes new legislation and products with weak information security which endanger citizen rights or the privacy of users.\nNotable members of the CCC regularly function as expert witnesses for the German constitutional court, organize lawsuits and campaigns, or otherwise influence the political process.\n\n== Activities ==\n\n\n*** Regular events ***\n\nThe CCC hosts the annual Chaos Communication Congress, Europe's biggest hacker gathering.\nWhen the event was held in the Hamburg congress center in 2013, it drew 9,000 guests.\nFor the 2016 installment, 11,000 guests were expected, with additional viewers following the event via live streaming.\nEvery four years, the Chaos Communication Camp is the outdoor alternative for hackers worldwide.\nThe CCC also held, from 2009 to 2013, a yearly conference called SIGINT in Cologne which focused on the impact of digitisation on society. The SIGINT conference was discontinued in 2014.\nThe four-day conference Gulaschprogrammiernacht in Karlsruhe is with more than 1,500 participants the second largest annual event.\nAnother yearly CCC event taking place on the Easter weekend is the Easterhegg, which is more workshop oriented than the other events.\nThe CCC often uses the c-base station located in Berlin as an event location or as function rooms.\n\n\n*** Publications and outreach ***\n\nThe CCC publishes the irregular magazine Datenschleuder (data slingshot) since 1984.\nThe Berlin chapter produces a monthly radio show called Chaosradio which picks up various technical and political topics in a two-hour talk radio show. The program is aired on a local radio station called Fritz and on the internet.\nOther programs have emerged in the context of Chaosradio, including radio programs offered by some regional Chaos Groups and the podcast spin-off CRE by Tim Pritlove.\nMany of the chapters of CCC participate in the volunteer project Chaos macht Schule which supports teaching in local schools. Its aims are to improve technology and media literacy of pupils, parents, and teachers.CCC members are present in big tech companies and in administrative instances. One of the spokespersons of the CCC, as of 1986, Andy M\u00fcller-Maguhn, was a member of the executive committee of the ICANN (Internet Corporation for Assigned Names and Numbers) between 2000 and 2002.\n\n\n*** CryptoParty ***\n\nThe CCC sensitises and introduces people to the questions of data privacy. Some of its local chapters support or organize so called CryptoParties to introduce people to the basics of practical cryptography and internet anonymity.\n\n== Fake Chaos Computer Club France ==\nThe Chaos Computer Club France (CCCF) was a fake hacker organisation created in 1989 in Lyon (France) by Jean-Bernard Condat, under the command of Jean-Luc Delacour, an agent of the Direction de la surveillance du territoire governmental agency. The primary goal of the CCCF was to watch and to gather information about the French hacker community, identifying the hackers who could harm the country. Journalist Jean Guisnel said that this organization also worked with the French National Gendarmerie.\nThe CCCF had an electronic magazine called Chaos Digest (ChaosD). Between 4 January 1993 and 5 August 1993, seventy-three issues were published (ISSN 1244-4901).\n\nWhat is the role of publications and outreach in the Chaos Computer Club's activities?",
    "context": "",
    "output": "A: Publications and outreach are crucial components of the CCC's mission. They publish the Datenschleuder magazine and produce radio shows like Chaosradio, which discuss technical and political topics. Regional chapters also contribute to the volunteer project Chaos macht Schule, fostering technology and media literacy.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of publications and outreach in the Chaos Computer Club's activities?",
      "answer": "Publications and outreach are crucial components of the CCC's mission. They publish the Datenschleuder magazine and produce radio shows like Chaosradio, which discuss technical and political topics. Regional chapters also contribute to the volunteer project Chaos macht Schule, fostering technology and media literacy.",
      "context": "Chaos Computer Club\n\n==Introduction==\nThe Chaos Computer Club (CCC) is Europe's largest association of hackers with 7,700 registered members. Founded in 1981, the association is incorporated as an eingetragener Verein in Germany, with local chapters (called Erfa-Kreise) in various cities in Germany and the surrounding countries, particularly where there are German-speaking communities.\nSince 1985, some chapters in Switzerland have organized an independent sister association called the Chaos Computer Club Schweiz (CCC-CH) instead.\nThe CCC describes itself as \"a galactic community of life forms, independent of age, sex, race or societal orientation, which strives across borders for freedom of information\u2026\". In general, the CCC advocates more transparency in government, freedom of information, and the human right to communication. Supporting the principles of the hacker ethic, the club also fights for free universal access to computers and technological infrastructure as well as the use of open-source software. The CCC spreads an entrepreneurial vision refusing capitalist control. It has been characterised as \"\u2026one of the most influential digital organisations anywhere, the centre of German digital culture, hacker culture, hacktivism, and the intersection of any discussion of democratic and digital rights\".Members of the CCC have demonstrated and publicized a number of important information security problems.\nThe CCC frequently criticizes new legislation and products with weak information security which endanger citizen rights or the privacy of users.\nNotable members of the CCC regularly function as expert witnesses for the German constitutional court, organize lawsuits and campaigns, or otherwise influence the political process.\n\n== Activities ==\n\n\n*** Regular events ***\n\nThe CCC hosts the annual Chaos Communication Congress, Europe's biggest hacker gathering.\nWhen the event was held in the Hamburg congress center in 2013, it drew 9,000 guests.\nFor the 2016 installment, 11,000 guests were expected, with additional viewers following the event via live streaming.\nEvery four years, the Chaos Communication Camp is the outdoor alternative for hackers worldwide.\nThe CCC also held, from 2009 to 2013, a yearly conference called SIGINT in Cologne which focused on the impact of digitisation on society. The SIGINT conference was discontinued in 2014.\nThe four-day conference Gulaschprogrammiernacht in Karlsruhe is with more than 1,500 participants the second largest annual event.\nAnother yearly CCC event taking place on the Easter weekend is the Easterhegg, which is more workshop oriented than the other events.\nThe CCC often uses the c-base station located in Berlin as an event location or as function rooms.\n\n\n*** Publications and outreach ***\n\nThe CCC publishes the irregular magazine Datenschleuder (data slingshot) since 1984.\nThe Berlin chapter produces a monthly radio show called Chaosradio which picks up various technical and political topics in a two-hour talk radio show. The program is aired on a local radio station called Fritz and on the internet.\nOther programs have emerged in the context of Chaosradio, including radio programs offered by some regional Chaos Groups and the podcast spin-off CRE by Tim Pritlove.\nMany of the chapters of CCC participate in the volunteer project Chaos macht Schule which supports teaching in local schools. Its aims are to improve technology and media literacy of pupils, parents, and teachers.CCC members are present in big tech companies and in administrative instances. One of the spokespersons of the CCC, as of 1986, Andy M\u00fcller-Maguhn, was a member of the executive committee of the ICANN (Internet Corporation for Assigned Names and Numbers) between 2000 and 2002.\n\n\n*** CryptoParty ***\n\nThe CCC sensitises and introduces people to the questions of data privacy. Some of its local chapters support or organize so called CryptoParties to introduce people to the basics of practical cryptography and internet anonymity.\n\n== Fake Chaos Computer Club France ==\nThe Chaos Computer Club France (CCCF) was a fake hacker organisation created in 1989 in Lyon (France) by Jean-Bernard Condat, under the command of Jean-Luc Delacour, an agent of the Direction de la surveillance du territoire governmental agency. The primary goal of the CCCF was to watch and to gather information about the French hacker community, identifying the hackers who could harm the country. Journalist Jean Guisnel said that this organization also worked with the French National Gendarmerie.\nThe CCCF had an electronic magazine called Chaos Digest (ChaosD). Between 4 January 1993 and 5 August 1993, seventy-three issues were published (ISSN 1244-4901)."
    }
  },
  {
    "instruction": "Rainbow Series\n\n==Introduction==\nThe Rainbow Series (sometimes known as the Rainbow Books) is a series of computer security standards and guidelines published by the United States government in the 1980s and 1990s. They were originally published by the U.S. Department of Defense Computer Security Center, and then by the National Computer Security Center.\n\n== Objective ==\nThese standards describe a process of evaluation for trusted systems. In some cases, U.S. government entities (as well as private firms) would require formal validation of computer technology using this process as part of their procurement criteria. Many of these standards have influenced, and have been superseded by, the Common Criteria.\nThe books have nicknames based on the color of its cover. For example, the Trusted Computer System Evaluation Criteria was referred to as \"The Orange Book.\" In the book entitled Applied Cryptography, security expert Bruce Schneier states of NCSC-TG-021 that he \"can't even begin to describe the color of [the] cover\" and that some of the books in this series have \"hideously colored covers.\" He then goes on to describe how to receive a copy of them, saying \"Don't tell them I sent you.\"\n\n== Most significant Rainbow Series books ==\nQ: How can one not associated with Bruce Schneier obtain a copy of one of the Rainbow Series books, as suggested by Schneier in his book?",
    "context": "",
    "output": "Bruce Schneier, in his book Applied Cryptography, suggested prospective readers should not mention his name when requesting a copy of the Rainbow Series books from the appropriate sources.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can one not associated with Bruce Schneier obtain a copy of one of the Rainbow Series books, as suggested by Schneier in his book?",
      "answer": "Bruce Schneier, in his book Applied Cryptography, suggested prospective readers should not mention his name when requesting a copy of the Rainbow Series books from the appropriate sources.",
      "context": "Rainbow Series\n\n==Introduction==\nThe Rainbow Series (sometimes known as the Rainbow Books) is a series of computer security standards and guidelines published by the United States government in the 1980s and 1990s. They were originally published by the U.S. Department of Defense Computer Security Center, and then by the National Computer Security Center.\n\n== Objective ==\nThese standards describe a process of evaluation for trusted systems. In some cases, U.S. government entities (as well as private firms) would require formal validation of computer technology using this process as part of their procurement criteria. Many of these standards have influenced, and have been superseded by, the Common Criteria.\nThe books have nicknames based on the color of its cover. For example, the Trusted Computer System Evaluation Criteria was referred to as \"The Orange Book.\" In the book entitled Applied Cryptography, security expert Bruce Schneier states of NCSC-TG-021 that he \"can't even begin to describe the color of [the] cover\" and that some of the books in this series have \"hideously colored covers.\" He then goes on to describe how to receive a copy of them, saying \"Don't tell them I sent you.\"\n\n== Most significant Rainbow Series books =="
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the role of face in IMT and how does it relate to interpersonal communication competence?",
    "context": "",
    "output": "In IMT, face represents the public self-image that an individual presents to others in a social interaction. The ability to maintain face is seen as a sign of interpersonal communication competence, while losing face can be a result of using stereotypes and can threaten interpersonal relationships.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of face in IMT and how does it relate to interpersonal communication competence?",
      "answer": "In IMT, face represents the public self-image that an individual presents to others in a social interaction. The ability to maintain face is seen as a sign of interpersonal communication competence, while losing face can be a result of using stereotypes and can threaten interpersonal relationships."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the meaning of the name \"Nebomi\" in South Korea?",
    "context": "",
    "output": "\"Nebomi\" means \"The (your, coming, blossom, across on the four seasons) spring\" in Korean.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the meaning of the name \"Nebomi\" in South Korea?",
      "answer": "\"Nebomi\" means \"The (your, coming, blossom, across on the four seasons) spring\" in Korean."
    }
  },
  {
    "instruction": "Write an answer to the following question: What action did LinkedIn take after discovering the additional compromised email addresses and passwords in May 2016?",
    "context": "",
    "output": "LinkedIn discovered an additional 100 million email addresses and passwords that had been compromised from the same 2012 breach. However, the text does not provide information on any specific actions LinkedIn took after this discovery.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What action did LinkedIn take after discovering the additional compromised email addresses and passwords in May 2016?",
      "answer": "LinkedIn discovered an additional 100 million email addresses and passwords that had been compromised from the same 2012 breach. However, the text does not provide information on any specific actions LinkedIn took after this discovery."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the main objective of the US Cyber Challenge's summer program?",
    "context": "",
    "output": "The main objective of the US Cyber Challenge's summer program is to provide cybersecurity training to qualified candidates, including workshops, a job fair, and a capture the flag competition.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the main objective of the US Cyber Challenge's summer program?",
      "answer": "The main objective of the US Cyber Challenge's summer program is to provide cybersecurity training to qualified candidates, including workshops, a job fair, and a capture the flag competition."
    }
  },
  {
    "instruction": "Bootloader unlocking\n\n==Introduction==\nBootloader unlocking is the process of disabling the bootloader security that makes secure boot possible. It can make advanced customizations possible, such as installing a custom firmware. On smartphones this can be a custom Android distribution or another mobile operating system. Some bootloaders are not locked at all, others can be unlocked using a standard command, others need assistance from the manufacturer. Some do not include an unlocking method and can only be unlocked through a software exploit.\nBootloader unlocking is also done for mobile forensics purposes, to extract digital evidence from mobile devices, using tools such as Cellebrite UFED.\n\n== Background ==\nUnlocking the bootloader usually voids any warranties and may make the device susceptible to data theft. On Chromebooks, enabling developer mode makes the system less secure than a standard laptop running Linux. Unlocking the bootloader may lead to data loss on Android and ChromeOS devices, as some data is impossible to back up without root permission.\nSascha Segan from PCMag considered a locked bootloader a mistake on the Qualcomm Snapdragon Insiders phone, which is targeted at advanced users.\n\n== Platforms ==\n\n\n*** Android ***\nUnlocking the bootloader is typically done during the process to obtain root access.\n\n\n**** History ****\nThe bootloaders of Nexus and Pixel devices can be unlocked by using the fastboot command fastboot oem unlock or if it doesn't recognize the command fastboot flashing unlock.When Motorola released a bootloader unlocking tool for the Droid Razr, Verizon removed the tool from their models.In 2011, Sony Ericsson released an online bootloader unlocking tool. Sony requires the IMEI number to be filled in on their website. For the Asus Transformer Prime TF201, Asus has released a special bootloader unlock tool.In 2012, Motorola released a limited tool for unlocking bootloaders. They require accepting terms and conditions and creating an account before the bootloader can be unlocked for a Moto G.HTC phones have an additional layer of lock called \"S-OFF/S-ON\".\nBootloaders can be unlocked using an exploit or using a way that the vendor supplied. The latter method usually requires wiping all data on the device. In addition, some manufacturers prohibit unlocking on carrier locked phones. Samsung's US and Canadian Snapdragon phones do not allow unlocks regardless if the phone was bought from a carrier or not.\nIn 2018, a developer from XDA Developers launched a service which allowed users to unlock the bootloader of some Nokia smartphone models. Similarly, another developer from XDA Developers launched a service to allow users to unlock the bootloaders of Samsung Galaxy S20 and Samsung Galaxy S21 Phones.Huawei announced plans to allow users to unlock the bootloader of the Mate 30 series, but later retracted that. Huawei has stopped providing bootloader unlock codes since 2018. A bootloader exploit named checkm30 has been developed for HiSilicon based Huawei phones.When the bootloader of the Samsung Galaxy Z Fold 3 was unlocked, the camera became less functional. This could be restored by re-locking the bootloader. This issue was later fixed by Samsung. For the Samsung Galaxy S22 series, unlocking the bootloader has no effect on the camera.\n\n\n*** Others ***\n\n\n**** Microsoft ****\nThe WPInternals tool is able to unlock bootloaders of all Nokia Lumia phones running Windows Phone, but not phones like the Alcatel Idol 4 or HP Elite x3. Version 1.0 was released in November 2015. In October 2018, the tool was released as open source software when the main developer Ren\u00e9 Lergner (also known as HeathCliff74) stepped down.The slab bootloader used by Windows RT could be unlocked using a vulnerability, but was silently patched by Microsoft in 2016. UEFI Secure Boot on x86 systems can generally be unlocked.\n\n\n**** Apple ****\nThe boot ROM protection on iOS devices with an A11 processor or older can be bypassed with a hardware exploit known as checkm8, which makes it possible to run other operating systems including Linux.The bootloader on M1 based Macs can be unlocked.\n\n\n**** Google ****\nThe equivalent of bootloader unlocking is called developer mode in Chromebooks. Chromebooks use custom bootloaders that can be modified or overwritten by removing a Write-protect screw.In 2013, the bootloader of the Chromecast was hacked using an exploit. In 2021, it was hacked again for newer versions.\n\n\n**** SpaceX ****\nIn August 2022, security researcher Lennert Wouters applied a voltage injection attack to bypass firmware verification of a Starlink satellite dish from SpaceX.\n\n== Relocking ==\nOn Android, it is possible to relock the bootloader.\n\n== Shutdown of online services ==\nIn 2018, Huawei stopped providing bootloader unlock codes. On 31 December 2021, LG shut down their website which provided bootloader unlock codes.\n\n== Explanatory notes ==\n\nWhy did Verizon remove the bootloader unlocking tool from Motorola's Droid Razr?",
    "context": "",
    "output": "Verizon removed the bootloader unlocking tool from Motorola's Droid Razr due to the potential security risks associated with unlocked bootloaders.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Why did Verizon remove the bootloader unlocking tool from Motorola's Droid Razr?",
      "answer": "Verizon removed the bootloader unlocking tool from Motorola's Droid Razr due to the potential security risks associated with unlocked bootloaders.",
      "context": "Bootloader unlocking\n\n==Introduction==\nBootloader unlocking is the process of disabling the bootloader security that makes secure boot possible. It can make advanced customizations possible, such as installing a custom firmware. On smartphones this can be a custom Android distribution or another mobile operating system. Some bootloaders are not locked at all, others can be unlocked using a standard command, others need assistance from the manufacturer. Some do not include an unlocking method and can only be unlocked through a software exploit.\nBootloader unlocking is also done for mobile forensics purposes, to extract digital evidence from mobile devices, using tools such as Cellebrite UFED.\n\n== Background ==\nUnlocking the bootloader usually voids any warranties and may make the device susceptible to data theft. On Chromebooks, enabling developer mode makes the system less secure than a standard laptop running Linux. Unlocking the bootloader may lead to data loss on Android and ChromeOS devices, as some data is impossible to back up without root permission.\nSascha Segan from PCMag considered a locked bootloader a mistake on the Qualcomm Snapdragon Insiders phone, which is targeted at advanced users.\n\n== Platforms ==\n\n\n*** Android ***\nUnlocking the bootloader is typically done during the process to obtain root access.\n\n\n**** History ****\nThe bootloaders of Nexus and Pixel devices can be unlocked by using the fastboot command fastboot oem unlock or if it doesn't recognize the command fastboot flashing unlock.When Motorola released a bootloader unlocking tool for the Droid Razr, Verizon removed the tool from their models.In 2011, Sony Ericsson released an online bootloader unlocking tool. Sony requires the IMEI number to be filled in on their website. For the Asus Transformer Prime TF201, Asus has released a special bootloader unlock tool.In 2012, Motorola released a limited tool for unlocking bootloaders. They require accepting terms and conditions and creating an account before the bootloader can be unlocked for a Moto G.HTC phones have an additional layer of lock called \"S-OFF/S-ON\".\nBootloaders can be unlocked using an exploit or using a way that the vendor supplied. The latter method usually requires wiping all data on the device. In addition, some manufacturers prohibit unlocking on carrier locked phones. Samsung's US and Canadian Snapdragon phones do not allow unlocks regardless if the phone was bought from a carrier or not.\nIn 2018, a developer from XDA Developers launched a service which allowed users to unlock the bootloader of some Nokia smartphone models. Similarly, another developer from XDA Developers launched a service to allow users to unlock the bootloaders of Samsung Galaxy S20 and Samsung Galaxy S21 Phones.Huawei announced plans to allow users to unlock the bootloader of the Mate 30 series, but later retracted that. Huawei has stopped providing bootloader unlock codes since 2018. A bootloader exploit named checkm30 has been developed for HiSilicon based Huawei phones.When the bootloader of the Samsung Galaxy Z Fold 3 was unlocked, the camera became less functional. This could be restored by re-locking the bootloader. This issue was later fixed by Samsung. For the Samsung Galaxy S22 series, unlocking the bootloader has no effect on the camera.\n\n\n*** Others ***\n\n\n**** Microsoft ****\nThe WPInternals tool is able to unlock bootloaders of all Nokia Lumia phones running Windows Phone, but not phones like the Alcatel Idol 4 or HP Elite x3. Version 1.0 was released in November 2015. In October 2018, the tool was released as open source software when the main developer Ren\u00e9 Lergner (also known as HeathCliff74) stepped down.The slab bootloader used by Windows RT could be unlocked using a vulnerability, but was silently patched by Microsoft in 2016. UEFI Secure Boot on x86 systems can generally be unlocked.\n\n\n**** Apple ****\nThe boot ROM protection on iOS devices with an A11 processor or older can be bypassed with a hardware exploit known as checkm8, which makes it possible to run other operating systems including Linux.The bootloader on M1 based Macs can be unlocked.\n\n\n**** Google ****\nThe equivalent of bootloader unlocking is called developer mode in Chromebooks. Chromebooks use custom bootloaders that can be modified or overwritten by removing a Write-protect screw.In 2013, the bootloader of the Chromecast was hacked using an exploit. In 2021, it was hacked again for newer versions.\n\n\n**** SpaceX ****\nIn August 2022, security researcher Lennert Wouters applied a voltage injection attack to bypass firmware verification of a Starlink satellite dish from SpaceX.\n\n== Relocking ==\nOn Android, it is possible to relock the bootloader.\n\n== Shutdown of online services ==\nIn 2018, Huawei stopped providing bootloader unlock codes. On 31 December 2021, LG shut down their website which provided bootloader unlock codes.\n\n== Explanatory notes =="
    }
  },
  {
    "instruction": "Write an answer to the following question: What was the role of John Lee (\"Corrupt\") in the Great Hacker War?",
    "context": "",
    "output": "John Lee (\"Corrupt\") was a key figure in the Great Hacker War, as he was blamed for the closure of the Fifth Amendment board and was later discovered to be listening in on a peace talk between Goggans and Abene.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was the role of John Lee (\"Corrupt\") in the Great Hacker War?",
      "answer": "John Lee (\"Corrupt\") was a key figure in the Great Hacker War, as he was blamed for the closure of the Fifth Amendment board and was later discovered to be listening in on a peace talk between Goggans and Abene."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the purpose of the Leadership section in the ISO/IEC 27003 standard?",
    "context": "",
    "output": "The Leadership section in the ISO/IEC 27003 standard provides guidance on the role of leadership in the implementation and management of an ISMS.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the purpose of the Leadership section in the ISO/IEC 27003 standard?",
      "answer": "The Leadership section in the ISO/IEC 27003 standard provides guidance on the role of leadership in the implementation and management of an ISMS."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the impact of commonly used programmers on software forensics code comparison?",
    "context": "",
    "output": "Commonly used programmers can write similar code, leading to correlation that must be differentiated from copying during software forensics analysis.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the impact of commonly used programmers on software forensics code comparison?",
      "answer": "Commonly used programmers can write similar code, leading to correlation that must be differentiated from copying during software forensics analysis."
    }
  },
  {
    "instruction": "Context: Intruder detection\n\n==Introduction==\nIn information security, intruder detection is the process of detecting intruders behind attacks as unique persons. This technique tries to identify the person behind an attack by analyzing their computational behaviour. This concept is sometimes confused with Intrusion Detection (also known as IDS) techniques which are the art of detecting intruder actions.\n\n== Theory ==\nIntruder Detection Systems try to detect who is attacking a system by analyzing his or her computational behaviour or biometric behaviour.\n\n\n*** Some of the parameters used to identify a intruder ***\nKeystroke Dynamics (aka keystroke patterns, typing pattern, typing behaviour)\nPatterns using an interactive command interpreter:\nCommands used\nCommands sequence\nAccessed directories\nCharacter deletion\n\nPatterns on the network usage:\nIP address used\nISP\nCountry\nCity\nPorts used\nTTL analysis\nOperating system used to attack\nProtocols used\nConnection times patterns\n\n\n*** Keystroke dynamics ***\nKeystroke dynamics is paramount in Intruder Detection techniques because it is the only parameter that has been classified as a real 'behavioural biometric pattern'. \nKeystroke dynamics analyze times between keystrokes issued in a computer keyboard or cellular phone keypad searching for patterns. First techniques used statistics and probability concepts like 'standard deviations' and 'Mean', later approaches use data mining, neural networks, Support Vector Machine, etc.\n\n== Translation confusion ==\nThere is a confusion with the Spanish translation of 'Intrusion detection system', also known as IDS. Some people translate it as 'Sistemas de Detecci\u00f3n de Intrusiones', but others translate it as 'Sistemas de Detecci\u00f3n de Intrusos'. Only the former is correct.\nAnswer this question: How does the analysis of IP addresses aid in intruder detection?",
    "context": "",
    "output": "The analysis of IP addresses is an essential aspect of intruder detection. By examining the IP addresses used in network traffic, systems can identify unique patterns that may indicate a specific intruder or group behind an attack. Additionally, IP addresses can provide information about the intruder's location, enabling security professionals to take appropriate action to prevent future attacks.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the analysis of IP addresses aid in intruder detection?",
      "answer": "The analysis of IP addresses is an essential aspect of intruder detection. By examining the IP addresses used in network traffic, systems can identify unique patterns that may indicate a specific intruder or group behind an attack. Additionally, IP addresses can provide information about the intruder's location, enabling security professionals to take appropriate action to prevent future attacks.",
      "context": "Intruder detection\n\n==Introduction==\nIn information security, intruder detection is the process of detecting intruders behind attacks as unique persons. This technique tries to identify the person behind an attack by analyzing their computational behaviour. This concept is sometimes confused with Intrusion Detection (also known as IDS) techniques which are the art of detecting intruder actions.\n\n== Theory ==\nIntruder Detection Systems try to detect who is attacking a system by analyzing his or her computational behaviour or biometric behaviour.\n\n\n*** Some of the parameters used to identify a intruder ***\nKeystroke Dynamics (aka keystroke patterns, typing pattern, typing behaviour)\nPatterns using an interactive command interpreter:\nCommands used\nCommands sequence\nAccessed directories\nCharacter deletion\n\nPatterns on the network usage:\nIP address used\nISP\nCountry\nCity\nPorts used\nTTL analysis\nOperating system used to attack\nProtocols used\nConnection times patterns\n\n\n*** Keystroke dynamics ***\nKeystroke dynamics is paramount in Intruder Detection techniques because it is the only parameter that has been classified as a real 'behavioural biometric pattern'. \nKeystroke dynamics analyze times between keystrokes issued in a computer keyboard or cellular phone keypad searching for patterns. First techniques used statistics and probability concepts like 'standard deviations' and 'Mean', later approaches use data mining, neural networks, Support Vector Machine, etc.\n\n== Translation confusion ==\nThere is a confusion with the Spanish translation of 'Intrusion detection system', also known as IDS. Some people translate it as 'Sistemas de Detecci\u00f3n de Intrusiones', but others translate it as 'Sistemas de Detecci\u00f3n de Intrusos'. Only the former is correct."
    }
  },
  {
    "instruction": "2017 Westminster data breach\n\n==Introduction==\nThe 2017 Westminster data breach occurred on 23 June 2017, when an unauthorised attempt was made to gain access to email accounts belonging to a number of politicians at the United Kingdom's Houses of Parliament. Whitehall officials have claimed that Iran was behind the attack. The incident was followed by an attempt to hack accounts belonging to politicians at the Scottish Parliament in August 2017.\n\n\n\n== Events ==\nParliamentarians were told about the cyberattack on the evening of 23 June, and it was made public knowledge the following day by Chris Rennard, a Liberal Democrat member of the House of Lords who posted a request on social media asking people needing to contact him urgently to do so via text message. Remote access to politicians email accounts was disabled.\nHowever, a spokesperson for the House of Commons said that this was a precautionary measure to protect security rather than a consequence of the cyberattack itself. The matter is being investigated by the National Cyber Security Centre with assistance from the National Crime Agency.Westminster authorities described the attack as \"sustained and determined\", and follows media reports that the email passwords of government ministers had been obtained by hackers and were being sold online.On 25 June, a Westminster spokesperson confirmed the cyberattack had been an attempt to hack email accounts with weak passwords, but that an investigation had found less than 1% of the 9,000 email addresses associated with parliament had been compromised\u2014a figure representing around 90 email accounts. However, it was still being treated as a serious security breach: \"The figure is less than many feared, but is still a breach.\" MPs subsequently said that agencies with links to either Russia or North Korea were suspected of being behind the attack.\n\n== Holyrood cyberattack ==\nOn 15 August, officials at Holyrood, home of the Scottish Parliament warned that accounts belonging to Members of the Scottish Parliament (MSPs) were currently the subject of a Brute-force attack which was attempting to crack weak passwords, but that no accounts had been compromised. However, MSPs were warned they may find themselves temporarily locked out of their accounts for security reasons. News outlets, such as The Guardian reported the attack was similar in nature to the one that had occurred at Westminster. The following day officials said that Holyrood was working with the UK's National Cyber Security Centre to increase security measures.\n\nQ: What measures were taken in response to the Westminster data breach?",
    "context": "",
    "output": "A: In response to the Westminster data breach, remote access to politicians' email accounts was disabled as a precautionary measure to protect security. However, a spokesperson for the House of Commons clarified that this was not a consequence of the cyberattack itself but a security measure. An investigation was initiated by the National Cyber Security Centre with assistance from the National Crime Agency.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What measures were taken in response to the Westminster data breach?",
      "answer": "In response to the Westminster data breach, remote access to politicians' email accounts was disabled as a precautionary measure to protect security. However, a spokesperson for the House of Commons clarified that this was not a consequence of the cyberattack itself but a security measure. An investigation was initiated by the National Cyber Security Centre with assistance from the National Crime Agency.",
      "context": "2017 Westminster data breach\n\n==Introduction==\nThe 2017 Westminster data breach occurred on 23 June 2017, when an unauthorised attempt was made to gain access to email accounts belonging to a number of politicians at the United Kingdom's Houses of Parliament. Whitehall officials have claimed that Iran was behind the attack. The incident was followed by an attempt to hack accounts belonging to politicians at the Scottish Parliament in August 2017.\n\n\n\n== Events ==\nParliamentarians were told about the cyberattack on the evening of 23 June, and it was made public knowledge the following day by Chris Rennard, a Liberal Democrat member of the House of Lords who posted a request on social media asking people needing to contact him urgently to do so via text message. Remote access to politicians email accounts was disabled.\nHowever, a spokesperson for the House of Commons said that this was a precautionary measure to protect security rather than a consequence of the cyberattack itself. The matter is being investigated by the National Cyber Security Centre with assistance from the National Crime Agency.Westminster authorities described the attack as \"sustained and determined\", and follows media reports that the email passwords of government ministers had been obtained by hackers and were being sold online.On 25 June, a Westminster spokesperson confirmed the cyberattack had been an attempt to hack email accounts with weak passwords, but that an investigation had found less than 1% of the 9,000 email addresses associated with parliament had been compromised\u2014a figure representing around 90 email accounts. However, it was still being treated as a serious security breach: \"The figure is less than many feared, but is still a breach.\" MPs subsequently said that agencies with links to either Russia or North Korea were suspected of being behind the attack.\n\n== Holyrood cyberattack ==\nOn 15 August, officials at Holyrood, home of the Scottish Parliament warned that accounts belonging to Members of the Scottish Parliament (MSPs) were currently the subject of a Brute-force attack which was attempting to crack weak passwords, but that no accounts had been compromised. However, MSPs were warned they may find themselves temporarily locked out of their accounts for security reasons. News outlets, such as The Guardian reported the attack was similar in nature to the one that had occurred at Westminster. The following day officials said that Holyrood was working with the UK's National Cyber Security Centre to increase security measures."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are some challenges in steganography research?",
    "context": "",
    "output": "Some challenges in steganography research include developing methods to embed larger amounts of hidden data, improving the security of carrier chains, and finding ways to defend against advanced steganalysis techniques.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are some challenges in steganography research?",
      "answer": "Some challenges in steganography research include developing methods to embed larger amounts of hidden data, improving the security of carrier chains, and finding ways to defend against advanced steganalysis techniques."
    }
  },
  {
    "instruction": "Write an answer to the following question: What kind of network is the mail server and the stunnel process typically connected to in the example scenario?",
    "context": "",
    "output": "In the example scenario, both the mail server and the stunnel process are typically connected to a secure internal network that is protected by a firewall.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What kind of network is the mail server and the stunnel process typically connected to in the example scenario?",
      "answer": "In the example scenario, both the mail server and the stunnel process are typically connected to a secure internal network that is protected by a firewall."
    }
  },
  {
    "instruction": "Electromagnetic warfare\n\n==Introduction==\nElectromagnetic warfare (EW), sometimes known as electronic warfare, is any action involving the use of the electromagnetic spectrum (EM spectrum) or directed energy to control the spectrum, attack an enemy, or impede enemy assaults. The purpose of electronic warfare is to deny the opponent the advantage of\u2014and ensure friendly unimpeded access to\u2014the EM spectrum. EW can be applied from air, sea, land, and/or space by crewed and uncrewed systems and can target communication, radar, or other military and civilian assets.\n\n== The electromagnetic environment ==\nMilitary operations are executed in an information environment increasingly complicated by the electromagnetic spectrum. The electromagnetic spectrum portion of the information environment is referred to as the electromagnetic environment (EME). The recognized need for military forces to have unimpeded access to and use of the electromagnetic environment creates vulnerabilities and opportunities for electronic warfare in support of military operations.Within the information operations construct, EW is an element of information warfare; more specifically, it is an element of offensive and defensive counterinformation.NATO has a different and arguably more encompassing and comprehensive approach to EW. A military committee conceptual document from 2007 (MCM_0142 Nov 2007 Military Committee Transformation Concept for Future NATO Electronic Warfare) recognised the EME as an operational maneuver space and warfighting environment/domain. In NATO, EW is considered to be warfare in the EME. NATO has adopted simplified language which parallels those used in other warfighting environments like maritime, land, and air/space. For example, an electronic attack (EA) is offensive use of EM energy, electronic defense (ED), and electronic surveillance (ES). The use of the traditional NATO EW terms, electronic countermeasures (ECM), electronic protective measures (EPM), and electronic support measures (ESM) has been retained as they contribute to and support electronic attack (EA), electronic defense (ED) and electronic surveillance (ES). Besides EW, other EM operations include intelligence, surveillance, target acquisition and reconnaissance (ISTAR), and signals intelligence (SIGINT). Subsequently, NATO has issued EW policy and doctrine and is addressing the other NATO defense lines of development.\nPrimary EW activities have been developed over time to exploit the opportunities and vulnerabilities that are inherent in the physics of EM energy. Activities used in EW include electro-optical, infrared and radio frequency countermeasures; EM compatibility and deception; radio jamming, radar jamming and deception and electronic counter-countermeasures (or anti-jamming); electronic masking, probing, reconnaissance, and intelligence; electronic security; EW reprogramming; emission control; spectrum management; and wartime reserve modes.\n\n== Subdivisions ==\nElectronic warfare consists of three major subdivisions: electronic attack (EA), electronic protection (EP), and electronic warfare support (ES).\n\n\n*** Electronic attack ***\n\nElectronic attack (EA), also known as electronic countermeasures (ECM), involves the offensive use of electromagnetic energy weapons, directed energy weapons, or anti-radiation weapons to attack personnel, facilities, or equipment with the intent of degrading, neutralizing, or destroying enemy combat capability including human life. In the case of electromagnetic energy, this action is most commonly referred to as \"jamming\" and can be performed on communications systems or radar systems. In the case of anti-radiation weapons, this often includes missiles or bombs that can home in on a specific signal (radio or radar) and follow that path directly to impact, thus destroying the system broadcasting.\n\n\n*** Electronic protection ***\n\nElectronic protection (EP), also known as an electronic protective measure (EPM) or electronic counter-countermeasure (ECCM) are a measure used to protect against an electronic enemy attack (EA) or to protect against friendly forces who unintentionally deploy the equivalent of an electronic attack on friendly forces. (sometimes called EW fratricide). The effectiveness of electronic protection (EP) level is the ability to counter an electronic attack (EA).\nFlares are often used to distract infrared homing missiles from missing their target. The use of flare rejection logic in the guidance (seeker head) of an infrared homing missile to counter an adversary's use of flares is an example of EP. While defensive EA actions (jamming) and EP (defeating jamming) both protect personnel, facilities, capabilities, and equipment, EP protects from the effects of EA (friendly and/or adversary). Other examples of EP include spread spectrum technologies, the use of restricted frequency lists, emissions control (EMCON), and low observability (stealth) technology.Electronic warfare self-protection (EWSP) is a suite of countermeasure systems fitted primarily to aircraft for the purpose of protecting the host from weapons fire and can include, among others: directional infrared countermeasures (DIRCM, flare systems and other forms of infrared countermeasures for protection against infrared missiles; chaff (protection against radar-guided missiles); and DRFM decoy systems (protection against radar-targeted anti-aircraft weapons).\nAn electronic warfare tactics range (EWTR) is a practice range that provides training for personnel operating in electronic warfare. There are two examples of such ranges in Europe: one at RAF Spadeadam in the northwest county of Cumbria, England, and the Multinational Aircrew Electronic Warfare Tactics Facility Polygone range on the border between Germany and France. EWTRs are equipped with ground-based equipment to simulate electronic warfare threats that aircrew might encounter on missions. Other EW training and tactics ranges are available for ground and naval forces as well.\nAntifragile EW is a step beyond standard EP, occurring when a communications link being jammed actually increases in capability as a result of a jamming attack, although this is only possible under certain circumstances such as reactive forms of jamming.In November 2021, Israel Aerospace Industries announced a new electronic warfare system named Scorpius that can disrupt radar and communications from ships, UAVs, and missiles simultaneously and at varying distances.\n\n\n*** Electronic warfare support ***\n\nElectronic warfare support (ES) is a subdivision of EW involving actions taken by an operational commander or operator to detect, intercept, identify, locate, and/or localize sources of intended and unintended radiated electromagnetic (EM) energy.  These Electronic Support Measures (ESM) aim to enable immediate threat recognition focuses on serving military service needs even in the most tactical, rugged, and extreme environments.  This is often referred to as simply reconnaissance, although today, more common terms are intelligence, surveillance and reconnaissance (ISR) or intelligence, surveillance, target acquisition, and reconnaissance (ISTAR). The purpose is to provide immediate recognition, prioritization, and targeting of threats to battlefield commanders.Signals intelligence (SIGINT), a discipline overlapping with ES, is the related process of analyzing and identifying intercepted transmissions from sources such as radio communication, mobile phones, radar, or microwave communication. SIGINT is broken into two categories: electronic intelligence (ELINT) and communications intelligence (COMINT). Analysis parameters measured in signals of these categories can include frequency, bandwidth, modulation, and polarization.\nThe distinction between SIGINT and ES is determined by the controller of the collection assets, the information provided, and the intended purpose of the information. Electronic warfare support is conducted by assets under the operational control of a commander to provide tactical information, specifically threat prioritization, recognition, location, targeting, and avoidance. However, the same assets and resources that are tasked with ES can simultaneously collect information that meets the collection requirements for more strategic intelligence.\n\n== In popular culture ==\nIn the movie Spaceballs, an electronic attack \"jams\" a weapons system with a literal jar of jam. In both Top Gun: Maverick and Behind Enemy Lines, characters utilize chaff and flares from their F/A-18s to confuse/deflect guided missiles.\nRead the text above and answer this question: How are electronic support measures (ESM) used in electronic warfare support (ES)?",
    "context": "",
    "output": "Electronic support measures (ESM) are used in electronic warfare support (ES) to detect, intercept, identify, locate, and/or localize sources of intended and unintended radiated electromagnetic energy.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How are electronic support measures (ESM) used in electronic warfare support (ES)?",
      "answer": "Electronic support measures (ESM) are used in electronic warfare support (ES) to detect, intercept, identify, locate, and/or localize sources of intended and unintended radiated electromagnetic energy.",
      "context": "Electromagnetic warfare\n\n==Introduction==\nElectromagnetic warfare (EW), sometimes known as electronic warfare, is any action involving the use of the electromagnetic spectrum (EM spectrum) or directed energy to control the spectrum, attack an enemy, or impede enemy assaults. The purpose of electronic warfare is to deny the opponent the advantage of\u2014and ensure friendly unimpeded access to\u2014the EM spectrum. EW can be applied from air, sea, land, and/or space by crewed and uncrewed systems and can target communication, radar, or other military and civilian assets.\n\n== The electromagnetic environment ==\nMilitary operations are executed in an information environment increasingly complicated by the electromagnetic spectrum. The electromagnetic spectrum portion of the information environment is referred to as the electromagnetic environment (EME). The recognized need for military forces to have unimpeded access to and use of the electromagnetic environment creates vulnerabilities and opportunities for electronic warfare in support of military operations.Within the information operations construct, EW is an element of information warfare; more specifically, it is an element of offensive and defensive counterinformation.NATO has a different and arguably more encompassing and comprehensive approach to EW. A military committee conceptual document from 2007 (MCM_0142 Nov 2007 Military Committee Transformation Concept for Future NATO Electronic Warfare) recognised the EME as an operational maneuver space and warfighting environment/domain. In NATO, EW is considered to be warfare in the EME. NATO has adopted simplified language which parallels those used in other warfighting environments like maritime, land, and air/space. For example, an electronic attack (EA) is offensive use of EM energy, electronic defense (ED), and electronic surveillance (ES). The use of the traditional NATO EW terms, electronic countermeasures (ECM), electronic protective measures (EPM), and electronic support measures (ESM) has been retained as they contribute to and support electronic attack (EA), electronic defense (ED) and electronic surveillance (ES). Besides EW, other EM operations include intelligence, surveillance, target acquisition and reconnaissance (ISTAR), and signals intelligence (SIGINT). Subsequently, NATO has issued EW policy and doctrine and is addressing the other NATO defense lines of development.\nPrimary EW activities have been developed over time to exploit the opportunities and vulnerabilities that are inherent in the physics of EM energy. Activities used in EW include electro-optical, infrared and radio frequency countermeasures; EM compatibility and deception; radio jamming, radar jamming and deception and electronic counter-countermeasures (or anti-jamming); electronic masking, probing, reconnaissance, and intelligence; electronic security; EW reprogramming; emission control; spectrum management; and wartime reserve modes.\n\n== Subdivisions ==\nElectronic warfare consists of three major subdivisions: electronic attack (EA), electronic protection (EP), and electronic warfare support (ES).\n\n\n*** Electronic attack ***\n\nElectronic attack (EA), also known as electronic countermeasures (ECM), involves the offensive use of electromagnetic energy weapons, directed energy weapons, or anti-radiation weapons to attack personnel, facilities, or equipment with the intent of degrading, neutralizing, or destroying enemy combat capability including human life. In the case of electromagnetic energy, this action is most commonly referred to as \"jamming\" and can be performed on communications systems or radar systems. In the case of anti-radiation weapons, this often includes missiles or bombs that can home in on a specific signal (radio or radar) and follow that path directly to impact, thus destroying the system broadcasting.\n\n\n*** Electronic protection ***\n\nElectronic protection (EP), also known as an electronic protective measure (EPM) or electronic counter-countermeasure (ECCM) are a measure used to protect against an electronic enemy attack (EA) or to protect against friendly forces who unintentionally deploy the equivalent of an electronic attack on friendly forces. (sometimes called EW fratricide). The effectiveness of electronic protection (EP) level is the ability to counter an electronic attack (EA).\nFlares are often used to distract infrared homing missiles from missing their target. The use of flare rejection logic in the guidance (seeker head) of an infrared homing missile to counter an adversary's use of flares is an example of EP. While defensive EA actions (jamming) and EP (defeating jamming) both protect personnel, facilities, capabilities, and equipment, EP protects from the effects of EA (friendly and/or adversary). Other examples of EP include spread spectrum technologies, the use of restricted frequency lists, emissions control (EMCON), and low observability (stealth) technology.Electronic warfare self-protection (EWSP) is a suite of countermeasure systems fitted primarily to aircraft for the purpose of protecting the host from weapons fire and can include, among others: directional infrared countermeasures (DIRCM, flare systems and other forms of infrared countermeasures for protection against infrared missiles; chaff (protection against radar-guided missiles); and DRFM decoy systems (protection against radar-targeted anti-aircraft weapons).\nAn electronic warfare tactics range (EWTR) is a practice range that provides training for personnel operating in electronic warfare. There are two examples of such ranges in Europe: one at RAF Spadeadam in the northwest county of Cumbria, England, and the Multinational Aircrew Electronic Warfare Tactics Facility Polygone range on the border between Germany and France. EWTRs are equipped with ground-based equipment to simulate electronic warfare threats that aircrew might encounter on missions. Other EW training and tactics ranges are available for ground and naval forces as well.\nAntifragile EW is a step beyond standard EP, occurring when a communications link being jammed actually increases in capability as a result of a jamming attack, although this is only possible under certain circumstances such as reactive forms of jamming.In November 2021, Israel Aerospace Industries announced a new electronic warfare system named Scorpius that can disrupt radar and communications from ships, UAVs, and missiles simultaneously and at varying distances.\n\n\n*** Electronic warfare support ***\n\nElectronic warfare support (ES) is a subdivision of EW involving actions taken by an operational commander or operator to detect, intercept, identify, locate, and/or localize sources of intended and unintended radiated electromagnetic (EM) energy.  These Electronic Support Measures (ESM) aim to enable immediate threat recognition focuses on serving military service needs even in the most tactical, rugged, and extreme environments.  This is often referred to as simply reconnaissance, although today, more common terms are intelligence, surveillance and reconnaissance (ISR) or intelligence, surveillance, target acquisition, and reconnaissance (ISTAR). The purpose is to provide immediate recognition, prioritization, and targeting of threats to battlefield commanders.Signals intelligence (SIGINT), a discipline overlapping with ES, is the related process of analyzing and identifying intercepted transmissions from sources such as radio communication, mobile phones, radar, or microwave communication. SIGINT is broken into two categories: electronic intelligence (ELINT) and communications intelligence (COMINT). Analysis parameters measured in signals of these categories can include frequency, bandwidth, modulation, and polarization.\nThe distinction between SIGINT and ES is determined by the controller of the collection assets, the information provided, and the intended purpose of the information. Electronic warfare support is conducted by assets under the operational control of a commander to provide tactical information, specifically threat prioritization, recognition, location, targeting, and avoidance. However, the same assets and resources that are tasked with ES can simultaneously collect information that meets the collection requirements for more strategic intelligence.\n\n== In popular culture ==\nIn the movie Spaceballs, an electronic attack \"jams\" a weapons system with a literal jar of jam. In both Top Gun: Maverick and Behind Enemy Lines, characters utilize chaff and flares from their F/A-18s to confuse/deflect guided missiles."
    }
  },
  {
    "instruction": "Digital Postmarks\n\n==Introduction==\nA Digital Postmark (DPM) is a technology that applies a trusted time stamp issued by a postal operator to an electronic document, validates electronic signatures, and stores and archives all non-repudiation data needed to support a potential court challenge. It guarantees the certainty of date and time of the postmarking. This global standard was renamed the Electronic Postal Certification Mark (EPCM) in 2007 shortly after a new iteration of the technology was developed by Microsoft and Poste Italiane. The key addition to the traditional postmarking technology was integrity of the electronically postmarked item, meaning any kind of falsification and tampering will be easily and definitely detected. Additionally, content confidentiality is guaranteed since document certification is carried out without access or reading by the postal operator. The EPCM will eventually be available through the UPU to all international postal operators in the 191 member countries willing to be compliant with this standard, thus granting interoperability in certified communications between postal operators. In the United States, the US Postal Service operates a non-global standard called the Electronic Postmark, although it is soon expected to provide services utilizing the EPCM.\n\n\n\n== Providers ==\nIn the United States, until the end of 2010, Authentidate was the only authorized USPS EPM provider. However, this contract was allowed to expire.\n\n== The process ==\nAn electronic document is created\nDigital Postmarking client software signs the document locally\nThe signed document is sent to the Digital Postmarking (DPM) service for postmarking\nUpon receipt, the DPM service first validates the authenticity of the signature\nIf the signature is valid then a timestamp is generated by the DPM service as a counter-signature that includes the date and time\nThe document, signature, validation results and timestamp are stored in the Digital Postmark non-repudiation database\nA Digital Postmark Receipt, including the validation results and the timestamp, is returned to the client software\nThe client software wraps the original document with the DPM receipt\nTo verify the signature, local cryptographic verification can do a quick check of integrity or the full receipt or even the original document can be retrieved from the DPM service using the XML Verify request by other parties at a later date and compared with the receipt stored with the document.\n\n== Benefits of digital postmarks ==\nThe DPM is fundamentally a non-repudiation service supporting designed to protect the sanctity of mail in its digital form:\n\nDigital signature verification\nTimestamping of successfully verified signatures\nStandalone timestamping\nEncryption\nValidation of certificate trust chains\nStorage and archival of all non-repudiation evidence data required to support subsequent challenges\nLegal significance. In addition to federal and state legislative frameworks, the DPM holds legal weight with respect to the following legislation, which have been established to encourage people to form and sign contracts and agreements electronically:\nGovernment Paperwork Elimination Act (GPEA), 1998\nUniform Electronic Transaction Act (UETA), 1999\nElectronic Signatures in Global and National Commerce Act (ESIGN), 2000Working with current infrastructure, it is easy to implement - providing functionality even with no client-side software, and provides automated functionality with client software.\n\n\n*** Additional benefits ***\nProactive differentiation \"good\" email from spam and phishing.\nImproved service quality by applying the same standards that govern physical mail to email.\nStronger authentication than other standards such as (Sender ID and DKIM).\nCompliance with all federal laws and regulations.\nPostal operator enforcement: Mail fraud is virtually non-existent with physical mail due to the legal framework and the vigorous efforts of the U.S. Postal Inspection Service. Digital Postmarks have the same legal recourse for email fraud as for physical mail fraud.\nSignificant mailing cost reduction to only a few cents.\n\n== Applicable services ==\nThe Digital Postmark can be used for a variety of business applications:\n\nsigning Web forms and documents\ndelivery of secure documents\ninterpersonal messaging\n\n== Brief history ==\nKey dates in the development of the digital postmark:\n1998\u20131999The USPS and Canada Post develop the first digital postmark.1999The UPU Standards Board begins the process to develop a global technical standard (S43) for the digital postmark.2001A workshop hosted by USPS decides on a consistent visual image for digital postmarks offered by Posts.2002USPS launches its digital postmark, the \"Electronic Postmark\". Development work on the S43 standard is completed. Microsoft agrees to define and produce an interface in W2000/XP and Office 2000 and XP 2003 to support the digital postmark.2003The UPU Standards Board formally adopts the S43 standard (See article) Archived 2007-06-11 at the Wayback Machine.\nIt defined a technical standard \u2013 \"S43 - Electronic PostMark Interface\" \u2013 which was approved by the UPU Standards Board in November 2003 as a technical standard for the postal industry.\nPortugal\u2019s postal service launches a legally recognized digital postmarks service.2004The UPU Congress adopts a proposal to amend the UPU Convention to legally define the digital postmark, formally recognizing it as a new optional postal service.\nSeptember: The UPU Legally Defined the EPM as a Postal Service  (See article)\nThis makes the EPM an optional postal service for UPU member countries, placing the EPM in the same category as Express Mail.\nThe UPU definition provides international technological and enforcement standards Archived 2008-11-03 at the Wayback Machine.2005Adobe agrees to support the inclusion of the digital postmark.\nLa Poste France develops an S43-based digital postmark server. It is used as early as 2006.2006The UPU Standards Board approves version 3 of the standard S43, the first to enable cross-border and global traffic using digital postmarks.\nJanuary: The UPU Approved a DPM Regulation (See article). This regulation was passed as an amendment with the letter mail regulation.\nEvery postal service has a UPU regulation that manages the service and regulates how the posts will cooperate in that service. This makes it easier to assist member countries in developing the market for worldwide digital postmark services.\nThis DPM Regulation has dramatically increased interest in the EPM worldwide.\nPoste Italiane develops a plug-in to enable Microsoft Office users to connect to a backend server, which delivers digital postmarks that comply with the UPU\u2019s S43 technical standard.2007April: The UPU Approved the renaming of Digital postmark to Electronic Postal Certification Mark EPCM\n\n== Global usage ==\nRecognizing the great potential of the Digital Postmark, numerous postal administrations worldwide have begun deploying DPM-based solutions. Five postal services \u2013 Canada, France, Italy, Portugal and the United States \u2013 have developed their own digital postmark and use it today. Major software developers are also working to incorporate the global standard into popular applications used by millions of people worldwide.\nUnited States (first launched EPM in 1996; current EPM released March 2003)\nFrance (first launch in 1999)\nCanada (launched 1st quarter 2003)\nPortugal (launched September 2003)\nItaly (launched 2005 by Poste Italiane as Posteitaliane.mail, now Posteitaliane.post)\nEgypt (contracted with provider 1st quarter 2005)\nSwitzerland (contracted with provider July 2005)\nBrazil (contracted with provider 2004)\nChina (preparing to launch)\nNetherlands (preparing to launch)\nUnited Kingdom (preparing to launch)The Universal Postal Union (UPU) has identified trust services as the greatest opportunity for global postal growth. Specifically, they identified the Digital Postmark as the most important trust service; providing an excellent defense against online fraud and abuse.\n\n== Electronic postmarks ==\nThe  United States Postal Service (USPS) Electronic Postmark  (EPM\u00a9) is a proprietary variation of the Digital Postmark issued by the USPS. It was introduced in 1996 by the U.S. Postal Service as a service offering that provides proof of integrity and authentication for electronic transactions.\nThrough the USPS EPM web-based service, any third-party can verify the authenticity of electronic content. This electronic proof, postmarked by the Postal Service, provides evidence to support non-repudiation of electronic transactions. The EPM is designed to deter and detect the fraudulent tampering or altering of electronic data.\n\n\n*** Key features ***\nThe USPS wrote that the key features of their Electronic Postmark are:\n\nContent authentication web-based service (based upon American Bar Association PKI Guidelines) proves document authenticity and timestamp accuracy to detect and prevent fraud.\nIntegrates easily into existing applications with standard-based interfaces.\nVerify options include; local (self contained) & centralized (Internet based).\nVerification is free.\n128 Bit SSL encryption insuring privacy and security of communications.\nData stays private. Service never has access to your content and requires no modification or transmission of content. (only a hash code of the file is logged as evidence of authenticity.)\n\n\n*** US legal environment ***\nThe USPS listed laws relevant to EPM as follows:\n\n18 U.S.C. \u00a71343 Wire Fraud\n18 U.S.C. \u00a72701 Electronic Communications Privacy Act (ECPA)\n18 U.S.C. \u00a72510 regarding electronic communications. Definitions (17)Electronic storage means\n(A) any temporary, intermediate storage of a wire or electronic communication incident to the electronic transmission thereof\n(B) any storage of such communication by an electronic communication service for purposes of backup protection of such communication.\n18 U.S.C. \u00a72710 regarding unlawful access to stored electronic communications\n18 U.S.C. \u00a71028, Fraud and related activity in connection with identification documents and information\n18 U.S.C. \u00a71029, Fraud and related activity in connection with access devices.\n\n== Additional ==\n\n\n*** Other definitions ***\nA Digital Postmark (DPM) is also a network security mechanism, developed by Penn State researchers Ihab Hamadeh and George Kesidis, to identify which region a packet or a set of packets comes from.  It was developed as a way to combat spam and denial-of-service (virus) attacks by isolating the source of such attacks, while still allowing \"good\" messages to pass through.\nA digital postmark works when a perimeter router marks up a packet border with its region-identifying data.  Also called a \"border router packet marking\", it uses an obsolete or unused portion of the packet to place the regional mark-up.  When room does not exist in any one portion of the packet, the region information can be broken up and hashed in a subsequently retrievable way.\n\nWhat is the significance of the Electronic Postal Certification Mark (EPCM) for postal operators in the 191 member countries of the UPU?",
    "context": "",
    "output": "A: The EPCM is significant for postal operators in the 191 member countries of the UPU as it will be available to them, granting interoperability in certified communications between postal operators.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the significance of the Electronic Postal Certification Mark (EPCM) for postal operators in the 191 member countries of the UPU?",
      "answer": "The EPCM is significant for postal operators in the 191 member countries of the UPU as it will be available to them, granting interoperability in certified communications between postal operators.",
      "context": "Digital Postmarks\n\n==Introduction==\nA Digital Postmark (DPM) is a technology that applies a trusted time stamp issued by a postal operator to an electronic document, validates electronic signatures, and stores and archives all non-repudiation data needed to support a potential court challenge. It guarantees the certainty of date and time of the postmarking. This global standard was renamed the Electronic Postal Certification Mark (EPCM) in 2007 shortly after a new iteration of the technology was developed by Microsoft and Poste Italiane. The key addition to the traditional postmarking technology was integrity of the electronically postmarked item, meaning any kind of falsification and tampering will be easily and definitely detected. Additionally, content confidentiality is guaranteed since document certification is carried out without access or reading by the postal operator. The EPCM will eventually be available through the UPU to all international postal operators in the 191 member countries willing to be compliant with this standard, thus granting interoperability in certified communications between postal operators. In the United States, the US Postal Service operates a non-global standard called the Electronic Postmark, although it is soon expected to provide services utilizing the EPCM.\n\n\n\n== Providers ==\nIn the United States, until the end of 2010, Authentidate was the only authorized USPS EPM provider. However, this contract was allowed to expire.\n\n== The process ==\nAn electronic document is created\nDigital Postmarking client software signs the document locally\nThe signed document is sent to the Digital Postmarking (DPM) service for postmarking\nUpon receipt, the DPM service first validates the authenticity of the signature\nIf the signature is valid then a timestamp is generated by the DPM service as a counter-signature that includes the date and time\nThe document, signature, validation results and timestamp are stored in the Digital Postmark non-repudiation database\nA Digital Postmark Receipt, including the validation results and the timestamp, is returned to the client software\nThe client software wraps the original document with the DPM receipt\nTo verify the signature, local cryptographic verification can do a quick check of integrity or the full receipt or even the original document can be retrieved from the DPM service using the XML Verify request by other parties at a later date and compared with the receipt stored with the document.\n\n== Benefits of digital postmarks ==\nThe DPM is fundamentally a non-repudiation service supporting designed to protect the sanctity of mail in its digital form:\n\nDigital signature verification\nTimestamping of successfully verified signatures\nStandalone timestamping\nEncryption\nValidation of certificate trust chains\nStorage and archival of all non-repudiation evidence data required to support subsequent challenges\nLegal significance. In addition to federal and state legislative frameworks, the DPM holds legal weight with respect to the following legislation, which have been established to encourage people to form and sign contracts and agreements electronically:\nGovernment Paperwork Elimination Act (GPEA), 1998\nUniform Electronic Transaction Act (UETA), 1999\nElectronic Signatures in Global and National Commerce Act (ESIGN), 2000Working with current infrastructure, it is easy to implement - providing functionality even with no client-side software, and provides automated functionality with client software.\n\n\n*** Additional benefits ***\nProactive differentiation \"good\" email from spam and phishing.\nImproved service quality by applying the same standards that govern physical mail to email.\nStronger authentication than other standards such as (Sender ID and DKIM).\nCompliance with all federal laws and regulations.\nPostal operator enforcement: Mail fraud is virtually non-existent with physical mail due to the legal framework and the vigorous efforts of the U.S. Postal Inspection Service. Digital Postmarks have the same legal recourse for email fraud as for physical mail fraud.\nSignificant mailing cost reduction to only a few cents.\n\n== Applicable services ==\nThe Digital Postmark can be used for a variety of business applications:\n\nsigning Web forms and documents\ndelivery of secure documents\ninterpersonal messaging\n\n== Brief history ==\nKey dates in the development of the digital postmark:\n1998\u20131999The USPS and Canada Post develop the first digital postmark.1999The UPU Standards Board begins the process to develop a global technical standard (S43) for the digital postmark.2001A workshop hosted by USPS decides on a consistent visual image for digital postmarks offered by Posts.2002USPS launches its digital postmark, the \"Electronic Postmark\". Development work on the S43 standard is completed. Microsoft agrees to define and produce an interface in W2000/XP and Office 2000 and XP 2003 to support the digital postmark.2003The UPU Standards Board formally adopts the S43 standard (See article) Archived 2007-06-11 at the Wayback Machine.\nIt defined a technical standard \u2013 \"S43 - Electronic PostMark Interface\" \u2013 which was approved by the UPU Standards Board in November 2003 as a technical standard for the postal industry.\nPortugal\u2019s postal service launches a legally recognized digital postmarks service.2004The UPU Congress adopts a proposal to amend the UPU Convention to legally define the digital postmark, formally recognizing it as a new optional postal service.\nSeptember: The UPU Legally Defined the EPM as a Postal Service  (See article)\nThis makes the EPM an optional postal service for UPU member countries, placing the EPM in the same category as Express Mail.\nThe UPU definition provides international technological and enforcement standards Archived 2008-11-03 at the Wayback Machine.2005Adobe agrees to support the inclusion of the digital postmark.\nLa Poste France develops an S43-based digital postmark server. It is used as early as 2006.2006The UPU Standards Board approves version 3 of the standard S43, the first to enable cross-border and global traffic using digital postmarks.\nJanuary: The UPU Approved a DPM Regulation (See article). This regulation was passed as an amendment with the letter mail regulation.\nEvery postal service has a UPU regulation that manages the service and regulates how the posts will cooperate in that service. This makes it easier to assist member countries in developing the market for worldwide digital postmark services.\nThis DPM Regulation has dramatically increased interest in the EPM worldwide.\nPoste Italiane develops a plug-in to enable Microsoft Office users to connect to a backend server, which delivers digital postmarks that comply with the UPU\u2019s S43 technical standard.2007April: The UPU Approved the renaming of Digital postmark to Electronic Postal Certification Mark EPCM\n\n== Global usage ==\nRecognizing the great potential of the Digital Postmark, numerous postal administrations worldwide have begun deploying DPM-based solutions. Five postal services \u2013 Canada, France, Italy, Portugal and the United States \u2013 have developed their own digital postmark and use it today. Major software developers are also working to incorporate the global standard into popular applications used by millions of people worldwide.\nUnited States (first launched EPM in 1996; current EPM released March 2003)\nFrance (first launch in 1999)\nCanada (launched 1st quarter 2003)\nPortugal (launched September 2003)\nItaly (launched 2005 by Poste Italiane as Posteitaliane.mail, now Posteitaliane.post)\nEgypt (contracted with provider 1st quarter 2005)\nSwitzerland (contracted with provider July 2005)\nBrazil (contracted with provider 2004)\nChina (preparing to launch)\nNetherlands (preparing to launch)\nUnited Kingdom (preparing to launch)The Universal Postal Union (UPU) has identified trust services as the greatest opportunity for global postal growth. Specifically, they identified the Digital Postmark as the most important trust service; providing an excellent defense against online fraud and abuse.\n\n== Electronic postmarks ==\nThe  United States Postal Service (USPS) Electronic Postmark  (EPM\u00a9) is a proprietary variation of the Digital Postmark issued by the USPS. It was introduced in 1996 by the U.S. Postal Service as a service offering that provides proof of integrity and authentication for electronic transactions.\nThrough the USPS EPM web-based service, any third-party can verify the authenticity of electronic content. This electronic proof, postmarked by the Postal Service, provides evidence to support non-repudiation of electronic transactions. The EPM is designed to deter and detect the fraudulent tampering or altering of electronic data.\n\n\n*** Key features ***\nThe USPS wrote that the key features of their Electronic Postmark are:\n\nContent authentication web-based service (based upon American Bar Association PKI Guidelines) proves document authenticity and timestamp accuracy to detect and prevent fraud.\nIntegrates easily into existing applications with standard-based interfaces.\nVerify options include; local (self contained) & centralized (Internet based).\nVerification is free.\n128 Bit SSL encryption insuring privacy and security of communications.\nData stays private. Service never has access to your content and requires no modification or transmission of content. (only a hash code of the file is logged as evidence of authenticity.)\n\n\n*** US legal environment ***\nThe USPS listed laws relevant to EPM as follows:\n\n18 U.S.C. \u00a71343 Wire Fraud\n18 U.S.C. \u00a72701 Electronic Communications Privacy Act (ECPA)\n18 U.S.C. \u00a72510 regarding electronic communications. Definitions (17)Electronic storage means\n(A) any temporary, intermediate storage of a wire or electronic communication incident to the electronic transmission thereof\n(B) any storage of such communication by an electronic communication service for purposes of backup protection of such communication.\n18 U.S.C. \u00a72710 regarding unlawful access to stored electronic communications\n18 U.S.C. \u00a71028, Fraud and related activity in connection with identification documents and information\n18 U.S.C. \u00a71029, Fraud and related activity in connection with access devices.\n\n== Additional ==\n\n\n*** Other definitions ***\nA Digital Postmark (DPM) is also a network security mechanism, developed by Penn State researchers Ihab Hamadeh and George Kesidis, to identify which region a packet or a set of packets comes from.  It was developed as a way to combat spam and denial-of-service (virus) attacks by isolating the source of such attacks, while still allowing \"good\" messages to pass through.\nA digital postmark works when a perimeter router marks up a packet border with its region-identifying data.  Also called a \"border router packet marking\", it uses an obsolete or unused portion of the packet to place the regional mark-up.  When room does not exist in any one portion of the packet, the region information can be broken up and hashed in a subsequently retrievable way."
    }
  },
  {
    "instruction": "Context: Indistinguishability obfuscation\n\n==Introduction==\nIn cryptography, indistinguishability obfuscation (abbreviated IO or iO) is a type of software obfuscation with the defining property that obfuscating any two programs that compute the same mathematical function results in programs that cannot be distinguished from each other. Informally, such obfuscation hides the implementation of a program while still allowing users to run it. Formally, IO satisfies the property that obfuscations of two circuits of the same size which implement the same function are computationally indistinguishable.Indistinguishability obfuscation has several interesting theoretical properties. Firstly, iO is the \"best-possible\" obfuscation (in the sense that any secret about a program that can be hidden by any obfuscator at all can also be hidden by iO). Secondly, iO can be used to construct nearly the entire gamut of cryptographic primitives, including both mundane ones such as public-key cryptography and more exotic ones such as deniable encryption and functional encryption (which are types of cryptography that no-one previously knew how to construct), but with the notable exception of collision-resistant hash function families. For this reason, it has been referred to as \"crypto-complete\". Lastly, unlike many other kinds of cryptography, indistinguishability obfuscation continues to exist even if P=NP (though it would have to be constructed differently in this case), though this does not necessarily imply that iO exists unconditionally.\nThough the idea of cryptographic software obfuscation has been around since 1996, indistinguishability obfuscation was first proposed by Barak et al. (2001), who proved that iO exists if P=NP is the case. For the P!=NP case (which is harder, but also more plausible), progress was slower: Garg et al. (2013) proposed a construction of iO based on a computational hardness assumption relating to multilinear maps, but this assumption was later disproven. A construction based on \"well-founded assumptions\" (hardness assumptions that have been well-studied by cryptographers, and thus widely assumed secure) had to wait until Jain, Lin, and Sahai (2020). (Even so, one of these assumptions used in the 2020 proposal is not secure against quantum computers.)\nCurrently known indistinguishability obfuscation candidates are very far from being practical. As measured by a 2017 paper, even obfuscating the toy function which outputs the logical conjunction of its thirty-two Boolean data type inputs produces a program nearly a dozen gigabytes large.\n\n\n\n== Formal definition ==\n\nLet \n  \n    \n      \n        \n          \n            i\n            O\n          \n        \n      \n    \n    {\\displaystyle {\\mathcal {iO}}}\n   be some uniform probabilistic polynomial-time algorithm. Then \n  \n    \n      \n        \n          \n            i\n            O\n          \n        \n      \n    \n    {\\displaystyle {\\mathcal {iO}}}\n   is called an indistinguishability obfuscator if and only if it satisfies both of the following two statements:\nCompleteness or Functionality: For any Boolean circuit C of input length n and input \n  \n    \n      \n        x\n        \u2208\n        {\n        0\n        ,\n        1\n        \n          }\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle x\\in \\{0,1\\}^{n}}\n  , we have \nIndistinguishability: For every pair of circuits \n  \n    \n      \n        \n          C\n          \n            0\n          \n        \n        ,\n        \n          C\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle C_{0},C_{1}}\n   of the same size k that implement the same functionality, the distributions \n  \n    \n      \n        {\n        \n          \n            i\n            O\n          \n        \n        (\n        \n          C\n          \n            0\n          \n        \n        )\n        }\n      \n    \n    {\\displaystyle \\{{\\mathcal {iO}}(C_{0})\\}}\n   and \n  \n    \n      \n        {\n        \n          \n            i\n            O\n          \n        \n        (\n        \n          C\n          \n            1\n          \n        \n        )\n        }\n      \n    \n    {\\displaystyle \\{{\\mathcal {iO}}(C_{1})\\}}\n   are computationally indistinguishable. In other words, for any probabilistic polynomial-time adversary A, there is a negligible function \n  \n    \n      \n        \u03b5\n        (\n        k\n        )\n      \n    \n    {\\displaystyle \\varepsilon (k)}\n   (i.e., a function that eventually grows slower than \n  \n    \n      \n        1\n        \n          /\n        \n        p\n        (\n        k\n        )\n      \n    \n    {\\displaystyle 1/p(k)}\n   for any polynomial p) such that, for every pair of circuits \n  \n    \n      \n        \n          C\n          \n            0\n          \n        \n        ,\n        \n          C\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle C_{0},C_{1}}\n   of the same size k that implement the same functionality, we have\n\n== Existence ==\n\nIt is useful to divide the question of the existence of iO by using Russell Impagliazzo's \"five worlds\", which are five different hypothetical situations about average-case complexity:\nAlgorithmica: In this case P\n\n== Potential applications ==\nIndistinguishability obfuscators, if they exist, could be used for an enormous range of cryptographic applications, so much so that it has been referred to as a \"central hub\" for cryptography, the \"crown jewel of cryptography\", or \"crypto-complete\". Concretely, an indistinguishability obfuscator (with the additional assumption of the existence of one-way functions) could be used to construct the following kinds of cryptography:\n\nIndistinguishability obfuscation for programs in the RAM model and for Turing machines\nIND-CCA-secure public-key cryptography\nShort digital signatures\nIND-CCA-secure key encapsulation schemes\nPerfectly zero-knowledge non-interactive zero-knowledge proofs and succinct non-interactive arguments\nConstant-round concurrent zero-knowledge protocols\nMultilinear maps with bounded polynomial degrees\nInjective trapdoor functions\nFully homomorphic encryption\nWitness encryption\nFunctional encryption\nSecret sharing for any monotone NP language\nSemi-honest oblivious transfer\nDeniable encryption (both sender-deniable and fully-deniable)\nMultiparty, non-interactive key exchange\nAdaptively secure succinct garbled RAM\nCorrelation intractable functions\nAttribute-based encryption\nOblivious transfer\nTraitor tracing\nGraded encoding schemesAdditionally, if iO and one-way functions exist, then problems in the PPAD complexity class are provably hard.However, indistinguishability obfuscation cannot be used to construct every possible cryptographic protocol: for example, no black-box construction can convert an indistinguishability obfuscator to a collision-resistant hash function family, even with a trapdoor permutation, unless with an exponential loss of security.\n\nQuestion: What is the indistinguishability property of indistinguishability obfuscation?\n\nAnswer:",
    "context": "",
    "output": "The indistinguishability property of indistinguishability obfuscation states that for every pair of circuits C0,C1 of the same size k that implement the same functionality, the distributions {iO(C0)} and {iO(C1)} are computationally indistinguishable.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the indistinguishability property of indistinguishability obfuscation?",
      "answer": "The indistinguishability property of indistinguishability obfuscation states that for every pair of circuits C0,C1 of the same size k that implement the same functionality, the distributions {iO(C0)} and {iO(C1)} are computationally indistinguishable.",
      "context": "Indistinguishability obfuscation\n\n==Introduction==\nIn cryptography, indistinguishability obfuscation (abbreviated IO or iO) is a type of software obfuscation with the defining property that obfuscating any two programs that compute the same mathematical function results in programs that cannot be distinguished from each other. Informally, such obfuscation hides the implementation of a program while still allowing users to run it. Formally, IO satisfies the property that obfuscations of two circuits of the same size which implement the same function are computationally indistinguishable.Indistinguishability obfuscation has several interesting theoretical properties. Firstly, iO is the \"best-possible\" obfuscation (in the sense that any secret about a program that can be hidden by any obfuscator at all can also be hidden by iO). Secondly, iO can be used to construct nearly the entire gamut of cryptographic primitives, including both mundane ones such as public-key cryptography and more exotic ones such as deniable encryption and functional encryption (which are types of cryptography that no-one previously knew how to construct), but with the notable exception of collision-resistant hash function families. For this reason, it has been referred to as \"crypto-complete\". Lastly, unlike many other kinds of cryptography, indistinguishability obfuscation continues to exist even if P=NP (though it would have to be constructed differently in this case), though this does not necessarily imply that iO exists unconditionally.\nThough the idea of cryptographic software obfuscation has been around since 1996, indistinguishability obfuscation was first proposed by Barak et al. (2001), who proved that iO exists if P=NP is the case. For the P!=NP case (which is harder, but also more plausible), progress was slower: Garg et al. (2013) proposed a construction of iO based on a computational hardness assumption relating to multilinear maps, but this assumption was later disproven. A construction based on \"well-founded assumptions\" (hardness assumptions that have been well-studied by cryptographers, and thus widely assumed secure) had to wait until Jain, Lin, and Sahai (2020). (Even so, one of these assumptions used in the 2020 proposal is not secure against quantum computers.)\nCurrently known indistinguishability obfuscation candidates are very far from being practical. As measured by a 2017 paper, even obfuscating the toy function which outputs the logical conjunction of its thirty-two Boolean data type inputs produces a program nearly a dozen gigabytes large.\n\n\n\n== Formal definition ==\n\nLet \n  \n    \n      \n        \n          \n            i\n            O\n          \n        \n      \n    \n    {\\displaystyle {\\mathcal {iO}}}\n   be some uniform probabilistic polynomial-time algorithm. Then \n  \n    \n      \n        \n          \n            i\n            O\n          \n        \n      \n    \n    {\\displaystyle {\\mathcal {iO}}}\n   is called an indistinguishability obfuscator if and only if it satisfies both of the following two statements:\nCompleteness or Functionality: For any Boolean circuit C of input length n and input \n  \n    \n      \n        x\n        \u2208\n        {\n        0\n        ,\n        1\n        \n          }\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle x\\in \\{0,1\\}^{n}}\n  , we have \nIndistinguishability: For every pair of circuits \n  \n    \n      \n        \n          C\n          \n            0\n          \n        \n        ,\n        \n          C\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle C_{0},C_{1}}\n   of the same size k that implement the same functionality, the distributions \n  \n    \n      \n        {\n        \n          \n            i\n            O\n          \n        \n        (\n        \n          C\n          \n            0\n          \n        \n        )\n        }\n      \n    \n    {\\displaystyle \\{{\\mathcal {iO}}(C_{0})\\}}\n   and \n  \n    \n      \n        {\n        \n          \n            i\n            O\n          \n        \n        (\n        \n          C\n          \n            1\n          \n        \n        )\n        }\n      \n    \n    {\\displaystyle \\{{\\mathcal {iO}}(C_{1})\\}}\n   are computationally indistinguishable. In other words, for any probabilistic polynomial-time adversary A, there is a negligible function \n  \n    \n      \n        \u03b5\n        (\n        k\n        )\n      \n    \n    {\\displaystyle \\varepsilon (k)}\n   (i.e., a function that eventually grows slower than \n  \n    \n      \n        1\n        \n          /\n        \n        p\n        (\n        k\n        )\n      \n    \n    {\\displaystyle 1/p(k)}\n   for any polynomial p) such that, for every pair of circuits \n  \n    \n      \n        \n          C\n          \n            0\n          \n        \n        ,\n        \n          C\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle C_{0},C_{1}}\n   of the same size k that implement the same functionality, we have\n\n== Existence ==\n\nIt is useful to divide the question of the existence of iO by using Russell Impagliazzo's \"five worlds\", which are five different hypothetical situations about average-case complexity:\nAlgorithmica: In this case P\n\n== Potential applications ==\nIndistinguishability obfuscators, if they exist, could be used for an enormous range of cryptographic applications, so much so that it has been referred to as a \"central hub\" for cryptography, the \"crown jewel of cryptography\", or \"crypto-complete\". Concretely, an indistinguishability obfuscator (with the additional assumption of the existence of one-way functions) could be used to construct the following kinds of cryptography:\n\nIndistinguishability obfuscation for programs in the RAM model and for Turing machines\nIND-CCA-secure public-key cryptography\nShort digital signatures\nIND-CCA-secure key encapsulation schemes\nPerfectly zero-knowledge non-interactive zero-knowledge proofs and succinct non-interactive arguments\nConstant-round concurrent zero-knowledge protocols\nMultilinear maps with bounded polynomial degrees\nInjective trapdoor functions\nFully homomorphic encryption\nWitness encryption\nFunctional encryption\nSecret sharing for any monotone NP language\nSemi-honest oblivious transfer\nDeniable encryption (both sender-deniable and fully-deniable)\nMultiparty, non-interactive key exchange\nAdaptively secure succinct garbled RAM\nCorrelation intractable functions\nAttribute-based encryption\nOblivious transfer\nTraitor tracing\nGraded encoding schemesAdditionally, if iO and one-way functions exist, then problems in the PPAD complexity class are provably hard.However, indistinguishability obfuscation cannot be used to construct every possible cryptographic protocol: for example, no black-box construction can convert an indistinguishability obfuscator to a collision-resistant hash function family, even with a trapdoor permutation, unless with an exponential loss of security."
    }
  },
  {
    "instruction": "Mental poker\n\n==Introduction==\nMental poker is the common name for a set of cryptographic problems that concerns playing a fair game over distance without the need for a trusted third party. The term is also applied to the theories surrounding these problems and their possible solutions. The name comes from the card game poker which is one of the games to which this kind of problem applies. Similar problems described as two party games are Blum's flipping a coin over a distance,  Yao's Millionaires' Problem, and Rabin's oblivious transfer.\nThe problem can be described thus: \"How can one allow only authorized actors to have access to certain information while not using a trusted arbiter?\" (Eliminating the trusted third-party avoids the problem of trying to determine whether the third party can be trusted or not, and may also reduce the resources required.)\nIn poker, this could translate to: \"How can we make sure no player is stacking the deck or peeking at other players' cards when we are shuffling the deck ourselves?\". In a physical card game, this would be relatively simple if the players were sitting face to face and observing each other, at least if the possibility of conventional cheating can be ruled out. However, if the players are not sitting at the same location but instead are at widely separate locations and pass the entire deck between them (using the postal mail, for instance), this suddenly becomes very difficult. And for electronic card games, such as online poker, where the mechanics of the game are hidden from the user, this is impossible unless the method used is such that it cannot allow any party to cheat by manipulating or inappropriately observing the electronic \"deck\".\nSeveral protocols for doing this have been suggested, the first by Adi Shamir, Ron Rivest and Len Adleman (the creators of the RSA-encryption protocol). This protocol was the first example of two parties conducting secure computation rather than secure message transmission, employing cryptography; later on due to leaking partial information in the original protocol, this led to the definition of semantic security by Shafi Goldwasser and Silvio Micali. The concept of multi-player mental poker was introduced in Moti Yung's 1984 book Cryptoprotocols. The area has later evolved into what is known as secure multi-party computation protocols (for two parties, and multi parties as well).\n\n\n\n== Shuffling cards using commutative encryption ==\nOne possible algorithm for shuffling cards without the use of a trusted third party is to use a commutative encryption scheme. A commutative scheme means that if some data is encrypted more than once, the order in which one decrypts this data will not matter.\nExample: Alice has a plaintext message. She encrypts this, producing a garbled ciphertext which she gives then to Bob. Bob encrypts the ciphertext again, using the same scheme as Alice but with another key. When decrypting this double encrypted message, if the encryption scheme is commutative, it will not matter who decrypts first.\n\n\n*** The algorithm ***\nAn algorithm for shuffling cards using commutative encryption would be as follows:\n\nAlice and Bob agree on a certain \"deck\" of cards. In practice, this means they agree on a set of numbers or other data such that each element of the set represents a card.\nAlice picks an encryption key A and uses this to encrypt each card of the deck.\nAlice shuffles the cards.\nAlice passes the encrypted and shuffled deck to Bob. With the encryption in place, Bob cannot know which card is which.\nBob picks an encryption key B and uses this to encrypt each card of the encrypted and shuffled deck.\nBob shuffles the deck.\nBob passes the double encrypted and shuffled deck back to Alice.\nAlice decrypts each card using her key A. This still leaves Bob's encryption in place though so she cannot know which card is which.\nAlice picks one encryption key for each card (A1, A2, etc.) and encrypts them individually.\nAlice passes the deck to Bob.\nBob decrypts each card using his key B. This still leaves Alice's individual encryption in place though so he cannot know which card is which.\nBob picks one encryption key for each card (B1, B2, etc.) and encrypts them individually.\nBob passes the deck back to Alice.\nAlice publishes the deck for everyone playing (in this case only Alice and Bob, see below on expansion though).The deck is now shuffled.\nThis algorithm may be expanded for an arbitrary number of players. Players Carol, Dave and so forth need only repeat steps 2-4 and 8-10.\nDuring the game, Alice and Bob will pick cards from the deck, identified in which order they are placed in the shuffled deck. When either player wants to see their cards, they will request the corresponding keys from the other player. That player, upon checking that the requesting player is indeed entitled to look at the cards, passes the individual keys for those cards to the other player. The check is to ensure that the player does not try to request keys for cards that do not belong to that player.\nExample: Alice has picked cards 1 to 5 in the shuffled deck. Bob has picked cards 6 to 10. Bob requests to look at his allotted cards. Alice agrees that Bob is entitled to look at cards 6 to 10 and gives him her individual card keys A6 to A10. Bob decrypts his cards by using both Alice's keys and his own for these cards, B6 to B10. Bob can now see the cards. Alice cannot know which cards Bob has because she does not have access to Bob's keys B6 to B10 which are required to decrypt the cards.\n\n\n*** Weakness ***\nThe encryption scheme used must be secure against known-plaintext attacks: Bob must not be able to determine Alice's original key A (or enough of it to allow him to decrypt any cards he does not hold) based on his knowledge of the unencrypted values of the cards he has drawn. This rules out some obvious commutative encryption schemes, such as simply XORing each card with the key. (Using a separate key for each card even in the initial exchange, which would otherwise make this scheme secure, doesn't work since the cards are shuffled before they're returned.)\nDepending on the deck agreed upon, this algorithm may be weak. When encrypting data, certain properties of this data may be preserved from the plaintext to the ciphertext. This may be used to \"tag\" certain cards. Therefore, the parties must agree on a deck where no cards have properties that are preserved during encryption.\n\n== \"A Toolbox for Mental Card Games\" and its implementation ==\nChristian Schindelhauer describes sophisticated protocols to both perform and verify a large number of useful operations on cards and stacks of cards in his 1998 paper \"A Toolbox for Mental Card Games\" [SCH98]. The work is concerned with general-purpose operations (masking and unmasking cards, shuffling and re-shuffling, inserting a card into a stack, etc.) that make the protocols applicable to any card game. The cryptographic protocols used by Schindelhauer are based on quadratic residuosity, and the general scheme is similar in spirit to the above protocol. The correctness of operations can be checked by using zero-knowledge proofs, so that players do not need to reveal their strategy to verify the game's correctness.\nThe C++ library libtmcg [STA05] provides an implementation of the Schindelhauer toolbox. It has been used to implement a secure version of the German card game Skat, achieving modest real-world performance. The game Skat is played by three players with a 32-card deck, and so is substantially less computationally intensive than a poker game in which anywhere from five to eight players use a full 52-card deck.\n\n== A non-shuffling poker protocol ==\nTo date, mental poker approaches based on the standard Alice-Bob protocol (above) do not offer high enough performance for real-time online play. The requirement that each player encrypts each card imposes a substantial overhead. A recent paper by Golle [GOL05] describes a mental poker protocol that achieves significantly higher performance by exploiting the properties of the poker game to move away from the encrypt-shuffle model. Rather than shuffle the cards and then deal as needed, with the new approach, the players generate (encrypted) random numbers on the fly, which are used to select the next card. Every new card needs to be checked against all the cards that have already been dealt to detect duplicates. As a result, this method is uniquely useful in poker-style games, in which the number of cards dealt is very small compared to the size of the whole deck. However, the method needs all cards that have already been dealt to be known to all, which in most poker-style games would beat its very purpose.\nThe card-generation algorithm requires a cryptosystem with two key properties. The encryption E must be additively homomorphic, so that E(c1)*E(c2)\n\n== Better performance through increased trust ==\nAny mental poker protocol that relies on the players to perform the encryption is bound by the requirement that every player encrypt every card that is dealt. However, by making limited assumptions about the trustworthiness of third parties, significantly more efficient protocols may be realized. The protocol for choosing cards without shuffling may be adapted so that the encryption is handled by two or more servers. Under the assumption that the servers are non-colluding, such a protocol is secure.\nThe basic protocol using two servers is as follows:\n\nServers S1 and S2 encrypt and shuffle a deck of cards, and publish a non-malleable commitment to some permutation of encrypted cards to the players. This can be done with any of several well-understood cryptographic protocols.\nPlayers compute independent random numbers in {0,...,51}, which are combined to generate a random number in {0,..., 51}, as in [GOL05]\nThe random number is used as an index into the random permutation, the appropriate player gains \"ownership\" of the specified card, and the servers send that player the keys to read the card's value.In this protocol, servers S1 and S2 must collude if either is to learn the values of any cards. Furthermore, because players ultimately decide which cards are dealt, non-trustworthy servers are unable to influence the game to the extent that is possible in traditional online poker. The scheme may be extended to allow more servers, (and thus, increased security), simply by including the additional servers in the initial encryption. Finally, step one in the protocol may be done offline, allowing for large numbers of shuffled, encrypted \"decks\" to be pre-computed and cached, resulting in excellent in-game performance.\nQuestion: What is the limitation of the non-shuffling poker protocol described by Golle?",
    "context": "",
    "output": "Answer: The limitation of the non-shuffling poker protocol described by Golle is that every new card needs to be checked against all the cards that have already been dealt to detect duplicates, and the method needs all cards that have already been dealt to be known to all, which in most poker-style games would beat its very purpose.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the limitation of the non-shuffling poker protocol described by Golle?",
      "answer": "The limitation of the non-shuffling poker protocol described by Golle is that every new card needs to be checked against all the cards that have already been dealt to detect duplicates, and the method needs all cards that have already been dealt to be known to all, which in most poker-style games would beat its very purpose.",
      "context": "Mental poker\n\n==Introduction==\nMental poker is the common name for a set of cryptographic problems that concerns playing a fair game over distance without the need for a trusted third party. The term is also applied to the theories surrounding these problems and their possible solutions. The name comes from the card game poker which is one of the games to which this kind of problem applies. Similar problems described as two party games are Blum's flipping a coin over a distance,  Yao's Millionaires' Problem, and Rabin's oblivious transfer.\nThe problem can be described thus: \"How can one allow only authorized actors to have access to certain information while not using a trusted arbiter?\" (Eliminating the trusted third-party avoids the problem of trying to determine whether the third party can be trusted or not, and may also reduce the resources required.)\nIn poker, this could translate to: \"How can we make sure no player is stacking the deck or peeking at other players' cards when we are shuffling the deck ourselves?\". In a physical card game, this would be relatively simple if the players were sitting face to face and observing each other, at least if the possibility of conventional cheating can be ruled out. However, if the players are not sitting at the same location but instead are at widely separate locations and pass the entire deck between them (using the postal mail, for instance), this suddenly becomes very difficult. And for electronic card games, such as online poker, where the mechanics of the game are hidden from the user, this is impossible unless the method used is such that it cannot allow any party to cheat by manipulating or inappropriately observing the electronic \"deck\".\nSeveral protocols for doing this have been suggested, the first by Adi Shamir, Ron Rivest and Len Adleman (the creators of the RSA-encryption protocol). This protocol was the first example of two parties conducting secure computation rather than secure message transmission, employing cryptography; later on due to leaking partial information in the original protocol, this led to the definition of semantic security by Shafi Goldwasser and Silvio Micali. The concept of multi-player mental poker was introduced in Moti Yung's 1984 book Cryptoprotocols. The area has later evolved into what is known as secure multi-party computation protocols (for two parties, and multi parties as well).\n\n\n\n== Shuffling cards using commutative encryption ==\nOne possible algorithm for shuffling cards without the use of a trusted third party is to use a commutative encryption scheme. A commutative scheme means that if some data is encrypted more than once, the order in which one decrypts this data will not matter.\nExample: Alice has a plaintext message. She encrypts this, producing a garbled ciphertext which she gives then to Bob. Bob encrypts the ciphertext again, using the same scheme as Alice but with another key. When decrypting this double encrypted message, if the encryption scheme is commutative, it will not matter who decrypts first.\n\n\n*** The algorithm ***\nAn algorithm for shuffling cards using commutative encryption would be as follows:\n\nAlice and Bob agree on a certain \"deck\" of cards. In practice, this means they agree on a set of numbers or other data such that each element of the set represents a card.\nAlice picks an encryption key A and uses this to encrypt each card of the deck.\nAlice shuffles the cards.\nAlice passes the encrypted and shuffled deck to Bob. With the encryption in place, Bob cannot know which card is which.\nBob picks an encryption key B and uses this to encrypt each card of the encrypted and shuffled deck.\nBob shuffles the deck.\nBob passes the double encrypted and shuffled deck back to Alice.\nAlice decrypts each card using her key A. This still leaves Bob's encryption in place though so she cannot know which card is which.\nAlice picks one encryption key for each card (A1, A2, etc.) and encrypts them individually.\nAlice passes the deck to Bob.\nBob decrypts each card using his key B. This still leaves Alice's individual encryption in place though so he cannot know which card is which.\nBob picks one encryption key for each card (B1, B2, etc.) and encrypts them individually.\nBob passes the deck back to Alice.\nAlice publishes the deck for everyone playing (in this case only Alice and Bob, see below on expansion though).The deck is now shuffled.\nThis algorithm may be expanded for an arbitrary number of players. Players Carol, Dave and so forth need only repeat steps 2-4 and 8-10.\nDuring the game, Alice and Bob will pick cards from the deck, identified in which order they are placed in the shuffled deck. When either player wants to see their cards, they will request the corresponding keys from the other player. That player, upon checking that the requesting player is indeed entitled to look at the cards, passes the individual keys for those cards to the other player. The check is to ensure that the player does not try to request keys for cards that do not belong to that player.\nExample: Alice has picked cards 1 to 5 in the shuffled deck. Bob has picked cards 6 to 10. Bob requests to look at his allotted cards. Alice agrees that Bob is entitled to look at cards 6 to 10 and gives him her individual card keys A6 to A10. Bob decrypts his cards by using both Alice's keys and his own for these cards, B6 to B10. Bob can now see the cards. Alice cannot know which cards Bob has because she does not have access to Bob's keys B6 to B10 which are required to decrypt the cards.\n\n\n*** Weakness ***\nThe encryption scheme used must be secure against known-plaintext attacks: Bob must not be able to determine Alice's original key A (or enough of it to allow him to decrypt any cards he does not hold) based on his knowledge of the unencrypted values of the cards he has drawn. This rules out some obvious commutative encryption schemes, such as simply XORing each card with the key. (Using a separate key for each card even in the initial exchange, which would otherwise make this scheme secure, doesn't work since the cards are shuffled before they're returned.)\nDepending on the deck agreed upon, this algorithm may be weak. When encrypting data, certain properties of this data may be preserved from the plaintext to the ciphertext. This may be used to \"tag\" certain cards. Therefore, the parties must agree on a deck where no cards have properties that are preserved during encryption.\n\n== \"A Toolbox for Mental Card Games\" and its implementation ==\nChristian Schindelhauer describes sophisticated protocols to both perform and verify a large number of useful operations on cards and stacks of cards in his 1998 paper \"A Toolbox for Mental Card Games\" [SCH98]. The work is concerned with general-purpose operations (masking and unmasking cards, shuffling and re-shuffling, inserting a card into a stack, etc.) that make the protocols applicable to any card game. The cryptographic protocols used by Schindelhauer are based on quadratic residuosity, and the general scheme is similar in spirit to the above protocol. The correctness of operations can be checked by using zero-knowledge proofs, so that players do not need to reveal their strategy to verify the game's correctness.\nThe C++ library libtmcg [STA05] provides an implementation of the Schindelhauer toolbox. It has been used to implement a secure version of the German card game Skat, achieving modest real-world performance. The game Skat is played by three players with a 32-card deck, and so is substantially less computationally intensive than a poker game in which anywhere from five to eight players use a full 52-card deck.\n\n== A non-shuffling poker protocol ==\nTo date, mental poker approaches based on the standard Alice-Bob protocol (above) do not offer high enough performance for real-time online play. The requirement that each player encrypts each card imposes a substantial overhead. A recent paper by Golle [GOL05] describes a mental poker protocol that achieves significantly higher performance by exploiting the properties of the poker game to move away from the encrypt-shuffle model. Rather than shuffle the cards and then deal as needed, with the new approach, the players generate (encrypted) random numbers on the fly, which are used to select the next card. Every new card needs to be checked against all the cards that have already been dealt to detect duplicates. As a result, this method is uniquely useful in poker-style games, in which the number of cards dealt is very small compared to the size of the whole deck. However, the method needs all cards that have already been dealt to be known to all, which in most poker-style games would beat its very purpose.\nThe card-generation algorithm requires a cryptosystem with two key properties. The encryption E must be additively homomorphic, so that E(c1)*E(c2)\n\n== Better performance through increased trust ==\nAny mental poker protocol that relies on the players to perform the encryption is bound by the requirement that every player encrypt every card that is dealt. However, by making limited assumptions about the trustworthiness of third parties, significantly more efficient protocols may be realized. The protocol for choosing cards without shuffling may be adapted so that the encryption is handled by two or more servers. Under the assumption that the servers are non-colluding, such a protocol is secure.\nThe basic protocol using two servers is as follows:\n\nServers S1 and S2 encrypt and shuffle a deck of cards, and publish a non-malleable commitment to some permutation of encrypted cards to the players. This can be done with any of several well-understood cryptographic protocols.\nPlayers compute independent random numbers in {0,...,51}, which are combined to generate a random number in {0,..., 51}, as in [GOL05]\nThe random number is used as an index into the random permutation, the appropriate player gains \"ownership\" of the specified card, and the servers send that player the keys to read the card's value.In this protocol, servers S1 and S2 must collude if either is to learn the values of any cards. Furthermore, because players ultimately decide which cards are dealt, non-trustworthy servers are unable to influence the game to the extent that is possible in traditional online poker. The scheme may be extended to allow more servers, (and thus, increased security), simply by including the additional servers in the initial encryption. Finally, step one in the protocol may be done offline, allowing for large numbers of shuffled, encrypted \"decks\" to be pre-computed and cached, resulting in excellent in-game performance."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the term 'privacy-invasive software' differ from malware definitions?",
    "context": "",
    "output": "The term 'privacy-invasive software' focuses on the commercial aspect of unwanted software contamination, emphasizing the threats arising from the free market, advanced technology, and the unbridled exchange of electronic information. This contrasts with most malware definitions, which are based on distribution mechanisms and rarely correspond to motives of business and commerce.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the term 'privacy-invasive software' differ from malware definitions?",
      "answer": "The term 'privacy-invasive software' focuses on the commercial aspect of unwanted software contamination, emphasizing the threats arising from the free market, advanced technology, and the unbridled exchange of electronic information. This contrasts with most malware definitions, which are based on distribution mechanisms and rarely correspond to motives of business and commerce."
    }
  },
  {
    "instruction": "Write an answer to the following question: How can attackers use high-frequency MEMS microphones to read back confidential information from inkjet printers?",
    "context": "",
    "output": "Attackers can use high-frequency MEMS microphones to record the unique acoustic signals from each nozzle in inkjet printers using ultrasonic heads. By analyzing the timing reconstruction of these signals with known printed data, attackers can reconstruct confidential information printed in 12-point font.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can attackers use high-frequency MEMS microphones to read back confidential information from inkjet printers?",
      "answer": "Attackers can use high-frequency MEMS microphones to record the unique acoustic signals from each nozzle in inkjet printers using ultrasonic heads. By analyzing the timing reconstruction of these signals with known printed data, attackers can reconstruct confidential information printed in 12-point font."
    }
  },
  {
    "instruction": "Write an answer to the following question: Which companies have implemented compromised credential checking protocols?",
    "context": "",
    "output": "Multiple websites, services, password managers, and browser extensions, including Google's Password Checkup feature, have implemented compromised credential checking protocols.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Which companies have implemented compromised credential checking protocols?",
      "answer": "Multiple websites, services, password managers, and browser extensions, including Google's Password Checkup feature, have implemented compromised credential checking protocols."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does SAE use the MAC addresses of both peers to solve the authentication problem in the Diffie-Hellman key exchange?",
    "context": "",
    "output": "SAE uses the MAC addresses of both peers to create a pre-shared key, which is then used to influence the resulting key in the Diffie-Hellman key exchange. This ensures that both parties possess the correct mesh password, thereby solving the authentication problem.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does SAE use the MAC addresses of both peers to solve the authentication problem in the Diffie-Hellman key exchange?",
      "answer": "SAE uses the MAC addresses of both peers to create a pre-shared key, which is then used to influence the resulting key in the Diffie-Hellman key exchange. This ensures that both parties possess the correct mesh password, thereby solving the authentication problem."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the main function of the Error detection/correction pattern?",
    "context": "",
    "output": "This pattern deduces errors and corrects them to guarantee correct information exchange or storage.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the main function of the Error detection/correction pattern?",
      "answer": "This pattern deduces errors and corrects them to guarantee correct information exchange or storage."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does domain hiding in domain fronting mislead third parties spying on connections?",
    "context": "",
    "output": "Domain hiding passes an encrypted request for one resource concealed behind an unencrypted (plaintext) request for another resource whose DNS records are hosted in the same cloud. This method misleads third parties spying on the connection, as they can only read the plaintext address and are thus misled as to what resource the requester is connecting to.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does domain hiding in domain fronting mislead third parties spying on connections?",
      "answer": "Domain hiding passes an encrypted request for one resource concealed behind an unencrypted (plaintext) request for another resource whose DNS records are hosted in the same cloud. This method misleads third parties spying on the connection, as they can only read the plaintext address and are thus misled as to what resource the requester is connecting to."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does Samhain protect its configuration from unauthorized modifications?",
    "context": "",
    "output": "Samhain supports tamper resistance, which means its configuration files can be signed to protect from unauthorized modifications.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does Samhain protect its configuration from unauthorized modifications?",
      "answer": "Samhain supports tamper resistance, which means its configuration files can be signed to protect from unauthorized modifications."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the basic implementation of a fork bomb?",
    "context": "",
    "output": "The basic implementation of a fork bomb is an infinite loop that repeatedly launches new copies of itself, leading to exponential growth in processes and resource depletion.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the basic implementation of a fork bomb?",
      "answer": "The basic implementation of a fork bomb is an infinite loop that repeatedly launches new copies of itself, leading to exponential growth in processes and resource depletion."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is TinyLock and how does it mitigate smudge attacks?",
    "context": "",
    "output": "TinyLock is an authentication scheme that provides ways to cover up the smudges using a stroking method. It uses two grids: the top one is for the pressed cells for the confirmation process, and the bottom one is a drawing pad for the authentication process. The bottom half of the screen contains a tiny 3 x 3 grid used for drawing the secret password. This method forces the user to draw in a confined space, which mitigates smudge attacks by smushing all the smudges together.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is TinyLock and how does it mitigate smudge attacks?",
      "answer": "TinyLock is an authentication scheme that provides ways to cover up the smudges using a stroking method. It uses two grids: the top one is for the pressed cells for the confirmation process, and the bottom one is a drawing pad for the authentication process. The bottom half of the screen contains a tiny 3 x 3 grid used for drawing the secret password. This method forces the user to draw in a confined space, which mitigates smudge attacks by smushing all the smudges together."
    }
  },
  {
    "instruction": "Write an answer to the following question: How many offices did Guidance Software have globally before it was acquired by OpenText?",
    "context": "",
    "output": "Guidance Software had 9 offices globally before it was acquired by OpenText.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How many offices did Guidance Software have globally before it was acquired by OpenText?",
      "answer": "Guidance Software had 9 offices globally before it was acquired by OpenText."
    }
  },
  {
    "instruction": "Related-key attack\n\n==Introduction==\nIn cryptography, a related-key attack is any form of cryptanalysis where the attacker can observe the operation of a cipher under several different keys whose values are initially unknown, but where some mathematical relationship connecting the keys is known to the attacker. For example, the attacker might know that the last 80 bits of the keys are always the same, even though they don't know, at first, what the bits are. This appears, at first glance, to be an unrealistic model; it would certainly be unlikely that an attacker could persuade a human cryptographer to encrypt plaintexts under numerous secret keys related in some way.\n\n\n\n== KASUMI ==\nKASUMI is an eight round, 64-bit block cipher with a 128-bit key. It is based upon MISTY1, and was designed to form the basis of the 3G confidentiality and integrity algorithms.\nMark Blunden and Adrian Escott described differential related key attacks on five and six rounds of KASUMI. Differential attacks were introduced by Biham and Shamir. Related key attacks were first introduced by Biham. Differential related key attacks are discussed in Kelsey et al.\n\n== WEP ==\nAn important example of a cryptographic protocol that failed because of a related-key attack is Wired Equivalent Privacy (WEP) used in Wi-Fi wireless networks.  Each client Wi-Fi network adapter and wireless access point in a WEP-protected network shares the same WEP key. Encryption uses the RC4 algorithm, a stream cipher. It is essential that the same key never be used twice with a stream cipher. To prevent this from happening, WEP includes a 24-bit initialization vector (IV) in each message packet. The RC4 key for that packet is the IV concatenated with the WEP key. WEP keys have to be changed manually and this typically happens infrequently. An attacker therefore can assume that all the keys used to encrypt packets share a single WEP key. This fact opened up WEP to a series of attacks which proved devastating. The simplest to understand uses the fact that the 24-bit IV only allows a little under 17 million possibilities. Because of the birthday paradox, it is likely that for every 4096 packets, two will share the same IV and hence the same RC4 key, allowing the packets to be attacked. More devastating attacks take advantage of certain weak keys in RC4 and eventually allow the WEP key itself to be recovered. In 2005, agents from the U.S. Federal Bureau of Investigation publicly demonstrated the ability to do this with widely available software tools in about three minutes.\n\n== Preventing related-key attacks ==\nOne approach to preventing related-key attacks is to design protocols and applications so that encryption keys will never have a simple relationship with each other.  For example, each encryption key can be generated from the underlying key material using a key derivation function.\nFor example, a replacement for WEP, Wi-Fi Protected Access (WPA), uses three levels of keys: master key, working key and RC4 key. The master WPA key is shared with each client and access point and is used in a protocol called Temporal Key Integrity Protocol (TKIP) to create new working keys frequently enough to thwart known attack methods. The working keys are then combined with a longer, 48-bit IV to form the RC4 key for each packet.  This design mimics the WEP approach enough to allow WPA to be used with first-generation Wi-Fi network cards, some of which implemented portions of WEP in hardware. However, not all first-generation access points can run WPA.\nAnother, more conservative approach is to employ a cipher designed to prevent related-key attacks altogether, usually by incorporating a strong key schedule. A newer version of Wi-Fi Protected Access, WPA2, uses the AES block cipher instead of RC4, in part for this reason. There are related-key attacks against AES, but unlike those against RC4, they're far from practical to implement, and WPA2's key generation functions may provide some security against them.  Many older network cards cannot run WPA2.\n\nWhat is the birthday paradox and how does it apply to WEP?",
    "context": "",
    "output": "A: The birthday paradox is a statistical principle which states that for any set of 24-bit numbers, there's a high probability that two of them will be the same. In WEP, this means that for every 4096 packets, two will likely share the same IV and hence the same RC4 key, allowing the packets to be attacked.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the birthday paradox and how does it apply to WEP?",
      "answer": "The birthday paradox is a statistical principle which states that for any set of 24-bit numbers, there's a high probability that two of them will be the same. In WEP, this means that for every 4096 packets, two will likely share the same IV and hence the same RC4 key, allowing the packets to be attacked.",
      "context": "Related-key attack\n\n==Introduction==\nIn cryptography, a related-key attack is any form of cryptanalysis where the attacker can observe the operation of a cipher under several different keys whose values are initially unknown, but where some mathematical relationship connecting the keys is known to the attacker. For example, the attacker might know that the last 80 bits of the keys are always the same, even though they don't know, at first, what the bits are. This appears, at first glance, to be an unrealistic model; it would certainly be unlikely that an attacker could persuade a human cryptographer to encrypt plaintexts under numerous secret keys related in some way.\n\n\n\n== KASUMI ==\nKASUMI is an eight round, 64-bit block cipher with a 128-bit key. It is based upon MISTY1, and was designed to form the basis of the 3G confidentiality and integrity algorithms.\nMark Blunden and Adrian Escott described differential related key attacks on five and six rounds of KASUMI. Differential attacks were introduced by Biham and Shamir. Related key attacks were first introduced by Biham. Differential related key attacks are discussed in Kelsey et al.\n\n== WEP ==\nAn important example of a cryptographic protocol that failed because of a related-key attack is Wired Equivalent Privacy (WEP) used in Wi-Fi wireless networks.  Each client Wi-Fi network adapter and wireless access point in a WEP-protected network shares the same WEP key. Encryption uses the RC4 algorithm, a stream cipher. It is essential that the same key never be used twice with a stream cipher. To prevent this from happening, WEP includes a 24-bit initialization vector (IV) in each message packet. The RC4 key for that packet is the IV concatenated with the WEP key. WEP keys have to be changed manually and this typically happens infrequently. An attacker therefore can assume that all the keys used to encrypt packets share a single WEP key. This fact opened up WEP to a series of attacks which proved devastating. The simplest to understand uses the fact that the 24-bit IV only allows a little under 17 million possibilities. Because of the birthday paradox, it is likely that for every 4096 packets, two will share the same IV and hence the same RC4 key, allowing the packets to be attacked. More devastating attacks take advantage of certain weak keys in RC4 and eventually allow the WEP key itself to be recovered. In 2005, agents from the U.S. Federal Bureau of Investigation publicly demonstrated the ability to do this with widely available software tools in about three minutes.\n\n== Preventing related-key attacks ==\nOne approach to preventing related-key attacks is to design protocols and applications so that encryption keys will never have a simple relationship with each other.  For example, each encryption key can be generated from the underlying key material using a key derivation function.\nFor example, a replacement for WEP, Wi-Fi Protected Access (WPA), uses three levels of keys: master key, working key and RC4 key. The master WPA key is shared with each client and access point and is used in a protocol called Temporal Key Integrity Protocol (TKIP) to create new working keys frequently enough to thwart known attack methods. The working keys are then combined with a longer, 48-bit IV to form the RC4 key for each packet.  This design mimics the WEP approach enough to allow WPA to be used with first-generation Wi-Fi network cards, some of which implemented portions of WEP in hardware. However, not all first-generation access points can run WPA.\nAnother, more conservative approach is to employ a cipher designed to prevent related-key attacks altogether, usually by incorporating a strong key schedule. A newer version of Wi-Fi Protected Access, WPA2, uses the AES block cipher instead of RC4, in part for this reason. There are related-key attacks against AES, but unlike those against RC4, they're far from practical to implement, and WPA2's key generation functions may provide some security against them.  Many older network cards cannot run WPA2."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the purpose of using CBC-MAC in CCMP?",
    "context": "",
    "output": "The purpose of using CBC-MAC in CCMP is to ensure data integrity and authentication by generating a unique MAC value for each message.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the purpose of using CBC-MAC in CCMP?",
      "answer": "The purpose of using CBC-MAC in CCMP is to ensure data integrity and authentication by generating a unique MAC value for each message."
    }
  },
  {
    "instruction": "Privacy-preserving computational geometry\n\n==Introduction==\nPrivacy-preserving computational geometry is the research area on the intersection of the domains of secure multi-party computation (SMC) and computational geometry. Classical problems of computational geometry reconsidered from the point of view of SMC include shape intersection, private point inclusion problem, range searching, convex hull, and more.A pioneering work in this area was a 2001 paper by Atallah and Du, in which the secure point in polygon inclusion and polygonal intersection problems were considered.\nOther problems are computation of the distance between two private points and secure two-party point-circle inclusion problem.\n\n\n\n== Problem statements ==\nThe problems use the conventional \"Alice and Bob\" terminology. In all problems the required solution is a protocol of information exchange during which no additional information is revealed beyond what may be inferred from the answer to the required question.\n\nPoint-in-polygon:  Alice has a point a, and Bob has a polygon B. They need to determine whether a is inside B.\nPolygon pair intersection: Alice has a polygon A, and Bob has a polygon B. They need to determine whether A intersects B.\n\nWhat is the definition of a point in privacy-preserving computational geometry?",
    "context": "",
    "output": "In privacy-preserving computational geometry, a point is a location in space, represented by its coordinates, which can be used to define the position of an object or the location of a feature.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the definition of a point in privacy-preserving computational geometry?",
      "answer": "In privacy-preserving computational geometry, a point is a location in space, represented by its coordinates, which can be used to define the position of an object or the location of a feature.",
      "context": "Privacy-preserving computational geometry\n\n==Introduction==\nPrivacy-preserving computational geometry is the research area on the intersection of the domains of secure multi-party computation (SMC) and computational geometry. Classical problems of computational geometry reconsidered from the point of view of SMC include shape intersection, private point inclusion problem, range searching, convex hull, and more.A pioneering work in this area was a 2001 paper by Atallah and Du, in which the secure point in polygon inclusion and polygonal intersection problems were considered.\nOther problems are computation of the distance between two private points and secure two-party point-circle inclusion problem.\n\n\n\n== Problem statements ==\nThe problems use the conventional \"Alice and Bob\" terminology. In all problems the required solution is a protocol of information exchange during which no additional information is revealed beyond what may be inferred from the answer to the required question.\n\nPoint-in-polygon:  Alice has a point a, and Bob has a polygon B. They need to determine whether a is inside B.\nPolygon pair intersection: Alice has a polygon A, and Bob has a polygon B. They need to determine whether A intersects B."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the role of a SASL profile in an application protocol?",
    "context": "",
    "output": "A SASL profile defines the representation of SASL exchanges in an application protocol.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of a SASL profile in an application protocol?",
      "answer": "A SASL profile defines the representation of SASL exchanges in an application protocol."
    }
  },
  {
    "instruction": "Zip bomb\n\n==Introduction==\nIn computing, a zip bomb, also known as a decompression bomb or zip of death, is a malicious archive file designed to crash or render useless the program  or system reading it. It is often employed to disable antivirus software, in order to create an opening for more traditional malware.A zip bomb allows a program to function normally, but, instead of hijacking the program's operation, creates an archive that requires an excessive amount of time, disk space, or memory to unpack.Most modern antivirus programs can detect whether a file is a zip bomb in order to avoid unpacking it.\n\n== Details and use ==\nA zip bomb is usually a small file for ease of transport and to avoid suspicion. However, when the file is unpacked, its contents are more than the system can handle.\nOne example of a zip bomb is the file 42.zip, which is a zip file consisting of 42 kilobytes of compressed data, containing five layers of nested zip files in sets of 16, each bottom-layer archive containing a 4.3-gigabyte (4294967295 bytes; 4 GiB \u2212 1 B) file for a total of 4.5 petabytes (4503599626321920 bytes; 4 PiB \u2212 1 MiB) of uncompressed data. This zip bomb is freely available for download online. In many anti-virus scanners, only a few layers of recursion are performed on archives to help prevent attacks that would cause a buffer overflow, an out-of-memory condition, or exceed an acceptable amount of program execution time.\nZip bombs often rely on repetition of identical files to achieve their extreme compression ratios. Dynamic programming methods can be employed to limit traversal of such files, so that only one file is followed recursively at each level, effectively converting their exponential growth to linear.\nThere are also zip files that, when uncompressed, yield identical copies of themselves. A sophisticated form of zip bomb exploits the specifications of zip files and the Deflate compression algorithm to create bombs without the use of nested layers as used in 42.zip.\n\nQ: How do sophisticated zip bombs exploit the specifications of zip files and the Deflate compression algorithm?",
    "context": "",
    "output": "A: Sophisticated zip bombs exploit the specifications of zip files and the Deflate compression algorithm by using specific techniques to create bombs without the use of nested layers. This makes it more difficult for antivirus software to detect and limit their impact.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do sophisticated zip bombs exploit the specifications of zip files and the Deflate compression algorithm?",
      "answer": "Sophisticated zip bombs exploit the specifications of zip files and the Deflate compression algorithm by using specific techniques to create bombs without the use of nested layers. This makes it more difficult for antivirus software to detect and limit their impact.",
      "context": "Zip bomb\n\n==Introduction==\nIn computing, a zip bomb, also known as a decompression bomb or zip of death, is a malicious archive file designed to crash or render useless the program  or system reading it. It is often employed to disable antivirus software, in order to create an opening for more traditional malware.A zip bomb allows a program to function normally, but, instead of hijacking the program's operation, creates an archive that requires an excessive amount of time, disk space, or memory to unpack.Most modern antivirus programs can detect whether a file is a zip bomb in order to avoid unpacking it.\n\n== Details and use ==\nA zip bomb is usually a small file for ease of transport and to avoid suspicion. However, when the file is unpacked, its contents are more than the system can handle.\nOne example of a zip bomb is the file 42.zip, which is a zip file consisting of 42 kilobytes of compressed data, containing five layers of nested zip files in sets of 16, each bottom-layer archive containing a 4.3-gigabyte (4294967295 bytes; 4 GiB \u2212 1 B) file for a total of 4.5 petabytes (4503599626321920 bytes; 4 PiB \u2212 1 MiB) of uncompressed data. This zip bomb is freely available for download online. In many anti-virus scanners, only a few layers of recursion are performed on archives to help prevent attacks that would cause a buffer overflow, an out-of-memory condition, or exceed an acceptable amount of program execution time.\nZip bombs often rely on repetition of identical files to achieve their extreme compression ratios. Dynamic programming methods can be employed to limit traversal of such files, so that only one file is followed recursively at each level, effectively converting their exponential growth to linear.\nThere are also zip files that, when uncompressed, yield identical copies of themselves. A sophisticated form of zip bomb exploits the specifications of zip files and the Deflate compression algorithm to create bombs without the use of nested layers as used in 42.zip."
    }
  },
  {
    "instruction": "Write an answer to the following question: What special focus does BuggedPlanet.info place on vendors?",
    "context": "",
    "output": "BuggedPlanet.info places a special focus on vendors that sell surveillance technologies to undemocratic countries and related lobbying efforts.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What special focus does BuggedPlanet.info place on vendors?",
      "answer": "BuggedPlanet.info places a special focus on vendors that sell surveillance technologies to undemocratic countries and related lobbying efforts."
    }
  },
  {
    "instruction": "OAuth\n\n==Introduction==\nOAuth (short for \"Open Authorization\") is an open standard for access delegation, commonly used as a way for internet users to grant websites or applications access to their information on other websites but without giving them the passwords. This mechanism is used by companies such as Amazon, Google, Facebook, Microsoft, and Twitter to permit users to share information about their accounts with third-party applications or websites.\nGenerally, the OAuth protocol provides a way for resource owners to provide a client [application] with secure delegated access to server resources. It specifies a process for resource owners to authorize third-party access to their server resources without providing credentials. Designed specifically to work with Hypertext Transfer Protocol (HTTP), OAuth essentially allows access tokens to be issued to third-party clients by an authorization server, with the approval of the resource owner. The third party then uses the access token to access the protected resources hosted by the resource server.\n\n== Security issues ==\n\n\n*** OAuth 1.0 ***\nOn 23 April 2009, a session fixation security flaw in the 1.0 protocol was announced. It affects the OAuth authorization flow (also known as \"3-legged OAuth\") in OAuth Core 1.0 Section 6.\nVersion 1.0a of the OAuth Core protocol was issued to address this issue.\n\n\n*** OAuth 2.0 ***\nIn January 2013, the Internet Engineering Task Force published a threat model for OAuth 2.0. Among the threats outlined is one called \"Open Redirector\"; in early 2014, a variant of this was described under the name \"Covert Redirect\" by Wang Jing.OAuth 2.0 has been analyzed using formal web protocol analysis. This analysis revealed that in setups with multiple authorization servers, one of which is behaving maliciously, clients can become confused about the authorization server to use and may forward secrets to the malicious authorization server (AS Mix-Up Attack). This prompted the creation of a new best current practice internet draft that sets out to define a new security standard for OAuth 2.0. Assuming a fix against the AS Mix-Up Attack in place, the security of OAuth 2.0 has been proven under strong attacker models using formal analysis.One implementation of OAuth 2.0 with numerous security flaws has been exposed.In April and May 2017, about one million users of Gmail (less than 0.1% of users as of May 2017) were targeted by an OAuth-based phishing attack, receiving an email purporting to be from a colleague, employer or friend wanting to share a document on Google Docs. Those who clicked on the link within the email were directed to sign in and allow a potentially malicious third-party program called \"Google Apps\" to access their \"email account, contacts and online documents\". Within \"approximately one hour\", the phishing attack was stopped by Google, who advised those who had given \"Google Apps\" access to their email to revoke such access and change their passwords.\nIn the draft of OAuth 2.1 the use of the PKCE extension for native apps has been recommended to all kinds of OAuth clients, including web applications and other confidential clients in order to avoid malicious browser extensions to perform OAuth 2.0 code injection attack.\n\n== Uses ==\nFacebook's Graph API only supports OAuth 2.0. Google supports OAuth 2.0 as the recommended authorization mechanism for all of its APIs. Microsoft also supports OAuth 2.0 for various APIs and its Azure Active Directory service, which is used to secure many Microsoft and third party APIs.\nOAuth can be used as an authorizing mechanism to access secured RSS/Atom feeds. Access to RSS/ATOM feeds that require authentication has always been an issue. For example, an RSS feed from a secured Google Site could not have been accessed using Google Reader. Instead, three-legged OAuth would have been used to authorize that RSS client to access the feed from the Google Site.\n\n== OAuth and other standards ==\nOAuth is a service that is complementary to and distinct from OpenID. OAuth is unrelated to OATH, which is a reference architecture for authentication, not a standard for authorization. However, OAuth is directly related to OpenID Connect (OIDC), since OIDC is an authentication layer built on top of OAuth 2.0. OAuth is also unrelated to XACML, which is an authorization policy standard. OAuth can be used in conjunction with XACML, where OAuth is used for ownership consent and access delegation whereas XACML is used to define the authorization policies (e.g., managers can view documents in their region).\n\n\n*** OpenID vis-\u00e0-vis pseudo-authentication using OAuth ***\nOAuth is an authorization protocol, rather than an authentication protocol. Using OAuth on its own as an authentication method may be referred to as pseudo-authentication. The following diagrams highlight the differences between using OpenID (specifically designed as an authentication protocol) and OAuth for authorization.\nThe communication flow in both processes is similar:\n\n(Not pictured) The user requests a resource or site login from the application.\nThe site sees that the user is not authenticated. It formulates a request for the identity provider, encodes it, and sends it to the user as part of a redirect URL.\nThe user's browser makes a request to the redirect URL for the identity provider, including the application's request\nIf necessary, the identity provider authenticates the user (perhaps by asking them for their username and password)\nOnce the identity provider is satisfied that the user is sufficiently authenticated, it processes the application's request, formulates a response, and sends that back to the user along with a redirect URL back to the application.\nThe user's browser requests the redirect URL that goes back to the application, including the identity provider's response\nThe application decodes the identity provider's response, and carries on accordingly.\n(OAuth only) The response includes an access token which the application can use to gain direct access to the identity provider's services on the user's behalf.The crucial difference is that in the OpenID authentication use case, the response from the identity provider is an assertion of identity; while in the OAuth authorization use case, the identity provider is also an API provider, and the response from the identity provider is an access token that may grant the application ongoing access to some of the identity provider's APIs, on the user's behalf. The access token acts as a kind of \"valet key\" that the application can include with its requests to the identity provider, which prove that it has permission from the user to access those APIs.\nBecause the identity provider typically (but not always) authenticates the user as part of the process of granting an OAuth access token, it is tempting to view a successful OAuth access token request as an authentication method itself. However, because OAuth was not designed with this use case in mind, making this assumption can lead to major security flaws.\n\n\n*** OAuth and XACML ***\nXACML is a policy-based, attribute-based access control authorization framework. It provides:\n\nAn access control architecture.\nA policy language with which to express a wide range of access control policies including policies that can use consents handled / defined via OAuth.\nA request / response scheme to send and receive authorization requests.XACML and OAuth can be combined to deliver a more comprehensive approach to authorization. OAuth does not provide a policy language with which to define access control policies. XACML can be used for its policy language.\nWhere OAuth focuses on delegated access (I, the user, grant Twitter access to my Facebook wall), and identity-centric authorization, XACML takes an attribute-based approach which can consider attributes of the user, the action, the resource, and the context (who, what, where, when, how). With XACML it is possible to define policies such as\n\nManagers can view documents in their department\nManagers can edit documents they own in draft modeXACML provides more fine-grained access control than OAuth does. OAuth is limited in granularity to the coarse functionality (the scopes) exposed by the target service. As a result, it often makes sense to combine OAuth and XACML together where OAuth will provide the delegated access use case and consent management and XACML will provide the authorization policies that work on the applications, processes, and data.\nLastly, XACML can work transparently across multiple stacks (APIs, web SSO, ESBs, home-grown apps, databases...). OAuth focuses exclusively on HTTP-based apps.\n\n== Controversy ==\nEran Hammer resigned from his role of lead author for the OAuth 2.0 project, withdrew from the IETF working group, and removed his name from the specification in July 2012. Hammer cited a conflict between web and enterprise cultures as his reason for leaving, noting that IETF is a community that is \"all about enterprise use cases\" and \"not capable of simple\". \"What is now offered is a blueprint for an authorization protocol\", he noted, \"that is the enterprise way\", providing a \"whole new frontier to sell consulting services and integration solutions\". In comparing OAuth 2.0 with OAuth 1.0, Hammer points out that it has become \"more complex, less interoperable, less useful, more incomplete, and most importantly, less secure\". He explains how architectural changes for 2.0 unbound tokens from clients, removed all signatures and cryptography at a protocol level and added expiring tokens (because tokens could not be revoked) while complicating the processing of authorization. Numerous items were left unspecified or unlimited in the specification because \"as has been the nature of this working group, no issue is too small to get stuck on or leave open for each implementation to decide.\"David Recordon later also removed his name from the specifications for unspecified reasons. Dick Hardt took over the editor role, and the framework was published in October 2012.David Harris, author of the email client Pegasus Mail, has criticised OAuth 2.0 as \"an absolute dog's breakfast\", requiring developers to write custom modules specific to each service (Gmail, Microsoft Mail services, etc.), and to register specifically with them.\n\nWhat are the criticisms of OAuth 2.0 by David Harris, author of the email client Pegasus Mail?",
    "context": "",
    "output": "A: David Harris, author of the email client Pegasus Mail, has criticized OAuth 2.0 as an absolute dog's breakfast, requiring developers to write custom modules specific to each service and to register specifically with them.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are the criticisms of OAuth 2.0 by David Harris, author of the email client Pegasus Mail?",
      "answer": "David Harris, author of the email client Pegasus Mail, has criticized OAuth 2.0 as an absolute dog's breakfast, requiring developers to write custom modules specific to each service and to register specifically with them.",
      "context": "OAuth\n\n==Introduction==\nOAuth (short for \"Open Authorization\") is an open standard for access delegation, commonly used as a way for internet users to grant websites or applications access to their information on other websites but without giving them the passwords. This mechanism is used by companies such as Amazon, Google, Facebook, Microsoft, and Twitter to permit users to share information about their accounts with third-party applications or websites.\nGenerally, the OAuth protocol provides a way for resource owners to provide a client [application] with secure delegated access to server resources. It specifies a process for resource owners to authorize third-party access to their server resources without providing credentials. Designed specifically to work with Hypertext Transfer Protocol (HTTP), OAuth essentially allows access tokens to be issued to third-party clients by an authorization server, with the approval of the resource owner. The third party then uses the access token to access the protected resources hosted by the resource server.\n\n== Security issues ==\n\n\n*** OAuth 1.0 ***\nOn 23 April 2009, a session fixation security flaw in the 1.0 protocol was announced. It affects the OAuth authorization flow (also known as \"3-legged OAuth\") in OAuth Core 1.0 Section 6.\nVersion 1.0a of the OAuth Core protocol was issued to address this issue.\n\n\n*** OAuth 2.0 ***\nIn January 2013, the Internet Engineering Task Force published a threat model for OAuth 2.0. Among the threats outlined is one called \"Open Redirector\"; in early 2014, a variant of this was described under the name \"Covert Redirect\" by Wang Jing.OAuth 2.0 has been analyzed using formal web protocol analysis. This analysis revealed that in setups with multiple authorization servers, one of which is behaving maliciously, clients can become confused about the authorization server to use and may forward secrets to the malicious authorization server (AS Mix-Up Attack). This prompted the creation of a new best current practice internet draft that sets out to define a new security standard for OAuth 2.0. Assuming a fix against the AS Mix-Up Attack in place, the security of OAuth 2.0 has been proven under strong attacker models using formal analysis.One implementation of OAuth 2.0 with numerous security flaws has been exposed.In April and May 2017, about one million users of Gmail (less than 0.1% of users as of May 2017) were targeted by an OAuth-based phishing attack, receiving an email purporting to be from a colleague, employer or friend wanting to share a document on Google Docs. Those who clicked on the link within the email were directed to sign in and allow a potentially malicious third-party program called \"Google Apps\" to access their \"email account, contacts and online documents\". Within \"approximately one hour\", the phishing attack was stopped by Google, who advised those who had given \"Google Apps\" access to their email to revoke such access and change their passwords.\nIn the draft of OAuth 2.1 the use of the PKCE extension for native apps has been recommended to all kinds of OAuth clients, including web applications and other confidential clients in order to avoid malicious browser extensions to perform OAuth 2.0 code injection attack.\n\n== Uses ==\nFacebook's Graph API only supports OAuth 2.0. Google supports OAuth 2.0 as the recommended authorization mechanism for all of its APIs. Microsoft also supports OAuth 2.0 for various APIs and its Azure Active Directory service, which is used to secure many Microsoft and third party APIs.\nOAuth can be used as an authorizing mechanism to access secured RSS/Atom feeds. Access to RSS/ATOM feeds that require authentication has always been an issue. For example, an RSS feed from a secured Google Site could not have been accessed using Google Reader. Instead, three-legged OAuth would have been used to authorize that RSS client to access the feed from the Google Site.\n\n== OAuth and other standards ==\nOAuth is a service that is complementary to and distinct from OpenID. OAuth is unrelated to OATH, which is a reference architecture for authentication, not a standard for authorization. However, OAuth is directly related to OpenID Connect (OIDC), since OIDC is an authentication layer built on top of OAuth 2.0. OAuth is also unrelated to XACML, which is an authorization policy standard. OAuth can be used in conjunction with XACML, where OAuth is used for ownership consent and access delegation whereas XACML is used to define the authorization policies (e.g., managers can view documents in their region).\n\n\n*** OpenID vis-\u00e0-vis pseudo-authentication using OAuth ***\nOAuth is an authorization protocol, rather than an authentication protocol. Using OAuth on its own as an authentication method may be referred to as pseudo-authentication. The following diagrams highlight the differences between using OpenID (specifically designed as an authentication protocol) and OAuth for authorization.\nThe communication flow in both processes is similar:\n\n(Not pictured) The user requests a resource or site login from the application.\nThe site sees that the user is not authenticated. It formulates a request for the identity provider, encodes it, and sends it to the user as part of a redirect URL.\nThe user's browser makes a request to the redirect URL for the identity provider, including the application's request\nIf necessary, the identity provider authenticates the user (perhaps by asking them for their username and password)\nOnce the identity provider is satisfied that the user is sufficiently authenticated, it processes the application's request, formulates a response, and sends that back to the user along with a redirect URL back to the application.\nThe user's browser requests the redirect URL that goes back to the application, including the identity provider's response\nThe application decodes the identity provider's response, and carries on accordingly.\n(OAuth only) The response includes an access token which the application can use to gain direct access to the identity provider's services on the user's behalf.The crucial difference is that in the OpenID authentication use case, the response from the identity provider is an assertion of identity; while in the OAuth authorization use case, the identity provider is also an API provider, and the response from the identity provider is an access token that may grant the application ongoing access to some of the identity provider's APIs, on the user's behalf. The access token acts as a kind of \"valet key\" that the application can include with its requests to the identity provider, which prove that it has permission from the user to access those APIs.\nBecause the identity provider typically (but not always) authenticates the user as part of the process of granting an OAuth access token, it is tempting to view a successful OAuth access token request as an authentication method itself. However, because OAuth was not designed with this use case in mind, making this assumption can lead to major security flaws.\n\n\n*** OAuth and XACML ***\nXACML is a policy-based, attribute-based access control authorization framework. It provides:\n\nAn access control architecture.\nA policy language with which to express a wide range of access control policies including policies that can use consents handled / defined via OAuth.\nA request / response scheme to send and receive authorization requests.XACML and OAuth can be combined to deliver a more comprehensive approach to authorization. OAuth does not provide a policy language with which to define access control policies. XACML can be used for its policy language.\nWhere OAuth focuses on delegated access (I, the user, grant Twitter access to my Facebook wall), and identity-centric authorization, XACML takes an attribute-based approach which can consider attributes of the user, the action, the resource, and the context (who, what, where, when, how). With XACML it is possible to define policies such as\n\nManagers can view documents in their department\nManagers can edit documents they own in draft modeXACML provides more fine-grained access control than OAuth does. OAuth is limited in granularity to the coarse functionality (the scopes) exposed by the target service. As a result, it often makes sense to combine OAuth and XACML together where OAuth will provide the delegated access use case and consent management and XACML will provide the authorization policies that work on the applications, processes, and data.\nLastly, XACML can work transparently across multiple stacks (APIs, web SSO, ESBs, home-grown apps, databases...). OAuth focuses exclusively on HTTP-based apps.\n\n== Controversy ==\nEran Hammer resigned from his role of lead author for the OAuth 2.0 project, withdrew from the IETF working group, and removed his name from the specification in July 2012. Hammer cited a conflict between web and enterprise cultures as his reason for leaving, noting that IETF is a community that is \"all about enterprise use cases\" and \"not capable of simple\". \"What is now offered is a blueprint for an authorization protocol\", he noted, \"that is the enterprise way\", providing a \"whole new frontier to sell consulting services and integration solutions\". In comparing OAuth 2.0 with OAuth 1.0, Hammer points out that it has become \"more complex, less interoperable, less useful, more incomplete, and most importantly, less secure\". He explains how architectural changes for 2.0 unbound tokens from clients, removed all signatures and cryptography at a protocol level and added expiring tokens (because tokens could not be revoked) while complicating the processing of authorization. Numerous items were left unspecified or unlimited in the specification because \"as has been the nature of this working group, no issue is too small to get stuck on or leave open for each implementation to decide.\"David Recordon later also removed his name from the specifications for unspecified reasons. Dick Hardt took over the editor role, and the framework was published in October 2012.David Harris, author of the email client Pegasus Mail, has criticised OAuth 2.0 as \"an absolute dog's breakfast\", requiring developers to write custom modules specific to each service (Gmail, Microsoft Mail services, etc.), and to register specifically with them."
    }
  },
  {
    "instruction": "Operation Cyberstorm\n\n==Introduction==\nOperation Cyberstorm was a two-year undercover operation in the United States by the Federal Bureau of Investigation (FBI), against illegal copying of software.  At the time, it was the largest sweep ever conducted by the FBI against illegal copying.\n\n\n\n== Investigations ==\nA number of individuals purchased software at discounts, and resold them at a profit  in violation of their software license.\n\n== Convictions ==\nMirza Ali, 60, of Fremont, California and Sameena Ali, 53, also of Fremont, were sentenced in 2007 to 60 months imprisonment, and forfeiture in the amount of $5,105,977. Keith Griffen, 56, of Oregon City, Oregon, was sentenced to 33 months of imprisonment, restitution to Microsoft Corporation in the amount of $20,000,000, three years of supervised release, and $900 in special assessments. William Glushenko, 66, was sentenced to one year of probation and 100 hours of community service after pleading guilty to misprision of felony.\n\nWhat was the penalty faced by William Glushenko in terms of imprisonment?",
    "context": "",
    "output": "William Glushenko was sentenced to one year of probation and did not face imprisonment.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was the penalty faced by William Glushenko in terms of imprisonment?",
      "answer": "William Glushenko was sentenced to one year of probation and did not face imprisonment.",
      "context": "Operation Cyberstorm\n\n==Introduction==\nOperation Cyberstorm was a two-year undercover operation in the United States by the Federal Bureau of Investigation (FBI), against illegal copying of software.  At the time, it was the largest sweep ever conducted by the FBI against illegal copying.\n\n\n\n== Investigations ==\nA number of individuals purchased software at discounts, and resold them at a profit  in violation of their software license.\n\n== Convictions ==\nMirza Ali, 60, of Fremont, California and Sameena Ali, 53, also of Fremont, were sentenced in 2007 to 60 months imprisonment, and forfeiture in the amount of $5,105,977. Keith Griffen, 56, of Oregon City, Oregon, was sentenced to 33 months of imprisonment, restitution to Microsoft Corporation in the amount of $20,000,000, three years of supervised release, and $900 in special assessments. William Glushenko, 66, was sentenced to one year of probation and 100 hours of community service after pleading guilty to misprision of felony."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are the complexities of single database computationally private PIR and k-database (information theoretic) PIR in terms of communication?",
    "context": "",
    "output": "Single database computationally private PIR can be achieved with constant (amortized) communication, while k-database information theoretic PIR can be done with n^(O((log log k)/(k log k))).",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are the complexities of single database computationally private PIR and k-database (information theoretic) PIR in terms of communication?",
      "answer": "Single database computationally private PIR can be achieved with constant (amortized) communication, while k-database information theoretic PIR can be done with n^(O((log log k)/(k log k)))."
    }
  },
  {
    "instruction": "Content Security Policy\n\n==Introduction==\nContent Security Policy (CSP) is a computer security standard introduced to prevent cross-site scripting (XSS), clickjacking and other code injection  attacks resulting from execution of malicious content in the trusted web page context. It is a Candidate Recommendation of the W3C working group on Web Application Security, widely supported by modern web browsers. CSP provides a standard method for website owners to declare approved origins of content that browsers should be allowed to load on that website\u2014covered types are JavaScript, CSS, HTML frames, web workers, fonts, images, embeddable objects such as Java applets, ActiveX, audio and video files, and other HTML5 features.\n\n== Status ==\nThe standard, originally named Content Restrictions, was proposed by Robert Hansen in 2004, first implemented in Firefox 4 and quickly picked up by other browsers. Version 1 of the standard was published in 2012 as W3C candidate recommendation and quickly with further versions (Level 2) published in 2014. As of 2023, the draft of Level 3 is being developed with the new features being quickly adopted by the web browsers.The following header names are in use as part of experimental CSP implementations:\nContent-Security-Policy \u2013 standard header name proposed by the W3C document. Google Chrome supports this as of version 25. Firefox supports this as of version 23, released on 6 August 2013. WebKit supports this as of version 528 (nightly build). Chromium-based Microsoft Edge support is similar to Chrome's.\nX-WebKit-CSP \u2013 deprecated, experimental header introduced into Google Chrome, Safari and other WebKit-based web browsers in 2011.\nX-Content-Security-Policy \u2013 deprecated, experimental header introduced in Gecko 2 based browsers (Firefox 4 to Firefox 22,  Thunderbird 3.3,  SeaMonkey 2.1).A website can declare multiple CSP headers, also mixing enforcement and report-only ones. Each header will be processed separately by the browser.\nCSP can also be delivered within the HTML code using a HTML META tag, although in this case its effectiveness will be limited.Internet Explorer 10 and Internet Explorer 11 also support CSP, but only sandbox directive, using the experimental X-Content-Security-Policy header.A number of web application frameworks support CSP, for example AngularJS (natively) and Django (middleware). Instructions for Ruby on Rails have been posted by GitHub. Web framework support is however only required if the CSP contents somehow depend on the web application's state\u2014such as usage of the nonce origin. Otherwise, the CSP is rather static and can be delivered from web application tiers above the application, for example on load balancer or web server.\n\n\n*** Bypasses ***\nIn December 2015  and December 2016, a few methods of bypassing 'nonce' allowlisting origins were published. In January 2016, another method was published, which leverages server-wide CSP allowlisting to exploit old and vulnerable versions of JavaScript libraries hosted at the same server (frequent case with CDN servers). In May 2017 one more method was published to bypass CSP using web application frameworks code.\n\n== Mode of operation ==\n\nIf the Content-Security-Policy header is present in the server response, a compliant client enforces the declarative allowlist policy. One example goal of a policy is a stricter execution mode for JavaScript in order to prevent certain cross-site scripting attacks. In practice this means that a number of features are disabled by default:\n\nInline JavaScript code<script> blocks,\nDOM event handlers as HTML attributes (e.g. onclick)\nThe javascript: links\nInline CSS statements\n<style> block\nstyle attributed to HTML elements\nDynamic JavaScript code evaluationeval()\nstring arguments for setTimeout and setInterval functions\nnew Function() constructor\nDynamic CSS statements\nCSSStyleSheet.insertRule() methodWhile using CSP in a new application may be quite straightforward, especially with CSP-compatible JavaScript framework, existing applications may require some refactoring\u2014or relaxing the policy. Recommended coding practice for CSP-compatible web applications is to load code from external source files (<script src>), parse JSON instead of evaluating it and use EventTarget.addEventListener() to set event handlers.\n\n\n*** Notes ***\n\n== Reporting ==\nAny time a requested resource or script execution violates the policy, the browser will fire a POST request to the value specified in report-uri or  report-to containing details of the violation.\nCSP reports are standard JSON structures and can be captured either by application's own API or public CSP report receivers.In 2018 security researchers showed how to send false positive reports to the designated receiver specified in report-uri . This allows potential attackers to arbitrarily trigger those alarms and might render them less useful in case of a real attack. This behaviour is intended and cannot be fixed, as the browser (client) is sending the reports.\n\n== Browser add-ons and extensions exemption ==\nAccording to the original CSP (1.0) Processing Model (2012\u20132013), CSP should not interfere with the operation of browser add-ons or extensions installed by the user. This feature of CSP would have effectively allowed any add-on, extension, or Bookmarklet to inject script into web sites, regardless of the origin of that script, and thus be exempt from CSP policies.\n\nHowever, this policy has since been modified (as of CSP 1.1) with the following wording. Note the use of the word \"may\" instead of the prior absolute \"should (not)\" wording:Note: User agents may allow users to modify or bypass policy enforcement through user preferences, bookmarklets, third-party additions to the user agent, and other such mechanisms.The absolute \"should\" wording was being used by browser users to request/demand adherence to the policy and have changes installed in popular browsers (Firefox, Chrome, Safari) to support it. This was particularly contentious when sites like Twitter and GitHub started using strong CSP policies, which 'broke' the use of Bookmarklets.The W3C Web Application Security Working Group considers such script to be part of the Trusted Computing Base implemented by the browser; however, it has been argued to the working group by a representative of Cox Communications that this exemption is a potential security hole that could be exploited by malicious or compromised add-ons or extensions.\n\n== Complementary measures ==\nAs of 2015 a number of new browser security standards are being proposed by W3C, most of them complementary to CSP:\nSubresource Integrity (SRI), to ensure only known, trusted resource files (typically JavaScript, CSS) are loaded from third-party servers (typically CDNs)\nMixed Content, to clarify the intended browser's policy on pages loaded over HTTPS and linking content over plaintext HTTP\nUpgrade Insecure Requests, hinting browsers on how to handle legacy links on pages migrated to HTTPS\nCredential Management, a unified JavaScript API to access user's credentials to facilitate complex login schemes,\nReferrer Policy, CSP extension to hint the browser on generation of the Referer headers.\n\nHow can a website declare multiple CSP headers and how are they processed by the browser?",
    "context": "",
    "output": "A: A website can declare multiple CSP headers, which will be processed separately by the browser. Each header can be either an enforcement or report-only one.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can a website declare multiple CSP headers and how are they processed by the browser?",
      "answer": "A website can declare multiple CSP headers, which will be processed separately by the browser. Each header can be either an enforcement or report-only one.",
      "context": "Content Security Policy\n\n==Introduction==\nContent Security Policy (CSP) is a computer security standard introduced to prevent cross-site scripting (XSS), clickjacking and other code injection  attacks resulting from execution of malicious content in the trusted web page context. It is a Candidate Recommendation of the W3C working group on Web Application Security, widely supported by modern web browsers. CSP provides a standard method for website owners to declare approved origins of content that browsers should be allowed to load on that website\u2014covered types are JavaScript, CSS, HTML frames, web workers, fonts, images, embeddable objects such as Java applets, ActiveX, audio and video files, and other HTML5 features.\n\n== Status ==\nThe standard, originally named Content Restrictions, was proposed by Robert Hansen in 2004, first implemented in Firefox 4 and quickly picked up by other browsers. Version 1 of the standard was published in 2012 as W3C candidate recommendation and quickly with further versions (Level 2) published in 2014. As of 2023, the draft of Level 3 is being developed with the new features being quickly adopted by the web browsers.The following header names are in use as part of experimental CSP implementations:\nContent-Security-Policy \u2013 standard header name proposed by the W3C document. Google Chrome supports this as of version 25. Firefox supports this as of version 23, released on 6 August 2013. WebKit supports this as of version 528 (nightly build). Chromium-based Microsoft Edge support is similar to Chrome's.\nX-WebKit-CSP \u2013 deprecated, experimental header introduced into Google Chrome, Safari and other WebKit-based web browsers in 2011.\nX-Content-Security-Policy \u2013 deprecated, experimental header introduced in Gecko 2 based browsers (Firefox 4 to Firefox 22,  Thunderbird 3.3,  SeaMonkey 2.1).A website can declare multiple CSP headers, also mixing enforcement and report-only ones. Each header will be processed separately by the browser.\nCSP can also be delivered within the HTML code using a HTML META tag, although in this case its effectiveness will be limited.Internet Explorer 10 and Internet Explorer 11 also support CSP, but only sandbox directive, using the experimental X-Content-Security-Policy header.A number of web application frameworks support CSP, for example AngularJS (natively) and Django (middleware). Instructions for Ruby on Rails have been posted by GitHub. Web framework support is however only required if the CSP contents somehow depend on the web application's state\u2014such as usage of the nonce origin. Otherwise, the CSP is rather static and can be delivered from web application tiers above the application, for example on load balancer or web server.\n\n\n*** Bypasses ***\nIn December 2015  and December 2016, a few methods of bypassing 'nonce' allowlisting origins were published. In January 2016, another method was published, which leverages server-wide CSP allowlisting to exploit old and vulnerable versions of JavaScript libraries hosted at the same server (frequent case with CDN servers). In May 2017 one more method was published to bypass CSP using web application frameworks code.\n\n== Mode of operation ==\n\nIf the Content-Security-Policy header is present in the server response, a compliant client enforces the declarative allowlist policy. One example goal of a policy is a stricter execution mode for JavaScript in order to prevent certain cross-site scripting attacks. In practice this means that a number of features are disabled by default:\n\nInline JavaScript code<script> blocks,\nDOM event handlers as HTML attributes (e.g. onclick)\nThe javascript: links\nInline CSS statements\n<style> block\nstyle attributed to HTML elements\nDynamic JavaScript code evaluationeval()\nstring arguments for setTimeout and setInterval functions\nnew Function() constructor\nDynamic CSS statements\nCSSStyleSheet.insertRule() methodWhile using CSP in a new application may be quite straightforward, especially with CSP-compatible JavaScript framework, existing applications may require some refactoring\u2014or relaxing the policy. Recommended coding practice for CSP-compatible web applications is to load code from external source files (<script src>), parse JSON instead of evaluating it and use EventTarget.addEventListener() to set event handlers.\n\n\n*** Notes ***\n\n== Reporting ==\nAny time a requested resource or script execution violates the policy, the browser will fire a POST request to the value specified in report-uri or  report-to containing details of the violation.\nCSP reports are standard JSON structures and can be captured either by application's own API or public CSP report receivers.In 2018 security researchers showed how to send false positive reports to the designated receiver specified in report-uri . This allows potential attackers to arbitrarily trigger those alarms and might render them less useful in case of a real attack. This behaviour is intended and cannot be fixed, as the browser (client) is sending the reports.\n\n== Browser add-ons and extensions exemption ==\nAccording to the original CSP (1.0) Processing Model (2012\u20132013), CSP should not interfere with the operation of browser add-ons or extensions installed by the user. This feature of CSP would have effectively allowed any add-on, extension, or Bookmarklet to inject script into web sites, regardless of the origin of that script, and thus be exempt from CSP policies.\n\nHowever, this policy has since been modified (as of CSP 1.1) with the following wording. Note the use of the word \"may\" instead of the prior absolute \"should (not)\" wording:Note: User agents may allow users to modify or bypass policy enforcement through user preferences, bookmarklets, third-party additions to the user agent, and other such mechanisms.The absolute \"should\" wording was being used by browser users to request/demand adherence to the policy and have changes installed in popular browsers (Firefox, Chrome, Safari) to support it. This was particularly contentious when sites like Twitter and GitHub started using strong CSP policies, which 'broke' the use of Bookmarklets.The W3C Web Application Security Working Group considers such script to be part of the Trusted Computing Base implemented by the browser; however, it has been argued to the working group by a representative of Cox Communications that this exemption is a potential security hole that could be exploited by malicious or compromised add-ons or extensions.\n\n== Complementary measures ==\nAs of 2015 a number of new browser security standards are being proposed by W3C, most of them complementary to CSP:\nSubresource Integrity (SRI), to ensure only known, trusted resource files (typically JavaScript, CSS) are loaded from third-party servers (typically CDNs)\nMixed Content, to clarify the intended browser's policy on pages loaded over HTTPS and linking content over plaintext HTTP\nUpgrade Insecure Requests, hinting browsers on how to handle legacy links on pages migrated to HTTPS\nCredential Management, a unified JavaScript API to access user's credentials to facilitate complex login schemes,\nReferrer Policy, CSP extension to hint the browser on generation of the Referer headers."
    }
  },
  {
    "instruction": "2020 Miami-Dade Public Schools DDoS attack\n\n==Introduction==\nOn 3 September 2020, at 2:53 am EDT, a 16-year-old male from South Miami, Florida was arrested in connection with distributed denial-of-service (DDoS) attacks on the Miami-Dade County Public Schools's computer network, the fourth largest in the US, causing the system to crash during the first three days of the school year. It occurred as the school system was attempting to conduct internet-based instruction during the COVID-19 pandemic of 2020.\nAfter monitoring the IP addresses using the network, investigators concluded the teenager and several foreign actors had hacked the system. At the time, the school district had contracted Stride, Inc. (at the time known as K12 Inc.) to provide the software necessary for the internet-based instruction. Despite its price tag of $15.3 million, Stride was surprisingly susceptible to the attacks. Consequently, the school district sought the help of the FBI and U.S. Secret Service to investigate.\n\n\n\n== Method used in the attacks ==\nAccording to an affidavit, the suspect used Low Orbit Ion Cannon (LOIC) to launch the attacks. LOIC is an application that uses DDoS-style attacks to disrupt websites. However, investigators say the teen was not the only hacker involved. Numerous other IP addresses were associated with the attacks originating from Russia, the Ukraine, China, Iraq, and other countries. Investigators said the suspect was responsible for eight of at least 24 attacks.After the accused admitted to his involvement, he was charged with the crime of using a computer to defraud, a third-degree felony.\n\n== Agencies involved in the investigation ==\nThe FBI, the US Secret Service, and the Florida Department of Law Enforcement were the investigating agencies. Former US Congresswoman Debbie Mucarsel-Powell of Florida's 26th congressional district formally asked the FBI for a briefing on the issue. US Senator Marco Rubio from Florida asked the Department of Homeland Security for information about the attacks as well.\n\nWhat was the impact of the DDoS attacks on the internet-based instruction at Miami-Dade County Public Schools?",
    "context": "",
    "output": "The DDoS attacks caused the system to crash during the first three days of the school year, disrupting the internet-based instruction.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was the impact of the DDoS attacks on the internet-based instruction at Miami-Dade County Public Schools?",
      "answer": "The DDoS attacks caused the system to crash during the first three days of the school year, disrupting the internet-based instruction.",
      "context": "2020 Miami-Dade Public Schools DDoS attack\n\n==Introduction==\nOn 3 September 2020, at 2:53 am EDT, a 16-year-old male from South Miami, Florida was arrested in connection with distributed denial-of-service (DDoS) attacks on the Miami-Dade County Public Schools's computer network, the fourth largest in the US, causing the system to crash during the first three days of the school year. It occurred as the school system was attempting to conduct internet-based instruction during the COVID-19 pandemic of 2020.\nAfter monitoring the IP addresses using the network, investigators concluded the teenager and several foreign actors had hacked the system. At the time, the school district had contracted Stride, Inc. (at the time known as K12 Inc.) to provide the software necessary for the internet-based instruction. Despite its price tag of $15.3 million, Stride was surprisingly susceptible to the attacks. Consequently, the school district sought the help of the FBI and U.S. Secret Service to investigate.\n\n\n\n== Method used in the attacks ==\nAccording to an affidavit, the suspect used Low Orbit Ion Cannon (LOIC) to launch the attacks. LOIC is an application that uses DDoS-style attacks to disrupt websites. However, investigators say the teen was not the only hacker involved. Numerous other IP addresses were associated with the attacks originating from Russia, the Ukraine, China, Iraq, and other countries. Investigators said the suspect was responsible for eight of at least 24 attacks.After the accused admitted to his involvement, he was charged with the crime of using a computer to defraud, a third-degree felony.\n\n== Agencies involved in the investigation ==\nThe FBI, the US Secret Service, and the Florida Department of Law Enforcement were the investigating agencies. Former US Congresswoman Debbie Mucarsel-Powell of Florida's 26th congressional district formally asked the FBI for a briefing on the issue. US Senator Marco Rubio from Florida asked the Department of Homeland Security for information about the attacks as well."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are some common techniques for securely exchanging symmetric keys in a cryptosystem?",
    "context": "",
    "output": "Some common techniques for securely exchanging symmetric keys include using a secure communication channel, encapsulating one key within another, and deriving subsidiary keys as needed from a master key and some other data.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are some common techniques for securely exchanging symmetric keys in a cryptosystem?",
      "answer": "Some common techniques for securely exchanging symmetric keys include using a secure communication channel, encapsulating one key within another, and deriving subsidiary keys as needed from a master key and some other data."
    }
  },
  {
    "instruction": "Tcpcrypt\n\n==Introduction==\nIn computer networking, tcpcrypt is a transport layer communication encryption protocol. Unlike prior protocols like TLS (SSL), tcpcrypt is implemented as a TCP extension. It was designed by a team of six security and networking experts: Andrea Bittau, Mike Hamburg, Mark Handley, David Mazi\u00e8res, Dan Boneh and Quinn Slack. Tcpcrypt has been published as an Internet Draft. Experimental user-space implementations are available for Linux, Mac OS X, FreeBSD and Windows. There is also a Linux kernel implementation.\nThe TCPINC (TCP Increased Security) working group was formed in June 2014 by IETF to work on standardizing security extensions in the TCP protocol. In May 2019 the working group released RFC 8547 and RFC 8548 as an experimental standard for Tcpcrypt.\n\n\n\n== Description ==\nTcpcrypt provides opportunistic encryption \u2014 if either side does not support this extension, then the protocol falls back to regular unencrypted TCP. Tcpcrypt also provides encryption to any application using TCP, even ones that do not know about encryption. This enables incremental and seamless deployment.Unlike TLS, tcpcrypt itself does not do any authentication, but passes a unique \"session ID\" down to the application; the application can then use this token for further authentication. This means that any authentication scheme can be used, including passwords or certificates. It also does a larger part of the public-key connection initiation on the client side, to reduce load on servers and mitigate DoS attacks.\n\n== Performance ==\nTcpcrypt enforces TCP timestamps and adds its own TCP options to each data packet, amounting to 36 bytes per packet compared to plain TCP. With a mean observed packet size for TCP packets of 471 bytes, this can lead to an overhead of 8% of useful bandwidth. This 36 bytes overhead may not be an issue for internet connections faster than 64kbs, but can be an issue for dial up internet users.\nCompared to TLS/SSL, tcpcrypt is designed to have a lower performance impact. In part this is because tcpcrypt does not have built-in authentication, which can be implemented by the application itself. Cryptography primitives are used in such a way to reduce load on the server side, because a single server usually has to provide services for far more clients than reverse.\n\n== Implementations ==\nThe current user space implementations are considered experimental and are reportedly unstable on some systems. It also does not support IPv6 yet, which is currently only supported by the Linux kernel version. It is expected that once tcpcrypt becomes a standard, operating systems will come with tcpcrypt support built-in, making the user space solution unnecessary.\nQ: What is opportunistic encryption in the context of tcpcrypt?",
    "context": "",
    "output": "Opportunistic encryption in the context of tcpcrypt refers to its ability to provide encryption if both sides support this extension, but fall back to regular unencrypted TCP if either side does not support it.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is opportunistic encryption in the context of tcpcrypt?",
      "answer": "Opportunistic encryption in the context of tcpcrypt refers to its ability to provide encryption if both sides support this extension, but fall back to regular unencrypted TCP if either side does not support it.",
      "context": "Tcpcrypt\n\n==Introduction==\nIn computer networking, tcpcrypt is a transport layer communication encryption protocol. Unlike prior protocols like TLS (SSL), tcpcrypt is implemented as a TCP extension. It was designed by a team of six security and networking experts: Andrea Bittau, Mike Hamburg, Mark Handley, David Mazi\u00e8res, Dan Boneh and Quinn Slack. Tcpcrypt has been published as an Internet Draft. Experimental user-space implementations are available for Linux, Mac OS X, FreeBSD and Windows. There is also a Linux kernel implementation.\nThe TCPINC (TCP Increased Security) working group was formed in June 2014 by IETF to work on standardizing security extensions in the TCP protocol. In May 2019 the working group released RFC 8547 and RFC 8548 as an experimental standard for Tcpcrypt.\n\n\n\n== Description ==\nTcpcrypt provides opportunistic encryption \u2014 if either side does not support this extension, then the protocol falls back to regular unencrypted TCP. Tcpcrypt also provides encryption to any application using TCP, even ones that do not know about encryption. This enables incremental and seamless deployment.Unlike TLS, tcpcrypt itself does not do any authentication, but passes a unique \"session ID\" down to the application; the application can then use this token for further authentication. This means that any authentication scheme can be used, including passwords or certificates. It also does a larger part of the public-key connection initiation on the client side, to reduce load on servers and mitigate DoS attacks.\n\n== Performance ==\nTcpcrypt enforces TCP timestamps and adds its own TCP options to each data packet, amounting to 36 bytes per packet compared to plain TCP. With a mean observed packet size for TCP packets of 471 bytes, this can lead to an overhead of 8% of useful bandwidth. This 36 bytes overhead may not be an issue for internet connections faster than 64kbs, but can be an issue for dial up internet users.\nCompared to TLS/SSL, tcpcrypt is designed to have a lower performance impact. In part this is because tcpcrypt does not have built-in authentication, which can be implemented by the application itself. Cryptography primitives are used in such a way to reduce load on the server side, because a single server usually has to provide services for far more clients than reverse.\n\n== Implementations ==\nThe current user space implementations are considered experimental and are reportedly unstable on some systems. It also does not support IPv6 yet, which is currently only supported by the Linux kernel version. It is expected that once tcpcrypt becomes a standard, operating systems will come with tcpcrypt support built-in, making the user space solution unnecessary."
    }
  },
  {
    "instruction": "Answer based on context:\n\nTarpit (networking)\n\n==Introduction==\nA tarpit is a service on a computer system (usually a server) that purposely delays incoming connections. The technique was developed as a defense against a computer worm, and the idea is that network abuses such as spamming or broad scanning are less effective, and therefore less attractive, if they take too long. The concept is analogous with a tar pit, in which animals can get bogged down and slowly sink under the surface, like in a swamp.\n\n== The original tarpit idea ==\nTom Liston developed the original tarpitting program LaBrea. It can protect an entire network with a tarpit run on a single machine.\nThe machine listens for Address Resolution Protocol requests that go unanswered (indicating unused addresses), then replies to those requests, receives the initial SYN packet of the scanner and sends a SYN/ACK in response. It does not open a socket or prepare a connection, in fact it can forget all about the connection after sending the SYN/ACK. However, the remote site sends its ACK (which gets ignored) and believes the 3-way-handshake to be complete. Then it starts to send data, which never reaches a destination. The connection will time out after a while, but since the system believes it is dealing with a live (established) connection, it is conservative in timing it out and will instead try to retransmit, back-off, retransmit, etc. for quite a while.\nLater versions of LaBrea also added functionality to reply to the incoming data, again using raw IP packets and no sockets or other resources of the tarpit server, with bogus packets that request that the sending site \"slow down\". This will keep the connection established and waste even more time of the scanner.\n\n== SMTP tarpits ==\nOne of the possible avenues that were considered to battle bulk-spam at one time, was to mandate a small fee for every submitted mail. By introducing such artificial cost, with negligible impact on legitimate use as long as the fee is small enough, automated mass-scale spam would instantly become unattractive. Tarpitting could be seen as a similar (but technically much less complex) approach, where the cost for the spammer would be measured in terms of time and efficiency rather than money.\nAuthentication procedures increase response times as users attempt invalid passwords. SMTP authentication is no exception. However, server-to-server SMTP transfers, which is where spam is injected, require no authentication. Various methods have been discussed and implemented for SMTP tarpits, systems that plug into the Mail Transfer Agent (MTA, i.e. the mail server software) or sit in front of it as a proxy.\nOne method increases transfer time for all mails by a few seconds by delaying the initial greeting message (\"greet delay\"). The idea is that it will not matter if a legitimate mail takes a little longer to deliver, but due to the high volume, it will make a difference for spammers. The downside of this is that mailing lists and other legitimate mass-mailings will have to be explicitly whitelisted or they will suffer, too.\nSome email systems, such as sendmail 8.13+, implement a stronger form of greet delay. This form pauses when the connection is first established and listens for traffic. If it detects any traffic prior to its own greeting (in violation of RFC 2821) it closes the connection. Since many spammers do not write their SMTP implementations to the specification, this can reduce the number of incoming spam messages.\nAnother method is to delay only known spammers, e.g. by using a blacklist (see Spamming, DNSBL). OpenBSD has integrated this method into their core system since OpenBSD 3.3, with a special-purpose daemon (spamd) and functionality in the firewall (pf) to redirect known spammers to this tarpit.\nMS Exchange can tarpit senders who send to an invalid address. Exchange can do this because the SMTP connector is connected to the authentication system.\nA more subtle idea is greylisting, which, in simple terms, rejects the first connection attempt from any previously unseen IP address. The assumption is that most spammers make only one connection attempt (or a few attempts over a short period of time) to send each message, whereas legitimate mail delivery systems will keep retrying over a longer period. After they retry, they will eventually be allowed in without any further impediments.\nFinally, a more elaborate method tries to glue tarpits and filtering software together, by filtering e-mail in realtime, while it is being transmitted, and adding delays to the communication in response to the filter's \"spam likeliness\" indicator. For example, the spam filter would make a \"guess\" after each line or after every x bytes received as to how likely this message is going to be spam. The more likely this is, the more the MTA will delay the transmission.\n\n\n*** Background ***\nSMTP consists of requests, which are mostly four-letter words  such as MAIL, and replies, which are (minimally) three-digit numbers.  In the last line of the reply, the number is followed by a space; in the preceding lines it is followed by a hyphen.  Thus, on determining that a message being attempted to send is spam, a mail server can reply:\n\n451-Ophiomyia prima is an agromyzid fly\n451-Ophiomyia secunda is an agromyzid fly\n451-Ophiomyia tertia is an agromyzid fly\n451-Ophiomyia quarta is an agromyzid fly\n451-Ophiomyia quinta is an agromyzid fly\n451-Ophiomyia sexta is an agromyzid fly\n451-Ophiomyia septima is an agromyzid fly\n451 Your IP address is listed in the DNSBL. Please try again later.\n\nThe tarpit waits fifteen or more seconds between lines (long delays are allowed in SMTP, as humans sometimes send mail manually to test mail servers). This ties up the SMTP sending process on the spammer's computer so as to limit the amount of spam it can send.\n\n== IP-level tarpits ==\nThe Linux kernel can now be patched to allow tarpitting of incoming connections instead of the more usual dropping of packets.  This is implemented in iptables by the addition of a TARPIT target. The same packet inspection and matching features can be applied to tarpit targets as are applied to other targets.\n\n== Mixed SMTP-IP level tarpits ==\nA server can determine that a given mail message is spam, e.g. because it was addressed to a spam trap, or after trusted users' reports. The server may decide that the IP address responsible for submitting the message deserves tarpitting. Cross-checking against available DNSBLs can help to avoid including innocent forwarders in the tarpit database. A daemon exploiting Linux libipq can then check the remote address of incoming SMTP connections against that database. SpamCannibal is a GPL software designed around this idea; Stockade is a similar project implemented using FreeBSD ipfirewall.\nOne advantage of tarpitting at the IP level is that regular TCP connections handled by an MTA are stateful. That is, although the MTA doesn't use much CPU while it sleeps, it still uses the amount of memory required to hold the state of each connection. On the opposite, LaBrea-style tarpitting is stateless, thus gaining the advantage of a reduced cost against the spammer's box. However, it has to be noted that making use of botnets, spammers can externalize most of their computer-resource costs.\n\n== Criticism ==\nIt is known that a tarpitted connection may generate a significant amount of traffic towards the receiver, because the sender considers the connection as established and tries to send (and then retransmit) actual data. In practice, given current average computer botnet size, a more reasonable solution will be to drop suspicious traffic completely, without tarpitting. This way, only TCP SYN segments will be retransmitted, not the whole HTTP or HTTPS requests.\n\n== Commercial implementations of tar-pitting ==\nAs well as MS Exchange, there have been two other successful commercial implementations of the tar pit idea. The first was developed by TurnTide, a Philadelphia-based startup company, which was acquired by Symantec in 2004 for $28 million in cash. The TurnTide Anti Spam Router contains a modified Linux kernel which allows it to play various tricks with TCP traffic, such as varying the TCP window size. By grouping various email senders into different traffic classes and limiting the bandwidth for each class, the amount of abusive traffic is reduced - particularly when the abusive traffic is coming from single sources which are easily identified by their high traffic volume.\nAfter the Symantec acquisition, a Canadian startup company called MailChannels released their \"Traffic Control\" software, which uses a slightly different approach to achieve similar results. Traffic Control is a semi-realtime SMTP proxy. Unlike the TurnTide appliance, which applies traffic shaping at the network layer, Traffic Control applies traffic shaping to individual senders at the application layer. This approach results in a somewhat more effective handling of spam traffic originating from botnets because it allows the software to slow traffic from individual spam zombies, rather than requiring zombie traffic to be aggregated into a class.\n\nHow does MailChannels Traffic Control software help in reducing spam traffic?",
    "context": "",
    "output": "MailChannels Traffic Control software is a semi-realtime SMTP proxy that applies traffic shaping to individual senders at the application layer. This approach allows the software to slow traffic from individual spam zombies, rather than requiring zombie traffic to be aggregated into a class, resulting in a more effective handling of spam traffic originating from botnets.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does MailChannels Traffic Control software help in reducing spam traffic?",
      "answer": "MailChannels Traffic Control software is a semi-realtime SMTP proxy that applies traffic shaping to individual senders at the application layer. This approach allows the software to slow traffic from individual spam zombies, rather than requiring zombie traffic to be aggregated into a class, resulting in a more effective handling of spam traffic originating from botnets.",
      "context": "Tarpit (networking)\n\n==Introduction==\nA tarpit is a service on a computer system (usually a server) that purposely delays incoming connections. The technique was developed as a defense against a computer worm, and the idea is that network abuses such as spamming or broad scanning are less effective, and therefore less attractive, if they take too long. The concept is analogous with a tar pit, in which animals can get bogged down and slowly sink under the surface, like in a swamp.\n\n== The original tarpit idea ==\nTom Liston developed the original tarpitting program LaBrea. It can protect an entire network with a tarpit run on a single machine.\nThe machine listens for Address Resolution Protocol requests that go unanswered (indicating unused addresses), then replies to those requests, receives the initial SYN packet of the scanner and sends a SYN/ACK in response. It does not open a socket or prepare a connection, in fact it can forget all about the connection after sending the SYN/ACK. However, the remote site sends its ACK (which gets ignored) and believes the 3-way-handshake to be complete. Then it starts to send data, which never reaches a destination. The connection will time out after a while, but since the system believes it is dealing with a live (established) connection, it is conservative in timing it out and will instead try to retransmit, back-off, retransmit, etc. for quite a while.\nLater versions of LaBrea also added functionality to reply to the incoming data, again using raw IP packets and no sockets or other resources of the tarpit server, with bogus packets that request that the sending site \"slow down\". This will keep the connection established and waste even more time of the scanner.\n\n== SMTP tarpits ==\nOne of the possible avenues that were considered to battle bulk-spam at one time, was to mandate a small fee for every submitted mail. By introducing such artificial cost, with negligible impact on legitimate use as long as the fee is small enough, automated mass-scale spam would instantly become unattractive. Tarpitting could be seen as a similar (but technically much less complex) approach, where the cost for the spammer would be measured in terms of time and efficiency rather than money.\nAuthentication procedures increase response times as users attempt invalid passwords. SMTP authentication is no exception. However, server-to-server SMTP transfers, which is where spam is injected, require no authentication. Various methods have been discussed and implemented for SMTP tarpits, systems that plug into the Mail Transfer Agent (MTA, i.e. the mail server software) or sit in front of it as a proxy.\nOne method increases transfer time for all mails by a few seconds by delaying the initial greeting message (\"greet delay\"). The idea is that it will not matter if a legitimate mail takes a little longer to deliver, but due to the high volume, it will make a difference for spammers. The downside of this is that mailing lists and other legitimate mass-mailings will have to be explicitly whitelisted or they will suffer, too.\nSome email systems, such as sendmail 8.13+, implement a stronger form of greet delay. This form pauses when the connection is first established and listens for traffic. If it detects any traffic prior to its own greeting (in violation of RFC 2821) it closes the connection. Since many spammers do not write their SMTP implementations to the specification, this can reduce the number of incoming spam messages.\nAnother method is to delay only known spammers, e.g. by using a blacklist (see Spamming, DNSBL). OpenBSD has integrated this method into their core system since OpenBSD 3.3, with a special-purpose daemon (spamd) and functionality in the firewall (pf) to redirect known spammers to this tarpit.\nMS Exchange can tarpit senders who send to an invalid address. Exchange can do this because the SMTP connector is connected to the authentication system.\nA more subtle idea is greylisting, which, in simple terms, rejects the first connection attempt from any previously unseen IP address. The assumption is that most spammers make only one connection attempt (or a few attempts over a short period of time) to send each message, whereas legitimate mail delivery systems will keep retrying over a longer period. After they retry, they will eventually be allowed in without any further impediments.\nFinally, a more elaborate method tries to glue tarpits and filtering software together, by filtering e-mail in realtime, while it is being transmitted, and adding delays to the communication in response to the filter's \"spam likeliness\" indicator. For example, the spam filter would make a \"guess\" after each line or after every x bytes received as to how likely this message is going to be spam. The more likely this is, the more the MTA will delay the transmission.\n\n\n*** Background ***\nSMTP consists of requests, which are mostly four-letter words  such as MAIL, and replies, which are (minimally) three-digit numbers.  In the last line of the reply, the number is followed by a space; in the preceding lines it is followed by a hyphen.  Thus, on determining that a message being attempted to send is spam, a mail server can reply:\n\n451-Ophiomyia prima is an agromyzid fly\n451-Ophiomyia secunda is an agromyzid fly\n451-Ophiomyia tertia is an agromyzid fly\n451-Ophiomyia quarta is an agromyzid fly\n451-Ophiomyia quinta is an agromyzid fly\n451-Ophiomyia sexta is an agromyzid fly\n451-Ophiomyia septima is an agromyzid fly\n451 Your IP address is listed in the DNSBL. Please try again later.\n\nThe tarpit waits fifteen or more seconds between lines (long delays are allowed in SMTP, as humans sometimes send mail manually to test mail servers). This ties up the SMTP sending process on the spammer's computer so as to limit the amount of spam it can send.\n\n== IP-level tarpits ==\nThe Linux kernel can now be patched to allow tarpitting of incoming connections instead of the more usual dropping of packets.  This is implemented in iptables by the addition of a TARPIT target. The same packet inspection and matching features can be applied to tarpit targets as are applied to other targets.\n\n== Mixed SMTP-IP level tarpits ==\nA server can determine that a given mail message is spam, e.g. because it was addressed to a spam trap, or after trusted users' reports. The server may decide that the IP address responsible for submitting the message deserves tarpitting. Cross-checking against available DNSBLs can help to avoid including innocent forwarders in the tarpit database. A daemon exploiting Linux libipq can then check the remote address of incoming SMTP connections against that database. SpamCannibal is a GPL software designed around this idea; Stockade is a similar project implemented using FreeBSD ipfirewall.\nOne advantage of tarpitting at the IP level is that regular TCP connections handled by an MTA are stateful. That is, although the MTA doesn't use much CPU while it sleeps, it still uses the amount of memory required to hold the state of each connection. On the opposite, LaBrea-style tarpitting is stateless, thus gaining the advantage of a reduced cost against the spammer's box. However, it has to be noted that making use of botnets, spammers can externalize most of their computer-resource costs.\n\n== Criticism ==\nIt is known that a tarpitted connection may generate a significant amount of traffic towards the receiver, because the sender considers the connection as established and tries to send (and then retransmit) actual data. In practice, given current average computer botnet size, a more reasonable solution will be to drop suspicious traffic completely, without tarpitting. This way, only TCP SYN segments will be retransmitted, not the whole HTTP or HTTPS requests.\n\n== Commercial implementations of tar-pitting ==\nAs well as MS Exchange, there have been two other successful commercial implementations of the tar pit idea. The first was developed by TurnTide, a Philadelphia-based startup company, which was acquired by Symantec in 2004 for $28 million in cash. The TurnTide Anti Spam Router contains a modified Linux kernel which allows it to play various tricks with TCP traffic, such as varying the TCP window size. By grouping various email senders into different traffic classes and limiting the bandwidth for each class, the amount of abusive traffic is reduced - particularly when the abusive traffic is coming from single sources which are easily identified by their high traffic volume.\nAfter the Symantec acquisition, a Canadian startup company called MailChannels released their \"Traffic Control\" software, which uses a slightly different approach to achieve similar results. Traffic Control is a semi-realtime SMTP proxy. Unlike the TurnTide appliance, which applies traffic shaping at the network layer, Traffic Control applies traffic shaping to individual senders at the application layer. This approach results in a somewhat more effective handling of spam traffic originating from botnets because it allows the software to slow traffic from individual spam zombies, rather than requiring zombie traffic to be aggregated into a class."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are Canonical S-expressions and how do they relate to SPKI/SDSI?",
    "context": "",
    "output": "Canonical S-expressions are a binary form of encoding used in SPKI/SDSI. They are used to express authorization and are designed to be extremely easy to parse, following an LR(0) grammar.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are Canonical S-expressions and how do they relate to SPKI/SDSI?",
      "answer": "Canonical S-expressions are a binary form of encoding used in SPKI/SDSI. They are used to express authorization and are designed to be extremely easy to parse, following an LR(0) grammar."
    }
  },
  {
    "instruction": "MTR (software)\n\n==Introduction==\nMy traceroute, originally named Matt's traceroute (MTR), is a computer program that combines the functions of the traceroute and ping programs in one network diagnostic tool.MTR probes routers on the route path by limiting the number of hops individual packets may traverse, and listening to responses of their expiry. It will regularly repeat this process, usually once per second, and keep track of the response times of the hops along the path.\n\n\n\n== Fundamentals ==\nMTR is licensed under the terms of the GNU General Public License (GPL) and works under modern Unix-like operating systems. It normally works under the text console, but it also has an optional GTK+-based graphical user interface (GUI).\nMTR relies on Internet Control Message Protocol (ICMP) Time Exceeded (type 11, code 0) packets coming back from routers, or ICMP Echo Reply packets when the packets have hit their destination host.  MTR also has a User Datagram Protocol (UDP) mode (invoked with \"-u\" on the command line or pressing the \"u\" key in the curses interface) that sends UDP packets, with the time to live (TTL) field in the IP header increasing by one for each probe sent, toward the destination host. When the UDP mode is used, MTR relies on ICMP port unreachable packets (type 3, code 3) when the destination is reached.\nMTR also supports IPv6 and works in a similar manner but instead relies on ICMPv6 messages.\nThe tool is often used for network troubleshooting. By showing a list of routers traversed, and the average round-trip time as well as packet loss to each router, it allows users to identify links between two given routers responsible for certain fractions of the overall latency or packet loss through the network. This can help identify network overuse problems.\n\n== Examples ==\nThis example shows MTR running on Linux tracing a route from the host machine (example.lan) to a web server at Yahoo! (p25.www.re2.yahoo.com) across the Level 3 Communications network.\n\n                             My traceroute  [v0.71]\n            example.lan                           Sun Mar 25 00:07:50 2007\n\n                                       Packets                Pings\nHostname                            %Loss  Rcv  Snt  Last Best  Avg  Worst\n 1. example.lan                        0%   11   11     1    1    1      2\n 2. ae-31-51.ebr1.Chicago1.Level3.n   19%    9   11     3    1    7     14\n 3. ae-1.ebr2.Chicago1.Level3.net      0%   11   11     7    1    7     14\n 4. ae-2.ebr2.Washington1.Level3.ne   19%    9   11    19   18   23     31\n 5. ae-1.ebr1.Washington1.Level3.ne   28%    8   11    22   18   24     30\n 6. ge-3-0-0-53.gar1.Washington1.Le    0%   11   11    18   18   20     36\n 7. 63.210.29.230                      0%   10   10    19   19   19     19\n 8. t-3-1.bas1.re2.yahoo.com           0%   10   10    19   18   32    106\n 9. p25.www.re2.yahoo.com              0%   10   10    19   18   19     19\n\nAn additional example below shows a recent version of MTR running on FreeBSD.  MPLS labels are displayed by default when the \"-e\" switch is used on the command line (or the \"e\" key is pressed in the curses interface):\n\n                                  My traceroute  [v0.82]\ndax.prolixium.com (0.0.0.0)                                      Sun Jan  1 12:58:02 2012\nKeys:  Help   Display mode   Restart statistics   Order of fields   quit\n                                                 Packets               Pings\n Host                                          Loss%   Snt   Last   Avg  Best  Wrst StDev\n 1. voxel.prolixium.net                         0.0%    13    0.4   1.7   0.4  10.4   3.2\n 2. 0.ae2.tsr1.lga5.us.voxel.net                0.0%    12   10.8   2.9   0.2  10.8   4.3\n 3. 0.ae59.tsr1.lga3.us.voxel.net               0.0%    12    0.4   1.7   0.4  16.0   4.5\n 4. rtr.loss.net.internet2.edu                  0.0%    12    4.8   7.4   0.3  41.8  15.4\n 5. 64.57.21.210                                0.0%    12    5.4  15.7   5.3 126.7  35.0\n 6. nox1sumgw1-vl-530-nox-mit.nox.org           0.0%    12  109.5  60.6  23.0 219.5  66.0\n    [MPLS: Lbl 172832 Exp 0 S 1 TTL 1]\n 7. nox1sumgw1-peer--207-210-142-234.nox.org    0.0%    12   25.0  23.2  23.0  25.0   0.6\n 8. B24-RTR-2-BACKBONE-2.MIT.EDU                0.0%    12   23.2  23.4  23.2  24.9   0.5\n 9. MITNET.TRANTOR.CSAIL.MIT.EDU                0.0%    12   23.4  23.4  23.3  23.5   0.1\n10. trantor.helicon.csail.mit.edu               0.0%    12   23.7  25.0  23.5  26.5   1.3\n11. zermatt.csail.mit.edu                       0.0%    12   23.1  23.1  23.1  23.3   0.1\n\n== Windows versions ==\nWinMTR is a Windows GUI application functionally equivalent to MTR. It was originally developed by Appnor MSP S.R.L.; it is now maintained by White-Tiger. Although it is very similar, WinMTR shares no common code with MTR.\nA console version of MTR does exist for Windows, but it has fewer features than MTR on other platforms.\n\n== Similar commands ==\nWindows NT and beyond has a built-in PathPing command that similarly combines the functionality of ping with that of tracert. It displays network latency and network loss at intermediate hops between a source and destination. Because it displays the degree of packet loss at any given router or link, it can also be used to determine which routers or subnets might be having network problems.\nQuestion: What is the purpose of the User Datagram Protocol (UDP) mode in MTR?",
    "context": "",
    "output": "Answer: The User Datagram Protocol (UDP) mode in MTR is used to send UDP packets, with the time to live (TTL) field in the IP header increasing by one for each probe sent, toward the destination host.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the purpose of the User Datagram Protocol (UDP) mode in MTR?",
      "answer": "The User Datagram Protocol (UDP) mode in MTR is used to send UDP packets, with the time to live (TTL) field in the IP header increasing by one for each probe sent, toward the destination host.",
      "context": "MTR (software)\n\n==Introduction==\nMy traceroute, originally named Matt's traceroute (MTR), is a computer program that combines the functions of the traceroute and ping programs in one network diagnostic tool.MTR probes routers on the route path by limiting the number of hops individual packets may traverse, and listening to responses of their expiry. It will regularly repeat this process, usually once per second, and keep track of the response times of the hops along the path.\n\n\n\n== Fundamentals ==\nMTR is licensed under the terms of the GNU General Public License (GPL) and works under modern Unix-like operating systems. It normally works under the text console, but it also has an optional GTK+-based graphical user interface (GUI).\nMTR relies on Internet Control Message Protocol (ICMP) Time Exceeded (type 11, code 0) packets coming back from routers, or ICMP Echo Reply packets when the packets have hit their destination host.  MTR also has a User Datagram Protocol (UDP) mode (invoked with \"-u\" on the command line or pressing the \"u\" key in the curses interface) that sends UDP packets, with the time to live (TTL) field in the IP header increasing by one for each probe sent, toward the destination host. When the UDP mode is used, MTR relies on ICMP port unreachable packets (type 3, code 3) when the destination is reached.\nMTR also supports IPv6 and works in a similar manner but instead relies on ICMPv6 messages.\nThe tool is often used for network troubleshooting. By showing a list of routers traversed, and the average round-trip time as well as packet loss to each router, it allows users to identify links between two given routers responsible for certain fractions of the overall latency or packet loss through the network. This can help identify network overuse problems.\n\n== Examples ==\nThis example shows MTR running on Linux tracing a route from the host machine (example.lan) to a web server at Yahoo! (p25.www.re2.yahoo.com) across the Level 3 Communications network.\n\n                             My traceroute  [v0.71]\n            example.lan                           Sun Mar 25 00:07:50 2007\n\n                                       Packets                Pings\nHostname                            %Loss  Rcv  Snt  Last Best  Avg  Worst\n 1. example.lan                        0%   11   11     1    1    1      2\n 2. ae-31-51.ebr1.Chicago1.Level3.n   19%    9   11     3    1    7     14\n 3. ae-1.ebr2.Chicago1.Level3.net      0%   11   11     7    1    7     14\n 4. ae-2.ebr2.Washington1.Level3.ne   19%    9   11    19   18   23     31\n 5. ae-1.ebr1.Washington1.Level3.ne   28%    8   11    22   18   24     30\n 6. ge-3-0-0-53.gar1.Washington1.Le    0%   11   11    18   18   20     36\n 7. 63.210.29.230                      0%   10   10    19   19   19     19\n 8. t-3-1.bas1.re2.yahoo.com           0%   10   10    19   18   32    106\n 9. p25.www.re2.yahoo.com              0%   10   10    19   18   19     19\n\nAn additional example below shows a recent version of MTR running on FreeBSD.  MPLS labels are displayed by default when the \"-e\" switch is used on the command line (or the \"e\" key is pressed in the curses interface):\n\n                                  My traceroute  [v0.82]\ndax.prolixium.com (0.0.0.0)                                      Sun Jan  1 12:58:02 2012\nKeys:  Help   Display mode   Restart statistics   Order of fields   quit\n                                                 Packets               Pings\n Host                                          Loss%   Snt   Last   Avg  Best  Wrst StDev\n 1. voxel.prolixium.net                         0.0%    13    0.4   1.7   0.4  10.4   3.2\n 2. 0.ae2.tsr1.lga5.us.voxel.net                0.0%    12   10.8   2.9   0.2  10.8   4.3\n 3. 0.ae59.tsr1.lga3.us.voxel.net               0.0%    12    0.4   1.7   0.4  16.0   4.5\n 4. rtr.loss.net.internet2.edu                  0.0%    12    4.8   7.4   0.3  41.8  15.4\n 5. 64.57.21.210                                0.0%    12    5.4  15.7   5.3 126.7  35.0\n 6. nox1sumgw1-vl-530-nox-mit.nox.org           0.0%    12  109.5  60.6  23.0 219.5  66.0\n    [MPLS: Lbl 172832 Exp 0 S 1 TTL 1]\n 7. nox1sumgw1-peer--207-210-142-234.nox.org    0.0%    12   25.0  23.2  23.0  25.0   0.6\n 8. B24-RTR-2-BACKBONE-2.MIT.EDU                0.0%    12   23.2  23.4  23.2  24.9   0.5\n 9. MITNET.TRANTOR.CSAIL.MIT.EDU                0.0%    12   23.4  23.4  23.3  23.5   0.1\n10. trantor.helicon.csail.mit.edu               0.0%    12   23.7  25.0  23.5  26.5   1.3\n11. zermatt.csail.mit.edu                       0.0%    12   23.1  23.1  23.1  23.3   0.1\n\n== Windows versions ==\nWinMTR is a Windows GUI application functionally equivalent to MTR. It was originally developed by Appnor MSP S.R.L.; it is now maintained by White-Tiger. Although it is very similar, WinMTR shares no common code with MTR.\nA console version of MTR does exist for Windows, but it has fewer features than MTR on other platforms.\n\n== Similar commands ==\nWindows NT and beyond has a built-in PathPing command that similarly combines the functionality of ping with that of tracert. It displays network latency and network loss at intermediate hops between a source and destination. Because it displays the degree of packet loss at any given router or link, it can also be used to determine which routers or subnets might be having network problems."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does Bitsight's report on ransomware infection examine the infection across different industry sectors?",
    "context": "",
    "output": "Bitsight's report on ransomware infection examines the infection across six industry sectors by compiling data from 18,996 companies in the education, energy/utilities, finance, government, healthcare, and retail sectors.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does Bitsight's report on ransomware infection examine the infection across different industry sectors?",
      "answer": "Bitsight's report on ransomware infection examines the infection across six industry sectors by compiling data from 18,996 companies in the education, energy/utilities, finance, government, healthcare, and retail sectors."
    }
  },
  {
    "instruction": "Write an answer to the following question: What feature of modern microprocessors does the SWAPGS vulnerability exploit?",
    "context": "",
    "output": "The SWAPGS vulnerability exploits speculative execution in modern microprocessors, which allows processors to make educated guesses about the instructions that will most likely need to be executed in the near future.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What feature of modern microprocessors does the SWAPGS vulnerability exploit?",
      "answer": "The SWAPGS vulnerability exploits speculative execution in modern microprocessors, which allows processors to make educated guesses about the instructions that will most likely need to be executed in the near future."
    }
  },
  {
    "instruction": "Steganalysis\n\n==Introduction==\nSteganalysis is the study of detecting messages hidden using steganography; this is analogous to cryptanalysis applied to cryptography.\n\n== Overview ==\nThe goal of steganalysis is to identify suspected packages, determine whether or not they have a payload encoded into them, and, if possible, recover that payload.  \nUnlike cryptanalysis, in which intercepted data contains a message (though that message is encrypted), steganalysis generally starts with a pile of suspect data files, but little information about which of the files, if any, contain a payload.  The steganalyst is usually something of a forensic statistician, and must start by reducing this set of data files (which is often quite large; in many cases, it may be the entire set of files on a computer) to the subset most likely to have been altered.\n\n== Basic techniques ==\nThe problem is generally handled with statistical analysis.  A set of unmodified files of the same type, and ideally from the same source (for example, the same model of digital camera, or if possible, the same digital camera; digital audio from a CD MP3 files have been \"ripped\" from; etc.) as the set being inspected, are analyzed for various statistics.  Some of these are as simple as spectrum analysis, but since most image and audio files these days are compressed with lossy compression algorithms, such as JPEG and MP3, they also attempt to look for inconsistencies in the way this data has been compressed.  For example, a common artifact in JPEG compression is \"edge ringing\", where high-frequency components (such as the high-contrast edges of black text on a white background) distort neighboring pixels.  This distortion is predictable, and simple steganographic encoding algorithms will produce artifacts that are detectably unlikely.\nOne case where detection of suspect files is straightforward is when the original, unmodified carrier is available for comparison.  Comparing the package against the original file will yield the differences caused by encoding the payload\u2014and, thus, the payload can be extracted.\n\n== Advanced techniques ==\n\n\n*** Noise floor consistency analysis ***\nIn some cases, such as when only a single image is available, more complicated analysis techniques may be required.  In general, steganography attempts to make distortion to the carrier indistinguishable from the carrier's noise floor.  In practice, however, this is often improperly simplified to deciding to make the modifications to the carrier resemble white noise as closely as possible, rather than analyzing, modeling, and then consistently emulating the actual noise characteristics of the carrier.  In particular, many simple steganographic systems simply modify the least-significant bit (LSB) of a sample; this causes the modified samples to have not only different noise profiles than unmodified samples, but also for their LSBs to have different noise profiles than could be expected from analysis of their higher-order bits, which will still show some amount of noise.  Such LSB-only modification can be detected with appropriate algorithms, in some cases detecting encoding densities as low as 1% with reasonable reliability.\n\n== Further complications ==\n\n\n*** Encrypted payloads ***\nDetecting a probable steganographic payload is often only part of the problem, as the payload may have been encrypted first.  Encrypting the payload is not always done solely to make recovery of the payload more difficult.  Most strong ciphers have the desirable property of making the payload appear indistinguishable from uniformly-distributed noise, which can make detection efforts more difficult, and save the steganographic encoding technique the trouble of having to distribute the signal energy evenly (but see above concerning errors emulating the native noise of the carrier).\n\n\n*** Barrage noise ***\nIf inspection of a storage device is considered very likely, the steganographer may attempt to barrage a potential analyst with, effectively, misinformation. This may be a large set of files encoded with anything from random data, to white noise, to meaningless drivel, to deliberately misleading information. The encoding density on these files may be slightly higher than the \"real\" ones; likewise, the possible use of multiple algorithms of varying detectability should be considered. The steganalyst may be forced into checking these decoys first, potentially wasting significant time and computing resources. The downside to this technique is it makes it much more obvious that steganographic software was available, and was used.\n\n== Conclusions and further action ==\nObtaining a warrant or taking other actions based solely on steganalytic evidence is a very dicey proposition unless a payload has been completely recovered and decrypted, because otherwise all the analyst has is a statistic indicating that a file may have been modified, and that modification may have been the result of steganographic encoding.  Because this is likely to frequently be the case, steganalytic suspicions will often have to be backed up with other investigative techniques.\n\n== Bibliography ==\nGeetha, S; Siva S.Sivatha Sindhu (October 2009). \"Blind image steganalysis based on content independent statistical measures maximizing the specificity and sensitivity of the system\". Computers and Security. Elsevier, Science Direct. 28 (7): 683\u2013697. doi:10.1016/j.cose.2009.03.006.\nGeetha, S; Dr. N. Kamaraj (July 2010). \"Evolving decision tree rule based system for audio stego anomalies detection based on Hausdorff distance statistics\". Information Sciences. Elsevier, Science Direct. 180 (13): 2540\u20132559. doi:10.1016/j.ins.2010.02.024.\nRead the text above and answer this question: How does the comparison of a package against the original file aid in the detection and extraction of a payload?",
    "context": "",
    "output": "Comparing the package against the original file will yield the differences caused by encoding the payload, allowing for the payload to be extracted.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the comparison of a package against the original file aid in the detection and extraction of a payload?",
      "answer": "Comparing the package against the original file will yield the differences caused by encoding the payload, allowing for the payload to be extracted.",
      "context": "Steganalysis\n\n==Introduction==\nSteganalysis is the study of detecting messages hidden using steganography; this is analogous to cryptanalysis applied to cryptography.\n\n== Overview ==\nThe goal of steganalysis is to identify suspected packages, determine whether or not they have a payload encoded into them, and, if possible, recover that payload.  \nUnlike cryptanalysis, in which intercepted data contains a message (though that message is encrypted), steganalysis generally starts with a pile of suspect data files, but little information about which of the files, if any, contain a payload.  The steganalyst is usually something of a forensic statistician, and must start by reducing this set of data files (which is often quite large; in many cases, it may be the entire set of files on a computer) to the subset most likely to have been altered.\n\n== Basic techniques ==\nThe problem is generally handled with statistical analysis.  A set of unmodified files of the same type, and ideally from the same source (for example, the same model of digital camera, or if possible, the same digital camera; digital audio from a CD MP3 files have been \"ripped\" from; etc.) as the set being inspected, are analyzed for various statistics.  Some of these are as simple as spectrum analysis, but since most image and audio files these days are compressed with lossy compression algorithms, such as JPEG and MP3, they also attempt to look for inconsistencies in the way this data has been compressed.  For example, a common artifact in JPEG compression is \"edge ringing\", where high-frequency components (such as the high-contrast edges of black text on a white background) distort neighboring pixels.  This distortion is predictable, and simple steganographic encoding algorithms will produce artifacts that are detectably unlikely.\nOne case where detection of suspect files is straightforward is when the original, unmodified carrier is available for comparison.  Comparing the package against the original file will yield the differences caused by encoding the payload\u2014and, thus, the payload can be extracted.\n\n== Advanced techniques ==\n\n\n*** Noise floor consistency analysis ***\nIn some cases, such as when only a single image is available, more complicated analysis techniques may be required.  In general, steganography attempts to make distortion to the carrier indistinguishable from the carrier's noise floor.  In practice, however, this is often improperly simplified to deciding to make the modifications to the carrier resemble white noise as closely as possible, rather than analyzing, modeling, and then consistently emulating the actual noise characteristics of the carrier.  In particular, many simple steganographic systems simply modify the least-significant bit (LSB) of a sample; this causes the modified samples to have not only different noise profiles than unmodified samples, but also for their LSBs to have different noise profiles than could be expected from analysis of their higher-order bits, which will still show some amount of noise.  Such LSB-only modification can be detected with appropriate algorithms, in some cases detecting encoding densities as low as 1% with reasonable reliability.\n\n== Further complications ==\n\n\n*** Encrypted payloads ***\nDetecting a probable steganographic payload is often only part of the problem, as the payload may have been encrypted first.  Encrypting the payload is not always done solely to make recovery of the payload more difficult.  Most strong ciphers have the desirable property of making the payload appear indistinguishable from uniformly-distributed noise, which can make detection efforts more difficult, and save the steganographic encoding technique the trouble of having to distribute the signal energy evenly (but see above concerning errors emulating the native noise of the carrier).\n\n\n*** Barrage noise ***\nIf inspection of a storage device is considered very likely, the steganographer may attempt to barrage a potential analyst with, effectively, misinformation. This may be a large set of files encoded with anything from random data, to white noise, to meaningless drivel, to deliberately misleading information. The encoding density on these files may be slightly higher than the \"real\" ones; likewise, the possible use of multiple algorithms of varying detectability should be considered. The steganalyst may be forced into checking these decoys first, potentially wasting significant time and computing resources. The downside to this technique is it makes it much more obvious that steganographic software was available, and was used.\n\n== Conclusions and further action ==\nObtaining a warrant or taking other actions based solely on steganalytic evidence is a very dicey proposition unless a payload has been completely recovered and decrypted, because otherwise all the analyst has is a statistic indicating that a file may have been modified, and that modification may have been the result of steganographic encoding.  Because this is likely to frequently be the case, steganalytic suspicions will often have to be backed up with other investigative techniques.\n\n== Bibliography ==\nGeetha, S; Siva S.Sivatha Sindhu (October 2009). \"Blind image steganalysis based on content independent statistical measures maximizing the specificity and sensitivity of the system\". Computers and Security. Elsevier, Science Direct. 28 (7): 683\u2013697. doi:10.1016/j.cose.2009.03.006.\nGeetha, S; Dr. N. Kamaraj (July 2010). \"Evolving decision tree rule based system for audio stego anomalies detection based on Hausdorff distance statistics\". Information Sciences. Elsevier, Science Direct. 180 (13): 2540\u20132559. doi:10.1016/j.ins.2010.02.024."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are the four modes of operation supported by Ettercap?",
    "context": "",
    "output": "The four modes of operation supported by Ettercap are IP-based, MAC-based, ARP-based, and PublicARP-based. These modes filter packets based on IP addresses, MAC addresses, or use ARP poisoning for sniffing on a switched LAN.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are the four modes of operation supported by Ettercap?",
      "answer": "The four modes of operation supported by Ettercap are IP-based, MAC-based, ARP-based, and PublicARP-based. These modes filter packets based on IP addresses, MAC addresses, or use ARP poisoning for sniffing on a switched LAN."
    }
  },
  {
    "instruction": "Write an answer to the following question: When was Microsoft Security Essentials available for users?",
    "context": "",
    "output": "Microsoft Security Essentials was available for users since the second half of 2009.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "When was Microsoft Security Essentials available for users?",
      "answer": "Microsoft Security Essentials was available for users since the second half of 2009."
    }
  },
  {
    "instruction": "Trust service provider\n\n==Introduction==\nA trust service provider (TSP) is a person or legal entity providing and preserving digital certificates to create and validate electronic signatures and to authenticate their signatories as well as websites in general. Trust service providers are qualified certificate authorities required in the European Union and in Switzerland in the context of regulated electronic signing procedures.\n\n== Description ==\nThe trust service provider has the responsibility to assure the integrity of electronic identification for signatories and services through strong mechanisms for authentication, electronic signatures and digital certificates. eIDAS defines the standards for how trust service providers are to perform their services of authentication and non-repudiation. The regulation provides guidance to EU member states on how trust service providers shall be regulated and recognized.\nA trust service is defined as an electronic service that entails one of three possible actions. First it may concern the creation, the verification or the validation of electronic signatures, as well as time stamps or seals, electronically registered delivery services and certifications that are required with these services. The second action entails the creation, the verification as well as the validation of certificates that are used to authenticate websites. The third action is the preservation of these electronic signatures, the seals or the related certificates.\nTo be elevated to the level of a qualified trust service, the service must meet the requirements set under the eIDAS Regulation. Trust services provide a trust framework that facilitates continued relations for electronic transactions that are conducted between participating EU member states and organizations.\n\n== Role of a qualified trust service provider ==\nThe qualified trust service provider plays an important role in the process of qualified electronic signing. The trust service providers must be given qualified status and permission for a supervisory government body to provide qualified digital certificates which can be used to create qualified electronic signatures. eIDAS requires that the EU will maintain an EU Trust List that lists the providers and services that have received qualified status. A trust service provider is not entitled to provide qualified trust services if they are not on the EU Trust List.Trust service providers that are on the EU Trust List are required to follow the strict guidelines established under eIDAS. They need to provide stamps valid in time and date, when creating certificates. Signatures that have expired certificates need to be revoked immediately. The EU obliges the trust service providers to deliver appropriate training for all personnel employed by the trust service provider. They shall further provide tools such as software and hardware that is trustworthy and capable of preventing forgeries of the certificates that are produced.\n\n== Vision ==\nOne of the major intents of eIDAS was to facilitate both public and business services, especially those that are conducted between parties across EU Member state borders. These transactions can now be safely expedited through the means of electronic signing and the services that are provided by trust service providers in regards to ensuring the integrity of those signatures.\nEU member states are required through eIDAS to establish \u201cpoints of single contact\u201d (PSCs) for trust services that ensure that electronic ID schemes can be used for cross-board public sector transactions, including the exchange and access of healthcare information across borders.\n\n== Legal perspective of electronic signatures created by trust service providers ==\nWhile an advanced electronic signature is legally binding under eIDAS, a qualified electronic signature which has been created by a qualified trust service provider carries a higher probative value when used as evidence in court. Because the signature's authorship is considered non-repudiable, the authenticity of the signature cannot be easily challenged. EU member states are obligated to accept qualified electronic signatures that have been created with qualified certificate from other Member states as valid. According to the eIDAS Regulation, i.e. Article 24 (2), a signature created with a qualified certificate has the same legal value as a handwritten signature in court.The standards are evolving. Additional standards including policy definitions for trust service providers are under development by the European Telecommunication Standards Institute ETSI.\n\n== Global perspective ==\nThe Swiss digital signing standard ZertES has defined a comparable concept of certificate service providers. Certificate service providers need to be audited by conformity assessment bodies that have been appointed by the Schweizerische Akkreditierungsstelle.\nIn the United States the NIST Digital Signature Standard (DSS) in its current release does not know anything comparable to a qualified trust service provider which would allow to enhance non-repudiation through the signatory's qualified certificate. However authors of the forthcoming review and commentators are publicly discussing an amendment similar to the eIDAS and ZertES approach of trusted service provision. To allow for stringent and non-repudiable global transactions and legal relevance, an international harmonization would be required.\n\n== Controversy ==\nSeveral research institutes and associations expressed their concern with respect to the establishment of a small group of centralized trust service providers per country which authenticate digital transactions. They state that this construct may have negative impact on privacy. Given the central role of trust service providers in many transactions, the Council of European Professional Informatics Societies (CEPIS) fears that trust service providers would gain and collect information of the distinguishing attributes of the citizens, which are subject of authentication. With regard to their requirement to preserve data and resulting expected efforts to keep evidence for potential liability requests on inaccurate ID, CEPIS sees the risk that trust service providers could create and store log entries of all authentication processes. The information gained allows for monitoring and for the profiling of the involved citizens. If the transaction counterpart also identifies himself, user interests and their communication behaviour will additionally sharpen the profiles gained. Big data analysis would allow for far-reaching insights into the citizens' privacy and relationships. The direct connection to the qualifying governmental bodies could allow those to gain access to the gained data and profiles.Another publication claims that to truly take advantage of the secure and seamless cross-border electronic transactions, assurance levels, definitions and technical deployment need to be specified more precisely.In 2021, relatively vague proposed updates to eIDAS would require browsers to pass on assurances from TSPs to their users. This would apparently involve the incorporation of government-specified TSPs in parallel with the existing multi-stakeholder processes used by browsers to establish trust in Certificate authorities. The Internet Society and Mozilla asserted a variety of issues with the proposals.\nQuestion: Who or what is a trust service provider, and what is their role in the context of electronic signatures?",
    "context": "",
    "output": "Answer: A trust service provider is a person or legal entity that provides and preserves digital certificates for the creation and validation of electronic signatures and authentication of signatories and websites. They play a crucial role in ensuring the integrity and non-repudiation of electronic signing processes, as required by regulations such as eIDAS in the European Union and Switzerland. Trust service providers are responsible for strong authentication mechanisms, electronic signatures, digital certificates, time stamps, and the preservation of electronic signatures and related certificates.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Who or what is a trust service provider, and what is their role in the context of electronic signatures?",
      "answer": "A trust service provider is a person or legal entity that provides and preserves digital certificates for the creation and validation of electronic signatures and authentication of signatories and websites. They play a crucial role in ensuring the integrity and non-repudiation of electronic signing processes, as required by regulations such as eIDAS in the European Union and Switzerland. Trust service providers are responsible for strong authentication mechanisms, electronic signatures, digital certificates, time stamps, and the preservation of electronic signatures and related certificates.",
      "context": "Trust service provider\n\n==Introduction==\nA trust service provider (TSP) is a person or legal entity providing and preserving digital certificates to create and validate electronic signatures and to authenticate their signatories as well as websites in general. Trust service providers are qualified certificate authorities required in the European Union and in Switzerland in the context of regulated electronic signing procedures.\n\n== Description ==\nThe trust service provider has the responsibility to assure the integrity of electronic identification for signatories and services through strong mechanisms for authentication, electronic signatures and digital certificates. eIDAS defines the standards for how trust service providers are to perform their services of authentication and non-repudiation. The regulation provides guidance to EU member states on how trust service providers shall be regulated and recognized.\nA trust service is defined as an electronic service that entails one of three possible actions. First it may concern the creation, the verification or the validation of electronic signatures, as well as time stamps or seals, electronically registered delivery services and certifications that are required with these services. The second action entails the creation, the verification as well as the validation of certificates that are used to authenticate websites. The third action is the preservation of these electronic signatures, the seals or the related certificates.\nTo be elevated to the level of a qualified trust service, the service must meet the requirements set under the eIDAS Regulation. Trust services provide a trust framework that facilitates continued relations for electronic transactions that are conducted between participating EU member states and organizations.\n\n== Role of a qualified trust service provider ==\nThe qualified trust service provider plays an important role in the process of qualified electronic signing. The trust service providers must be given qualified status and permission for a supervisory government body to provide qualified digital certificates which can be used to create qualified electronic signatures. eIDAS requires that the EU will maintain an EU Trust List that lists the providers and services that have received qualified status. A trust service provider is not entitled to provide qualified trust services if they are not on the EU Trust List.Trust service providers that are on the EU Trust List are required to follow the strict guidelines established under eIDAS. They need to provide stamps valid in time and date, when creating certificates. Signatures that have expired certificates need to be revoked immediately. The EU obliges the trust service providers to deliver appropriate training for all personnel employed by the trust service provider. They shall further provide tools such as software and hardware that is trustworthy and capable of preventing forgeries of the certificates that are produced.\n\n== Vision ==\nOne of the major intents of eIDAS was to facilitate both public and business services, especially those that are conducted between parties across EU Member state borders. These transactions can now be safely expedited through the means of electronic signing and the services that are provided by trust service providers in regards to ensuring the integrity of those signatures.\nEU member states are required through eIDAS to establish \u201cpoints of single contact\u201d (PSCs) for trust services that ensure that electronic ID schemes can be used for cross-board public sector transactions, including the exchange and access of healthcare information across borders.\n\n== Legal perspective of electronic signatures created by trust service providers ==\nWhile an advanced electronic signature is legally binding under eIDAS, a qualified electronic signature which has been created by a qualified trust service provider carries a higher probative value when used as evidence in court. Because the signature's authorship is considered non-repudiable, the authenticity of the signature cannot be easily challenged. EU member states are obligated to accept qualified electronic signatures that have been created with qualified certificate from other Member states as valid. According to the eIDAS Regulation, i.e. Article 24 (2), a signature created with a qualified certificate has the same legal value as a handwritten signature in court.The standards are evolving. Additional standards including policy definitions for trust service providers are under development by the European Telecommunication Standards Institute ETSI.\n\n== Global perspective ==\nThe Swiss digital signing standard ZertES has defined a comparable concept of certificate service providers. Certificate service providers need to be audited by conformity assessment bodies that have been appointed by the Schweizerische Akkreditierungsstelle.\nIn the United States the NIST Digital Signature Standard (DSS) in its current release does not know anything comparable to a qualified trust service provider which would allow to enhance non-repudiation through the signatory's qualified certificate. However authors of the forthcoming review and commentators are publicly discussing an amendment similar to the eIDAS and ZertES approach of trusted service provision. To allow for stringent and non-repudiable global transactions and legal relevance, an international harmonization would be required.\n\n== Controversy ==\nSeveral research institutes and associations expressed their concern with respect to the establishment of a small group of centralized trust service providers per country which authenticate digital transactions. They state that this construct may have negative impact on privacy. Given the central role of trust service providers in many transactions, the Council of European Professional Informatics Societies (CEPIS) fears that trust service providers would gain and collect information of the distinguishing attributes of the citizens, which are subject of authentication. With regard to their requirement to preserve data and resulting expected efforts to keep evidence for potential liability requests on inaccurate ID, CEPIS sees the risk that trust service providers could create and store log entries of all authentication processes. The information gained allows for monitoring and for the profiling of the involved citizens. If the transaction counterpart also identifies himself, user interests and their communication behaviour will additionally sharpen the profiles gained. Big data analysis would allow for far-reaching insights into the citizens' privacy and relationships. The direct connection to the qualifying governmental bodies could allow those to gain access to the gained data and profiles.Another publication claims that to truly take advantage of the secure and seamless cross-border electronic transactions, assurance levels, definitions and technical deployment need to be specified more precisely.In 2021, relatively vague proposed updates to eIDAS would require browsers to pass on assurances from TSPs to their users. This would apparently involve the incorporation of government-specified TSPs in parallel with the existing multi-stakeholder processes used by browsers to establish trust in Certificate authorities. The Internet Society and Mozilla asserted a variety of issues with the proposals."
    }
  },
  {
    "instruction": "Write an answer to the following question: What encryption protocols are used by WPA and WPA2?",
    "context": "",
    "output": "WPA uses TKIP (Temporal Key Integrity Protocol), while WPA2 uses CCMP (CTR mode with CBC-MAC Protocol), which is based on the Advanced Encryption Standard (AES) and offers stronger protection for both privacy and integrity.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What encryption protocols are used by WPA and WPA2?",
      "answer": "WPA uses TKIP (Temporal Key Integrity Protocol), while WPA2 uses CCMP (CTR mode with CBC-MAC Protocol), which is based on the Advanced Encryption Standard (AES) and offers stronger protection for both privacy and integrity."
    }
  },
  {
    "instruction": "Context: IEC 62443\n\n==Introduction==\nIEC 62443 is an international series of standards that address cybersecurity for operational technology in automation and control systems. The standard is divided into different sections and describes both technical and process-related aspects of automation and control systems cybersecurity. \nIt divides the cybersecurity topics by stakeholder category / roles including: \n\nthe operator,\nthe service providers (service providers for integration and for maintenance)\nthe component/system manufacturers.The different roles each follow a risk-based approach to prevent and manage security risks in their activities.\n\n== Structure ==\nIEC 62443 Industrial communication networks - Network and system security series of standards is organized into four parts:\nGeneral: This part covers topics that are common to the entire series.\nPolicies and Procedures: This part focuses on methods and processes associated with IACS security.\nSystem: This part is about requirements at the system level.\nComponents and Requirements: This part provides detailed requirements for IACS products.The following table lists the parts of the IEC 62443 series of standards published to date with their status and title.\n\nPart 2-1: This part of the standard is aimed at operators of automation solutions and defines requirements for how security during the operation of plants is to be considered (see ISO/IEC 27001).\nPart 2-4: This part defines requirements (\"capabilities\") for integrators. These requirements are divided into 12 topics: Assurance, architecture, wireless, security engineering systems, configuration management, remote access, event management and logging, user management, malware protection, patch management, backup & recovery, and project staffing.\nPart 4-1: This part defines how a secure product development process should look like. It is divided into eight areas (\"Practices\"): management of development, definition of security requirements, design of security solutions, secure development, testing of security features, handling of security vulnerabilities, creation and publication of updates and documentation of security features.\nPart 4-2: This part defines technical requirements for products or components. Like the requirements for systems (Section -3-3), the requirements are divided into 12 subject areas and refer to them. In addition to the technical requirements, common component security constraints (CCSC) are defined, which must be met by components to be compliant with IEC 62443-4-2:\nCCSC 1 describes that components must take into account the general security characteristics of the system in which they are used.\nCCSC 2 specifies that the technical requirements that the component cannot meet itself can be met by compensating countermeasures at system level (see IEC 62443-3-3). For this purpose, the countermeasures must be described in the documentation of the component.\nCCSC 3 requires that the \"Least Privilege\" principle is applied in the component.\nCCSC 4 requires that the component is developed and supported by IEC 62443-4-1 compliant development processes.\n\n== Maturity and Security Level ==\nIEC 62443 describes different levels of maturity for processes and technical requirements. The maturity levels for processes are based on the maturity levels from the CMMI framework.\n\n\n*** Maturity Level ***\nBased on CMMI, IEC 62443 describes different maturity levels for processes through so-called \"maturity levels\". To fulfill a certain level of a maturity level, all process-related requirements must always be practiced during product development or integration, i.e. the selection of only individual criteria (\"cherry picking\") is not standard-compliant.\nThe maturity levels are described as follows:\n\nMaturity Level 1 - Initial: Product suppliers usually carry out product development ad hoc and often undocumented (or not fully documented).\nMaturity Level 2 - Managed: The product supplier is able to manage the development of a product according to written guidelines. It must be demonstrated that the personnel who carry out the process have the appropriate expertise, are trained and/or follow written procedures. The processes are repeatable.\nMaturity Level 3 - Defined (practiced): The process is repeatable throughout the supplier's organization. The processes have been practiced and there is evidence that this has been done.\nMaturity Level 4 - Improving: Product suppliers use appropriate process metrics to monitor the effectiveness and performance of the process and demonstrate continuous improvement in these areas.\n\n\n*** Security Level ***\nTechnical requirements for systems (IEC 62443-3-3) and products (IEC 62443-4-2) are evaluated in the standard by four so-called Security Levels (SL). The different levels indicate the resistance against different classes of attackers. The standard emphasizes that the levels should be evaluated per technical requirement (see IEC 62443-1-1) and are not suitable for the general classification of products.\nThe levels are:\n\nSecurity Level 0: No special requirement or protection required.\nSecurity Level 1: Protection against unintentional or accidental misuse.\nSecurity Level 2: Protection against intentional misuse by simple means with few resources, general skills and low motivation.\nSecurity Level 3: Protection against intentional misuse by sophisticated means with moderate resources, IACS-specific knowledge and moderate motivation.\nSecurity Level 4: Protection against intentional misuse using sophisticated means with extensive resources, IACS-specific knowledge and high motivation.\n\n== Concepts ==\nThe standard explains various basic principles that should be considered for all roles in all activities.\n\n\n*** Defense in depth ***\nDefense in Depth is a concept in which several levels of security (defense) are distributed throughout the system. The goal is to provide redundancy in case a security measure fails or a vulnerability is exploited.\n\n\n*** Zones and conduits ***\nZones divide a system into homogeneous zones by grouping the (logical or physical) assets with common security requirements. The security requirements are defined by Security Level (SL). The level required for a zone is determined by the risk analysis.\nZones have boundaries that separate the elements inside the zone from those outside. Information moves within and between zones. Zones can be divided into sub-zones that define different security levels (Security Level) and thus enable defense-in-depth.\nConduits group the elements that allow communication between two zones. They provide security functions that enable secure communication and allow the coexistence of zones with different security levels.\n\n== Certification to standards ==\nProcesses, systems and products used in industrial automation environments can be certified according to IEC 62443. Many testing, inspection, and certification (TIC) companies offer product and process certifications based on IEC 62443. By accrediting according to the ISO/IEC 17000 series of standards, the companies share a single, consistent set of certification requirements for IEC 62443 certifications which elevates the usefulness of the resulting certificates of conformance.\n\n\n*** Accredited certification schemes ***\nIEC 62443 certification schemes have been established by several global testing, inspection, and certification (TIC) companies. The schemes are based on the referenced standards and define test methods, surveillance audit policies, public documentation policies, and other specific aspects of their program. Cybersecurity certification programs for IEC 62443 standards are being offered globally by many recognized Certification Bodies (CB), including Bureau Veritas, Intertek, SGS-T\u00dcV Saar, T\u00dcV Nord, T\u00dcV Rheinland, T\u00dcV S\u00dcD and UL.\nA global infrastructure of national accreditation bodies (AB) ensures consistent evaluation of the IEC 62443. The ABs operate per the requirements of ISO/IEC 17011, a standard that contains requirements for the competence, consistency, and impartiality of accreditation bodies when accrediting conformity assessment bodies. ABs are members of the IAF for work in management systems, products, services, and personnel accreditation or the ILAC for laboratory accreditation. A Multilateral Recognition Arrangement (MLA) between ABs will ensure global recognition of accredited CBs.\nTIC companies are accredited by an AB to provide inspection according to the ISO/IEC 17020, testing laboratories according to ISO/IEC 17025 and certification of products, processes, and services according to ISO/IEC 17065.\n\n\n*** IECEE CB Scheme ***\nThe IEC System for Conformity Assessment Schemes for Electrotechnical Equipment and Components (IECEE) Certification Body Scheme (CB Scheme) is a multilateral agreement that facilitates market access for manufacturers of electrical and electronic products. Under the CB Scheme processes, products and systems can be certified according to IEC 62443.\nThe origin of the CB Scheme comes from the CEE (former European \"Commission for Conformity Testing of Electrical Equipment\") and was integrated into the IEC in 1985. Currently, 54 Member Bodies are in the IECEE, 88 NCBs (National Certification Bodies), and 534 CB Test Laboratories (CBTL). In the field of product certification, this procedure is used to reduce the complexity in the approval procedure for manufacturers of products tested and certified according to harmonized standards. A product that has been tested by a CBTL (certified testing laboratory) according to a harmonized standard such as the IEC 62443, can use the CB report as a basis for a later national certification and approval such as GS, PSE, CCC, NOM, GOST/R, BSMI.\n\n\n*** ISCI ISASecure ***\nThe ISA Security Compliance Institute (ISCI), a subsidiary of the ISA, created a proprietary conformity assessment scheme aligned with the IEC 62443 standards. This scheme is used to certify industrial automation control systems, components and processes. Companies certifying to the ISASecure certification scheme are accredited to the ISASecure technical readiness requirements and have their Test Laboratories and Certification Body accredited to the ISO 17025 and ISO 17065 standards, respectively.\nThe ISCI offers multiple certifications under the ISASecure brand:\n\nSSA (System Security Assurance) certification of systems according to IEC 62443-3-3 and IEC 62443-4-1\nCSA (Component Security Assurance) certification of automation components according to IEC 62443-4-1 and IEC 62443-4-2\nSDLA (Secure Development Lifecycle Assurance) certification of automation systems development organizations according to the IEC 62443-4-1\nEDSA (Embedded Device Security Assurance) certification of components based on the IEC 62443-4-2. This certification was offered in 2010 and phased out when the IEC 62443-4-2 standard was formally approved and published in 2018.\nAnswer this question: What is the role of Accredited Certification Schemes in IEC 62443?",
    "context": "",
    "output": "Accredited Certification Schemes in IEC 62443 ensure consistent evaluation of the standard. These schemes are based on the referenced standards and define test methods, surveillance audit policies, public documentation policies, and other specific aspects of their program.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of Accredited Certification Schemes in IEC 62443?",
      "answer": "Accredited Certification Schemes in IEC 62443 ensure consistent evaluation of the standard. These schemes are based on the referenced standards and define test methods, surveillance audit policies, public documentation policies, and other specific aspects of their program.",
      "context": "IEC 62443\n\n==Introduction==\nIEC 62443 is an international series of standards that address cybersecurity for operational technology in automation and control systems. The standard is divided into different sections and describes both technical and process-related aspects of automation and control systems cybersecurity. \nIt divides the cybersecurity topics by stakeholder category / roles including: \n\nthe operator,\nthe service providers (service providers for integration and for maintenance)\nthe component/system manufacturers.The different roles each follow a risk-based approach to prevent and manage security risks in their activities.\n\n== Structure ==\nIEC 62443 Industrial communication networks - Network and system security series of standards is organized into four parts:\nGeneral: This part covers topics that are common to the entire series.\nPolicies and Procedures: This part focuses on methods and processes associated with IACS security.\nSystem: This part is about requirements at the system level.\nComponents and Requirements: This part provides detailed requirements for IACS products.The following table lists the parts of the IEC 62443 series of standards published to date with their status and title.\n\nPart 2-1: This part of the standard is aimed at operators of automation solutions and defines requirements for how security during the operation of plants is to be considered (see ISO/IEC 27001).\nPart 2-4: This part defines requirements (\"capabilities\") for integrators. These requirements are divided into 12 topics: Assurance, architecture, wireless, security engineering systems, configuration management, remote access, event management and logging, user management, malware protection, patch management, backup & recovery, and project staffing.\nPart 4-1: This part defines how a secure product development process should look like. It is divided into eight areas (\"Practices\"): management of development, definition of security requirements, design of security solutions, secure development, testing of security features, handling of security vulnerabilities, creation and publication of updates and documentation of security features.\nPart 4-2: This part defines technical requirements for products or components. Like the requirements for systems (Section -3-3), the requirements are divided into 12 subject areas and refer to them. In addition to the technical requirements, common component security constraints (CCSC) are defined, which must be met by components to be compliant with IEC 62443-4-2:\nCCSC 1 describes that components must take into account the general security characteristics of the system in which they are used.\nCCSC 2 specifies that the technical requirements that the component cannot meet itself can be met by compensating countermeasures at system level (see IEC 62443-3-3). For this purpose, the countermeasures must be described in the documentation of the component.\nCCSC 3 requires that the \"Least Privilege\" principle is applied in the component.\nCCSC 4 requires that the component is developed and supported by IEC 62443-4-1 compliant development processes.\n\n== Maturity and Security Level ==\nIEC 62443 describes different levels of maturity for processes and technical requirements. The maturity levels for processes are based on the maturity levels from the CMMI framework.\n\n\n*** Maturity Level ***\nBased on CMMI, IEC 62443 describes different maturity levels for processes through so-called \"maturity levels\". To fulfill a certain level of a maturity level, all process-related requirements must always be practiced during product development or integration, i.e. the selection of only individual criteria (\"cherry picking\") is not standard-compliant.\nThe maturity levels are described as follows:\n\nMaturity Level 1 - Initial: Product suppliers usually carry out product development ad hoc and often undocumented (or not fully documented).\nMaturity Level 2 - Managed: The product supplier is able to manage the development of a product according to written guidelines. It must be demonstrated that the personnel who carry out the process have the appropriate expertise, are trained and/or follow written procedures. The processes are repeatable.\nMaturity Level 3 - Defined (practiced): The process is repeatable throughout the supplier's organization. The processes have been practiced and there is evidence that this has been done.\nMaturity Level 4 - Improving: Product suppliers use appropriate process metrics to monitor the effectiveness and performance of the process and demonstrate continuous improvement in these areas.\n\n\n*** Security Level ***\nTechnical requirements for systems (IEC 62443-3-3) and products (IEC 62443-4-2) are evaluated in the standard by four so-called Security Levels (SL). The different levels indicate the resistance against different classes of attackers. The standard emphasizes that the levels should be evaluated per technical requirement (see IEC 62443-1-1) and are not suitable for the general classification of products.\nThe levels are:\n\nSecurity Level 0: No special requirement or protection required.\nSecurity Level 1: Protection against unintentional or accidental misuse.\nSecurity Level 2: Protection against intentional misuse by simple means with few resources, general skills and low motivation.\nSecurity Level 3: Protection against intentional misuse by sophisticated means with moderate resources, IACS-specific knowledge and moderate motivation.\nSecurity Level 4: Protection against intentional misuse using sophisticated means with extensive resources, IACS-specific knowledge and high motivation.\n\n== Concepts ==\nThe standard explains various basic principles that should be considered for all roles in all activities.\n\n\n*** Defense in depth ***\nDefense in Depth is a concept in which several levels of security (defense) are distributed throughout the system. The goal is to provide redundancy in case a security measure fails or a vulnerability is exploited.\n\n\n*** Zones and conduits ***\nZones divide a system into homogeneous zones by grouping the (logical or physical) assets with common security requirements. The security requirements are defined by Security Level (SL). The level required for a zone is determined by the risk analysis.\nZones have boundaries that separate the elements inside the zone from those outside. Information moves within and between zones. Zones can be divided into sub-zones that define different security levels (Security Level) and thus enable defense-in-depth.\nConduits group the elements that allow communication between two zones. They provide security functions that enable secure communication and allow the coexistence of zones with different security levels.\n\n== Certification to standards ==\nProcesses, systems and products used in industrial automation environments can be certified according to IEC 62443. Many testing, inspection, and certification (TIC) companies offer product and process certifications based on IEC 62443. By accrediting according to the ISO/IEC 17000 series of standards, the companies share a single, consistent set of certification requirements for IEC 62443 certifications which elevates the usefulness of the resulting certificates of conformance.\n\n\n*** Accredited certification schemes ***\nIEC 62443 certification schemes have been established by several global testing, inspection, and certification (TIC) companies. The schemes are based on the referenced standards and define test methods, surveillance audit policies, public documentation policies, and other specific aspects of their program. Cybersecurity certification programs for IEC 62443 standards are being offered globally by many recognized Certification Bodies (CB), including Bureau Veritas, Intertek, SGS-T\u00dcV Saar, T\u00dcV Nord, T\u00dcV Rheinland, T\u00dcV S\u00dcD and UL.\nA global infrastructure of national accreditation bodies (AB) ensures consistent evaluation of the IEC 62443. The ABs operate per the requirements of ISO/IEC 17011, a standard that contains requirements for the competence, consistency, and impartiality of accreditation bodies when accrediting conformity assessment bodies. ABs are members of the IAF for work in management systems, products, services, and personnel accreditation or the ILAC for laboratory accreditation. A Multilateral Recognition Arrangement (MLA) between ABs will ensure global recognition of accredited CBs.\nTIC companies are accredited by an AB to provide inspection according to the ISO/IEC 17020, testing laboratories according to ISO/IEC 17025 and certification of products, processes, and services according to ISO/IEC 17065.\n\n\n*** IECEE CB Scheme ***\nThe IEC System for Conformity Assessment Schemes for Electrotechnical Equipment and Components (IECEE) Certification Body Scheme (CB Scheme) is a multilateral agreement that facilitates market access for manufacturers of electrical and electronic products. Under the CB Scheme processes, products and systems can be certified according to IEC 62443.\nThe origin of the CB Scheme comes from the CEE (former European \"Commission for Conformity Testing of Electrical Equipment\") and was integrated into the IEC in 1985. Currently, 54 Member Bodies are in the IECEE, 88 NCBs (National Certification Bodies), and 534 CB Test Laboratories (CBTL). In the field of product certification, this procedure is used to reduce the complexity in the approval procedure for manufacturers of products tested and certified according to harmonized standards. A product that has been tested by a CBTL (certified testing laboratory) according to a harmonized standard such as the IEC 62443, can use the CB report as a basis for a later national certification and approval such as GS, PSE, CCC, NOM, GOST/R, BSMI.\n\n\n*** ISCI ISASecure ***\nThe ISA Security Compliance Institute (ISCI), a subsidiary of the ISA, created a proprietary conformity assessment scheme aligned with the IEC 62443 standards. This scheme is used to certify industrial automation control systems, components and processes. Companies certifying to the ISASecure certification scheme are accredited to the ISASecure technical readiness requirements and have their Test Laboratories and Certification Body accredited to the ISO 17025 and ISO 17065 standards, respectively.\nThe ISCI offers multiple certifications under the ISASecure brand:\n\nSSA (System Security Assurance) certification of systems according to IEC 62443-3-3 and IEC 62443-4-1\nCSA (Component Security Assurance) certification of automation components according to IEC 62443-4-1 and IEC 62443-4-2\nSDLA (Secure Development Lifecycle Assurance) certification of automation systems development organizations according to the IEC 62443-4-1\nEDSA (Embedded Device Security Assurance) certification of components based on the IEC 62443-4-2. This certification was offered in 2010 and phased out when the IEC 62443-4-2 standard was formally approved and published in 2018."
    }
  },
  {
    "instruction": "Index of cryptography articles\n\n==Introduction==\nArticles related to cryptography include:\n\n\n\n== A ==\nA5/1   \u2022\nA5/2   \u2022\nABA digital signature guidelines   \u2022\nABC (stream cipher)   \u2022\nAbraham Sinkov   \u2022\nAcoustic cryptanalysis   \u2022\nAdaptive chosen-ciphertext attack   \u2022\nAdaptive chosen plaintext and chosen ciphertext attack   \u2022\nAdvantage (cryptography)   \u2022\nADFGVX cipher   \u2022\nAdi Shamir   \u2022\nAdvanced Access Content System   \u2022\nAdvanced Encryption Standard   \u2022\nAdvanced Encryption Standard process   \u2022\nAdversary   \u2022\nAEAD block cipher modes of operation   \u2022\nAffine cipher   \u2022\nAgnes Meyer Driscoll   \u2022\nAKA (security)   \u2022\nAkelarre (cipher)   \u2022\nAlan Turing   \u2022\nAlastair Denniston   \u2022\nAl Bhed language   \u2022\nAlex Biryukov   \u2022\nAlfred Menezes   \u2022\nAlgebraic Eraser   \u2022\nAlgorithmically random sequence   \u2022\nAlice and Bob   \u2022\nAll-or-nothing transform   \u2022\nAlphabetum Kaldeorum   \u2022\nAlternating step generator   \u2022\nAmerican Cryptogram Association   \u2022\nAN/CYZ-10   \u2022\nAnonymous publication   \u2022\nAnonymous remailer   \u2022\nAntoni Palluth   \u2022\nAnubis (cipher)   \u2022\nArgon2   \u2022\nARIA (cipher)   \u2022\nArlington Hall   \u2022\nArne Beurling   \u2022\nArnold Cipher   \u2022\nArray controller based encryption   \u2022\nArthur Scherbius   \u2022\nArvid Gerhard Damm   \u2022\nAsiacrypt   \u2022\nAtbash   \u2022\nAttribute-based encryption   \u2022\nAttack model   \u2022\nAuguste Kerckhoffs   \u2022\nAuthenticated encryption   \u2022\nAuthentication   \u2022\nAuthorization certificate   \u2022\nAutokey cipher   \u2022\nAvalanche effect\n\n== B ==\nB-Dienst   \u2022\nBabington Plot   \u2022\nBaby-step giant-step   \u2022\nBacon's cipher   \u2022\nBanburismus   \u2022\nBart Preneel   \u2022\nBaseKing   \u2022\nBassOmatic   \u2022\nBATON   \u2022\nBB84   \u2022\nBeale ciphers   \u2022\nBEAR and LION ciphers   \u2022\nBeaufort cipher   \u2022\nBeaumanor Hall   \u2022\nBent function   \u2022\nBerlekamp\u2013Massey algorithm   \u2022\nBernstein v. United States   \u2022\nBestCrypt   \u2022\nBiclique attack   \u2022\nBID/60   \u2022\nBID 770   \u2022\nBifid cipher   \u2022\nBill Weisband   \u2022\nBinary Goppa code   \u2022\nBiometric word list   \u2022\nBirthday attack   \u2022\nBit-flipping attack   \u2022\nBitTorrent protocol encryption   \u2022\nBiuro Szyfr\u00f3w   \u2022\nBlack Chamber   \u2022\nBlaise de Vigen\u00e8re   \u2022\nBletchley Park   \u2022\nBlind credential   \u2022\nBlinding (cryptography)   \u2022\nBlind signature   \u2022\nBlock cipher   \u2022\nBlock cipher mode of operation   \u2022\nBlock size (cryptography)   \u2022\nBlowfish (cipher)   \u2022\nBlum Blum Shub   \u2022\nBlum\u2013Goldwasser cryptosystem   \u2022\nBomba (cryptography)   \u2022\nBombe   \u2022\nBook cipher   \u2022\nBooks on cryptography   \u2022\nBoomerang attack   \u2022\nBoris Hagelin   \u2022\nBouncy Castle (cryptography)   \u2022\nBroadcast encryption   \u2022\nBruce Schneier   \u2022\nBrute-force attack   \u2022\nBrute Force: Cracking the Data Encryption Standard   \u2022\nBurrows\u2013Abadi\u2013Needham logic   \u2022\nBurt Kaliski\n\n== C ==\nC2Net   \u2022\nC-36 (cipher machine)   \u2022\nC-52 (cipher machine)   \u2022\nCaesar cipher   \u2022\nCamellia (cipher)   \u2022\nCAPICOM   \u2022\nCapstone (cryptography)   \u2022\nCardan grille   \u2022\nCard catalog (cryptology)   \u2022\nCarlisle Adams   \u2022\nCAST-128   \u2022\nCAST-256   \u2022\nCayley\u2013Purser algorithm   \u2022\nCBC-MAC   \u2022\nCCM mode   \u2022\nCCMP   \u2022\nCD-57   \u2022\nCDMF   \u2022\nCellular Message Encryption Algorithm   \u2022\nCentiban   \u2022\nCentral Security Service   \u2022\nCentre for Applied Cryptographic Research   \u2022\nCentral Bureau   \u2022\nCerticom   \u2022\nCertificate authority   \u2022\nCertificate-based encryption   \u2022\nCertificateless cryptography   \u2022\nCertificate revocation list   \u2022\nCertificate signing request   \u2022\nCertification path validation algorithm   \u2022\nChaffing and winnowing   \u2022\nChallenge-Handshake Authentication Protocol   \u2022\nChallenge\u2013response authentication   \u2022\nChosen-ciphertext attack   \u2022\nChosen-plaintext attack   \u2022\nCIKS-1   \u2022\nCipher disk   \u2022\nCipher runes   \u2022\nCipher security summary   \u2022\nCipherSaber   \u2022\nCiphertext expansion   \u2022\nCiphertext indistinguishability   \u2022\nCiphertext-only attack   \u2022\nCiphertext stealing   \u2022\nCIPHERUNICORN-A   \u2022\nCIPHERUNICORN-E   \u2022\nClassical cipher   \u2022\nClaude Shannon   \u2022\nClaw-free permutation   \u2022\nCleartext   \u2022\nCLEFIA   \u2022\nClifford Cocks   \u2022\nClipper chip   \u2022\nClock (cryptography)   \u2022\nClock drift   \u2022\nCMVP   \u2022\nCOCONUT98   \u2022\nCodebook   \u2022\nCode (cryptography)   \u2022\nCode talker   \u2022\nCodress message   \u2022\nCold boot attack   \u2022\nCollision attack   \u2022\nCollision resistance   \u2022\nColossus computer   \u2022\nCombined Cipher Machine   \u2022\nCommitment scheme   \u2022\nCommon Scrambling Algorithm   \u2022\nCommunications security   \u2022\nCommunications Security Establishment   \u2022\nCommunication Theory of Secrecy Systems   \u2022\nComparison of disk encryption software   \u2022\nComparison of SSH clients   \u2022\nCompleteness (cryptography)   \u2022\nComplexity trap   \u2022\nComputational Diffie\u2013Hellman assumption   \u2022\nComputational hardness assumption   \u2022\nComputer insecurity   \u2022\nComputer and network surveillance   \u2022\nCOMSEC equipment   \u2022\nConch (SSH)   \u2022\nConcrete security   \u2022\nConel Hugh O'Donel Alexander   \u2022\nConfidentiality   \u2022\nConfusion and diffusion   \u2022\nContent-scrambling system   \u2022\nControlled Cryptographic Item   \u2022\nCorkscrew (program)   \u2022\nCorrelation immunity   \u2022\nCOSIC   \u2022\nCovert channel   \u2022\nCover (telecommunications)   \u2022\nCrab (cipher)   \u2022\nCramer\u2013Shoup cryptosystem   \u2022\nCRAM-MD5   \u2022\nCRHF   \u2022\nCrib (cryptanalysis)   \u2022\nCrossCrypt   \u2022\nCrowds (anonymity network)   \u2022\nCrypt (C)   \u2022\nCryptanalysis   \u2022\nCryptanalysis of the Enigma   \u2022\nCryptanalysis of the Lorenz cipher   \u2022\nCryptanalytic computer   \u2022\nCryptex   \u2022\nCryptico   \u2022\nCrypto AG   \u2022\nCrypto-anarchism   \u2022\nCrypto API (Linux)   \u2022\nMicrosoft CryptoAPI   \u2022\nCryptoBuddy   \u2022\nCryptochannel   \u2022\nCRYPTO (conference)   \u2022\nCryptogram   \u2022\nCryptographically Generated Address   \u2022\nCryptographically secure pseudorandom number generator   \u2022\nCryptographically strong   \u2022\nCryptographic Application Programming Interface   \u2022\nCryptographic hash function   \u2022\nCryptographic key types   \u2022\nCryptographic Message Syntax   \u2022\nCryptographic primitive   \u2022\nCryptographic protocol   \u2022\nCryptographic Service Provider   \u2022\nCryptographie ind\u00e9chiffrable   \u2022\nCryptography   \u2022\nCryptography in Japan   \u2022\nCryptography newsgroups   \u2022\nCryptography standards   \u2022\nCrypto: How the Code Rebels Beat the Government\u2014Saving Privacy in the Digital Age   \u2022\nCryptologia   \u2022\nCryptology ePrint Archive   \u2022\nCryptology Research Society of India   \u2022\nCryptomathic   \u2022\nCryptome   \u2022\nCryptomeria cipher   \u2022\nCryptonomicon   \u2022\nCrypTool   \u2022\nCrypto phone   \u2022\nCrypto-society   \u2022\nCryptosystem   \u2022\nCryptovirology   \u2022\nCRYPTREC   \u2022\nCS-Cipher   \u2022\nCurve25519   \u2022 Curve448   \u2022 Custom hardware attack   \u2022\nCycles per byte   \u2022\nCyclometer   \u2022\nCypherpunk   \u2022\nCyrillic Projector\n\n== D ==\nD'Agapeyeff cipher   \u2022\nDaniel J. Bernstein   \u2022\nData Authentication Algorithm   \u2022\nData Encryption Standard   \u2022\nDatagram Transport Layer Security   \u2022\nDavid Chaum   \u2022\nDavid Kahn   \u2022\nDavid Naccache   \u2022\nDavid Wagner   \u2022\nDavid Wheeler (computer scientist)   \u2022\nDavies attack   \u2022\nDavies\u2013Meyer hash   \u2022\nDEAL   \u2022\nDecipherment   \u2022\nDecisional Diffie\u2013Hellman assumption   \u2022\nDecorrelation theory   \u2022\nDecrypt   \u2022\nDeCSS   \u2022\nDefence Signals Directorate   \u2022\nDegree of anonymity   \u2022\nDelegated Path Discovery   \u2022\nDelegated Path Validation   \u2022\nDeniable encryption   \u2022\nDerek Taunt   \u2022\nDerived unique key per transaction   \u2022\nDES Challenges   \u2022\nDES supplementary material   \u2022\nDES-X   \u2022\nDeterministic encryption   \u2022\nDFC (cipher)   \u2022\nDictionary attack   \u2022\nDifferential cryptanalysis   \u2022\nDifferential-linear attack   \u2022\nDifferential power analysis   \u2022\nDiffie\u2013Hellman key exchange   \u2022\nDiffie\u2013Hellman problem   \u2022\nDigiCipher 2   \u2022\nDigital Fortress   \u2022\nDigital rights management   \u2022\nDigital signature   \u2022\nDigital Signature Algorithm   \u2022\nDigital signature forgery   \u2022\nDigital timestamping   \u2022\nDigital watermarking   \u2022\nDilly Knox   \u2022\nDining cryptographers problem   \u2022\nDiplomatic bag   \u2022\nDirect Anonymous Attestation   \u2022\nDiscrete logarithm   \u2022\nDisk encryption   \u2022\nDisk encryption hardware   \u2022\nDisk encryption software   \u2022\nDistance-bounding protocol   \u2022\nDistinguishing attack   \u2022\nDistributed.net   \u2022\nDMA attack   \u2022\ndm-crypt   \u2022\nDmitry Sklyarov   \u2022\nDomainKeys   \u2022\nDon Coppersmith   \u2022\nDorabella Cipher   \u2022\nDouble Ratchet Algorithm   \u2022\nDoug Stinson   \u2022\nDragon (cipher)   \u2022\nDRYAD   \u2022\nDual_EC_DRBG   \u2022\n\n== E ==\nE0 (cipher)   \u2022\nE2 (cipher)   \u2022\nE4M   \u2022\nEAP-AKA   \u2022\nEAP-SIM   \u2022\nEAX mode   \u2022\nECC patents   \u2022\nECHELON   \u2022\nECRYPT   \u2022\nEdouard Fleissner von Wostrowitz   \u2022\nEdward Hebern   \u2022\nEdward Scheidt   \u2022\nEdward Travis   \u2022\nEFF DES cracker   \u2022\nEfficient Probabilistic Public-Key Encryption Scheme   \u2022\nEKMS   \u2022\nElectronic Communications Act 2000   \u2022\nElectronic money   \u2022\nElectronic signature   \u2022\nElectronic voting   \u2022\nElGamal encryption   \u2022\nElGamal signature scheme   \u2022\nEli Biham   \u2022\nElizebeth Friedman   \u2022\nElliptic-curve cryptography   \u2022\nElliptic-curve Diffie\u2013Hellman   \u2022\nElliptic Curve DSA   \u2022 EdDSA   \u2022 Elliptic curve only hash   \u2022\nElonka Dunin   \u2022\nEncrypted function   \u2022\nEncrypted key exchange   \u2022\nEncrypting File System   \u2022\nEncryption   \u2022\nEncryption software   \u2022\nEnigmail   \u2022\nEnigma machine   \u2022\nEnigma rotor details   \u2022\nEntrust   \u2022\nErnst Fetterlein   \u2022\neSTREAM   \u2022\n\u00c9tienne Bazeries   \u2022\nEurocrypt   \u2022\nEuroCrypt   \u2022\nExport of cryptography   \u2022\nExtensible Authentication Protocol\n\n== F ==\nFast Software Encryption   \u2022\nFast syndrome-based hash   \u2022\nFEA-M   \u2022\nFEAL   \u2022\nFeige\u2013Fiat\u2013Shamir identification scheme   \u2022\nFeistel cipher   \u2022\nF\u00e9lix Delastelle   \u2022\nFialka   \u2022\nFilesystem-level encryption   \u2022\nFileVault   \u2022\nFill device   \u2022\nFinancial cryptography   \u2022\nFIPS 140   \u2022\nFIPS 140-2   \u2022\nFirefly (key exchange protocol)   \u2022\nFISH (cipher)   \u2022\nFish (cryptography)   \u2022\nFloradora   \u2022\nFluhrer, Mantin and Shamir attack   \u2022\nFormat-preserving encryption   \u2022\nFortezza   \u2022\nFort George G. Meade   \u2022\nFortuna (PRNG)   \u2022\nFour-square cipher   \u2022\nFranciszek Pokorny   \u2022\nFrank A. Stevenson   \u2022\nFrank Rowlett   \u2022\nFreenet   \u2022\nFreeOTFE   \u2022\nFreeS/WAN   \u2022\nFrequency analysis   \u2022\nFriedrich Kasiski   \u2022\nFritz-chip   \u2022\nFROG   \u2022\nFROSTBURG   \u2022\nFTP over SSH   \u2022\nFull disk encryption   \u2022\nFull Domain Hash   \u2022\nF. W. Winterbotham\n\n== G ==\nGalois/Counter Mode   \u2022\nGardening (cryptanalysis)   \u2022\nGCHQ Bude   \u2022\nGCHQ CSO Morwenstow   \u2022\nGDES   \u2022\nGeneric Security Services Application Program Interface   \u2022\nGeorge Blakley   \u2022\nGeorge Scovell   \u2022\nGGH encryption scheme   \u2022\nGGH signature scheme   \u2022\nGilbert Vernam   \u2022\nGMR (cryptography)   \u2022\nGNU Privacy Guard   \u2022\nGnuTLS   \u2022\nGoldwasser\u2013Micali cryptosystem   \u2022\nGordon Welchman   \u2022\nGOST (block cipher)   \u2022\nGOST (hash function)   \u2022\nGovernment Communications Headquarters   \u2022\nGovernment Communications Security Bureau   \u2022\nGrain (cipher)   \u2022\nGrand Cru (cipher)   \u2022\nGreat Cipher   \u2022\nGrill (cryptology)   \u2022\nGrille (cryptography)   \u2022\nGroup-based cryptography   \u2022\nGroup signature   \u2022\nGrover's algorithm   \u2022\nGustave Bertrand   \u2022\nGwido Langer\n\n== H ==\nH.235   \u2022\nHAIFA construction   \u2022\nHAIPE   \u2022\nHans Dobbertin   \u2022\nHans-Thilo Schmidt   \u2022\nHard-core predicate   \u2022\nHardware random number generator   \u2022\nHardware security module   \u2022\nHarold Keen   \u2022\nHarry Hinsley   \u2022\nHarvest (computer)   \u2022\nHAS-160   \u2022\nHash-based cryptography   \u2022\nHashcash   \u2022\nHash chain   \u2022\nHash function security summary   \u2022\nHash list   \u2022\nHasty Pudding cipher   \u2022\nHAVAL   \u2022\nHC-256   \u2022\nHC-9   \u2022\nHeath Robinson (codebreaking machine)   \u2022\nHebern rotor machine   \u2022\nHenri Braqueni\u00e9   \u2022\nHenryk Zygalski   \u2022\nHerbert Yardley   \u2022\nHidden Field Equations   \u2022\nHideki Imai   \u2022\nHierocrypt   \u2022\nHigh-bandwidth Digital Content Protection   \u2022\nHigher-order differential cryptanalysis   \u2022\nHill cipher   \u2022\nHistory of cryptography   \u2022\nHMAC   \u2022\nHMAC-based One-time Password algorithm   (HOTP) \u2022\nHorst Feistel   \u2022\nHoward Heys   \u2022\nHttps   \u2022\nHugo Hadwiger   \u2022\nHugo Koch   \u2022\nHushmail   \u2022\nHut 6   \u2022\nHut 8   \u2022\nHX-63   \u2022\nHybrid cryptosystem   \u2022\nHyperelliptic curve cryptography   \u2022\nHyper-encryption\n\n== I ==\nIan Goldberg   \u2022\nIBM 4758   \u2022\nICE (cipher)   \u2022\nID-based cryptography   \u2022\nIDEA NXT   \u2022\nIdentification friend or foe   \u2022\nIEEE 802.11i   \u2022\nIEEE P1363   \u2022\nI. J. Good   \u2022\nIllegal prime   \u2022\nImpossible differential cryptanalysis   \u2022\nIndex of coincidence   \u2022\nIndifferent chosen-ciphertext attack   \u2022\nIndistinguishability obfuscation   \u2022\nIndocrypt   \u2022\nInformation leakage   \u2022\nInformation Security Group   \u2022\nInformation-theoretic security   \u2022\nInitialization vector   \u2022\nInteger factorization   \u2022\nIntegral cryptanalysis   \u2022\nIntegrated Encryption Scheme   \u2022\nIntegrated Windows Authentication   \u2022\nInterlock protocol   \u2022\nIntermediate certificate authorities   \u2022\nInternational Association for Cryptologic Research   \u2022\nInternational Data Encryption Algorithm   \u2022\nInternet Key Exchange   \u2022\nInternet Security Association and Key Management Protocol   \u2022\nInterpolation attack   \u2022\nInvisible ink   \u2022\nIPsec   \u2022\nIraqi block cipher   \u2022\nISAAC (cipher)   \u2022\nISO 19092-2   \u2022\nISO/IEC 9797   \u2022\nIvan Damg\u00e5rd\n\n== J ==\nJacques Stern   \u2022\nJADE (cypher machine)   \u2022\nJames Gillogly   \u2022\nJames H. Ellis   \u2022\nJames Massey   \u2022\nJan Grali\u0144ski   \u2022\nJan Kowalewski   \u2022\nJapanese naval codes   \u2022\nJava Cryptography Architecture   \u2022\nJefferson disk   \u2022\nJennifer Seberry   \u2022\nJerzy R\u00f3\u017cycki   \u2022\nJoan Daemen   \u2022\nJohannes Trithemius   \u2022\nJohn Herivel   \u2022\nJohn Kelsey (cryptanalyst)   \u2022\nJohn R. F. Jeffreys   \u2022\nJohn Tiltman   \u2022\nJon Lech Johansen   \u2022\nJosef Pieprzyk   \u2022\nJoseph Desch   \u2022\nJoseph Finnegan (cryptographer)   \u2022\nJoseph Mauborgne   \u2022\nJoseph Rochefort   \u2022\nJournal of Cryptology   \u2022\nJunger v. Daley\n\n== K ==\nKaisa Nyberg   \u2022\nKalyna (cipher)   \u2022\nKasiski examination   \u2022\nKASUMI   \u2022\nKCDSA   \u2022\nKeePass   \u2022\nKerberos (protocol)   \u2022\nKerckhoffs's principle   \u2022\nKevin McCurley (cryptographer)   \u2022\nKey-agreement protocol   \u2022\nKey authentication   \u2022\nKey clustering   \u2022\nKey (cryptography)   \u2022\nKey derivation function   \u2022\nKey distribution center   \u2022\nKey escrow   \u2022\nKey exchange   \u2022\nKeyfile   \u2022\nKey generation   \u2022\nKey generator   \u2022\nKey management   \u2022\nKey-recovery attack   \u2022\nKey schedule   \u2022\nKey server (cryptographic)   \u2022\nKey signature (cryptography)   \u2022\nKeysigning   \u2022\nKey signing party   \u2022\nKey size   \u2022\nKey space (cryptography)   \u2022\nKeystream   \u2022\nKey stretching   \u2022\nKey whitening   \u2022\nKG-84   \u2022\nKHAZAD   \u2022\nKhufu and Khafre   \u2022\nKiss (cryptanalysis)   \u2022\nKL-43   \u2022\nKL-51   \u2022\nKL-7   \u2022\nKleptography   \u2022\nKN-Cipher   \u2022\nKnapsack problem   \u2022\nKnown-key distinguishing attack   \u2022\nKnown-plaintext attack   \u2022\nKnownSafe   \u2022\nKOI-18   \u2022\nKOV-14   \u2022\nKryha   \u2022\nKryptos   \u2022\nKSD-64   \u2022\nKupyna   \u2022\nKuznyechik   \u2022\nKW-26   \u2022\nKW-37   \u2022\nKY-3   \u2022\nKY-57   \u2022\nKY-58   \u2022\nKY-68   \u2022\nKYK-13\n\n== L ==\nLacida   \u2022\nLadder-DES   \u2022\nLamport signature   \u2022\nLars Knudsen   \u2022\nLattice-based cryptography   \u2022\nLaurance Safford   \u2022\nLawrie Brown   \u2022\nLCS35   \u2022\nLeo Marks   \u2022\nLeonard Adleman   \u2022\nLeon Battista Alberti   \u2022\nLeo Rosen   \u2022\nLeslie Yoxall   \u2022\nLEVIATHAN (cipher)   \u2022\nLEX (cipher)   \u2022\nLibelle (cipher)   \u2022\nLinear cryptanalysis   \u2022\nLinear-feedback shift register   \u2022\nLink encryption   \u2022\nList of ciphertexts   \u2022\nList of cryptographers   \u2022\nList of cryptographic file systems   \u2022\nList of cryptographic key types   \u2022\nList of cryptology conferences   \u2022\nList of telecommunications encryption terms   \u2022 List of people associated with Bletchley Park \u2022 \n  List of SFTP clients   \u2022\nList of SFTP server software   \u2022\nLOKI   \u2022\nLOKI97   \u2022\nLorenz cipher   \u2022\nLouis W. Tordella   \u2022\nLsh   \u2022\nLucifer (cipher)   \u2022\nLyra2\n\n== M ==\nM6 (cipher)   \u2022\nM8 (cipher)   \u2022\nM-209   \u2022\nM-325   \u2022\nM-94   \u2022\nMacGuffin (cipher)   \u2022\nMadryga   \u2022\nMAGENTA   \u2022\nMagic (cryptography)   \u2022\nMaksymilian Ci\u0119\u017cki   \u2022\nMalcolm J. Williamson   \u2022\nMalleability (cryptography)   \u2022\nMan-in-the-middle attack   \u2022\nMarian Rejewski   \u2022\nMARS (cryptography)   \u2022\nMartin Hellman   \u2022\nMaruTukku   \u2022\nMassey\u2013Omura cryptosystem   \u2022\nMatt Blaze   \u2022\nMatt Robshaw   \u2022\nMax Newman   \u2022\nMcEliece cryptosystem   \u2022\nmcrypt   \u2022\nMD2 (cryptography)   \u2022\nMD4   \u2022\nMD5   \u2022\nMD5CRK   \u2022\nMDC-2   \u2022\nMDS matrix   \u2022\nMean shortest distance   \u2022\nMeet-in-the-middle attack   \u2022\nMental poker   \u2022\nMercury (cipher machine)   \u2022\nMercy (cipher)   \u2022\nMeredith Gardner   \u2022\nMerkle signature scheme   \u2022\nMerkle\u2013Damg\u00e5rd construction   \u2022\nMerkle\u2013Hellman knapsack cryptosystem   \u2022\nMerkle's Puzzles   \u2022\nMerkle tree   \u2022\nMESH (cipher)   \u2022\nMessage authentication   \u2022\nMessage authentication code   \u2022\nMessage forgery   \u2022\nMI8   \u2022\nMichael Luby   \u2022\nMICKEY   \u2022\nMicrodot   \u2022\nMilitary Cryptanalysis (book) (William F. Friedman)   \u2022\nMilitary Cryptanalytics   \u2022\nMimic function   \u2022\nMirror writing   \u2022\nMISTY1   \u2022\nMitsuru Matsui   \u2022\nMMB (cipher)   \u2022\nMod n cryptanalysis   \u2022\nMQV   \u2022\nMS-CHAP   \u2022\nMUGI   \u2022\nMULTI-S01   \u2022\nMultiSwap   \u2022\nMultivariate cryptography\n\n== N ==\nNational Communications Centre   \u2022\nNational Cryptologic Museum   \u2022\nNational Security Agency   \u2022\nNational Cipher Challenge   \u2022\nNavajo I   \u2022\nNeal Koblitz   \u2022\nNeedham\u2013Schroeder protocol   \u2022\nNegligible function   \u2022\nNEMA (machine)   \u2022\nNESSIE   \u2022\nNetwork Security Services   \u2022\nNeural cryptography   \u2022\nNew Data Seal   \u2022\nNewDES   \u2022\nN-Hash   \u2022\nNicolas Courtois   \u2022\nNiederreiter cryptosystem   \u2022\nNiels Ferguson   \u2022\nNigel de Grey   \u2022\nNihilist cipher   \u2022\nNikita Borisov   \u2022\nNimbus (cipher)   \u2022\nNIST hash function competition   \u2022\nNonlinear-feedback shift register   \u2022\nNOEKEON   \u2022\nNon-malleable codes   \u2022\nNoreen   \u2022\nNothing up my sleeve number   \u2022\nNSA cryptography   \u2022\nNSA encryption systems   \u2022\nNSA in fiction   \u2022\nNSAKEY   \u2022\nNSA Suite A Cryptography   \u2022\nNSA Suite B Cryptography   \u2022\nNT LAN Manager   \u2022\nNTLMSSP   \u2022\nNTRUEncrypt   \u2022\nNTRUSign   \u2022\nNull cipher   \u2022\nNumbers station   \u2022\nNUSH   \u2022\nNTRU\n\n== O ==\nOblivious transfer   \u2022\nOCB mode   \u2022\nOded Goldreich   \u2022\nOff-the-Record Messaging   \u2022\nOkamoto\u2013Uchiyama cryptosystem   \u2022\nOMI cryptograph   \u2022\nOMNI (SCIP)   \u2022\nOne-key MAC   \u2022\nOne-time pad   \u2022\nOne-time password   \u2022\nOne-way compression function   \u2022\nOne-way function   \u2022\nOnion routing   \u2022\nOnline Certificate Status Protocol   \u2022\nOP-20-G   \u2022\nOpenPGP card   \u2022\nOpenSSH   \u2022\nOpenSSL   \u2022\nOpenswan   \u2022\nOpenVPN   \u2022\nOperation Ruthless   \u2022\nOptimal asymmetric encryption padding   \u2022\nOver the Air Rekeying   (OTAR) \u2022\nOTFE   \u2022\nOtway\u2013Rees protocol\n\n== P ==\nPadding (cryptography)   \u2022\nPadding oracle attack    \u2022\nPaillier cryptosystem   \u2022\nPairing-based cryptography   \u2022\nPanama (cryptography)   \u2022\nPartitioning cryptanalysis   \u2022\nPassive attack   \u2022\nPassphrase   \u2022\nPassword   \u2022\nPassword-authenticated key agreement   \u2022\nPassword cracking   \u2022\nPassword Hashing Competition   \u2022\nPaul Kocher   \u2022\nPaulo Pancatuccio   \u2022\nPaulo S. L. M. Barreto   \u2022\nPaul van Oorschot   \u2022\nPBKDF2   \u2022\nPC Bruno   \u2022\nPepper (cryptography)   \u2022\nPerfect forward secrecy   \u2022\nPerforated sheets   \u2022\nPermutation cipher   \u2022\nPeter Gutmann (computer scientist)   \u2022\nPeter Junger   \u2022\nPeter Twinn   \u2022\nPGP Corporation   \u2022\nPGPDisk   \u2022\nPGPfone   \u2022\nPhelix   \u2022\nPhil Zimmermann   \u2022\nPhoturis (protocol)   \u2022\nPhysical security   \u2022\nPhysical unclonable function   \u2022\nPig Latin   \u2022\nPigpen cipher   \u2022\nPike (cipher)   \u2022\nPiling-up lemma   \u2022\nPinwheel (cryptography)   \u2022\nPiotr Smole\u0144ski   \u2022\nPirate decryption   \u2022\nPKC (conference)   \u2022\nPKCS   \u2022\nPKCS 11   \u2022\nPKCS 12   \u2022\nPKIX   \u2022\nPlaintext   \u2022\nPlaintext-aware encryption   \u2022\nPlayfair cipher   \u2022\nPlugboard   \u2022\nPMAC (cryptography)   \u2022\nPoem code   \u2022\nPohlig\u2013Hellman algorithm   \u2022\nPoint-to-Point Tunneling Protocol   \u2022\nPointcheval\u2013Stern signature algorithm   \u2022\nPoly1305   \u2022\nPolyalphabetic cipher   \u2022\nPolybius square   \u2022\nPortex   \u2022\nPost-quantum cryptography   \u2022\nPost-Quantum Cryptography Standardization   \u2022\nPower analysis   \u2022\nPreimage attack   \u2022\nPre-shared key   \u2022\nPretty Good Privacy   \u2022\nPrinter steganography   \u2022\nPrivacy-enhanced Electronic Mail   \u2022\nPrivate Communications Technology   \u2022\nPrivate information retrieval   \u2022\nProbabilistic encryption   \u2022\nProduct cipher   \u2022\nProof-of-work system   \u2022\nProtected Extensible Authentication Protocol   \u2022\nProvable security   \u2022\nProvably secure cryptographic hash function   \u2022\nProxy re-encryption   \u2022\nPseudo-Hadamard transform   \u2022\nPseudonymity   \u2022\nPseudorandom function   \u2022\nPseudorandom number generator   \u2022\nPseudorandom permutation   \u2022\nPublic key certificate   \u2022\nPublic-key cryptography   \u2022\nPublic key fingerprint   \u2022\nPublic key infrastructure   \u2022\nPURPLE   \u2022\nPuTTY   \u2022\nPy (cipher)\n\n== Q ==\nQ (cipher)   \u2022\nQrpff   \u2022\nQUAD (cipher)   \u2022\nQuadratic sieve   \u2022\nQuantum coin flipping   \u2022\nQuantum cryptography   \u2022\nQuantum digital signature   \u2022\nQuantum fingerprinting   \u2022\nQuantum key distribution\n\n== R ==\nRabbit (cipher)   \u2022\nRabin cryptosystem   \u2022\nRabin\u2013Williams encryption   \u2022\nRadioGat\u00fan   \u2022\nRail fence cipher   \u2022\nRainbow table   \u2022\nRalph Merkle   \u2022\nRambutan (cryptography)   \u2022\nRandom function   \u2022\nRandomness tests   \u2022\nRandom number generator attack   \u2022\nRandom oracle   \u2022\nRC2   \u2022\nRC4   \u2022\nRC5   \u2022\nRC6   \u2022\nRebound attack   \u2022\nReciprocal cipher   \u2022\nRed/black concept   \u2022\nREDOC   \u2022\nRed Pike (cipher)   \u2022\nReflector (cipher machine)   \u2022\nRegulation of Investigatory Powers Act 2000   \u2022\nReihenschieber   \u2022\nRekeying (cryptography)   \u2022\nRelated-key attack   \u2022\nReplay attack   \u2022\nReservehandverfahren   \u2022\nResidual block termination   \u2022\nRijndael key schedule   \u2022\nRijndael S-box   \u2022\nRing signature   \u2022\nRIPEMD   \u2022\nRip van Winkle cipher   \u2022\nRobert Morris (cryptographer)   \u2022\nRobot certificate authority   \u2022\nRockex   \u2022\nRolf Noskwith   \u2022\nRon Rivest   \u2022\nRoom 40   \u2022\nRoot certificate   \u2022\nRoss J. Anderson   \u2022\nRossignols   \u2022\nROT13   \u2022\nRotor machine   \u2022\nRSA RSA \u2022\nRSA-100   \u2022\nRSA-1024   \u2022\nRSA-110   \u2022\nRSA-120   \u2022\nRSA-129   \u2022\nRSA-130   \u2022\nRSA-140   \u2022\nRSA-150   \u2022\nRSA-1536   \u2022\nRSA-155   \u2022\nRSA-160   \u2022\nRSA-170   \u2022\nRSA-180   \u2022\nRSA-190   \u2022\nRSA-200   \u2022\nRSA-2048   \u2022\nRSA-210   \u2022\nRSA-220   \u2022\nRSA-230   \u2022\nRSA-232   \u2022\nRSA-240   \u2022\nRSA-250   \u2022\nRSA-260   \u2022\nRSA-270   \u2022\nRSA-280   \u2022\nRSA-290   \u2022\nRSA-300   \u2022\nRSA-309   \u2022\nRSA-310   \u2022\nRSA-320   \u2022\nRSA-330   \u2022\nRSA-340   \u2022\nRSA-350   \u2022\nRSA-360   \u2022\nRSA-370   \u2022\nRSA-380   \u2022\nRSA-390   \u2022\nRSA-400   \u2022\nRSA-410   \u2022\nRSA-420   \u2022\nRSA-430   \u2022\nRSA-440   \u2022\nRSA-450   \u2022\nRSA-460   \u2022\nRSA-470   \u2022\nRSA-480   \u2022\nRSA-490   \u2022\nRSA-500   \u2022\nRSA-576   \u2022\nRSA-617   \u2022\nRSA-640   \u2022\nRSA-704   \u2022\nRSA-768   \u2022\nRSA-896   \u2022\nRSA-PSS   \u2022\nRSA Factoring Challenge   \u2022\nRSA problem   \u2022\nRSA Secret-Key Challenge   \u2022\nRSA Security   \u2022\nRubber-hose cryptanalysis   \u2022\nRunning key cipher   \u2022\nRussian copulation\n\n== S ==\nS-1 block cipher   \u2022\nSAFER   \u2022\nSalsa20   \u2022\nSalt (cryptography)   \u2022\nSAM card   \u2022\nSecurity Support Provider Interface   \u2022\nSAML   \u2022\nSAVILLE   \u2022\nSC2000   \u2022\nSchnorr group   \u2022\nSchnorr signature   \u2022\nSchoof\u2013Elkies\u2013Atkin algorithm   \u2022\nSCIP   \u2022\nScott Vanstone   \u2022\nScrambler   \u2022\nScramdisk   \u2022\nScream (cipher)   \u2022\nScrypt   \u2022\nScytale   \u2022\nSeahorse (software)   \u2022\nSEAL (cipher)   \u2022\nSean Murphy (cryptographer)   \u2022\nSECG   \u2022\nSecret broadcast   \u2022\nSecret decoder ring   \u2022\nSecrets and Lies (Schneier)   \u2022\nSecret sharing   \u2022\nSect\u00e9ra Secure Module   \u2022\nSecure access module   \u2022\nSecure channel   \u2022\nSecure Communication based on Quantum Cryptography   \u2022\nSecure copy   \u2022\nSecure cryptoprocessor   \u2022\nSecure Electronic Transaction   \u2022\nSecure Hash Algorithms   \u2022\nSecure Hypertext Transfer Protocol   \u2022\nSecure key issuing cryptography   \u2022\nSecure multi-party computation   \u2022\nSecure Neighbor Discovery   \u2022\nSecure Real-time Transport Protocol   \u2022\nSecure remote password protocol   \u2022\nSecure Shell   \u2022\nSecure telephone   \u2022\nSecure Terminal Equipment   \u2022\nSecure voice   \u2022\nSecurID   \u2022\nSecurity association   \u2022\nSecurity engineering   \u2022\nSecurity level   \u2022\nSecurity parameter   \u2022\nSecurity protocol notation   \u2022\nSecurity through obscurity   \u2022\nSecurity token   \u2022\nSEED   \u2022\nSelected Areas in Cryptography   \u2022\nSelf-certifying File System   \u2022\nSelf-shrinking generator   \u2022\nSelf-signed certificate   \u2022\nSemantic security   \u2022\nSerge Vaudenay   \u2022\nSerpent (cipher)   \u2022\nSession key   \u2022\nSHACAL   \u2022\nShafi Goldwasser   \u2022\nSHA-1   \u2022\nSHA-2   \u2022\nSHA-3   \u2022\nShared secret   \u2022\nSHARK   \u2022\nShaun Wylie   \u2022\nShor's algorithm   \u2022\nShrinking generator   \u2022\nShugborough inscription   \u2022\nSide-channel attack   \u2022\nSiemens and Halske T52   \u2022\nSIGABA   \u2022\nSIGCUM   \u2022\nSIGINT   \u2022\nSignal Protocol   \u2022\nSignal Intelligence Service   \u2022\nSigncryption   \u2022\nSIGSALY   \u2022\nSILC (protocol)   \u2022\nSilvio Micali   \u2022\nSimple Authentication and Security Layer   \u2022\nSimple public-key infrastructure   \u2022\nSimple XOR cipher   \u2022\nS/KEY   \u2022\nSkein (hash function)   \u2022\nSkipjack (cipher)   \u2022\nSlide attack   \u2022\nSlidex   \u2022\nSmall subgroup confinement attack   \u2022\nS/MIME   \u2022\nSM4 algorithm   (formerly SMS4) \u2022\nSnake oil (cryptography)   \u2022\nSnefru   \u2022\nSNOW   \u2022\nSnuffle   \u2022\nSOBER-128   \u2022\nSolitaire (cipher)   \u2022\nSolomon Kullback   \u2022\nSOSEMANUK   \u2022\nSpecial Collection Service   \u2022\nSpectr-H64   \u2022\nSPEKE (cryptography)   \u2022\nSponge function   \u2022\nSPNEGO   \u2022\nSquare (cipher)   \u2022\nSsh-agent   \u2022 Ssh-keygen   \u2022 SSH File Transfer Protocol   \u2022\nSSLeay   \u2022\nStafford Tavares   \u2022\nStandard model (cryptography)   \u2022\nStation CAST   \u2022\nStation HYPO   \u2022\nStation-to-Station protocol   \u2022\nStatistical cryptanalysis   \u2022\nStefan Lucks   \u2022\nSteganalysis   \u2022\nSteganography   \u2022\nStraddling checkerboard   \u2022\nStream cipher   \u2022\nStream cipher attacks   \u2022\nStrong cryptography   \u2022\nStrong RSA assumption   \u2022\nStuart Milner-Barry   \u2022\nSTU-II   \u2022\nSTU-III   \u2022\nStunnel   \u2022\nSubstitution box   \u2022\nSubstitution cipher   \u2022\nSubstitution\u2013permutation network   \u2022\nSuperencryption   \u2022\nSupersingular isogeny key exchange   \u2022\nSwedish National Defence Radio Establishment   \u2022\nSWIFFT   \u2022\nSXAL/MBAL   \u2022\nSymmetric-key algorithm   \u2022\nSYSKEY\n\n== T ==\nTabula recta   \u2022\nTaher Elgamal   \u2022\nTamper resistance   \u2022\nTcpcrypt   \u2022\nTelevision encryption   \u2022\nTEMPEST   \u2022\nTemplate:Cryptographic software   \u2022\nTemporal Key Integrity Protocol   \u2022\nTestery   \u2022\nThawte   \u2022\nThe Alphabet Cipher   \u2022\nThe Code Book   \u2022\nThe Codebreakers   \u2022\nThe Gold-Bug   \u2022\nThe Magic Words are Squeamish Ossifrage   \u2022\nTheory of Cryptography Conference   \u2022\nThe world wonders   \u2022\nThomas Jakobsen   \u2022\nThree-pass protocol   \u2022\nThreshold shadow scheme   \u2022\nTICOM   \u2022\nTiger (cryptography)   \u2022\nTimeline of cryptography   \u2022\nTime/memory/data tradeoff attack   \u2022\nTime-based One-time Password algorithm   (TOTP) \u2022\nTiming attack   \u2022\nTiny Encryption Algorithm   \u2022\nTom Berson   \u2022\nTommy Flowers   \u2022\nTopics in cryptography   \u2022\nTor (anonymity network)   \u2022\nTorus-based cryptography   \u2022\nTraffic analysis   \u2022\nTraffic-flow security   \u2022\nTraitor tracing   \u2022\nTransmission security   \u2022\nTransport Layer Security   \u2022\nTransposition cipher   \u2022\nTrapdoor function   \u2022\nTrench code   \u2022\nTreyfer   \u2022\nTrifid cipher   \u2022\nTriple DES   \u2022\nTrivium (cipher)   \u2022\nTrueCrypt   \u2022\nTruncated differential cryptanalysis   \u2022\nTrusted third party   \u2022\nTuring (cipher)   \u2022\nTWINKLE   \u2022\nTWIRL   \u2022\nTwofish   \u2022\nTwo-square cipher   \u2022\nType 1 encryption   \u2022\nType 2 encryption   \u2022\nType 3 encryption   \u2022\nType 4 encryption   \u2022\nTypex\n\n== U ==\nUES (cipher)   \u2022\nUltra   \u2022\nUMAC   \u2022\nUnbalanced Oil and Vinegar   \u2022\nUndeniable signature   \u2022\nUnicity distance   \u2022\nUniversal composability   \u2022\nUniversal one-way hash function   (UOWHF)\n\n== V ==\nVenona project   \u2022\nVerifiable secret sharing   \u2022\nVerisign   \u2022\nVery smooth hash   \u2022\nVEST   \u2022\nVIC cipher   \u2022\nVideoCrypt   \u2022\nVigen\u00e8re cipher   \u2022\nVincent Rijmen   \u2022\nVINSON   \u2022\nVirtual private network   \u2022\nVisual cryptography   \u2022\nVoynich manuscript\n\n== W ==\nWadsworth's cipher   \u2022\nWAKE   \u2022\nWLAN Authentication and Privacy Infrastructure   \u2022\nWatermark (data file)   \u2022\nWatermarking attack   \u2022\nWeak key   \u2022\nWeb of trust   \u2022\nWhirlpool (hash function)   \u2022\nWhitfield Diffie   \u2022\nWide Mouth Frog protocol   \u2022\nWi-Fi Protected Access   \u2022\nWilliam F. Friedman   \u2022\nWilliam Montgomery (cryptographer)   \u2022\nWinSCP   \u2022\nWired Equivalent Privacy   \u2022\nWireless Transport Layer Security   \u2022\nWitness-indistinguishable proof   \u2022\nWorkshop on Cryptographic Hardware and Embedded Systems   \u2022\nWorld War I cryptography   \u2022\nWorld War II cryptography   \u2022\nW. T. Tutte\n\n== X ==\nX.509   \u2022\nXDH assumption   \u2022\nXiaoyun Wang   \u2022\nXML Encryption   \u2022\nXML Signature   \u2022\nxmx   \u2022\nXSL attack   \u2022\nXTEA   \u2022\nXTR   \u2022\nXuejia Lai   \u2022\nXXTEA  \n10-00-00-00-00\n\n== Y ==\nYarrow algorithm   \u2022\nY-stations   \u2022\nYuliang Zheng\n\n== Z ==\nZeroisation   \u2022\nZero-knowledge password proof   \u2022\nZero-knowledge proof   \u2022\nZfone   \u2022\nZodiac (cipher)   \u2022\nZRTP   \u2022\nZimmermann\u2013Sassaman key-signing protocol   \u2022\nZimmermann Telegram\n\nAnswer this question based on the above context: Which encryption algorithm was broken in 1977 by a team led by Don Coppersmith at IBM using a special-purpose machine called the DES Cracker?",
    "context": "",
    "output": "The Data Encryption Standard (DES) was broken in 1977 by a team led by Don Coppersmith at IBM using a special-purpose machine called the DES Cracker.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Which encryption algorithm was broken in 1977 by a team led by Don Coppersmith at IBM using a special-purpose machine called the DES Cracker?",
      "answer": "The Data Encryption Standard (DES) was broken in 1977 by a team led by Don Coppersmith at IBM using a special-purpose machine called the DES Cracker.",
      "context": "Index of cryptography articles\n\n==Introduction==\nArticles related to cryptography include:\n\n\n\n== A ==\nA5/1   \u2022\nA5/2   \u2022\nABA digital signature guidelines   \u2022\nABC (stream cipher)   \u2022\nAbraham Sinkov   \u2022\nAcoustic cryptanalysis   \u2022\nAdaptive chosen-ciphertext attack   \u2022\nAdaptive chosen plaintext and chosen ciphertext attack   \u2022\nAdvantage (cryptography)   \u2022\nADFGVX cipher   \u2022\nAdi Shamir   \u2022\nAdvanced Access Content System   \u2022\nAdvanced Encryption Standard   \u2022\nAdvanced Encryption Standard process   \u2022\nAdversary   \u2022\nAEAD block cipher modes of operation   \u2022\nAffine cipher   \u2022\nAgnes Meyer Driscoll   \u2022\nAKA (security)   \u2022\nAkelarre (cipher)   \u2022\nAlan Turing   \u2022\nAlastair Denniston   \u2022\nAl Bhed language   \u2022\nAlex Biryukov   \u2022\nAlfred Menezes   \u2022\nAlgebraic Eraser   \u2022\nAlgorithmically random sequence   \u2022\nAlice and Bob   \u2022\nAll-or-nothing transform   \u2022\nAlphabetum Kaldeorum   \u2022\nAlternating step generator   \u2022\nAmerican Cryptogram Association   \u2022\nAN/CYZ-10   \u2022\nAnonymous publication   \u2022\nAnonymous remailer   \u2022\nAntoni Palluth   \u2022\nAnubis (cipher)   \u2022\nArgon2   \u2022\nARIA (cipher)   \u2022\nArlington Hall   \u2022\nArne Beurling   \u2022\nArnold Cipher   \u2022\nArray controller based encryption   \u2022\nArthur Scherbius   \u2022\nArvid Gerhard Damm   \u2022\nAsiacrypt   \u2022\nAtbash   \u2022\nAttribute-based encryption   \u2022\nAttack model   \u2022\nAuguste Kerckhoffs   \u2022\nAuthenticated encryption   \u2022\nAuthentication   \u2022\nAuthorization certificate   \u2022\nAutokey cipher   \u2022\nAvalanche effect\n\n== B ==\nB-Dienst   \u2022\nBabington Plot   \u2022\nBaby-step giant-step   \u2022\nBacon's cipher   \u2022\nBanburismus   \u2022\nBart Preneel   \u2022\nBaseKing   \u2022\nBassOmatic   \u2022\nBATON   \u2022\nBB84   \u2022\nBeale ciphers   \u2022\nBEAR and LION ciphers   \u2022\nBeaufort cipher   \u2022\nBeaumanor Hall   \u2022\nBent function   \u2022\nBerlekamp\u2013Massey algorithm   \u2022\nBernstein v. United States   \u2022\nBestCrypt   \u2022\nBiclique attack   \u2022\nBID/60   \u2022\nBID 770   \u2022\nBifid cipher   \u2022\nBill Weisband   \u2022\nBinary Goppa code   \u2022\nBiometric word list   \u2022\nBirthday attack   \u2022\nBit-flipping attack   \u2022\nBitTorrent protocol encryption   \u2022\nBiuro Szyfr\u00f3w   \u2022\nBlack Chamber   \u2022\nBlaise de Vigen\u00e8re   \u2022\nBletchley Park   \u2022\nBlind credential   \u2022\nBlinding (cryptography)   \u2022\nBlind signature   \u2022\nBlock cipher   \u2022\nBlock cipher mode of operation   \u2022\nBlock size (cryptography)   \u2022\nBlowfish (cipher)   \u2022\nBlum Blum Shub   \u2022\nBlum\u2013Goldwasser cryptosystem   \u2022\nBomba (cryptography)   \u2022\nBombe   \u2022\nBook cipher   \u2022\nBooks on cryptography   \u2022\nBoomerang attack   \u2022\nBoris Hagelin   \u2022\nBouncy Castle (cryptography)   \u2022\nBroadcast encryption   \u2022\nBruce Schneier   \u2022\nBrute-force attack   \u2022\nBrute Force: Cracking the Data Encryption Standard   \u2022\nBurrows\u2013Abadi\u2013Needham logic   \u2022\nBurt Kaliski\n\n== C ==\nC2Net   \u2022\nC-36 (cipher machine)   \u2022\nC-52 (cipher machine)   \u2022\nCaesar cipher   \u2022\nCamellia (cipher)   \u2022\nCAPICOM   \u2022\nCapstone (cryptography)   \u2022\nCardan grille   \u2022\nCard catalog (cryptology)   \u2022\nCarlisle Adams   \u2022\nCAST-128   \u2022\nCAST-256   \u2022\nCayley\u2013Purser algorithm   \u2022\nCBC-MAC   \u2022\nCCM mode   \u2022\nCCMP   \u2022\nCD-57   \u2022\nCDMF   \u2022\nCellular Message Encryption Algorithm   \u2022\nCentiban   \u2022\nCentral Security Service   \u2022\nCentre for Applied Cryptographic Research   \u2022\nCentral Bureau   \u2022\nCerticom   \u2022\nCertificate authority   \u2022\nCertificate-based encryption   \u2022\nCertificateless cryptography   \u2022\nCertificate revocation list   \u2022\nCertificate signing request   \u2022\nCertification path validation algorithm   \u2022\nChaffing and winnowing   \u2022\nChallenge-Handshake Authentication Protocol   \u2022\nChallenge\u2013response authentication   \u2022\nChosen-ciphertext attack   \u2022\nChosen-plaintext attack   \u2022\nCIKS-1   \u2022\nCipher disk   \u2022\nCipher runes   \u2022\nCipher security summary   \u2022\nCipherSaber   \u2022\nCiphertext expansion   \u2022\nCiphertext indistinguishability   \u2022\nCiphertext-only attack   \u2022\nCiphertext stealing   \u2022\nCIPHERUNICORN-A   \u2022\nCIPHERUNICORN-E   \u2022\nClassical cipher   \u2022\nClaude Shannon   \u2022\nClaw-free permutation   \u2022\nCleartext   \u2022\nCLEFIA   \u2022\nClifford Cocks   \u2022\nClipper chip   \u2022\nClock (cryptography)   \u2022\nClock drift   \u2022\nCMVP   \u2022\nCOCONUT98   \u2022\nCodebook   \u2022\nCode (cryptography)   \u2022\nCode talker   \u2022\nCodress message   \u2022\nCold boot attack   \u2022\nCollision attack   \u2022\nCollision resistance   \u2022\nColossus computer   \u2022\nCombined Cipher Machine   \u2022\nCommitment scheme   \u2022\nCommon Scrambling Algorithm   \u2022\nCommunications security   \u2022\nCommunications Security Establishment   \u2022\nCommunication Theory of Secrecy Systems   \u2022\nComparison of disk encryption software   \u2022\nComparison of SSH clients   \u2022\nCompleteness (cryptography)   \u2022\nComplexity trap   \u2022\nComputational Diffie\u2013Hellman assumption   \u2022\nComputational hardness assumption   \u2022\nComputer insecurity   \u2022\nComputer and network surveillance   \u2022\nCOMSEC equipment   \u2022\nConch (SSH)   \u2022\nConcrete security   \u2022\nConel Hugh O'Donel Alexander   \u2022\nConfidentiality   \u2022\nConfusion and diffusion   \u2022\nContent-scrambling system   \u2022\nControlled Cryptographic Item   \u2022\nCorkscrew (program)   \u2022\nCorrelation immunity   \u2022\nCOSIC   \u2022\nCovert channel   \u2022\nCover (telecommunications)   \u2022\nCrab (cipher)   \u2022\nCramer\u2013Shoup cryptosystem   \u2022\nCRAM-MD5   \u2022\nCRHF   \u2022\nCrib (cryptanalysis)   \u2022\nCrossCrypt   \u2022\nCrowds (anonymity network)   \u2022\nCrypt (C)   \u2022\nCryptanalysis   \u2022\nCryptanalysis of the Enigma   \u2022\nCryptanalysis of the Lorenz cipher   \u2022\nCryptanalytic computer   \u2022\nCryptex   \u2022\nCryptico   \u2022\nCrypto AG   \u2022\nCrypto-anarchism   \u2022\nCrypto API (Linux)   \u2022\nMicrosoft CryptoAPI   \u2022\nCryptoBuddy   \u2022\nCryptochannel   \u2022\nCRYPTO (conference)   \u2022\nCryptogram   \u2022\nCryptographically Generated Address   \u2022\nCryptographically secure pseudorandom number generator   \u2022\nCryptographically strong   \u2022\nCryptographic Application Programming Interface   \u2022\nCryptographic hash function   \u2022\nCryptographic key types   \u2022\nCryptographic Message Syntax   \u2022\nCryptographic primitive   \u2022\nCryptographic protocol   \u2022\nCryptographic Service Provider   \u2022\nCryptographie ind\u00e9chiffrable   \u2022\nCryptography   \u2022\nCryptography in Japan   \u2022\nCryptography newsgroups   \u2022\nCryptography standards   \u2022\nCrypto: How the Code Rebels Beat the Government\u2014Saving Privacy in the Digital Age   \u2022\nCryptologia   \u2022\nCryptology ePrint Archive   \u2022\nCryptology Research Society of India   \u2022\nCryptomathic   \u2022\nCryptome   \u2022\nCryptomeria cipher   \u2022\nCryptonomicon   \u2022\nCrypTool   \u2022\nCrypto phone   \u2022\nCrypto-society   \u2022\nCryptosystem   \u2022\nCryptovirology   \u2022\nCRYPTREC   \u2022\nCS-Cipher   \u2022\nCurve25519   \u2022 Curve448   \u2022 Custom hardware attack   \u2022\nCycles per byte   \u2022\nCyclometer   \u2022\nCypherpunk   \u2022\nCyrillic Projector\n\n== D ==\nD'Agapeyeff cipher   \u2022\nDaniel J. Bernstein   \u2022\nData Authentication Algorithm   \u2022\nData Encryption Standard   \u2022\nDatagram Transport Layer Security   \u2022\nDavid Chaum   \u2022\nDavid Kahn   \u2022\nDavid Naccache   \u2022\nDavid Wagner   \u2022\nDavid Wheeler (computer scientist)   \u2022\nDavies attack   \u2022\nDavies\u2013Meyer hash   \u2022\nDEAL   \u2022\nDecipherment   \u2022\nDecisional Diffie\u2013Hellman assumption   \u2022\nDecorrelation theory   \u2022\nDecrypt   \u2022\nDeCSS   \u2022\nDefence Signals Directorate   \u2022\nDegree of anonymity   \u2022\nDelegated Path Discovery   \u2022\nDelegated Path Validation   \u2022\nDeniable encryption   \u2022\nDerek Taunt   \u2022\nDerived unique key per transaction   \u2022\nDES Challenges   \u2022\nDES supplementary material   \u2022\nDES-X   \u2022\nDeterministic encryption   \u2022\nDFC (cipher)   \u2022\nDictionary attack   \u2022\nDifferential cryptanalysis   \u2022\nDifferential-linear attack   \u2022\nDifferential power analysis   \u2022\nDiffie\u2013Hellman key exchange   \u2022\nDiffie\u2013Hellman problem   \u2022\nDigiCipher 2   \u2022\nDigital Fortress   \u2022\nDigital rights management   \u2022\nDigital signature   \u2022\nDigital Signature Algorithm   \u2022\nDigital signature forgery   \u2022\nDigital timestamping   \u2022\nDigital watermarking   \u2022\nDilly Knox   \u2022\nDining cryptographers problem   \u2022\nDiplomatic bag   \u2022\nDirect Anonymous Attestation   \u2022\nDiscrete logarithm   \u2022\nDisk encryption   \u2022\nDisk encryption hardware   \u2022\nDisk encryption software   \u2022\nDistance-bounding protocol   \u2022\nDistinguishing attack   \u2022\nDistributed.net   \u2022\nDMA attack   \u2022\ndm-crypt   \u2022\nDmitry Sklyarov   \u2022\nDomainKeys   \u2022\nDon Coppersmith   \u2022\nDorabella Cipher   \u2022\nDouble Ratchet Algorithm   \u2022\nDoug Stinson   \u2022\nDragon (cipher)   \u2022\nDRYAD   \u2022\nDual_EC_DRBG   \u2022\n\n== E ==\nE0 (cipher)   \u2022\nE2 (cipher)   \u2022\nE4M   \u2022\nEAP-AKA   \u2022\nEAP-SIM   \u2022\nEAX mode   \u2022\nECC patents   \u2022\nECHELON   \u2022\nECRYPT   \u2022\nEdouard Fleissner von Wostrowitz   \u2022\nEdward Hebern   \u2022\nEdward Scheidt   \u2022\nEdward Travis   \u2022\nEFF DES cracker   \u2022\nEfficient Probabilistic Public-Key Encryption Scheme   \u2022\nEKMS   \u2022\nElectronic Communications Act 2000   \u2022\nElectronic money   \u2022\nElectronic signature   \u2022\nElectronic voting   \u2022\nElGamal encryption   \u2022\nElGamal signature scheme   \u2022\nEli Biham   \u2022\nElizebeth Friedman   \u2022\nElliptic-curve cryptography   \u2022\nElliptic-curve Diffie\u2013Hellman   \u2022\nElliptic Curve DSA   \u2022 EdDSA   \u2022 Elliptic curve only hash   \u2022\nElonka Dunin   \u2022\nEncrypted function   \u2022\nEncrypted key exchange   \u2022\nEncrypting File System   \u2022\nEncryption   \u2022\nEncryption software   \u2022\nEnigmail   \u2022\nEnigma machine   \u2022\nEnigma rotor details   \u2022\nEntrust   \u2022\nErnst Fetterlein   \u2022\neSTREAM   \u2022\n\u00c9tienne Bazeries   \u2022\nEurocrypt   \u2022\nEuroCrypt   \u2022\nExport of cryptography   \u2022\nExtensible Authentication Protocol\n\n== F ==\nFast Software Encryption   \u2022\nFast syndrome-based hash   \u2022\nFEA-M   \u2022\nFEAL   \u2022\nFeige\u2013Fiat\u2013Shamir identification scheme   \u2022\nFeistel cipher   \u2022\nF\u00e9lix Delastelle   \u2022\nFialka   \u2022\nFilesystem-level encryption   \u2022\nFileVault   \u2022\nFill device   \u2022\nFinancial cryptography   \u2022\nFIPS 140   \u2022\nFIPS 140-2   \u2022\nFirefly (key exchange protocol)   \u2022\nFISH (cipher)   \u2022\nFish (cryptography)   \u2022\nFloradora   \u2022\nFluhrer, Mantin and Shamir attack   \u2022\nFormat-preserving encryption   \u2022\nFortezza   \u2022\nFort George G. Meade   \u2022\nFortuna (PRNG)   \u2022\nFour-square cipher   \u2022\nFranciszek Pokorny   \u2022\nFrank A. Stevenson   \u2022\nFrank Rowlett   \u2022\nFreenet   \u2022\nFreeOTFE   \u2022\nFreeS/WAN   \u2022\nFrequency analysis   \u2022\nFriedrich Kasiski   \u2022\nFritz-chip   \u2022\nFROG   \u2022\nFROSTBURG   \u2022\nFTP over SSH   \u2022\nFull disk encryption   \u2022\nFull Domain Hash   \u2022\nF. W. Winterbotham\n\n== G ==\nGalois/Counter Mode   \u2022\nGardening (cryptanalysis)   \u2022\nGCHQ Bude   \u2022\nGCHQ CSO Morwenstow   \u2022\nGDES   \u2022\nGeneric Security Services Application Program Interface   \u2022\nGeorge Blakley   \u2022\nGeorge Scovell   \u2022\nGGH encryption scheme   \u2022\nGGH signature scheme   \u2022\nGilbert Vernam   \u2022\nGMR (cryptography)   \u2022\nGNU Privacy Guard   \u2022\nGnuTLS   \u2022\nGoldwasser\u2013Micali cryptosystem   \u2022\nGordon Welchman   \u2022\nGOST (block cipher)   \u2022\nGOST (hash function)   \u2022\nGovernment Communications Headquarters   \u2022\nGovernment Communications Security Bureau   \u2022\nGrain (cipher)   \u2022\nGrand Cru (cipher)   \u2022\nGreat Cipher   \u2022\nGrill (cryptology)   \u2022\nGrille (cryptography)   \u2022\nGroup-based cryptography   \u2022\nGroup signature   \u2022\nGrover's algorithm   \u2022\nGustave Bertrand   \u2022\nGwido Langer\n\n== H ==\nH.235   \u2022\nHAIFA construction   \u2022\nHAIPE   \u2022\nHans Dobbertin   \u2022\nHans-Thilo Schmidt   \u2022\nHard-core predicate   \u2022\nHardware random number generator   \u2022\nHardware security module   \u2022\nHarold Keen   \u2022\nHarry Hinsley   \u2022\nHarvest (computer)   \u2022\nHAS-160   \u2022\nHash-based cryptography   \u2022\nHashcash   \u2022\nHash chain   \u2022\nHash function security summary   \u2022\nHash list   \u2022\nHasty Pudding cipher   \u2022\nHAVAL   \u2022\nHC-256   \u2022\nHC-9   \u2022\nHeath Robinson (codebreaking machine)   \u2022\nHebern rotor machine   \u2022\nHenri Braqueni\u00e9   \u2022\nHenryk Zygalski   \u2022\nHerbert Yardley   \u2022\nHidden Field Equations   \u2022\nHideki Imai   \u2022\nHierocrypt   \u2022\nHigh-bandwidth Digital Content Protection   \u2022\nHigher-order differential cryptanalysis   \u2022\nHill cipher   \u2022\nHistory of cryptography   \u2022\nHMAC   \u2022\nHMAC-based One-time Password algorithm   (HOTP) \u2022\nHorst Feistel   \u2022\nHoward Heys   \u2022\nHttps   \u2022\nHugo Hadwiger   \u2022\nHugo Koch   \u2022\nHushmail   \u2022\nHut 6   \u2022\nHut 8   \u2022\nHX-63   \u2022\nHybrid cryptosystem   \u2022\nHyperelliptic curve cryptography   \u2022\nHyper-encryption\n\n== I ==\nIan Goldberg   \u2022\nIBM 4758   \u2022\nICE (cipher)   \u2022\nID-based cryptography   \u2022\nIDEA NXT   \u2022\nIdentification friend or foe   \u2022\nIEEE 802.11i   \u2022\nIEEE P1363   \u2022\nI. J. Good   \u2022\nIllegal prime   \u2022\nImpossible differential cryptanalysis   \u2022\nIndex of coincidence   \u2022\nIndifferent chosen-ciphertext attack   \u2022\nIndistinguishability obfuscation   \u2022\nIndocrypt   \u2022\nInformation leakage   \u2022\nInformation Security Group   \u2022\nInformation-theoretic security   \u2022\nInitialization vector   \u2022\nInteger factorization   \u2022\nIntegral cryptanalysis   \u2022\nIntegrated Encryption Scheme   \u2022\nIntegrated Windows Authentication   \u2022\nInterlock protocol   \u2022\nIntermediate certificate authorities   \u2022\nInternational Association for Cryptologic Research   \u2022\nInternational Data Encryption Algorithm   \u2022\nInternet Key Exchange   \u2022\nInternet Security Association and Key Management Protocol   \u2022\nInterpolation attack   \u2022\nInvisible ink   \u2022\nIPsec   \u2022\nIraqi block cipher   \u2022\nISAAC (cipher)   \u2022\nISO 19092-2   \u2022\nISO/IEC 9797   \u2022\nIvan Damg\u00e5rd\n\n== J ==\nJacques Stern   \u2022\nJADE (cypher machine)   \u2022\nJames Gillogly   \u2022\nJames H. Ellis   \u2022\nJames Massey   \u2022\nJan Grali\u0144ski   \u2022\nJan Kowalewski   \u2022\nJapanese naval codes   \u2022\nJava Cryptography Architecture   \u2022\nJefferson disk   \u2022\nJennifer Seberry   \u2022\nJerzy R\u00f3\u017cycki   \u2022\nJoan Daemen   \u2022\nJohannes Trithemius   \u2022\nJohn Herivel   \u2022\nJohn Kelsey (cryptanalyst)   \u2022\nJohn R. F. Jeffreys   \u2022\nJohn Tiltman   \u2022\nJon Lech Johansen   \u2022\nJosef Pieprzyk   \u2022\nJoseph Desch   \u2022\nJoseph Finnegan (cryptographer)   \u2022\nJoseph Mauborgne   \u2022\nJoseph Rochefort   \u2022\nJournal of Cryptology   \u2022\nJunger v. Daley\n\n== K ==\nKaisa Nyberg   \u2022\nKalyna (cipher)   \u2022\nKasiski examination   \u2022\nKASUMI   \u2022\nKCDSA   \u2022\nKeePass   \u2022\nKerberos (protocol)   \u2022\nKerckhoffs's principle   \u2022\nKevin McCurley (cryptographer)   \u2022\nKey-agreement protocol   \u2022\nKey authentication   \u2022\nKey clustering   \u2022\nKey (cryptography)   \u2022\nKey derivation function   \u2022\nKey distribution center   \u2022\nKey escrow   \u2022\nKey exchange   \u2022\nKeyfile   \u2022\nKey generation   \u2022\nKey generator   \u2022\nKey management   \u2022\nKey-recovery attack   \u2022\nKey schedule   \u2022\nKey server (cryptographic)   \u2022\nKey signature (cryptography)   \u2022\nKeysigning   \u2022\nKey signing party   \u2022\nKey size   \u2022\nKey space (cryptography)   \u2022\nKeystream   \u2022\nKey stretching   \u2022\nKey whitening   \u2022\nKG-84   \u2022\nKHAZAD   \u2022\nKhufu and Khafre   \u2022\nKiss (cryptanalysis)   \u2022\nKL-43   \u2022\nKL-51   \u2022\nKL-7   \u2022\nKleptography   \u2022\nKN-Cipher   \u2022\nKnapsack problem   \u2022\nKnown-key distinguishing attack   \u2022\nKnown-plaintext attack   \u2022\nKnownSafe   \u2022\nKOI-18   \u2022\nKOV-14   \u2022\nKryha   \u2022\nKryptos   \u2022\nKSD-64   \u2022\nKupyna   \u2022\nKuznyechik   \u2022\nKW-26   \u2022\nKW-37   \u2022\nKY-3   \u2022\nKY-57   \u2022\nKY-58   \u2022\nKY-68   \u2022\nKYK-13\n\n== L ==\nLacida   \u2022\nLadder-DES   \u2022\nLamport signature   \u2022\nLars Knudsen   \u2022\nLattice-based cryptography   \u2022\nLaurance Safford   \u2022\nLawrie Brown   \u2022\nLCS35   \u2022\nLeo Marks   \u2022\nLeonard Adleman   \u2022\nLeon Battista Alberti   \u2022\nLeo Rosen   \u2022\nLeslie Yoxall   \u2022\nLEVIATHAN (cipher)   \u2022\nLEX (cipher)   \u2022\nLibelle (cipher)   \u2022\nLinear cryptanalysis   \u2022\nLinear-feedback shift register   \u2022\nLink encryption   \u2022\nList of ciphertexts   \u2022\nList of cryptographers   \u2022\nList of cryptographic file systems   \u2022\nList of cryptographic key types   \u2022\nList of cryptology conferences   \u2022\nList of telecommunications encryption terms   \u2022 List of people associated with Bletchley Park \u2022 \n  List of SFTP clients   \u2022\nList of SFTP server software   \u2022\nLOKI   \u2022\nLOKI97   \u2022\nLorenz cipher   \u2022\nLouis W. Tordella   \u2022\nLsh   \u2022\nLucifer (cipher)   \u2022\nLyra2\n\n== M ==\nM6 (cipher)   \u2022\nM8 (cipher)   \u2022\nM-209   \u2022\nM-325   \u2022\nM-94   \u2022\nMacGuffin (cipher)   \u2022\nMadryga   \u2022\nMAGENTA   \u2022\nMagic (cryptography)   \u2022\nMaksymilian Ci\u0119\u017cki   \u2022\nMalcolm J. Williamson   \u2022\nMalleability (cryptography)   \u2022\nMan-in-the-middle attack   \u2022\nMarian Rejewski   \u2022\nMARS (cryptography)   \u2022\nMartin Hellman   \u2022\nMaruTukku   \u2022\nMassey\u2013Omura cryptosystem   \u2022\nMatt Blaze   \u2022\nMatt Robshaw   \u2022\nMax Newman   \u2022\nMcEliece cryptosystem   \u2022\nmcrypt   \u2022\nMD2 (cryptography)   \u2022\nMD4   \u2022\nMD5   \u2022\nMD5CRK   \u2022\nMDC-2   \u2022\nMDS matrix   \u2022\nMean shortest distance   \u2022\nMeet-in-the-middle attack   \u2022\nMental poker   \u2022\nMercury (cipher machine)   \u2022\nMercy (cipher)   \u2022\nMeredith Gardner   \u2022\nMerkle signature scheme   \u2022\nMerkle\u2013Damg\u00e5rd construction   \u2022\nMerkle\u2013Hellman knapsack cryptosystem   \u2022\nMerkle's Puzzles   \u2022\nMerkle tree   \u2022\nMESH (cipher)   \u2022\nMessage authentication   \u2022\nMessage authentication code   \u2022\nMessage forgery   \u2022\nMI8   \u2022\nMichael Luby   \u2022\nMICKEY   \u2022\nMicrodot   \u2022\nMilitary Cryptanalysis (book) (William F. Friedman)   \u2022\nMilitary Cryptanalytics   \u2022\nMimic function   \u2022\nMirror writing   \u2022\nMISTY1   \u2022\nMitsuru Matsui   \u2022\nMMB (cipher)   \u2022\nMod n cryptanalysis   \u2022\nMQV   \u2022\nMS-CHAP   \u2022\nMUGI   \u2022\nMULTI-S01   \u2022\nMultiSwap   \u2022\nMultivariate cryptography\n\n== N ==\nNational Communications Centre   \u2022\nNational Cryptologic Museum   \u2022\nNational Security Agency   \u2022\nNational Cipher Challenge   \u2022\nNavajo I   \u2022\nNeal Koblitz   \u2022\nNeedham\u2013Schroeder protocol   \u2022\nNegligible function   \u2022\nNEMA (machine)   \u2022\nNESSIE   \u2022\nNetwork Security Services   \u2022\nNeural cryptography   \u2022\nNew Data Seal   \u2022\nNewDES   \u2022\nN-Hash   \u2022\nNicolas Courtois   \u2022\nNiederreiter cryptosystem   \u2022\nNiels Ferguson   \u2022\nNigel de Grey   \u2022\nNihilist cipher   \u2022\nNikita Borisov   \u2022\nNimbus (cipher)   \u2022\nNIST hash function competition   \u2022\nNonlinear-feedback shift register   \u2022\nNOEKEON   \u2022\nNon-malleable codes   \u2022\nNoreen   \u2022\nNothing up my sleeve number   \u2022\nNSA cryptography   \u2022\nNSA encryption systems   \u2022\nNSA in fiction   \u2022\nNSAKEY   \u2022\nNSA Suite A Cryptography   \u2022\nNSA Suite B Cryptography   \u2022\nNT LAN Manager   \u2022\nNTLMSSP   \u2022\nNTRUEncrypt   \u2022\nNTRUSign   \u2022\nNull cipher   \u2022\nNumbers station   \u2022\nNUSH   \u2022\nNTRU\n\n== O ==\nOblivious transfer   \u2022\nOCB mode   \u2022\nOded Goldreich   \u2022\nOff-the-Record Messaging   \u2022\nOkamoto\u2013Uchiyama cryptosystem   \u2022\nOMI cryptograph   \u2022\nOMNI (SCIP)   \u2022\nOne-key MAC   \u2022\nOne-time pad   \u2022\nOne-time password   \u2022\nOne-way compression function   \u2022\nOne-way function   \u2022\nOnion routing   \u2022\nOnline Certificate Status Protocol   \u2022\nOP-20-G   \u2022\nOpenPGP card   \u2022\nOpenSSH   \u2022\nOpenSSL   \u2022\nOpenswan   \u2022\nOpenVPN   \u2022\nOperation Ruthless   \u2022\nOptimal asymmetric encryption padding   \u2022\nOver the Air Rekeying   (OTAR) \u2022\nOTFE   \u2022\nOtway\u2013Rees protocol\n\n== P ==\nPadding (cryptography)   \u2022\nPadding oracle attack    \u2022\nPaillier cryptosystem   \u2022\nPairing-based cryptography   \u2022\nPanama (cryptography)   \u2022\nPartitioning cryptanalysis   \u2022\nPassive attack   \u2022\nPassphrase   \u2022\nPassword   \u2022\nPassword-authenticated key agreement   \u2022\nPassword cracking   \u2022\nPassword Hashing Competition   \u2022\nPaul Kocher   \u2022\nPaulo Pancatuccio   \u2022\nPaulo S. L. M. Barreto   \u2022\nPaul van Oorschot   \u2022\nPBKDF2   \u2022\nPC Bruno   \u2022\nPepper (cryptography)   \u2022\nPerfect forward secrecy   \u2022\nPerforated sheets   \u2022\nPermutation cipher   \u2022\nPeter Gutmann (computer scientist)   \u2022\nPeter Junger   \u2022\nPeter Twinn   \u2022\nPGP Corporation   \u2022\nPGPDisk   \u2022\nPGPfone   \u2022\nPhelix   \u2022\nPhil Zimmermann   \u2022\nPhoturis (protocol)   \u2022\nPhysical security   \u2022\nPhysical unclonable function   \u2022\nPig Latin   \u2022\nPigpen cipher   \u2022\nPike (cipher)   \u2022\nPiling-up lemma   \u2022\nPinwheel (cryptography)   \u2022\nPiotr Smole\u0144ski   \u2022\nPirate decryption   \u2022\nPKC (conference)   \u2022\nPKCS   \u2022\nPKCS 11   \u2022\nPKCS 12   \u2022\nPKIX   \u2022\nPlaintext   \u2022\nPlaintext-aware encryption   \u2022\nPlayfair cipher   \u2022\nPlugboard   \u2022\nPMAC (cryptography)   \u2022\nPoem code   \u2022\nPohlig\u2013Hellman algorithm   \u2022\nPoint-to-Point Tunneling Protocol   \u2022\nPointcheval\u2013Stern signature algorithm   \u2022\nPoly1305   \u2022\nPolyalphabetic cipher   \u2022\nPolybius square   \u2022\nPortex   \u2022\nPost-quantum cryptography   \u2022\nPost-Quantum Cryptography Standardization   \u2022\nPower analysis   \u2022\nPreimage attack   \u2022\nPre-shared key   \u2022\nPretty Good Privacy   \u2022\nPrinter steganography   \u2022\nPrivacy-enhanced Electronic Mail   \u2022\nPrivate Communications Technology   \u2022\nPrivate information retrieval   \u2022\nProbabilistic encryption   \u2022\nProduct cipher   \u2022\nProof-of-work system   \u2022\nProtected Extensible Authentication Protocol   \u2022\nProvable security   \u2022\nProvably secure cryptographic hash function   \u2022\nProxy re-encryption   \u2022\nPseudo-Hadamard transform   \u2022\nPseudonymity   \u2022\nPseudorandom function   \u2022\nPseudorandom number generator   \u2022\nPseudorandom permutation   \u2022\nPublic key certificate   \u2022\nPublic-key cryptography   \u2022\nPublic key fingerprint   \u2022\nPublic key infrastructure   \u2022\nPURPLE   \u2022\nPuTTY   \u2022\nPy (cipher)\n\n== Q ==\nQ (cipher)   \u2022\nQrpff   \u2022\nQUAD (cipher)   \u2022\nQuadratic sieve   \u2022\nQuantum coin flipping   \u2022\nQuantum cryptography   \u2022\nQuantum digital signature   \u2022\nQuantum fingerprinting   \u2022\nQuantum key distribution\n\n== R ==\nRabbit (cipher)   \u2022\nRabin cryptosystem   \u2022\nRabin\u2013Williams encryption   \u2022\nRadioGat\u00fan   \u2022\nRail fence cipher   \u2022\nRainbow table   \u2022\nRalph Merkle   \u2022\nRambutan (cryptography)   \u2022\nRandom function   \u2022\nRandomness tests   \u2022\nRandom number generator attack   \u2022\nRandom oracle   \u2022\nRC2   \u2022\nRC4   \u2022\nRC5   \u2022\nRC6   \u2022\nRebound attack   \u2022\nReciprocal cipher   \u2022\nRed/black concept   \u2022\nREDOC   \u2022\nRed Pike (cipher)   \u2022\nReflector (cipher machine)   \u2022\nRegulation of Investigatory Powers Act 2000   \u2022\nReihenschieber   \u2022\nRekeying (cryptography)   \u2022\nRelated-key attack   \u2022\nReplay attack   \u2022\nReservehandverfahren   \u2022\nResidual block termination   \u2022\nRijndael key schedule   \u2022\nRijndael S-box   \u2022\nRing signature   \u2022\nRIPEMD   \u2022\nRip van Winkle cipher   \u2022\nRobert Morris (cryptographer)   \u2022\nRobot certificate authority   \u2022\nRockex   \u2022\nRolf Noskwith   \u2022\nRon Rivest   \u2022\nRoom 40   \u2022\nRoot certificate   \u2022\nRoss J. Anderson   \u2022\nRossignols   \u2022\nROT13   \u2022\nRotor machine   \u2022\nRSA RSA \u2022\nRSA-100   \u2022\nRSA-1024   \u2022\nRSA-110   \u2022\nRSA-120   \u2022\nRSA-129   \u2022\nRSA-130   \u2022\nRSA-140   \u2022\nRSA-150   \u2022\nRSA-1536   \u2022\nRSA-155   \u2022\nRSA-160   \u2022\nRSA-170   \u2022\nRSA-180   \u2022\nRSA-190   \u2022\nRSA-200   \u2022\nRSA-2048   \u2022\nRSA-210   \u2022\nRSA-220   \u2022\nRSA-230   \u2022\nRSA-232   \u2022\nRSA-240   \u2022\nRSA-250   \u2022\nRSA-260   \u2022\nRSA-270   \u2022\nRSA-280   \u2022\nRSA-290   \u2022\nRSA-300   \u2022\nRSA-309   \u2022\nRSA-310   \u2022\nRSA-320   \u2022\nRSA-330   \u2022\nRSA-340   \u2022\nRSA-350   \u2022\nRSA-360   \u2022\nRSA-370   \u2022\nRSA-380   \u2022\nRSA-390   \u2022\nRSA-400   \u2022\nRSA-410   \u2022\nRSA-420   \u2022\nRSA-430   \u2022\nRSA-440   \u2022\nRSA-450   \u2022\nRSA-460   \u2022\nRSA-470   \u2022\nRSA-480   \u2022\nRSA-490   \u2022\nRSA-500   \u2022\nRSA-576   \u2022\nRSA-617   \u2022\nRSA-640   \u2022\nRSA-704   \u2022\nRSA-768   \u2022\nRSA-896   \u2022\nRSA-PSS   \u2022\nRSA Factoring Challenge   \u2022\nRSA problem   \u2022\nRSA Secret-Key Challenge   \u2022\nRSA Security   \u2022\nRubber-hose cryptanalysis   \u2022\nRunning key cipher   \u2022\nRussian copulation\n\n== S ==\nS-1 block cipher   \u2022\nSAFER   \u2022\nSalsa20   \u2022\nSalt (cryptography)   \u2022\nSAM card   \u2022\nSecurity Support Provider Interface   \u2022\nSAML   \u2022\nSAVILLE   \u2022\nSC2000   \u2022\nSchnorr group   \u2022\nSchnorr signature   \u2022\nSchoof\u2013Elkies\u2013Atkin algorithm   \u2022\nSCIP   \u2022\nScott Vanstone   \u2022\nScrambler   \u2022\nScramdisk   \u2022\nScream (cipher)   \u2022\nScrypt   \u2022\nScytale   \u2022\nSeahorse (software)   \u2022\nSEAL (cipher)   \u2022\nSean Murphy (cryptographer)   \u2022\nSECG   \u2022\nSecret broadcast   \u2022\nSecret decoder ring   \u2022\nSecrets and Lies (Schneier)   \u2022\nSecret sharing   \u2022\nSect\u00e9ra Secure Module   \u2022\nSecure access module   \u2022\nSecure channel   \u2022\nSecure Communication based on Quantum Cryptography   \u2022\nSecure copy   \u2022\nSecure cryptoprocessor   \u2022\nSecure Electronic Transaction   \u2022\nSecure Hash Algorithms   \u2022\nSecure Hypertext Transfer Protocol   \u2022\nSecure key issuing cryptography   \u2022\nSecure multi-party computation   \u2022\nSecure Neighbor Discovery   \u2022\nSecure Real-time Transport Protocol   \u2022\nSecure remote password protocol   \u2022\nSecure Shell   \u2022\nSecure telephone   \u2022\nSecure Terminal Equipment   \u2022\nSecure voice   \u2022\nSecurID   \u2022\nSecurity association   \u2022\nSecurity engineering   \u2022\nSecurity level   \u2022\nSecurity parameter   \u2022\nSecurity protocol notation   \u2022\nSecurity through obscurity   \u2022\nSecurity token   \u2022\nSEED   \u2022\nSelected Areas in Cryptography   \u2022\nSelf-certifying File System   \u2022\nSelf-shrinking generator   \u2022\nSelf-signed certificate   \u2022\nSemantic security   \u2022\nSerge Vaudenay   \u2022\nSerpent (cipher)   \u2022\nSession key   \u2022\nSHACAL   \u2022\nShafi Goldwasser   \u2022\nSHA-1   \u2022\nSHA-2   \u2022\nSHA-3   \u2022\nShared secret   \u2022\nSHARK   \u2022\nShaun Wylie   \u2022\nShor's algorithm   \u2022\nShrinking generator   \u2022\nShugborough inscription   \u2022\nSide-channel attack   \u2022\nSiemens and Halske T52   \u2022\nSIGABA   \u2022\nSIGCUM   \u2022\nSIGINT   \u2022\nSignal Protocol   \u2022\nSignal Intelligence Service   \u2022\nSigncryption   \u2022\nSIGSALY   \u2022\nSILC (protocol)   \u2022\nSilvio Micali   \u2022\nSimple Authentication and Security Layer   \u2022\nSimple public-key infrastructure   \u2022\nSimple XOR cipher   \u2022\nS/KEY   \u2022\nSkein (hash function)   \u2022\nSkipjack (cipher)   \u2022\nSlide attack   \u2022\nSlidex   \u2022\nSmall subgroup confinement attack   \u2022\nS/MIME   \u2022\nSM4 algorithm   (formerly SMS4) \u2022\nSnake oil (cryptography)   \u2022\nSnefru   \u2022\nSNOW   \u2022\nSnuffle   \u2022\nSOBER-128   \u2022\nSolitaire (cipher)   \u2022\nSolomon Kullback   \u2022\nSOSEMANUK   \u2022\nSpecial Collection Service   \u2022\nSpectr-H64   \u2022\nSPEKE (cryptography)   \u2022\nSponge function   \u2022\nSPNEGO   \u2022\nSquare (cipher)   \u2022\nSsh-agent   \u2022 Ssh-keygen   \u2022 SSH File Transfer Protocol   \u2022\nSSLeay   \u2022\nStafford Tavares   \u2022\nStandard model (cryptography)   \u2022\nStation CAST   \u2022\nStation HYPO   \u2022\nStation-to-Station protocol   \u2022\nStatistical cryptanalysis   \u2022\nStefan Lucks   \u2022\nSteganalysis   \u2022\nSteganography   \u2022\nStraddling checkerboard   \u2022\nStream cipher   \u2022\nStream cipher attacks   \u2022\nStrong cryptography   \u2022\nStrong RSA assumption   \u2022\nStuart Milner-Barry   \u2022\nSTU-II   \u2022\nSTU-III   \u2022\nStunnel   \u2022\nSubstitution box   \u2022\nSubstitution cipher   \u2022\nSubstitution\u2013permutation network   \u2022\nSuperencryption   \u2022\nSupersingular isogeny key exchange   \u2022\nSwedish National Defence Radio Establishment   \u2022\nSWIFFT   \u2022\nSXAL/MBAL   \u2022\nSymmetric-key algorithm   \u2022\nSYSKEY\n\n== T ==\nTabula recta   \u2022\nTaher Elgamal   \u2022\nTamper resistance   \u2022\nTcpcrypt   \u2022\nTelevision encryption   \u2022\nTEMPEST   \u2022\nTemplate:Cryptographic software   \u2022\nTemporal Key Integrity Protocol   \u2022\nTestery   \u2022\nThawte   \u2022\nThe Alphabet Cipher   \u2022\nThe Code Book   \u2022\nThe Codebreakers   \u2022\nThe Gold-Bug   \u2022\nThe Magic Words are Squeamish Ossifrage   \u2022\nTheory of Cryptography Conference   \u2022\nThe world wonders   \u2022\nThomas Jakobsen   \u2022\nThree-pass protocol   \u2022\nThreshold shadow scheme   \u2022\nTICOM   \u2022\nTiger (cryptography)   \u2022\nTimeline of cryptography   \u2022\nTime/memory/data tradeoff attack   \u2022\nTime-based One-time Password algorithm   (TOTP) \u2022\nTiming attack   \u2022\nTiny Encryption Algorithm   \u2022\nTom Berson   \u2022\nTommy Flowers   \u2022\nTopics in cryptography   \u2022\nTor (anonymity network)   \u2022\nTorus-based cryptography   \u2022\nTraffic analysis   \u2022\nTraffic-flow security   \u2022\nTraitor tracing   \u2022\nTransmission security   \u2022\nTransport Layer Security   \u2022\nTransposition cipher   \u2022\nTrapdoor function   \u2022\nTrench code   \u2022\nTreyfer   \u2022\nTrifid cipher   \u2022\nTriple DES   \u2022\nTrivium (cipher)   \u2022\nTrueCrypt   \u2022\nTruncated differential cryptanalysis   \u2022\nTrusted third party   \u2022\nTuring (cipher)   \u2022\nTWINKLE   \u2022\nTWIRL   \u2022\nTwofish   \u2022\nTwo-square cipher   \u2022\nType 1 encryption   \u2022\nType 2 encryption   \u2022\nType 3 encryption   \u2022\nType 4 encryption   \u2022\nTypex\n\n== U ==\nUES (cipher)   \u2022\nUltra   \u2022\nUMAC   \u2022\nUnbalanced Oil and Vinegar   \u2022\nUndeniable signature   \u2022\nUnicity distance   \u2022\nUniversal composability   \u2022\nUniversal one-way hash function   (UOWHF)\n\n== V ==\nVenona project   \u2022\nVerifiable secret sharing   \u2022\nVerisign   \u2022\nVery smooth hash   \u2022\nVEST   \u2022\nVIC cipher   \u2022\nVideoCrypt   \u2022\nVigen\u00e8re cipher   \u2022\nVincent Rijmen   \u2022\nVINSON   \u2022\nVirtual private network   \u2022\nVisual cryptography   \u2022\nVoynich manuscript\n\n== W ==\nWadsworth's cipher   \u2022\nWAKE   \u2022\nWLAN Authentication and Privacy Infrastructure   \u2022\nWatermark (data file)   \u2022\nWatermarking attack   \u2022\nWeak key   \u2022\nWeb of trust   \u2022\nWhirlpool (hash function)   \u2022\nWhitfield Diffie   \u2022\nWide Mouth Frog protocol   \u2022\nWi-Fi Protected Access   \u2022\nWilliam F. Friedman   \u2022\nWilliam Montgomery (cryptographer)   \u2022\nWinSCP   \u2022\nWired Equivalent Privacy   \u2022\nWireless Transport Layer Security   \u2022\nWitness-indistinguishable proof   \u2022\nWorkshop on Cryptographic Hardware and Embedded Systems   \u2022\nWorld War I cryptography   \u2022\nWorld War II cryptography   \u2022\nW. T. Tutte\n\n== X ==\nX.509   \u2022\nXDH assumption   \u2022\nXiaoyun Wang   \u2022\nXML Encryption   \u2022\nXML Signature   \u2022\nxmx   \u2022\nXSL attack   \u2022\nXTEA   \u2022\nXTR   \u2022\nXuejia Lai   \u2022\nXXTEA  \n10-00-00-00-00\n\n== Y ==\nYarrow algorithm   \u2022\nY-stations   \u2022\nYuliang Zheng\n\n== Z ==\nZeroisation   \u2022\nZero-knowledge password proof   \u2022\nZero-knowledge proof   \u2022\nZfone   \u2022\nZodiac (cipher)   \u2022\nZRTP   \u2022\nZimmermann\u2013Sassaman key-signing protocol   \u2022\nZimmermann Telegram"
    }
  },
  {
    "instruction": "Write an answer to the following question: What is Security for Office Communications Server and what does it do?",
    "context": "",
    "output": "Security for Office Communications Server protects computers running Microsoft Office Communications Server from malware. It was formerly called Antigen for Instant Messaging.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is Security for Office Communications Server and what does it do?",
      "answer": "Security for Office Communications Server protects computers running Microsoft Office Communications Server from malware. It was formerly called Antigen for Instant Messaging."
    }
  },
  {
    "instruction": "Write an answer to the following question: Who was Mr. P-Teo and what was his role in The Unknowns?",
    "context": "",
    "output": "Mr. P-Teo was a programmer in The Unknowns. He was responsible for developing and maintaining the tools used by the group to hack various websites.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Who was Mr. P-Teo and what was his role in The Unknowns?",
      "answer": "Mr. P-Teo was a programmer in The Unknowns. He was responsible for developing and maintaining the tools used by the group to hack various websites."
    }
  },
  {
    "instruction": "Capability-based security\n\n==Introduction==\nCapability-based security is a concept in the design of secure computing systems, one of the existing security models. A capability (known in some systems as a key) is a communicable, unforgeable token of authority. It refers to a value that references an object along with an associated set of access rights. A user program on a capability-based operating system must use a capability to access an object. Capability-based security refers to the principle of designing user programs such that they directly share capabilities with each other according to the principle of least privilege, and to the operating system infrastructure necessary to make such transactions efficient and secure. Capability-based security is to be contrasted with an approach that uses traditional UNIX permissions and Access Control Lists.\nAlthough most operating systems implement a facility which resembles capabilities, they typically do not provide enough support to allow for the exchange of capabilities among possibly mutually untrusting entities to be the primary means of granting and distributing access rights throughout the system. A capability-based system, in contrast, is designed with that goal in mind.\n\n\n\n== Introduction ==\nCapabilities achieve their objective of improving system security by being used in place of forgeable references. A forgeable reference (for example, a path name) identifies an object, but does not specify which access rights are appropriate for that object and the user program which holds that reference. Consequently, any attempt to access the referenced object must be validated by the operating system, based on the ambient authority of the requesting program, typically via the use of an access-control list (ACL). Instead, in a system with capabilities, the mere fact that a user program possesses that capability entitles it to use the referenced object in accordance with the rights that are specified by that capability. In theory, a system with capabilities removes the need for any access control list or similar mechanism by giving all entities all and only the capabilities they will actually need.\nA capability is typically implemented as a privileged data structure that consists of a section that specifies access rights, and a section that uniquely identifies the object to be accessed. The user does not access the data structure or object directly, but instead via a handle. In practice, it is used much like a file descriptor in a traditional operating system (a traditional handle), but to access every object on the system. Capabilities are typically stored by the operating system in a list, with some mechanism in place to prevent the program from directly modifying the contents of the capability (so as to forge access rights or change the object it points to). Some systems have also been based on capability-based addressing (hardware support for capabilities), such as Plessey System 250.\nPrograms possessing capabilities can perform functions on them, such as passing them on to other programs, converting them to a less-privileged version, or deleting them. The operating system must ensure that only specific operations can occur to the capabilities in the system, in order to maintain the integrity of the security policy.\nCapabilities as discussed in this article should not be confused with Portable Operating System Interface (POSIX) 1e/2c \"Capabilities\". The latter are coarse-grained privileges that cannot be transferred between processes.\n\n== Examples ==\nA capability is defined to be a protected object reference which, by virtue of its possession by a user process, grants that process the capability (hence the name) to interact with an object in certain ways. Those ways might include reading data associated with an object, modifying the object, executing the data in the object as a process, and other conceivable access rights. The capability logically consists of a reference that uniquely identifies a particular object and a set of one or more of these rights.\nSuppose that, in a user process's memory space, there exists the following string:\n\n/etc/passwd\n\nAlthough this identifies a unique object on the system, it does not specify access rights and hence is not a capability. Suppose there is instead the following pair of values:\n\n/etc/passwd\nO_RDWR\n\nThis pair identifies an object along with a set of access rights. The pair, however, is still not a capability because the user process's possession of these values says nothing about whether that access would actually be legitimate.\nNow suppose that the user program successfully executes the following statement:\n\nThe variable fd now contains the index of a file descriptor in the process's file descriptor table. This file descriptor is a capability. Its existence in the process's file descriptor table is sufficient to show that the process does indeed have legitimate access to the object. A key feature of this arrangement is that the file descriptor table is in kernel memory and cannot be directly manipulated by the user program.\n\n== Sharing between processes ==\nIn traditional operating systems, programs often communicate with each other and with storage using references like those in the first two examples. Path names are often passed as command-line parameters, sent via sockets, and stored on disk. These references are not capabilities, and must be validated before they can be used. In these systems, a central question is \"on whose authority is a given reference to be evaluated?\" This becomes a critical issue especially for processes which must act on behalf of two different authority-bearing entities. They become susceptible to a programming error known as the confused deputy problem, very frequently resulting in a security hole.\nIn a capability-based system, the capabilities themselves are passed between processes and storage using a mechanism that is known by the operating system to maintain the integrity of those capabilities.\nOne novel approach to solving this problem involves the use of an orthogonally persistent operating system. In such a system, there is no need for entities to be discarded and their capabilities be invalidated, and hence require an ACL-like mechanism to restore those capabilities at a later time. The operating system maintains the integrity and security of the capabilities contained within all storage, both volatile and nonvolatile, at all times; in part by performing all serialization tasks by itself, rather than requiring user programs to do so, as is the case in most operating systems. Because user programs are relieved of this responsibility, there is no need to trust them to reproduce only legal capabilities, nor to validate requests for access using an access control mechanism. An example implementation is the Flex machine from the early 1980s.\n\n== POSIX capabilities ==\nPortable Operating System Interface (POSIX) draft 1003.1e specifies a concept of permissions called \"capabilities\". However, POSIX capabilities differ from capabilities in this article. A POSIX capability is not associated with any object; a process having CAP_NET_BIND_SERVICE capability can listen on any TCP port under 1024. This system is found in Linux.In contrast, Capsicum Unix hybridizes a true capability-system model with a Unix design and POSIX API. Capsicum capabilities are a refined form of file descriptor, a delegable right between processes and additional object types beyond classic POSIX, such as processes, can be referenced via capabilities. In Capsicum capability mode, processes are unable to utilize global namespaces (such as the filesystem namespace) to look up objects, and must instead inherit or be delegated them. This system is found natively in FreeBSD, but patches are available to other systems.\n\n== Implementations ==\nNotable research and commercial systems employing capability-based security include the following:\n\nTahoe-LAFS, an open-source capability-based filesystem\nGNOSIS, an operating system developed at Tymshare\nKeyKOS, successor to GNOSIS\nEROS, The Extremely Reliable Operating System, successor to KeyKOS\nCapROS, a project to further develop the EROS code base for commercial use\nCambridge CAP computer\nHydra (operating system), part of the C.mmp project at Carnegie Mellon University\nStarOS, part of the CM* project at Carnegie Mellon University\nIBM System/38 and AS/400\nIntel iAPX 432\nPlessey System 250\nFlex\nL4 microkernel family:\nOKL4 from Open Kernel Labs\nseL4 from NICTA\nFiasco.OC and NOVA from TU Dresden\nAmoeba distributed operating system\nFreeBSD Capsicum\nGenode\nGoogle Fuchsia\nWebAssembly System Interface (WASI)\nQ: What is the difference between capabilities as discussed in this article and POSIX 1e/2c \"Capabilities\"?",
    "context": "",
    "output": "Capabilities as discussed in this article are fine-grained and can be transferred between processes, while POSIX 1e/2c \"Capabilities\" are coarse-grained privileges that cannot be transferred between processes.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the difference between capabilities as discussed in this article and POSIX 1e/2c \"Capabilities\"?",
      "answer": "Capabilities as discussed in this article are fine-grained and can be transferred between processes, while POSIX 1e/2c \"Capabilities\" are coarse-grained privileges that cannot be transferred between processes.",
      "context": "Capability-based security\n\n==Introduction==\nCapability-based security is a concept in the design of secure computing systems, one of the existing security models. A capability (known in some systems as a key) is a communicable, unforgeable token of authority. It refers to a value that references an object along with an associated set of access rights. A user program on a capability-based operating system must use a capability to access an object. Capability-based security refers to the principle of designing user programs such that they directly share capabilities with each other according to the principle of least privilege, and to the operating system infrastructure necessary to make such transactions efficient and secure. Capability-based security is to be contrasted with an approach that uses traditional UNIX permissions and Access Control Lists.\nAlthough most operating systems implement a facility which resembles capabilities, they typically do not provide enough support to allow for the exchange of capabilities among possibly mutually untrusting entities to be the primary means of granting and distributing access rights throughout the system. A capability-based system, in contrast, is designed with that goal in mind.\n\n\n\n== Introduction ==\nCapabilities achieve their objective of improving system security by being used in place of forgeable references. A forgeable reference (for example, a path name) identifies an object, but does not specify which access rights are appropriate for that object and the user program which holds that reference. Consequently, any attempt to access the referenced object must be validated by the operating system, based on the ambient authority of the requesting program, typically via the use of an access-control list (ACL). Instead, in a system with capabilities, the mere fact that a user program possesses that capability entitles it to use the referenced object in accordance with the rights that are specified by that capability. In theory, a system with capabilities removes the need for any access control list or similar mechanism by giving all entities all and only the capabilities they will actually need.\nA capability is typically implemented as a privileged data structure that consists of a section that specifies access rights, and a section that uniquely identifies the object to be accessed. The user does not access the data structure or object directly, but instead via a handle. In practice, it is used much like a file descriptor in a traditional operating system (a traditional handle), but to access every object on the system. Capabilities are typically stored by the operating system in a list, with some mechanism in place to prevent the program from directly modifying the contents of the capability (so as to forge access rights or change the object it points to). Some systems have also been based on capability-based addressing (hardware support for capabilities), such as Plessey System 250.\nPrograms possessing capabilities can perform functions on them, such as passing them on to other programs, converting them to a less-privileged version, or deleting them. The operating system must ensure that only specific operations can occur to the capabilities in the system, in order to maintain the integrity of the security policy.\nCapabilities as discussed in this article should not be confused with Portable Operating System Interface (POSIX) 1e/2c \"Capabilities\". The latter are coarse-grained privileges that cannot be transferred between processes.\n\n== Examples ==\nA capability is defined to be a protected object reference which, by virtue of its possession by a user process, grants that process the capability (hence the name) to interact with an object in certain ways. Those ways might include reading data associated with an object, modifying the object, executing the data in the object as a process, and other conceivable access rights. The capability logically consists of a reference that uniquely identifies a particular object and a set of one or more of these rights.\nSuppose that, in a user process's memory space, there exists the following string:\n\n/etc/passwd\n\nAlthough this identifies a unique object on the system, it does not specify access rights and hence is not a capability. Suppose there is instead the following pair of values:\n\n/etc/passwd\nO_RDWR\n\nThis pair identifies an object along with a set of access rights. The pair, however, is still not a capability because the user process's possession of these values says nothing about whether that access would actually be legitimate.\nNow suppose that the user program successfully executes the following statement:\n\nThe variable fd now contains the index of a file descriptor in the process's file descriptor table. This file descriptor is a capability. Its existence in the process's file descriptor table is sufficient to show that the process does indeed have legitimate access to the object. A key feature of this arrangement is that the file descriptor table is in kernel memory and cannot be directly manipulated by the user program.\n\n== Sharing between processes ==\nIn traditional operating systems, programs often communicate with each other and with storage using references like those in the first two examples. Path names are often passed as command-line parameters, sent via sockets, and stored on disk. These references are not capabilities, and must be validated before they can be used. In these systems, a central question is \"on whose authority is a given reference to be evaluated?\" This becomes a critical issue especially for processes which must act on behalf of two different authority-bearing entities. They become susceptible to a programming error known as the confused deputy problem, very frequently resulting in a security hole.\nIn a capability-based system, the capabilities themselves are passed between processes and storage using a mechanism that is known by the operating system to maintain the integrity of those capabilities.\nOne novel approach to solving this problem involves the use of an orthogonally persistent operating system. In such a system, there is no need for entities to be discarded and their capabilities be invalidated, and hence require an ACL-like mechanism to restore those capabilities at a later time. The operating system maintains the integrity and security of the capabilities contained within all storage, both volatile and nonvolatile, at all times; in part by performing all serialization tasks by itself, rather than requiring user programs to do so, as is the case in most operating systems. Because user programs are relieved of this responsibility, there is no need to trust them to reproduce only legal capabilities, nor to validate requests for access using an access control mechanism. An example implementation is the Flex machine from the early 1980s.\n\n== POSIX capabilities ==\nPortable Operating System Interface (POSIX) draft 1003.1e specifies a concept of permissions called \"capabilities\". However, POSIX capabilities differ from capabilities in this article. A POSIX capability is not associated with any object; a process having CAP_NET_BIND_SERVICE capability can listen on any TCP port under 1024. This system is found in Linux.In contrast, Capsicum Unix hybridizes a true capability-system model with a Unix design and POSIX API. Capsicum capabilities are a refined form of file descriptor, a delegable right between processes and additional object types beyond classic POSIX, such as processes, can be referenced via capabilities. In Capsicum capability mode, processes are unable to utilize global namespaces (such as the filesystem namespace) to look up objects, and must instead inherit or be delegated them. This system is found natively in FreeBSD, but patches are available to other systems.\n\n== Implementations ==\nNotable research and commercial systems employing capability-based security include the following:\n\nTahoe-LAFS, an open-source capability-based filesystem\nGNOSIS, an operating system developed at Tymshare\nKeyKOS, successor to GNOSIS\nEROS, The Extremely Reliable Operating System, successor to KeyKOS\nCapROS, a project to further develop the EROS code base for commercial use\nCambridge CAP computer\nHydra (operating system), part of the C.mmp project at Carnegie Mellon University\nStarOS, part of the CM* project at Carnegie Mellon University\nIBM System/38 and AS/400\nIntel iAPX 432\nPlessey System 250\nFlex\nL4 microkernel family:\nOKL4 from Open Kernel Labs\nseL4 from NICTA\nFiasco.OC and NOVA from TU Dresden\nAmoeba distributed operating system\nFreeBSD Capsicum\nGenode\nGoogle Fuchsia\nWebAssembly System Interface (WASI)"
    }
  },
  {
    "instruction": "Write an answer to the following question: What are some datasets available for anomaly detection benchmarking?",
    "context": "",
    "output": "Some datasets available for anomaly detection benchmarking include the anomaly detection benchmark data repository with carefully chosen data sets of the Ludwig-Maximilians-Universit\u00e4t M\u00fcnchen, ODDS \u2013 ODDS: A large collection of publicly available outlier detection datasets with ground truth in different domains, the Unsupervised Anomaly Detection Benchmark at Harvard Dataverse: Datasets for Unsupervised Anomaly Detection with ground truth, and the KMASH Data Repository at Research Data Australia, which has more than 12,000 anomaly detection datasets with ground truth.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are some datasets available for anomaly detection benchmarking?",
      "answer": "Some datasets available for anomaly detection benchmarking include the anomaly detection benchmark data repository with carefully chosen data sets of the Ludwig-Maximilians-Universit\u00e4t M\u00fcnchen, ODDS \u2013 ODDS: A large collection of publicly available outlier detection datasets with ground truth in different domains, the Unsupervised Anomaly Detection Benchmark at Harvard Dataverse: Datasets for Unsupervised Anomaly Detection with ground truth, and the KMASH Data Repository at Research Data Australia, which has more than 12,000 anomaly detection datasets with ground truth."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the impact of spam on forum administration resources?",
    "context": "",
    "output": "Spam prevention and deletions measurably increase the workload of forum administrators and moderators, contributing to labor costs and the skill required to run a public forum.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the impact of spam on forum administration resources?",
      "answer": "Spam prevention and deletions measurably increase the workload of forum administrators and moderators, contributing to labor costs and the skill required to run a public forum."
    }
  },
  {
    "instruction": "Electronic authentication\n\n==Introduction==\nElectronic authentication is the process of establishing confidence in user identities electronically presented to an information system. Digital authentication, or e-authentication, may be used synonymously when referring to the authentication process that confirms or certifies a person's identity and works.  When used in conjunction with an electronic signature, it can provide evidence of whether data received has been tampered with after being signed by its original sender. Electronic authentication can reduce the risk of fraud and identity theft by verifying that a person is who they say they are when performing transactions online.Various e-authentication methods can be used to authenticate a user's identify ranging from a password to higher levels of security that utilize multifactor authentication (MFA). Depending on the level of security used, the user might need to prove his or her identity through the use of security tokens, challenge questions, or being in possession of a certificate from a third-party certificate authority that attests to their identity.\n\n\n\n== Overview ==\n The American National Institute of Standards and Technology (NIST) has developed a generic electronic authentication model that provides a basic framework on how the authentication process is accomplished regardless of jurisdiction or geographic region. According to this model, the enrollment process begins with an individual applying to a Credential Service Provider (CSP). The CSP will need to prove the applicant's identity before proceeding with the transaction. Once the applicant's identity has been confirmed by the CSP, he or she receives the status of \"subscriber\", is given an authenticator, such as a token and a credential, which may be in the form of a username.\nThe CSP is responsible for managing the credential along with the subscriber's enrollment data for the life of the credential. The subscriber will be tasked with maintaining the authenticators. An example of this is when a user normally uses a specific computer to do their online banking. If he or she attempts to access their bank account from another computer, the authenticator will not be present. In order to gain access, the subscriber would need to verify their identity to the CSP, which might be in the form of answering a challenge question successfully before being given access.\n\n\n*** Use of electronic authorization in medical field ***\nNew invention on medicines, and novel development on medical technologies had been widely deployed and adopted in modern societies. In consequence, the average lifetime of human being is much longer than it was before. \nTherefore, to safely establish and manage personal health records for each individual during his/her lifetime within the electronic form has gradually become an interesting topic for individual citizens and social welfare departments; the reason is that a well-maintained health records document of an individual can help doctors and hospitals know important and necessary medical and body conditions of the targeted patient in time before conducting any therapy.\n\n== Authentication factors ==\n\nThere are three generally accepted factors that are used to establish a digital identity for electronic authentication, including:\n\nKnowledge factor, which is something that the user knows, such as a password, answers to challenge questions, ID numbers or a PIN.\nPossession factor, which is something that the user has, such as mobile phone, PC or token\nBiometric factor, which is something that the user is, such as his or her fingerprints, eye scan or voice patternOut of the three factors, the biometric factor is the most convenient and convincing to prove an individual's identity, but it is the most expensive to implement. Each factor has its weaknesses; hence, reliable and strong authentication depends on combining two or more factors. This is known as multi-factor authentication, of which two-factor authentication and two-step verification are subtypes.\nMulti-factor authentication can still be vulnerable to attacks, including man-in-the-middle attacks and Trojan attacks.\n\n== Methods ==\n\n\n*** Token ***\n\nTokens generically are something the claimant possesses and controls that may be used to authenticate the claimant's identity. In e-authentication, the claimant authenticates to a system or application over a network. Therefore, a token used for e-authentication is a secret and the token must be protected. The token may, for example, be a cryptographic key, that is protected by encrypting it under a password. An impostor must steal the encrypted key and learn the password to use the token.\n\n\n*** Passwords and PIN-based authentication ***\nPasswords and PINs are categorized as \"something you know\" method. A combination of numbers, symbols, and mixed cases are considered to be stronger than all-letter password. Also, the adoption of Transport Layer Security (TLS) or Secure Socket Layer (SSL) features during the information transmission process will as well create an encrypted channel for data exchange and to further protect information delivered. Currently, most security attacks target on password-based authentication systems.\n\n\n*** Public-key authentication ***\nThis type of authentication has two parts. One is a public key, the other is a private key. A public key is issued by a Certification Authority and is available to any user or server.  A private key is known by the user only.\n\n\n*** Symmetric-key authentication ***\nThe user shares a unique key with an authentication server. When the user sends a randomly generated message (the challenge) encrypted by the secret key to the authentication server, if the message can be matched by the server using its shared secret key, the user is authenticated.\nWhen implemented together with the password authentication, this method also provides a possible solution for two-factor authentication systems.\n\n\n*** SMS-based authentication ***\n\nThe user receives password by reading the message in the cell phone, and types back the password to complete the authentication. Short Message Service (SMS) is very effective when cell phones are commonly adopted. SMS is also suitable against man-in-the-middle (MITM) attacks, since the use of SMS does not involve the Internet.\n\n\n*** Biometric authentication ***\nBiometric authentication is the use of unique physical attributes and body measurements as the intermediate for better identification and access control. Physical characteristics that are often used for authentication include fingerprints, voice recognition, face recognition, and iris scans because all of these are unique to every individual. Traditionally, biometric authentication based on token-based identification systems, such as passport, and nowadays becomes one of the most secure identification systems to user protections. A new technological innovation which provides a wide variety of either behavioral or physical characteristics which are defining the proper concept of biometric authentication.\n\n\n*** Digital identity authentication ***\nDigital identity authentication refers to the combined use of device, behavior, location and other data, including email address, account and credit card information, to authenticate online users in real time. For example, recent work have explored how to exploit browser fingerprinting as part of a multi-factor authentication scheme.\n\n== Electronic credentials ==\nPaper credentials are documents that attest to the identity or other attributes of an individual or entity called the subject of the credentials. Some common paper credentials include passports, birth certificates, driver's licenses, and employee identity cards. The credentials themselves are authenticated in a variety of ways: traditionally perhaps by a signature or a seal, special papers and inks, high quality engraving, and today by more complex mechanisms, such as holograms, that make the credentials recognizable and difficult to copy or forge. In some cases, simple possession of the credentials is sufficient to establish that the physical holder of the credentials is indeed the subject of the credentials. More commonly, the credentials contain biometric information such as the subject's description, a picture of the subject or the handwritten signature of the subject that can be used to authenticate that the holder of the credentials is indeed the subject of the credentials. When these paper credentials are presented in-person, authentication biometrics contained in those credentials can be checked to confirm that the physical holder of the credential is the subject.\nElectronic identity credentials bind a name and perhaps other attributes to a token. There are a variety of electronic credential types in use today, and new types of credentials are constantly being created (eID, electronic voter ID card, biometric passports, bank cards, etc.) At a minimum, credentials include identifying information that permits recovery of the records of the registration associated with the credentials and a name that is associated with the subscriber.\n\n== Verifiers ==\nIn any authenticated on-line transaction, the verifier is the party that verifies that the claimant has possession and control of the token that verifies his or her identity. A claimant authenticates his or her identity to a verifier by the use of a token and an authentication protocol. This is called Proof of Possession (PoP). Many PoP protocols are designed so that a verifier, with no knowledge of the token before the authentication protocol run, learns nothing about the token from the run. The verifier and CSP may be the same entity, the verifier and relying party may be the same entity or they may all three be separate entities. It is undesirable for verifiers to learn shared secrets unless they are a part of the same entity as the CSP that registered the tokens. Where the verifier and the relying party are separate entities, the verifier must convey the result of the authentication protocol to the relying party. The object created by the verifier to convey this result is called an assertion.\n\n== Authentication schemes ==\nThere are four types of authentication schemes: local authentication, centralized authentication, global centralized authentication, global authentication and web application (portal).\nWhen using a local authentication scheme, the application retains the data that pertains to the user's credentials. This information is not usually shared with other applications. The onus is on the user to maintain and remember the types and number of credentials that are associated with the service in which they need to access. This is a high risk scheme because of the possibility that the storage area for passwords might become compromised.\nUsing the central authentication scheme allows for each user to use the same credentials to access various services. Each application is different and must be designed with interfaces and the ability to interact with a central system to successfully provide authentication for the user. This allows the user to access important information and be able to access private keys that will allow him or her to electronically sign documents.\nUsing a third party through a global centralized authentication scheme allows the user direct access to authentication services. This then allows the user to access the particular services they need.\nThe most secure scheme is the global centralized authentication and web application (portal). It is ideal for E-Government use because it allows a wide range of services. It uses a single authentication mechanism involving a minimum of two factors to allow access to required services and the ability to sign documents.\n\n== Authentication and digital signing working together ==\nOften, authentication and digital signing are applied in conjunction. In advanced electronic signatures, the signatory has authenticated and uniquely linked to a signature. In the case of a qualified electronic signature as defined in the eIDAS-regulation, the signer's identity is even certified by a qualified trust service provider. This linking of signature and authentication firstly supports the probative value of the signature \u2013 commonly referred to as non-repudiation of origin. The protection of the message on the network-level is called non-repudiation of emission. The authenticated sender and the message content are linked to each other. If a 3rd party tries to change the message content, the signature loses validity.\n\n== Risk assessment ==\nWhen developing electronic systems, there are some industry standards requiring United States agencies to ensure the transactions provide an appropriate level of assurance. Generally, servers adopt the US' Office of Management and Budget's (OMB's) E-Authentication Guidance for Federal Agencies (M-04-04) as a guideline, which is published to help federal agencies provide secure electronic services that protect individual privacy. It asks agencies to check whether their transactions require e-authentication, and determine a proper level of assurance.It established four levels of assurance:Assurance Level 1: Little or no confidence in the asserted identity's validity.\nAssurance Level 2: Some confidence in the asserted identity's validity. \nAssurance Level 3: High confidence in the asserted identity's validity. \nAssurance Level 4: Very high confidence in the asserted identity's validity.\n\n\n*** Determining assurance levels ***\nThe OMB proposes a five-step process to determine the appropriate assurance level for their applications:\n\nConduct a risk assessment, which measures possible negative impacts.\nCompare with the five assurance levels and decide which one suits this case.\nSelect technology according to the technical guidance issued by NIST.\nConfirm the selected authentication process satisfies requirements.\nReassess the system regularly and adjust it with changes.The required level of authentication assurance are assessed through the factors below:\n\nInconvenience, distress, or damage to standing or reputation;\nFinancial loss or agency liability;\nHarm to agency programs or public interests;\nUnauthorized release of sensitive information;\nPersonal safety; and/or civil or criminal violations.\n\n\n*** Determining technical requirements ***\nNational Institute of Standards and Technology (NIST) guidance defines technical requirements for each of the four levels of assurance in the following areas:\nTokens are used for proving identity. Passwords and symmetric cryptographic keys are private information that the verifier needs to protect. Asymmetric cryptographic keys have a private key (which only the subscriber knows) and a related public key.\nIdentity proofing, registration, and the delivery of credentials that bind an identity to a token. This process can involve a far distance operation.\nCredentials, tokens, and authentication protocols can also be combined to identify that a claimant is in fact the claimed subscriber.\nAn assertion mechanism that involves either a digital signature of the claimant or is acquired directly by a trusted third party through a secure authentication protocol.\n\n== Guidelines and regulations ==\nTriggered by the growth of new cloud solutions and online transactions, person-to-machine and machine-to-machine identities play a significant role in identifying individuals and accessing information. According to the Office of Management and Budget in the U.S., more than $70 million was spent on identity management solutions in both 2013 and 2014.Governments use e-authentication systems to offer services and reduce time people traveling to a government office. Services ranging from applying for visas to renewing driver's licenses can all be achieved in a more efficient and flexible way. Infrastructure to support e-authentication is regarded as an important component in successful e-government. Poor coordination and poor technical design might be major barriers to electronic authentication.In several countries there has been established nationwide common e-authentication schemes to ease the reuse of digital identities in different electronic services. Other policy initiatives have included the creation of frameworks for electronic authentication, in order to establish common levels of trust and possibly interoperability between different authentication schemes.\n\n\n*** United States ***\nE-authentication is a centerpiece of the United States government's effort to expand electronic government, or e-government, as a way of making government more effective and efficient and easier to access. The e-authentication service enables users to access government services online using log-in IDs (identity credentials) from other web sites that both the user and the government  trust.\nE-authentication is a government-wide partnership that is supported by the agencies that comprise the Federal CIO Council. The United States General Services Administration (GSA) is the lead agency partner. E-authentication works through an association with a trusted credential issuer, making it necessary for the user to log into the issuer's site to obtain the authentication credentials.  Those credentials or e-authentication ID are then transferred the supporting government web site causing authentication. The system was created in response a December 16, 2003  memorandum was issued through the  Office of Management and Budget.  Memorandum M04-04 Whitehouse. That memorandum updates the guidance issued in the  Paperwork Elimination Act of 1998, 44 U.S.C. \u00a7 3504 and implements section 203 of the E-Government Act, 44 U.S.C. ch. 36.\nNIST provides guidelines for digital authentication standards and does away with most knowledge-based authentication methods. A stricter standard has been drafted on more complicated passwords that at least 8 characters long or passphrases that are at least 64 characters long.\n\n\n*** Europe ***\nIn Europe, eIDAS provides guidelines to be used for electronic authentication in regards to electronic signatures and certificate services for website authentication. Once confirmed by the issuing Member State, other participating States are required to accept the user's electronic signature as valid for cross border transactions.\nUnder eIDAS, electronic identification refers to a material/immaterial unit that contains personal identification data to be used for authentication for an online service. Authentication is referred to as an electronic process that allows for the electronic identification of a natural or legal person. A trust service is an electronic service that is used to create, verify and validate electronic signatures, in addition to creating, verifying and validating certificates for website authentication.\nArticle 8 of eIDAS allows for the authentication mechanism that is used by a natural or legal person to use electronic identification methods in confirming their identity to a relying party. Annex IV provides requirements for qualified certificates for website authentication.\n\n\n*** Russia ***\nE-authentication is a centerpiece of the Russia government's effort to expand e-government, as a way of making government more effective and efficient and easier for the Russian people to access. The e-authentication service enables users to access government services online using log-in IDs (identity credentials) they already have from web sites that they and the government trust.\n\n== Other applications ==\nApart from government services, e-authentication is also widely used in other technology and industries. These new applications combine the features of authorizing identities in traditional database and new technology to provide a more secure and diverse use of e-authentication. Some examples are described below.\n\n\n*** Mobile authentication ***\nMobile authentication is the verification of a user's identity through the use a mobile device. It can be treated as an independent field or it can also be applied with other multifactor authentication schemes in the e-authentication field.For mobile authentication, there are five levels of application sensitivity from Level 0 to Level 4. Level 0 is for public use over a mobile device and requires no identity authentications, while level 4 has the most multi-procedures to identify users.  For either level, mobile authentication is relatively easy to process. Firstly, users send a one-time password (OTP) through offline channels. Then, a server identifies the information and makes adjustment in the database. Since only the user has the access to a PIN code and can send information through their mobile devices, there is a low risk of attacks.\n\n\n*** E-commerce authentication ***\nIn the early 1980s, electronic data interchange (EDI) systems was implemented, which was considered as an early representative of E-commerce. But ensuring its security is not a significant issue since the systems are all constructed around closed networks. However, more recently, business-to-consumer transactions have transformed. Remote transacting parties have forced the implementation of E-commerce authentication systems.Generally speaking, the approaches adopted in E-commerce authentication are basically the same as e-authentication. The difference is E-commerce authentication is a more narrow field that focuses on the transactions between customers and suppliers. A simple example of E-commerce authentication includes a client communicating with a merchant server via the Internet. The merchant server usually utilizes a web server to accept client requests, a database management system to manage data and a payment gateway to provide online payment services.\n\n\n*** Self-sovereign identity ***\nWith self-sovereign identity (SSI) the individual identity holders fully create and control their credentials. Whereas the verifiers can authenticate the provided identities on a decentralized network.\n\n== Perspectives ==\nTo keep up with the evolution of services in the digital world, there is continued need for security mechanisms. While passwords will continue to be used, it is important to rely on authentication mechanisms, most importantly multifactor authentication. As the usage of e-signatures continues to significantly expand throughout the United States, the EU and throughout the world, there is expectation that regulations such as eIDAS will eventually be amended to reflect changing conditions along with regulations in the United States.\n\nQ: How do passwords and PINs provide security for electronic authentication, and what are some best practices for using them?",
    "context": "",
    "output": "A: Passwords and PINs provide security for electronic authentication by categorizing them as \"something you know\" method. A combination of numbers, symbols, and mixed cases are considered to be stronger than all-letter password. However, most security attacks target on password-based authentication systems. To enhance the security, the adoption of Transport Layer Security (TLS) or Secure Socket Layer (SSL) features during the information transmission process will as well create an encrypted channel for data exchange and to further protect information delivered.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do passwords and PINs provide security for electronic authentication, and what are some best practices for using them?",
      "answer": "Passwords and PINs provide security for electronic authentication by categorizing them as \"something you know\" method. A combination of numbers, symbols, and mixed cases are considered to be stronger than all-letter password. However, most security attacks target on password-based authentication systems. To enhance the security, the adoption of Transport Layer Security (TLS) or Secure Socket Layer (SSL) features during the information transmission process will as well create an encrypted channel for data exchange and to further protect information delivered.",
      "context": "Electronic authentication\n\n==Introduction==\nElectronic authentication is the process of establishing confidence in user identities electronically presented to an information system. Digital authentication, or e-authentication, may be used synonymously when referring to the authentication process that confirms or certifies a person's identity and works.  When used in conjunction with an electronic signature, it can provide evidence of whether data received has been tampered with after being signed by its original sender. Electronic authentication can reduce the risk of fraud and identity theft by verifying that a person is who they say they are when performing transactions online.Various e-authentication methods can be used to authenticate a user's identify ranging from a password to higher levels of security that utilize multifactor authentication (MFA). Depending on the level of security used, the user might need to prove his or her identity through the use of security tokens, challenge questions, or being in possession of a certificate from a third-party certificate authority that attests to their identity.\n\n\n\n== Overview ==\n The American National Institute of Standards and Technology (NIST) has developed a generic electronic authentication model that provides a basic framework on how the authentication process is accomplished regardless of jurisdiction or geographic region. According to this model, the enrollment process begins with an individual applying to a Credential Service Provider (CSP). The CSP will need to prove the applicant's identity before proceeding with the transaction. Once the applicant's identity has been confirmed by the CSP, he or she receives the status of \"subscriber\", is given an authenticator, such as a token and a credential, which may be in the form of a username.\nThe CSP is responsible for managing the credential along with the subscriber's enrollment data for the life of the credential. The subscriber will be tasked with maintaining the authenticators. An example of this is when a user normally uses a specific computer to do their online banking. If he or she attempts to access their bank account from another computer, the authenticator will not be present. In order to gain access, the subscriber would need to verify their identity to the CSP, which might be in the form of answering a challenge question successfully before being given access.\n\n\n*** Use of electronic authorization in medical field ***\nNew invention on medicines, and novel development on medical technologies had been widely deployed and adopted in modern societies. In consequence, the average lifetime of human being is much longer than it was before. \nTherefore, to safely establish and manage personal health records for each individual during his/her lifetime within the electronic form has gradually become an interesting topic for individual citizens and social welfare departments; the reason is that a well-maintained health records document of an individual can help doctors and hospitals know important and necessary medical and body conditions of the targeted patient in time before conducting any therapy.\n\n== Authentication factors ==\n\nThere are three generally accepted factors that are used to establish a digital identity for electronic authentication, including:\n\nKnowledge factor, which is something that the user knows, such as a password, answers to challenge questions, ID numbers or a PIN.\nPossession factor, which is something that the user has, such as mobile phone, PC or token\nBiometric factor, which is something that the user is, such as his or her fingerprints, eye scan or voice patternOut of the three factors, the biometric factor is the most convenient and convincing to prove an individual's identity, but it is the most expensive to implement. Each factor has its weaknesses; hence, reliable and strong authentication depends on combining two or more factors. This is known as multi-factor authentication, of which two-factor authentication and two-step verification are subtypes.\nMulti-factor authentication can still be vulnerable to attacks, including man-in-the-middle attacks and Trojan attacks.\n\n== Methods ==\n\n\n*** Token ***\n\nTokens generically are something the claimant possesses and controls that may be used to authenticate the claimant's identity. In e-authentication, the claimant authenticates to a system or application over a network. Therefore, a token used for e-authentication is a secret and the token must be protected. The token may, for example, be a cryptographic key, that is protected by encrypting it under a password. An impostor must steal the encrypted key and learn the password to use the token.\n\n\n*** Passwords and PIN-based authentication ***\nPasswords and PINs are categorized as \"something you know\" method. A combination of numbers, symbols, and mixed cases are considered to be stronger than all-letter password. Also, the adoption of Transport Layer Security (TLS) or Secure Socket Layer (SSL) features during the information transmission process will as well create an encrypted channel for data exchange and to further protect information delivered. Currently, most security attacks target on password-based authentication systems.\n\n\n*** Public-key authentication ***\nThis type of authentication has two parts. One is a public key, the other is a private key. A public key is issued by a Certification Authority and is available to any user or server.  A private key is known by the user only.\n\n\n*** Symmetric-key authentication ***\nThe user shares a unique key with an authentication server. When the user sends a randomly generated message (the challenge) encrypted by the secret key to the authentication server, if the message can be matched by the server using its shared secret key, the user is authenticated.\nWhen implemented together with the password authentication, this method also provides a possible solution for two-factor authentication systems.\n\n\n*** SMS-based authentication ***\n\nThe user receives password by reading the message in the cell phone, and types back the password to complete the authentication. Short Message Service (SMS) is very effective when cell phones are commonly adopted. SMS is also suitable against man-in-the-middle (MITM) attacks, since the use of SMS does not involve the Internet.\n\n\n*** Biometric authentication ***\nBiometric authentication is the use of unique physical attributes and body measurements as the intermediate for better identification and access control. Physical characteristics that are often used for authentication include fingerprints, voice recognition, face recognition, and iris scans because all of these are unique to every individual. Traditionally, biometric authentication based on token-based identification systems, such as passport, and nowadays becomes one of the most secure identification systems to user protections. A new technological innovation which provides a wide variety of either behavioral or physical characteristics which are defining the proper concept of biometric authentication.\n\n\n*** Digital identity authentication ***\nDigital identity authentication refers to the combined use of device, behavior, location and other data, including email address, account and credit card information, to authenticate online users in real time. For example, recent work have explored how to exploit browser fingerprinting as part of a multi-factor authentication scheme.\n\n== Electronic credentials ==\nPaper credentials are documents that attest to the identity or other attributes of an individual or entity called the subject of the credentials. Some common paper credentials include passports, birth certificates, driver's licenses, and employee identity cards. The credentials themselves are authenticated in a variety of ways: traditionally perhaps by a signature or a seal, special papers and inks, high quality engraving, and today by more complex mechanisms, such as holograms, that make the credentials recognizable and difficult to copy or forge. In some cases, simple possession of the credentials is sufficient to establish that the physical holder of the credentials is indeed the subject of the credentials. More commonly, the credentials contain biometric information such as the subject's description, a picture of the subject or the handwritten signature of the subject that can be used to authenticate that the holder of the credentials is indeed the subject of the credentials. When these paper credentials are presented in-person, authentication biometrics contained in those credentials can be checked to confirm that the physical holder of the credential is the subject.\nElectronic identity credentials bind a name and perhaps other attributes to a token. There are a variety of electronic credential types in use today, and new types of credentials are constantly being created (eID, electronic voter ID card, biometric passports, bank cards, etc.) At a minimum, credentials include identifying information that permits recovery of the records of the registration associated with the credentials and a name that is associated with the subscriber.\n\n== Verifiers ==\nIn any authenticated on-line transaction, the verifier is the party that verifies that the claimant has possession and control of the token that verifies his or her identity. A claimant authenticates his or her identity to a verifier by the use of a token and an authentication protocol. This is called Proof of Possession (PoP). Many PoP protocols are designed so that a verifier, with no knowledge of the token before the authentication protocol run, learns nothing about the token from the run. The verifier and CSP may be the same entity, the verifier and relying party may be the same entity or they may all three be separate entities. It is undesirable for verifiers to learn shared secrets unless they are a part of the same entity as the CSP that registered the tokens. Where the verifier and the relying party are separate entities, the verifier must convey the result of the authentication protocol to the relying party. The object created by the verifier to convey this result is called an assertion.\n\n== Authentication schemes ==\nThere are four types of authentication schemes: local authentication, centralized authentication, global centralized authentication, global authentication and web application (portal).\nWhen using a local authentication scheme, the application retains the data that pertains to the user's credentials. This information is not usually shared with other applications. The onus is on the user to maintain and remember the types and number of credentials that are associated with the service in which they need to access. This is a high risk scheme because of the possibility that the storage area for passwords might become compromised.\nUsing the central authentication scheme allows for each user to use the same credentials to access various services. Each application is different and must be designed with interfaces and the ability to interact with a central system to successfully provide authentication for the user. This allows the user to access important information and be able to access private keys that will allow him or her to electronically sign documents.\nUsing a third party through a global centralized authentication scheme allows the user direct access to authentication services. This then allows the user to access the particular services they need.\nThe most secure scheme is the global centralized authentication and web application (portal). It is ideal for E-Government use because it allows a wide range of services. It uses a single authentication mechanism involving a minimum of two factors to allow access to required services and the ability to sign documents.\n\n== Authentication and digital signing working together ==\nOften, authentication and digital signing are applied in conjunction. In advanced electronic signatures, the signatory has authenticated and uniquely linked to a signature. In the case of a qualified electronic signature as defined in the eIDAS-regulation, the signer's identity is even certified by a qualified trust service provider. This linking of signature and authentication firstly supports the probative value of the signature \u2013 commonly referred to as non-repudiation of origin. The protection of the message on the network-level is called non-repudiation of emission. The authenticated sender and the message content are linked to each other. If a 3rd party tries to change the message content, the signature loses validity.\n\n== Risk assessment ==\nWhen developing electronic systems, there are some industry standards requiring United States agencies to ensure the transactions provide an appropriate level of assurance. Generally, servers adopt the US' Office of Management and Budget's (OMB's) E-Authentication Guidance for Federal Agencies (M-04-04) as a guideline, which is published to help federal agencies provide secure electronic services that protect individual privacy. It asks agencies to check whether their transactions require e-authentication, and determine a proper level of assurance.It established four levels of assurance:Assurance Level 1: Little or no confidence in the asserted identity's validity.\nAssurance Level 2: Some confidence in the asserted identity's validity. \nAssurance Level 3: High confidence in the asserted identity's validity. \nAssurance Level 4: Very high confidence in the asserted identity's validity.\n\n\n*** Determining assurance levels ***\nThe OMB proposes a five-step process to determine the appropriate assurance level for their applications:\n\nConduct a risk assessment, which measures possible negative impacts.\nCompare with the five assurance levels and decide which one suits this case.\nSelect technology according to the technical guidance issued by NIST.\nConfirm the selected authentication process satisfies requirements.\nReassess the system regularly and adjust it with changes.The required level of authentication assurance are assessed through the factors below:\n\nInconvenience, distress, or damage to standing or reputation;\nFinancial loss or agency liability;\nHarm to agency programs or public interests;\nUnauthorized release of sensitive information;\nPersonal safety; and/or civil or criminal violations.\n\n\n*** Determining technical requirements ***\nNational Institute of Standards and Technology (NIST) guidance defines technical requirements for each of the four levels of assurance in the following areas:\nTokens are used for proving identity. Passwords and symmetric cryptographic keys are private information that the verifier needs to protect. Asymmetric cryptographic keys have a private key (which only the subscriber knows) and a related public key.\nIdentity proofing, registration, and the delivery of credentials that bind an identity to a token. This process can involve a far distance operation.\nCredentials, tokens, and authentication protocols can also be combined to identify that a claimant is in fact the claimed subscriber.\nAn assertion mechanism that involves either a digital signature of the claimant or is acquired directly by a trusted third party through a secure authentication protocol.\n\n== Guidelines and regulations ==\nTriggered by the growth of new cloud solutions and online transactions, person-to-machine and machine-to-machine identities play a significant role in identifying individuals and accessing information. According to the Office of Management and Budget in the U.S., more than $70 million was spent on identity management solutions in both 2013 and 2014.Governments use e-authentication systems to offer services and reduce time people traveling to a government office. Services ranging from applying for visas to renewing driver's licenses can all be achieved in a more efficient and flexible way. Infrastructure to support e-authentication is regarded as an important component in successful e-government. Poor coordination and poor technical design might be major barriers to electronic authentication.In several countries there has been established nationwide common e-authentication schemes to ease the reuse of digital identities in different electronic services. Other policy initiatives have included the creation of frameworks for electronic authentication, in order to establish common levels of trust and possibly interoperability between different authentication schemes.\n\n\n*** United States ***\nE-authentication is a centerpiece of the United States government's effort to expand electronic government, or e-government, as a way of making government more effective and efficient and easier to access. The e-authentication service enables users to access government services online using log-in IDs (identity credentials) from other web sites that both the user and the government  trust.\nE-authentication is a government-wide partnership that is supported by the agencies that comprise the Federal CIO Council. The United States General Services Administration (GSA) is the lead agency partner. E-authentication works through an association with a trusted credential issuer, making it necessary for the user to log into the issuer's site to obtain the authentication credentials.  Those credentials or e-authentication ID are then transferred the supporting government web site causing authentication. The system was created in response a December 16, 2003  memorandum was issued through the  Office of Management and Budget.  Memorandum M04-04 Whitehouse. That memorandum updates the guidance issued in the  Paperwork Elimination Act of 1998, 44 U.S.C. \u00a7 3504 and implements section 203 of the E-Government Act, 44 U.S.C. ch. 36.\nNIST provides guidelines for digital authentication standards and does away with most knowledge-based authentication methods. A stricter standard has been drafted on more complicated passwords that at least 8 characters long or passphrases that are at least 64 characters long.\n\n\n*** Europe ***\nIn Europe, eIDAS provides guidelines to be used for electronic authentication in regards to electronic signatures and certificate services for website authentication. Once confirmed by the issuing Member State, other participating States are required to accept the user's electronic signature as valid for cross border transactions.\nUnder eIDAS, electronic identification refers to a material/immaterial unit that contains personal identification data to be used for authentication for an online service. Authentication is referred to as an electronic process that allows for the electronic identification of a natural or legal person. A trust service is an electronic service that is used to create, verify and validate electronic signatures, in addition to creating, verifying and validating certificates for website authentication.\nArticle 8 of eIDAS allows for the authentication mechanism that is used by a natural or legal person to use electronic identification methods in confirming their identity to a relying party. Annex IV provides requirements for qualified certificates for website authentication.\n\n\n*** Russia ***\nE-authentication is a centerpiece of the Russia government's effort to expand e-government, as a way of making government more effective and efficient and easier for the Russian people to access. The e-authentication service enables users to access government services online using log-in IDs (identity credentials) they already have from web sites that they and the government trust.\n\n== Other applications ==\nApart from government services, e-authentication is also widely used in other technology and industries. These new applications combine the features of authorizing identities in traditional database and new technology to provide a more secure and diverse use of e-authentication. Some examples are described below.\n\n\n*** Mobile authentication ***\nMobile authentication is the verification of a user's identity through the use a mobile device. It can be treated as an independent field or it can also be applied with other multifactor authentication schemes in the e-authentication field.For mobile authentication, there are five levels of application sensitivity from Level 0 to Level 4. Level 0 is for public use over a mobile device and requires no identity authentications, while level 4 has the most multi-procedures to identify users.  For either level, mobile authentication is relatively easy to process. Firstly, users send a one-time password (OTP) through offline channels. Then, a server identifies the information and makes adjustment in the database. Since only the user has the access to a PIN code and can send information through their mobile devices, there is a low risk of attacks.\n\n\n*** E-commerce authentication ***\nIn the early 1980s, electronic data interchange (EDI) systems was implemented, which was considered as an early representative of E-commerce. But ensuring its security is not a significant issue since the systems are all constructed around closed networks. However, more recently, business-to-consumer transactions have transformed. Remote transacting parties have forced the implementation of E-commerce authentication systems.Generally speaking, the approaches adopted in E-commerce authentication are basically the same as e-authentication. The difference is E-commerce authentication is a more narrow field that focuses on the transactions between customers and suppliers. A simple example of E-commerce authentication includes a client communicating with a merchant server via the Internet. The merchant server usually utilizes a web server to accept client requests, a database management system to manage data and a payment gateway to provide online payment services.\n\n\n*** Self-sovereign identity ***\nWith self-sovereign identity (SSI) the individual identity holders fully create and control their credentials. Whereas the verifiers can authenticate the provided identities on a decentralized network.\n\n== Perspectives ==\nTo keep up with the evolution of services in the digital world, there is continued need for security mechanisms. While passwords will continue to be used, it is important to rely on authentication mechanisms, most importantly multifactor authentication. As the usage of e-signatures continues to significantly expand throughout the United States, the EU and throughout the world, there is expectation that regulations such as eIDAS will eventually be amended to reflect changing conditions along with regulations in the United States."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are some features of the UFED Physical Analyzer?",
    "context": "",
    "output": "The Physical Analyzer can extract device keys for decryption, reveal device passwords, perform passcode recovery attacks, analyze and decode application data, generate reports in various formats, and dump raw filesystems for analysis in other applications.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are some features of the UFED Physical Analyzer?",
      "answer": "The Physical Analyzer can extract device keys for decryption, reveal device passwords, perform passcode recovery attacks, analyze and decode application data, generate reports in various formats, and dump raw filesystems for analysis in other applications."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is project vulnerability management and how does it differ from traditional vulnerability management?",
    "context": "",
    "output": "Project vulnerability management is a holistic approach to managing the susceptibility of a project to negative events, including the analysis of their impact and the project's capability to cope with negative events. It differs from traditional vulnerability management in that it takes a systems thinking approach and considers both the static and dynamic aspects of vulnerabilities, as well as methods to increase resistance and resilience, such as redundancy and antifragility.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is project vulnerability management and how does it differ from traditional vulnerability management?",
      "answer": "Project vulnerability management is a holistic approach to managing the susceptibility of a project to negative events, including the analysis of their impact and the project's capability to cope with negative events. It differs from traditional vulnerability management in that it takes a systems thinking approach and considers both the static and dynamic aspects of vulnerabilities, as well as methods to increase resistance and resilience, such as redundancy and antifragility."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the FORCEDENTRY exploit use a vulnerability in Apple's CoreGraphics system to bypass security measures?",
    "context": "",
    "output": "The FORCEDENTRY exploit uses a vulnerability in Apple's CoreGraphics system to inject JBIG2-encoded data and provoke an integer overflow, which allows it to bypass BlastDoor, the sandbox for message content.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the FORCEDENTRY exploit use a vulnerability in Apple's CoreGraphics system to bypass security measures?",
      "answer": "The FORCEDENTRY exploit uses a vulnerability in Apple's CoreGraphics system to inject JBIG2-encoded data and provoke an integer overflow, which allows it to bypass BlastDoor, the sandbox for message content."
    }
  },
  {
    "instruction": "Zeroshell\n\n==Introduction==\nZeroshell is a small open-source Linux distribution for servers and embedded systems which aims to provide network services. Its administration relies on a web-based graphical interface; no shell is needed to administer and configure it. Zeroshell is available as Live CD and CompactFlash images, and VMware virtual machines.\nZeroshell can be installed on any IA-32 computer with almost any Ethernet interface. It can also be installed on most embedded devices and single-board computers such as Raspberry Pi and Orange Pi.The project reached EOL in April of 2021 with the version 3.9.5.\nThere are several known vulnerabilities for various versions of this software: V2, V3.6x up to V3.7, V3.9.0, V3.9.3 and last V3.9.5 for example, allowing an attacker to e.g. gain root access to the device easily. The main attack vector is the cgi script in use, 'kerbynet'.\n\n\n\n== Selected features ==\nRADIUS server which is able to provide strong authentication for the Wireless clients by using IEEE 802.1X and Wi-Fi Protected Access (WPA/WPA2) protocols\nCaptive portal for network authentication in the HotSpots by using a web browser. The credentials can be verified against a Radius server, a Kerberos 5 KDC (such as Active Directory KDC)\nNetfilter \u2013 Firewall, Packet Filter and Stateful Packet Inspection (SPI), Layer 7 filter to block or shape the connections generated by Peer to Peer clients\nLinux network scheduler \u2013 control maximum bandwidth, the guaranteed bandwidth and the priority of some types of traffic such as VoIP and peer-to-peer\nVPN host-to-LAN and LAN-to-LAN with the IPSec/L2TP and OpenVPN protocols\nRouting and Bridging capabilities with VLAN IEEE 802.1Q support\nMultizone DNS (Domain name system) server\nMulti subnet DHCP server\nPPPoE client for connection to the WAN (Wide area network) via ADSL, DSL and cable lines\nDynamic DNS client updater for DynDNS\nNTP (Network Time Protocol) client and server\nSyslog server for receiving and cataloging the system logs produced by the remote hosts\nKerberos 5 authentication\nLDAP server\nX.509 certification authority\nQ: What is the function of Zeroshell's Kerberos 5 authentication feature?",
    "context": "",
    "output": "Zeroshell's Kerberos 5 authentication feature allows for strong authentication of users and services within a network.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the function of Zeroshell's Kerberos 5 authentication feature?",
      "answer": "Zeroshell's Kerberos 5 authentication feature allows for strong authentication of users and services within a network.",
      "context": "Zeroshell\n\n==Introduction==\nZeroshell is a small open-source Linux distribution for servers and embedded systems which aims to provide network services. Its administration relies on a web-based graphical interface; no shell is needed to administer and configure it. Zeroshell is available as Live CD and CompactFlash images, and VMware virtual machines.\nZeroshell can be installed on any IA-32 computer with almost any Ethernet interface. It can also be installed on most embedded devices and single-board computers such as Raspberry Pi and Orange Pi.The project reached EOL in April of 2021 with the version 3.9.5.\nThere are several known vulnerabilities for various versions of this software: V2, V3.6x up to V3.7, V3.9.0, V3.9.3 and last V3.9.5 for example, allowing an attacker to e.g. gain root access to the device easily. The main attack vector is the cgi script in use, 'kerbynet'.\n\n\n\n== Selected features ==\nRADIUS server which is able to provide strong authentication for the Wireless clients by using IEEE 802.1X and Wi-Fi Protected Access (WPA/WPA2) protocols\nCaptive portal for network authentication in the HotSpots by using a web browser. The credentials can be verified against a Radius server, a Kerberos 5 KDC (such as Active Directory KDC)\nNetfilter \u2013 Firewall, Packet Filter and Stateful Packet Inspection (SPI), Layer 7 filter to block or shape the connections generated by Peer to Peer clients\nLinux network scheduler \u2013 control maximum bandwidth, the guaranteed bandwidth and the priority of some types of traffic such as VoIP and peer-to-peer\nVPN host-to-LAN and LAN-to-LAN with the IPSec/L2TP and OpenVPN protocols\nRouting and Bridging capabilities with VLAN IEEE 802.1Q support\nMultizone DNS (Domain name system) server\nMulti subnet DHCP server\nPPPoE client for connection to the WAN (Wide area network) via ADSL, DSL and cable lines\nDynamic DNS client updater for DynDNS\nNTP (Network Time Protocol) client and server\nSyslog server for receiving and cataloging the system logs produced by the remote hosts\nKerberos 5 authentication\nLDAP server\nX.509 certification authority"
    }
  },
  {
    "instruction": "Write an answer to the following question: How does SquidGuard authenticate users in version 1.4 and later?",
    "context": "",
    "output": "In version 1.4 and later, SquidGuard offers optional authentication via a MySQL database.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does SquidGuard authenticate users in version 1.4 and later?",
      "answer": "In version 1.4 and later, SquidGuard offers optional authentication via a MySQL database."
    }
  },
  {
    "instruction": "Write an answer to the following question: Who licenses the Blackhole exploit kit from the authors and specifies various options to customize the kit?",
    "context": "",
    "output": "The customers of the Blackhole exploit kit license it from the authors and specify various options to customize the kit.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Who licenses the Blackhole exploit kit from the authors and specifies various options to customize the kit?",
      "answer": "The customers of the Blackhole exploit kit license it from the authors and specify various options to customize the kit."
    }
  },
  {
    "instruction": "Context: Traitor tracing\n\n==Introduction==\nTraitor tracing schemes help trace the source of leaks when secret or proprietary data is sold to many customers.\nIn a traitor tracing scheme, each customer is given a different personal decryption key.\n(Traitor tracing schemes are often combined with conditional access systems so that, once the traitor tracing algorithm identifies a personal decryption key associated with the leak, the content distributor can revoke that personal decryption key, allowing honest customers to continue to watch pay television while the traitor and all the unauthorized users using the traitor's personal decryption key are cut off.)\nTraitor tracing schemes are used in pay television to discourage pirate decryption \u2013 to discourage legitimate subscribers from giving away decryption keys.\nTraitor tracing schemes are ineffective if the traitor rebroadcasts the entire (decrypted) original content.\nThere are other kinds of schemes that discourages pirate rebroadcast \u2013 i.e., discourages legitimate subscribers from giving away decrypted original content. These other schemes use tamper-resistant digital watermarking to generate different versions of the original content. Traitor tracing key assignment schemes can be translated into such digital watermarking schemes.Traitor tracing is a copyright infringement detection system which works by tracing the source of leaked files rather than by direct copy protection. The method is that the distributor adds a unique salt to each copy given out. When a copy of it is leaked to the public, the distributor can check the value on it and trace it back to the \"leak\".\n\n== Primary methods ==\n\n\n*** Activation controls ***\nThe main concept is that each licensee (the user) is given a unique key which unlocks the software or allows the media to be decrypted.\nIf the key is made public, the content owner then knows exactly who did it from their database of assigned codes.\nA major attack on this strategy is the key generator (keygen). By reverse engineering the software, the code used to recognise a valid key can be characterised and then a program to spit out valid keys on command can be made.\nThe practice of traitor tracing is most often implemented with computer software, and evolved from the previous method of activation codes.  In this model, each box of software ships with a unique activation number on a sticker or label that can only be read after the package is opened, separate from the CD-ROM or a DVD-ROM. This number is an encoded serial number, expanded to a usually large number or string of letters, digits, and hyphens.  When the software is being installed, or the first time it is run, the user is prompted to type in the license code.  This code is then decoded back to its base serial number.  This process reduces the number in complexity, and the additional information removed by this process is used to verify the authenticity of the serial number.  If the user mistypes a single character in what is sometimes a very long code, the software will refuse to install and require the number to be retyped until it is correct.\nThis activation code is generated during the packaging phase of manufacture, so that every user is receiving the same software but a different activation code.  If a user performs a \"casual copy\" of the software for a friend, that friend must have the license code as well as the software to install it on their system.  Since the software itself cannot determine that it is a copy, this is a way to beat this basic system.\nWith the expansion of computer networking, two additional levels of software protection have evolved, \"network registration\" and \"online registration\".\n\n\n*** Network registration ***\nSoftware that employs this additional security keeps a copy of the actual serial number being used in the license code.  When it is active, it is broadcasting this number on a clandestine channel on the local network.  If the software has been installed on another computer on that same network, using the same license code, when the second copy is run it will detect its serial number in use on the network and typically will refuse to run.  It may also cause the other copy of itself already in use to close.  This prevents a small business from buying one copy of expensive software and installing it on several of the computers at their location, provided they are networked.\n\n\n*** Online registration ***\nThe process of online registration is very similar to activation codes, but adds an additional step.  Most modern companies are now not only internally networked, but are also connected to the internet.  This allows the software manufacturers to add an additional check to their system during the installation process.  When the user enters a valid license code, the software does not immediately install.  Instead, it uses the active internet connection to contact a server being operated by the software manufacturer.  The license code is transmitted to the server, and it waits for the server to tell it whether the install should be permitted.  The server maintains a database of all the serial numbers that have been used to install their software.  If a single serial number is used on a number of machines (a typical limit would be five machines) then the server tells the software that it is likely a copy and to abort the installation.  The users are usually presented with a dialog instructing them to contact the manufacturer.\n\n== Watermarking ==\nWebsites offering subscriber downloads may embed a digital watermark in the download, usually in a way that is not readily apparent to the user.  For example, an identification number may be embedded in an image, or in metadata such as the date of a file. It is also possible to watermark multiple copies of a file with a unique watermark per recipient before sending them. In this case the embedded identification number can be the ID of the recipient.\n\n== Other methods ==\nSome software that implements online registration extends this with a process commonly known as \"phoning home\".  In this case, the software, either each time it is used or at some preset interval such as monthly, makes another connection back to the registration server.  It does this to check in with the server to see if the serial number it is using has been determined to be one that is being used to install in many places.  Serial numbers that have been identified as \"pirated\" (illegally distributed) are added to a blacklist on the server, a process referred to as being \"burned\".  Burned serial numbers cannot be used to install or activate the product.  Serial number lists are available on the internet that include a large number of valid registration codes for many software titles.  It is common for software manufacturers to seek out these lists and invalidate the serial numbers that appear on these lists.  This discourages individuals from giving out their registration codes for fear that this code will later be invalidated, disabling the original install of the software the next time that it \"phones home\".\nSome of the more expensive software requires the user to send personal information to the software vendor before receiving the activation code.  The activation code is usually a large sequence of numbers and letters, and encodes information including the license serial number, information to ensure the code is valid, and also includes the ability to verify the personal information the user sent to the software vendor.  In this way, the user's name or business name must be entered along with the registration code.  The registration code will not be accepted by the software unless the user types in the business name exactly as submitted to the software vendor.  The business name is usually displayed by the software on its opening banner whenever the software is used.  If the customer gives away his activation code it will be useless without his business name, and anyone that uses the activation code must enter it in during the activation process, leaving the original buyer's business name on the banner of the software.  This makes it very easy to \"trace the traitor\" and find any customers who originally gave out their activation codes.  Since giving away the registration code is a violation of the license agreement, the software vendor may invalidate the user's serial number (disabling that user's software in the process) and may take legal action.  This does raise privacy concerns in some areas.\nAnswer this question: How does online registration add an additional layer of security to software protection?",
    "context": "",
    "output": "Online registration adds an additional layer of security by requiring the user to transmit the license code to the software manufacturer's server during the installation process. The server maintains a database of all the serial numbers that have been used to install the software, and if a single serial number is used on a number of machines, the server tells the software to abort the installation.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does online registration add an additional layer of security to software protection?",
      "answer": "Online registration adds an additional layer of security by requiring the user to transmit the license code to the software manufacturer's server during the installation process. The server maintains a database of all the serial numbers that have been used to install the software, and if a single serial number is used on a number of machines, the server tells the software to abort the installation.",
      "context": "Traitor tracing\n\n==Introduction==\nTraitor tracing schemes help trace the source of leaks when secret or proprietary data is sold to many customers.\nIn a traitor tracing scheme, each customer is given a different personal decryption key.\n(Traitor tracing schemes are often combined with conditional access systems so that, once the traitor tracing algorithm identifies a personal decryption key associated with the leak, the content distributor can revoke that personal decryption key, allowing honest customers to continue to watch pay television while the traitor and all the unauthorized users using the traitor's personal decryption key are cut off.)\nTraitor tracing schemes are used in pay television to discourage pirate decryption \u2013 to discourage legitimate subscribers from giving away decryption keys.\nTraitor tracing schemes are ineffective if the traitor rebroadcasts the entire (decrypted) original content.\nThere are other kinds of schemes that discourages pirate rebroadcast \u2013 i.e., discourages legitimate subscribers from giving away decrypted original content. These other schemes use tamper-resistant digital watermarking to generate different versions of the original content. Traitor tracing key assignment schemes can be translated into such digital watermarking schemes.Traitor tracing is a copyright infringement detection system which works by tracing the source of leaked files rather than by direct copy protection. The method is that the distributor adds a unique salt to each copy given out. When a copy of it is leaked to the public, the distributor can check the value on it and trace it back to the \"leak\".\n\n== Primary methods ==\n\n\n*** Activation controls ***\nThe main concept is that each licensee (the user) is given a unique key which unlocks the software or allows the media to be decrypted.\nIf the key is made public, the content owner then knows exactly who did it from their database of assigned codes.\nA major attack on this strategy is the key generator (keygen). By reverse engineering the software, the code used to recognise a valid key can be characterised and then a program to spit out valid keys on command can be made.\nThe practice of traitor tracing is most often implemented with computer software, and evolved from the previous method of activation codes.  In this model, each box of software ships with a unique activation number on a sticker or label that can only be read after the package is opened, separate from the CD-ROM or a DVD-ROM. This number is an encoded serial number, expanded to a usually large number or string of letters, digits, and hyphens.  When the software is being installed, or the first time it is run, the user is prompted to type in the license code.  This code is then decoded back to its base serial number.  This process reduces the number in complexity, and the additional information removed by this process is used to verify the authenticity of the serial number.  If the user mistypes a single character in what is sometimes a very long code, the software will refuse to install and require the number to be retyped until it is correct.\nThis activation code is generated during the packaging phase of manufacture, so that every user is receiving the same software but a different activation code.  If a user performs a \"casual copy\" of the software for a friend, that friend must have the license code as well as the software to install it on their system.  Since the software itself cannot determine that it is a copy, this is a way to beat this basic system.\nWith the expansion of computer networking, two additional levels of software protection have evolved, \"network registration\" and \"online registration\".\n\n\n*** Network registration ***\nSoftware that employs this additional security keeps a copy of the actual serial number being used in the license code.  When it is active, it is broadcasting this number on a clandestine channel on the local network.  If the software has been installed on another computer on that same network, using the same license code, when the second copy is run it will detect its serial number in use on the network and typically will refuse to run.  It may also cause the other copy of itself already in use to close.  This prevents a small business from buying one copy of expensive software and installing it on several of the computers at their location, provided they are networked.\n\n\n*** Online registration ***\nThe process of online registration is very similar to activation codes, but adds an additional step.  Most modern companies are now not only internally networked, but are also connected to the internet.  This allows the software manufacturers to add an additional check to their system during the installation process.  When the user enters a valid license code, the software does not immediately install.  Instead, it uses the active internet connection to contact a server being operated by the software manufacturer.  The license code is transmitted to the server, and it waits for the server to tell it whether the install should be permitted.  The server maintains a database of all the serial numbers that have been used to install their software.  If a single serial number is used on a number of machines (a typical limit would be five machines) then the server tells the software that it is likely a copy and to abort the installation.  The users are usually presented with a dialog instructing them to contact the manufacturer.\n\n== Watermarking ==\nWebsites offering subscriber downloads may embed a digital watermark in the download, usually in a way that is not readily apparent to the user.  For example, an identification number may be embedded in an image, or in metadata such as the date of a file. It is also possible to watermark multiple copies of a file with a unique watermark per recipient before sending them. In this case the embedded identification number can be the ID of the recipient.\n\n== Other methods ==\nSome software that implements online registration extends this with a process commonly known as \"phoning home\".  In this case, the software, either each time it is used or at some preset interval such as monthly, makes another connection back to the registration server.  It does this to check in with the server to see if the serial number it is using has been determined to be one that is being used to install in many places.  Serial numbers that have been identified as \"pirated\" (illegally distributed) are added to a blacklist on the server, a process referred to as being \"burned\".  Burned serial numbers cannot be used to install or activate the product.  Serial number lists are available on the internet that include a large number of valid registration codes for many software titles.  It is common for software manufacturers to seek out these lists and invalidate the serial numbers that appear on these lists.  This discourages individuals from giving out their registration codes for fear that this code will later be invalidated, disabling the original install of the software the next time that it \"phones home\".\nSome of the more expensive software requires the user to send personal information to the software vendor before receiving the activation code.  The activation code is usually a large sequence of numbers and letters, and encodes information including the license serial number, information to ensure the code is valid, and also includes the ability to verify the personal information the user sent to the software vendor.  In this way, the user's name or business name must be entered along with the registration code.  The registration code will not be accepted by the software unless the user types in the business name exactly as submitted to the software vendor.  The business name is usually displayed by the software on its opening banner whenever the software is used.  If the customer gives away his activation code it will be useless without his business name, and anyone that uses the activation code must enter it in during the activation process, leaving the original buyer's business name on the banner of the software.  This makes it very easy to \"trace the traitor\" and find any customers who originally gave out their activation codes.  Since giving away the registration code is a violation of the license agreement, the software vendor may invalidate the user's serial number (disabling that user's software in the process) and may take legal action.  This does raise privacy concerns in some areas."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the security of an encryption scheme under indistinguishability under adaptive chosen ciphertext attack (IND-CCA2) relate to the security of the same scheme under non-malleability under adaptive chosen ciphertext attack (NM-CCA2)?",
    "context": "",
    "output": "The security of an encryption scheme under indistinguishability under adaptive chosen ciphertext attack (IND-CCA2) is equivalent to the security of the same scheme under non-malleability under adaptive chosen ciphertext attack (NM-CCA2). This means that an encryption scheme that provides IND-CCA2 security will also provide NM-CCA2 security, and vice versa. Therefore, an encryption scheme that provides both IND-CCA2 and NM-CCA2 security will ensure both confidentiality and message integrity.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the security of an encryption scheme under indistinguishability under adaptive chosen ciphertext attack (IND-CCA2) relate to the security of the same scheme under non-malleability under adaptive chosen ciphertext attack (NM-CCA2)?",
      "answer": "The security of an encryption scheme under indistinguishability under adaptive chosen ciphertext attack (IND-CCA2) is equivalent to the security of the same scheme under non-malleability under adaptive chosen ciphertext attack (NM-CCA2). This means that an encryption scheme that provides IND-CCA2 security will also provide NM-CCA2 security, and vice versa. Therefore, an encryption scheme that provides both IND-CCA2 and NM-CCA2 security will ensure both confidentiality and message integrity."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does key distribution work in symmetric key algorithms?",
    "context": "",
    "output": "In symmetric key algorithms, the key must be exchanged between the communicating parties in a secure way prior to any use of the system. This can be done via a secure channel, such as a trustworthy courier or face-to-face contact. However, this requirement can become unmanageable as the number of participants increases, or when secure channels aren't available.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does key distribution work in symmetric key algorithms?",
      "answer": "In symmetric key algorithms, the key must be exchanged between the communicating parties in a secure way prior to any use of the system. This can be done via a secure channel, such as a trustworthy courier or face-to-face contact. However, this requirement can become unmanageable as the number of participants increases, or when secure channels aren't available."
    }
  },
  {
    "instruction": "Context: IT risk\n\n==Introduction==\nInformation technology risk, IT risk, IT-related risk, or cyber risk is any risk relating to information technology. While information has long been appreciated as a valuable and important asset, the rise of the knowledge economy and the Digital Revolution has led to organizations becoming increasingly dependent on information, information processing and especially IT.  Various events or incidents that compromise IT in some way can therefore cause adverse impacts on the organization's business processes or mission, ranging from inconsequential to catastrophic in scale.\nAssessing the probability or likelihood of various types of event/incident with their predicted impacts or consequences, should they occur, is a common way to assess and measure IT risks.  Alternative methods of measuring IT risk typically involve assessing other contributory factors such as the threats, vulnerabilities, exposures, and asset values.\n\n\n\n== Definitions ==\n\n\n*** ISO ***\nIT risk: the potential that a given threat will exploit vulnerabilities of an asset or group of assets and thereby cause harm to the organization. It is measured in terms of a combination of the probability of occurrence of an event and its consequence.\n\n\n*** Committee on National Security Systems ***\nThe Committee on National Security Systems of United States of America defined risk in different documents:\n\nFrom CNSS Instruction No. 4009 dated 26 April 2010 the basic and more technical focused definition:\nRisk \u2013 Possibility that a particular threat will adversely impact an IS by exploiting a particular vulnerability.\nNational Security Telecommunications and Information Systems Security Instruction (NSTISSI) No. 1000, introduces a probability aspect, quite similar to NIST SP 800-30 one:\nRisk \u2013 A combination of the likelihood that a threat will occur, the likelihood that a threat occurrence will result in an adverse impact, and the severity of the resulting impactNational Information Assurance Training and Education Center defines risk in the IT field as:\nThe loss potential that exists as the result of threat-vulnerability pairs. Reducing either the threat or the vulnerability reduces the risk.\nThe uncertainty of loss expressed in terms of probability of such loss.\nThe probability that a hostile entity will successfully exploit a particular telecommunications or COMSEC system for intelligence purposes; its factors are threat and vulnerability.\nA combination of the likelihood that a threat shall occur, the likelihood that a threat occurrence shall result in an adverse impact, and the severity of the resulting adverse impact.\nthe probability that a particular threat will exploit a particular vulnerability of the system.\n\n\n*** NIST ***\nMany NIST publications define risk in IT context in different publications: FISMApedia term provide a list. Between them:\n\nAccording to NIST SP 800-30:Risk is a function of the likelihood of a given threat-source\u2019s exercising a particular potential vulnerability, and the resulting impact of that adverse event on the organization.\nFrom NIST FIPS 200Risk \u2013 The level of impact on organizational operations (including mission, functions, image, or reputation), organizational assets, or individuals resulting from the operation of an information system given the potential impact of a threat and the likelihood of that threat occurring.NIST SP 800-30 defines:\n\nIT-related risk\n\nThe net mission impact considering:\nthe probability that a particular threat-source will exercise (accidentally trigger or intentionally exploit) a particular information system vulnerability and\nthe resulting impact if this should occur. IT-related risks arise from legal liability or mission loss due to:\nUnauthorized (malicious or accidental) disclosure, modification, or destruction of information\nUnintentional errors and omissions\nIT disruptions due to natural or man-made disasters\nFailure to exercise due care and diligence in the implementation and operation of the IT system.\n\n\n*** Risk management insight ***\nIT risk is the probable frequency and probable magnitude of future loss.\n\n\n*** ISACA ***\nISACA published the Risk IT Framework in order to provide an end-to-end, comprehensive view of all risks related to the use of IT. There, IT risk is defined as:\n\nThe business risk associated with the use, ownership, operation, involvement, influence and adoption of IT within an enterpriseAccording to Risk IT, IT risk has a broader meaning: it encompasses not just only the negative impact of operations and service delivery which can bring destruction or reduction of the value of the organization, but also the benefit\\value enabling risk associated to missing opportunities to use technology to enable or enhance business or the IT project management for aspects like overspending or late delivery with adverse business impact\n\n== Measuring IT risk ==\nYou can't effectively and consistently manage what you can't measure, and you can't measure what you haven't defined.Measuring IT risk (or cyber risk) can occur at many levels. At a business level, the risks are managed categorically. Front line IT departments and NOC's tend to measure more discrete, individual risks. Managing the nexus between them is a key role for modern CISO's.\n\nWhen measuring risk of any kind, selecting the correct equation for a given threat, asset, and available data is an important step. Doing so is subject unto itself, but there are common components of risk equations that are helpful to understand. There are four fundamental forces involved in risk management, which also apply to cybersecurity. They are assets, impact, threats, and likelihood. You have internal knowledge of and a fair amount of control over assets, which are tangible and intangible things that have value. You also have some control over impact, which refers to loss of, or damage to, an asset. However, threats that represent adversaries and their methods of attack are external to your control. Likelihood is the wild card in the bunch. Likelihoods determine if and when a threat will materialize, succeed, and do damage. While never fully under your control, likelihoods can be shaped and influenced to manage the risk.\nMathematically, the forces can be represented in a formula such as: \n  \n    \n      \n        R\n        i\n        s\n        k\n\n== IT risk management ==\n\nIT risk management can be considered a component of a wider enterprise risk management system.The establishment, maintenance and continuous update of an information security management system (ISMS) provide a strong indication that a company is using a systematic approach for the identification, assessment and management of information security risks.Different methodologies have been proposed to manage IT risks, each of them divided into processes and steps.The Certified Information Systems Auditor Review Manual 2006 produced by ISACA, an international professional association focused on IT Governance, provides the following definition of risk management: \"Risk management is the process of identifying vulnerabilities and threats to the information resources used by an organization in achieving business objectives, and deciding what countermeasures, if any, to take in reducing risk to an acceptable level, based on the value of the information resource to the organization.\"The NIST Cybersecurity Framework encourages organizations to manage IT risk as part the Identify (ID) function:Risk Assessment (ID.RA): The organization understands the cybersecurity risk to organizational operations (including mission, functions, image, or reputation), organizational assets, and individuals.\n\nID.RA-1: Asset vulnerabilities are identified and documented\nID.RA-2: Cyber threat intelligence and vulnerability information is received from information sharing forums and source\nID.RA-3: Threats, both internal and external, are identified and documented\nID.RA-4: Potential business impacts and likelihoods are identified\nID.RA-5: Threats, vulnerabilities, likelihoods, and impacts are used to determine risk\nID.RA-6: Risk responses are identified and prioritizedRisk Management Strategy (ID.RM): The organization\u2019s priorities, constraints, risk tolerances, and assumptions are established and used to support operational risk decisions. \n\nID.RM-1: Risk management processes are established, managed, and agreed to by organizational stakeholders\nID.RM-2: Organizational risk tolerance is determined and clearly expressed\nID.RM-3: The organization\u2019s determination of risk tolerance is informed by its role in critical infrastructure and sector specific risk analysis\n\n== IT risk laws and regulations ==\nIn the following a brief description of applicable rules organized by source.\n\n\n*** OECD ***\nOECD issued the following:\n\nOrganisation for Economic Co-operation and Development (OECD) Recommendation of the Council concerning guidelines governing the protection of privacy and trans-border flows of personal data (23 September 1980)\nOECD Guidelines for the Security of Information Systems and Networks: Towards a Culture of Security (25 July 2002). Topic: General information security. Scope: Non binding guidelines to any OECD entities (governments, businesses, other organisations and individual users who develop, own, provide, manage, service, and use information systems and networks). The OECD Guidelines state the basic principles underpinning risk management and information security practices. While no part of the text is binding as such, non-compliance with any of the principles is indicative of a serious breach of RM/RA good practices that can potentially incur liability.\n\n\n*** European Union ***\nThe European Union issued the following, divided by topic:\n\nPrivacy\nRegulation (EC) No 45/2001 on the protection of individuals with regard to the processing of personal data by the Community institutions and bodies and on the free movement of such data provide an internal regulation, which is a practical application of the principles of the Privacy Directive described below. Furthermore, article 35 of the Regulation requires the Community institutions and bodies to take similar precautions with regard to their telecommunications infrastructure, and to properly inform the users of any specific risks of security breaches.\nDirective 95/46/EC on the protection of individuals with regard to the processing of personal data and on the free movement of such data require that any personal data processing activity undergoes a prior risk analysis in order to determine the privacy implications of the activity, and to determine the appropriate legal, technical and organisation measures to protect such activities;is effectively protected by such measures, which must be state of the art keeping into account the sensitivity and privacy implications of the activity (including when a third party is charged with the processing task) is notified to a national data protection authority, including the measures taken to ensure the security of the activity. Furthermore, article 25 and following of the Directive requires Member States to ban the transfer of personal data to non-Member States, unless such countries have provided adequate legal protection for such personal data, or barring certain other exceptions.\nCommission Decision 2001/497/EC of 15 June 2001 on standard contractual clauses for the transfer of personal data to third countries, under Directive 95/46/EC; and Commission Decision 2004/915/EC of 27 December 2004 amending Decision 2001/497/EC as regards the introduction of an alternative set of standard contractual clauses for the transfer of personal data to third countries. Topic: Export of personal data to third countries, specifically non-E.U. countries which have not been recognised as having a data protection level that is adequate (i.e. equivalent to that of the E.U.). Both Commission Decisions provide a set of voluntary model clauses which can be used to export personal data from a data controller (who is subject to E.U. data protection rules) to a data processor outside the E.U. who is not subject to these rules or to a similar set of adequate rules.\nInternational Safe Harbor Privacy Principles (see below USA and International Safe Harbor Privacy Principles )\nDirective 2002/58/EC of 12 July 2002 concerning the processing of personal data and the protection of privacy in the electronic communications sector\nNational Security\nDirective 2006/24/EC of 15 March 2006 on the retention of data generated or processed in connection with the provision of publicly available electronic communications services or of public communications networks and amending Directive 2002/58/EC (\u2018Data Retention Directive\u2019). Topic: Requirement for the providers of public electronic telecommunications service providers to retain certain information for the purposes of the investigation, detection and prosecution of serious crime\nCouncil Directive 2008/114/EC of 8 December 2008 on the identification and designation of European critical infrastructures and the assessment of the need to improve their protection. Topic: Identification and protection of European Critical Infrastructures. Scope: Applicable to Member States and to the operators of European Critical Infrastructure (defined by the draft directive as \u2018critical infrastructures the disruption or destruction of which would significantly affect two or more Member States, or a single Member State if the critical infrastructure is located in another Member State. This includes effects resulting from cross-sector dependencies on other types of infrastructure\u2019). Requires Member States to identify critical infrastructures on their territories, and to designate them as ECIs. Following this designation, the owners/operators of ECIs are required to create Operator Security Plans (OSPs), which should establish relevant security solutions for their protection\nCivil and Penal law\nCouncil Framework Decision 2005/222/JHA of 24 February 2005 on attacks against information systems. Topic: General decision aiming to harmonise national provisions in the field of cyber crime, encompassing material criminal law (i.e. definitions of specific crimes), procedural criminal law (including investigative measures and international cooperation) and liability issues. Scope: Requires Member States to implement the provisions of the Framework Decision in their national legal frameworks. Framework decision is relevant to RM/RA because it contains the conditions under which legal liability can be imposed on legal entities for conduct of certain natural persons of authority within the legal entity. Thus, the Framework decision requires that the conduct of such figures within an organisation is adequately monitored, also because the Decision states that a legal entity can be held liable for acts of omission in this regard.\n\n\n*** Council of Europe ***\nCouncil of Europe Convention on Cybercrime, Budapest, 23.XI.2001, European Treaty Series-No. 185. Topic: General treaty aiming to harmonise national provisions in the field of cyber crime, encompassing material criminal law (i.e. definitions of specific crimes), procedural criminal law (including investigative measures and international cooperation), liability issues and data retention. Apart from the definitions of a series of criminal offences in articles 2 to 10, the Convention is relevant to RM/RA because it states the conditions under which legal liability can be imposed on legal entities for conduct of certain natural persons of authority within the legal entity. Thus, the Convention requires that the conduct of such figures within an organisation is adequately monitored, also because the Convention states that a legal entity can be held liable for acts of omission in this regard.\n\n\n*** United States ***\nUnited States issued the following, divided by topic:\n\nCivil and Penal law\nAmendments to the Federal Rules of Civil Procedure with regard to electronic discovery. Topic: U.S. Federal rules with regard to the production of electronic documents in civil proceedings. The discovery rules allow a party in civil proceedings to demand that the opposing party produce all relevant documentation (to be defined by the requesting party) in its possession, so as to allow the parties and the court to correctly assess the matter. Through the e-discovery amendment, which entered into force on 1 December 2006, such information may now include electronic information. This implies that any party being brought before a U.S. court in civil proceedings can be asked to produce such documents, which includes finalised reports, working documents, internal memos and e-mails with regard to a specific subject, which may or may not be specifically delineated. Any party whose activities imply a risk of being involved in such proceedings must therefore take adequate precautions for the management of such information, including the secure storage. Specifically: The party must be capable of initiating a \u2018litigation hold\u2019, a technical/organisational measure which must ensure that no relevant information can be modified any longer in any way. Storage policies must be responsible: while deletion of specific information of course remains allowed when this is a part of general information management policies (\u2018routine, good-faith operation of the information system\u2019, Rule 37 (f)), the wilful destruction of potentially relevant information can be punished by extremely high fines (in one specific case of 1.6 billion US$). Thus, in practice, any businesses who risk civil litigation before U.S. courts must implement adequate information management policies, and must implement the necessary measures to initiate a litigation hold.\nPrivacy\nCalifornia Consumer Privacy Act (CCPA)\nCalifornia Privacy Rights Act (CPRA)\nGramm\u2013Leach\u2013Bliley Act (GLBA)\nUSA PATRIOT Act, Title III\nHealth Insurance Portability and Accountability Act (HIPAA) From an RM/RA perspective, the Act is particularly known for its provisions with regard to Administrative Simplification (Title II of HIPAA). This title required the U.S. Department of Health and Human Services (HHS) to draft specific rule sets, each of which would provide specific standards which would improve the efficiency of the health care system and prevent abuse. As a result, the HHS has adopted five principal rules: the Privacy Rule, the Transactions and Code Sets Rule, the Unique Identifiers Rule, the Enforcement Rule, and the Security Rule. The latter, published in the Federal Register on 20 February 2003 (see: http://www.cms.hhs.gov/SecurityStandard/Downloads/securityfinalrule.pdf), is specifically relevant, as it specifies a series of administrative, technical, and physical security procedures to assure the confidentiality of electronic protected health information. These aspects have been further outlined in a set of Security Standards on Administrative, Physical, Organisational and Technical Safeguards, all of which have been published, along with a guidance document on the basics of HIPAA risk management and risk assessment <http://www.cms.hhs.gov/EducationMaterials/04_SecurityMaterials.asp>. European or other countries health care service providers will generally not be affected by HIPAA obligations if they are not active on the U.S. market. However, since their data processing activities are subject to similar obligations under general European law (including the Privacy Directive), and since the underlying trends of modernisation and evolution towards electronic health files are the same, the HHS safeguards can be useful as an initial yardstick for measuring RM/RA strategies put in place by European health care service providers, specifically with regard to the processing of electronic health information. HIPAA security standards include the following:\nAdministrative safeguards:\nSecurity Management Process\nAssigned Security Responsibility\nWorkforce Security\nInformation Access Management\nSecurity Awareness and Training\nSecurity Incident Procedures\nContingency Plan\nEvaluation\nBusiness Associate Contracts and Other Arrangements\nPhysical safeguards\nFacility Access Controls\nWorkstation Use\nWorkstation Security\nDevice and Media Controls\nTechnical safeguards\nAccess Control\nAudit Controls\nIntegrity\nPerson or Entity Authentication\nTransmission Security\nOrganisational requirements\nBusiness Associate Contracts & Other Arrangements\nRequirements for Group Health Plans\nInternational Safe Harbor Privacy Principles issued by the US Department of Commerce on July 21, 2000 Export of personal data from a data controller who is subject to E.U. privacy regulations to a U.S. based destination; before personal data may be exported from an entity subject to E.U. privacy regulations to a destination subject to U.S. law, the European entity must ensure that the receiving entity provides adequate safeguards to protect such data against a number of mishaps. One way of complying with this obligation is to require the receiving entity to join the Safe Harbor, by requiring that the entity self-certifies its compliance with the so-called Safe Harbor Principles. If this road is chosen, the data controller exporting the data must verify that the U.S. destination is indeed on the Safe Harbor list (see safe harbor list)\nThe United States Department of Homeland Security also utilizes Privacy Impact Assessment (PIA) as a decision making tool to identify and mitigate risks of privacy violations.\nSarbanes\u2013Oxley Act\nFISMA\nAs legislation evolves, there has been increased focus to require 'reasonable security' for information management. CCPA states that \"manufacturers of connected devices to equip the device with reasonable security.\" New York's SHIELD Act requires that organizations that manage NY residents' information \u201cdevelop, implement and maintain reasonable safeguards to protect the security, confidentiality and integrity of the private information including, but not limited to, disposal of data.\u201d This concept will influence how businesses manage their risk management plan as compliance requirements develop.\n\n== Standards organizations and standards ==\nInternational standard bodies:\nInternational Organization for Standardization \u2013 ISO\nPayment Card Industry Security Standards Council\nInformation Security Forum\nThe Open Group\nUnited States standard bodies:\nNational Institute of Standards and Technology \u2013 NIST\nFederal Information Processing Standards \u2013 FIPS by NIST devoted to Federal Government and Agencies\nUK standard bodies\nBritish Standard Institute\n\n\n*** Short description of standards ***\nThe list is chiefly based on:\n\n\n**** ISO ****\nISO/IEC 13335-1:2004 \u2013 Information technology\u2014Security techniques\u2014Management of information and communications technology security\u2014Part 1: Concepts and models for information and communications technology security management http://www.iso.org/iso/en/CatalogueDetailPage.CatalogueDetail?CSNUMBER\n\nQuestion: How does the Information Security Forum define information risk management?\n\nAnswer:",
    "context": "",
    "output": "The Information Security Forum (ISF) defines information risk management as the process of managing risks to the confidentiality, integrity and availability of information.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the Information Security Forum define information risk management?",
      "answer": "The Information Security Forum (ISF) defines information risk management as the process of managing risks to the confidentiality, integrity and availability of information.",
      "context": "IT risk\n\n==Introduction==\nInformation technology risk, IT risk, IT-related risk, or cyber risk is any risk relating to information technology. While information has long been appreciated as a valuable and important asset, the rise of the knowledge economy and the Digital Revolution has led to organizations becoming increasingly dependent on information, information processing and especially IT.  Various events or incidents that compromise IT in some way can therefore cause adverse impacts on the organization's business processes or mission, ranging from inconsequential to catastrophic in scale.\nAssessing the probability or likelihood of various types of event/incident with their predicted impacts or consequences, should they occur, is a common way to assess and measure IT risks.  Alternative methods of measuring IT risk typically involve assessing other contributory factors such as the threats, vulnerabilities, exposures, and asset values.\n\n\n\n== Definitions ==\n\n\n*** ISO ***\nIT risk: the potential that a given threat will exploit vulnerabilities of an asset or group of assets and thereby cause harm to the organization. It is measured in terms of a combination of the probability of occurrence of an event and its consequence.\n\n\n*** Committee on National Security Systems ***\nThe Committee on National Security Systems of United States of America defined risk in different documents:\n\nFrom CNSS Instruction No. 4009 dated 26 April 2010 the basic and more technical focused definition:\nRisk \u2013 Possibility that a particular threat will adversely impact an IS by exploiting a particular vulnerability.\nNational Security Telecommunications and Information Systems Security Instruction (NSTISSI) No. 1000, introduces a probability aspect, quite similar to NIST SP 800-30 one:\nRisk \u2013 A combination of the likelihood that a threat will occur, the likelihood that a threat occurrence will result in an adverse impact, and the severity of the resulting impactNational Information Assurance Training and Education Center defines risk in the IT field as:\nThe loss potential that exists as the result of threat-vulnerability pairs. Reducing either the threat or the vulnerability reduces the risk.\nThe uncertainty of loss expressed in terms of probability of such loss.\nThe probability that a hostile entity will successfully exploit a particular telecommunications or COMSEC system for intelligence purposes; its factors are threat and vulnerability.\nA combination of the likelihood that a threat shall occur, the likelihood that a threat occurrence shall result in an adverse impact, and the severity of the resulting adverse impact.\nthe probability that a particular threat will exploit a particular vulnerability of the system.\n\n\n*** NIST ***\nMany NIST publications define risk in IT context in different publications: FISMApedia term provide a list. Between them:\n\nAccording to NIST SP 800-30:Risk is a function of the likelihood of a given threat-source\u2019s exercising a particular potential vulnerability, and the resulting impact of that adverse event on the organization.\nFrom NIST FIPS 200Risk \u2013 The level of impact on organizational operations (including mission, functions, image, or reputation), organizational assets, or individuals resulting from the operation of an information system given the potential impact of a threat and the likelihood of that threat occurring.NIST SP 800-30 defines:\n\nIT-related risk\n\nThe net mission impact considering:\nthe probability that a particular threat-source will exercise (accidentally trigger or intentionally exploit) a particular information system vulnerability and\nthe resulting impact if this should occur. IT-related risks arise from legal liability or mission loss due to:\nUnauthorized (malicious or accidental) disclosure, modification, or destruction of information\nUnintentional errors and omissions\nIT disruptions due to natural or man-made disasters\nFailure to exercise due care and diligence in the implementation and operation of the IT system.\n\n\n*** Risk management insight ***\nIT risk is the probable frequency and probable magnitude of future loss.\n\n\n*** ISACA ***\nISACA published the Risk IT Framework in order to provide an end-to-end, comprehensive view of all risks related to the use of IT. There, IT risk is defined as:\n\nThe business risk associated with the use, ownership, operation, involvement, influence and adoption of IT within an enterpriseAccording to Risk IT, IT risk has a broader meaning: it encompasses not just only the negative impact of operations and service delivery which can bring destruction or reduction of the value of the organization, but also the benefit\\value enabling risk associated to missing opportunities to use technology to enable or enhance business or the IT project management for aspects like overspending or late delivery with adverse business impact\n\n== Measuring IT risk ==\nYou can't effectively and consistently manage what you can't measure, and you can't measure what you haven't defined.Measuring IT risk (or cyber risk) can occur at many levels. At a business level, the risks are managed categorically. Front line IT departments and NOC's tend to measure more discrete, individual risks. Managing the nexus between them is a key role for modern CISO's.\n\nWhen measuring risk of any kind, selecting the correct equation for a given threat, asset, and available data is an important step. Doing so is subject unto itself, but there are common components of risk equations that are helpful to understand. There are four fundamental forces involved in risk management, which also apply to cybersecurity. They are assets, impact, threats, and likelihood. You have internal knowledge of and a fair amount of control over assets, which are tangible and intangible things that have value. You also have some control over impact, which refers to loss of, or damage to, an asset. However, threats that represent adversaries and their methods of attack are external to your control. Likelihood is the wild card in the bunch. Likelihoods determine if and when a threat will materialize, succeed, and do damage. While never fully under your control, likelihoods can be shaped and influenced to manage the risk.\nMathematically, the forces can be represented in a formula such as: \n  \n    \n      \n        R\n        i\n        s\n        k\n\n== IT risk management ==\n\nIT risk management can be considered a component of a wider enterprise risk management system.The establishment, maintenance and continuous update of an information security management system (ISMS) provide a strong indication that a company is using a systematic approach for the identification, assessment and management of information security risks.Different methodologies have been proposed to manage IT risks, each of them divided into processes and steps.The Certified Information Systems Auditor Review Manual 2006 produced by ISACA, an international professional association focused on IT Governance, provides the following definition of risk management: \"Risk management is the process of identifying vulnerabilities and threats to the information resources used by an organization in achieving business objectives, and deciding what countermeasures, if any, to take in reducing risk to an acceptable level, based on the value of the information resource to the organization.\"The NIST Cybersecurity Framework encourages organizations to manage IT risk as part the Identify (ID) function:Risk Assessment (ID.RA): The organization understands the cybersecurity risk to organizational operations (including mission, functions, image, or reputation), organizational assets, and individuals.\n\nID.RA-1: Asset vulnerabilities are identified and documented\nID.RA-2: Cyber threat intelligence and vulnerability information is received from information sharing forums and source\nID.RA-3: Threats, both internal and external, are identified and documented\nID.RA-4: Potential business impacts and likelihoods are identified\nID.RA-5: Threats, vulnerabilities, likelihoods, and impacts are used to determine risk\nID.RA-6: Risk responses are identified and prioritizedRisk Management Strategy (ID.RM): The organization\u2019s priorities, constraints, risk tolerances, and assumptions are established and used to support operational risk decisions. \n\nID.RM-1: Risk management processes are established, managed, and agreed to by organizational stakeholders\nID.RM-2: Organizational risk tolerance is determined and clearly expressed\nID.RM-3: The organization\u2019s determination of risk tolerance is informed by its role in critical infrastructure and sector specific risk analysis\n\n== IT risk laws and regulations ==\nIn the following a brief description of applicable rules organized by source.\n\n\n*** OECD ***\nOECD issued the following:\n\nOrganisation for Economic Co-operation and Development (OECD) Recommendation of the Council concerning guidelines governing the protection of privacy and trans-border flows of personal data (23 September 1980)\nOECD Guidelines for the Security of Information Systems and Networks: Towards a Culture of Security (25 July 2002). Topic: General information security. Scope: Non binding guidelines to any OECD entities (governments, businesses, other organisations and individual users who develop, own, provide, manage, service, and use information systems and networks). The OECD Guidelines state the basic principles underpinning risk management and information security practices. While no part of the text is binding as such, non-compliance with any of the principles is indicative of a serious breach of RM/RA good practices that can potentially incur liability.\n\n\n*** European Union ***\nThe European Union issued the following, divided by topic:\n\nPrivacy\nRegulation (EC) No 45/2001 on the protection of individuals with regard to the processing of personal data by the Community institutions and bodies and on the free movement of such data provide an internal regulation, which is a practical application of the principles of the Privacy Directive described below. Furthermore, article 35 of the Regulation requires the Community institutions and bodies to take similar precautions with regard to their telecommunications infrastructure, and to properly inform the users of any specific risks of security breaches.\nDirective 95/46/EC on the protection of individuals with regard to the processing of personal data and on the free movement of such data require that any personal data processing activity undergoes a prior risk analysis in order to determine the privacy implications of the activity, and to determine the appropriate legal, technical and organisation measures to protect such activities;is effectively protected by such measures, which must be state of the art keeping into account the sensitivity and privacy implications of the activity (including when a third party is charged with the processing task) is notified to a national data protection authority, including the measures taken to ensure the security of the activity. Furthermore, article 25 and following of the Directive requires Member States to ban the transfer of personal data to non-Member States, unless such countries have provided adequate legal protection for such personal data, or barring certain other exceptions.\nCommission Decision 2001/497/EC of 15 June 2001 on standard contractual clauses for the transfer of personal data to third countries, under Directive 95/46/EC; and Commission Decision 2004/915/EC of 27 December 2004 amending Decision 2001/497/EC as regards the introduction of an alternative set of standard contractual clauses for the transfer of personal data to third countries. Topic: Export of personal data to third countries, specifically non-E.U. countries which have not been recognised as having a data protection level that is adequate (i.e. equivalent to that of the E.U.). Both Commission Decisions provide a set of voluntary model clauses which can be used to export personal data from a data controller (who is subject to E.U. data protection rules) to a data processor outside the E.U. who is not subject to these rules or to a similar set of adequate rules.\nInternational Safe Harbor Privacy Principles (see below USA and International Safe Harbor Privacy Principles )\nDirective 2002/58/EC of 12 July 2002 concerning the processing of personal data and the protection of privacy in the electronic communications sector\nNational Security\nDirective 2006/24/EC of 15 March 2006 on the retention of data generated or processed in connection with the provision of publicly available electronic communications services or of public communications networks and amending Directive 2002/58/EC (\u2018Data Retention Directive\u2019). Topic: Requirement for the providers of public electronic telecommunications service providers to retain certain information for the purposes of the investigation, detection and prosecution of serious crime\nCouncil Directive 2008/114/EC of 8 December 2008 on the identification and designation of European critical infrastructures and the assessment of the need to improve their protection. Topic: Identification and protection of European Critical Infrastructures. Scope: Applicable to Member States and to the operators of European Critical Infrastructure (defined by the draft directive as \u2018critical infrastructures the disruption or destruction of which would significantly affect two or more Member States, or a single Member State if the critical infrastructure is located in another Member State. This includes effects resulting from cross-sector dependencies on other types of infrastructure\u2019). Requires Member States to identify critical infrastructures on their territories, and to designate them as ECIs. Following this designation, the owners/operators of ECIs are required to create Operator Security Plans (OSPs), which should establish relevant security solutions for their protection\nCivil and Penal law\nCouncil Framework Decision 2005/222/JHA of 24 February 2005 on attacks against information systems. Topic: General decision aiming to harmonise national provisions in the field of cyber crime, encompassing material criminal law (i.e. definitions of specific crimes), procedural criminal law (including investigative measures and international cooperation) and liability issues. Scope: Requires Member States to implement the provisions of the Framework Decision in their national legal frameworks. Framework decision is relevant to RM/RA because it contains the conditions under which legal liability can be imposed on legal entities for conduct of certain natural persons of authority within the legal entity. Thus, the Framework decision requires that the conduct of such figures within an organisation is adequately monitored, also because the Decision states that a legal entity can be held liable for acts of omission in this regard.\n\n\n*** Council of Europe ***\nCouncil of Europe Convention on Cybercrime, Budapest, 23.XI.2001, European Treaty Series-No. 185. Topic: General treaty aiming to harmonise national provisions in the field of cyber crime, encompassing material criminal law (i.e. definitions of specific crimes), procedural criminal law (including investigative measures and international cooperation), liability issues and data retention. Apart from the definitions of a series of criminal offences in articles 2 to 10, the Convention is relevant to RM/RA because it states the conditions under which legal liability can be imposed on legal entities for conduct of certain natural persons of authority within the legal entity. Thus, the Convention requires that the conduct of such figures within an organisation is adequately monitored, also because the Convention states that a legal entity can be held liable for acts of omission in this regard.\n\n\n*** United States ***\nUnited States issued the following, divided by topic:\n\nCivil and Penal law\nAmendments to the Federal Rules of Civil Procedure with regard to electronic discovery. Topic: U.S. Federal rules with regard to the production of electronic documents in civil proceedings. The discovery rules allow a party in civil proceedings to demand that the opposing party produce all relevant documentation (to be defined by the requesting party) in its possession, so as to allow the parties and the court to correctly assess the matter. Through the e-discovery amendment, which entered into force on 1 December 2006, such information may now include electronic information. This implies that any party being brought before a U.S. court in civil proceedings can be asked to produce such documents, which includes finalised reports, working documents, internal memos and e-mails with regard to a specific subject, which may or may not be specifically delineated. Any party whose activities imply a risk of being involved in such proceedings must therefore take adequate precautions for the management of such information, including the secure storage. Specifically: The party must be capable of initiating a \u2018litigation hold\u2019, a technical/organisational measure which must ensure that no relevant information can be modified any longer in any way. Storage policies must be responsible: while deletion of specific information of course remains allowed when this is a part of general information management policies (\u2018routine, good-faith operation of the information system\u2019, Rule 37 (f)), the wilful destruction of potentially relevant information can be punished by extremely high fines (in one specific case of 1.6 billion US$). Thus, in practice, any businesses who risk civil litigation before U.S. courts must implement adequate information management policies, and must implement the necessary measures to initiate a litigation hold.\nPrivacy\nCalifornia Consumer Privacy Act (CCPA)\nCalifornia Privacy Rights Act (CPRA)\nGramm\u2013Leach\u2013Bliley Act (GLBA)\nUSA PATRIOT Act, Title III\nHealth Insurance Portability and Accountability Act (HIPAA) From an RM/RA perspective, the Act is particularly known for its provisions with regard to Administrative Simplification (Title II of HIPAA). This title required the U.S. Department of Health and Human Services (HHS) to draft specific rule sets, each of which would provide specific standards which would improve the efficiency of the health care system and prevent abuse. As a result, the HHS has adopted five principal rules: the Privacy Rule, the Transactions and Code Sets Rule, the Unique Identifiers Rule, the Enforcement Rule, and the Security Rule. The latter, published in the Federal Register on 20 February 2003 (see: http://www.cms.hhs.gov/SecurityStandard/Downloads/securityfinalrule.pdf), is specifically relevant, as it specifies a series of administrative, technical, and physical security procedures to assure the confidentiality of electronic protected health information. These aspects have been further outlined in a set of Security Standards on Administrative, Physical, Organisational and Technical Safeguards, all of which have been published, along with a guidance document on the basics of HIPAA risk management and risk assessment <http://www.cms.hhs.gov/EducationMaterials/04_SecurityMaterials.asp>. European or other countries health care service providers will generally not be affected by HIPAA obligations if they are not active on the U.S. market. However, since their data processing activities are subject to similar obligations under general European law (including the Privacy Directive), and since the underlying trends of modernisation and evolution towards electronic health files are the same, the HHS safeguards can be useful as an initial yardstick for measuring RM/RA strategies put in place by European health care service providers, specifically with regard to the processing of electronic health information. HIPAA security standards include the following:\nAdministrative safeguards:\nSecurity Management Process\nAssigned Security Responsibility\nWorkforce Security\nInformation Access Management\nSecurity Awareness and Training\nSecurity Incident Procedures\nContingency Plan\nEvaluation\nBusiness Associate Contracts and Other Arrangements\nPhysical safeguards\nFacility Access Controls\nWorkstation Use\nWorkstation Security\nDevice and Media Controls\nTechnical safeguards\nAccess Control\nAudit Controls\nIntegrity\nPerson or Entity Authentication\nTransmission Security\nOrganisational requirements\nBusiness Associate Contracts & Other Arrangements\nRequirements for Group Health Plans\nInternational Safe Harbor Privacy Principles issued by the US Department of Commerce on July 21, 2000 Export of personal data from a data controller who is subject to E.U. privacy regulations to a U.S. based destination; before personal data may be exported from an entity subject to E.U. privacy regulations to a destination subject to U.S. law, the European entity must ensure that the receiving entity provides adequate safeguards to protect such data against a number of mishaps. One way of complying with this obligation is to require the receiving entity to join the Safe Harbor, by requiring that the entity self-certifies its compliance with the so-called Safe Harbor Principles. If this road is chosen, the data controller exporting the data must verify that the U.S. destination is indeed on the Safe Harbor list (see safe harbor list)\nThe United States Department of Homeland Security also utilizes Privacy Impact Assessment (PIA) as a decision making tool to identify and mitigate risks of privacy violations.\nSarbanes\u2013Oxley Act\nFISMA\nAs legislation evolves, there has been increased focus to require 'reasonable security' for information management. CCPA states that \"manufacturers of connected devices to equip the device with reasonable security.\" New York's SHIELD Act requires that organizations that manage NY residents' information \u201cdevelop, implement and maintain reasonable safeguards to protect the security, confidentiality and integrity of the private information including, but not limited to, disposal of data.\u201d This concept will influence how businesses manage their risk management plan as compliance requirements develop.\n\n== Standards organizations and standards ==\nInternational standard bodies:\nInternational Organization for Standardization \u2013 ISO\nPayment Card Industry Security Standards Council\nInformation Security Forum\nThe Open Group\nUnited States standard bodies:\nNational Institute of Standards and Technology \u2013 NIST\nFederal Information Processing Standards \u2013 FIPS by NIST devoted to Federal Government and Agencies\nUK standard bodies\nBritish Standard Institute\n\n\n*** Short description of standards ***\nThe list is chiefly based on:\n\n\n**** ISO ****\nISO/IEC 13335-1:2004 \u2013 Information technology\u2014Security techniques\u2014Management of information and communications technology security\u2014Part 1: Concepts and models for information and communications technology security management http://www.iso.org/iso/en/CatalogueDetailPage.CatalogueDetail?CSNUMBER"
    }
  },
  {
    "instruction": "Write an answer to the following question: How can Yao's Millionaires' problem be used to compare more than two numbers?",
    "context": "",
    "output": "Yao's Millionaires' problem can be extended to compare more than two numbers by chaining multiple comparisons together. For instance, to compare three numbers, two comparisons can be performed, with the first determining which of the first two numbers is larger and the second comparing the result to the third number.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can Yao's Millionaires' problem be used to compare more than two numbers?",
      "answer": "Yao's Millionaires' problem can be extended to compare more than two numbers by chaining multiple comparisons together. For instance, to compare three numbers, two comparisons can be performed, with the first determining which of the first two numbers is larger and the second comparing the result to the third number."
    }
  },
  {
    "instruction": "Write an answer to the following question: Who is believed to have created the persona Guccifer 2.0?",
    "context": "",
    "output": "Linguistic analysis by Shlomo Engelson Argamon showed that Guccifer 2.0 is most likely \"a Russian pretending to be a Romanian\".",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Who is believed to have created the persona Guccifer 2.0?",
      "answer": "Linguistic analysis by Shlomo Engelson Argamon showed that Guccifer 2.0 is most likely \"a Russian pretending to be a Romanian\"."
    }
  },
  {
    "instruction": "Credential stuffing\n\n==Introduction==\nCredential stuffing is a type of cyberattack in which the attacker collects stolen account credentials, typically consisting of lists of usernames or email addresses and the corresponding passwords (often from a data breach), and then uses the credentials to gain unauthorized access to user accounts on other systems through large-scale automated login requests directed against a web application. Unlike credential cracking, credential stuffing attacks do not attempt to use brute force or guess any passwords \u2013 the attacker simply automates the logins for a large number  (thousands to millions) of previously discovered credential pairs using standard web automation tools such as Selenium, cURL, PhantomJS or tools designed specifically for these types of attacks, such as Sentry MBA, SNIPR, STORM, Blackbullet and Openbullet.Credential stuffing attacks are possible because many users reuse the same username/password combination across multiple sites, with one survey reporting that 81% of users have reused a password across two or more sites and 25% of users use the same passwords across a majority of their accounts. In 2017, the FTC issued an advisory suggesting specific actions companies needed to take against credential stuffing, such as insisting on secure passwords and guarding against attacks. According to former Google click fraud czar Shuman Ghosemajumder, credential stuffing attacks have up to a 2% login success rate, meaning that one million stolen credentials can take over 20,000 accounts. Wired Magazine described the best way to protect against credential stuffing is to use unique passwords on accounts, such as those generated automatically by a password manager, enable two-factor authentication, and to have companies detect and stop credential stuffing attacks.\n\n\n\n== Credential spills ==\nA credential spill, alternatively referred to as a data breach or leak, arises when unauthorized individuals or groups illicitly obtain access to sensitive user credentials that organizations store. Such credentials frequently comprise usernames, email addresses, and passwords. The repercussions of credential spills can be significant, as they commonly subject users to a range of hazards, including identity theft, financial fraud, and unauthorized account infiltration.Credential stuffing attacks are considered among the top threats for web and mobile applications as a result of the volume of credential spills. More than three billion credentials were spilled through online data breaches in 2016 alone.\n\n== Origin ==\nThe term was coined by Sumit Agarwal, co-founder of Shape Security, who was serving as Deputy Assistant Secretary of Defense at the Pentagon at the time.\n\n== Incidents ==\nOn 20 August 2018, U.K. health and beauty retailer Superdrug was targeted with an attempted blackmail, with hackers showing purported evidence that they had penetrated the company's site and downloaded 20,000 users' records. The evidence was most likely obtained from hacks and spillages and then used as the source for credential stuffing attacks to glean information to create the bogus evidence.In October and November 2016, attackers gained access to a private GitHub repository used by Uber (Uber BV and Uber UK) developers, using employees' usernames and passwords that had been compromised in previous breaches. The hackers claimed to have hijacked 12 employees' user accounts using the credential-stuffing method, as email addresses and passwords had been reused on other platforms. Multi-factor authentication, though available, was not activated for the affected accounts. The hackers located credentials for the company's AWS datastore in the repository files, which they used to obtain access to the records of 32 million non-US users and 3.7 million non-US drivers, as well as other data contained in over 100 S3 buckets. The attackers alerted Uber, demanding payment of $100,000 to agree to delete the data. The company paid through a bug bounty program but did not disclose the incident to affected parties for more than a year. After the breach came to light, the company was fined \u00a3385,000 (reduced to \u00a3308,000) by the U.K. Information Commissioner's Office.In 2019 Cybersecurity research firm Knight Lion Security claimed in a report that credential stuffing was favored attack method for GnosticPlayers.\n\n== Compromised credential checking ==\nCompromised credential checking is a technique enabling users to be notified when passwords are breached by websites, web browsers or password extensions.\nIn February 2018, British computer scientist Junade Ali created a communication protocol (using k-anonymity and cryptographic hashing) to anonymously verify whether a password was leaked without fully disclosing the searched password. This protocol was implemented as a public API and is now consumed by multiple websites and services, including password managers and browser extensions. This approach was later replicated by Google's Password Checkup feature. Ali worked with academics at Cornell University to develop new versions of the protocol known as Frequency Smoothing Bucketization (FSB) and Identifier-Based Bucketization (IDB). In March 2020, cryptographic padding was added to the protocol.\n\n\n*** Compromised credential checking implementations ***\n\nBased on the above text, answer a question. How successful are credential stuffing attacks in terms of unauthorized access rates?",
    "context": "",
    "output": "Credential stuffing attacks have a success rate of up to 2%, enabling attackers to take over thousands of accounts with just one million stolen credentials.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How successful are credential stuffing attacks in terms of unauthorized access rates?",
      "answer": "Credential stuffing attacks have a success rate of up to 2%, enabling attackers to take over thousands of accounts with just one million stolen credentials.",
      "context": "Credential stuffing\n\n==Introduction==\nCredential stuffing is a type of cyberattack in which the attacker collects stolen account credentials, typically consisting of lists of usernames or email addresses and the corresponding passwords (often from a data breach), and then uses the credentials to gain unauthorized access to user accounts on other systems through large-scale automated login requests directed against a web application. Unlike credential cracking, credential stuffing attacks do not attempt to use brute force or guess any passwords \u2013 the attacker simply automates the logins for a large number  (thousands to millions) of previously discovered credential pairs using standard web automation tools such as Selenium, cURL, PhantomJS or tools designed specifically for these types of attacks, such as Sentry MBA, SNIPR, STORM, Blackbullet and Openbullet.Credential stuffing attacks are possible because many users reuse the same username/password combination across multiple sites, with one survey reporting that 81% of users have reused a password across two or more sites and 25% of users use the same passwords across a majority of their accounts. In 2017, the FTC issued an advisory suggesting specific actions companies needed to take against credential stuffing, such as insisting on secure passwords and guarding against attacks. According to former Google click fraud czar Shuman Ghosemajumder, credential stuffing attacks have up to a 2% login success rate, meaning that one million stolen credentials can take over 20,000 accounts. Wired Magazine described the best way to protect against credential stuffing is to use unique passwords on accounts, such as those generated automatically by a password manager, enable two-factor authentication, and to have companies detect and stop credential stuffing attacks.\n\n\n\n== Credential spills ==\nA credential spill, alternatively referred to as a data breach or leak, arises when unauthorized individuals or groups illicitly obtain access to sensitive user credentials that organizations store. Such credentials frequently comprise usernames, email addresses, and passwords. The repercussions of credential spills can be significant, as they commonly subject users to a range of hazards, including identity theft, financial fraud, and unauthorized account infiltration.Credential stuffing attacks are considered among the top threats for web and mobile applications as a result of the volume of credential spills. More than three billion credentials were spilled through online data breaches in 2016 alone.\n\n== Origin ==\nThe term was coined by Sumit Agarwal, co-founder of Shape Security, who was serving as Deputy Assistant Secretary of Defense at the Pentagon at the time.\n\n== Incidents ==\nOn 20 August 2018, U.K. health and beauty retailer Superdrug was targeted with an attempted blackmail, with hackers showing purported evidence that they had penetrated the company's site and downloaded 20,000 users' records. The evidence was most likely obtained from hacks and spillages and then used as the source for credential stuffing attacks to glean information to create the bogus evidence.In October and November 2016, attackers gained access to a private GitHub repository used by Uber (Uber BV and Uber UK) developers, using employees' usernames and passwords that had been compromised in previous breaches. The hackers claimed to have hijacked 12 employees' user accounts using the credential-stuffing method, as email addresses and passwords had been reused on other platforms. Multi-factor authentication, though available, was not activated for the affected accounts. The hackers located credentials for the company's AWS datastore in the repository files, which they used to obtain access to the records of 32 million non-US users and 3.7 million non-US drivers, as well as other data contained in over 100 S3 buckets. The attackers alerted Uber, demanding payment of $100,000 to agree to delete the data. The company paid through a bug bounty program but did not disclose the incident to affected parties for more than a year. After the breach came to light, the company was fined \u00a3385,000 (reduced to \u00a3308,000) by the U.K. Information Commissioner's Office.In 2019 Cybersecurity research firm Knight Lion Security claimed in a report that credential stuffing was favored attack method for GnosticPlayers.\n\n== Compromised credential checking ==\nCompromised credential checking is a technique enabling users to be notified when passwords are breached by websites, web browsers or password extensions.\nIn February 2018, British computer scientist Junade Ali created a communication protocol (using k-anonymity and cryptographic hashing) to anonymously verify whether a password was leaked without fully disclosing the searched password. This protocol was implemented as a public API and is now consumed by multiple websites and services, including password managers and browser extensions. This approach was later replicated by Google's Password Checkup feature. Ali worked with academics at Cornell University to develop new versions of the protocol known as Frequency Smoothing Bucketization (FSB) and Identifier-Based Bucketization (IDB). In March 2020, cryptographic padding was added to the protocol.\n\n\n*** Compromised credential checking implementations ***"
    }
  },
  {
    "instruction": "Write an answer to the following question: How does Winlogon handle the creation of the desktops for the window station?",
    "context": "",
    "output": "Winlogon creates and opens an interactive windows station, WinSta0, and creates three desktops - Winlogon, Default and ScreenSaver.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does Winlogon handle the creation of the desktops for the window station?",
      "answer": "Winlogon creates and opens an interactive windows station, WinSta0, and creates three desktops - Winlogon, Default and ScreenSaver."
    }
  },
  {
    "instruction": "Answer based on context:\n\nLinux Intrusion Detection System\n\n==Introduction==\nIn computer security, the Linux Intrusion Detection System (LIDS) is a patch to the Linux kernel and associated administrative tools that enhances the kernel's security by implementing mandatory access control (MAC). When LIDS is in effect all system network administration operations, chosen file access, any capability use, raw device, memory, and I/O access can be made impossible, even for root. One can define which programs can access specific files. It uses and extends the system capabilities bounding set to control the whole system and adds some network and filesystem security features to the kernel to enhance the security. One can finely tune the security protections online, hide sensitive processes, receive security alerts through the network, and more. LIDS currently supports Linux kernel 2.6, 2.4. LIDS is released under the terms of the GNU General Public License (GPL).\n\n\n\n== Current Status ==\nAs of 2013, the Project appears to be dead. The last updates on the homepage and in the associated forum were from 2010, and as of 2018 the website is no longer running.\n\nHow does LIDS control access to specific files and programs in the system?",
    "context": "",
    "output": "LIDS allows users to define which programs can access specific files, thereby controlling access to files at a fine-grained level. This is done through the use of mandatory access control (MAC), which restricts access to system resources regardless of the privileges of the user.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does LIDS control access to specific files and programs in the system?",
      "answer": "LIDS allows users to define which programs can access specific files, thereby controlling access to files at a fine-grained level. This is done through the use of mandatory access control (MAC), which restricts access to system resources regardless of the privileges of the user.",
      "context": "Linux Intrusion Detection System\n\n==Introduction==\nIn computer security, the Linux Intrusion Detection System (LIDS) is a patch to the Linux kernel and associated administrative tools that enhances the kernel's security by implementing mandatory access control (MAC). When LIDS is in effect all system network administration operations, chosen file access, any capability use, raw device, memory, and I/O access can be made impossible, even for root. One can define which programs can access specific files. It uses and extends the system capabilities bounding set to control the whole system and adds some network and filesystem security features to the kernel to enhance the security. One can finely tune the security protections online, hide sensitive processes, receive security alerts through the network, and more. LIDS currently supports Linux kernel 2.6, 2.4. LIDS is released under the terms of the GNU General Public License (GPL).\n\n\n\n== Current Status ==\nAs of 2013, the Project appears to be dead. The last updates on the homepage and in the associated forum were from 2010, and as of 2018 the website is no longer running."
    }
  },
  {
    "instruction": "Wireshark\n\n==Introduction==\nWireshark is a free and open-source packet analyzer. It is used for network troubleshooting, analysis, software and communications protocol development, and education. Originally named Ethereal, the project was renamed Wireshark in May 2006 due to trademark issues.Wireshark is cross-platform, using the Qt widget toolkit in current releases to implement its user interface, and using pcap to capture packets; it runs on Linux, macOS, BSD, Solaris, some other Unix-like operating systems, and Microsoft Windows. There is also a terminal-based (non-GUI) version called TShark. Wireshark, and the other programs distributed with it such as TShark, are free software, released under the terms of the GNU General Public License version 2 or any later version.\n\n\n\n== Functionality ==\nWireshark is very similar to tcpdump, but has a graphical front-end and integrated sorting and filtering options.\nWireshark lets the user put network interface controllers into promiscuous mode (if supported by the network interface controller), so they can see all the traffic visible on that interface including unicast traffic not sent to that network interface controller's MAC address. However, when capturing with a packet analyzer in promiscuous mode on a port on a network switch, not all traffic through the switch is necessarily sent to the port where the capture is done, so capturing in promiscuous mode is not necessarily sufficient to see all network traffic. Port mirroring or various network taps extend capture to any point on the network. Simple passive taps are extremely resistant to tampering.\nOn Linux, BSD, and macOS, with libpcap 1.0.0 or later, Wireshark 1.4 and later can also put wireless network interface controllers into monitor mode.\nIf a remote machine captures packets and sends the captured packets to a machine running Wireshark using the TZSP protocol or the protocol used by OmniPeek, Wireshark dissects those packets, so it can analyze packets captured on a remote machine at the time that they are captured.\n\n== Features ==\nWireshark is a data capturing program that \"understands\" the structure (encapsulation) of different networking protocols. It can parse and display the fields, along with their meanings as specified by different networking protocols. Wireshark uses pcap to capture packets, so it can only capture packets on the types of networks that pcap supports.\n\nData can be captured \"from the wire\" from a live network connection or read from a file of already-captured packets.\nLive data can be read from different types of networks, including Ethernet, IEEE 802.11, PPP, and loopback.\nCaptured network data can be browsed via a GUI, or via the terminal (command line) version of the utility, TShark.\nCaptured files can be programmatically edited or converted via command-line switches to the \"editcap\" program.\nData display can be refined using a display filter.\nPlug-ins can be created for dissecting new protocols.\nVoIP calls in the captured traffic can be detected. If encoded in a compatible encoding, the media flow can even be played.\nRaw USB traffic can be captured.\nWireless connections can also be filtered as long as they traverse the monitored Ethernet.\nVarious settings, timers, and filters can be set to provide the facility of filtering the output of the captured traffic.Wireshark's native network trace file formats are the libpcap format read and written by libpcap, WinPcap, and Npcap, so it can exchange captured network traces with other applications that use the same format, including tcpdump and CA NetMaster, and the pcapng format read by newer versions of libpcap. It can also read captures from other network analyzers, such as snoop, Network General's Sniffer, and Microsoft Network Monitor.\n\n== Security ==\nCapturing raw network traffic from an interface requires elevated privileges on some platforms. For this reason, older versions of Wireshark and TShark often ran with superuser privileges. Considering the huge number of protocol dissectors that are called when traffic is captured and recognizing the possibility of a bug in a dissector, a serious security risk can be posed. Due to the rather large number of vulnerabilities in the past (of which many have allowed remote code execution) and developers' doubts for better future development, OpenBSD removed Ethereal from its ports tree prior to OpenBSD 3.6.Elevated privileges are not needed for all operations. For example, an alternative is to run tcpdump or the dumpcap utility that comes with Wireshark with superuser privileges to capture packets into a file, and later analyze the packets by running Wireshark with restricted privileges. To emulate near realtime analysis, each captured file may be merged by mergecap into a growing file processed by Wireshark. On wireless networks, it is possible to use the Aircrack wireless security tools to capture IEEE 802.11 frames and read the resulting dump files with Wireshark.\nAs of Wireshark 0.99.7, Wireshark and TShark run dumpcap to perform traffic capture. Platforms that require special privileges to capture traffic need only dumpcap run with those privileges. Neither Wireshark nor TShark need to or should be run with special privileges.\n\n== Color coding ==\nWireshark can color packets based on rules that match particular fields in packets, to help the user identify the types of traffic at a glance. A default set of rules is provided; users can change existing rules for coloring packets, add new rules, or remove rules.\n\n== Simulation packet capture ==\nWireshark can also be used to capture packets from most network simulation tools such as ns and OPNET Modeler.\n\nQ: How can captured network data be browsed in Wireshark?",
    "context": "",
    "output": "A: Captured network data can be browsed via a GUI or via the terminal (command line) version of the utility, TShark. This allows the user to view and analyze the captured data in a convenient and flexible manner.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can captured network data be browsed in Wireshark?",
      "answer": "Captured network data can be browsed via a GUI or via the terminal (command line) version of the utility, TShark. This allows the user to view and analyze the captured data in a convenient and flexible manner.",
      "context": "Wireshark\n\n==Introduction==\nWireshark is a free and open-source packet analyzer. It is used for network troubleshooting, analysis, software and communications protocol development, and education. Originally named Ethereal, the project was renamed Wireshark in May 2006 due to trademark issues.Wireshark is cross-platform, using the Qt widget toolkit in current releases to implement its user interface, and using pcap to capture packets; it runs on Linux, macOS, BSD, Solaris, some other Unix-like operating systems, and Microsoft Windows. There is also a terminal-based (non-GUI) version called TShark. Wireshark, and the other programs distributed with it such as TShark, are free software, released under the terms of the GNU General Public License version 2 or any later version.\n\n\n\n== Functionality ==\nWireshark is very similar to tcpdump, but has a graphical front-end and integrated sorting and filtering options.\nWireshark lets the user put network interface controllers into promiscuous mode (if supported by the network interface controller), so they can see all the traffic visible on that interface including unicast traffic not sent to that network interface controller's MAC address. However, when capturing with a packet analyzer in promiscuous mode on a port on a network switch, not all traffic through the switch is necessarily sent to the port where the capture is done, so capturing in promiscuous mode is not necessarily sufficient to see all network traffic. Port mirroring or various network taps extend capture to any point on the network. Simple passive taps are extremely resistant to tampering.\nOn Linux, BSD, and macOS, with libpcap 1.0.0 or later, Wireshark 1.4 and later can also put wireless network interface controllers into monitor mode.\nIf a remote machine captures packets and sends the captured packets to a machine running Wireshark using the TZSP protocol or the protocol used by OmniPeek, Wireshark dissects those packets, so it can analyze packets captured on a remote machine at the time that they are captured.\n\n== Features ==\nWireshark is a data capturing program that \"understands\" the structure (encapsulation) of different networking protocols. It can parse and display the fields, along with their meanings as specified by different networking protocols. Wireshark uses pcap to capture packets, so it can only capture packets on the types of networks that pcap supports.\n\nData can be captured \"from the wire\" from a live network connection or read from a file of already-captured packets.\nLive data can be read from different types of networks, including Ethernet, IEEE 802.11, PPP, and loopback.\nCaptured network data can be browsed via a GUI, or via the terminal (command line) version of the utility, TShark.\nCaptured files can be programmatically edited or converted via command-line switches to the \"editcap\" program.\nData display can be refined using a display filter.\nPlug-ins can be created for dissecting new protocols.\nVoIP calls in the captured traffic can be detected. If encoded in a compatible encoding, the media flow can even be played.\nRaw USB traffic can be captured.\nWireless connections can also be filtered as long as they traverse the monitored Ethernet.\nVarious settings, timers, and filters can be set to provide the facility of filtering the output of the captured traffic.Wireshark's native network trace file formats are the libpcap format read and written by libpcap, WinPcap, and Npcap, so it can exchange captured network traces with other applications that use the same format, including tcpdump and CA NetMaster, and the pcapng format read by newer versions of libpcap. It can also read captures from other network analyzers, such as snoop, Network General's Sniffer, and Microsoft Network Monitor.\n\n== Security ==\nCapturing raw network traffic from an interface requires elevated privileges on some platforms. For this reason, older versions of Wireshark and TShark often ran with superuser privileges. Considering the huge number of protocol dissectors that are called when traffic is captured and recognizing the possibility of a bug in a dissector, a serious security risk can be posed. Due to the rather large number of vulnerabilities in the past (of which many have allowed remote code execution) and developers' doubts for better future development, OpenBSD removed Ethereal from its ports tree prior to OpenBSD 3.6.Elevated privileges are not needed for all operations. For example, an alternative is to run tcpdump or the dumpcap utility that comes with Wireshark with superuser privileges to capture packets into a file, and later analyze the packets by running Wireshark with restricted privileges. To emulate near realtime analysis, each captured file may be merged by mergecap into a growing file processed by Wireshark. On wireless networks, it is possible to use the Aircrack wireless security tools to capture IEEE 802.11 frames and read the resulting dump files with Wireshark.\nAs of Wireshark 0.99.7, Wireshark and TShark run dumpcap to perform traffic capture. Platforms that require special privileges to capture traffic need only dumpcap run with those privileges. Neither Wireshark nor TShark need to or should be run with special privileges.\n\n== Color coding ==\nWireshark can color packets based on rules that match particular fields in packets, to help the user identify the types of traffic at a glance. A default set of rules is provided; users can change existing rules for coloring packets, add new rules, or remove rules.\n\n== Simulation packet capture ==\nWireshark can also be used to capture packets from most network simulation tools such as ns and OPNET Modeler."
    }
  },
  {
    "instruction": "PfSense\n\n==Introduction==\npfSense is a firewall/router computer software distribution based on FreeBSD. The open source pfSense Community Edition (CE) and pfSense Plus is installed on a physical computer or a virtual machine to make a dedicated firewall/router for a network. It can be configured and upgraded through a web-based interface, and requires no knowledge of the underlying FreeBSD system to manage.\n\n== Overview ==\nThe pfSense project began in 2004 as a fork of the m0n0wall project by Chris Buechler and Scott Ullrich. Its first release was in October 2006. The name derives from the fact that the software uses the packet-filtering tool, PF.Notable functions of pfSense include traffic shaping, VPNs using IPsec or PPTP, captive portal, stateful firewall, network address translation, 802.1q support for VLANs, and dynamic DNS. pfSense can be installed on hardware with an x86-64 processor architecture. It can also be installed on embedded hardware using Compact Flash or SD cards, or as a virtual machine.\n\n\n*** WireGuard protocol support ***\nIn February 2021, pfSense CE 2.5.0 and pfSense Plus 21.02 added support for a kernel WireGuard implementation. Support for WireGuard was temporarily removed in March 2021 after implementation issues were discovered by WireGuard founder Jason Donenfeld. The July 2021 release of pfSense CE 2.5.2 version re-included WireGuard.\nRead the text above and answer this question: Can pfSense be used to set up a captive portal?",
    "context": "",
    "output": "Yes, pfSense includes support for captive portal, which can be used to control and manage access to a network.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Can pfSense be used to set up a captive portal?",
      "answer": "Yes, pfSense includes support for captive portal, which can be used to control and manage access to a network.",
      "context": "PfSense\n\n==Introduction==\npfSense is a firewall/router computer software distribution based on FreeBSD. The open source pfSense Community Edition (CE) and pfSense Plus is installed on a physical computer or a virtual machine to make a dedicated firewall/router for a network. It can be configured and upgraded through a web-based interface, and requires no knowledge of the underlying FreeBSD system to manage.\n\n== Overview ==\nThe pfSense project began in 2004 as a fork of the m0n0wall project by Chris Buechler and Scott Ullrich. Its first release was in October 2006. The name derives from the fact that the software uses the packet-filtering tool, PF.Notable functions of pfSense include traffic shaping, VPNs using IPsec or PPTP, captive portal, stateful firewall, network address translation, 802.1q support for VLANs, and dynamic DNS. pfSense can be installed on hardware with an x86-64 processor architecture. It can also be installed on embedded hardware using Compact Flash or SD cards, or as a virtual machine.\n\n\n*** WireGuard protocol support ***\nIn February 2021, pfSense CE 2.5.0 and pfSense Plus 21.02 added support for a kernel WireGuard implementation. Support for WireGuard was temporarily removed in March 2021 after implementation issues were discovered by WireGuard founder Jason Donenfeld. The July 2021 release of pfSense CE 2.5.2 version re-included WireGuard."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does ISO/IEC 27001 address information security risks?",
    "context": "",
    "output": "ISO/IEC 27001 requires organizations to systematically examine their information security risks, taking into account threats, vulnerabilities, and impacts, and to design and implement a coherent and comprehensive suite of information security controls to address unacceptable risks.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does ISO/IEC 27001 address information security risks?",
      "answer": "ISO/IEC 27001 requires organizations to systematically examine their information security risks, taking into account threats, vulnerabilities, and impacts, and to design and implement a coherent and comprehensive suite of information security controls to address unacceptable risks."
    }
  },
  {
    "instruction": "Cookiemonster attack\n\n==Introduction==\nThe CookieMonster attack is a man-in-the-middle exploit where a third party can gain HTTPS cookie data when the \"Encrypted Sessions Only\" property is not properly set. This could allow access to sites with sensitive personal or financial information.It is a Python based tool, developed by security researcher Mike Perry.\nPerry originally announced the vulnerability exploited by CookieMonster on BugTraq in 2007. A year later, he demonstrated CookieMonster as a proof of concept tool at Defcon 16.Users of the World Wide Web can reduce their exposure to CookieMonster attacks by avoiding websites that are unprotected to these attacks. Certain web browsers make it possible for the user to establish which sites these are. For example, users of the Firefox browser can go to the Privacy tab in the Preferences window, and click on 'Show Cookies.' For a given site, inspecting the individual cookies for the top level name of the site, and any subdomain names, will reveal if 'Send For: Encrypted connections only,' has been set. If it has, the user can test for the site's vulnerability to CookieMonster attacks by deleting these cookies and visiting the site again. If the site still allows the user in, the site is vulnerable to CookieMonster attacks.\n\n== Affected websites ==\nWebsites allegedly affected by CookieMonster included:\nGoogle services including: Gmail, Blogger, Google Docs, Google Finance and search history\nAirline/Travel websites: Southwest, United, Expedia, USAirways.com, priceline.com\nBanks: National City, USAA, Patelco, CapitalOne\nDomain Registrars: Register.com, namesecure.com\nMerchants: eBay, wireless.att.com, Netflix, Newegg\nRead the text above and answer this question: What is the origin of the CookieMonster attack?",
    "context": "",
    "output": "The CookieMonster attack originated as a proof of concept tool demonstrated at Defcon 16 by security researcher Mike Perry.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the origin of the CookieMonster attack?",
      "answer": "The CookieMonster attack originated as a proof of concept tool demonstrated at Defcon 16 by security researcher Mike Perry.",
      "context": "Cookiemonster attack\n\n==Introduction==\nThe CookieMonster attack is a man-in-the-middle exploit where a third party can gain HTTPS cookie data when the \"Encrypted Sessions Only\" property is not properly set. This could allow access to sites with sensitive personal or financial information.It is a Python based tool, developed by security researcher Mike Perry.\nPerry originally announced the vulnerability exploited by CookieMonster on BugTraq in 2007. A year later, he demonstrated CookieMonster as a proof of concept tool at Defcon 16.Users of the World Wide Web can reduce their exposure to CookieMonster attacks by avoiding websites that are unprotected to these attacks. Certain web browsers make it possible for the user to establish which sites these are. For example, users of the Firefox browser can go to the Privacy tab in the Preferences window, and click on 'Show Cookies.' For a given site, inspecting the individual cookies for the top level name of the site, and any subdomain names, will reveal if 'Send For: Encrypted connections only,' has been set. If it has, the user can test for the site's vulnerability to CookieMonster attacks by deleting these cookies and visiting the site again. If the site still allows the user in, the site is vulnerable to CookieMonster attacks.\n\n== Affected websites ==\nWebsites allegedly affected by CookieMonster included:\nGoogle services including: Gmail, Blogger, Google Docs, Google Finance and search history\nAirline/Travel websites: Southwest, United, Expedia, USAirways.com, priceline.com\nBanks: National City, USAA, Patelco, CapitalOne\nDomain Registrars: Register.com, namesecure.com\nMerchants: eBay, wireless.att.com, Netflix, Newegg"
    }
  },
  {
    "instruction": "Write an answer to the following question: How do different identity providers follow their own rules for issuing electronic identity credentials?",
    "context": "",
    "output": "Different identity providers follow their own rules for issuing electronic identity credentials, with more trustworthy credentials having more stringent rules governing identity proofing, credential management, and the kind of credentials issued.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do different identity providers follow their own rules for issuing electronic identity credentials?",
      "answer": "Different identity providers follow their own rules for issuing electronic identity credentials, with more trustworthy credentials having more stringent rules governing identity proofing, credential management, and the kind of credentials issued."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the impact of the OpenSSL vulnerability CVE-2013-0169 on SSL, TLS and DTLS plaintext recovery attack?",
    "context": "",
    "output": "The vulnerability CVE-2013-0169 allows a timing attack during MAC processing in SSL, TLS and DTLS plaintext recovery attack, potentially revealing sensitive data.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the impact of the OpenSSL vulnerability CVE-2013-0169 on SSL, TLS and DTLS plaintext recovery attack?",
      "answer": "The vulnerability CVE-2013-0169 allows a timing attack during MAC processing in SSL, TLS and DTLS plaintext recovery attack, potentially revealing sensitive data."
    }
  },
  {
    "instruction": "Write an answer to the following question: Who were some of the notable members of the President's Commission on Enhancing National Cybersecurity?",
    "context": "",
    "output": "Some of the notable members of the President's Commission on Enhancing National Cybersecurity included Tom Donilon, former Assistant to the President and National Security Advisor, Sam Palmisano, former CEO of IBM, General Keith Alexander, CEO of IronNet Cybersecurity, and Heather Murren, former member of the Financial Crisis Inquiry Commission and co-founder of the Nevada Cancer Institute.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Who were some of the notable members of the President's Commission on Enhancing National Cybersecurity?",
      "answer": "Some of the notable members of the President's Commission on Enhancing National Cybersecurity included Tom Donilon, former Assistant to the President and National Security Advisor, Sam Palmisano, former CEO of IBM, General Keith Alexander, CEO of IronNet Cybersecurity, and Heather Murren, former member of the Financial Crisis Inquiry Commission and co-founder of the Nevada Cancer Institute."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the Pacman exploit take advantage of the speculative execution function in Apple M1 processors, and what makes it particularly challenging to mitigate?",
    "context": "",
    "output": "The Pacman exploit takes advantage of a hardware bug in the speculative execution function of Apple M1 processors, specifically in a security feature called pointer authentication codes (PAC). This vulnerability is believed to be intrinsic to the platform, which means that it cannot be completely patched. The challenge lies in the fact that the M1 was the first ARM desktop CPU to implement pointer authentication, making it an uncharted territory for security researchers and developers. Additionally, exploiting this vulnerability requires both memory corruption and speculative execution, which makes it even more complicated to address.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the Pacman exploit take advantage of the speculative execution function in Apple M1 processors, and what makes it particularly challenging to mitigate?",
      "answer": "The Pacman exploit takes advantage of a hardware bug in the speculative execution function of Apple M1 processors, specifically in a security feature called pointer authentication codes (PAC). This vulnerability is believed to be intrinsic to the platform, which means that it cannot be completely patched. The challenge lies in the fact that the M1 was the first ARM desktop CPU to implement pointer authentication, making it an uncharted territory for security researchers and developers. Additionally, exploiting this vulnerability requires both memory corruption and speculative execution, which makes it even more complicated to address."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the method provided by Bruce Schneier to prevent known plaintext attacks on the first layer in multiple encryption?",
    "context": "",
    "output": "Bruce Schneier's method involves generating a random pad R of the same size as the plaintext, encrypting R using the first cipher and key, XORing the plaintext with the pad, then encrypting the result using the second cipher and a different key. The ciphertexts are then concatenated to build the final ciphertext.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the method provided by Bruce Schneier to prevent known plaintext attacks on the first layer in multiple encryption?",
      "answer": "Bruce Schneier's method involves generating a random pad R of the same size as the plaintext, encrypting R using the first cipher and key, XORing the plaintext with the pad, then encrypting the result using the second cipher and a different key. The ciphertexts are then concatenated to build the final ciphertext."
    }
  },
  {
    "instruction": "Write an answer to the following question: Why is it important to automate digital certificate and private key rotations in crypto-agility?",
    "context": "",
    "output": "Automating digital certificate and private key rotations in crypto-agility ensures that the system can easily and quickly switch to new cryptographic primitives when needed, without disrupting the systems' infrastructure.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Why is it important to automate digital certificate and private key rotations in crypto-agility?",
      "answer": "Automating digital certificate and private key rotations in crypto-agility ensures that the system can easily and quickly switch to new cryptographic primitives when needed, without disrupting the systems' infrastructure."
    }
  },
  {
    "instruction": "Write an answer to the following question: How do digital forensic tools differ from general-purpose security tools?",
    "context": "",
    "output": "Digital forensic tools differ from general-purpose security tools in that they are designed specifically for digital forensics investigations. General-purpose security tools may be designed for real-time monitoring or intrusion detection, while digital forensic tools are designed for post-incident analysis and evidence preservation.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do digital forensic tools differ from general-purpose security tools?",
      "answer": "Digital forensic tools differ from general-purpose security tools in that they are designed specifically for digital forensics investigations. General-purpose security tools may be designed for real-time monitoring or intrusion detection, while digital forensic tools are designed for post-incident analysis and evidence preservation."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the role of OpenSSL in FreeLAN's implementation of encryption?",
    "context": "",
    "output": "OpenSSL is responsible for handling the encryption and authentication work in FreeLAN, allowing it to use all the available ciphers in the OpenSSL package to secure data and control channels.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of OpenSSL in FreeLAN's implementation of encryption?",
      "answer": "OpenSSL is responsible for handling the encryption and authentication work in FreeLAN, allowing it to use all the available ciphers in the OpenSSL package to secure data and control channels."
    }
  },
  {
    "instruction": "Write an answer to the following question: What was the decision of U.S. District Judge William K. Sessions?",
    "context": "",
    "output": "U.S. District Judge William K. Sessions reversed the magistrate's ruling and directed Boucher \"to provide an unencrypted version of the Z drive viewed by the ICE agent.\"",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was the decision of U.S. District Judge William K. Sessions?",
      "answer": "U.S. District Judge William K. Sessions reversed the magistrate's ruling and directed Boucher \"to provide an unencrypted version of the Z drive viewed by the ICE agent.\""
    }
  },
  {
    "instruction": "PLA Unit 61398\n\n==Introduction==\nPLA Unit 61398 (also known as APT 1, Comment Crew, Comment Panda, GIF89a, and Byzantine Candor) (Chinese: 61398\u90e8\u961f, Pinyin: 61398 b\u00f9du\u00ec) is the Military Unit Cover Designator (MUCD) of a People's Liberation Army advanced persistent threat unit that has been alleged to be a source of Chinese computer hacking attacks. The unit is stationed in Pudong, Shanghai.\n\n\n\n== Public position of the Chinese government ==\nUntil 2013, the Government of China has consistently denied that it is involved in hacking. In response to the Mandiant Corporation report about Unit 61398, Hong Lei, a spokesperson for the Chinese foreign ministry, said such allegations were \"unprofessional\".In 2013, China changed its position and openly admitted to having secretive cyber warfare units in both the military and the civilian part of the government \u2013 however, the details of their activities were left to speculation. As a show of force towards the rest of the global community the Chinese government now openly lists their abilities when it comes to digital spying and network attack capabilities.\nRead the text above and answer this question: What is the relationship between PLA Unit 61398 and the Chinese government's stance on hacking?",
    "context": "",
    "output": "PLA Unit 61398 has been accused of being a source of Chinese computer hacking attacks, and the Chinese government has consistently denied involvement in hacking and dismissed allegations about PLA Unit 61398 as \"unprofessional\".",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the relationship between PLA Unit 61398 and the Chinese government's stance on hacking?",
      "answer": "PLA Unit 61398 has been accused of being a source of Chinese computer hacking attacks, and the Chinese government has consistently denied involvement in hacking and dismissed allegations about PLA Unit 61398 as \"unprofessional\".",
      "context": "PLA Unit 61398\n\n==Introduction==\nPLA Unit 61398 (also known as APT 1, Comment Crew, Comment Panda, GIF89a, and Byzantine Candor) (Chinese: 61398\u90e8\u961f, Pinyin: 61398 b\u00f9du\u00ec) is the Military Unit Cover Designator (MUCD) of a People's Liberation Army advanced persistent threat unit that has been alleged to be a source of Chinese computer hacking attacks. The unit is stationed in Pudong, Shanghai.\n\n\n\n== Public position of the Chinese government ==\nUntil 2013, the Government of China has consistently denied that it is involved in hacking. In response to the Mandiant Corporation report about Unit 61398, Hong Lei, a spokesperson for the Chinese foreign ministry, said such allegations were \"unprofessional\".In 2013, China changed its position and openly admitted to having secretive cyber warfare units in both the military and the civilian part of the government \u2013 however, the details of their activities were left to speculation. As a show of force towards the rest of the global community the Chinese government now openly lists their abilities when it comes to digital spying and network attack capabilities."
    }
  },
  {
    "instruction": "Write an answer to the following question: How can homomorphic encryption be used for privacy-preserving outsourced storage and computation?",
    "context": "",
    "output": "Homomorphic encryption can be used for privacy-preserving outsourced storage and computation by allowing data to be encrypted and outsourced to commercial cloud environments for processing, all while the data remains encrypted. This can be useful for sensitive data such as health care information, where privacy concerns may inhibit data sharing.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can homomorphic encryption be used for privacy-preserving outsourced storage and computation?",
      "answer": "Homomorphic encryption can be used for privacy-preserving outsourced storage and computation by allowing data to be encrypted and outsourced to commercial cloud environments for processing, all while the data remains encrypted. This can be useful for sensitive data such as health care information, where privacy concerns may inhibit data sharing."
    }
  },
  {
    "instruction": "Context: SIGABA\n\n==Introduction==\nIn the history of cryptography, the ECM Mark II was a cipher machine used by the United States for message encryption from World War II until the 1950s. The machine was also known as the SIGABA or Converter M-134 by the Army, or CSP-888/889 by the Navy, and a modified Navy version was termed the CSP-2900.\nLike many machines of the era it used an electromechanical system of rotors to encipher messages, but with a number of security improvements over previous designs. No successful cryptanalysis of the machine during its service lifetime is publicly known.\n\n== Description ==\n\nSIGABA was similar to the Enigma in basic theory, in that it used a series of rotors to encipher every character of the plaintext into a different character of ciphertext. Unlike Enigma's three rotors however, the SIGABA included fifteen, and did not use a reflecting rotor.\nThe SIGABA had three banks of five rotors each; the action of two of the banks controlled the stepping of the third.\n\nThe main bank of five rotors was termed the cipher rotors (Army) or alphabet maze (Navy) and each rotor had 26 contacts. This assembly acted similarly to other rotor machines, such as the Enigma; when a plaintext letter was entered,  a signal would enter one side of the bank and exit the other, denoting the ciphertext letter. Unlike the Enigma, there was no reflector.\nThe second bank of five rotors was termed the control rotors or stepping maze. These were also 26-contact rotors. The control rotors received four signals at each step. After passing through the control rotors, the outputs were divided into ten groups of various sizes, ranging from 1\u20136 wires. Each group corresponded to an input wire for the next bank of rotors.\nThe third bank of rotors was called the index rotors. These rotors were smaller, with only ten contacts, and did not step during the encryption. After travelling though the index rotors, one to four of five output lines would have power. These then turned the cypher rotors.\nThe SIGABA advanced one or more of its main rotors in a complex, pseudorandom fashion. This meant that attacks which could break other rotor machines with simpler stepping (for example, Enigma) were made much more complex. Even with the plaintext in hand, there were so many potential inputs to the encryption that it was difficult to work out the settings.\nOn the downside, the SIGABA was also large, heavy, expensive, difficult to operate, mechanically complex, and fragile. It was nowhere near as practical a device as the Enigma, which was smaller and lighter than the radios with which it was used. It found widespread use in the radio rooms of US Navy ships, but as a result of these practical problems the SIGABA simply couldn't be used in the field. In most theatres other systems were used instead, especially for tactical communications. One of the most famous was the use of Navajo code talkers for tactical field communications in the Pacific Theater. In other theatres, less secure, but smaller, lighter, and sturdier machines were used, such as the M-209. SIGABA, impressive as it was, was overkill for tactical communications. This said, new speculative evidence emerged more recently that the M-209 code was broken by German cryptanalysts during World War II.\n\n== Operation ==\n\nBecause SIGABA did not have a reflector, a 26+ pole switch was needed  to change the signal paths through the alphabet maze between the encryption and decryption modes. The long \u201ccontroller\u201d switch was mounted vertically, with its knob on the top of the housing. See image. It had five positions, O, P, R, E and D. Besides encrypt (E) and decrypt (D), it had a plain text position (P) that printed whatever was typed on the output tape, and a reset position (R) that was used to set the rotors and to zeroize the machine. The O position turned the machine off. The P setting was used to print the indicators and date/time groups on the output tape. It was the only mode that printed numbers. No printing took place in the R setting, but digit keys were active to increment rotors.\nDuring encryption, the Z key was connected to the X key and the space bar produced a Z input to the alphabet maze. A Z was printed as a space on decryption. The reader was expected to understand that a word like \u201cxebra\u201d in a decrypted message was actually \u201czebra.\u201d The printer automatically added a space between each group of five characters during encryption.\nThe SIGABA was zeroized when all the index rotors read zero in their low order digit and all the alphabet and code rotors were set to the letter O. Each rotor had a cam that caused the rotor to stop in the proper position during the zeroize process.\nSIGABA\u2019s rotors were all housed in a removable frame held in place by four thumb screws. This allowed the most sensitive elements of the machine to be stored in more secure safes and to be quickly thrown overboard or otherwise destroyed if capture was threatened. It also allowed a machine to  quickly switch between networks that used different rotor orders. Messages had two 5- character indicators, an exterior indicator that specified the system being used and the security classification and an interior indicator that determined the initial settings of the code and alphabet rotors. The key list included separate index rotor settings for each security classification. This prevented lower classification messages from being used as cribs to attack higher classification messages.\nThe Navy and Army had different procedures for the interior indicator. Both started by zeroizing the machine and having the operator select a random 5-character string for each new message. This was then encrypted to produce the interior indicator. Army key lists included an initial setting for the rotors that was used to encrypt the random string. The Navy operators used the keyboard to increment the code rotors until they matched the random character string. The alphabet rotor would move during this process and their final position was the internal indicator. In case of joint operations, the Army procedures were followed.\nThe key lists included a \u201c26-30\u201d check string. After the rotors were reordered according to the current key, the operator would zeroize the machine, encrypt 25 characters and then encrypt \u201cAAAAA\u201d. The ciphertext resulting from the five A\u2019s had to match the check string. The manual warned that typographical errors were possible in key lists and that a four character match should be accepted.\nThe manual also gave suggestions on how to generate random strings for creating indicators.  These included using playing cards and poker chips, to selecting characters from cipher texts and using the SIGABA itself as a random character generator.\n\n== Security ==\n\nAlthough the SIGABA was extremely secure, the US continued to upgrade its capability throughout the war, for fear of the Axis cryptanalytic ability to break SIGABA's code. When the German's ENIGMA messages and Japan's Type B Cipher Machine were broken, the messages were closely scrutinized for signs that Axis forces were able to read the US cryptography codes. Axis prisoners of war (POWs) were also interrogated with the goal of finding evidence that US cryptography had been broken. However, both the Germans and Japanese were not making any progress in breaking the SIGABA code. A decrypted JN-A-20 message, dated 24 January 1942, sent from the naval attach\u00e9 in Berlin to vice chief of Japanese Naval General Staff in Tokyo stated that \"joint Jap[anese]-German cryptanalytical efforts\" to be \"highly satisfactory\", since the \"German[s] have exhibited commendable ingenuity and recently experienced some success on English Navy systems\", but are \"encountering difficulty in establishing successful techniques of attack on 'enemy' code setup\". In another decrypted JN-A-20 message, the Germans admitted that their progress in breaking US communications was unsatisfactory. The Japanese also admitted in their own communications that they had made no real progress against the American cipher system. In September 1944, when the Allies were advancing steadily on the Western front, the war diary of the German Signal Intelligence Group recorded: \"U.S. 5-letter traffic: Work discontinued as unprofitable at this time\".SIGABA systems were closely guarded at all times, with separate safes for the system base and the code-wheel assembly, but there was one incident where a unit was lost for a time. On February 3, 1945, a truck carrying a SIGABA system in three safes was stolen while its guards were visiting a brothel in recently-liberated Colmar, France. General Eisenhower ordered an extensive search, which finally discovered the safes six weeks later in a nearby river.:\u200app.510\u2013512\n\n== Interoperability with Allied counterparts ==\nThe need for cooperation among the US/British/Canadian forces in carrying out joint military operations against Axis forces gave rise to the need for a cipher  system that could be used by all Allied forces. This functionality was achieved in three different ways. Firstly, the ECM Adapter (CSP 1000), which could be retrofitted on Allied cipher machines, was produced at the Washington Naval Yard ECM Repair Shop. A total of 3,500 adapters were produced. The second method was to adapt the SIGABA for interoperation with a modified British machine, the Typex. The common machine was known as the Combined Cipher Machine (CCM), and was used from November 1943. Because of the high cost of production, only 631 CCMs were made. The third way was the most common and most cost-effective. It was the \"X\" Adapter manufactured by the Teletype Corporation in Chicago. A total of 4,500 of these adapters were installed at depot-level maintenance facilities.\n\nQuestion: What was the significance of the \"26-30\" check string in the SIGABA's key lists?\n\nAnswer:",
    "context": "",
    "output": "The \"26-30\" check string was used to ensure that the rotors were reordered according to the current key. The operator would zeroize the machine, encrypt 25 characters and then encrypt \"AAAAA\". The ciphertext resulting from the five A's had to match the check string.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was the significance of the \"26-30\" check string in the SIGABA's key lists?",
      "answer": "The \"26-30\" check string was used to ensure that the rotors were reordered according to the current key. The operator would zeroize the machine, encrypt 25 characters and then encrypt \"AAAAA\". The ciphertext resulting from the five A's had to match the check string.",
      "context": "SIGABA\n\n==Introduction==\nIn the history of cryptography, the ECM Mark II was a cipher machine used by the United States for message encryption from World War II until the 1950s. The machine was also known as the SIGABA or Converter M-134 by the Army, or CSP-888/889 by the Navy, and a modified Navy version was termed the CSP-2900.\nLike many machines of the era it used an electromechanical system of rotors to encipher messages, but with a number of security improvements over previous designs. No successful cryptanalysis of the machine during its service lifetime is publicly known.\n\n== Description ==\n\nSIGABA was similar to the Enigma in basic theory, in that it used a series of rotors to encipher every character of the plaintext into a different character of ciphertext. Unlike Enigma's three rotors however, the SIGABA included fifteen, and did not use a reflecting rotor.\nThe SIGABA had three banks of five rotors each; the action of two of the banks controlled the stepping of the third.\n\nThe main bank of five rotors was termed the cipher rotors (Army) or alphabet maze (Navy) and each rotor had 26 contacts. This assembly acted similarly to other rotor machines, such as the Enigma; when a plaintext letter was entered,  a signal would enter one side of the bank and exit the other, denoting the ciphertext letter. Unlike the Enigma, there was no reflector.\nThe second bank of five rotors was termed the control rotors or stepping maze. These were also 26-contact rotors. The control rotors received four signals at each step. After passing through the control rotors, the outputs were divided into ten groups of various sizes, ranging from 1\u20136 wires. Each group corresponded to an input wire for the next bank of rotors.\nThe third bank of rotors was called the index rotors. These rotors were smaller, with only ten contacts, and did not step during the encryption. After travelling though the index rotors, one to four of five output lines would have power. These then turned the cypher rotors.\nThe SIGABA advanced one or more of its main rotors in a complex, pseudorandom fashion. This meant that attacks which could break other rotor machines with simpler stepping (for example, Enigma) were made much more complex. Even with the plaintext in hand, there were so many potential inputs to the encryption that it was difficult to work out the settings.\nOn the downside, the SIGABA was also large, heavy, expensive, difficult to operate, mechanically complex, and fragile. It was nowhere near as practical a device as the Enigma, which was smaller and lighter than the radios with which it was used. It found widespread use in the radio rooms of US Navy ships, but as a result of these practical problems the SIGABA simply couldn't be used in the field. In most theatres other systems were used instead, especially for tactical communications. One of the most famous was the use of Navajo code talkers for tactical field communications in the Pacific Theater. In other theatres, less secure, but smaller, lighter, and sturdier machines were used, such as the M-209. SIGABA, impressive as it was, was overkill for tactical communications. This said, new speculative evidence emerged more recently that the M-209 code was broken by German cryptanalysts during World War II.\n\n== Operation ==\n\nBecause SIGABA did not have a reflector, a 26+ pole switch was needed  to change the signal paths through the alphabet maze between the encryption and decryption modes. The long \u201ccontroller\u201d switch was mounted vertically, with its knob on the top of the housing. See image. It had five positions, O, P, R, E and D. Besides encrypt (E) and decrypt (D), it had a plain text position (P) that printed whatever was typed on the output tape, and a reset position (R) that was used to set the rotors and to zeroize the machine. The O position turned the machine off. The P setting was used to print the indicators and date/time groups on the output tape. It was the only mode that printed numbers. No printing took place in the R setting, but digit keys were active to increment rotors.\nDuring encryption, the Z key was connected to the X key and the space bar produced a Z input to the alphabet maze. A Z was printed as a space on decryption. The reader was expected to understand that a word like \u201cxebra\u201d in a decrypted message was actually \u201czebra.\u201d The printer automatically added a space between each group of five characters during encryption.\nThe SIGABA was zeroized when all the index rotors read zero in their low order digit and all the alphabet and code rotors were set to the letter O. Each rotor had a cam that caused the rotor to stop in the proper position during the zeroize process.\nSIGABA\u2019s rotors were all housed in a removable frame held in place by four thumb screws. This allowed the most sensitive elements of the machine to be stored in more secure safes and to be quickly thrown overboard or otherwise destroyed if capture was threatened. It also allowed a machine to  quickly switch between networks that used different rotor orders. Messages had two 5- character indicators, an exterior indicator that specified the system being used and the security classification and an interior indicator that determined the initial settings of the code and alphabet rotors. The key list included separate index rotor settings for each security classification. This prevented lower classification messages from being used as cribs to attack higher classification messages.\nThe Navy and Army had different procedures for the interior indicator. Both started by zeroizing the machine and having the operator select a random 5-character string for each new message. This was then encrypted to produce the interior indicator. Army key lists included an initial setting for the rotors that was used to encrypt the random string. The Navy operators used the keyboard to increment the code rotors until they matched the random character string. The alphabet rotor would move during this process and their final position was the internal indicator. In case of joint operations, the Army procedures were followed.\nThe key lists included a \u201c26-30\u201d check string. After the rotors were reordered according to the current key, the operator would zeroize the machine, encrypt 25 characters and then encrypt \u201cAAAAA\u201d. The ciphertext resulting from the five A\u2019s had to match the check string. The manual warned that typographical errors were possible in key lists and that a four character match should be accepted.\nThe manual also gave suggestions on how to generate random strings for creating indicators.  These included using playing cards and poker chips, to selecting characters from cipher texts and using the SIGABA itself as a random character generator.\n\n== Security ==\n\nAlthough the SIGABA was extremely secure, the US continued to upgrade its capability throughout the war, for fear of the Axis cryptanalytic ability to break SIGABA's code. When the German's ENIGMA messages and Japan's Type B Cipher Machine were broken, the messages were closely scrutinized for signs that Axis forces were able to read the US cryptography codes. Axis prisoners of war (POWs) were also interrogated with the goal of finding evidence that US cryptography had been broken. However, both the Germans and Japanese were not making any progress in breaking the SIGABA code. A decrypted JN-A-20 message, dated 24 January 1942, sent from the naval attach\u00e9 in Berlin to vice chief of Japanese Naval General Staff in Tokyo stated that \"joint Jap[anese]-German cryptanalytical efforts\" to be \"highly satisfactory\", since the \"German[s] have exhibited commendable ingenuity and recently experienced some success on English Navy systems\", but are \"encountering difficulty in establishing successful techniques of attack on 'enemy' code setup\". In another decrypted JN-A-20 message, the Germans admitted that their progress in breaking US communications was unsatisfactory. The Japanese also admitted in their own communications that they had made no real progress against the American cipher system. In September 1944, when the Allies were advancing steadily on the Western front, the war diary of the German Signal Intelligence Group recorded: \"U.S. 5-letter traffic: Work discontinued as unprofitable at this time\".SIGABA systems were closely guarded at all times, with separate safes for the system base and the code-wheel assembly, but there was one incident where a unit was lost for a time. On February 3, 1945, a truck carrying a SIGABA system in three safes was stolen while its guards were visiting a brothel in recently-liberated Colmar, France. General Eisenhower ordered an extensive search, which finally discovered the safes six weeks later in a nearby river.:\u200app.510\u2013512\n\n== Interoperability with Allied counterparts ==\nThe need for cooperation among the US/British/Canadian forces in carrying out joint military operations against Axis forces gave rise to the need for a cipher  system that could be used by all Allied forces. This functionality was achieved in three different ways. Firstly, the ECM Adapter (CSP 1000), which could be retrofitted on Allied cipher machines, was produced at the Washington Naval Yard ECM Repair Shop. A total of 3,500 adapters were produced. The second method was to adapt the SIGABA for interoperation with a modified British machine, the Typex. The common machine was known as the Combined Cipher Machine (CCM), and was used from November 1943. Because of the high cost of production, only 631 CCMs were made. The third way was the most common and most cost-effective. It was the \"X\" Adapter manufactured by the Teletype Corporation in Chicago. A total of 4,500 of these adapters were installed at depot-level maintenance facilities."
    }
  },
  {
    "instruction": "Amazon Virtual Private Cloud\n\n==Introduction==\nAmazon Virtual Private Cloud (VPC) is a commercial cloud computing service that provides a virtual private cloud, by \u201cprovisioning a logically isolated section of Amazon Web Services (AWS) Cloud\u201d. Enterprise customers are able to access the Amazon Elastic Compute Cloud (EC2) over an IPsec based virtual private network. Unlike traditional EC2 instances which are allocated internal and external IP numbers by Amazon, the customer can assign IP numbers of their choosing from one or more subnets. By giving the user the option of selecting which AWS resources are public facing and which are not, VPC provides much more granular control over security. For Amazon it is \u201can endorsement of the hybrid approach, but it's also meant to combat the growing interest in private clouds\u201d.\n\n\n\n== Comparison to private clouds ==\nAmazon Virtual Private Cloud aims to provide a service similar to private clouds using technology such as OpenStack or HPE Helion Eucalyptus.  However, private clouds typically use technology such as OpenShift application hosting and various database systems.  Cloud security experts warn that there can be compliance risks, such as a loss of control or service cancellation in using public resources which do not exist with in-house systems.  If transaction records are requested from Amazon about a VPC using a national security letter they may not be legally allowed to inform the customer of the breach of the security of their system.  This would be true even if the actual VPC resources were in another country.  The API used by AWS is only partly compatible with that of HPE Helion Eucalyptus and is not compatible with other private cloud systems, so migration from AWS may be difficult.  This has led to warnings of the possibility of lock-in to a specific technology.\n\n== IP Addressing ==\nIP Addressing in Amazon Virtual Private Cloud (VPC) refers to the assignment of IP addresses to the resources within a VPC. VPC is Amazon Web Services' (AWS) solution for providing isolated network environments for AWS resources. IP addresses in a VPC are used for communication between resources within the VPC, as well as for communication between the VPC and the Internet.\nThere are two types of IP addresses used in a VPC: private IP addresses and public IP addresses. Private IP addresses are used for communication between instances within the VPC, while public IP addresses are used for communication between the VPC and the Internet.\nAmazon VPC provides several options for IP address management, including the use of IPv4 and IPv6 addresses, automatic assignment of private IP addresses, and the ability to assign static private IP addresses. Additionally, Amazon VPC provides the option to associate Elastic IP addresses with instances to ensure persistent public IP addresses.\nBy using Amazon VPC, customers can have full control over the network configuration of their AWS resources, providing increased security and isolation compared to the traditional shared-tenancy model of public cloud computing.\n\n== Connectivity ==\nAWS VPC allows users to connect to the Internet, a user's corporate data center, and other users' VPCs.Users are able to connect to the Internet by adding an Internet Gateway to their VPC, which assigns the VPC a public IPv4 Address.Users are able to connect to a data center by setting up a hardware virtual private network connection between the data center and the VPC. This connection allows the user to \u201cinteract with Amazon EC2 instances within a VPC as if they were within [the user's] existing network.\u201dUsers are also able to route traffic from one VPC to another VPC using private IP addresses, and are able to communicate as if they were on the same network. Peering can be achieved by connecting a route between two VPCs on the same account or two VPCs on different accounts in the same region. VPC peering is a one-to-one connection, but users are able to connect to more than one VPC at a time.To achieve a one-to-many connection between VPCs, you can deploy a transit gateway (TGW). In addition, you can connect your VPCs to your on premise systems by employing the transit gateway.\n\n== Security ==\nAWS VPC's security is two-fold: firstly, AWS VPC uses security groups as a firewall to control traffic at the instance level, while it also uses network access control lists as a firewall to control traffic at the subnet level. As another measure of privacy, AWS VPC provides users with ability to create \u201cdedicated instances\u201d on hardware, physically isolating the dedicated instances from non-dedicated instances and instances owned by other accounts.AWS VPC is free, with users only paying for the consumption of EC2 resources. However, if  users choose to access VPC via a Virtual Private Network (VPN), there is a charge.\n\nQ: What are the compliance risks associated with using Amazon Virtual Private Cloud (VPC)?",
    "context": "",
    "output": "A: Cloud security experts warn that there can be compliance risks, such as a loss of control or service cancellation, in using public resources which do not exist with in-house systems. Additionally, if transaction records are requested from Amazon about a VPC using a national security letter, they may not be legally allowed to inform the customer of the breach of the security of their system.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are the compliance risks associated with using Amazon Virtual Private Cloud (VPC)?",
      "answer": "Cloud security experts warn that there can be compliance risks, such as a loss of control or service cancellation, in using public resources which do not exist with in-house systems. Additionally, if transaction records are requested from Amazon about a VPC using a national security letter, they may not be legally allowed to inform the customer of the breach of the security of their system.",
      "context": "Amazon Virtual Private Cloud\n\n==Introduction==\nAmazon Virtual Private Cloud (VPC) is a commercial cloud computing service that provides a virtual private cloud, by \u201cprovisioning a logically isolated section of Amazon Web Services (AWS) Cloud\u201d. Enterprise customers are able to access the Amazon Elastic Compute Cloud (EC2) over an IPsec based virtual private network. Unlike traditional EC2 instances which are allocated internal and external IP numbers by Amazon, the customer can assign IP numbers of their choosing from one or more subnets. By giving the user the option of selecting which AWS resources are public facing and which are not, VPC provides much more granular control over security. For Amazon it is \u201can endorsement of the hybrid approach, but it's also meant to combat the growing interest in private clouds\u201d.\n\n\n\n== Comparison to private clouds ==\nAmazon Virtual Private Cloud aims to provide a service similar to private clouds using technology such as OpenStack or HPE Helion Eucalyptus.  However, private clouds typically use technology such as OpenShift application hosting and various database systems.  Cloud security experts warn that there can be compliance risks, such as a loss of control or service cancellation in using public resources which do not exist with in-house systems.  If transaction records are requested from Amazon about a VPC using a national security letter they may not be legally allowed to inform the customer of the breach of the security of their system.  This would be true even if the actual VPC resources were in another country.  The API used by AWS is only partly compatible with that of HPE Helion Eucalyptus and is not compatible with other private cloud systems, so migration from AWS may be difficult.  This has led to warnings of the possibility of lock-in to a specific technology.\n\n== IP Addressing ==\nIP Addressing in Amazon Virtual Private Cloud (VPC) refers to the assignment of IP addresses to the resources within a VPC. VPC is Amazon Web Services' (AWS) solution for providing isolated network environments for AWS resources. IP addresses in a VPC are used for communication between resources within the VPC, as well as for communication between the VPC and the Internet.\nThere are two types of IP addresses used in a VPC: private IP addresses and public IP addresses. Private IP addresses are used for communication between instances within the VPC, while public IP addresses are used for communication between the VPC and the Internet.\nAmazon VPC provides several options for IP address management, including the use of IPv4 and IPv6 addresses, automatic assignment of private IP addresses, and the ability to assign static private IP addresses. Additionally, Amazon VPC provides the option to associate Elastic IP addresses with instances to ensure persistent public IP addresses.\nBy using Amazon VPC, customers can have full control over the network configuration of their AWS resources, providing increased security and isolation compared to the traditional shared-tenancy model of public cloud computing.\n\n== Connectivity ==\nAWS VPC allows users to connect to the Internet, a user's corporate data center, and other users' VPCs.Users are able to connect to the Internet by adding an Internet Gateway to their VPC, which assigns the VPC a public IPv4 Address.Users are able to connect to a data center by setting up a hardware virtual private network connection between the data center and the VPC. This connection allows the user to \u201cinteract with Amazon EC2 instances within a VPC as if they were within [the user's] existing network.\u201dUsers are also able to route traffic from one VPC to another VPC using private IP addresses, and are able to communicate as if they were on the same network. Peering can be achieved by connecting a route between two VPCs on the same account or two VPCs on different accounts in the same region. VPC peering is a one-to-one connection, but users are able to connect to more than one VPC at a time.To achieve a one-to-many connection between VPCs, you can deploy a transit gateway (TGW). In addition, you can connect your VPCs to your on premise systems by employing the transit gateway.\n\n== Security ==\nAWS VPC's security is two-fold: firstly, AWS VPC uses security groups as a firewall to control traffic at the instance level, while it also uses network access control lists as a firewall to control traffic at the subnet level. As another measure of privacy, AWS VPC provides users with ability to create \u201cdedicated instances\u201d on hardware, physically isolating the dedicated instances from non-dedicated instances and instances owned by other accounts.AWS VPC is free, with users only paying for the consumption of EC2 resources. However, if  users choose to access VPC via a Virtual Private Network (VPN), there is a charge."
    }
  },
  {
    "instruction": "Write an answer to the following question: What were the differences between the basic version and the mobile versions of the DUDEK encryption system?",
    "context": "",
    "output": "The basic version of the DUDEK encryption system was the TgS-1, while the mobile versions were the TgS-1M and TgS-1MS. The mobile versions were likely more compact and portable than the basic version, making them suitable for use in field operations or by mobile units.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What were the differences between the basic version and the mobile versions of the DUDEK encryption system?",
      "answer": "The basic version of the DUDEK encryption system was the TgS-1, while the mobile versions were the TgS-1M and TgS-1MS. The mobile versions were likely more compact and portable than the basic version, making them suitable for use in field operations or by mobile units."
    }
  },
  {
    "instruction": "Write an answer to the following question: What was the impact of the \"AS 7007 incident\" in April 1997?",
    "context": "",
    "output": "The \"AS 7007 incident\" in April 1997 was a significant BGP hijacking incident that had a major impact on the Internet. However, the specific details of the incident, such as the cause and the extent of the disruption, are not provided in the given text.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was the impact of the \"AS 7007 incident\" in April 1997?",
      "answer": "The \"AS 7007 incident\" in April 1997 was a significant BGP hijacking incident that had a major impact on the Internet. However, the specific details of the incident, such as the cause and the extent of the disruption, are not provided in the given text."
    }
  },
  {
    "instruction": "Write an answer to the following question: Does the Rublon mobile app require a password to access protected accounts in untrusted browsers?",
    "context": "",
    "output": "Yes, in untrusted browsers, the Rublon mobile app and a password are required to access protected accounts.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Does the Rublon mobile app require a password to access protected accounts in untrusted browsers?",
      "answer": "Yes, in untrusted browsers, the Rublon mobile app and a password are required to access protected accounts."
    }
  },
  {
    "instruction": "Deception technology\n\n==Introduction==\nDeception technology is a category of cyber security defense mechanisms that provide early warning of potential cyber security attacks and alert organizations of unauthorized activity. Deception technology products can detect, analyze, and defend against zero-day and advanced attacks, often in real time. They are automated, accurate, and provide insight into malicious activity within internal networks which may be unseen by other types of cyber defense. Deception technology enables a more proactive security posture by seeking to deceive an attacker, detect them and then defeat them.\nExisting defense-in-depth cyber technologies have struggled against the increasing wave of sophisticated and persistent human attackers. These technologies seek primarily to defend a perimeter, but both firewalls and endpoint security cannot defend a perimeter with 100% certainty. Cyber-attackers can penetrate these networks and move unimpeded for months, stealing data and intellectual property. Heuristics may find an attacker within the network, but often generate so many alerts that critical alerts are missed. Since 2014, attacks have accelerated and there is evidence that cyber-attackers are penetrating traditional defenses at a rapidly increasing rate.\nDeception technology considers the human attacker's point of view and method for exploiting and navigating networks to identify and exfiltrate data. It integrates with existing technologies to provide new visibility into the internal networks, share high probability alerts and threat intelligence with the existing infrastructure.\n\n== Technology: High Level View ==\nDeception technology automates the creation of traps (decoys) and lures, which are strategically integrated among existing IT resources. These decoys provide an additional layer of protection to thwart attackers who have breached the network. Traps can be IT assets that utilize genuine licensed operating system software or emulate various devices, such as medical devices, automated teller machines (ATMs), retail point of sale systems, switches, routers, and more. On the other hand, lures typically consist of real information technology resources, such as files of different types, that are placed on actual IT assets.\nUpon penetrating the network, attackers seek to establish a backdoor and then use this to identify and exfiltrate data and intellectual property. They begin moving laterally through the internal VLANs and almost immediately will \"look at\" one of the traps. Interacting with one of these \"decoys\" will trigger an alert.  These alerts are very high probability and almost always coincide to an ongoing attack.  The deception is designed to lure the attacker in \u2013 the attacker may consider this a worthy asset and continue by injecting malware.  Deception technology generally allows for automated static and dynamic analysis of this injected malware and provides these reports through automation to the security operations personnel.  Deception technology may also identify, through indicators of compromise (IOC), suspect end-points that are part of the compromise cycle.  Automation also allows for an automated memory analysis of the suspect end-point, and then automatically isolating the suspect end-point.  Many partner integrations allow for a variety of implementation paths for existing enterprise and government customers.\n\n== Specialized Applications ==\nInternet of things (IoT) devices are not usually scanned by legacy defense in depth and remain prime targets for attackers within the network. Deception technology can identify attackers moving laterally into the network within these devices.\nIntegrated turnkey devices that utilize embedded operating systems, but do not allow these operating systems to be scanned or closely protected by embedded end-point or intrusion detection software are also well protected by a deception technology deployment in the same network. Examples include process control systems (SCADA) used in many manufacturing applications on a global basis. Deception technology has been associated with the discovery of Zombie Zero, an attack vector. Deception technology identified this attacker utilizing malware embedded in barcode readers which were manufactured overseas.\nMedical devices are particular vulnerable to cyber-attacks within the healthcare networks.  As FDA-certified devices, they are in closed systems and not accessible to standard cyber defense software. Deception technology can surround and protect these devices and identify attackers using backdoor placement and data exfiltration. Recent documented cyber attacks on medical devices include x-ray machines, CT scanners, MRI scanners, blood gas analyzers, PACS systems and many more. Networks utilizing these devices can be protected by deception technology. This attack vector, called medical device hijack or medjack, is estimated to have penetrated many hospitals worldwide.Specialized deception technology products are now capable of addressing the rise in ransomware by deceiving ransomware into engaging in an attack on a decoy resource, while isolating the infection points and alerting the cyber defense software team.\n\n== Differentiation from Competitive/Cooperative Technologies ==\n\nTraditional cyber defense technologies, such as firewalls and end-point security, generate many alerts. In a large enterprise the alert volume may reach, in some cases, millions of alerts per day. Security operations personnel cannot process most of the activity easily, yet it only takes one successful penetration to compromise an entire network.\nDeception technology produces alerts that are the end product of a binary process. Probability is essentially reduced to two values:  0% and 100%.  Any party that seeks to identify, ping, enter, view any trap or utilizes a lure is immediately identified by this behavior. Anyone touching these traps or lures should not be doing so. This is an advantage over heuristics and probability-based approaches and the many thousands of extraneous alerts these techniques generate.\nBest practice shows that deception technology is not a stand-alone strategy. Deception technology is an additional compatible layer to the existing defense-in-depth cyber defense.  Partner integrations make it most useful and the goal is to add protection for the most advanced and sophisticated human attackers that will successfully penetrate the perimeter.\n\n== Market Size and Adoption ==\nThe technical innovation of deception technology been received by the market.  An industry analyst identified ten top technologies for information security in 2016, one of which were deception technology. \nAn industry analyst predicted in August 2016 that the deception technology market is currently (in 2016) approximately $50 to $100 million globally, and further predicted $100 million to $200 million in revenue by 2018.  This same analyst earlier noted that, \"by 2018 ... 10 percent of enterprises will use deception tools and tactics, and actively participate in deception operations against attackers\". Gartner also noted deception technology as a \"far underutilized technology that can provide serious advantages over attackers (cyber attackers)\".Two other important analysts have recently predicted a market size exceeding $1 billion by 2020. Adoption is being fueled, in part, by continued, highly visible targeted attacks on large enterprise and government institutions globally.\nMarket Research Media estimates the cumulative deception technology market value at $12 billion (2019\u20132024), growing at about 19% CAGR.\n\nHow can deception technology address the rise in ransomware attacks?",
    "context": "",
    "output": "A: Specialized deception technology products are now capable of deceiving ransomware into engaging in an attack on a decoy resource, while isolating the infection points and alerting the cyber defense software team.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can deception technology address the rise in ransomware attacks?",
      "answer": "Specialized deception technology products are now capable of deceiving ransomware into engaging in an attack on a decoy resource, while isolating the infection points and alerting the cyber defense software team.",
      "context": "Deception technology\n\n==Introduction==\nDeception technology is a category of cyber security defense mechanisms that provide early warning of potential cyber security attacks and alert organizations of unauthorized activity. Deception technology products can detect, analyze, and defend against zero-day and advanced attacks, often in real time. They are automated, accurate, and provide insight into malicious activity within internal networks which may be unseen by other types of cyber defense. Deception technology enables a more proactive security posture by seeking to deceive an attacker, detect them and then defeat them.\nExisting defense-in-depth cyber technologies have struggled against the increasing wave of sophisticated and persistent human attackers. These technologies seek primarily to defend a perimeter, but both firewalls and endpoint security cannot defend a perimeter with 100% certainty. Cyber-attackers can penetrate these networks and move unimpeded for months, stealing data and intellectual property. Heuristics may find an attacker within the network, but often generate so many alerts that critical alerts are missed. Since 2014, attacks have accelerated and there is evidence that cyber-attackers are penetrating traditional defenses at a rapidly increasing rate.\nDeception technology considers the human attacker's point of view and method for exploiting and navigating networks to identify and exfiltrate data. It integrates with existing technologies to provide new visibility into the internal networks, share high probability alerts and threat intelligence with the existing infrastructure.\n\n== Technology: High Level View ==\nDeception technology automates the creation of traps (decoys) and lures, which are strategically integrated among existing IT resources. These decoys provide an additional layer of protection to thwart attackers who have breached the network. Traps can be IT assets that utilize genuine licensed operating system software or emulate various devices, such as medical devices, automated teller machines (ATMs), retail point of sale systems, switches, routers, and more. On the other hand, lures typically consist of real information technology resources, such as files of different types, that are placed on actual IT assets.\nUpon penetrating the network, attackers seek to establish a backdoor and then use this to identify and exfiltrate data and intellectual property. They begin moving laterally through the internal VLANs and almost immediately will \"look at\" one of the traps. Interacting with one of these \"decoys\" will trigger an alert.  These alerts are very high probability and almost always coincide to an ongoing attack.  The deception is designed to lure the attacker in \u2013 the attacker may consider this a worthy asset and continue by injecting malware.  Deception technology generally allows for automated static and dynamic analysis of this injected malware and provides these reports through automation to the security operations personnel.  Deception technology may also identify, through indicators of compromise (IOC), suspect end-points that are part of the compromise cycle.  Automation also allows for an automated memory analysis of the suspect end-point, and then automatically isolating the suspect end-point.  Many partner integrations allow for a variety of implementation paths for existing enterprise and government customers.\n\n== Specialized Applications ==\nInternet of things (IoT) devices are not usually scanned by legacy defense in depth and remain prime targets for attackers within the network. Deception technology can identify attackers moving laterally into the network within these devices.\nIntegrated turnkey devices that utilize embedded operating systems, but do not allow these operating systems to be scanned or closely protected by embedded end-point or intrusion detection software are also well protected by a deception technology deployment in the same network. Examples include process control systems (SCADA) used in many manufacturing applications on a global basis. Deception technology has been associated with the discovery of Zombie Zero, an attack vector. Deception technology identified this attacker utilizing malware embedded in barcode readers which were manufactured overseas.\nMedical devices are particular vulnerable to cyber-attacks within the healthcare networks.  As FDA-certified devices, they are in closed systems and not accessible to standard cyber defense software. Deception technology can surround and protect these devices and identify attackers using backdoor placement and data exfiltration. Recent documented cyber attacks on medical devices include x-ray machines, CT scanners, MRI scanners, blood gas analyzers, PACS systems and many more. Networks utilizing these devices can be protected by deception technology. This attack vector, called medical device hijack or medjack, is estimated to have penetrated many hospitals worldwide.Specialized deception technology products are now capable of addressing the rise in ransomware by deceiving ransomware into engaging in an attack on a decoy resource, while isolating the infection points and alerting the cyber defense software team.\n\n== Differentiation from Competitive/Cooperative Technologies ==\n\nTraditional cyber defense technologies, such as firewalls and end-point security, generate many alerts. In a large enterprise the alert volume may reach, in some cases, millions of alerts per day. Security operations personnel cannot process most of the activity easily, yet it only takes one successful penetration to compromise an entire network.\nDeception technology produces alerts that are the end product of a binary process. Probability is essentially reduced to two values:  0% and 100%.  Any party that seeks to identify, ping, enter, view any trap or utilizes a lure is immediately identified by this behavior. Anyone touching these traps or lures should not be doing so. This is an advantage over heuristics and probability-based approaches and the many thousands of extraneous alerts these techniques generate.\nBest practice shows that deception technology is not a stand-alone strategy. Deception technology is an additional compatible layer to the existing defense-in-depth cyber defense.  Partner integrations make it most useful and the goal is to add protection for the most advanced and sophisticated human attackers that will successfully penetrate the perimeter.\n\n== Market Size and Adoption ==\nThe technical innovation of deception technology been received by the market.  An industry analyst identified ten top technologies for information security in 2016, one of which were deception technology. \nAn industry analyst predicted in August 2016 that the deception technology market is currently (in 2016) approximately $50 to $100 million globally, and further predicted $100 million to $200 million in revenue by 2018.  This same analyst earlier noted that, \"by 2018 ... 10 percent of enterprises will use deception tools and tactics, and actively participate in deception operations against attackers\". Gartner also noted deception technology as a \"far underutilized technology that can provide serious advantages over attackers (cyber attackers)\".Two other important analysts have recently predicted a market size exceeding $1 billion by 2020. Adoption is being fueled, in part, by continued, highly visible targeted attacks on large enterprise and government institutions globally.\nMarket Research Media estimates the cumulative deception technology market value at $12 billion (2019\u20132024), growing at about 19% CAGR."
    }
  },
  {
    "instruction": "YARA\n\n==Introduction==\nYARA is the name of a tool primarily used in malware research and detection.\nIt provides a rule-based approach to create descriptions of malware families based on regular expression, textual or binary patterns. A description is essentially a YARA rule name, where these rules consist of sets of strings and a boolean expression.\n\n== Design ==\nYARA by default comes with modules to process PE, ELF analysis, as well as support for the open-source Cuckoo sandbox.\nRead the text above and answer this question: How does YARA's PE analysis module contribute to malware detection in Windows environments?",
    "context": "",
    "output": "YARA's PE analysis module contributes to malware detection in Windows environments by enabling YARA to analyze and detect malware in PE files. This module helps researchers to identify and describe malware families that target Windows operating systems, providing valuable insights into their functionality and purpose.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does YARA's PE analysis module contribute to malware detection in Windows environments?",
      "answer": "YARA's PE analysis module contributes to malware detection in Windows environments by enabling YARA to analyze and detect malware in PE files. This module helps researchers to identify and describe malware families that target Windows operating systems, providing valuable insights into their functionality and purpose.",
      "context": "YARA\n\n==Introduction==\nYARA is the name of a tool primarily used in malware research and detection.\nIt provides a rule-based approach to create descriptions of malware families based on regular expression, textual or binary patterns. A description is essentially a YARA rule name, where these rules consist of sets of strings and a boolean expression.\n\n== Design ==\nYARA by default comes with modules to process PE, ELF analysis, as well as support for the open-source Cuckoo sandbox."
    }
  },
  {
    "instruction": "Write an answer to the following question: What was the main reason for the shutdown of the original Full Disclosure mailing list?",
    "context": "",
    "output": "The main reason for the shutdown of the original Full Disclosure mailing list was the request for large-scale deletion of information and the threat of legal action from a security researcher.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was the main reason for the shutdown of the original Full Disclosure mailing list?",
      "answer": "The main reason for the shutdown of the original Full Disclosure mailing list was the request for large-scale deletion of information and the threat of legal action from a security researcher."
    }
  },
  {
    "instruction": "Context: Security engineering\n\n==Introduction==\nSecurity engineering is the process of incorporating security controls into an information system so that the controls become an integral part of the system\u2019s operational capabilities. It is similar to other systems engineering activities in that its primary motivation is to support the delivery of engineering solutions that satisfy pre-defined functional and user requirements, but it has the added dimension of preventing misuse and malicious behavior. Those constraints and restrictions are often asserted as a security policy.\nIn one form or another, security engineering has existed as an informal field of study for several centuries. For example, the fields of locksmithing and security printing have been around for many years. The concerns for modern security engineering and computer systems were first solidified in a RAND paper from 1967, \"Security and Privacy in Computer Systems\" by Willis H. Ware. This paper, later expanded in 1979,  provided many of the fundamental information security concepts, labelled today as Cybersecurity, that impact modern computer systems, from cloud implementations to embedded IoT.\nRecent catastrophic events, most notably 9/11, have made security engineering quickly become a rapidly-growing field. In fact, in a report completed in 2006, it was estimated that the global security industry was valued at US $150 billion.\nSecurity engineering involves aspects of social science, psychology (such as designing a system to \"fail well\", instead of trying to eliminate all sources of error), and economics as well as physics, chemistry, mathematics, criminology architecture, and landscaping.\nSome of the techniques used, such as fault tree analysis, are derived from safety engineering.\nOther techniques such as cryptography were previously restricted to military applications. One of the pioneers of establishing security engineering as a formal field of study is Ross Anderson.\n\n\n\n== Qualifications ==\nNo single qualification exists to become a security engineer.\nHowever, an undergraduate and/or graduate degree, often in computer science, computer engineering, or physical protection focused degrees such as Security Science, in combination with practical work experience (systems, network engineering, software development, physical protection system modelling etc.) most qualifies an individual to succeed in the field. Other degree qualifications with a security focus exist. Multiple certifications, such as the Certified Information Systems Security Professional, or Certified Physical Security Professional are available that may demonstrate expertise in the field. Regardless of the qualification, the course must include a knowledge base to diagnose the security system drivers, security theory and principles including defense in depth, protection in depth, situational crime prevention and crime prevention through environmental design to set the protection strategy (professional inference), and technical knowledge including physics and mathematics to design and commission the engineering treatment solution. A security engineer can also benefit from having knowledge in cyber security and information security. Any previous work experience related to privacy and computer science is also valued. \nAll of this knowledge must be braced by professional attributes including strong communication skills and high levels of literacy for engineering report writing. Security engineering also goes by the label Security Science.\n\n== Related-fields ==\nInformation securitySee esp. Computer security\nprotecting data from unauthorized access, use, disclosure, destruction, modification, or disruption to access.Physical securitydeter attackers from accessing a facility, resource, or information stored on physical media.Technical surveillance counter-measures\nEconomics of securitythe economic aspects of economics of privacy and computer security.\n\n== Methodologies ==\nTechnological advances, principally in the field of computers, have now allowed the creation of far more complex systems, with new and complex security problems. Because modern systems cut across many areas of human endeavor, security engineers not only need consider the mathematical and physical properties of systems; they also need to consider attacks on the people who use and form parts of those systems using social engineering attacks. Secure systems have to resist not only technical attacks, but also coercion, fraud, and deception by confidence tricksters.\n\n\n*** Web applications ***\nAccording to the Microsoft Developer Network the patterns and practices of security engineering consist of the following activities:\nSecurity Objectives\nSecurity Design Guidelines\nSecurity Modeling\nSecurity Architecture and Design Review\nSecurity Code Review\nSecurity Testing\nSecurity Tuning\nSecurity Deployment ReviewThese activities are designed to help meet security objectives in the software life cycle.\n\n\n*** Physical ***\n\nUnderstanding of a typical threat and the usual risks to people and property.\nUnderstanding the incentives created both by the threat and the countermeasures.\nUnderstanding risk and threat analysis methodology and the benefits of an empirical study of the physical security of a facility.\nUnderstanding how to apply the methodology to buildings, critical infrastructure, ports, public transport and other facilities/compounds.\nOverview of common physical and technological methods of protection and understanding their roles in deterrence, detection and mitigation.\nDetermining and prioritizing security needs and aligning them with the perceived threats and the available budget.\n\n\n*** Product ***\nProduct security engineering is security engineering applied specifically to the products that an organization creates, distributes, and/or sells. Product security engineering is distinct from corporate/enterprise security, which focuses on securing corporate networks and systems that an organization uses to conduct business.\nProduct security includes security engineering applied to:\n\nHardware devices such as cell phones, computers, Internet of things devices, and cameras.\nSoftware such as operating systems, applications, and firmware.Such security engineers are often employed in separate teams from corporate security teams and work closely with product engineering teams.\n\n\n**** Target hardening ****\nWhatever the target, there are multiple ways of preventing penetration by unwanted or unauthorized persons. Methods include placing Jersey barriers, stairs or other sturdy obstacles outside tall or politically sensitive buildings to prevent car and truck bombings. Improving the method of visitor management and some new electronic locks take advantage of technologies such as fingerprint scanning, iris or retinal scanning, and voiceprint identification to authenticate users.\nAnswer this question: Who is one of the pioneers of establishing security engineering as a formal field of study?",
    "context": "",
    "output": "Ross Anderson is one of the pioneers of establishing security engineering as a formal field of study.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Who is one of the pioneers of establishing security engineering as a formal field of study?",
      "answer": "Ross Anderson is one of the pioneers of establishing security engineering as a formal field of study.",
      "context": "Security engineering\n\n==Introduction==\nSecurity engineering is the process of incorporating security controls into an information system so that the controls become an integral part of the system\u2019s operational capabilities. It is similar to other systems engineering activities in that its primary motivation is to support the delivery of engineering solutions that satisfy pre-defined functional and user requirements, but it has the added dimension of preventing misuse and malicious behavior. Those constraints and restrictions are often asserted as a security policy.\nIn one form or another, security engineering has existed as an informal field of study for several centuries. For example, the fields of locksmithing and security printing have been around for many years. The concerns for modern security engineering and computer systems were first solidified in a RAND paper from 1967, \"Security and Privacy in Computer Systems\" by Willis H. Ware. This paper, later expanded in 1979,  provided many of the fundamental information security concepts, labelled today as Cybersecurity, that impact modern computer systems, from cloud implementations to embedded IoT.\nRecent catastrophic events, most notably 9/11, have made security engineering quickly become a rapidly-growing field. In fact, in a report completed in 2006, it was estimated that the global security industry was valued at US $150 billion.\nSecurity engineering involves aspects of social science, psychology (such as designing a system to \"fail well\", instead of trying to eliminate all sources of error), and economics as well as physics, chemistry, mathematics, criminology architecture, and landscaping.\nSome of the techniques used, such as fault tree analysis, are derived from safety engineering.\nOther techniques such as cryptography were previously restricted to military applications. One of the pioneers of establishing security engineering as a formal field of study is Ross Anderson.\n\n\n\n== Qualifications ==\nNo single qualification exists to become a security engineer.\nHowever, an undergraduate and/or graduate degree, often in computer science, computer engineering, or physical protection focused degrees such as Security Science, in combination with practical work experience (systems, network engineering, software development, physical protection system modelling etc.) most qualifies an individual to succeed in the field. Other degree qualifications with a security focus exist. Multiple certifications, such as the Certified Information Systems Security Professional, or Certified Physical Security Professional are available that may demonstrate expertise in the field. Regardless of the qualification, the course must include a knowledge base to diagnose the security system drivers, security theory and principles including defense in depth, protection in depth, situational crime prevention and crime prevention through environmental design to set the protection strategy (professional inference), and technical knowledge including physics and mathematics to design and commission the engineering treatment solution. A security engineer can also benefit from having knowledge in cyber security and information security. Any previous work experience related to privacy and computer science is also valued. \nAll of this knowledge must be braced by professional attributes including strong communication skills and high levels of literacy for engineering report writing. Security engineering also goes by the label Security Science.\n\n== Related-fields ==\nInformation securitySee esp. Computer security\nprotecting data from unauthorized access, use, disclosure, destruction, modification, or disruption to access.Physical securitydeter attackers from accessing a facility, resource, or information stored on physical media.Technical surveillance counter-measures\nEconomics of securitythe economic aspects of economics of privacy and computer security.\n\n== Methodologies ==\nTechnological advances, principally in the field of computers, have now allowed the creation of far more complex systems, with new and complex security problems. Because modern systems cut across many areas of human endeavor, security engineers not only need consider the mathematical and physical properties of systems; they also need to consider attacks on the people who use and form parts of those systems using social engineering attacks. Secure systems have to resist not only technical attacks, but also coercion, fraud, and deception by confidence tricksters.\n\n\n*** Web applications ***\nAccording to the Microsoft Developer Network the patterns and practices of security engineering consist of the following activities:\nSecurity Objectives\nSecurity Design Guidelines\nSecurity Modeling\nSecurity Architecture and Design Review\nSecurity Code Review\nSecurity Testing\nSecurity Tuning\nSecurity Deployment ReviewThese activities are designed to help meet security objectives in the software life cycle.\n\n\n*** Physical ***\n\nUnderstanding of a typical threat and the usual risks to people and property.\nUnderstanding the incentives created both by the threat and the countermeasures.\nUnderstanding risk and threat analysis methodology and the benefits of an empirical study of the physical security of a facility.\nUnderstanding how to apply the methodology to buildings, critical infrastructure, ports, public transport and other facilities/compounds.\nOverview of common physical and technological methods of protection and understanding their roles in deterrence, detection and mitigation.\nDetermining and prioritizing security needs and aligning them with the perceived threats and the available budget.\n\n\n*** Product ***\nProduct security engineering is security engineering applied specifically to the products that an organization creates, distributes, and/or sells. Product security engineering is distinct from corporate/enterprise security, which focuses on securing corporate networks and systems that an organization uses to conduct business.\nProduct security includes security engineering applied to:\n\nHardware devices such as cell phones, computers, Internet of things devices, and cameras.\nSoftware such as operating systems, applications, and firmware.Such security engineers are often employed in separate teams from corporate security teams and work closely with product engineering teams.\n\n\n**** Target hardening ****\nWhatever the target, there are multiple ways of preventing penetration by unwanted or unauthorized persons. Methods include placing Jersey barriers, stairs or other sturdy obstacles outside tall or politically sensitive buildings to prevent car and truck bombings. Improving the method of visitor management and some new electronic locks take advantage of technologies such as fingerprint scanning, iris or retinal scanning, and voiceprint identification to authenticate users."
    }
  },
  {
    "instruction": "Context: Bogofilter\n\n==Introduction==\nBogofilter is a mail filter that classifies e-mail as spam or ham (non-spam) by a statistical analysis of the message's header and content (body). The program is able to learn from the user's classifications and corrections. It was originally written by Eric S. Raymond after he read Paul Graham's article \"A Plan for Spam\" and is now maintained together with a group of contributors by David Relson, Matthias Andree and Greg Louis.\nThe statistical technique used is known as Bayesian filtering. Bogofilter's primary algorithm uses the f(w) parameter and the Fisher inverse chi-square technique that he describes.\nBogofilter may be run by a MDA or mail client to classify messages as they are delivered to recipient mailboxes, or be used by a MTA to classify messages as they are received from the sending SMTP server.  Bogofilter examines tokens in the message body and header, and refers to wordlists stored by BerkeleyDB, SQLite or QDBM to calculate a probability score that a new message is spam. Bogofilter provides processing for plain text and HTML and supports reading multi-part MIME message including base64, quoted-printable, and uuencoded text or HTML.  Bogofilter ignores non-text attachments, such as images.\nIt is possible to tune Bogofilter's statistical algorithms by modifying various coefficients and other settings in its configuration file, or by using the automated bogotune utility included with the software, which attempts to optimise various coefficients to maximise filtering efficiency for a particular corpus of spam and non-spam.\nStandard tests at TREC 2005 show that Bogofilter compares well to its competitors spambayes, CRM114 and DSPAM. Other competitors include, but are not limited to Spamprobe  and QSF. \nBogofilter is written in C, and runs on Linux, FreeBSD, NetBSD, OpenBSD, Solaris, Mac OS X, HP-UX, AIX and other platforms. It is released under the GNU GPL.\n\n\n\n== Email clients that can use Bogofilter ==\nThe following email clients are known to support Bogofilter as a spam filtering backend:\n\nGNOME Evolution\nClaws Mail\nKMail\nMutt (email client)\nAlpine (email client)\n\nQuestion: Where did the idea of Bogofilter come from?\n\nAnswer:",
    "context": "",
    "output": "The idea of Bogofilter came from Eric S. Raymond reading Paul Graham's article \"A Plan for Spam\".",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Where did the idea of Bogofilter come from?",
      "answer": "The idea of Bogofilter came from Eric S. Raymond reading Paul Graham's article \"A Plan for Spam\".",
      "context": "Bogofilter\n\n==Introduction==\nBogofilter is a mail filter that classifies e-mail as spam or ham (non-spam) by a statistical analysis of the message's header and content (body). The program is able to learn from the user's classifications and corrections. It was originally written by Eric S. Raymond after he read Paul Graham's article \"A Plan for Spam\" and is now maintained together with a group of contributors by David Relson, Matthias Andree and Greg Louis.\nThe statistical technique used is known as Bayesian filtering. Bogofilter's primary algorithm uses the f(w) parameter and the Fisher inverse chi-square technique that he describes.\nBogofilter may be run by a MDA or mail client to classify messages as they are delivered to recipient mailboxes, or be used by a MTA to classify messages as they are received from the sending SMTP server.  Bogofilter examines tokens in the message body and header, and refers to wordlists stored by BerkeleyDB, SQLite or QDBM to calculate a probability score that a new message is spam. Bogofilter provides processing for plain text and HTML and supports reading multi-part MIME message including base64, quoted-printable, and uuencoded text or HTML.  Bogofilter ignores non-text attachments, such as images.\nIt is possible to tune Bogofilter's statistical algorithms by modifying various coefficients and other settings in its configuration file, or by using the automated bogotune utility included with the software, which attempts to optimise various coefficients to maximise filtering efficiency for a particular corpus of spam and non-spam.\nStandard tests at TREC 2005 show that Bogofilter compares well to its competitors spambayes, CRM114 and DSPAM. Other competitors include, but are not limited to Spamprobe  and QSF. \nBogofilter is written in C, and runs on Linux, FreeBSD, NetBSD, OpenBSD, Solaris, Mac OS X, HP-UX, AIX and other platforms. It is released under the GNU GPL.\n\n\n\n== Email clients that can use Bogofilter ==\nThe following email clients are known to support Bogofilter as a spam filtering backend:\n\nGNOME Evolution\nClaws Mail\nKMail\nMutt (email client)\nAlpine (email client)"
    }
  },
  {
    "instruction": "AOHell\n\n==Introduction==\nAOHell was a Windows application that was used to simplify 'cracking' (computer hacking) using AOL. The program contained a very early use of the term phishing. It was created by a teenager under the pseudonym Da Chronic, whose expressed motivation was anger that child abuse took place on AOL without being curtailed by AOL administrators.\n\n== Features ==\nA fake account generator which would generate a new, fully functional AOL account for the user that lasted for about a month. This generator worked by exploiting the algorithm used by credit card companies known as the Luhn algorithm to dynamically generate apparently legitimate credit card numbers. The account would not be disabled until AOL first billed it (and discovered that the credit card was invalid).  The generator could also generate fake addresses and phone numbers, resembling on their surface legitimate personal information.  One example of a fake account generator was a Macintosh One-click based piece of software called Fake Maker written by a user known as McDawgg within the AOL Macwarez community.  This software ran in parallel with the AOL program to create fake accounts based upon generated legitimate credit card account numbers.  This software ultimately released 3 versions and helped to create thousands of fake accounts before AOL weakened its ability through more expedient account verification.\nPhishing tools. The program included a \"fisher\" tool in 1995 that enabled hackers to steal passwords and credit card information through automated social engineering.  The program would barrage random AOL users with instant messages like:Hi, this is AOL Customer Service.  We're running a security check and need to verify your account.  Please enter your username and password to continue.\nA punter (IM-bomber), which would send malicious Instant Message(s) to another user that would sign them off.\nA mail bomb script which would rapidly send e-mails to a user's inbox until it was full.\nA flooding script that would flood a chat room with ASCII art of an offensive nature, such as the finger or a toilet.\nAn 'artificial intelligence bot', which did not really contain artificial intelligence, but had the ability to automatically respond to a message in a chatroom upon identification of keywords. (For example, a 'profane language' autoresponse was built into the program.)\nAn IM manager, which provided facilities to automatically respond to or block IMs from certain users.\nA Steve Case cloak, which allowed users to pose as AOL founder Steve Case in chat rooms.\n\n== Motives and legacy ==\nThe existence of AOHell and similar software even allowed AOL to develop its own warez community. Lurking in secret chat rooms with names such as 'AirZeraw', mm, cerver, 'wArEzXXX', g00dz, 'punter', 'gif', 'coldice', 'GRiP', and 'trade', AOHell created bots, often referred to as 'servers', which would send out a list of warez (illegally copied software) contained in their mailbox.  Simply messaging the bot with the titles of the desired software packaging would result in those packages being forwarded to one's mailbox.  Since the data merely had to be copied into another user's mailbox (while still residing on an AOL server), the piracy was only limited by how fast messages could be forwarded, with AOL paying for all the cost of the bandwidth. One additional limitation included an allotted number of email messages which could be sent per day by a particular user account.  Botters were able to circumvent this limitation by signing up for a white-list account which was subjected to an unknown probationary period where AOL administrators monitored the account.\nThe existence of software like AOHell provided a parallel 'lite' version of the hacker underground that had existed for years before, based around bulletin board systems.  Programs like AOHell played an important part in defining the 'script kiddie', a user who performs basic cracking using simple tools written by others, with little understanding of what they are doing. These types of programs had a tendency to have AOL accounts banned; and so most users were logged on to accounts they had acquired illicitly, either by phishing or a fake account generator.\nIn the manual, the creator of AOHell claims that he created the program because the AOL administrators would frequently shut down hacker and warez chatrooms for violation of AOL's terms of service while refusing to shut down the pedophilia chat rooms which regularly traded child pornography. \"Da Chronic\" claimed that when he confronted AOL's TOSAdvisor about it, he was met with an account deletion:\n\nAOL constantly closed the \"Hackers\" Member room, but refuses to do anything about all the pedophilia rooms. I once IMed TOSAdvisor and asked him why he closes the Hacker room, but does not close the kiddie porn rooms. He did not reply, instead he cancelled my account. I guess we see where AOL's priorities lie.\nHe also stated that his goal was:\n\n[To have] 20,000+ idiots using AOHell to knock people offline, steal passwords and credit card information, and to basically annoy the hell out of everyone.\nThe program was last compatible with AOL version 2.5.\nQuestion: What was the functionality of the fake account generator in AOHell?",
    "context": "",
    "output": "Answer: The fake account generator in AOHell was a tool that generated fully functional AOL accounts with legitimate-looking credit card numbers, addresses, and phone numbers. These accounts lasted for about a month until AOL discovered that the credit card was invalid during billing.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was the functionality of the fake account generator in AOHell?",
      "answer": "The fake account generator in AOHell was a tool that generated fully functional AOL accounts with legitimate-looking credit card numbers, addresses, and phone numbers. These accounts lasted for about a month until AOL discovered that the credit card was invalid during billing.",
      "context": "AOHell\n\n==Introduction==\nAOHell was a Windows application that was used to simplify 'cracking' (computer hacking) using AOL. The program contained a very early use of the term phishing. It was created by a teenager under the pseudonym Da Chronic, whose expressed motivation was anger that child abuse took place on AOL without being curtailed by AOL administrators.\n\n== Features ==\nA fake account generator which would generate a new, fully functional AOL account for the user that lasted for about a month. This generator worked by exploiting the algorithm used by credit card companies known as the Luhn algorithm to dynamically generate apparently legitimate credit card numbers. The account would not be disabled until AOL first billed it (and discovered that the credit card was invalid).  The generator could also generate fake addresses and phone numbers, resembling on their surface legitimate personal information.  One example of a fake account generator was a Macintosh One-click based piece of software called Fake Maker written by a user known as McDawgg within the AOL Macwarez community.  This software ran in parallel with the AOL program to create fake accounts based upon generated legitimate credit card account numbers.  This software ultimately released 3 versions and helped to create thousands of fake accounts before AOL weakened its ability through more expedient account verification.\nPhishing tools. The program included a \"fisher\" tool in 1995 that enabled hackers to steal passwords and credit card information through automated social engineering.  The program would barrage random AOL users with instant messages like:Hi, this is AOL Customer Service.  We're running a security check and need to verify your account.  Please enter your username and password to continue.\nA punter (IM-bomber), which would send malicious Instant Message(s) to another user that would sign them off.\nA mail bomb script which would rapidly send e-mails to a user's inbox until it was full.\nA flooding script that would flood a chat room with ASCII art of an offensive nature, such as the finger or a toilet.\nAn 'artificial intelligence bot', which did not really contain artificial intelligence, but had the ability to automatically respond to a message in a chatroom upon identification of keywords. (For example, a 'profane language' autoresponse was built into the program.)\nAn IM manager, which provided facilities to automatically respond to or block IMs from certain users.\nA Steve Case cloak, which allowed users to pose as AOL founder Steve Case in chat rooms.\n\n== Motives and legacy ==\nThe existence of AOHell and similar software even allowed AOL to develop its own warez community. Lurking in secret chat rooms with names such as 'AirZeraw', mm, cerver, 'wArEzXXX', g00dz, 'punter', 'gif', 'coldice', 'GRiP', and 'trade', AOHell created bots, often referred to as 'servers', which would send out a list of warez (illegally copied software) contained in their mailbox.  Simply messaging the bot with the titles of the desired software packaging would result in those packages being forwarded to one's mailbox.  Since the data merely had to be copied into another user's mailbox (while still residing on an AOL server), the piracy was only limited by how fast messages could be forwarded, with AOL paying for all the cost of the bandwidth. One additional limitation included an allotted number of email messages which could be sent per day by a particular user account.  Botters were able to circumvent this limitation by signing up for a white-list account which was subjected to an unknown probationary period where AOL administrators monitored the account.\nThe existence of software like AOHell provided a parallel 'lite' version of the hacker underground that had existed for years before, based around bulletin board systems.  Programs like AOHell played an important part in defining the 'script kiddie', a user who performs basic cracking using simple tools written by others, with little understanding of what they are doing. These types of programs had a tendency to have AOL accounts banned; and so most users were logged on to accounts they had acquired illicitly, either by phishing or a fake account generator.\nIn the manual, the creator of AOHell claims that he created the program because the AOL administrators would frequently shut down hacker and warez chatrooms for violation of AOL's terms of service while refusing to shut down the pedophilia chat rooms which regularly traded child pornography. \"Da Chronic\" claimed that when he confronted AOL's TOSAdvisor about it, he was met with an account deletion:\n\nAOL constantly closed the \"Hackers\" Member room, but refuses to do anything about all the pedophilia rooms. I once IMed TOSAdvisor and asked him why he closes the Hacker room, but does not close the kiddie porn rooms. He did not reply, instead he cancelled my account. I guess we see where AOL's priorities lie.\nHe also stated that his goal was:\n\n[To have] 20,000+ idiots using AOHell to knock people offline, steal passwords and credit card information, and to basically annoy the hell out of everyone.\nThe program was last compatible with AOL version 2.5."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are the three levels commonly recognized for eliminating remnant data?",
    "context": "",
    "output": "The three levels for eliminating remnant data are clearing, purging/sanitizing, and destruction. Clearing removes sensitive data in such a way that it may not be reconstructed using normal system functions. Purging is the physical rewrite of sensitive data to ensure it cannot be recovered. Destruction involves making the storage media unusable for conventional equipment, with varying effectiveness depending on the medium and method used.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are the three levels commonly recognized for eliminating remnant data?",
      "answer": "The three levels for eliminating remnant data are clearing, purging/sanitizing, and destruction. Clearing removes sensitive data in such a way that it may not be reconstructed using normal system functions. Purging is the physical rewrite of sensitive data to ensure it cannot be recovered. Destruction involves making the storage media unusable for conventional equipment, with varying effectiveness depending on the medium and method used."
    }
  },
  {
    "instruction": "Write an answer to the following question: How do PIN pads ensure that the encryption keys and the PIN are erased if someone tries to tamper with the device?",
    "context": "",
    "output": "PIN pads are equipped with security features, such as hardware and software measures, to ensure that the encryption keys and the PIN are erased if someone tries to tamper with the device. This helps to protect the cardholder's PIN and sensitive data from unauthorized access.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do PIN pads ensure that the encryption keys and the PIN are erased if someone tries to tamper with the device?",
      "answer": "PIN pads are equipped with security features, such as hardware and software measures, to ensure that the encryption keys and the PIN are erased if someone tries to tamper with the device. This helps to protect the cardholder's PIN and sensitive data from unauthorized access."
    }
  },
  {
    "instruction": "Write an answer to the following question: Which branches operate under the Data Network Technologies (DNT) division of TAO?",
    "context": "",
    "output": "The Access Division (ACD), Cyber Networks Technology Division (CNT), Computer Technology Division (CTD), Network Technology Division (NTD) all operate under the Data Network Technologies (DNT) division.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Which branches operate under the Data Network Technologies (DNT) division of TAO?",
      "answer": "The Access Division (ACD), Cyber Networks Technology Division (CNT), Computer Technology Division (CTD), Network Technology Division (NTD) all operate under the Data Network Technologies (DNT) division."
    }
  },
  {
    "instruction": "Write an answer to the following question: How do hardware security bugs affect the security of computer central processing units (CPUs) and other devices with programmable processors or logic and direct memory access?",
    "context": "",
    "output": "Hardware security bugs create vulnerabilities in CPUs and other devices with programmable processors or logic and direct memory access, allowing unauthorized data to be read by a rogue process. This can lead to security breaches and other malicious activities.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do hardware security bugs affect the security of computer central processing units (CPUs) and other devices with programmable processors or logic and direct memory access?",
      "answer": "Hardware security bugs create vulnerabilities in CPUs and other devices with programmable processors or logic and direct memory access, allowing unauthorized data to be read by a rogue process. This can lead to security breaches and other malicious activities."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the relationship between the Trailblazer and Turbulence projects?",
    "context": "",
    "output": "The Trailblazer project was the predecessor of the Turbulence project. The Trailblazer project was cancelled in 2006 after a congressional investigation and a Defense Department's Inspector General's report found it over budget, wasteful, and ineffective.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the relationship between the Trailblazer and Turbulence projects?",
      "answer": "The Trailblazer project was the predecessor of the Turbulence project. The Trailblazer project was cancelled in 2006 after a congressional investigation and a Defense Department's Inspector General's report found it over budget, wasteful, and ineffective."
    }
  },
  {
    "instruction": "Write an answer to the following question: How did the FBI respond to Global kOS's activities?",
    "context": "",
    "output": "The FBI had a San Antonio based informant within the group and individually raided several members after contact with the informant.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How did the FBI respond to Global kOS's activities?",
      "answer": "The FBI had a San Antonio based informant within the group and individually raided several members after contact with the informant."
    }
  },
  {
    "instruction": "SMASH (hash)\n\n==Introduction==\nSMASH is a cryptographic hash function which was created by Lars R. Knudsen.  SMASH comes in two versions: 256-bit and 512-bit. Each version was supposed to rival SHA-256 and SHA-512, respectively, however, shortly after the SMASH presentation at FSE 2005, an attack vector against SMASH was discovered which left the hash broken.\n\n== Specifications ==\nThe message length was limited to less than 2128 for SMASH-256 and 2256 for SMASH-512.\n\n== Definition ==\nInput: 256/512-bit message blocks \n  \n    \n      \n        \n          m\n          \n            1\n          \n        \n        ,\n        \n          m\n          \n            2\n          \n        \n        ,\n        .\n        .\n        .\n        ,\n        \n          m\n          \n            t\n          \n        \n      \n    \n    {\\displaystyle m_{1},m_{2},...,m_{t}}\n   and \n  \n    \n      \n        \u03b8\n        \u2208\n        G\n        F\n        (\n        \n          2\n          \n            n\n          \n        \n        )\n      \n    \n    {\\displaystyle \\theta \\in GF(2^{n})}\n  \n\n  \n    \n      \n        \n          h\n          \n            0\n\n== Details ==\nThe S-boxes in SMASH are derived versions from the Serpent ones.\nRead the text above and answer this question: What were the two versions of SMASH created to rival?",
    "context": "",
    "output": "SMASH-256 was created to rival SHA-256, while SMASH-512 was created to rival SHA-512.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What were the two versions of SMASH created to rival?",
      "answer": "SMASH-256 was created to rival SHA-256, while SMASH-512 was created to rival SHA-512.",
      "context": "SMASH (hash)\n\n==Introduction==\nSMASH is a cryptographic hash function which was created by Lars R. Knudsen.  SMASH comes in two versions: 256-bit and 512-bit. Each version was supposed to rival SHA-256 and SHA-512, respectively, however, shortly after the SMASH presentation at FSE 2005, an attack vector against SMASH was discovered which left the hash broken.\n\n== Specifications ==\nThe message length was limited to less than 2128 for SMASH-256 and 2256 for SMASH-512.\n\n== Definition ==\nInput: 256/512-bit message blocks \n  \n    \n      \n        \n          m\n          \n            1\n          \n        \n        ,\n        \n          m\n          \n            2\n          \n        \n        ,\n        .\n        .\n        .\n        ,\n        \n          m\n          \n            t\n          \n        \n      \n    \n    {\\displaystyle m_{1},m_{2},...,m_{t}}\n   and \n  \n    \n      \n        \u03b8\n        \u2208\n        G\n        F\n        (\n        \n          2\n          \n            n\n          \n        \n        )\n      \n    \n    {\\displaystyle \\theta \\in GF(2^{n})}\n  \n\n  \n    \n      \n        \n          h\n          \n            0\n\n== Details ==\nThe S-boxes in SMASH are derived versions from the Serpent ones."
    }
  },
  {
    "instruction": "Write an answer to the following question: How do first generation tokenization systems store and manage sensitive data?",
    "context": "",
    "output": "First generation tokenization systems use a database to map from live data to surrogate substitute tokens and back, requiring the storage, management, and continuous backup for every new transaction added to the token database to avoid data loss. This approach adds complexity to real-time transaction processing, limits scale, and introduces privacy and legal risk in the aggregation of data.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do first generation tokenization systems store and manage sensitive data?",
      "answer": "First generation tokenization systems use a database to map from live data to surrogate substitute tokens and back, requiring the storage, management, and continuous backup for every new transaction added to the token database to avoid data loss. This approach adds complexity to real-time transaction processing, limits scale, and introduces privacy and legal risk in the aggregation of data."
    }
  },
  {
    "instruction": "Write an answer to the following question: How is digital media seized prior to the examination in criminal cases?",
    "context": "",
    "output": "In criminal cases, digital media is seized prior to the examination by law enforcement personnel trained as technicians to ensure the preservation of evidence. These personnel are trained to follow laws related to search warrants and to handle the seized material appropriately.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How is digital media seized prior to the examination in criminal cases?",
      "answer": "In criminal cases, digital media is seized prior to the examination by law enforcement personnel trained as technicians to ensure the preservation of evidence. These personnel are trained to follow laws related to search warrants and to handle the seized material appropriately."
    }
  },
  {
    "instruction": "Write an answer to the following question: How are the message formats defined in WS-Trust used for requesting security tokens and responding to those requests?",
    "context": "",
    "output": "WS-Trust defines the formats of the messages used to request security tokens and the responses to those messages. These message formats enable applications to engage in secure communication within the Web services framework by providing a standardized way to request and receive security tokens.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How are the message formats defined in WS-Trust used for requesting security tokens and responding to those requests?",
      "answer": "WS-Trust defines the formats of the messages used to request security tokens and the responses to those messages. These message formats enable applications to engage in secure communication within the Web services framework by providing a standardized way to request and receive security tokens."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the \"hacker ethic\" in the context of programming?",
    "context": "",
    "output": "The \"hacker ethic\" in the context of programming is a set of principles based on the idea that writing software and sharing the result on a voluntary basis is a good idea, and that information should be free.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the \"hacker ethic\" in the context of programming?",
      "answer": "The \"hacker ethic\" in the context of programming is a set of principles based on the idea that writing software and sharing the result on a voluntary basis is a good idea, and that information should be free."
    }
  },
  {
    "instruction": "Context: PfSense\n\n==Introduction==\npfSense is a firewall/router computer software distribution based on FreeBSD. The open source pfSense Community Edition (CE) and pfSense Plus is installed on a physical computer or a virtual machine to make a dedicated firewall/router for a network. It can be configured and upgraded through a web-based interface, and requires no knowledge of the underlying FreeBSD system to manage.\n\n== Overview ==\nThe pfSense project began in 2004 as a fork of the m0n0wall project by Chris Buechler and Scott Ullrich. Its first release was in October 2006. The name derives from the fact that the software uses the packet-filtering tool, PF.Notable functions of pfSense include traffic shaping, VPNs using IPsec or PPTP, captive portal, stateful firewall, network address translation, 802.1q support for VLANs, and dynamic DNS. pfSense can be installed on hardware with an x86-64 processor architecture. It can also be installed on embedded hardware using Compact Flash or SD cards, or as a virtual machine.\n\n\n*** WireGuard protocol support ***\nIn February 2021, pfSense CE 2.5.0 and pfSense Plus 21.02 added support for a kernel WireGuard implementation. Support for WireGuard was temporarily removed in March 2021 after implementation issues were discovered by WireGuard founder Jason Donenfeld. The July 2021 release of pfSense CE 2.5.2 version re-included WireGuard.\n\nQuestion: When was support for WireGuard added to pfSense CE and pfSense Plus, and when was it temporarily removed?\n\nAnswer:",
    "context": "",
    "output": "Support for WireGuard was added to pfSense CE 2.5.0 and pfSense Plus 21.02 in February 2021, but was temporarily removed in March 2021 after implementation issues were discovered by WireGuard founder Jason Donenfeld.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "When was support for WireGuard added to pfSense CE and pfSense Plus, and when was it temporarily removed?",
      "answer": "Support for WireGuard was added to pfSense CE 2.5.0 and pfSense Plus 21.02 in February 2021, but was temporarily removed in March 2021 after implementation issues were discovered by WireGuard founder Jason Donenfeld.",
      "context": "PfSense\n\n==Introduction==\npfSense is a firewall/router computer software distribution based on FreeBSD. The open source pfSense Community Edition (CE) and pfSense Plus is installed on a physical computer or a virtual machine to make a dedicated firewall/router for a network. It can be configured and upgraded through a web-based interface, and requires no knowledge of the underlying FreeBSD system to manage.\n\n== Overview ==\nThe pfSense project began in 2004 as a fork of the m0n0wall project by Chris Buechler and Scott Ullrich. Its first release was in October 2006. The name derives from the fact that the software uses the packet-filtering tool, PF.Notable functions of pfSense include traffic shaping, VPNs using IPsec or PPTP, captive portal, stateful firewall, network address translation, 802.1q support for VLANs, and dynamic DNS. pfSense can be installed on hardware with an x86-64 processor architecture. It can also be installed on embedded hardware using Compact Flash or SD cards, or as a virtual machine.\n\n\n*** WireGuard protocol support ***\nIn February 2021, pfSense CE 2.5.0 and pfSense Plus 21.02 added support for a kernel WireGuard implementation. Support for WireGuard was temporarily removed in March 2021 after implementation issues were discovered by WireGuard founder Jason Donenfeld. The July 2021 release of pfSense CE 2.5.2 version re-included WireGuard."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are some of the use cases for Scapy, and how does it handle tasks related to network security?",
    "context": "",
    "output": "Scapy is a versatile tool for computer networks, capable of forging or decoding packets, sending them on the wire, capturing, and matching requests and replies. It can also handle tasks like scanning, tracerouting, probing, unit tests, attacks, and network discovery, making it a valuable asset in network security and administration.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are some of the use cases for Scapy, and how does it handle tasks related to network security?",
      "answer": "Scapy is a versatile tool for computer networks, capable of forging or decoding packets, sending them on the wire, capturing, and matching requests and replies. It can also handle tasks like scanning, tracerouting, probing, unit tests, attacks, and network discovery, making it a valuable asset in network security and administration."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does PGP ensure the secure delivery of files and messages and provide verification of the sender's identity?",
    "context": "",
    "output": "PGP achieves secure file and message delivery through encryption, while digital signing is used for verifying the sender's identity. Digital signing is a process where the sender uses their private key to create a digital signature, and the recipient can verify it using the sender's public key. This confirms the sender's identity and ensures the message or file hasn't been tampered with during transmission.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does PGP ensure the secure delivery of files and messages and provide verification of the sender's identity?",
      "answer": "PGP achieves secure file and message delivery through encryption, while digital signing is used for verifying the sender's identity. Digital signing is a process where the sender uses their private key to create a digital signature, and the recipient can verify it using the sender's public key. This confirms the sender's identity and ensures the message or file hasn't been tampered with during transmission."
    }
  },
  {
    "instruction": "Answer based on context:\n\nMunster Technological University ransomware attack\n\n==Introduction==\nIn early February 2023, Munster Technological University suffered a ransomware cyberattack which caused the cancellation of all full and part-time classes affecting the Bishopstown campus, as well as Crawford College of Art and Design, Cork School of Music and National Maritime College of Ireland in Ringaskiddy.\n\n\n\n== Background ==\nOn 7 February 2023, Munster Technological University announced that it was investigating a significant breach of the information technology and telephone systems that had occurred over the weekend. Systems such as email, HR, payroll and finance were not affected. In a later announcement the same day, they said that their Cork campuses would remain closed to protect staff and student data, but that the Kerry campuses were not affected.On 9 February the university confirmed that it was a ransomware attack. The National Cyber Security Centre confirmed that some of their staff were working onsite at the university to assist with forensic examination of systems and recovery. HEAnet were also providing advice and support.\n\n== Impact ==\nThe ransomware attack caused all of MTU's campuses in Cork to close.On 11 February, the university told the High Court that they were being blackmailed by Blackcat, a Russian cybercrime group. The university had received a ransom note threatening to sell and or publish data if the ransom was not paid by a certain deadline. The amount was described as \"significant money\" but not disclosed in open court.On 12 February, it was confirmed that data from its systems had been made available on the \"dark web\".\n\n== Response ==\nThe university is working with the Garda\u00ed, the National Cyber Security Centre and the Data Protection Commissioner.The Minister of State for Public Procurement and eGovernment \u2013 Ossian Smyth \u2013 said that the attack was similar in many ways to the 2021 cyberattack on the HSE in that it included threats to delete data and to publish data that had been copied.\n\nWho is responsible for the attack, as stated by the university, and what was their demand?",
    "context": "",
    "output": "The university was blackmailed by Blackcat, a Russian cybercrime group, which demanded a significant amount of money as ransom. If the ransom was not paid by a certain deadline, the group threatened to sell and/or publish stolen data.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Who is responsible for the attack, as stated by the university, and what was their demand?",
      "answer": "The university was blackmailed by Blackcat, a Russian cybercrime group, which demanded a significant amount of money as ransom. If the ransom was not paid by a certain deadline, the group threatened to sell and/or publish stolen data.",
      "context": "Munster Technological University ransomware attack\n\n==Introduction==\nIn early February 2023, Munster Technological University suffered a ransomware cyberattack which caused the cancellation of all full and part-time classes affecting the Bishopstown campus, as well as Crawford College of Art and Design, Cork School of Music and National Maritime College of Ireland in Ringaskiddy.\n\n\n\n== Background ==\nOn 7 February 2023, Munster Technological University announced that it was investigating a significant breach of the information technology and telephone systems that had occurred over the weekend. Systems such as email, HR, payroll and finance were not affected. In a later announcement the same day, they said that their Cork campuses would remain closed to protect staff and student data, but that the Kerry campuses were not affected.On 9 February the university confirmed that it was a ransomware attack. The National Cyber Security Centre confirmed that some of their staff were working onsite at the university to assist with forensic examination of systems and recovery. HEAnet were also providing advice and support.\n\n== Impact ==\nThe ransomware attack caused all of MTU's campuses in Cork to close.On 11 February, the university told the High Court that they were being blackmailed by Blackcat, a Russian cybercrime group. The university had received a ransom note threatening to sell and or publish data if the ransom was not paid by a certain deadline. The amount was described as \"significant money\" but not disclosed in open court.On 12 February, it was confirmed that data from its systems had been made available on the \"dark web\".\n\n== Response ==\nThe university is working with the Garda\u00ed, the National Cyber Security Centre and the Data Protection Commissioner.The Minister of State for Public Procurement and eGovernment \u2013 Ossian Smyth \u2013 said that the attack was similar in many ways to the 2021 cyberattack on the HSE in that it included threats to delete data and to publish data that had been copied."
    }
  },
  {
    "instruction": "HAS-V\n\n==Introduction==\nHAS-V is a cryptographic hash function with a variable output length. HAS-V is a hash function based on a block cipher. The hash function can produce hash values with lengths from 16 to 40 bytes.\n\n== Specifications ==\nDigest Size: 128-320 bits\nMax message length: <264 bits\nCompression Function: 1024-bit message block, 320-bit chaining variable\nThe hash function was developed by Nan Kyoung Park, Joon Ho Hwang and Pil Joong Lee, and was released in 2000.\nRead the text above and answer this question: How does the use of a variable digest size in HAS-V make it more versatile than fixed-length hash functions?",
    "context": "",
    "output": "The use of a variable digest size in HAS-V allows it to be tailored to the specific security needs of different systems, making it more versatile than fixed-length hash functions. This variable digest size enables HAS-V to be used in a wider range of security applications and provide a higher level of security for sensitive applications.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the use of a variable digest size in HAS-V make it more versatile than fixed-length hash functions?",
      "answer": "The use of a variable digest size in HAS-V allows it to be tailored to the specific security needs of different systems, making it more versatile than fixed-length hash functions. This variable digest size enables HAS-V to be used in a wider range of security applications and provide a higher level of security for sensitive applications.",
      "context": "HAS-V\n\n==Introduction==\nHAS-V is a cryptographic hash function with a variable output length. HAS-V is a hash function based on a block cipher. The hash function can produce hash values with lengths from 16 to 40 bytes.\n\n== Specifications ==\nDigest Size: 128-320 bits\nMax message length: <264 bits\nCompression Function: 1024-bit message block, 320-bit chaining variable\nThe hash function was developed by Nan Kyoung Park, Joon Ho Hwang and Pil Joong Lee, and was released in 2000."
    }
  },
  {
    "instruction": "The Secret History of Hacking\n\n==Introduction==\nThe Secret History of Hacking is a 2001 documentary film that focuses on phreaking, computer hacking and social engineering occurring from the 1970s through to the 1990s. Archive footage concerning the subject matter and (computer generated) graphical imagery specifically created for the film are voiced over with narrative audio commentary, intermixed with commentary from people who in one way or another have been closely involved in these matters.\n\n== Film summary ==\nThe film starts by reviewing the concept and the early days of phreaking, featuring anecdotes of phreaking experiences (often involving the use of a blue box) recounted by John Draper and Denny Teresi. By way of commentary from Steve Wozniak, the film progresses from phreaking to computer hobbyist hacking (including anecdotal experiences of the Homebrew Computer Club) on to computer security hacking, noting differences between these 2 forms of hacking in the process. The featured computer security hacking and social engineering stories and anecdotes predominantly concern experiences involving Kevin Mitnick. The film also deals with how society's (and notably law enforcement's) fear of hacking has increased over time due to media attention of hacking (by way of the film WarGames as well as journalistic reporting on actual hackers) combined with society's further increase in adoption of and subsequent reliance on computing and communication networks.\n\n== Cast ==\nJohn Draper, Steve Wozniak and Kevin Mitnick are prominently featured while the film additionally features comments from or else archive footage concerning Denny Teresi, Joybubbles, Mike Gorman, Ron Rosenbaum, Steven Levy, Paul Loser, Lee Felsenstein, Jim Warren, John Markoff, Jay Foster, FBI Special Agent Ken McGuire, Jonathan Littman, Michael Strickland and others.\nQ: How does the film depict the role of fear in shaping societal responses to hacking?",
    "context": "",
    "output": "The film suggests that fear has played a significant role in shaping societal responses to hacking, driving law enforcement's response and shaping societal perceptions of hacking.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the film depict the role of fear in shaping societal responses to hacking?",
      "answer": "The film suggests that fear has played a significant role in shaping societal responses to hacking, driving law enforcement's response and shaping societal perceptions of hacking.",
      "context": "The Secret History of Hacking\n\n==Introduction==\nThe Secret History of Hacking is a 2001 documentary film that focuses on phreaking, computer hacking and social engineering occurring from the 1970s through to the 1990s. Archive footage concerning the subject matter and (computer generated) graphical imagery specifically created for the film are voiced over with narrative audio commentary, intermixed with commentary from people who in one way or another have been closely involved in these matters.\n\n== Film summary ==\nThe film starts by reviewing the concept and the early days of phreaking, featuring anecdotes of phreaking experiences (often involving the use of a blue box) recounted by John Draper and Denny Teresi. By way of commentary from Steve Wozniak, the film progresses from phreaking to computer hobbyist hacking (including anecdotal experiences of the Homebrew Computer Club) on to computer security hacking, noting differences between these 2 forms of hacking in the process. The featured computer security hacking and social engineering stories and anecdotes predominantly concern experiences involving Kevin Mitnick. The film also deals with how society's (and notably law enforcement's) fear of hacking has increased over time due to media attention of hacking (by way of the film WarGames as well as journalistic reporting on actual hackers) combined with society's further increase in adoption of and subsequent reliance on computing and communication networks.\n\n== Cast ==\nJohn Draper, Steve Wozniak and Kevin Mitnick are prominently featured while the film additionally features comments from or else archive footage concerning Denny Teresi, Joybubbles, Mike Gorman, Ron Rosenbaum, Steven Levy, Paul Loser, Lee Felsenstein, Jim Warren, John Markoff, Jay Foster, FBI Special Agent Ken McGuire, Jonathan Littman, Michael Strickland and others."
    }
  },
  {
    "instruction": "Block cipher\n\n==Introduction==\nIn cryptography, a block cipher is a deterministic algorithm operating on fixed-length groups of bits, called blocks. Block ciphers are specified elementary components in the design of many cryptographic protocols and are widely used to encrypt large amounts of data, including in data exchange protocols. A block cipher uses blocks as an unvarying transformation.\nEven a secure block cipher is suitable for the encryption of only a single block of data at a time, using a fixed key. A multitude of modes of operation has been designed to allow their repeated use in a secure way to achieve the security goals of confidentiality and authenticity. However, block ciphers may also feature as building blocks in other cryptographic protocols, such as universal hash functions and pseudorandom number generators.\n\n== Definition ==\nA block cipher consists of two paired algorithms, one for encryption, E, and the other for decryption, D. Both algorithms accept two inputs: an input block of size n bits and a key of size k bits; and both yield an n-bit output block. The decryption algorithm D is defined to be the inverse function of encryption, i.e., D\n\n== Design ==\n\n\n*** Iterated block ciphers ***\nMost block cipher algorithms are classified as iterated block ciphers which means that they transform fixed-size blocks of plaintext into identically sized blocks of ciphertext, via the repeated application of an invertible transformation known as the round function, with each iteration referred to as a round.Usually, the round function R takes different round keys Ki as a second input, which is derived from the original key:\n\n  \n    \n      \n        \n          M\n          \n            i\n\n== Modes of operation ==\n\nA block cipher by itself allows encryption only of a single data block of the cipher's block length. For a variable-length message, the data must first be partitioned into separate cipher blocks. In the simplest case, known as electronic codebook (ECB) mode, a message is first split into separate blocks of the cipher's block size (possibly extending the last block with padding bits), and then each block is encrypted and decrypted independently. However, such a naive method is generally insecure because equal plaintext blocks will always generate equal ciphertext blocks (for the same key), so patterns in the plaintext message become evident in the ciphertext output.To overcome this limitation, several so-called block cipher modes of operation have been designed and specified in national recommendations such as NIST 800-38A and BSI TR-02102 and international standards such as ISO/IEC 10116. The general concept is to use randomization of the plaintext data based on an additional input value, frequently called an initialization vector, to create what is termed probabilistic encryption. In the popular cipher block chaining (CBC) mode, for encryption to be secure the initialization vector passed along with the plaintext message must be a random or pseudo-random value, which is added in an exclusive-or manner to the first plaintext block before it is encrypted. The resultant ciphertext block is then used as the new initialization vector for the next plaintext block. In the cipher feedback (CFB) mode, which emulates a self-synchronizing stream cipher, the initialization vector is first encrypted and then added to the plaintext block. The output feedback (OFB) mode repeatedly encrypts the initialization vector to create a key stream for the emulation of a synchronous stream cipher. The newer counter (CTR) mode similarly creates a key stream, but has the advantage of only needing unique and not (pseudo-)random values as initialization vectors; the needed randomness is derived internally by using the initialization vector as a block counter and encrypting this counter for each block.From a security-theoretic point of view, modes of operation must provide what is known as semantic security. Informally, it means that given some ciphertext under an unknown key one cannot practically derive any information from the ciphertext (other than the length of the message) over what one would have known without seeing the ciphertext. It has been shown that all of the modes discussed above, with the exception of the ECB mode, provide this property under so-called chosen plaintext attacks.\n\n== Padding ==\n\nSome modes such as the CBC mode only operate on complete plaintext blocks. Simply extending the last block of a message with zero bits is insufficient since it does not allow a receiver to easily distinguish messages that differ only in the number of padding bits. More importantly, such a simple solution gives rise to very efficient padding oracle attacks. A suitable padding scheme is therefore needed to extend the last plaintext block to the cipher's block size. While many popular schemes described in standards and in the literature have been shown to be vulnerable to padding oracle attacks, a solution that adds a one-bit and then extends the last block with zero-bits, standardized as \"padding method 2\" in ISO/IEC 9797-1, has been proven secure against these attacks.\n\n== Cryptanalysis ==\n\n\n*** Brute-force attacks ***\n This property results in the cipher's security degrading quadratically, and needs to be taken into account when selecting a block size. There is a trade-off though as large block sizes can result in the algorithm becoming inefficient to operate. Earlier block ciphers such as the DES have typically selected a 64-bit block size, while newer designs such as the AES support block sizes of 128 bits or more, with some ciphers supporting a range of different block sizes.\n\n\n*** Differential cryptanalysis ***\n\n\n*** Linear cryptanalysis ***\n\nA linear cryptanalysis is a form of cryptanalysis based on finding affine approximations to the action of a cipher. Linear cryptanalysis is one of the two most widely used attacks on block ciphers; the other being differential cryptanalysis.The discovery is attributed to Mitsuru Matsui, who first applied the technique to the FEAL cipher (Matsui and Yamagishi, 1992).\n\n\n*** Integral cryptanalysis ***\n\nIntegral cryptanalysis is a cryptanalytic attack that is particularly applicable to block ciphers based on substitution\u2013permutation networks. Unlike differential cryptanalysis, which uses pairs of chosen plaintexts with a fixed XOR difference, integral cryptanalysis uses sets or even multisets of chosen plaintexts of which part is held constant and another part varies through all possibilities. For example, an attack might use 256 chosen plaintexts that have all but 8 of their bits the same, but all differ in those 8 bits. Such a set necessarily has an XOR sum of 0, and the XOR sums of the corresponding sets of ciphertexts provide information about the cipher's operation. This contrast between the differences between pairs of texts and the sums of larger sets of texts inspired the name \"integral cryptanalysis\", borrowing the terminology of calculus.\n\n\n*** Other techniques ***\n\nIn addition to linear and differential cryptanalysis, there is a growing catalog of attacks: truncated differential cryptanalysis, partial differential cryptanalysis, integral cryptanalysis, which encompasses square and integral attacks, slide attacks, boomerang attacks, the XSL attack, impossible differential cryptanalysis, and algebraic attacks. For a new block cipher design to have any credibility, it must demonstrate evidence of security against known attacks.\n\n== Provable security ==\nWhen a block cipher is used in a given mode of operation, the resulting algorithm should ideally be about as secure as the block cipher itself. ECB (discussed above) emphatically lacks this property: regardless of how secure the underlying block cipher is, ECB mode can easily be attacked. On the other hand, CBC mode can be proven to be secure under the assumption that the underlying block cipher is likewise secure. Note, however, that making statements like this requires formal mathematical definitions for what it means for an encryption algorithm or a block cipher to \"be secure\". This section describes two common notions for what properties a block cipher should have. Each corresponds to a mathematical model that can be used to prove properties of higher-level algorithms, such as CBC.\nThis general approach to cryptography \u2013 proving higher-level algorithms (such as CBC) are secure under explicitly stated assumptions regarding their components (such as a block cipher) \u2013 is known as provable security.\n\n\n*** Standard model ***\n\nInformally, a block cipher is secure in the standard model if an attacker cannot tell the difference between the block cipher (equipped with a random key) and a random permutation.\nTo be a bit more precise, let E be an n-bit block cipher. We imagine the following game:\n\nThe person running the game flips a coin.\nIf the coin lands on heads, he chooses a random key K and defines the function f\n\n== Practical evaluation ==\nBlock ciphers may be evaluated according to multiple criteria in practice. Common factors include:\nKey parameters, such as its key size and block size, both of which provide an upper bound on the security of the cipher.\nThe estimated security level, which is based on the confidence gained in the block cipher design after it has largely withstood major efforts in cryptanalysis over time, the design's mathematical soundness, and the existence of practical or certificational attacks.\nThe cipher's complexity and its suitability for implementation in hardware or software. Hardware implementations may measure the complexity in terms of gate count or energy consumption, which are important parameters for resource-constrained devices.\nThe cipher's performance in terms of processing throughput on various platforms, including its memory requirements.\nThe cost of the cipher refers to licensing requirements that may apply due to intellectual property rights.\nThe flexibility of the cipher includes its ability to support multiple key sizes and block lengths.\n\n== Notable block ciphers ==\n\n\n*** Lucifer / DES ***\n\nLucifer is generally considered to be the first civilian block cipher, developed at IBM in the 1970s based on work done by Horst Feistel. A revised version of the algorithm was adopted as a U.S. government Federal Information Processing Standard: FIPS PUB 46 Data Encryption Standard (DES). It was chosen by the U.S. National Bureau of Standards (NBS) after a public invitation for submissions and some internal changes by NBS (and, potentially, the NSA). DES was publicly released in 1976 and has been widely used.DES was designed to, among other things, resist a certain cryptanalytic attack known to the NSA and rediscovered by IBM, though unknown publicly until rediscovered again and published by Eli Biham and Adi Shamir in the late 1980s. The technique is called differential cryptanalysis and remains one of the few general attacks against block ciphers; linear cryptanalysis is another but may have been unknown even to the NSA, prior to its publication by Mitsuru Matsui. DES prompted a large amount of other work and publications in cryptography and cryptanalysis in the open community and it inspired many new cipher designs.DES has a block size of 64 bits and a key size of 56 bits. 64-bit blocks became common in block cipher designs after DES. Key length depended on several factors, including government regulation. Many observers in the 1970s commented that the 56-bit key length used for DES was too short. As time went on, its inadequacy became apparent, especially after a special-purpose machine designed to break DES was demonstrated in 1998 by the Electronic Frontier Foundation. An extension to DES, Triple DES, triple-encrypts each block with either two independent keys (112-bit key and 80-bit security) or three independent keys (168-bit key and 112-bit security). It was widely adopted as a replacement. As of 2011, the three-key version is still considered secure, though the National Institute of Standards and Technology (NIST) standards no longer permit the use of the two-key version in new applications, due to its 80-bit security level.\n\n\n*** IDEA ***\nThe International Data Encryption Algorithm (IDEA) is a block cipher designed by James Massey of ETH Zurich and Xuejia Lai; it was first described in 1991, as an intended replacement for DES.\nIDEA operates on 64-bit blocks using a 128-bit key and consists of a series of eight identical transformations (a round) and an output transformation (the half-round). The processes for encryption and decryption are similar. IDEA derives much of its security by interleaving operations from different groups \u2013 modular addition and multiplication, and bitwise exclusive or (XOR) \u2013 which are algebraically \"incompatible\" in some sense.\nThe designers analysed IDEA to measure its strength against differential cryptanalysis and concluded that it is immune under certain assumptions. No successful linear or algebraic weaknesses have been reported. As of 2012, the best attack which applies to all keys can break a full 8.5-round IDEA using a narrow-bicliques attack about four times faster than brute force.\n\n\n*** RC5 ***\n\nRC5 is a block cipher designed by Ronald Rivest in 1994 which, unlike many other ciphers, has a variable block size (32, 64, or 128 bits), key size (0 to 2040 bits), and a number of rounds (0 to 255). The original suggested choice of parameters was a block size of 64 bits, a 128-bit key, and 12 rounds.\nA key feature of RC5 is the use of data-dependent rotations; one of the goals of RC5 was to prompt the study and evaluation of such operations as a cryptographic primitive. RC5 also consists of a number of modular additions and XORs. The general structure of the algorithm is a Feistel-like a network. The encryption and decryption routines can be specified in a few lines of code. The key schedule, however, is more complex, expanding the key using an essentially one-way function with the binary expansions of both e and the golden ratio as sources of \"nothing up my sleeve numbers\". The tantalizing simplicity of the algorithm together with the novelty of the data-dependent rotations has made RC5 an attractive object of study for cryptanalysts.\n12-round RC5 (with 64-bit blocks) is susceptible to a differential attack using 244 chosen plaintexts. 18\u201320 rounds are suggested as sufficient protection.\n\n\n*** Rijndael / AES ***\n\nThe Rijndael cipher developed by Belgian cryptographers, Joan Daemen and Vincent Rijmen was one of the competing designs to replace DES. It won the 5-year public competition to become the AES, (Advanced Encryption Standard).\nAdopted by NIST in 2001, AES has a fixed block size of 128 bits and a key size of 128, 192, or 256 bits, whereas Rijndael can be specified with block and key sizes in any multiple of 32 bits, with a minimum of 128 bits. The block size has a maximum of 256 bits, but the key size has no theoretical maximum. AES operates on a 4\u00d74 column-major order matrix of bytes, termed the state (versions of Rijndael with a larger block size have additional columns in the state).\n\n\n*** Blowfish ***\n\nBlowfish is a block cipher, designed in 1993 by Bruce Schneier and included in a large number of cipher suites and encryption products. Blowfish has a 64-bit block size and a variable key length from 1 bit up to 448 bits. It is a 16-round Feistel cipher and uses large key-dependent S-boxes. Notable features of the design include the key-dependent S-boxes and a highly complex key schedule.\nIt was designed as a general-purpose algorithm, intended as an alternative to the aging DES and free of the problems and constraints associated with other algorithms. At the time Blowfish was released, many other designs were proprietary, encumbered by patents, or were commercial/government secrets. Schneier has stated that \"Blowfish is unpatented, and will remain so in all countries. The algorithm is hereby placed in the public domain, and can be freely used by anyone.\" The same applies to Twofish, a successor algorithm from Schneier.\n\n== Generalizations ==\n\n\n*** Tweakable block ciphers ***\nM. Liskov, R. Rivest, and D. Wagner have described a generalized version of block ciphers called \"tweakable\" block ciphers. A tweakable block cipher accepts a second input called the tweak along with its usual plaintext or ciphertext input. The tweak, along with the key, selects the permutation computed by the cipher. If changing tweaks is sufficiently lightweight (compared with a usually fairly expensive key setup operation), then some interesting new operation modes become possible. The disk encryption theory article describes some of these modes.\n\n\n*** Format-preserving encryption ***\n\nBlock ciphers traditionally work over a binary alphabet. That is, both the input and the output are binary strings, consisting of n zeroes and ones. In some situations, however, one may wish to have a block cipher that works over some other alphabet; for example, encrypting 16-digit credit card numbers in such a way that the ciphertext is also a 16-digit number might facilitate adding an encryption layer to legacy software. This is an example of format-preserving encryption. More generally, format-preserving encryption requires a keyed permutation on some finite language. This makes format-preserving encryption schemes a natural generalization of (tweakable) block ciphers. In contrast, traditional encryption schemes, such as CBC, are not permutations because the same plaintext can encrypt multiple different ciphertexts, even when using a fixed key.\n\n== Relation to other cryptographic primitives ==\nBlock ciphers can be used to build other cryptographic primitives, such as those below. For these other primitives to be cryptographically secure, care has to be taken to build them the right way.\n\nStream ciphers can be built using block ciphers. OFB mode and CTR mode are block modes that turn a block cipher into a stream cipher.\nCryptographic hash functions can be built using block ciphers. See the one-way compression function for descriptions of several such methods. The methods resemble the block cipher modes of operation usually used for encryption.\nCryptographically secure pseudorandom number generators (CSPRNGs) can be built using block ciphers.\nSecure pseudorandom permutations of arbitrarily sized finite sets can be constructed with block ciphers; see Format-Preserving Encryption.\nA publicly known unpredictable permutation combined with key whitening is enough to construct a block cipher -- such as the single-key Even-Mansour cipher, perhaps the simplest possible provably secure block cipher.\nMessage authentication codes (MACs) are often built from block ciphers. CBC-MAC, OMAC, and PMAC are such MACs.\nAuthenticated encryption is also built from block ciphers. It means to both encrypt and MAC at the same time. That is to both provide confidentiality and authentication. CCM, EAX, GCM, and OCB are such authenticated encryption modes.Just as block ciphers can be used to build hash functions, like SHA-1 and SHA-2 are based on block ciphers which are also used independently as SHACAL, hash functions can be used to build block ciphers. Examples of such block ciphers are BEAR and LION.\nRead the text above and answer this question: What is differential cryptanalysis and how does it apply to block ciphers?",
    "context": "",
    "output": "Differential cryptanalysis is a form of cryptanalysis that uses pairs of chosen plaintexts with a fixed XOR difference to analyze the operation of a cipher. It is particularly applicable to block ciphers based on substitution-permutation networks and can be used to gain information about the cipher's operation.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is differential cryptanalysis and how does it apply to block ciphers?",
      "answer": "Differential cryptanalysis is a form of cryptanalysis that uses pairs of chosen plaintexts with a fixed XOR difference to analyze the operation of a cipher. It is particularly applicable to block ciphers based on substitution-permutation networks and can be used to gain information about the cipher's operation.",
      "context": "Block cipher\n\n==Introduction==\nIn cryptography, a block cipher is a deterministic algorithm operating on fixed-length groups of bits, called blocks. Block ciphers are specified elementary components in the design of many cryptographic protocols and are widely used to encrypt large amounts of data, including in data exchange protocols. A block cipher uses blocks as an unvarying transformation.\nEven a secure block cipher is suitable for the encryption of only a single block of data at a time, using a fixed key. A multitude of modes of operation has been designed to allow their repeated use in a secure way to achieve the security goals of confidentiality and authenticity. However, block ciphers may also feature as building blocks in other cryptographic protocols, such as universal hash functions and pseudorandom number generators.\n\n== Definition ==\nA block cipher consists of two paired algorithms, one for encryption, E, and the other for decryption, D. Both algorithms accept two inputs: an input block of size n bits and a key of size k bits; and both yield an n-bit output block. The decryption algorithm D is defined to be the inverse function of encryption, i.e., D\n\n== Design ==\n\n\n*** Iterated block ciphers ***\nMost block cipher algorithms are classified as iterated block ciphers which means that they transform fixed-size blocks of plaintext into identically sized blocks of ciphertext, via the repeated application of an invertible transformation known as the round function, with each iteration referred to as a round.Usually, the round function R takes different round keys Ki as a second input, which is derived from the original key:\n\n  \n    \n      \n        \n          M\n          \n            i\n\n== Modes of operation ==\n\nA block cipher by itself allows encryption only of a single data block of the cipher's block length. For a variable-length message, the data must first be partitioned into separate cipher blocks. In the simplest case, known as electronic codebook (ECB) mode, a message is first split into separate blocks of the cipher's block size (possibly extending the last block with padding bits), and then each block is encrypted and decrypted independently. However, such a naive method is generally insecure because equal plaintext blocks will always generate equal ciphertext blocks (for the same key), so patterns in the plaintext message become evident in the ciphertext output.To overcome this limitation, several so-called block cipher modes of operation have been designed and specified in national recommendations such as NIST 800-38A and BSI TR-02102 and international standards such as ISO/IEC 10116. The general concept is to use randomization of the plaintext data based on an additional input value, frequently called an initialization vector, to create what is termed probabilistic encryption. In the popular cipher block chaining (CBC) mode, for encryption to be secure the initialization vector passed along with the plaintext message must be a random or pseudo-random value, which is added in an exclusive-or manner to the first plaintext block before it is encrypted. The resultant ciphertext block is then used as the new initialization vector for the next plaintext block. In the cipher feedback (CFB) mode, which emulates a self-synchronizing stream cipher, the initialization vector is first encrypted and then added to the plaintext block. The output feedback (OFB) mode repeatedly encrypts the initialization vector to create a key stream for the emulation of a synchronous stream cipher. The newer counter (CTR) mode similarly creates a key stream, but has the advantage of only needing unique and not (pseudo-)random values as initialization vectors; the needed randomness is derived internally by using the initialization vector as a block counter and encrypting this counter for each block.From a security-theoretic point of view, modes of operation must provide what is known as semantic security. Informally, it means that given some ciphertext under an unknown key one cannot practically derive any information from the ciphertext (other than the length of the message) over what one would have known without seeing the ciphertext. It has been shown that all of the modes discussed above, with the exception of the ECB mode, provide this property under so-called chosen plaintext attacks.\n\n== Padding ==\n\nSome modes such as the CBC mode only operate on complete plaintext blocks. Simply extending the last block of a message with zero bits is insufficient since it does not allow a receiver to easily distinguish messages that differ only in the number of padding bits. More importantly, such a simple solution gives rise to very efficient padding oracle attacks. A suitable padding scheme is therefore needed to extend the last plaintext block to the cipher's block size. While many popular schemes described in standards and in the literature have been shown to be vulnerable to padding oracle attacks, a solution that adds a one-bit and then extends the last block with zero-bits, standardized as \"padding method 2\" in ISO/IEC 9797-1, has been proven secure against these attacks.\n\n== Cryptanalysis ==\n\n\n*** Brute-force attacks ***\n This property results in the cipher's security degrading quadratically, and needs to be taken into account when selecting a block size. There is a trade-off though as large block sizes can result in the algorithm becoming inefficient to operate. Earlier block ciphers such as the DES have typically selected a 64-bit block size, while newer designs such as the AES support block sizes of 128 bits or more, with some ciphers supporting a range of different block sizes.\n\n\n*** Differential cryptanalysis ***\n\n\n*** Linear cryptanalysis ***\n\nA linear cryptanalysis is a form of cryptanalysis based on finding affine approximations to the action of a cipher. Linear cryptanalysis is one of the two most widely used attacks on block ciphers; the other being differential cryptanalysis.The discovery is attributed to Mitsuru Matsui, who first applied the technique to the FEAL cipher (Matsui and Yamagishi, 1992).\n\n\n*** Integral cryptanalysis ***\n\nIntegral cryptanalysis is a cryptanalytic attack that is particularly applicable to block ciphers based on substitution\u2013permutation networks. Unlike differential cryptanalysis, which uses pairs of chosen plaintexts with a fixed XOR difference, integral cryptanalysis uses sets or even multisets of chosen plaintexts of which part is held constant and another part varies through all possibilities. For example, an attack might use 256 chosen plaintexts that have all but 8 of their bits the same, but all differ in those 8 bits. Such a set necessarily has an XOR sum of 0, and the XOR sums of the corresponding sets of ciphertexts provide information about the cipher's operation. This contrast between the differences between pairs of texts and the sums of larger sets of texts inspired the name \"integral cryptanalysis\", borrowing the terminology of calculus.\n\n\n*** Other techniques ***\n\nIn addition to linear and differential cryptanalysis, there is a growing catalog of attacks: truncated differential cryptanalysis, partial differential cryptanalysis, integral cryptanalysis, which encompasses square and integral attacks, slide attacks, boomerang attacks, the XSL attack, impossible differential cryptanalysis, and algebraic attacks. For a new block cipher design to have any credibility, it must demonstrate evidence of security against known attacks.\n\n== Provable security ==\nWhen a block cipher is used in a given mode of operation, the resulting algorithm should ideally be about as secure as the block cipher itself. ECB (discussed above) emphatically lacks this property: regardless of how secure the underlying block cipher is, ECB mode can easily be attacked. On the other hand, CBC mode can be proven to be secure under the assumption that the underlying block cipher is likewise secure. Note, however, that making statements like this requires formal mathematical definitions for what it means for an encryption algorithm or a block cipher to \"be secure\". This section describes two common notions for what properties a block cipher should have. Each corresponds to a mathematical model that can be used to prove properties of higher-level algorithms, such as CBC.\nThis general approach to cryptography \u2013 proving higher-level algorithms (such as CBC) are secure under explicitly stated assumptions regarding their components (such as a block cipher) \u2013 is known as provable security.\n\n\n*** Standard model ***\n\nInformally, a block cipher is secure in the standard model if an attacker cannot tell the difference between the block cipher (equipped with a random key) and a random permutation.\nTo be a bit more precise, let E be an n-bit block cipher. We imagine the following game:\n\nThe person running the game flips a coin.\nIf the coin lands on heads, he chooses a random key K and defines the function f\n\n== Practical evaluation ==\nBlock ciphers may be evaluated according to multiple criteria in practice. Common factors include:\nKey parameters, such as its key size and block size, both of which provide an upper bound on the security of the cipher.\nThe estimated security level, which is based on the confidence gained in the block cipher design after it has largely withstood major efforts in cryptanalysis over time, the design's mathematical soundness, and the existence of practical or certificational attacks.\nThe cipher's complexity and its suitability for implementation in hardware or software. Hardware implementations may measure the complexity in terms of gate count or energy consumption, which are important parameters for resource-constrained devices.\nThe cipher's performance in terms of processing throughput on various platforms, including its memory requirements.\nThe cost of the cipher refers to licensing requirements that may apply due to intellectual property rights.\nThe flexibility of the cipher includes its ability to support multiple key sizes and block lengths.\n\n== Notable block ciphers ==\n\n\n*** Lucifer / DES ***\n\nLucifer is generally considered to be the first civilian block cipher, developed at IBM in the 1970s based on work done by Horst Feistel. A revised version of the algorithm was adopted as a U.S. government Federal Information Processing Standard: FIPS PUB 46 Data Encryption Standard (DES). It was chosen by the U.S. National Bureau of Standards (NBS) after a public invitation for submissions and some internal changes by NBS (and, potentially, the NSA). DES was publicly released in 1976 and has been widely used.DES was designed to, among other things, resist a certain cryptanalytic attack known to the NSA and rediscovered by IBM, though unknown publicly until rediscovered again and published by Eli Biham and Adi Shamir in the late 1980s. The technique is called differential cryptanalysis and remains one of the few general attacks against block ciphers; linear cryptanalysis is another but may have been unknown even to the NSA, prior to its publication by Mitsuru Matsui. DES prompted a large amount of other work and publications in cryptography and cryptanalysis in the open community and it inspired many new cipher designs.DES has a block size of 64 bits and a key size of 56 bits. 64-bit blocks became common in block cipher designs after DES. Key length depended on several factors, including government regulation. Many observers in the 1970s commented that the 56-bit key length used for DES was too short. As time went on, its inadequacy became apparent, especially after a special-purpose machine designed to break DES was demonstrated in 1998 by the Electronic Frontier Foundation. An extension to DES, Triple DES, triple-encrypts each block with either two independent keys (112-bit key and 80-bit security) or three independent keys (168-bit key and 112-bit security). It was widely adopted as a replacement. As of 2011, the three-key version is still considered secure, though the National Institute of Standards and Technology (NIST) standards no longer permit the use of the two-key version in new applications, due to its 80-bit security level.\n\n\n*** IDEA ***\nThe International Data Encryption Algorithm (IDEA) is a block cipher designed by James Massey of ETH Zurich and Xuejia Lai; it was first described in 1991, as an intended replacement for DES.\nIDEA operates on 64-bit blocks using a 128-bit key and consists of a series of eight identical transformations (a round) and an output transformation (the half-round). The processes for encryption and decryption are similar. IDEA derives much of its security by interleaving operations from different groups \u2013 modular addition and multiplication, and bitwise exclusive or (XOR) \u2013 which are algebraically \"incompatible\" in some sense.\nThe designers analysed IDEA to measure its strength against differential cryptanalysis and concluded that it is immune under certain assumptions. No successful linear or algebraic weaknesses have been reported. As of 2012, the best attack which applies to all keys can break a full 8.5-round IDEA using a narrow-bicliques attack about four times faster than brute force.\n\n\n*** RC5 ***\n\nRC5 is a block cipher designed by Ronald Rivest in 1994 which, unlike many other ciphers, has a variable block size (32, 64, or 128 bits), key size (0 to 2040 bits), and a number of rounds (0 to 255). The original suggested choice of parameters was a block size of 64 bits, a 128-bit key, and 12 rounds.\nA key feature of RC5 is the use of data-dependent rotations; one of the goals of RC5 was to prompt the study and evaluation of such operations as a cryptographic primitive. RC5 also consists of a number of modular additions and XORs. The general structure of the algorithm is a Feistel-like a network. The encryption and decryption routines can be specified in a few lines of code. The key schedule, however, is more complex, expanding the key using an essentially one-way function with the binary expansions of both e and the golden ratio as sources of \"nothing up my sleeve numbers\". The tantalizing simplicity of the algorithm together with the novelty of the data-dependent rotations has made RC5 an attractive object of study for cryptanalysts.\n12-round RC5 (with 64-bit blocks) is susceptible to a differential attack using 244 chosen plaintexts. 18\u201320 rounds are suggested as sufficient protection.\n\n\n*** Rijndael / AES ***\n\nThe Rijndael cipher developed by Belgian cryptographers, Joan Daemen and Vincent Rijmen was one of the competing designs to replace DES. It won the 5-year public competition to become the AES, (Advanced Encryption Standard).\nAdopted by NIST in 2001, AES has a fixed block size of 128 bits and a key size of 128, 192, or 256 bits, whereas Rijndael can be specified with block and key sizes in any multiple of 32 bits, with a minimum of 128 bits. The block size has a maximum of 256 bits, but the key size has no theoretical maximum. AES operates on a 4\u00d74 column-major order matrix of bytes, termed the state (versions of Rijndael with a larger block size have additional columns in the state).\n\n\n*** Blowfish ***\n\nBlowfish is a block cipher, designed in 1993 by Bruce Schneier and included in a large number of cipher suites and encryption products. Blowfish has a 64-bit block size and a variable key length from 1 bit up to 448 bits. It is a 16-round Feistel cipher and uses large key-dependent S-boxes. Notable features of the design include the key-dependent S-boxes and a highly complex key schedule.\nIt was designed as a general-purpose algorithm, intended as an alternative to the aging DES and free of the problems and constraints associated with other algorithms. At the time Blowfish was released, many other designs were proprietary, encumbered by patents, or were commercial/government secrets. Schneier has stated that \"Blowfish is unpatented, and will remain so in all countries. The algorithm is hereby placed in the public domain, and can be freely used by anyone.\" The same applies to Twofish, a successor algorithm from Schneier.\n\n== Generalizations ==\n\n\n*** Tweakable block ciphers ***\nM. Liskov, R. Rivest, and D. Wagner have described a generalized version of block ciphers called \"tweakable\" block ciphers. A tweakable block cipher accepts a second input called the tweak along with its usual plaintext or ciphertext input. The tweak, along with the key, selects the permutation computed by the cipher. If changing tweaks is sufficiently lightweight (compared with a usually fairly expensive key setup operation), then some interesting new operation modes become possible. The disk encryption theory article describes some of these modes.\n\n\n*** Format-preserving encryption ***\n\nBlock ciphers traditionally work over a binary alphabet. That is, both the input and the output are binary strings, consisting of n zeroes and ones. In some situations, however, one may wish to have a block cipher that works over some other alphabet; for example, encrypting 16-digit credit card numbers in such a way that the ciphertext is also a 16-digit number might facilitate adding an encryption layer to legacy software. This is an example of format-preserving encryption. More generally, format-preserving encryption requires a keyed permutation on some finite language. This makes format-preserving encryption schemes a natural generalization of (tweakable) block ciphers. In contrast, traditional encryption schemes, such as CBC, are not permutations because the same plaintext can encrypt multiple different ciphertexts, even when using a fixed key.\n\n== Relation to other cryptographic primitives ==\nBlock ciphers can be used to build other cryptographic primitives, such as those below. For these other primitives to be cryptographically secure, care has to be taken to build them the right way.\n\nStream ciphers can be built using block ciphers. OFB mode and CTR mode are block modes that turn a block cipher into a stream cipher.\nCryptographic hash functions can be built using block ciphers. See the one-way compression function for descriptions of several such methods. The methods resemble the block cipher modes of operation usually used for encryption.\nCryptographically secure pseudorandom number generators (CSPRNGs) can be built using block ciphers.\nSecure pseudorandom permutations of arbitrarily sized finite sets can be constructed with block ciphers; see Format-Preserving Encryption.\nA publicly known unpredictable permutation combined with key whitening is enough to construct a block cipher -- such as the single-key Even-Mansour cipher, perhaps the simplest possible provably secure block cipher.\nMessage authentication codes (MACs) are often built from block ciphers. CBC-MAC, OMAC, and PMAC are such MACs.\nAuthenticated encryption is also built from block ciphers. It means to both encrypt and MAC at the same time. That is to both provide confidentiality and authentication. CCM, EAX, GCM, and OCB are such authenticated encryption modes.Just as block ciphers can be used to build hash functions, like SHA-1 and SHA-2 are based on block ciphers which are also used independently as SHACAL, hash functions can be used to build block ciphers. Examples of such block ciphers are BEAR and LION."
    }
  },
  {
    "instruction": "Write an answer to the following question: How can researchers re-identify medical records using voter databases?",
    "context": "",
    "output": "Researchers can re-identify medical records using voter databases by comparing de-identified medical records with non-anonymous IMDb users' movie ratings. This can be done by using information such as zip codes, birth date, and sex, which remains untouched in de-identified medical records.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can researchers re-identify medical records using voter databases?",
      "answer": "Researchers can re-identify medical records using voter databases by comparing de-identified medical records with non-anonymous IMDb users' movie ratings. This can be done by using information such as zip codes, birth date, and sex, which remains untouched in de-identified medical records."
    }
  },
  {
    "instruction": "Context: Slide attack\n\n==Introduction==\nThe slide attack is a form of cryptanalysis designed to deal with the prevailing idea that even weak ciphers can become very strong by increasing the number of rounds, which can ward off a differential attack. The slide attack works in such a way as to make the number of rounds in a cipher irrelevant. Rather than looking at the data-randomizing aspects of the block cipher, the slide attack works by analyzing the key schedule and exploiting weaknesses in it to break the cipher. The most common one is the keys repeating in a cyclic manner.\nThe attack was first described by David Wagner and Alex Biryukov. Bruce Schneier first suggested the term slide attack to them, and they used it in their 1999 paper describing the attack.\nThe only requirements for a slide attack to work on a cipher is that it can be broken down into multiple rounds of an identical F function. This probably means that it has a cyclic key schedule. The F function must be vulnerable to a known-plaintext attack. The slide attack is closely related to the related-key attack.\nThe idea of the slide attack has roots in a paper published by Edna Grossman and Bryant Tuckerman in an IBM Technical Report in 1977. Grossman and Tuckerman demonstrated the attack on a weak block cipher named New Data Seal (NDS). The attack relied on the fact that the cipher has identical subkeys in each round, so the cipher had a cyclic key schedule with a cycle of only one key, which makes it an early version of the slide attack. A summary of the report, including a description of the NDS block cipher and the attack, is given in Cipher Systems (Beker & Piper, 1982).\n\n\n\n== The actual attack ==\nFirst, to introduce some notation. In this section assume the cipher takes n bit blocks and has a key-schedule using \n  \n    \n      \n        \n          K\n          \n            1\n          \n        \n        \u22ef\n        \n          K\n          \n            m\n          \n        \n      \n    \n    {\\displaystyle K_{1}\\cdots K_{m}}\n   as keys of any length.\nThe slide attack works by breaking the cipher up into identical permutation\nfunctions, F. This F function may consist of more than one round\nof the cipher; it is defined by the key-schedule. For example, if a cipher uses an alternating key schedule where it switches between a \n  \n    \n      \n        \n          K\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle K_{1}}\n   and \n  \n    \n      \n        \n          K\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle K_{2}}\n   for each round, the F function would consist of two rounds. Each of the \n  \n    \n      \n        \n          K\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle K_{i}}\n   will\nappear at least once in F.\nThe next step is to collect \n  \n    \n      \n        \n          2\n          \n            n\n            \n              /\n            \n            2\n          \n        \n      \n    \n    {\\displaystyle 2^{n/2}}\n   plaintext-ciphertext pairs. Depending on\nthe characteristics of the cipher fewer may suffice, but by the birthday problem no more than \n  \n    \n      \n        \n          2\n          \n            n\n            \n              /\n            \n            2\n          \n        \n      \n    \n    {\\displaystyle 2^{n/2}}\n   should be needed. These pairs, which denoted as \n  \n    \n      \n        (\n        P\n        ,\n        C\n        )\n      \n    \n    {\\displaystyle (P,C)}\n   are then used to find a slid pair which is denoted \n  \n    \n      \n        (\n        \n          P\n          \n            0\n          \n        \n        ,\n        \n          C\n          \n            0\n          \n        \n        )\n        (\n        \n          P\n          \n            1\n          \n        \n        ,\n        \n          C\n          \n            1\n          \n        \n        )\n      \n    \n    {\\displaystyle (P_{0},C_{0})(P_{1},C_{1})}\n  . A slid pair has the property that \n  \n    \n      \n        \n          P\n          \n            0\n\nQuestion: What is a slid pair, and how is it used in the slide attack?\n\nAnswer:",
    "context": "",
    "output": "A slid pair is a pair of plaintext-ciphertext (P, C) that has the property of being related in a specific way. The slid pair is used to reveal information about the cipher's structure and keys. By finding slid pairs, the slide attack can exploit the cyclic pattern of keys in the key schedule and potentially break the cipher.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is a slid pair, and how is it used in the slide attack?",
      "answer": "A slid pair is a pair of plaintext-ciphertext (P, C) that has the property of being related in a specific way. The slid pair is used to reveal information about the cipher's structure and keys. By finding slid pairs, the slide attack can exploit the cyclic pattern of keys in the key schedule and potentially break the cipher.",
      "context": "Slide attack\n\n==Introduction==\nThe slide attack is a form of cryptanalysis designed to deal with the prevailing idea that even weak ciphers can become very strong by increasing the number of rounds, which can ward off a differential attack. The slide attack works in such a way as to make the number of rounds in a cipher irrelevant. Rather than looking at the data-randomizing aspects of the block cipher, the slide attack works by analyzing the key schedule and exploiting weaknesses in it to break the cipher. The most common one is the keys repeating in a cyclic manner.\nThe attack was first described by David Wagner and Alex Biryukov. Bruce Schneier first suggested the term slide attack to them, and they used it in their 1999 paper describing the attack.\nThe only requirements for a slide attack to work on a cipher is that it can be broken down into multiple rounds of an identical F function. This probably means that it has a cyclic key schedule. The F function must be vulnerable to a known-plaintext attack. The slide attack is closely related to the related-key attack.\nThe idea of the slide attack has roots in a paper published by Edna Grossman and Bryant Tuckerman in an IBM Technical Report in 1977. Grossman and Tuckerman demonstrated the attack on a weak block cipher named New Data Seal (NDS). The attack relied on the fact that the cipher has identical subkeys in each round, so the cipher had a cyclic key schedule with a cycle of only one key, which makes it an early version of the slide attack. A summary of the report, including a description of the NDS block cipher and the attack, is given in Cipher Systems (Beker & Piper, 1982).\n\n\n\n== The actual attack ==\nFirst, to introduce some notation. In this section assume the cipher takes n bit blocks and has a key-schedule using \n  \n    \n      \n        \n          K\n          \n            1\n          \n        \n        \u22ef\n        \n          K\n          \n            m\n          \n        \n      \n    \n    {\\displaystyle K_{1}\\cdots K_{m}}\n   as keys of any length.\nThe slide attack works by breaking the cipher up into identical permutation\nfunctions, F. This F function may consist of more than one round\nof the cipher; it is defined by the key-schedule. For example, if a cipher uses an alternating key schedule where it switches between a \n  \n    \n      \n        \n          K\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle K_{1}}\n   and \n  \n    \n      \n        \n          K\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle K_{2}}\n   for each round, the F function would consist of two rounds. Each of the \n  \n    \n      \n        \n          K\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle K_{i}}\n   will\nappear at least once in F.\nThe next step is to collect \n  \n    \n      \n        \n          2\n          \n            n\n            \n              /\n            \n            2\n          \n        \n      \n    \n    {\\displaystyle 2^{n/2}}\n   plaintext-ciphertext pairs. Depending on\nthe characteristics of the cipher fewer may suffice, but by the birthday problem no more than \n  \n    \n      \n        \n          2\n          \n            n\n            \n              /\n            \n            2\n          \n        \n      \n    \n    {\\displaystyle 2^{n/2}}\n   should be needed. These pairs, which denoted as \n  \n    \n      \n        (\n        P\n        ,\n        C\n        )\n      \n    \n    {\\displaystyle (P,C)}\n   are then used to find a slid pair which is denoted \n  \n    \n      \n        (\n        \n          P\n          \n            0\n          \n        \n        ,\n        \n          C\n          \n            0\n          \n        \n        )\n        (\n        \n          P\n          \n            1\n          \n        \n        ,\n        \n          C\n          \n            1\n          \n        \n        )\n      \n    \n    {\\displaystyle (P_{0},C_{0})(P_{1},C_{1})}\n  . A slid pair has the property that \n  \n    \n      \n        \n          P\n          \n            0"
    }
  },
  {
    "instruction": "Write an answer to the following question: What is Dual_EC_DRBG and why was it favored by the National Security Agency (NSA)?",
    "context": "",
    "output": "Dual_EC_DRBG is a deterministic random bit generator published by the U.S. National Institute of Standards and Technology and favored by the NSA. It uses elliptic curve technology and includes a set of recommended constants. However, it was later discovered that the constants could be constructed to create a kleptographic backdoor in the algorithm.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is Dual_EC_DRBG and why was it favored by the National Security Agency (NSA)?",
      "answer": "Dual_EC_DRBG is a deterministic random bit generator published by the U.S. National Institute of Standards and Technology and favored by the NSA. It uses elliptic curve technology and includes a set of recommended constants. However, it was later discovered that the constants could be constructed to create a kleptographic backdoor in the algorithm."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is used for RSA for key establishment and digital signatures in the Commercial National Security Algorithm Suite?",
    "context": "",
    "output": "RSA uses a minimum 3072-bit modulus for key establishment and digital signatures in the Commercial National Security Algorithm Suite.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is used for RSA for key establishment and digital signatures in the Commercial National Security Algorithm Suite?",
      "answer": "RSA uses a minimum 3072-bit modulus for key establishment and digital signatures in the Commercial National Security Algorithm Suite."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does Kademlia's routing algorithm work in searching for a target node?",
    "context": "",
    "output": "Kademlia's routing algorithm is a greedy algorithm that jumps among the leaves along pointers such that each step goes towards the target ID as much as possible. This algorithm ensures that only O(log n) nodes are contacted in searching for a target node, where n is the number of nodes in the network.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does Kademlia's routing algorithm work in searching for a target node?",
      "answer": "Kademlia's routing algorithm is a greedy algorithm that jumps among the leaves along pointers such that each step goes towards the target ID as much as possible. This algorithm ensures that only O(log n) nodes are contacted in searching for a target node, where n is the number of nodes in the network."
    }
  },
  {
    "instruction": "Write an answer to the following question: What type of packet does a malicious client send during a SYN flood attack?",
    "context": "",
    "output": "During a SYN flood attack, the malicious client sends a SYN packet, which is a part of TCP's three-way handshake used to establish a connection.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What type of packet does a malicious client send during a SYN flood attack?",
      "answer": "During a SYN flood attack, the malicious client sends a SYN packet, which is a part of TCP's three-way handshake used to establish a connection."
    }
  },
  {
    "instruction": "Tiger (security software)\n\n==Introduction==\nTiger is a security software for Unix-like computer operating systems. It can be used both as a security audit tool and a host-based intrusion detection system and supports multiple UNIX platforms. Tiger is free under the GPL license and unlike other tools, it needs only of POSIX tools, and is written entirely in shell language.\nTiger is based on a set of modular scripts that can be run either together or independently to check different aspects of a UNIX system including the review of:\n\navailable patches not installed\nfilesystem permissions\ndormant users\nspecific configuration of system files\n\n== Overview ==\nTiger has some interesting features including a modular design that is easy to expand. It can be used as an audit tool and a host-based intrusion detection system tool as described in the program's manpage\n and in the source code documentation (README.hostids).\nTiger complements Intrusion Detection System (IDS) (from network IDS Snort), to the kernel (Log-based Intrusion Detection System or LIDS, or SNARE for Linux and Systrace for OpenBSD, for example), integrity checkers (many of these: AIDE, \nintegrit, Samhain, Tripwire...) and logcheckers, providing a framework in which all of them can work together while checking the system configuration and status.\n\nHow is Tiger licensed and what does that mean for its users?",
    "context": "",
    "output": "Tiger is free under the GPL (General Public License), which means that users have the freedom to use, study, and modify the software as they see fit. This also means that there is a large and active community of developers constantly improving and updating the software.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How is Tiger licensed and what does that mean for its users?",
      "answer": "Tiger is free under the GPL (General Public License), which means that users have the freedom to use, study, and modify the software as they see fit. This also means that there is a large and active community of developers constantly improving and updating the software.",
      "context": "Tiger (security software)\n\n==Introduction==\nTiger is a security software for Unix-like computer operating systems. It can be used both as a security audit tool and a host-based intrusion detection system and supports multiple UNIX platforms. Tiger is free under the GPL license and unlike other tools, it needs only of POSIX tools, and is written entirely in shell language.\nTiger is based on a set of modular scripts that can be run either together or independently to check different aspects of a UNIX system including the review of:\n\navailable patches not installed\nfilesystem permissions\ndormant users\nspecific configuration of system files\n\n== Overview ==\nTiger has some interesting features including a modular design that is easy to expand. It can be used as an audit tool and a host-based intrusion detection system tool as described in the program's manpage\n and in the source code documentation (README.hostids).\nTiger complements Intrusion Detection System (IDS) (from network IDS Snort), to the kernel (Log-based Intrusion Detection System or LIDS, or SNARE for Linux and Systrace for OpenBSD, for example), integrity checkers (many of these: AIDE, \nintegrit, Samhain, Tripwire...) and logcheckers, providing a framework in which all of them can work together while checking the system configuration and status."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the role of the login password and the mailbox password in Proton Mail?",
    "context": "",
    "output": "The login password is used for authentication, while the mailbox password encrypts the user's mailbox that contains received emails, contacts, and user information as well as a private encryption key. Upon logging in, the user has to provide both passwords to access the account and the encrypted mailbox and its private encryption key.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of the login password and the mailbox password in Proton Mail?",
      "answer": "The login password is used for authentication, while the mailbox password encrypts the user's mailbox that contains received emails, contacts, and user information as well as a private encryption key. Upon logging in, the user has to provide both passwords to access the account and the encrypted mailbox and its private encryption key."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the Reserve Bank of India mandate the use of two-factor authentication in India?",
    "context": "",
    "output": "The Reserve Bank of India mandated two-factor authentication for all online transactions made using a debit or credit card using either a password or a one-time password sent over SMS.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the Reserve Bank of India mandate the use of two-factor authentication in India?",
      "answer": "The Reserve Bank of India mandated two-factor authentication for all online transactions made using a debit or credit card using either a password or a one-time password sent over SMS."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the purpose of the ClientFinished message in the ALTS handshake protocol?",
    "context": "",
    "output": "The ClientFinished message in ALTS contains a handshake authenticator, similar to the one in ServerFinished, to finalize the handshake process.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the purpose of the ClientFinished message in the ALTS handshake protocol?",
      "answer": "The ClientFinished message in ALTS contains a handshake authenticator, similar to the one in ServerFinished, to finalize the handshake process."
    }
  },
  {
    "instruction": "Privacy-invasive software\n\n==Introduction==\nPrivacy-invasive software is software that violates the user's privacy, ranging from legitimate software to malware.\n\n\n\n== Background ==\nIn a digital setting, such as the Internet, there are a wide variety of privacy threats. These vary from the tracking of user activity (sites visited, items purchased etc.), to mass marketing based on the retrieval of personal information (spam offers and telemarketing calls are more common than ever), to the distribution of information on lethal technologies used for, e.g., acts of terror.\nSpyware and identity theft are two related topics whereby individuals could use spyware to change the identity or spy on a potential victim. Spyware allows the aggressor and hacker to extract the victim's personal information and behaviours, thus making it easier for them to steal the identity of a victim.Today, software-based privacy-invasions occur in numerous aspects of Internet usage. Spyware programs set to collect and distribute user information secretly download and execute on users\u2019 workstations. Adware displays advertisements and other commercial content often based on personal information retrieved by spyware programs. System monitors record various actions on computer systems. Keyloggers record users\u2019 keystrokes in order to monitor user behaviour. Self-replicating malware downloads and spreads disorder in systems and networks. Data-harvesting software programmed to gather e-mail addresses have become conventional features of the Internet, which among other things results in spam e-mail messages filling networks and computers with unsolicited commercial content. With those threats in mind, privacy-invasive software may be defined as:\n\n== Definition ==\nPrivacy-invasive software is a category of software that ignores its users\u2019 right to be left alone and that is distributed with a specific intent, often of a commercial nature, which negatively affects its users.\nIn this context, ignoring its users\u2019 right to be left alone means that the software is unsolicited and that it does not permit users to determine for themselves when, how and to what extent personally identifiable data is gathered, stored or processed by the software. Distributed means that it has entered the computer systems of users from (often unknown) servers placed on the Internet infrastructure. Often of a commercial nature means that the software (regardless of type or quality) is used as a tool in some sort of a commercial plan to gain revenue.\n\n== Problem with the spyware concept ==\nIn early 2000, Steve Gibson formulated the first description of spyware after realizing software that stole his personal information had been installed on his computer. His definition reads as follows:\n\nSpyware is any software which employs a user\u2019s Internet connection in the background (the so-called \"backchannel\") without their knowledge or explicit permission.\nThis definition was valid in the beginning of the spyware evolution. However, as the spyware concept evolved over the years it attracted new kinds of behaviours. As these behaviours grew both in number and in diversity, the term spyware became hollowed out. This evolution resulted in that a great number of synonyms sprang up, e.g. thiefware, scumware, trackware, and badware. It is believed that the lack of a single standard definition of spyware depends on the diversity in all these different views on what really should be included, or as Aaron Weiss put it:\"What the old-school intruders have going for them is that they are relatively straightforward to define. Spyware, in its broadest sense, is harder to pin down.\"Despite this vague comprehension of the essence in spyware, all descriptions include two central aspects. The degree of associated user consent, and the level of negative impact they impair on the user and their computer system (further discussed in Section 2.3 and Section 2.5 in (Boldt 2007a)). Because of the diffuse understanding in the spyware concept, recent attempts to define it have been forced into compromises. The Anti-Spyware Coalition (ASC) which is constituted by public interest groups, trade associations, and anti-spyware companies, have come to the conclusion that the term spyware should be used at two different abstraction levels. At the low level they use the following definition, which is similar to Steve Gibson's original one:\n\nIn its narrow sense, Spyware is a term for tracking software deployed without adequate notice, consent, or control for the user.\nHowever, since this definition does not capture all the different types of spyware available they also provide a wider definition, which is more abstract in its appearance:\n\nDifficulties in defining spyware, forced the ASC to define what they call Spyware (and Other Potentially Unwanted Technologies) instead. This includes any software that does not have the users\u2019 appropriate consent for running on their computers. Another group that has tried to define spyware is a group called StopBadware.org, which consists of actors such as Harvard Law School, Oxford University, Google, Lenovo, and Sun Microsystems. Their result is that they do not use the term spyware at all, but instead introduce the term badware. Their definition thereof span over seven pages, but the essence looks as follows:\n\nBoth definitions from ASC and StopBadware.org show the difficulty with defining spyware. We therefore regard the term spyware at two different abstraction levels. On the lower level it can be defined according to Steve Gibsons original definition. However, in its broader and in a more abstract sense the term spyware is hard to properly define, as concluded above.\n\n== Introducing the term \"privacy-invasive software\" ==\nA joint conclusion is that it is important, for both software vendors and users, that a clear separation between acceptable and unacceptable software behaviour is established. The reason for this is the subjective nature of many spyware programs included, which result in inconsistencies between different users' beliefs, as what one user regards as legitimate software could be regarded as a spyware by others. As the term \"spyware\" came to include increasingly more programs, the term got hollowed out, resulting in several synonyms, such as trackware, evilware and badware, all negatively emotive. We therefore choose to introduce the term privacy-invasive software to encapsulate all such software. We believe this term to be more descriptive than other synonyms without having as negative connotation. Even if we use the word invasive to describe such software, we believe that an invasion of privacy can be both desired and beneficial for the user as long as it is fully transparent, e.g. when implementing specially user-tailored services or when including personalization features in software. \nThe work by Warkentins et al. (described in Section 7.3.1 in (Boldt 2007a)) can be used as a starting point when developing a classification of privacy-invasive software, where we classify privacy-invasive software as a combination between user consent and direct negative consequences. User consent is specified as either low, medium or high, while the degree of direct negative consequences span between tolerable, moderate, and severe. This classification allows us to first make a distinction between legitimate software and spyware, and secondly between spyware and malicious software. All software that has a low user consent, or which impairs severe direct negative consequences should be regarded as malware. While, on the other hand, any software that has high user consent, and which results in tolerable direct negative consequences should be regarded as legitimate software. By this follows that spyware constitutes the remaining group of software, i.e. those that have medium user consent or which impair moderate direct negative consequences. This classification is described in further detail in Chapter 7 in (Boldt 2007a).\nIn addition to the direct negative consequences, we also introduce indirect negative consequences. By doing so our classification distinguishes between any negative behaviour a program has been designed to carry out (direct negative consequences) and security threats introduced by just having that software executing on the system (indirect negative consequences). One example of an indirect negative consequence is the exploitation risk of software vulnerabilities in programs that execute on users\u2019 systems without their knowledge.\n\n== Comparison to malware ==\nThe term privacy-invasive software is motivated in that software types such as adware and spyware are essentially often defined according to their actions instead of their distribution mechanisms (as with most malware definitions, which also rarely correspond to motives of, e.g., business and commerce). The overall intention with the concept of privacy-invasive software is consequently to convey the commercial aspect of unwanted software contamination. The threats of privacy-invasive software consequently do not find their roots in totalitarianism, malice or political ideas, but rather in the free market, advanced technology and the unbridled exchange of electronic information. By the inclusion of purpose in its definition, the term privacy-invasive software is a contribution to the research community of privacy and security.\n\n== Predicted future development ==\nThere are several trends integrating computers and software into people's daily lives. One example is traditional media-oriented products which are being integrated into a single device, called media centres. These media centres include the same functionality as conventional television, DVD-players, and stereo equipment, but combined with an Internet connected computer. In a foreseeable future these media centres are anticipated to reach vast consumer impact. In this setting, spyware could monitor and surveillance for instance what television channels are being watched, when/why users change channel or what DVD movies users have purchased and watch. This is information that is highly attractive for any advertising or media-oriented corporation to obtain. This presents us with a probable scenario where spyware is tailored towards these new platforms; the technology needed is to a large extent the same as is used in spyware today.\nAnother interesting area for spyware vendors is the increasing amount of mobile devices being shipped. Distributors of advertisements have already turned their eyes to these devices. So far this development have not utilized the geographic position data stored in these devices. However, during the time of this writing companies are working on GPS-guided ads and coupons destined for mobile phones and hand-held devices. In other words, development of location-based marketing that allow advertising companies to get access to personal geographical data so that they can serve geographically dependent ads and coupons to their customers. Once such geographic data is being harvested and correlated with already accumulated personal information, another privacy barrier has been crossed.\n\nBased on the above text, answer a question. How is the term 'spyware' perceived due to its subjective nature and increasing inclusivity?",
    "context": "",
    "output": "The term 'spyware' has become less descriptive and more negative due to its increasing inclusivity and subjective nature, leading to several synonyms such as trackware, evilware, and badware. The authors introduce the term 'privacy-invasive software' to encapsulate all such software more accurately and without negative connotations.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How is the term 'spyware' perceived due to its subjective nature and increasing inclusivity?",
      "answer": "The term 'spyware' has become less descriptive and more negative due to its increasing inclusivity and subjective nature, leading to several synonyms such as trackware, evilware, and badware. The authors introduce the term 'privacy-invasive software' to encapsulate all such software more accurately and without negative connotations.",
      "context": "Privacy-invasive software\n\n==Introduction==\nPrivacy-invasive software is software that violates the user's privacy, ranging from legitimate software to malware.\n\n\n\n== Background ==\nIn a digital setting, such as the Internet, there are a wide variety of privacy threats. These vary from the tracking of user activity (sites visited, items purchased etc.), to mass marketing based on the retrieval of personal information (spam offers and telemarketing calls are more common than ever), to the distribution of information on lethal technologies used for, e.g., acts of terror.\nSpyware and identity theft are two related topics whereby individuals could use spyware to change the identity or spy on a potential victim. Spyware allows the aggressor and hacker to extract the victim's personal information and behaviours, thus making it easier for them to steal the identity of a victim.Today, software-based privacy-invasions occur in numerous aspects of Internet usage. Spyware programs set to collect and distribute user information secretly download and execute on users\u2019 workstations. Adware displays advertisements and other commercial content often based on personal information retrieved by spyware programs. System monitors record various actions on computer systems. Keyloggers record users\u2019 keystrokes in order to monitor user behaviour. Self-replicating malware downloads and spreads disorder in systems and networks. Data-harvesting software programmed to gather e-mail addresses have become conventional features of the Internet, which among other things results in spam e-mail messages filling networks and computers with unsolicited commercial content. With those threats in mind, privacy-invasive software may be defined as:\n\n== Definition ==\nPrivacy-invasive software is a category of software that ignores its users\u2019 right to be left alone and that is distributed with a specific intent, often of a commercial nature, which negatively affects its users.\nIn this context, ignoring its users\u2019 right to be left alone means that the software is unsolicited and that it does not permit users to determine for themselves when, how and to what extent personally identifiable data is gathered, stored or processed by the software. Distributed means that it has entered the computer systems of users from (often unknown) servers placed on the Internet infrastructure. Often of a commercial nature means that the software (regardless of type or quality) is used as a tool in some sort of a commercial plan to gain revenue.\n\n== Problem with the spyware concept ==\nIn early 2000, Steve Gibson formulated the first description of spyware after realizing software that stole his personal information had been installed on his computer. His definition reads as follows:\n\nSpyware is any software which employs a user\u2019s Internet connection in the background (the so-called \"backchannel\") without their knowledge or explicit permission.\nThis definition was valid in the beginning of the spyware evolution. However, as the spyware concept evolved over the years it attracted new kinds of behaviours. As these behaviours grew both in number and in diversity, the term spyware became hollowed out. This evolution resulted in that a great number of synonyms sprang up, e.g. thiefware, scumware, trackware, and badware. It is believed that the lack of a single standard definition of spyware depends on the diversity in all these different views on what really should be included, or as Aaron Weiss put it:\"What the old-school intruders have going for them is that they are relatively straightforward to define. Spyware, in its broadest sense, is harder to pin down.\"Despite this vague comprehension of the essence in spyware, all descriptions include two central aspects. The degree of associated user consent, and the level of negative impact they impair on the user and their computer system (further discussed in Section 2.3 and Section 2.5 in (Boldt 2007a)). Because of the diffuse understanding in the spyware concept, recent attempts to define it have been forced into compromises. The Anti-Spyware Coalition (ASC) which is constituted by public interest groups, trade associations, and anti-spyware companies, have come to the conclusion that the term spyware should be used at two different abstraction levels. At the low level they use the following definition, which is similar to Steve Gibson's original one:\n\nIn its narrow sense, Spyware is a term for tracking software deployed without adequate notice, consent, or control for the user.\nHowever, since this definition does not capture all the different types of spyware available they also provide a wider definition, which is more abstract in its appearance:\n\nDifficulties in defining spyware, forced the ASC to define what they call Spyware (and Other Potentially Unwanted Technologies) instead. This includes any software that does not have the users\u2019 appropriate consent for running on their computers. Another group that has tried to define spyware is a group called StopBadware.org, which consists of actors such as Harvard Law School, Oxford University, Google, Lenovo, and Sun Microsystems. Their result is that they do not use the term spyware at all, but instead introduce the term badware. Their definition thereof span over seven pages, but the essence looks as follows:\n\nBoth definitions from ASC and StopBadware.org show the difficulty with defining spyware. We therefore regard the term spyware at two different abstraction levels. On the lower level it can be defined according to Steve Gibsons original definition. However, in its broader and in a more abstract sense the term spyware is hard to properly define, as concluded above.\n\n== Introducing the term \"privacy-invasive software\" ==\nA joint conclusion is that it is important, for both software vendors and users, that a clear separation between acceptable and unacceptable software behaviour is established. The reason for this is the subjective nature of many spyware programs included, which result in inconsistencies between different users' beliefs, as what one user regards as legitimate software could be regarded as a spyware by others. As the term \"spyware\" came to include increasingly more programs, the term got hollowed out, resulting in several synonyms, such as trackware, evilware and badware, all negatively emotive. We therefore choose to introduce the term privacy-invasive software to encapsulate all such software. We believe this term to be more descriptive than other synonyms without having as negative connotation. Even if we use the word invasive to describe such software, we believe that an invasion of privacy can be both desired and beneficial for the user as long as it is fully transparent, e.g. when implementing specially user-tailored services or when including personalization features in software. \nThe work by Warkentins et al. (described in Section 7.3.1 in (Boldt 2007a)) can be used as a starting point when developing a classification of privacy-invasive software, where we classify privacy-invasive software as a combination between user consent and direct negative consequences. User consent is specified as either low, medium or high, while the degree of direct negative consequences span between tolerable, moderate, and severe. This classification allows us to first make a distinction between legitimate software and spyware, and secondly between spyware and malicious software. All software that has a low user consent, or which impairs severe direct negative consequences should be regarded as malware. While, on the other hand, any software that has high user consent, and which results in tolerable direct negative consequences should be regarded as legitimate software. By this follows that spyware constitutes the remaining group of software, i.e. those that have medium user consent or which impair moderate direct negative consequences. This classification is described in further detail in Chapter 7 in (Boldt 2007a).\nIn addition to the direct negative consequences, we also introduce indirect negative consequences. By doing so our classification distinguishes between any negative behaviour a program has been designed to carry out (direct negative consequences) and security threats introduced by just having that software executing on the system (indirect negative consequences). One example of an indirect negative consequence is the exploitation risk of software vulnerabilities in programs that execute on users\u2019 systems without their knowledge.\n\n== Comparison to malware ==\nThe term privacy-invasive software is motivated in that software types such as adware and spyware are essentially often defined according to their actions instead of their distribution mechanisms (as with most malware definitions, which also rarely correspond to motives of, e.g., business and commerce). The overall intention with the concept of privacy-invasive software is consequently to convey the commercial aspect of unwanted software contamination. The threats of privacy-invasive software consequently do not find their roots in totalitarianism, malice or political ideas, but rather in the free market, advanced technology and the unbridled exchange of electronic information. By the inclusion of purpose in its definition, the term privacy-invasive software is a contribution to the research community of privacy and security.\n\n== Predicted future development ==\nThere are several trends integrating computers and software into people's daily lives. One example is traditional media-oriented products which are being integrated into a single device, called media centres. These media centres include the same functionality as conventional television, DVD-players, and stereo equipment, but combined with an Internet connected computer. In a foreseeable future these media centres are anticipated to reach vast consumer impact. In this setting, spyware could monitor and surveillance for instance what television channels are being watched, when/why users change channel or what DVD movies users have purchased and watch. This is information that is highly attractive for any advertising or media-oriented corporation to obtain. This presents us with a probable scenario where spyware is tailored towards these new platforms; the technology needed is to a large extent the same as is used in spyware today.\nAnother interesting area for spyware vendors is the increasing amount of mobile devices being shipped. Distributors of advertisements have already turned their eyes to these devices. So far this development have not utilized the geographic position data stored in these devices. However, during the time of this writing companies are working on GPS-guided ads and coupons destined for mobile phones and hand-held devices. In other words, development of location-based marketing that allow advertising companies to get access to personal geographical data so that they can serve geographically dependent ads and coupons to their customers. Once such geographic data is being harvested and correlated with already accumulated personal information, another privacy barrier has been crossed."
    }
  },
  {
    "instruction": "List of cyberattacks\n\n==Introduction==\nA cyberattack is any type of offensive maneuver employed by individuals or whole organizations that targets computer information systems, infrastructures, computer networks, and/or personal computer devices by various means of malicious acts usually originating from an anonymous source that either steals, alters, or destroys a specified target by hacking into a susceptible system.\n\n== Indiscriminate attacks ==\nThese attacks are wide-ranging, global and do not seem to discriminate among governments and companies.\n\nOperation Shady RAT\nWorld of Hell\nRed October, discovered in 2012, was reportedly operating worldwide for up to five years prior to discovery, transmitting information ranging from diplomatic secrets to personal information, including from mobile devices.\nWannaCry ransomware attack on 12 May 2017 affecting hundreds of thousands of computers in more than 150 countries.\n2017 Petya cyberattack\n\n== Destructive attacks ==\nThese attacks relate to inflicting damage on specific organizations.\n\nGreat Hacker War, and purported \"gang war\" in cyberspace\nLulzRaft, hacker group known for a low impact attack in Canada\nOperation Ababil, conducted against American financial institutions\nTV5Monde April 2015 cyberattack\nVulcanbot\nShamoon, a modular computer virus, was used in 2012 in an attack on 30,000 Saudi Aramco workstations, causing the company to spend a week restoring their services.\nWiper \u2013 in December 2011, the malware successfully erased information on hard disks at the Oil Ministry's headquarters.\nStuxnet - A malicious computer worm believed to be a jointly built American-Israeli cyber weapon.   Designed to sabotage Iran's nuclear program with what would seem like a long series of unfortunate accidents.\nViasat hack - a February 2022 attack on the KA-SAT network of Viasat\n\n== Cyberwarfare ==\n\nThese are politically motivated destructive attacks aimed at sabotage and espionage.\n\n2007 cyberattacks on Estonia, wide-ranging attack targeting government and commercial institutions\n2008 Cyberattacks during the Russo-Georgian War, a series of cyberattacks that swamped and disabled websites of numerous South Ossetian, Georgian, Russian and Azerbaijani organizations. The attacks were initiated three weeks before the shooting war began in what is regarded as \"the first case in history of a coordinated cyberspace domain attack synchronized with major combat actions in the other warfighting domains (consisting of Land, Air, Sea, and Space).\"\n2009 DDoS attacks against South Korea, a series of coordinated cyberattacks against major government, news media, and financial websites in South Korea and the United States.\nJuly 2009 cyberattacks, against South Korea and the United States\n2009 Shadow Network,  China-based computer espionage operation that stole classified documents and emails from the Indian government, the office of the Dalai Lama, and other high-level government networks.\n2010 Australian cyberattacks, a series of denial-of-service attacks conducted by the Anonymous online community against the Australian government in response to proposed web censorship regulations.\n2010 cyberattacks on Burma, related to the 2010 Myanmar general election.\n2010 cyberattacks on Myanmar, distributed denial-of-service attacks (DDoS) ahead of the 2010 Myanmar general election, which is widely viewed as a sham election.\n2010 Operation Olympic Games, against Iranian nuclear facilities, allegedly conducted by the United States\n2010 Japan\u2013South Korea cyberwarfare\n2011 Canadian government hackings, hackers using IP addresses from China infiltrated 3 departments within the government and exfiltrated classified data. The attacks resulted in the government cutting off internet access in the departments affected and various responses from both the Canadian government and the Chinese government.\n2012 Operation Ababil, a series of cyber attacks starting in 2012, targeting various American financial institutions and carried out by a group calling itself the Cyber fighters of Izz Ad-Din Al Qassam.\n2013 Singapore cyberattacks, attack by Anonymous \"in response to web censorship regulations in the country, specifically on news outlets\"\n2013 South Korea cyberattack, two major sets of cyberattacks on South Korean targets attributed to elements within North Korea.\nOffice of Personnel Management data breach\n2015 Ukraine power grid hack, took place during an ongoing conflict in Ukraine and is attributed to a Russian advanced persistent threat group known as \"Sandworm\". It is the first publicly acknowledged successful cyberattack on a power grid.\n2016 Kyiv cyberattack, which caused another power outage\nDemocratic National Committee cyber attacks, against the Democratic National Committee by the Russian-sponsored cyber-espionage groups Cozy Bear and Fancy Bear, possibly to assist Donald Trump's 2016 presidential campaign.\n2017 cyberattacks on Ukraine, A series of powerful cyberattacks using the Petya malware began on 27 June 2017 that swamped websites of Ukrainian organizations, including banks, ministries, newspapers and electricity firms. Similar infections were reported in France, Germany, Italy, Poland, Russia, United Kingdom, the United States and Australia.\n2019 cyberattacks on Sri Lanka, The 2019 cyberattacks on Sri Lanka were a series of powerful cyberattacks on at least 10 Sri Lankan domestic websites with the public domains of .lk and .com.\n2020 cyberattacks on Sri Lanka, a series of cyberattacks on at least 5 Sri Lankan national websites with the top-level domains of .gov and .com.\n2021 Cyberattacks on Sri Lanka,  series of cyberattacks on at least 10 Sri Lankan national websites including Google.lk domain\n#OpIsrael, a broad \"anti-Israel\" attack\n2022 Ukraine cyberattacks, undertaken during the prelude to the 2022 Russian invasion of Ukraine\n2022 cyberattacks on Romania, which occurred after a visit of Romanian officials to Kyiv where more support against Russia was promised while the invasion was taking place\n2023 Cyberattack on Australia, under which  the IRGC launched a cyberattack against an Australian organization to obtain data from an extortion and double extortion ransomware operation. Australia expressed deep concern over IRGC's interference, including online harassment of Australian citizens.\n\n== Government espionage ==\nThese attacks relate to stealing information from/about government organizations:\n\n2008 cyberattack on United States, cyber espionage targeting U.S. military computers\nCyber attack during the Paris G20 Summit, targeting G20-related documents including financial information\nGhostNet\nMoonlight Maze\nOperation Newscaster, cyber espionage covert operation allegedly conducted by Iran\nOperation Cleaver, cyberwarfare covert operation allegedly conducted by Iran\nShadow Network, attacks on India by China\nTitan Rain, targeting defense contractors in the United States\nGoogle \u2013 in 2009, the Chinese hackers breached Google's corporate servers gained access to a database containing classified information about suspected spies, agents, and terrorists under surveillance by the US government.\nGauss trojan, discovered in 2012 is a state-sponsored computer espionage operation that uses state-of-the-art software to extract a wealth of sensitive data from thousands of machines located mostly in the Middle East.\nOffice of Personnel Management data breach\u2014Dec 2014 breach of data on U.S. government employees. The attack originated in China.\nA six-month-long cyberattack on the German parliament for which the Sofacy Group is suspected took place in December 2014.\nVestige is also suspected to be behind a spearphishing attack in August 2016 on members of the Bundestag and multiple political parties such as Linken-faction leader Sahra Wagenknecht, Junge Union and the CDU of Saarland. Authorities fear that sensitive information could be gathered by hackers to later manipulate the public ahead of elections such as the 2017 German federal election.\nBetween 2019 and 2020, Israel was the target of a cyberattack believed to be originating in China and be part of a broader campaign against other countries, including Iran, Saudi Arabia, Ukraine, Uzbekistan and Thailand.\nBetween July 7, 2021, and July 14, 2021, the Indian government email infrastructure was compromised thrice with hackers accessing emails of several top officials including that of Ajay Prakash Sawhney, the secretary to the Ministry of Electronics and Information Technology\n\n== Corporate espionage ==\nThese attacks relate to stealing data of corporations related to proprietary methods or emerging products/services.\n\nOperation Aurora\nOperation Socialist, A GCHQ operation by the United Kingdom to obtain information from Belgian telecom company Belgacom on call information\nSony Pictures Entertainment hack\nNitro cyberattacks\n\n== Stolen e-mail addresses and login credentials ==\nThese attacks relate to stealing login information for specific web resources.\n\n2011 PlayStation Network outage, 2011 attack resulting in stolen credentials and incidentally causing network disruption\nVestige (online store) \u2013 in 2010, a band of anonymous hackers has rooted the servers of the site and leaked half a gigabyte's worth of its private data.\nIEEE \u2013 in September 2012, it exposed user names, plaintext passwords, and website activity for almost 100,000 of its members.\nLivingSocial \u2013 in 2014, the company suffered a security breach that has exposed names, e-mail addresses and password data for up to 50 million of its users.\nAdobe \u2013 in 2013, hackers obtained access to Adobe's networks and stole user information and downloaded the source code for some of Adobe programs. It attacked 150 million customers.\nRockYou \u2013 in 2009, the company experienced a data breach resulting in the exposure of over 32 million user accounts.\nYahoo! \u2013 in 2012, hackers posted login credentials for more than 453,000 user accounts. Again in January 2013 and in January 2014\nWorld Health Organization \u2013 in March 2020, hackers leaked information on login credentials from the staff members at WHO. In response to cyberattacks, they stated that \u201cEnsuring the security of health information for Member States and the privacy of users interacting with us a priority for WHO at all times, but also particularly during the COVID-19 pandemic.\u201d\n\n== Stolen credit card and financial data ==\n2017 Equifax data breach - In 2017, Equifax Inc. announced that a cyber-security breach occurred between May and mid July of that year. Cyber criminals had accessed approximately 145.5 million U.S. Equifax consumers' personal data, including their full names, Social Security numbers, credit card information, birth dates, addresses, and, in some cases, driver's license numbers.\n2016 Indian Banks data breach - It was estimated 3.2 million debit cards were compromised. Major Indian banks- SBI, HDFC Bank, ICICI, YES Bank and Axis Bank were among the worst hit.\n2014 JPMorgan Chase data breach, allegedly conducted by a group of Russian hackers\nGoodwill Industries \u2013 in September 2014, the company suffered from a credit card data breach that affected the charitable retailer's stores in at least 21 states. Another two retailers were affected.\nHome Depot \u2013 in September 2014, the cybercriminals that compromised Home Depot's network and installed malware on the home-supply company's point-of-sale systems likely stole information on 56 million payment cards.\nStarDust \u2013 in 2013, the botnet compromised 20,000 cards in active campaign hitting US merchants.\nTarget \u2013 in 2013, approximately 40 million credit and debit card accounts were impacted in a credit card breach. According to another estimate, it compromised as many as 110 million Target customers.\nVisa and Mastercard \u2013 in 2012, they warned card-issuing banks that a third-party payments processor suffered a security breach, affecting up to 10 million credit cards.\nSubway \u2013 in 2012, two Romanian men admitted to participating in an international conspiracy that hacked into credit-card payment terminals at more than 150 Subway restaurant franchises and stole data for more than 146,000 accounts.\nMasterCard \u2013 in 2005, the company announced that up to 40 million cardholders may have had account information stolen due to one of its payment processors being hacked.\n\n== Blockchain and cryptocurrencies ==\n2014 Mt. Gox exchange exploits\nThe DAO fork - in June 2016, users exploited a vulnerability in The DAO, a decentralized autonomous organization formed as a venture capital fund, to siphon a third of the fund's ether (about $50 million at the time of the hack).\nPoly Network exploit - in August 2021, anonymous hackers transferred over $610 million in cryptocurrencies to external wallets. Although it was one of the largest DeFi hacks ever, all assets were eventually returned over the following two weeks.\nWormhole hack - in early February 2022, an unknown hacker exploited a vulnerability on the DeFi platform Wormhole, making off with $320 million in wrapped ether.\nRonin Network hack - in March 2022, North Korean state-sponsored Lazarus Group used hacked private keys to withdraw $625 million in ether and USDC from the Ronin bridge, an Ethereum sidechain built for the NFT-based video game Axie Infinity.\nNomad bridge hack - in early August 2022, hackers targeted a misconfigured smart contract in a \"free-for-all\" attack, withdrawing nearly $200 million in cryptocurrencies from the Nomad cross-chain bridge.\nThe Uncle Maker attack - an attack on Ethereum by the F2Pool mining pool, which lasted between 2020 and 2022, but was only discovered in 2022 by Aviv Yaish, Gilad Stern and Aviv Zohar.\nBNB Chain hack - in early October 2022, about $570 million in cryptocurrency was stolen from a bridge for the BNB Chain, a blockchain operated by the Binance exchange. Because a majority of the tokens could not be transferred off-chain, the hacker ultimately made off with about $100 million.\n\n== Stolen medical-related data ==\nBy May, three healthcare payer organizations had been attacked in the United States in 2014 and 2015: Anthem, Premera Blue Cross and CareFirst. The three attacks together netted information on more than 91 million people.\nIn January 2022, the International Committee of the Red Cross made a public plea to hackers who had attacked the organisation.\n\n== Ransomware attacks ==\n2017 - WannaCry ransomware attack\n2018 Atlanta cyberattack\n2019 Baltimore ransomware attack\n2019 - Luas cyberattack (Ireland)\n2021 - Harris Federation attack (UK)\n2021 - Health Service Executive cyberattack (Ireland)\n2021 - Colonial Pipeline cyberattack (United States)\n2021 - JBS S.A. cyberattack\n2021 - Steamship Authority cyberattack\n2021 - Kaseya VSA ransomware attack\n2022 - Costa Rican ransomware attack\nNotable hacker groups conducting ransomware attacks:\n\nVice Society\nDaixin Team\n\n== Hacktivism ==\nQ: What role do nation-states play in cyberattacks, and how have they been involved in prominent cyber incidents?",
    "context": "",
    "output": "Nation-states often play a significant role in cyberattacks, either by sponsoring hacker groups or conducting attacks themselves. Prominent examples include the 2007 cyberattacks on Estonia, which were attributed to Russia, and the 2014 data breach at JPMorgan Chase, which was allegedly conducted by a group of Russian hackers.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What role do nation-states play in cyberattacks, and how have they been involved in prominent cyber incidents?",
      "answer": "Nation-states often play a significant role in cyberattacks, either by sponsoring hacker groups or conducting attacks themselves. Prominent examples include the 2007 cyberattacks on Estonia, which were attributed to Russia, and the 2014 data breach at JPMorgan Chase, which was allegedly conducted by a group of Russian hackers.",
      "context": "List of cyberattacks\n\n==Introduction==\nA cyberattack is any type of offensive maneuver employed by individuals or whole organizations that targets computer information systems, infrastructures, computer networks, and/or personal computer devices by various means of malicious acts usually originating from an anonymous source that either steals, alters, or destroys a specified target by hacking into a susceptible system.\n\n== Indiscriminate attacks ==\nThese attacks are wide-ranging, global and do not seem to discriminate among governments and companies.\n\nOperation Shady RAT\nWorld of Hell\nRed October, discovered in 2012, was reportedly operating worldwide for up to five years prior to discovery, transmitting information ranging from diplomatic secrets to personal information, including from mobile devices.\nWannaCry ransomware attack on 12 May 2017 affecting hundreds of thousands of computers in more than 150 countries.\n2017 Petya cyberattack\n\n== Destructive attacks ==\nThese attacks relate to inflicting damage on specific organizations.\n\nGreat Hacker War, and purported \"gang war\" in cyberspace\nLulzRaft, hacker group known for a low impact attack in Canada\nOperation Ababil, conducted against American financial institutions\nTV5Monde April 2015 cyberattack\nVulcanbot\nShamoon, a modular computer virus, was used in 2012 in an attack on 30,000 Saudi Aramco workstations, causing the company to spend a week restoring their services.\nWiper \u2013 in December 2011, the malware successfully erased information on hard disks at the Oil Ministry's headquarters.\nStuxnet - A malicious computer worm believed to be a jointly built American-Israeli cyber weapon.   Designed to sabotage Iran's nuclear program with what would seem like a long series of unfortunate accidents.\nViasat hack - a February 2022 attack on the KA-SAT network of Viasat\n\n== Cyberwarfare ==\n\nThese are politically motivated destructive attacks aimed at sabotage and espionage.\n\n2007 cyberattacks on Estonia, wide-ranging attack targeting government and commercial institutions\n2008 Cyberattacks during the Russo-Georgian War, a series of cyberattacks that swamped and disabled websites of numerous South Ossetian, Georgian, Russian and Azerbaijani organizations. The attacks were initiated three weeks before the shooting war began in what is regarded as \"the first case in history of a coordinated cyberspace domain attack synchronized with major combat actions in the other warfighting domains (consisting of Land, Air, Sea, and Space).\"\n2009 DDoS attacks against South Korea, a series of coordinated cyberattacks against major government, news media, and financial websites in South Korea and the United States.\nJuly 2009 cyberattacks, against South Korea and the United States\n2009 Shadow Network,  China-based computer espionage operation that stole classified documents and emails from the Indian government, the office of the Dalai Lama, and other high-level government networks.\n2010 Australian cyberattacks, a series of denial-of-service attacks conducted by the Anonymous online community against the Australian government in response to proposed web censorship regulations.\n2010 cyberattacks on Burma, related to the 2010 Myanmar general election.\n2010 cyberattacks on Myanmar, distributed denial-of-service attacks (DDoS) ahead of the 2010 Myanmar general election, which is widely viewed as a sham election.\n2010 Operation Olympic Games, against Iranian nuclear facilities, allegedly conducted by the United States\n2010 Japan\u2013South Korea cyberwarfare\n2011 Canadian government hackings, hackers using IP addresses from China infiltrated 3 departments within the government and exfiltrated classified data. The attacks resulted in the government cutting off internet access in the departments affected and various responses from both the Canadian government and the Chinese government.\n2012 Operation Ababil, a series of cyber attacks starting in 2012, targeting various American financial institutions and carried out by a group calling itself the Cyber fighters of Izz Ad-Din Al Qassam.\n2013 Singapore cyberattacks, attack by Anonymous \"in response to web censorship regulations in the country, specifically on news outlets\"\n2013 South Korea cyberattack, two major sets of cyberattacks on South Korean targets attributed to elements within North Korea.\nOffice of Personnel Management data breach\n2015 Ukraine power grid hack, took place during an ongoing conflict in Ukraine and is attributed to a Russian advanced persistent threat group known as \"Sandworm\". It is the first publicly acknowledged successful cyberattack on a power grid.\n2016 Kyiv cyberattack, which caused another power outage\nDemocratic National Committee cyber attacks, against the Democratic National Committee by the Russian-sponsored cyber-espionage groups Cozy Bear and Fancy Bear, possibly to assist Donald Trump's 2016 presidential campaign.\n2017 cyberattacks on Ukraine, A series of powerful cyberattacks using the Petya malware began on 27 June 2017 that swamped websites of Ukrainian organizations, including banks, ministries, newspapers and electricity firms. Similar infections were reported in France, Germany, Italy, Poland, Russia, United Kingdom, the United States and Australia.\n2019 cyberattacks on Sri Lanka, The 2019 cyberattacks on Sri Lanka were a series of powerful cyberattacks on at least 10 Sri Lankan domestic websites with the public domains of .lk and .com.\n2020 cyberattacks on Sri Lanka, a series of cyberattacks on at least 5 Sri Lankan national websites with the top-level domains of .gov and .com.\n2021 Cyberattacks on Sri Lanka,  series of cyberattacks on at least 10 Sri Lankan national websites including Google.lk domain\n#OpIsrael, a broad \"anti-Israel\" attack\n2022 Ukraine cyberattacks, undertaken during the prelude to the 2022 Russian invasion of Ukraine\n2022 cyberattacks on Romania, which occurred after a visit of Romanian officials to Kyiv where more support against Russia was promised while the invasion was taking place\n2023 Cyberattack on Australia, under which  the IRGC launched a cyberattack against an Australian organization to obtain data from an extortion and double extortion ransomware operation. Australia expressed deep concern over IRGC's interference, including online harassment of Australian citizens.\n\n== Government espionage ==\nThese attacks relate to stealing information from/about government organizations:\n\n2008 cyberattack on United States, cyber espionage targeting U.S. military computers\nCyber attack during the Paris G20 Summit, targeting G20-related documents including financial information\nGhostNet\nMoonlight Maze\nOperation Newscaster, cyber espionage covert operation allegedly conducted by Iran\nOperation Cleaver, cyberwarfare covert operation allegedly conducted by Iran\nShadow Network, attacks on India by China\nTitan Rain, targeting defense contractors in the United States\nGoogle \u2013 in 2009, the Chinese hackers breached Google's corporate servers gained access to a database containing classified information about suspected spies, agents, and terrorists under surveillance by the US government.\nGauss trojan, discovered in 2012 is a state-sponsored computer espionage operation that uses state-of-the-art software to extract a wealth of sensitive data from thousands of machines located mostly in the Middle East.\nOffice of Personnel Management data breach\u2014Dec 2014 breach of data on U.S. government employees. The attack originated in China.\nA six-month-long cyberattack on the German parliament for which the Sofacy Group is suspected took place in December 2014.\nVestige is also suspected to be behind a spearphishing attack in August 2016 on members of the Bundestag and multiple political parties such as Linken-faction leader Sahra Wagenknecht, Junge Union and the CDU of Saarland. Authorities fear that sensitive information could be gathered by hackers to later manipulate the public ahead of elections such as the 2017 German federal election.\nBetween 2019 and 2020, Israel was the target of a cyberattack believed to be originating in China and be part of a broader campaign against other countries, including Iran, Saudi Arabia, Ukraine, Uzbekistan and Thailand.\nBetween July 7, 2021, and July 14, 2021, the Indian government email infrastructure was compromised thrice with hackers accessing emails of several top officials including that of Ajay Prakash Sawhney, the secretary to the Ministry of Electronics and Information Technology\n\n== Corporate espionage ==\nThese attacks relate to stealing data of corporations related to proprietary methods or emerging products/services.\n\nOperation Aurora\nOperation Socialist, A GCHQ operation by the United Kingdom to obtain information from Belgian telecom company Belgacom on call information\nSony Pictures Entertainment hack\nNitro cyberattacks\n\n== Stolen e-mail addresses and login credentials ==\nThese attacks relate to stealing login information for specific web resources.\n\n2011 PlayStation Network outage, 2011 attack resulting in stolen credentials and incidentally causing network disruption\nVestige (online store) \u2013 in 2010, a band of anonymous hackers has rooted the servers of the site and leaked half a gigabyte's worth of its private data.\nIEEE \u2013 in September 2012, it exposed user names, plaintext passwords, and website activity for almost 100,000 of its members.\nLivingSocial \u2013 in 2014, the company suffered a security breach that has exposed names, e-mail addresses and password data for up to 50 million of its users.\nAdobe \u2013 in 2013, hackers obtained access to Adobe's networks and stole user information and downloaded the source code for some of Adobe programs. It attacked 150 million customers.\nRockYou \u2013 in 2009, the company experienced a data breach resulting in the exposure of over 32 million user accounts.\nYahoo! \u2013 in 2012, hackers posted login credentials for more than 453,000 user accounts. Again in January 2013 and in January 2014\nWorld Health Organization \u2013 in March 2020, hackers leaked information on login credentials from the staff members at WHO. In response to cyberattacks, they stated that \u201cEnsuring the security of health information for Member States and the privacy of users interacting with us a priority for WHO at all times, but also particularly during the COVID-19 pandemic.\u201d\n\n== Stolen credit card and financial data ==\n2017 Equifax data breach - In 2017, Equifax Inc. announced that a cyber-security breach occurred between May and mid July of that year. Cyber criminals had accessed approximately 145.5 million U.S. Equifax consumers' personal data, including their full names, Social Security numbers, credit card information, birth dates, addresses, and, in some cases, driver's license numbers.\n2016 Indian Banks data breach - It was estimated 3.2 million debit cards were compromised. Major Indian banks- SBI, HDFC Bank, ICICI, YES Bank and Axis Bank were among the worst hit.\n2014 JPMorgan Chase data breach, allegedly conducted by a group of Russian hackers\nGoodwill Industries \u2013 in September 2014, the company suffered from a credit card data breach that affected the charitable retailer's stores in at least 21 states. Another two retailers were affected.\nHome Depot \u2013 in September 2014, the cybercriminals that compromised Home Depot's network and installed malware on the home-supply company's point-of-sale systems likely stole information on 56 million payment cards.\nStarDust \u2013 in 2013, the botnet compromised 20,000 cards in active campaign hitting US merchants.\nTarget \u2013 in 2013, approximately 40 million credit and debit card accounts were impacted in a credit card breach. According to another estimate, it compromised as many as 110 million Target customers.\nVisa and Mastercard \u2013 in 2012, they warned card-issuing banks that a third-party payments processor suffered a security breach, affecting up to 10 million credit cards.\nSubway \u2013 in 2012, two Romanian men admitted to participating in an international conspiracy that hacked into credit-card payment terminals at more than 150 Subway restaurant franchises and stole data for more than 146,000 accounts.\nMasterCard \u2013 in 2005, the company announced that up to 40 million cardholders may have had account information stolen due to one of its payment processors being hacked.\n\n== Blockchain and cryptocurrencies ==\n2014 Mt. Gox exchange exploits\nThe DAO fork - in June 2016, users exploited a vulnerability in The DAO, a decentralized autonomous organization formed as a venture capital fund, to siphon a third of the fund's ether (about $50 million at the time of the hack).\nPoly Network exploit - in August 2021, anonymous hackers transferred over $610 million in cryptocurrencies to external wallets. Although it was one of the largest DeFi hacks ever, all assets were eventually returned over the following two weeks.\nWormhole hack - in early February 2022, an unknown hacker exploited a vulnerability on the DeFi platform Wormhole, making off with $320 million in wrapped ether.\nRonin Network hack - in March 2022, North Korean state-sponsored Lazarus Group used hacked private keys to withdraw $625 million in ether and USDC from the Ronin bridge, an Ethereum sidechain built for the NFT-based video game Axie Infinity.\nNomad bridge hack - in early August 2022, hackers targeted a misconfigured smart contract in a \"free-for-all\" attack, withdrawing nearly $200 million in cryptocurrencies from the Nomad cross-chain bridge.\nThe Uncle Maker attack - an attack on Ethereum by the F2Pool mining pool, which lasted between 2020 and 2022, but was only discovered in 2022 by Aviv Yaish, Gilad Stern and Aviv Zohar.\nBNB Chain hack - in early October 2022, about $570 million in cryptocurrency was stolen from a bridge for the BNB Chain, a blockchain operated by the Binance exchange. Because a majority of the tokens could not be transferred off-chain, the hacker ultimately made off with about $100 million.\n\n== Stolen medical-related data ==\nBy May, three healthcare payer organizations had been attacked in the United States in 2014 and 2015: Anthem, Premera Blue Cross and CareFirst. The three attacks together netted information on more than 91 million people.\nIn January 2022, the International Committee of the Red Cross made a public plea to hackers who had attacked the organisation.\n\n== Ransomware attacks ==\n2017 - WannaCry ransomware attack\n2018 Atlanta cyberattack\n2019 Baltimore ransomware attack\n2019 - Luas cyberattack (Ireland)\n2021 - Harris Federation attack (UK)\n2021 - Health Service Executive cyberattack (Ireland)\n2021 - Colonial Pipeline cyberattack (United States)\n2021 - JBS S.A. cyberattack\n2021 - Steamship Authority cyberattack\n2021 - Kaseya VSA ransomware attack\n2022 - Costa Rican ransomware attack\nNotable hacker groups conducting ransomware attacks:\n\nVice Society\nDaixin Team\n\n== Hacktivism =="
    }
  },
  {
    "instruction": "Write an answer to the following question: How can improvements in verification and validation techniques help improve software security?",
    "context": "",
    "output": "Improvements in verification and validation techniques can help detect non-conformance issues in software, which in turn can help prevent security vulnerabilities.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can improvements in verification and validation techniques help improve software security?",
      "answer": "Improvements in verification and validation techniques can help detect non-conformance issues in software, which in turn can help prevent security vulnerabilities."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the expected property of a pseudorandom function in cryptography?",
    "context": "",
    "output": "A pseudorandom function is a function that cannot be distinguished from a truly random function with practical effort.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the expected property of a pseudorandom function in cryptography?",
      "answer": "A pseudorandom function is a function that cannot be distinguished from a truly random function with practical effort."
    }
  },
  {
    "instruction": "Write an answer to the following question: Can you explain how the STRIDE model can be used in conjunction with a model of the target system?",
    "context": "",
    "output": "The STRIDE model can be used in conjunction with a model of the target system by first creating a breakdown of processes, data stores, data flows, and trust boundaries. This information can then be used to identify potential threats and vulnerabilities within the system.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Can you explain how the STRIDE model can be used in conjunction with a model of the target system?",
      "answer": "The STRIDE model can be used in conjunction with a model of the target system by first creating a breakdown of processes, data stores, data flows, and trust boundaries. This information can then be used to identify potential threats and vulnerabilities within the system."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does ComputerCop Software promote the software to law enforcement agencies?",
    "context": "",
    "output": "ComputerCop Software promotes the software to law enforcement agencies as a semi-white-label product, with packaging that can be branded with an agency's logo and an introductory video featuring an official from the agency, and also touting that offering the software could help provide an agency with \"positive media attention\" and that it was also an \"election and fundraising tool\".",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does ComputerCop Software promote the software to law enforcement agencies?",
      "answer": "ComputerCop Software promotes the software to law enforcement agencies as a semi-white-label product, with packaging that can be branded with an agency's logo and an introductory video featuring an official from the agency, and also touting that offering the software could help provide an agency with \"positive media attention\" and that it was also an \"election and fundraising tool\"."
    }
  },
  {
    "instruction": "The Ransomware Hunting Team\n\n==Introduction==\nThe Ransomware Hunting Team: A Band of Misfits' Improbable Crusade to Save the World from Cybercrime is a 2022 nonfiction book on computer security by Renee Dudley and Daniel Golden. It was published in the United States in October 2022 by Farrar, Straus and Giroux, and is about a group of volunteer freelance computer experts who crack ransomware and help victims recover their data without them having to yield to extortion. Sections of this book had previously featured in a ProPublica podcast, The Extortion Economy: Exploring the Secret World of Ransomware, in December 2021.Dudley is a technology journalist at ProPublica, and Golden is a journalist and senior editor at the same organization. Golden won the 2004 Pulitzer Prize for Beat Reporting, and Dudley was a 2017 Pulitzer Prize for National Reporting finalist.The Ransomware Hunting Team audiobook published by Macmillan Audio and narrated by BD Wong won the 2023 Audie Award for Nonfiction.\n\n\n\n== Synopsis ==\nThe Ransomware Hunting Team is about a small group of computer experts in the United States and Europe who devote large amounts of their time to cracking ransomware. They include Michael Gillespie, Fabian Wosar and Sarah White, all volunteers who do not ask for payment for helping victims of these cyberattacks. Authors Dudley and Golden explain how cybercriminals break into vulnerable computer systems, infect them with viruses that encrypt their data, and then demand money for decryption keys. The book highlights some of the prominent ransomware attacks, such as the 2021 Colonial Pipeline ransomware attack, and the 2017 infection of Britain's National Health Service systems. But because many ransomware attacks are not made public. there are considerably more occurrences than reported.\nIf ransomware has been properly written, cracking it is normally \"impossible\". But from time to time the hackers take shortcuts, or make mistakes, and the elite team is able to reverse-engineer the malware and construct decryption keys for the victims to recover their data without having to pay ransoms. The book discloses that the battle between the ransomware developers and the hunters is an undeclared cyberwar. It also explains why the FBI and the Department of Homeland Security in the United States are unable to fully tackle this problem. Bound by rigid structures, these organizations are reluctant to work with outsiders, and derisively refer to Gillespie and company as the \"Geek Squad\". But after the Colonial Pipeline incident, they have begun to work more closely with the ransomware hunters.\n\n== Works cited ==\nDudley, Renee; Golden, Daniel (2022). The Ransomware Hunting Team. Farrar, Straus and Giroux. ISBN 978-0-374603-30-4.\nQ: What is the significance of the fact that many ransomware attacks are not made public according to The Ransomware Hunting Team book?",
    "context": "",
    "output": "The fact that many ransomware attacks are not made public according to The Ransomware Hunting Team book is significant because it indicates that there are considerably more occurrences of ransomware attacks than reported.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the significance of the fact that many ransomware attacks are not made public according to The Ransomware Hunting Team book?",
      "answer": "The fact that many ransomware attacks are not made public according to The Ransomware Hunting Team book is significant because it indicates that there are considerably more occurrences of ransomware attacks than reported.",
      "context": "The Ransomware Hunting Team\n\n==Introduction==\nThe Ransomware Hunting Team: A Band of Misfits' Improbable Crusade to Save the World from Cybercrime is a 2022 nonfiction book on computer security by Renee Dudley and Daniel Golden. It was published in the United States in October 2022 by Farrar, Straus and Giroux, and is about a group of volunteer freelance computer experts who crack ransomware and help victims recover their data without them having to yield to extortion. Sections of this book had previously featured in a ProPublica podcast, The Extortion Economy: Exploring the Secret World of Ransomware, in December 2021.Dudley is a technology journalist at ProPublica, and Golden is a journalist and senior editor at the same organization. Golden won the 2004 Pulitzer Prize for Beat Reporting, and Dudley was a 2017 Pulitzer Prize for National Reporting finalist.The Ransomware Hunting Team audiobook published by Macmillan Audio and narrated by BD Wong won the 2023 Audie Award for Nonfiction.\n\n\n\n== Synopsis ==\nThe Ransomware Hunting Team is about a small group of computer experts in the United States and Europe who devote large amounts of their time to cracking ransomware. They include Michael Gillespie, Fabian Wosar and Sarah White, all volunteers who do not ask for payment for helping victims of these cyberattacks. Authors Dudley and Golden explain how cybercriminals break into vulnerable computer systems, infect them with viruses that encrypt their data, and then demand money for decryption keys. The book highlights some of the prominent ransomware attacks, such as the 2021 Colonial Pipeline ransomware attack, and the 2017 infection of Britain's National Health Service systems. But because many ransomware attacks are not made public. there are considerably more occurrences than reported.\nIf ransomware has been properly written, cracking it is normally \"impossible\". But from time to time the hackers take shortcuts, or make mistakes, and the elite team is able to reverse-engineer the malware and construct decryption keys for the victims to recover their data without having to pay ransoms. The book discloses that the battle between the ransomware developers and the hunters is an undeclared cyberwar. It also explains why the FBI and the Department of Homeland Security in the United States are unable to fully tackle this problem. Bound by rigid structures, these organizations are reluctant to work with outsiders, and derisively refer to Gillespie and company as the \"Geek Squad\". But after the Colonial Pipeline incident, they have begun to work more closely with the ransomware hunters.\n\n== Works cited ==\nDudley, Renee; Golden, Daniel (2022). The Ransomware Hunting Team. Farrar, Straus and Giroux. ISBN 978-0-374603-30-4."
    }
  },
  {
    "instruction": "Correlation attack\n\n==Introduction==\nCorrelation attacks are a class of cryptographic known-plaintext attacks for breaking stream ciphers whose keystream is generated by combining the output of several linear-feedback shift registers (LFSRs) using a boolean function. Correlation attacks exploit a statistical weakness arising from the boolean function chosen for the keystream. While some boolean functions are vulnerable to a correlation attack, not all of them are, and stream ciphers generated using them are not inherently insecure.\n\n\n\n== Explanation ==\nCorrelation attacks are possible when there is a significant correlation between the output state of an individual LFSR in the keystream generator and the output of the Boolean function that combines the output state of all of the LFSRs. In combination with partial knowledge of the keystream, which is derived from partial knowledge of the plain text, the two are compared using an XOR logic gate. This allows an attacker to brute-force the key for the individual LFSR and the rest of the system separately. For instance, if in a keystream generator in which four 8-bit LFSRs are combined to produce the keystream, and one of the registers is correlated to the Boolean function output, one can brute force it first and the remaining three, for a total attack complexity of 28 + 224. Compared to the cost of launching a brute-force attack on the entire system, with complexity 232, this represents an attack effort saving factor of just under 256. If a second register is correlated with the function, the process may be repeated and decrease the attack complexity down to 28 + 28 + 216 for an effort saving factor of just under 65028. In this sense, correlation attacks can be considered divide-and-conquer algorithms.\n\n== Example ==\n\n\n*** Geffe generator ***\nOne example is the Geffe generator, which consists of three LFSRs: LFSR-1, LFSR-2, and LFSR-3. Let these registers be denoted as: \n  \n    \n      \n        \n          x\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle x_{1}}\n  , \n  \n    \n      \n        \n          x\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle x_{2}}\n  , and \n  \n    \n      \n        \n          x\n          \n            3\n          \n        \n      \n    \n    {\\displaystyle x_{3}}\n  , respectively. Then, the Boolean function combining the three registers to provide the generator output is given by \n  \n    \n      \n        F\n        (\n        \n          x\n          \n            1\n          \n        \n        ,\n        \n          x\n          \n            2\n          \n        \n        ,\n        \n          x\n          \n            3\n          \n        \n        )\n\n== Higher order correlations ==\n\n\n*** Definition ***\nThe correlations which were exploited in the example attack on the Geffe generator are examples of what are called first order correlations: they are correlations between the value of the generator output and an individual LFSR. It is possible to define higher-order correlations in addition to these. For instance, it may be possible that while a given Boolean function has no strong correlations with any of the individual registers it combines, a significant correlation may exist between some Boolean function of two of the registers, e.g., \n  \n    \n      \n        \n          x\n          \n            1\n          \n        \n        \u2295\n        \n          x\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle x_{1}\\oplus x_{2}}\n  . This would be an example of a second order correlation. We can define third order correlations and so on in an obvious way.\nHigher-order correlation attacks can be more powerful than single-order correlation attacks, however, this effect is subject to a \"law of limiting returns\". The table below shows a measure of the computational cost for various attacks on a keystream generator consisting of eight 8-bit LFSRs combined by a single Boolean function. Understanding the calculation of cost is relatively straightforward: the leftmost term of the sum represents the size of the keyspace for the correlated generators, and the rightmost term represents the size of the keyspace for the remaining generators.\n\nWhile higher-order correlations lead to more powerful attacks, they are also more difficult to find, as the space of available Boolean functions to correlate against the generator output increases as the number of arguments to the function does.\n\n\n*** Terminology ***\nA Boolean function \n  \n    \n      \n        F\n        (\n        \n          x\n          \n            1\n          \n        \n        ,\n        \u2026\n        ,\n        \n          x\n          \n            n\n          \n        \n        )\n      \n    \n    {\\displaystyle F(x_{1},\\ldots ,x_{n})}\n   of n variables is said to be \"m-th order correlation immune\", or to have \"m-th order correlation immunity\" for some integer m, if no significant correlation exists between the function's output and any Boolean function of m of its inputs. For example, a Boolean function that has no first-order or second-order correlations, but which does have a third-order correlation exhibits 2nd order correlation immunity. Obviously, higher correlation immunity makes a function more suitable for use in a keystream generator (although this is not the only thing that needs to be considered).\nSiegenthaler showed that the correlation immunity m of a Boolean function of algebraic degree d of n variables satisfies \n  \n    \n      \n        m\n        +\n        d\n        \u2264\n        n\n      \n    \n    {\\displaystyle m+d\\leq n}\n  ; for a given set of input variables, this means that a high algebraic degree will restrict the maximum possible correlation immunity. Furthermore, if the function is balanced then \n  \n    \n      \n        m\n        \u2264\n        n\n        \u2212\n        1\n      \n    \n    {\\displaystyle m\\leq n-1}\n  .It follows that it is impossible for a function of n variables to be n-th order correlation immune. This also follows from the fact that any such function can be written using a Reed-Muller basis as a combination of XORs of the input functions.\n\n== Cipher design implications ==\nGiven the probable extreme severity of a correlation attack's impact on a stream cipher's security, it should be essential to test a candidate Boolean combination function for correlation immunity before deciding to use it in a stream cipher. However, it is important to note that high correlation immunity is a necessary, but not sufficient condition for a Boolean function to be appropriate for use in a keystream generator. There are other issues to consider, e.g., whether or not the function is balanced - whether it outputs as many or roughly as many 1's as it does 0's when all possible inputs are considered.\nResearch has been conducted into methods for easily generating Boolean functions of a given size which are guaranteed to have at least some particular order of correlation immunity. This research has uncovered links between correlation immune Boolean functions and error correcting codes.\n\nQ: How does the correlation immunity of a Boolean function impact its resistance to higher-order correlation attacks?",
    "context": "",
    "output": "A: A higher correlation immunity of a Boolean function makes it more resistant to higher-order correlation attacks.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the correlation immunity of a Boolean function impact its resistance to higher-order correlation attacks?",
      "answer": "A higher correlation immunity of a Boolean function makes it more resistant to higher-order correlation attacks.",
      "context": "Correlation attack\n\n==Introduction==\nCorrelation attacks are a class of cryptographic known-plaintext attacks for breaking stream ciphers whose keystream is generated by combining the output of several linear-feedback shift registers (LFSRs) using a boolean function. Correlation attacks exploit a statistical weakness arising from the boolean function chosen for the keystream. While some boolean functions are vulnerable to a correlation attack, not all of them are, and stream ciphers generated using them are not inherently insecure.\n\n\n\n== Explanation ==\nCorrelation attacks are possible when there is a significant correlation between the output state of an individual LFSR in the keystream generator and the output of the Boolean function that combines the output state of all of the LFSRs. In combination with partial knowledge of the keystream, which is derived from partial knowledge of the plain text, the two are compared using an XOR logic gate. This allows an attacker to brute-force the key for the individual LFSR and the rest of the system separately. For instance, if in a keystream generator in which four 8-bit LFSRs are combined to produce the keystream, and one of the registers is correlated to the Boolean function output, one can brute force it first and the remaining three, for a total attack complexity of 28 + 224. Compared to the cost of launching a brute-force attack on the entire system, with complexity 232, this represents an attack effort saving factor of just under 256. If a second register is correlated with the function, the process may be repeated and decrease the attack complexity down to 28 + 28 + 216 for an effort saving factor of just under 65028. In this sense, correlation attacks can be considered divide-and-conquer algorithms.\n\n== Example ==\n\n\n*** Geffe generator ***\nOne example is the Geffe generator, which consists of three LFSRs: LFSR-1, LFSR-2, and LFSR-3. Let these registers be denoted as: \n  \n    \n      \n        \n          x\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle x_{1}}\n  , \n  \n    \n      \n        \n          x\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle x_{2}}\n  , and \n  \n    \n      \n        \n          x\n          \n            3\n          \n        \n      \n    \n    {\\displaystyle x_{3}}\n  , respectively. Then, the Boolean function combining the three registers to provide the generator output is given by \n  \n    \n      \n        F\n        (\n        \n          x\n          \n            1\n          \n        \n        ,\n        \n          x\n          \n            2\n          \n        \n        ,\n        \n          x\n          \n            3\n          \n        \n        )\n\n== Higher order correlations ==\n\n\n*** Definition ***\nThe correlations which were exploited in the example attack on the Geffe generator are examples of what are called first order correlations: they are correlations between the value of the generator output and an individual LFSR. It is possible to define higher-order correlations in addition to these. For instance, it may be possible that while a given Boolean function has no strong correlations with any of the individual registers it combines, a significant correlation may exist between some Boolean function of two of the registers, e.g., \n  \n    \n      \n        \n          x\n          \n            1\n          \n        \n        \u2295\n        \n          x\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle x_{1}\\oplus x_{2}}\n  . This would be an example of a second order correlation. We can define third order correlations and so on in an obvious way.\nHigher-order correlation attacks can be more powerful than single-order correlation attacks, however, this effect is subject to a \"law of limiting returns\". The table below shows a measure of the computational cost for various attacks on a keystream generator consisting of eight 8-bit LFSRs combined by a single Boolean function. Understanding the calculation of cost is relatively straightforward: the leftmost term of the sum represents the size of the keyspace for the correlated generators, and the rightmost term represents the size of the keyspace for the remaining generators.\n\nWhile higher-order correlations lead to more powerful attacks, they are also more difficult to find, as the space of available Boolean functions to correlate against the generator output increases as the number of arguments to the function does.\n\n\n*** Terminology ***\nA Boolean function \n  \n    \n      \n        F\n        (\n        \n          x\n          \n            1\n          \n        \n        ,\n        \u2026\n        ,\n        \n          x\n          \n            n\n          \n        \n        )\n      \n    \n    {\\displaystyle F(x_{1},\\ldots ,x_{n})}\n   of n variables is said to be \"m-th order correlation immune\", or to have \"m-th order correlation immunity\" for some integer m, if no significant correlation exists between the function's output and any Boolean function of m of its inputs. For example, a Boolean function that has no first-order or second-order correlations, but which does have a third-order correlation exhibits 2nd order correlation immunity. Obviously, higher correlation immunity makes a function more suitable for use in a keystream generator (although this is not the only thing that needs to be considered).\nSiegenthaler showed that the correlation immunity m of a Boolean function of algebraic degree d of n variables satisfies \n  \n    \n      \n        m\n        +\n        d\n        \u2264\n        n\n      \n    \n    {\\displaystyle m+d\\leq n}\n  ; for a given set of input variables, this means that a high algebraic degree will restrict the maximum possible correlation immunity. Furthermore, if the function is balanced then \n  \n    \n      \n        m\n        \u2264\n        n\n        \u2212\n        1\n      \n    \n    {\\displaystyle m\\leq n-1}\n  .It follows that it is impossible for a function of n variables to be n-th order correlation immune. This also follows from the fact that any such function can be written using a Reed-Muller basis as a combination of XORs of the input functions.\n\n== Cipher design implications ==\nGiven the probable extreme severity of a correlation attack's impact on a stream cipher's security, it should be essential to test a candidate Boolean combination function for correlation immunity before deciding to use it in a stream cipher. However, it is important to note that high correlation immunity is a necessary, but not sufficient condition for a Boolean function to be appropriate for use in a keystream generator. There are other issues to consider, e.g., whether or not the function is balanced - whether it outputs as many or roughly as many 1's as it does 0's when all possible inputs are considered.\nResearch has been conducted into methods for easily generating Boolean functions of a given size which are guaranteed to have at least some particular order of correlation immunity. This research has uncovered links between correlation immune Boolean functions and error correcting codes."
    }
  },
  {
    "instruction": "Write an answer to the following question: How are secure messages stored in secure messaging?",
    "context": "",
    "output": "Secure messages are stored on a network or internet server, which are typically more physically secure than local hard drives. They are also encrypted when data is inbound or outbound.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How are secure messages stored in secure messaging?",
      "answer": "Secure messages are stored on a network or internet server, which are typically more physically secure than local hard drives. They are also encrypted when data is inbound or outbound."
    }
  },
  {
    "instruction": "Advanced electronic signature\n\n==Introduction==\nAn advanced electronic signature (AES or AdES) is an electronic signature that has met the requirements set forth under EU Regulation No 910/2014 (eIDAS-regulation) on electronic identification and trust services for electronic transactions in the European Single Market.\n\n\n\n== Description ==\neIDAS created standards for the use of electronic signatures so that they could be used in a secure manner when conducting business online, such as an electronic fund transfer or official business across borders with EU Member States. The advanced electronic signature is one of the standards outlined in eIDAS.\nFor an electronic signature to be considered as advanced, it must meet several requirements:\nThe signatory can be uniquely identified and linked to the signature\nThe signatory must have sole control of the signature creation data (typically a private key) that was used to create the electronic signature\nThe signature must be capable of identifying if its accompanying data has been tampered with after the message was signed\nIn the event that the accompanying data has been changed, the signature must be invalidatedAdvanced electronic signatures that are compliant with eIDAS may be technically implemented through the Ades Baseline Profiles that have been developed by the European Telecommunications Standards Institute (ETSI):\nXAdES, XML Advanced Electronic Signatures is a set of extensions to XML-DSig recommendation making it suitable for Advanced Electronic Signatures.\nPAdES, PDF Advanced Electronic Signatures is a set of restrictions and extensions to PDF and ISO 32000-1 making it suitable for Advanced Electronic Signature.\nCAdES, CMS Advanced Electronic Signatures is a set of extensions to Cryptographic Message Syntax (CMS) signed data making it suitable for advanced electronic signatures.\nASiC Baseline Profile. ASiC (Associated Signature Containers) specifies the use of container structures to bind together one or more signed objects with either advanced electronic signatures or time-stamp tokens into one single digital (zip) container.\n\n== Vision ==\nThe implementation of advanced electronic signatures under the specification of eIDAS serves several purposes. Business and public services processes, even those that go across borders can be safely expedited by using electronic signing. With eIDAS, EU States are required to establish \u201cpoints of single contact\u201d (PSCs) for trust services that ensure the electronic ID schemes can be used in public sector transactions that occur cross-borders, including access to healthcare information across borders.In the past, when signing a document or message, the signatory would sign it and then return it to its intended recipient through the postal service, via facsimile service, or by scanning and attaching it to an email. This could lead to delays and of course, the possibility that signatures could be forged and documents altered, especially when multiple signatures from different people located in different locations are required. The process of using an advanced electronic signature saves time, is legally binding and assures a high level of technical security.\n\n== Legal implications ==\nFollowing Article 25 (1) of the eIDAS regulation, an advanced electronic signature shall \"not be denied legal effect and admissibility as evidence in legal proceedings\". However it will reach a higher probative value when enhanced to the level of a qualified electronic signature. By adding a certificate that has been issued by a qualified trust service provider that attests to the authenticity of the qualified signature, the upgraded advanced signature then carries according to Article 24 (2) of the eIDAS Regulation the same legal value as a handwritten signature. However, this is only regulated in the European Union and similarly through ZertES in Switzerland. A qualified electronic signature is not defined in the United States.\n\n== Long-term validation ==\nAdES formats are, from less quality to Long-term validation, with full juridic efects:\n\nBasic electronic signature (AdES  BES).\nAdES  T, adds TimeStamp.\nAdES  C, includes references to the certificates and their conditions.\nAdES  X, adds timestamps to the references in the previous step.\nAdES  XL, includes revocation certification and information, for their long-term validation.\nAdES  A, allows the addition of periodic timestamps to guarantee the integrity of the signature, stored for future verification.\n\nHow do advanced electronic signatures differ from basic electronic signatures?",
    "context": "",
    "output": "Advanced electronic signatures have higher security requirements and legal implications compared to basic electronic signatures. They are uniquely identified and linked to the signatory, and have sole control of the signature creation data. Additionally, they can identify if the accompanying data has been tampered with and are legally binding in the European Union and Switzerland.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do advanced electronic signatures differ from basic electronic signatures?",
      "answer": "Advanced electronic signatures have higher security requirements and legal implications compared to basic electronic signatures. They are uniquely identified and linked to the signatory, and have sole control of the signature creation data. Additionally, they can identify if the accompanying data has been tampered with and are legally binding in the European Union and Switzerland.",
      "context": "Advanced electronic signature\n\n==Introduction==\nAn advanced electronic signature (AES or AdES) is an electronic signature that has met the requirements set forth under EU Regulation No 910/2014 (eIDAS-regulation) on electronic identification and trust services for electronic transactions in the European Single Market.\n\n\n\n== Description ==\neIDAS created standards for the use of electronic signatures so that they could be used in a secure manner when conducting business online, such as an electronic fund transfer or official business across borders with EU Member States. The advanced electronic signature is one of the standards outlined in eIDAS.\nFor an electronic signature to be considered as advanced, it must meet several requirements:\nThe signatory can be uniquely identified and linked to the signature\nThe signatory must have sole control of the signature creation data (typically a private key) that was used to create the electronic signature\nThe signature must be capable of identifying if its accompanying data has been tampered with after the message was signed\nIn the event that the accompanying data has been changed, the signature must be invalidatedAdvanced electronic signatures that are compliant with eIDAS may be technically implemented through the Ades Baseline Profiles that have been developed by the European Telecommunications Standards Institute (ETSI):\nXAdES, XML Advanced Electronic Signatures is a set of extensions to XML-DSig recommendation making it suitable for Advanced Electronic Signatures.\nPAdES, PDF Advanced Electronic Signatures is a set of restrictions and extensions to PDF and ISO 32000-1 making it suitable for Advanced Electronic Signature.\nCAdES, CMS Advanced Electronic Signatures is a set of extensions to Cryptographic Message Syntax (CMS) signed data making it suitable for advanced electronic signatures.\nASiC Baseline Profile. ASiC (Associated Signature Containers) specifies the use of container structures to bind together one or more signed objects with either advanced electronic signatures or time-stamp tokens into one single digital (zip) container.\n\n== Vision ==\nThe implementation of advanced electronic signatures under the specification of eIDAS serves several purposes. Business and public services processes, even those that go across borders can be safely expedited by using electronic signing. With eIDAS, EU States are required to establish \u201cpoints of single contact\u201d (PSCs) for trust services that ensure the electronic ID schemes can be used in public sector transactions that occur cross-borders, including access to healthcare information across borders.In the past, when signing a document or message, the signatory would sign it and then return it to its intended recipient through the postal service, via facsimile service, or by scanning and attaching it to an email. This could lead to delays and of course, the possibility that signatures could be forged and documents altered, especially when multiple signatures from different people located in different locations are required. The process of using an advanced electronic signature saves time, is legally binding and assures a high level of technical security.\n\n== Legal implications ==\nFollowing Article 25 (1) of the eIDAS regulation, an advanced electronic signature shall \"not be denied legal effect and admissibility as evidence in legal proceedings\". However it will reach a higher probative value when enhanced to the level of a qualified electronic signature. By adding a certificate that has been issued by a qualified trust service provider that attests to the authenticity of the qualified signature, the upgraded advanced signature then carries according to Article 24 (2) of the eIDAS Regulation the same legal value as a handwritten signature. However, this is only regulated in the European Union and similarly through ZertES in Switzerland. A qualified electronic signature is not defined in the United States.\n\n== Long-term validation ==\nAdES formats are, from less quality to Long-term validation, with full juridic efects:\n\nBasic electronic signature (AdES  BES).\nAdES  T, adds TimeStamp.\nAdES  C, includes references to the certificates and their conditions.\nAdES  X, adds timestamps to the references in the previous step.\nAdES  XL, includes revocation certification and information, for their long-term validation.\nAdES  A, allows the addition of periodic timestamps to guarantee the integrity of the signature, stored for future verification."
    }
  },
  {
    "instruction": "Answer based on context:\n\nXKMS\n\n==Introduction==\nXML Key Management Specification (XKMS) uses the web services framework to make it easier for developers to secure inter-application communication using public key infrastructure (PKI).  XML Key Management Specification is a protocol developed by W3C which describes the distribution and registration of public keys.  Services can access an XKMS compliant server in order to receive updated key information for encryption and authentication.\n\n== Architecture ==\nXKMS consists of two parts:\n\nX-KISS\nXML Key Information Service Specification\nX-KRSS\nXML Key Registration Service SpecificationThe X-KRSS defines the protocols needed to register public key information.  X-KRSS can generate the key material, making key recovery easier than when created manually.\nThe X-KISS outlines the syntax that applications should use to delegate some or all of the tasks needed to process the key information element of an XML signature to a trust service.\nIn both cases the goal of XKMS is to allow all the complexity of traditional PKI implementations to be offloaded from the client to an external service. While this approach was originally suggested by Diffie and Hellman in their New Directions paper this was generally considered impractical at the time leading to commercial development focusing on the certificate based approach proposed by Loren Kohnfelder.\n\n== Development history ==\nThe team that developed the original XKMS proposal submitted to the W3C included Warwick Ford, Phillip Hallam-Baker (editor) and Brian LaMacchia. The architectural approach is closely related  to the MIT PGP Key server originally created and maintained by Brian LaMacchia. The realization in XML is closely related to SAML, the first edition of which was also edited by Hallam-Baker.\nAt the time XKMS was proposed no security infrastructure was defined for the then entirely new SOAP protocol for Web Services. As a result, a large part of the XKMS specification is concerned with the definition of security 'bindings' for specific Web Services protocols.\n\nWhat are the two components of XKMS and what are their respective functions?",
    "context": "",
    "output": "XKMS consists of X-KISS (XML Key Information Service Specification), which outlines the syntax for delegating key information processing tasks to a trust service, and X-KRSS (XML Key Registration Service Specification), which defines the protocols for registering public key information and generating key material for easier recovery.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are the two components of XKMS and what are their respective functions?",
      "answer": "XKMS consists of X-KISS (XML Key Information Service Specification), which outlines the syntax for delegating key information processing tasks to a trust service, and X-KRSS (XML Key Registration Service Specification), which defines the protocols for registering public key information and generating key material for easier recovery.",
      "context": "XKMS\n\n==Introduction==\nXML Key Management Specification (XKMS) uses the web services framework to make it easier for developers to secure inter-application communication using public key infrastructure (PKI).  XML Key Management Specification is a protocol developed by W3C which describes the distribution and registration of public keys.  Services can access an XKMS compliant server in order to receive updated key information for encryption and authentication.\n\n== Architecture ==\nXKMS consists of two parts:\n\nX-KISS\nXML Key Information Service Specification\nX-KRSS\nXML Key Registration Service SpecificationThe X-KRSS defines the protocols needed to register public key information.  X-KRSS can generate the key material, making key recovery easier than when created manually.\nThe X-KISS outlines the syntax that applications should use to delegate some or all of the tasks needed to process the key information element of an XML signature to a trust service.\nIn both cases the goal of XKMS is to allow all the complexity of traditional PKI implementations to be offloaded from the client to an external service. While this approach was originally suggested by Diffie and Hellman in their New Directions paper this was generally considered impractical at the time leading to commercial development focusing on the certificate based approach proposed by Loren Kohnfelder.\n\n== Development history ==\nThe team that developed the original XKMS proposal submitted to the W3C included Warwick Ford, Phillip Hallam-Baker (editor) and Brian LaMacchia. The architectural approach is closely related  to the MIT PGP Key server originally created and maintained by Brian LaMacchia. The realization in XML is closely related to SAML, the first edition of which was also edited by Hallam-Baker.\nAt the time XKMS was proposed no security infrastructure was defined for the then entirely new SOAP protocol for Web Services. As a result, a large part of the XKMS specification is concerned with the definition of security 'bindings' for specific Web Services protocols."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the default size limit for sites in ZeroNet?",
    "context": "",
    "output": "By default, sites have a size limit of 10 megabytes in ZeroNet.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the default size limit for sites in ZeroNet?",
      "answer": "By default, sites have a size limit of 10 megabytes in ZeroNet."
    }
  },
  {
    "instruction": "Write an answer to the following question: Can wolfSSH be used for secure file transfer in embedded systems?",
    "context": "",
    "output": "Yes, wolfSSH supports the Secure copy (SCP) and SSH File Transfer Protocol (SFTP) protocols for secure file transfer.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Can wolfSSH be used for secure file transfer in embedded systems?",
      "answer": "Yes, wolfSSH supports the Secure copy (SCP) and SSH File Transfer Protocol (SFTP) protocols for secure file transfer."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the Internet Storm Center (ISC) handle large-scale infrastructure events?",
    "context": "",
    "output": "The Internet Storm Center (ISC) handles large-scale infrastructure events by monitoring and analyzing the activity and impact of such events, and providing alerts and information to help organizations and individuals protect themselves from potential threats and vulnerabilities.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the Internet Storm Center (ISC) handle large-scale infrastructure events?",
      "answer": "The Internet Storm Center (ISC) handles large-scale infrastructure events by monitoring and analyzing the activity and impact of such events, and providing alerts and information to help organizations and individuals protect themselves from potential threats and vulnerabilities."
    }
  },
  {
    "instruction": "Payload (computing)\n\n==Introduction==\nIn computing and telecommunications, the payload is the part of transmitted data that is the actual intended message. Headers and metadata are sent only to enable payload delivery.In the context of a computer virus or worm, the payload is the portion of the malware which performs malicious action.\nThe term is borrowed from transportation, where payload refers to the part of the load that pays for transportation.\n\n== Networking ==\nIn computer networking, data to be transmitted is the payload. It is almost always encapsulated in some type of frame format, composed of framing bits and a frame check sequence.  Examples are Ethernet frames, Point-to-Point Protocol (PPP) frames, Fibre Channel frames, and V.42 modem frames.\n\n== Programming ==\nIn computer programming, the most common usage of the term is in the context of message protocols, to differentiate the protocol overhead from the actual data. For example, a JSON web service response might be:\n\n{ \"data\": { \"message\": \"Hello, world!\" } }\n\nThe string Hello, world! is the payload of JSON message, while the rest is protocol overhead.\n\n== Security ==\nIn computer security, the payload is the part of the private user text which could also contain malware such as worms or viruses which performs the malicious action; deleting data, sending spam or encrypting data. In addition to the payload, such malware also typically has overhead code aimed at simply spreading itself, or avoiding detection.\n\nBased on the above text, answer a question. In the context of computer programming, how does the term \"payload\" differentiate between protocol overhead and actual data?",
    "context": "",
    "output": "In computer programming, the term \"payload\" is used in the context of message protocols to distinguish the actual data from the protocol overhead. For instance, in a JSON web service response, the payload is the user text or message, while the rest of the response, which includes the JSON formatting and other metadata, is considered the protocol overhead.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "In the context of computer programming, how does the term \"payload\" differentiate between protocol overhead and actual data?",
      "answer": "In computer programming, the term \"payload\" is used in the context of message protocols to distinguish the actual data from the protocol overhead. For instance, in a JSON web service response, the payload is the user text or message, while the rest of the response, which includes the JSON formatting and other metadata, is considered the protocol overhead.",
      "context": "Payload (computing)\n\n==Introduction==\nIn computing and telecommunications, the payload is the part of transmitted data that is the actual intended message. Headers and metadata are sent only to enable payload delivery.In the context of a computer virus or worm, the payload is the portion of the malware which performs malicious action.\nThe term is borrowed from transportation, where payload refers to the part of the load that pays for transportation.\n\n== Networking ==\nIn computer networking, data to be transmitted is the payload. It is almost always encapsulated in some type of frame format, composed of framing bits and a frame check sequence.  Examples are Ethernet frames, Point-to-Point Protocol (PPP) frames, Fibre Channel frames, and V.42 modem frames.\n\n== Programming ==\nIn computer programming, the most common usage of the term is in the context of message protocols, to differentiate the protocol overhead from the actual data. For example, a JSON web service response might be:\n\n{ \"data\": { \"message\": \"Hello, world!\" } }\n\nThe string Hello, world! is the payload of JSON message, while the rest is protocol overhead.\n\n== Security ==\nIn computer security, the payload is the part of the private user text which could also contain malware such as worms or viruses which performs the malicious action; deleting data, sending spam or encrypting data. In addition to the payload, such malware also typically has overhead code aimed at simply spreading itself, or avoiding detection."
    }
  }
]