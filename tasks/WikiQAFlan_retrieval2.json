[
  {
    "instruction": "The Treasury Department said that Trump's personal attorney Rudy Giuliani collaborated with active Russian agent Andrii Derkach, a Ukrainian lawmaker, to spread anti-Biden material during Trump's impeachment.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What did the Treasury Department say about Trump's personal attorney Rudy Giuliani and active Russian agent Andrii Derkach?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What did the Treasury Department say about Trump's personal attorney Rudy Giuliani and active Russian agent Andrii Derkach?",
      "answer": "The Treasury Department said that Trump's personal attorney Rudy Giuliani collaborated with active Russian agent Andrii Derkach, a Ukrainian lawmaker, to spread anti-Biden material during Trump's impeachment."
    }
  },
  {
    "instruction": "Strong secrecy is related to the concept of semantic security or indistinguishability used in the computational proof-based approach. Semantic security ensures that the adversary cannot learn any useful information about the plaintext message from the ciphertext, while indistinguishability ensures that the adversary cannot distinguish between two encrypted messages, even if they know the corresponding plaintext messages. Strong secrecy implies both semantic security and indistinguishability, providing a stronger notion of security in computational proof-based cryptography.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does strong secrecy relate to the concept of semantic security or indistinguishability in computational proof-based approach?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does strong secrecy relate to the concept of semantic security or indistinguishability in computational proof-based approach?",
      "answer": "Strong secrecy is related to the concept of semantic security or indistinguishability used in the computational proof-based approach. Semantic security ensures that the adversary cannot learn any useful information about the plaintext message from the ciphertext, while indistinguishability ensures that the adversary cannot distinguish between two encrypted messages, even if they know the corresponding plaintext messages. Strong secrecy implies both semantic security and indistinguishability, providing a stronger notion of security in computational proof-based cryptography."
    }
  },
  {
    "instruction": "Context: Citadel (malware)\n\n==Introduction==\nCitadel is a piece of massively-distributed malware based upon Zeus. It targets credentials stored in password managers such as Keepass, Password Safe and neXus Personal Security Client.By 2017 (it was first identified in 2011) Citadel had infected about 11 million computers worldwide and had caused over $500 million in losses.On March 20, 2017, having been extradited from Norway to the United States, a Russian computer science professional Mark Vartanyan pleaded guilty to a computer fraud charge for his part in developing the Control Panel for Citadel. In July 2017, he was sentenced to 5 years in federal prison.\n\n\n\n\nQuestion: How does Citadel malware infiltrate password managers and what kind of losses has it caused?. Whats the answer?",
    "context": "",
    "output": "Citadel malware is designed to target credentials stored in password managers such as Keepass, Password Safe, and neXus Personal Security Client. It has infected around 11 million computers worldwide and caused over $500 million in losses by 2017.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does Citadel malware infiltrate password managers and what kind of losses has it caused?",
      "answer": "Citadel malware is designed to target credentials stored in password managers such as Keepass, Password Safe, and neXus Personal Security Client. It has infected around 11 million computers worldwide and caused over $500 million in losses by 2017.",
      "context": "Citadel (malware)\n\n==Introduction==\nCitadel is a piece of massively-distributed malware based upon Zeus. It targets credentials stored in password managers such as Keepass, Password Safe and neXus Personal Security Client.By 2017 (it was first identified in 2011) Citadel had infected about 11 million computers worldwide and had caused over $500 million in losses.On March 20, 2017, having been extradited from Norway to the United States, a Russian computer science professional Mark Vartanyan pleaded guilty to a computer fraud charge for his part in developing the Control Panel for Citadel. In July 2017, he was sentenced to 5 years in federal prison.\n\n\n\n"
    }
  },
  {
    "instruction": "Operation High Roller had a significant impact on the banking industry, resulting in the loss of approximately $78 million and highlighting the need for improved cyber security measures.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How did Operation High Roller impact the banking industry?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How did Operation High Roller impact the banking industry?",
      "answer": "Operation High Roller had a significant impact on the banking industry, resulting in the loss of approximately $78 million and highlighting the need for improved cyber security measures."
    }
  },
  {
    "instruction": "UUNET\n\n==Introduction==\nUUNET, founded in 1987, was one of the largest Internet service providers and one of the early Tier 1 networks.  It was based in Northern Virginia and was one of the first commercial Internet service providers.  Today, UUNET is an internal brand of Verizon Business (formerly MCI).\n\n\n\n== Spam ==\nAfter it had been sold and resold during the onset of the dot-com bubble, UUNET acquired the nickname SpewSpewNET. This nickname was given because UUNET had become a home for many distributors of spam, including distributors of both Newsgroup spam and E-mail spam. UUNET also became known for providing bulletproof hosting to many web pages whose chief form of advertisement was spam. Because UUNET started with a loan from Usenix and controlled the e-mail addresses for moderated Usenet groups, it was hard to block email traffic to or from Usenet. In 1997, UUNET had lost so much credit that on 1 August, after finding alternate routes for moderated newsgroups, a Usenet death penalty (UDP) was issued against UUNET. A week later, the UDP was lifted. In 1998 UUNET threatened legal action for hosting a GIF image with \"SPAMUNET\" on it.\n\n== Timeline ==\n1987 \u2013 UUNET Communications Services is founded and passes its first traffic via the CompuServe Network on 12 May using UUCP (Unix to Unix Copy Protocol).\n1989 \u2013 UUNET becomes a for-profit corporation\n1990 \u2013 UUNET launches AlterNet\n1991 \u2013 UUNET participates in the founding of the Commercial Internet Exchange Association\n1992 - UUNET with MFS co-creates MAE-East, for a time the world's busiest Internet exchange and \"center of the internet\"\n1994 \u2013 Microsoft paid $16.4 million for a 15 percent share of the company\n1995 \u2013 In May, UUNET is listed on the NASDAQ stock market in an initial public offering that would become part of the beginning of the dot-com boom.\n1995 \u2013 UUNET Technologies Inc places a takeover bid against Unipalm Pipex.\n1996 \u2013 UUNET Technologies agreed to a merger with the Microsoft backed MFS Communications Company.\n1996 \u2013 Metropolitan Fiber Systems (MFS) acquires UUNET for $2 Billion on 12 August 1996. This marked the day UUNET stopped existing as an independent company.\n1996 \u2013 WorldCom acquires MFS on New Year's Eve \u2013 31 Dec. at 11:58 p.m EST for $12.4 billion\n1997 \u2013 Usenet death penalty (UDP) issued against UUNET, and lifted a week later\n1997 \u2013 On 10 November, WorldCom and MCI announced their US$37 billion merger including combining internetMCI & UUNET Internet operations.\n1998 \u2013 The combined MCI WorldCom opens for business on 15 September after being given the go-ahead from the DOJ, subsequent to divesting internet MCI.\n1998 \u2013 WorldCom acquires CompuServe Network Services from H&R Block and ANS Communications from AOL. Both become part of UUNET in 1999.\n1999 \u2013 On 5 October, MCI Worldcom announces its intentions to buy Sprint for $129 billion.\n2000 \u2013 The European Commission and DOJ denied the MCI WorldCom / Sprint merger on Antitrust Grounds.\n2001 \u2013 The UUNET brand is folded into WorldCom's product line and disappears\n2002 \u2013 WorldCom files for Chapter 11 bankruptcy protection as a result of a massive $11 billion accounting scandal.\n2003 \u2013 The UUNET brand re-emerges as WorldCom's wholesale-only brand.\n2004 \u2013 WorldCom emerges from Chapter 11 bankruptcy and renames itself to MCI, still using the UUNET brand for wholesale business.\n2005 \u2013 MCI again drops the UUNET brand for wholesale business. The name is no longer in use.\n2006 \u2013 Verizon acquires MCI, including its UUNET subsidiary, now known as Verizon Business. AS701 remains the backbone of Verizon Business although its origin dates back to 1990 when it was under the UUNET flag.\n\nAnswer this question \"What was the impact of UUNET's death penalty (UDP) on the Usenet community in 1997?\" using the text above.",
    "context": "",
    "output": "UUNET's death penalty (UDP) in 1997 had a significant impact on the Usenet community, as it disrupted email traffic and forced the community to find alternate routes for moderated newsgroups, causing temporary chaos and disruption.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What was the impact of UUNET's death penalty (UDP) on the Usenet community in 1997?",
      "answer": "UUNET's death penalty (UDP) in 1997 had a significant impact on the Usenet community, as it disrupted email traffic and forced the community to find alternate routes for moderated newsgroups, causing temporary chaos and disruption.",
      "context": "UUNET\n\n==Introduction==\nUUNET, founded in 1987, was one of the largest Internet service providers and one of the early Tier 1 networks.  It was based in Northern Virginia and was one of the first commercial Internet service providers.  Today, UUNET is an internal brand of Verizon Business (formerly MCI).\n\n\n\n== Spam ==\nAfter it had been sold and resold during the onset of the dot-com bubble, UUNET acquired the nickname SpewSpewNET. This nickname was given because UUNET had become a home for many distributors of spam, including distributors of both Newsgroup spam and E-mail spam. UUNET also became known for providing bulletproof hosting to many web pages whose chief form of advertisement was spam. Because UUNET started with a loan from Usenix and controlled the e-mail addresses for moderated Usenet groups, it was hard to block email traffic to or from Usenet. In 1997, UUNET had lost so much credit that on 1 August, after finding alternate routes for moderated newsgroups, a Usenet death penalty (UDP) was issued against UUNET. A week later, the UDP was lifted. In 1998 UUNET threatened legal action for hosting a GIF image with \"SPAMUNET\" on it.\n\n== Timeline ==\n1987 \u2013 UUNET Communications Services is founded and passes its first traffic via the CompuServe Network on 12 May using UUCP (Unix to Unix Copy Protocol).\n1989 \u2013 UUNET becomes a for-profit corporation\n1990 \u2013 UUNET launches AlterNet\n1991 \u2013 UUNET participates in the founding of the Commercial Internet Exchange Association\n1992 - UUNET with MFS co-creates MAE-East, for a time the world's busiest Internet exchange and \"center of the internet\"\n1994 \u2013 Microsoft paid $16.4 million for a 15 percent share of the company\n1995 \u2013 In May, UUNET is listed on the NASDAQ stock market in an initial public offering that would become part of the beginning of the dot-com boom.\n1995 \u2013 UUNET Technologies Inc places a takeover bid against Unipalm Pipex.\n1996 \u2013 UUNET Technologies agreed to a merger with the Microsoft backed MFS Communications Company.\n1996 \u2013 Metropolitan Fiber Systems (MFS) acquires UUNET for $2 Billion on 12 August 1996. This marked the day UUNET stopped existing as an independent company.\n1996 \u2013 WorldCom acquires MFS on New Year's Eve \u2013 31 Dec. at 11:58 p.m EST for $12.4 billion\n1997 \u2013 Usenet death penalty (UDP) issued against UUNET, and lifted a week later\n1997 \u2013 On 10 November, WorldCom and MCI announced their US$37 billion merger including combining internetMCI & UUNET Internet operations.\n1998 \u2013 The combined MCI WorldCom opens for business on 15 September after being given the go-ahead from the DOJ, subsequent to divesting internet MCI.\n1998 \u2013 WorldCom acquires CompuServe Network Services from H&R Block and ANS Communications from AOL. Both become part of UUNET in 1999.\n1999 \u2013 On 5 October, MCI Worldcom announces its intentions to buy Sprint for $129 billion.\n2000 \u2013 The European Commission and DOJ denied the MCI WorldCom / Sprint merger on Antitrust Grounds.\n2001 \u2013 The UUNET brand is folded into WorldCom's product line and disappears\n2002 \u2013 WorldCom files for Chapter 11 bankruptcy protection as a result of a massive $11 billion accounting scandal.\n2003 \u2013 The UUNET brand re-emerges as WorldCom's wholesale-only brand.\n2004 \u2013 WorldCom emerges from Chapter 11 bankruptcy and renames itself to MCI, still using the UUNET brand for wholesale business.\n2005 \u2013 MCI again drops the UUNET brand for wholesale business. The name is no longer in use.\n2006 \u2013 Verizon acquires MCI, including its UUNET subsidiary, now known as Verizon Business. AS701 remains the backbone of Verizon Business although its origin dates back to 1990 when it was under the UUNET flag."
    }
  },
  {
    "instruction": "Token Binding\n\n==Introduction==\nToken Binding is a proposed standard for a Transport Layer Security (TLS) extension that aims to increase TLS security by using cryptographic certificates on both ends of the TLS connection. Current practice often depends on bearer tokens, which may be lost or stolen. Bearer tokens are also vulnerable to man-in-the-middle attacks or replay attacks. In contrast, bound tokens are established by a user agent that generates a private-public key pair per target server, providing the public key to the server, and thereafter proving possession of the corresponding private key on every TLS connection to the server.\nToken Binding is an evolution of the Transport Layer Security Channel ID (previously known as Transport Layer Security \u2013 Origin Bound Certificates (TLS-OBC)) extension.\nIndustry participation is widespread with standards contributors including Microsoft, Google, PayPal, Ping Identity, and Yubico. Browser support remains limited, however. Only Microsoft Edge has support for token binding.\n\n\n\n== IETF standards ==\nThe following group of IETF RFCs and Internet Drafts comprise a set of interrelated specifications for implementing different aspects of the Token Binding standard.\n\nThe Token Binding Protocol Version 1.0. Allows client/server applications to create long-lived, uniquely identifiable TLS bindings spanning multiple TLS sessions and connections.  Applications are then enabled to cryptographically bind security tokens to the TLS layer, preventing token export and replay attacks.  To protect privacy, the Token Binding identifiers are only conveyed over TLS and can be reset by the user at any time.\nTransport Layer Security (TLS) Extension for Token Binding Protocol Negotiation. Extension for the negotiation of Token Binding protocol version and key parameters.\nToken Binding over HTTP. A collection of mechanisms that allow HTTP servers to cryptographically bind security tokens (such as cookies and OAuth tokens) to TLS connections.\nToken Binding for Transport Layer Security (TLS) Version 1.3 Connections. This companion document defines a backwards compatible way to negotiate Token Binding on TLS 1.3 connections.\nHTTPS Token Binding with TLS Terminating Reverse Proxies. Defines HTTP header fields that enable a TLS terminating reverse proxy to convey information to a backend server about the validated Token Binding Message received from a client, which enables that backend server to bind, or verify the binding of, cookies and other security tokens to the client's Token Binding key. This facilitates the reverse proxy and backend server functioning together as though they are a single logical server side deployment of HTTPS Token Binding.Related IETF draft standard:\n\nOAuth 2.0 Token Binding. Enables OAuth 2.0 implementations to apply Token Binding to Access Tokens, Authorization Codes, Refresh Tokens, JWT Authorization Grants, and JWT Client Authentication.  This cryptographically binds these tokens to a client's Token Binding key pair, possession of which is proven on the TLS connections over which the tokens are intended to be used.  This use of Token Binding protects these tokens from man-in-the-middle and token export and replay attacks.\n\n== Related standards ==\nThe use of TLS Token Binding allows for more robust web authentication. Several web authentication standards developed by standards bodies outside of IETF are adopting the draft standards.\n\nDraft OpenID Connect Token Bound Authentication 1.0. OpenID Connect (OIDC) is a simple identity layer on top of the OAuth 2.0 protocol. OIDC enables Clients to verify the identity of the End-User based on the authentication performed by an Authorization Server, as well as to obtain basic profile information about the End-User in an interoperable, REST-like manner. The OIDC Token Bound Authentication specification enables OIDC implementations to apply Token Binding to the OIDC ID Token. This cryptographically binds the ID Token to the TLS connection over which the authentication occurred. This use of Token Binding protects the authentication flow from man-in-the-middle and token export and replay attacks.\nW3C Proposed Recommendation for Web Authentication: An API for accessing Public Key Credentials. Web Authentication (WebAuthn), an interface for public-key authentication of users to web-based applications and services, supports Token Binding.\n\nAnswer this question \"Which organizations are contributing to the development of the Token Binding standard?\" using the text above.",
    "context": "",
    "output": "Industry participation in the development of the Token Binding standard is widespread and includes organizations such as Microsoft, Google, PayPal, Ping Identity, and Yubico.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "Which organizations are contributing to the development of the Token Binding standard?",
      "answer": "Industry participation in the development of the Token Binding standard is widespread and includes organizations such as Microsoft, Google, PayPal, Ping Identity, and Yubico.",
      "context": "Token Binding\n\n==Introduction==\nToken Binding is a proposed standard for a Transport Layer Security (TLS) extension that aims to increase TLS security by using cryptographic certificates on both ends of the TLS connection. Current practice often depends on bearer tokens, which may be lost or stolen. Bearer tokens are also vulnerable to man-in-the-middle attacks or replay attacks. In contrast, bound tokens are established by a user agent that generates a private-public key pair per target server, providing the public key to the server, and thereafter proving possession of the corresponding private key on every TLS connection to the server.\nToken Binding is an evolution of the Transport Layer Security Channel ID (previously known as Transport Layer Security \u2013 Origin Bound Certificates (TLS-OBC)) extension.\nIndustry participation is widespread with standards contributors including Microsoft, Google, PayPal, Ping Identity, and Yubico. Browser support remains limited, however. Only Microsoft Edge has support for token binding.\n\n\n\n== IETF standards ==\nThe following group of IETF RFCs and Internet Drafts comprise a set of interrelated specifications for implementing different aspects of the Token Binding standard.\n\nThe Token Binding Protocol Version 1.0. Allows client/server applications to create long-lived, uniquely identifiable TLS bindings spanning multiple TLS sessions and connections.  Applications are then enabled to cryptographically bind security tokens to the TLS layer, preventing token export and replay attacks.  To protect privacy, the Token Binding identifiers are only conveyed over TLS and can be reset by the user at any time.\nTransport Layer Security (TLS) Extension for Token Binding Protocol Negotiation. Extension for the negotiation of Token Binding protocol version and key parameters.\nToken Binding over HTTP. A collection of mechanisms that allow HTTP servers to cryptographically bind security tokens (such as cookies and OAuth tokens) to TLS connections.\nToken Binding for Transport Layer Security (TLS) Version 1.3 Connections. This companion document defines a backwards compatible way to negotiate Token Binding on TLS 1.3 connections.\nHTTPS Token Binding with TLS Terminating Reverse Proxies. Defines HTTP header fields that enable a TLS terminating reverse proxy to convey information to a backend server about the validated Token Binding Message received from a client, which enables that backend server to bind, or verify the binding of, cookies and other security tokens to the client's Token Binding key. This facilitates the reverse proxy and backend server functioning together as though they are a single logical server side deployment of HTTPS Token Binding.Related IETF draft standard:\n\nOAuth 2.0 Token Binding. Enables OAuth 2.0 implementations to apply Token Binding to Access Tokens, Authorization Codes, Refresh Tokens, JWT Authorization Grants, and JWT Client Authentication.  This cryptographically binds these tokens to a client's Token Binding key pair, possession of which is proven on the TLS connections over which the tokens are intended to be used.  This use of Token Binding protects these tokens from man-in-the-middle and token export and replay attacks.\n\n== Related standards ==\nThe use of TLS Token Binding allows for more robust web authentication. Several web authentication standards developed by standards bodies outside of IETF are adopting the draft standards.\n\nDraft OpenID Connect Token Bound Authentication 1.0. OpenID Connect (OIDC) is a simple identity layer on top of the OAuth 2.0 protocol. OIDC enables Clients to verify the identity of the End-User based on the authentication performed by an Authorization Server, as well as to obtain basic profile information about the End-User in an interoperable, REST-like manner. The OIDC Token Bound Authentication specification enables OIDC implementations to apply Token Binding to the OIDC ID Token. This cryptographically binds the ID Token to the TLS connection over which the authentication occurred. This use of Token Binding protects the authentication flow from man-in-the-middle and token export and replay attacks.\nW3C Proposed Recommendation for Web Authentication: An API for accessing Public Key Credentials. Web Authentication (WebAuthn), an interface for public-key authentication of users to web-based applications and services, supports Token Binding."
    }
  },
  {
    "instruction": "Fancy Bear was responsible for hacking Democratic National Committee emails to attempt to influence the outcome of the 2016 presidential elections. They used spear phishing emails to gain access to the email accounts of DNC staffers and stole 50,000 emails from Podesta's Gmail account.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What was the role of Fancy Bear in the 2016 US presidential elections?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What was the role of Fancy Bear in the 2016 US presidential elections?",
      "answer": "Fancy Bear was responsible for hacking Democratic National Committee emails to attempt to influence the outcome of the 2016 presidential elections. They used spear phishing emails to gain access to the email accounts of DNC staffers and stole 50,000 emails from Podesta's Gmail account."
    }
  },
  {
    "instruction": "NST provides a browser-based packet capture and protocol analysis system capable of monitoring up to four network interfaces using Wireshark. This feature enables users to visualize and manage Wireshark data effectively.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does NST visualize and manage Wireshark data?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does NST visualize and manage Wireshark data?",
      "answer": "NST provides a browser-based packet capture and protocol analysis system capable of monitoring up to four network interfaces using Wireshark. This feature enables users to visualize and manage Wireshark data effectively."
    }
  },
  {
    "instruction": "Context: Estonian Defence League's Cyber Unit\n\n==Introduction==\nThe Estonian Defence League\u2019s Cyber Unit (Estonian: K\u00fcberkaitseliit, or KKL) is a group of units within certain malevs of the Estonian Defense League established in 2010. Created out of inspiration from the 2007 cyberattacks on Estonia and spearheaded by Informatics Scientist \u00dclo Jaaksoo, it focuses on the defense of the Estonian state and private telecommunications infrastructure from outside-derived cyberattacks, and mostly employs the volunteer participation of IT professionals.\nThe KKL is headquartered on the grounds of the Tartu and Tallinn malevs, and it is jointly headed in Tallinn by Jaan Priisalu and in Tartu by Kuido K\u00fclm.\n\n\n\n== Purpose ==\nThe KKL's mission is to protect Estonia's high-tech way of life, protecting the information infrastructure, and thus carrying out  broad defense goals.\n\nhighly skilled IT professionals with volunteer youth organizations;\ncybersecurity of critical information infrastructure to increase the level of awareness through the rise and dissemination of best practices;\nnetwork, which brings together public and private sector crises of competence, organizational development, and act in times of crisis;\nMembers of the continuous training and training:\nMembers of the preparation;\naction plans;\nprevention and increasing cyber activities;\nparticipation in cybersecurity-related international cooperation networks\n\n== Proposed conscription ==\nDefence minister Jaak Aaviksoo has publicly suggested his desire for the spread of KKL units to other branches as an option for those who are conscripted to the Estonian military.\nQuestion: What is the role of the KKL in international cooperation networks related to cybersecurity?\n\nAnswer:",
    "context": "",
    "output": "The KKL participates in cybersecurity-related international cooperation networks, working with other organizations to improve cybersecurity.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the role of the KKL in international cooperation networks related to cybersecurity?",
      "answer": "The KKL participates in cybersecurity-related international cooperation networks, working with other organizations to improve cybersecurity.",
      "context": "Estonian Defence League's Cyber Unit\n\n==Introduction==\nThe Estonian Defence League\u2019s Cyber Unit (Estonian: K\u00fcberkaitseliit, or KKL) is a group of units within certain malevs of the Estonian Defense League established in 2010. Created out of inspiration from the 2007 cyberattacks on Estonia and spearheaded by Informatics Scientist \u00dclo Jaaksoo, it focuses on the defense of the Estonian state and private telecommunications infrastructure from outside-derived cyberattacks, and mostly employs the volunteer participation of IT professionals.\nThe KKL is headquartered on the grounds of the Tartu and Tallinn malevs, and it is jointly headed in Tallinn by Jaan Priisalu and in Tartu by Kuido K\u00fclm.\n\n\n\n== Purpose ==\nThe KKL's mission is to protect Estonia's high-tech way of life, protecting the information infrastructure, and thus carrying out  broad defense goals.\n\nhighly skilled IT professionals with volunteer youth organizations;\ncybersecurity of critical information infrastructure to increase the level of awareness through the rise and dissemination of best practices;\nnetwork, which brings together public and private sector crises of competence, organizational development, and act in times of crisis;\nMembers of the continuous training and training:\nMembers of the preparation;\naction plans;\nprevention and increasing cyber activities;\nparticipation in cybersecurity-related international cooperation networks\n\n== Proposed conscription ==\nDefence minister Jaak Aaviksoo has publicly suggested his desire for the spread of KKL units to other branches as an option for those who are conscripted to the Estonian military."
    }
  },
  {
    "instruction": "Users can install separate programs or configure filtering as part of their email program (email client). In email programs, users can make personal, \"manual\" filters that then automatically filter mail according to the chosen criteria.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How can users install mail filters?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How can users install mail filters?",
      "answer": "Users can install separate programs or configure filtering as part of their email program (email client). In email programs, users can make personal, \"manual\" filters that then automatically filter mail according to the chosen criteria."
    }
  },
  {
    "instruction": "The mechanical cams on the NEMA machine's drive wheels control the stepping of the rotors and the reflector.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the purpose of the mechanical cams on the NEMA machine's drive wheels?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the purpose of the mechanical cams on the NEMA machine's drive wheels?",
      "answer": "The mechanical cams on the NEMA machine's drive wheels control the stepping of the rotors and the reflector."
    }
  },
  {
    "instruction": "The Human Flesh Search Engine has been portrayed in various forms of media, including films and television series such as Caught in the Web, Mr. Robot, Law and Order, Wisdom of the Crowd, and Searching. These portrayals often explore the use of the HFSE in fictional instances and its implications in cyberviolence and violations of privacy law.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How has the Human Flesh Search Engine been portrayed in film and television and what notable examples can be found in this medium?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How has the Human Flesh Search Engine been portrayed in film and television and what notable examples can be found in this medium?",
      "answer": "The Human Flesh Search Engine has been portrayed in various forms of media, including films and television series such as Caught in the Web, Mr. Robot, Law and Order, Wisdom of the Crowd, and Searching. These portrayals often explore the use of the HFSE in fictional instances and its implications in cyberviolence and violations of privacy law."
    }
  },
  {
    "instruction": "The clear channel assessment is a critical function in the Wi-Fi network's functioning as it determines whether the wireless medium is ready and able to receive data, so that the transmitter may start sending it.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the significance of the clear channel assessment in the Wi-Fi network's functioning?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the significance of the clear channel assessment in the Wi-Fi network's functioning?",
      "answer": "The clear channel assessment is a critical function in the Wi-Fi network's functioning as it determines whether the wireless medium is ready and able to receive data, so that the transmitter may start sending it."
    }
  },
  {
    "instruction": "The memory complexity of Equihash is proportional to 2^(k+n/(k+1)), and it is not affected by reducing the number of iterations over the large list.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the memory complexity of Equihash if the number of iterations over the large list is reduced by a factor of 1/q?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the memory complexity of Equihash if the number of iterations over the large list is reduced by a factor of 1/q?",
      "answer": "The memory complexity of Equihash is proportional to 2^(k+n/(k+1)), and it is not affected by reducing the number of iterations over the large list."
    }
  },
  {
    "instruction": "Hacking Team\n\n==Introduction==\nHackingTeam was a Milan-based information technology company that sold offensive intrusion and surveillance capabilities to governments, law enforcement agencies and corporations. Its \"Remote Control Systems\" enable governments and corporations to monitor the communications of internet users, decipher their encrypted files and emails, record Skype and other Voice over IP communications, and remotely activate microphones and camera on target computers. The company has been criticized for providing these capabilities to governments with poor human rights records, though HackingTeam states that they have the ability to disable their software if it is used unethically. The Italian government has restricted their licence to do business with countries outside Europe.HackingTeam employs around 40 people in its Italian office, and has subsidiary branches in Annapolis, Washington, D.C., and Singapore. Its products are in use in dozens of countries across six continents.\n\n== Company foundation ==\nHackingTeam was founded in 2003 by Italian entrepreneurs  Vincenzetti and Valeriano Bedeschi.  In 2007 the company was invested by two Italian VC: Fondo Next and Innogest.The Milan police department learned of the company. Hoping to use its tool to spy on Italian citizens and listen to their Skype calls, the police contacted Vincenzetti and asked him to help. HackingTeam became \"the first sellers of commercial hacking software to the police\u201d.\nAccording to former employee Byamukama Robinhood, the company began as security services provider, offering penetration testing, auditing and other defensive capabilities to clients. Byamukama states that as malware and other offensive capabilities were developed and accounted for a larger percentage of revenues, the organization pivoted in a more offensive direction and became increasingly compartmentalized. Byamukama claims fellow employees working on aspects of the same platform \u2013 for example, Android exploits and payloads \u2013 would not communicate with one another, possibly leading to tensions and strife within the organization.In February 2014, a report from Citizen Lab identified the organisation to be using hosting services from Linode, Telecom Italia, Rackspace, NOC4Hosts and bullet proof hosting company Santrex.On 5 July 2015 the company suffered a major data breach of customer data, software code, internal documents and e-mails. (See: \u00a7 2015 data breach)\nOn 2 April 2019 HackingTeam was acquired by InTheCyber Group to create Memento Labs\n\n== Products and capabilities ==\nHacking Team enables clients to perform remote monitoring functions against citizens via their RCS (remote control systems), including their Da Vinci and Galileo platforms:\nCovert collection of emails, text message, phone call history and address books\nKeystroke logging\nUncover search history data and take screenshots\nRecord audio from phone callsCapture audio and video stream from device memory to bypass cryptography of Skype sessions\nUse microphones on device to collect ambient background noise and conversationsActivate phone or computer cameras\nHijack telephone GPS systems to monitor target's location\nInfect target computer's UEFI BIOS firmware with a rootkit\nExtract WiFi passwords\nExfiltrate Bitcoin and other cryptocurrency wallet files to collect data on local accounts, contacts and transaction historiesHackingTeam uses advanced techniques to avoid draining cell phone batteries, which could potentially raise suspicions, and other methods to avoid detection.The malware has payloads for Android, BlackBerry, Apple iOS, Linux, Mac OS X, Symbian, as well as Microsoft Windows, Windows Mobile and Windows Phone class of operating systems.RCS is a management platform that allows operators to remotely deploy exploits and payloads against targeted systems, remotely manage devices once compromised, and exfiltrate data for remote analysis.\n\n== Controversies ==\n\n\n*** Use by repressive governments ***\nHackingTeam has been criticized for selling its products and services to governments with poor human rights records, including Sudan, Bahrain, Venezuela, and Saudi Arabia.In June 2014, a United Nations panel monitoring the implementation of sanctions on Sudan requested information from HackingTeam about their alleged sales of software to the country in contravention of United Nations weapons export bans to Sudan. Documents leaked in the 2015 data breach of HackingTeam revealed the organization sold Sudanese National Intelligence and Security Service access to their \"Remote Control System\" software in 2012 for 960,000 Euros.In response to the United Nations panel, the company responded in January 2015 that they were not currently selling to Sudan. In a follow-up exchange, HackingTeam asserted that their product was not controlled as a weapon, and so the request was beyond the scope of the panel. There was no need for them to disclose previous sales, which they considered confidential business information.The U.N. disagreed. \"The view of the panel is that as such software is ideally suited to support military electronic intelligence (ELINT) operations it may potentially fall under the category of 'military ... equipment' or 'assistance' related to prohibited items,\" the secretary wrote in March. \"Thus its potential use in targeting any of the belligerents in the Darfur conflict is of interest to the Panel.\"In the fall of 2014, the Italian government abruptly froze all of HackingTeam's exports, citing human rights concerns. After lobbying Italian officials, the company temporarily won back the right to sell its products abroad.\n\n\n*** 2015 data breach ***\nOn July 5, 2015, the Twitter account of the company was compromised by an unknown individual who published an announcement of a data breach against HackingTeam's computer systems. The initial message read, \"Since we have nothing to hide, we're publishing all our e-mails, files, and source code ...\" and provided links to over 400 gigabytes of data, including alleged internal e-mails, invoices, and source code; which were leaked via BitTorrent and Mega. An announcement of the data breach, including a link to the bittorrent seed, was retweeted by WikiLeaks and by many others through social media.The material was voluminous and early analysis appeared to reveal that HackingTeam had invoiced the Lebanese Army and Sudan and that spy tools were also sold to Bahrain and Kazakhstan. HackingTeam had previously claimed they had never done business with Sudan.The leaked data revealed a zero-day cross-platform Flash exploit (CVE number: CVE-2015-5119. The dump included a demo of this exploit by opening Calculator from a test webpage. Adobe patched the hole on July 8, 2015. Another vulnerability involving Adobe was revealed in the dumps, which took advantage of a buffer overflow attack on an Adobe Open Type Manager DLL included with Microsoft Windows. The DLL is run in kernel mode, so the attack could perform privilege escalation to bypass the sandbox.Also revealed in leaked data was HackingTeam employees' use of weak passwords, including 'P4ssword', 'wolverine', and 'universo'.After a few hours without response from HackingTeam, member Christian Pozzi tweeted the company was working closely with police and \"what the attackers are claiming regarding our company is not true.\" He also claimed the leaked archive \"contains a virus\" and that it constituted \"false info\". Shortly after these tweets, Pozzi's Twitter account itself was apparently compromised.Responsibility for this attack was claimed by the hacker known as \"Phineas Fisher\" (or Phisher) on Twitter. Phineas has previously attacked spyware firm Gamma International, who produce malware, such as FinFisher, for governments and corporations. In 2016, Phineas published details of the attack, in Spanish and English, as a \"how-to\" for others, and explained the motivations behind the attack.The internal documents revealed details of HackingTeam's contracts with repressive governments. In 2016, the Italian government again revoked the company's license to sell spyware outside of Europe without special permission.\n\n\n*** Use by Mexican drug cartels ***\nCorrupt Mexican officials have helped drug cartels obtain state-of-the-art spyware (including Hacking Team spyware). The software  has been used to target and intimidate Mexican journalists by drug cartels and cartel-entwined government actors.\n\n== Customer list ==\nHackingTeam's clientele include not just governments, but also corporate clients such as Barclays and British Telecom (BT) of the United Kingdom, as well as Deutsche Bank of Germany.A full list of HackingTeam's customers were leaked in the 2015 breach. Disclosed documents show HackingTeam had 70 current customers, mostly military, police, federal and provincial governments. The total company revenues disclosed exceeded 40 million Euros.On Sep 8, 2021,SentinelLABS released a research report about a Turkish threat actor EGoManiac,that used Remote Control System (RCS), software from the Italian infosec firm Hacking Team,which was operated between 2010 and 2016 and campaign run by Turkish TV journalists at OdaTV for spying Turkish police.\n\nAnswer this question \"What is the Italian government's stance on HackingTeam's sales abroad?\" using the text above.",
    "context": "",
    "output": "The Italian government has expressed human rights concerns about HackingTeam's sales abroad. In 2014, they froze all of HackingTeam's exports, but the company temporarily won back the right to sell its products abroad. However, in 2016, the Italian government again revoked the company's license to sell spyware outside of Europe without special permission.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the Italian government's stance on HackingTeam's sales abroad?",
      "answer": "The Italian government has expressed human rights concerns about HackingTeam's sales abroad. In 2014, they froze all of HackingTeam's exports, but the company temporarily won back the right to sell its products abroad. However, in 2016, the Italian government again revoked the company's license to sell spyware outside of Europe without special permission.",
      "context": "Hacking Team\n\n==Introduction==\nHackingTeam was a Milan-based information technology company that sold offensive intrusion and surveillance capabilities to governments, law enforcement agencies and corporations. Its \"Remote Control Systems\" enable governments and corporations to monitor the communications of internet users, decipher their encrypted files and emails, record Skype and other Voice over IP communications, and remotely activate microphones and camera on target computers. The company has been criticized for providing these capabilities to governments with poor human rights records, though HackingTeam states that they have the ability to disable their software if it is used unethically. The Italian government has restricted their licence to do business with countries outside Europe.HackingTeam employs around 40 people in its Italian office, and has subsidiary branches in Annapolis, Washington, D.C., and Singapore. Its products are in use in dozens of countries across six continents.\n\n== Company foundation ==\nHackingTeam was founded in 2003 by Italian entrepreneurs  Vincenzetti and Valeriano Bedeschi.  In 2007 the company was invested by two Italian VC: Fondo Next and Innogest.The Milan police department learned of the company. Hoping to use its tool to spy on Italian citizens and listen to their Skype calls, the police contacted Vincenzetti and asked him to help. HackingTeam became \"the first sellers of commercial hacking software to the police\u201d.\nAccording to former employee Byamukama Robinhood, the company began as security services provider, offering penetration testing, auditing and other defensive capabilities to clients. Byamukama states that as malware and other offensive capabilities were developed and accounted for a larger percentage of revenues, the organization pivoted in a more offensive direction and became increasingly compartmentalized. Byamukama claims fellow employees working on aspects of the same platform \u2013 for example, Android exploits and payloads \u2013 would not communicate with one another, possibly leading to tensions and strife within the organization.In February 2014, a report from Citizen Lab identified the organisation to be using hosting services from Linode, Telecom Italia, Rackspace, NOC4Hosts and bullet proof hosting company Santrex.On 5 July 2015 the company suffered a major data breach of customer data, software code, internal documents and e-mails. (See: \u00a7 2015 data breach)\nOn 2 April 2019 HackingTeam was acquired by InTheCyber Group to create Memento Labs\n\n== Products and capabilities ==\nHacking Team enables clients to perform remote monitoring functions against citizens via their RCS (remote control systems), including their Da Vinci and Galileo platforms:\nCovert collection of emails, text message, phone call history and address books\nKeystroke logging\nUncover search history data and take screenshots\nRecord audio from phone callsCapture audio and video stream from device memory to bypass cryptography of Skype sessions\nUse microphones on device to collect ambient background noise and conversationsActivate phone or computer cameras\nHijack telephone GPS systems to monitor target's location\nInfect target computer's UEFI BIOS firmware with a rootkit\nExtract WiFi passwords\nExfiltrate Bitcoin and other cryptocurrency wallet files to collect data on local accounts, contacts and transaction historiesHackingTeam uses advanced techniques to avoid draining cell phone batteries, which could potentially raise suspicions, and other methods to avoid detection.The malware has payloads for Android, BlackBerry, Apple iOS, Linux, Mac OS X, Symbian, as well as Microsoft Windows, Windows Mobile and Windows Phone class of operating systems.RCS is a management platform that allows operators to remotely deploy exploits and payloads against targeted systems, remotely manage devices once compromised, and exfiltrate data for remote analysis.\n\n== Controversies ==\n\n\n*** Use by repressive governments ***\nHackingTeam has been criticized for selling its products and services to governments with poor human rights records, including Sudan, Bahrain, Venezuela, and Saudi Arabia.In June 2014, a United Nations panel monitoring the implementation of sanctions on Sudan requested information from HackingTeam about their alleged sales of software to the country in contravention of United Nations weapons export bans to Sudan. Documents leaked in the 2015 data breach of HackingTeam revealed the organization sold Sudanese National Intelligence and Security Service access to their \"Remote Control System\" software in 2012 for 960,000 Euros.In response to the United Nations panel, the company responded in January 2015 that they were not currently selling to Sudan. In a follow-up exchange, HackingTeam asserted that their product was not controlled as a weapon, and so the request was beyond the scope of the panel. There was no need for them to disclose previous sales, which they considered confidential business information.The U.N. disagreed. \"The view of the panel is that as such software is ideally suited to support military electronic intelligence (ELINT) operations it may potentially fall under the category of 'military ... equipment' or 'assistance' related to prohibited items,\" the secretary wrote in March. \"Thus its potential use in targeting any of the belligerents in the Darfur conflict is of interest to the Panel.\"In the fall of 2014, the Italian government abruptly froze all of HackingTeam's exports, citing human rights concerns. After lobbying Italian officials, the company temporarily won back the right to sell its products abroad.\n\n\n*** 2015 data breach ***\nOn July 5, 2015, the Twitter account of the company was compromised by an unknown individual who published an announcement of a data breach against HackingTeam's computer systems. The initial message read, \"Since we have nothing to hide, we're publishing all our e-mails, files, and source code ...\" and provided links to over 400 gigabytes of data, including alleged internal e-mails, invoices, and source code; which were leaked via BitTorrent and Mega. An announcement of the data breach, including a link to the bittorrent seed, was retweeted by WikiLeaks and by many others through social media.The material was voluminous and early analysis appeared to reveal that HackingTeam had invoiced the Lebanese Army and Sudan and that spy tools were also sold to Bahrain and Kazakhstan. HackingTeam had previously claimed they had never done business with Sudan.The leaked data revealed a zero-day cross-platform Flash exploit (CVE number: CVE-2015-5119. The dump included a demo of this exploit by opening Calculator from a test webpage. Adobe patched the hole on July 8, 2015. Another vulnerability involving Adobe was revealed in the dumps, which took advantage of a buffer overflow attack on an Adobe Open Type Manager DLL included with Microsoft Windows. The DLL is run in kernel mode, so the attack could perform privilege escalation to bypass the sandbox.Also revealed in leaked data was HackingTeam employees' use of weak passwords, including 'P4ssword', 'wolverine', and 'universo'.After a few hours without response from HackingTeam, member Christian Pozzi tweeted the company was working closely with police and \"what the attackers are claiming regarding our company is not true.\" He also claimed the leaked archive \"contains a virus\" and that it constituted \"false info\". Shortly after these tweets, Pozzi's Twitter account itself was apparently compromised.Responsibility for this attack was claimed by the hacker known as \"Phineas Fisher\" (or Phisher) on Twitter. Phineas has previously attacked spyware firm Gamma International, who produce malware, such as FinFisher, for governments and corporations. In 2016, Phineas published details of the attack, in Spanish and English, as a \"how-to\" for others, and explained the motivations behind the attack.The internal documents revealed details of HackingTeam's contracts with repressive governments. In 2016, the Italian government again revoked the company's license to sell spyware outside of Europe without special permission.\n\n\n*** Use by Mexican drug cartels ***\nCorrupt Mexican officials have helped drug cartels obtain state-of-the-art spyware (including Hacking Team spyware). The software  has been used to target and intimidate Mexican journalists by drug cartels and cartel-entwined government actors.\n\n== Customer list ==\nHackingTeam's clientele include not just governments, but also corporate clients such as Barclays and British Telecom (BT) of the United Kingdom, as well as Deutsche Bank of Germany.A full list of HackingTeam's customers were leaked in the 2015 breach. Disclosed documents show HackingTeam had 70 current customers, mostly military, police, federal and provincial governments. The total company revenues disclosed exceeded 40 million Euros.On Sep 8, 2021,SentinelLABS released a research report about a Turkish threat actor EGoManiac,that used Remote Control System (RCS), software from the Italian infosec firm Hacking Team,which was operated between 2010 and 2016 and campaign run by Turkish TV journalists at OdaTV for spying Turkish police."
    }
  },
  {
    "instruction": "The Key operations table in the given text compares cryptography libraries based on their support for various key operations, including key generation algorithms, key exchange agreements, and public key cryptography standards.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What functions do these cryptography libraries support in terms of key operations, such as key generation algorithms, key exchange agreements, and public key cryptography standards?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What functions do these cryptography libraries support in terms of key operations, such as key generation algorithms, key exchange agreements, and public key cryptography standards?",
      "answer": "The Key operations table in the given text compares cryptography libraries based on their support for various key operations, including key generation algorithms, key exchange agreements, and public key cryptography standards."
    }
  },
  {
    "instruction": "Context: Cyber threat hunting\n\n==Introduction==\nCyber threat hunting is a proactive cyber defence activity. It is \"the process of proactively and iteratively searching through networks to detect and isolate advanced threats that evade existing security solutions.\" This is in contrast to traditional threat management measures, such as firewalls, intrusion detection systems (IDS), malware sandbox (computer security) and SIEM systems, which typically involve an investigation of evidence-based data after there has been a warning of a potential threat.\n\n\n\n== Methodologies ==\nThreat hunting has traditionally been a manual process, in which a security analyst sifts through various data information using their own knowledge and familiarity with the network to create hypotheses about potential threats, such as, but not limited to, lateral movement by threat actors. To be even more effective and efficient, however, threat hunting can be partially automated, or machine-assisted, as well. In this case, the analyst uses software that leverages machine learning and user and entity behavior analytics (UEBA) to inform the analyst of potential risks. The analyst then investigates these potential risks, tracking suspicious behavior in the network. Thus, hunting is an iterative process, meaning that it must be continuously carried out in a loop, beginning with a hypothesis.\n\nAnalytics-Driven: \"Machine-learning and UEBA, used to develop aggregated risk scores that can also serve as hunting hypotheses\"\nSituational-Awareness Driven: \"Crown Jewel analysis, enterprise risk assessments, company- or employee-level trends\"\nIntelligence-Driven: \"Threat intelligence reports, threat intelligence feeds, malware analysis, vulnerability scans\"The analysts research their hypothesis by going through vast amounts of data about the network. The results are then stored so that they can be used to improve the automated portion of the detection system and to serve as a foundation for future hypotheses.\nThe Detection Maturity Level (DML) model  expresses threat indicators can be detected at different semantic levels. High semantic indicators such as goal and strategy or tactics, techniques and procedures (TTPs) are more valuable to identify than low semantic indicators such as network artifacts and atomic indicators such as IP addresses. SIEM tools typically only provide indicators at relatively low semantic levels. There is therefore a need to develop SIEM tools that can provide threat indicators at higher semantic levels.\n\n== Indicators ==\nThere are two types of indicators:\n\nIndicator of compromise - An indicator of compromise (IOC)  tells you that an action has happened and you are in a reactive mode. This type of IOC is done by looking inward at your own data from transaction logs and or SIEM data. Examples of IOC include unusual network traffic, unusual privileged user account activity, login anomalies, increases in database read volumes, suspicious registry or system file changes, unusual DNS requests and Web traffic showing non-human behavior. These types of unusual activities allow security administration teams to spot malicious actors earlier in the cyberattack process.\nIndicator of Concern - Using Open-source intelligence (OSINT), data can be collected from publicly available sources to be used for cyberattack detection and threat hunting.\n\n== Tactics, Techniques and Procedures (TTPs) ==\nThe SANS Institute identifies a threat hunting maturity model as follows:\nInitial - At Level 0 maturity, an organization relies primarily on automated reporting and does little or no routine data collection.\nMinimal - At Level 1 maturity, an organization incorporates threat intelligence indicator searches. It has a moderate or high level of routine data collection.\nProcedural - At Level 2 maturity, an organization follows analysis procedures created by others. It has a high or very high level of routine data collection.\nInnovative - At Level 3 maturity, an organization creates new data analysis procedures. It has a high or very high level of routine data collection.\nLeading - At Level 4 maturity, automates the majority of successful data analysis procedures. It has a high or very high level of routine data collection.\n\n== Dwell Time ==\nThe dwell time either indicates the entire span of a security incident (initial compromise until detection and full cleanup) or the 'mean time to detect' (from initial compromise until detection). According to the 2022 Mandiant M-Trends Report, cyberattackers operate undetected for an average of 21 days (a 79% reduction, compared to 2016), but this varies greatly by region. Per Mandiant, the dwell time can be as low as 17 days (in the Americas) or as high as 48 days (in EMEA). The study also showed that 47% of attacks are discovered only after notification from an external party.\n\n== Example Reports ==\nSeedworm: Group Compromises Government Agencies, Oil & Gas, NGOs, Telecoms, and IT Firms\n\n== Example Threat Hunting ==\nThreat hunting using DNS firewalls and data enrichment\n\n== Threat Hunting Methodologies ==\nInside the Network Perimeter\n\nReactive Threat Hunting - This method is triggered by a malicious event, typically after a data breach or theft is discovered. Efforts are typically focused on forensics and remediation.\nProactive Threat Hunting - This method actively seeks out ongoing malicious events and activities inside the network, the goal is to detect an in progress cyber attack.  Efforts are typically focused on detection and remediation.Outside the Network Perimeter\n\nExternal Threat Hunting - This method proactively seeks out malicious threat actor infrastructure to map and predict where cyber attacks are likely to emerge to prepare defensive strategies.  Efforts are typically focused on Cyber Threat Reconnaissance, Threat Surface Mapping and monitoring of third-party risks.\nQuestion: How does the Detection Maturity Level (DML) model express threat indicators?\n\nAnswer:",
    "context": "",
    "output": "The Detection Maturity Level (DML) model expresses threat indicators at different semantic levels. High semantic indicators, such as goal, strategy, or tactics, techniques, and procedures (TTPs), are more valuable for identification than low semantic indicators, such as network artifacts and atomic indicators like IP addresses.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does the Detection Maturity Level (DML) model express threat indicators?",
      "answer": "The Detection Maturity Level (DML) model expresses threat indicators at different semantic levels. High semantic indicators, such as goal, strategy, or tactics, techniques, and procedures (TTPs), are more valuable for identification than low semantic indicators, such as network artifacts and atomic indicators like IP addresses.",
      "context": "Cyber threat hunting\n\n==Introduction==\nCyber threat hunting is a proactive cyber defence activity. It is \"the process of proactively and iteratively searching through networks to detect and isolate advanced threats that evade existing security solutions.\" This is in contrast to traditional threat management measures, such as firewalls, intrusion detection systems (IDS), malware sandbox (computer security) and SIEM systems, which typically involve an investigation of evidence-based data after there has been a warning of a potential threat.\n\n\n\n== Methodologies ==\nThreat hunting has traditionally been a manual process, in which a security analyst sifts through various data information using their own knowledge and familiarity with the network to create hypotheses about potential threats, such as, but not limited to, lateral movement by threat actors. To be even more effective and efficient, however, threat hunting can be partially automated, or machine-assisted, as well. In this case, the analyst uses software that leverages machine learning and user and entity behavior analytics (UEBA) to inform the analyst of potential risks. The analyst then investigates these potential risks, tracking suspicious behavior in the network. Thus, hunting is an iterative process, meaning that it must be continuously carried out in a loop, beginning with a hypothesis.\n\nAnalytics-Driven: \"Machine-learning and UEBA, used to develop aggregated risk scores that can also serve as hunting hypotheses\"\nSituational-Awareness Driven: \"Crown Jewel analysis, enterprise risk assessments, company- or employee-level trends\"\nIntelligence-Driven: \"Threat intelligence reports, threat intelligence feeds, malware analysis, vulnerability scans\"The analysts research their hypothesis by going through vast amounts of data about the network. The results are then stored so that they can be used to improve the automated portion of the detection system and to serve as a foundation for future hypotheses.\nThe Detection Maturity Level (DML) model  expresses threat indicators can be detected at different semantic levels. High semantic indicators such as goal and strategy or tactics, techniques and procedures (TTPs) are more valuable to identify than low semantic indicators such as network artifacts and atomic indicators such as IP addresses. SIEM tools typically only provide indicators at relatively low semantic levels. There is therefore a need to develop SIEM tools that can provide threat indicators at higher semantic levels.\n\n== Indicators ==\nThere are two types of indicators:\n\nIndicator of compromise - An indicator of compromise (IOC)  tells you that an action has happened and you are in a reactive mode. This type of IOC is done by looking inward at your own data from transaction logs and or SIEM data. Examples of IOC include unusual network traffic, unusual privileged user account activity, login anomalies, increases in database read volumes, suspicious registry or system file changes, unusual DNS requests and Web traffic showing non-human behavior. These types of unusual activities allow security administration teams to spot malicious actors earlier in the cyberattack process.\nIndicator of Concern - Using Open-source intelligence (OSINT), data can be collected from publicly available sources to be used for cyberattack detection and threat hunting.\n\n== Tactics, Techniques and Procedures (TTPs) ==\nThe SANS Institute identifies a threat hunting maturity model as follows:\nInitial - At Level 0 maturity, an organization relies primarily on automated reporting and does little or no routine data collection.\nMinimal - At Level 1 maturity, an organization incorporates threat intelligence indicator searches. It has a moderate or high level of routine data collection.\nProcedural - At Level 2 maturity, an organization follows analysis procedures created by others. It has a high or very high level of routine data collection.\nInnovative - At Level 3 maturity, an organization creates new data analysis procedures. It has a high or very high level of routine data collection.\nLeading - At Level 4 maturity, automates the majority of successful data analysis procedures. It has a high or very high level of routine data collection.\n\n== Dwell Time ==\nThe dwell time either indicates the entire span of a security incident (initial compromise until detection and full cleanup) or the 'mean time to detect' (from initial compromise until detection). According to the 2022 Mandiant M-Trends Report, cyberattackers operate undetected for an average of 21 days (a 79% reduction, compared to 2016), but this varies greatly by region. Per Mandiant, the dwell time can be as low as 17 days (in the Americas) or as high as 48 days (in EMEA). The study also showed that 47% of attacks are discovered only after notification from an external party.\n\n== Example Reports ==\nSeedworm: Group Compromises Government Agencies, Oil & Gas, NGOs, Telecoms, and IT Firms\n\n== Example Threat Hunting ==\nThreat hunting using DNS firewalls and data enrichment\n\n== Threat Hunting Methodologies ==\nInside the Network Perimeter\n\nReactive Threat Hunting - This method is triggered by a malicious event, typically after a data breach or theft is discovered. Efforts are typically focused on forensics and remediation.\nProactive Threat Hunting - This method actively seeks out ongoing malicious events and activities inside the network, the goal is to detect an in progress cyber attack.  Efforts are typically focused on detection and remediation.Outside the Network Perimeter\n\nExternal Threat Hunting - This method proactively seeks out malicious threat actor infrastructure to map and predict where cyber attacks are likely to emerge to prepare defensive strategies.  Efforts are typically focused on Cyber Threat Reconnaissance, Threat Surface Mapping and monitoring of third-party risks."
    }
  },
  {
    "instruction": "The Trojan.Win32.Patched.A variant can modify a legitimate DLL file on an infected system.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does the Trojan.Win32.Patched.A variant infect a system?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does the Trojan.Win32.Patched.A variant infect a system?",
      "answer": "The Trojan.Win32.Patched.A variant can modify a legitimate DLL file on an infected system."
    }
  },
  {
    "instruction": "Context: Search engine privacy\n\n==Introduction==\nSearch engine privacy is a subset of internet privacy that deals with user data being collected by search engines. Both types of privacy fall under the umbrella of information privacy. Privacy concerns regarding search engines can take many forms, such as the ability for search engines to log individual search queries, browsing history, IP addresses, and cookies of users, and conducting user profiling in general. The collection of personally identifiable information (PII) of users by search engines is referred to as \"tracking\".This is controversial because search engines often claim to collect a user's data in order to better tailor results to that specific user and to provide the user with a better searching experience. However, search engines can also abuse and compromise its users' privacy by selling their data to advertisers for profit. In the absence of regulations, users must decide what is more important to their search engine experience: relevance and speed of results or their privacy, and choose a search engine accordingly.The legal framework for protecting user privacy is not very solid. The most popular search engines collect personal information, but other search engines that are focused on privacy have cropped up recently. There have been several well publicized breaches of search engine user privacy that occurred with companies like AOL and Yahoo. For individuals interested in preserving their privacy, there are options available to them, such as using software like Tor which makes the user's location and personal information anonymous or using a privacy focused search engine.\n\n\n\n== Privacy policies ==\nSearch engines generally publish privacy policies to inform users about what data of theirs may be collected and what purposes it may be used for. While these policies may be an attempt at transparency by search engines, many people never read them and are therefore unaware of how much of their private information, like passwords and saved files, are collected from cookies and may be logged and kept by the search engine. This ties in with the phenomenon of notice and consent, which is how many privacy policies are structured.\nNotice and consent policies essentially consist of a site showing the user a privacy policy and having them click to agree. This is intended to let the user freely decide whether or not to go ahead and use the website. This decision, however, may not actually be made so freely because the costs of opting out can be very high. Another big issue with putting the privacy policy in front of users and having them accept quickly is that they are often very hard to understand, even in the unlikely case that a user decides to read them. Privacy minded search engines, such as DuckDuckGo, state in their privacy policies that they collect much less data than search engines such as Google or Yahoo, and may not collect any. As of 2008, search engines were not in the business of selling user data to third parties, though they do note in their privacy policies that they comply with government subpoenas.\n\n\n*** Google and Yahoo ***\nGoogle, founded in 1998, is the most widely used search engine, receiving billions and billions of search queries every month. Google logs all search terms in a database along with the date and time of search, browser and operating system, IP address of user, the Google cookie, and the URL that shows the search engine and search query. The privacy policy of Google states that they pass user data on to various affiliates, subsidiaries, and \"trusted\" business partners.Yahoo, founded in 1995, also collects user data. It is a well-known fact that users do not read privacy policies, even for services that they use daily, such as Yahoo! Mail and Gmail. This persistent failure of consumers to read these privacy policies can be disadvantageous to them because while they may not pick up on differences in the language of privacy policies, judges in court cases certainly do. This means that search engine and email companies like Google and Yahoo are technically able to keep up the practice of targeting advertisements based on email content since they declare that they do so in their privacy policies. A study was done to see how much consumers cared about privacy policies of Google, specifically Gmail, and their detail, and it determined that users often thought that Google's practices were somewhat intrusive but that users would not often be willing to counteract this by paying a premium for their privacy.\n\n\n*** DuckDuckGo ***\nDuckDuckGo, founded in 2008, claims to be privacy focused. DuckDuckGo does not collect or share any personal information of users, such as IP addresses or cookies, which other search engines usually do log and keep for some time. It also does not have spam, and protects user privacy further by anonymizing search queries from the website the user chooses and using encryption. Similarly privacy oriented search engines include Startpage and Disconnect.\n\n== Types of data collected by search engines ==\nMost search engines can, and do, collect personal information about their users according to their own privacy policies. This user data could be anything from location information to cookies, IP addresses, search query histories, click-through history, and online fingerprints. This data is often stored in large databases, and users may be assigned numbers in an attempt to provide them with anonymity.\nData can be stored for an extended period of time. For example, the data collected by Google on its users is retained for up to 9 months. Some studies state that this number is actually 18 months. This data is used for various reasons such as optimizing and personalizing search results for users, targeting advertising, and trying to protect users from scams and phishing attacks. Such data can be collected even when a user is not logged in to their account or when using a different IP address by using cookies.\n\n\n*** Uses ***\n\n\n**** User profiling and personalization ****\nWhat search engines often do once they have collected information about a user's habits is to create a profile of them, which helps the search engine decide which links to show for different search queries submitted by that user or which ads to target them with. An interesting development in this field is the invention of automated learning, also known as machine learning. Using this, search engines can refine their profiling models to more accurately predict what any given user may want to click on by doing A/B testing of results offered to users and measuring the reactions of users.Companies like Google, Netflix, YouTube, and Amazon have all started personalizing results more and more. One notable example is how Google Scholar takes into account the publication history of a user in order to produce results it deems relevant. Personalization also occurs when Amazon recommends books or when IMDb suggests movies by using previously collected information about a user to predict their tastes. For personalization to occur, a user need not even be logged into their account.\n\n\n**** Targeted advertising ****\nThe internet advertising company DoubleClick, which helps advertisers target users for specific ads, was bought by Google in 2008 and was a subsidiary until June 2018, when Google rebranded and merged DoubleClick into its Google Marketing Platform. DoubleClick worked by depositing cookies on user's computers that would track sites they visited with DoubleClick ads on them. There was a privacy concern when Google was in the process of acquiring DoubleClick that the acquisition would let Google create even more comprehensive profiles of its users since they would be collecting data about search queries and additionally tracking websites visited. This could lead to users being shown ads that are increasingly effective with the use of behavioral targeting. With more effective ads comes the possibility of more purchases from consumers that they may not have made otherwise. In 1994, a conflict between selling ads and relevance of results on search engines began. This was sparked by the development of the cost-per-click model, which challenged the methods of the already-created cost-per-mille model. The cost-per-click method was directly related to what users searched, whereas the cost-per-mille method was directly influenced by how much a company could pay for an ad, no matter how many times people interacted with it.\n\n\n**** Improving search quality ****\nBesides ad targeting and personalization, Google also uses data collected on users to improve the quality of searches. Search result click histories and query logs are crucial in helping search engines optimize search results for individual users. Search logs also help search engines in the development of the algorithms they use to return results, such as Google's well known PageRank. An example of this is how Google uses databases of information to refine Google Spell Checker.\n\n\n*** Privacy organizations ***\nThere are many who believe that user profiling is a severe invasion of user privacy, and there are organizations such as the Electronic Privacy Information Center (EPIC) and Privacy International that are focused on advocating for user privacy rights. In fact, EPIC filed a complaint in 2007 with the Federal Trade Commission claiming that Google should not be able to acquire DoubleClick on the grounds that it would compromise user privacy.\n\n== Users' perception of privacy ==\nExperiments have been done to examine consumer behavior when given information on the privacy of retailers by integrating privacy ratings with search engines. Researchers used a search engine for the treatment group called Privacy Finder, which scans websites and automatically generates an icon to show the level of privacy the site will give the consumer as it compares to the privacy policies that consumer has specified that they prefer. The results of the experiment were that subjects in the treatment group, those who were using a search engine that indicated privacy levels of websites, purchased products from websites that gave them higher levels of privacy, whereas the participants in the control groups opted for the products that were simply the cheapest. The study participants also were given financial incentive because they would get to keep leftover money from purchases. This study suggests that since participants had to use their own credit cards, they had a significant aversion to purchasing products from sites that did not offer the level of privacy they wanted, indicating that consumers value their privacy monetarily.\n\n== Ethical debates ==\nMany individuals and scholars have recognized the ethical concerns regarding search engine privacy.\n\n\n*** Pro data collection ***\nThe collection of user data by search engines can be viewed as a positive practice because it allows the search engine to personalize results. This implies that users would receive more relevant results, and be shown more relevant advertisements, when their data, such as past search queries, location information, and clicks, is used to create a profile for them. Also, search engines are generally free of charge for users and can remain afloat because one of their main sources of revenue is advertising, which can be more effective when targeted.\n\n\n*** Anti-data collection ***\nThis collection of user data can also be seen as an overreach by private companies for their own financial gain or as an intrusive surveillance tactic. Search engines can make money using targeted advertising because advertisers are willing to pay a premium to present their ads to the most receptive consumers. Also, when a search engine collects and catalogs large amounts of data about its users, there is the potential for it to be leaked accidentally or breached. The government can also subpoena user data from search engines when they have databases of it. Search query database information may also be subpoenaed by private litigants for use in civil cases, such as divorces or employment disputes.\n\n== Data and privacy breaches ==\n\n\n*** AOL search data leak ***\nOne major controversy regarding search engine privacy was the AOL search data leak of 2006. For academic and research purposes, AOL made public a list of about 20 million search queries made by about 650,000 unique users. Although they assigned unique identification numbers to the users instead of attaching names to each query, it was still possible to ascertain the true identities of many users simply by analyzing what they had searched, including locations near them and names of friends and family members. A notable example of this was how the New York Times identified Thelma Arnold through \"reverse searching\". Users also sometimes do \"ego searches\" where they search themselves to see what information about them is on the internet, making it even easier to identify supposedly anonymous users. Many of the search queries released by AOL were incriminating or seemingly extremely private, such as \"how to kill your wife\" and \"can you adopt after a suicide attempt\". This data has since been used in several experiments that attempt to measure the effectiveness of user privacy solutions.\n\n\n*** Google and Yahoo ***\nBoth Google and Yahoo were subjects of a Chinese hack in 2010. While Google responded to the situation seriously by hiring new cybersecurity engineers and investing heavily into securing user data, Yahoo took a much more lax approach. Google started paying hackers to find vulnerabilities in 2010 while it took Yahoo until 2013 to follow suit. Yahoo was also identified in the Snowden data leaks as a common hacking target for spies of various nations, and Yahoo still did not give its newly hired chief information security officer the resources to really effect change within the company. In 2012, Yahoo hired Marissa Mayer, previously a Google employee, to be the new CEO, but she chose not to invest much in the security infrastructure of Yahoo and went as far as to refuse the implementation of a basic and standard security measure to force the reset of all passwords after a breach.Yahoo is known for being the subject of multiple breaches and hacks that have compromised large amounts of user data. As of late 2016, Yahoo had announced that at least 1.5 billion user accounts had been breached during 2013 and 2014. The breach of 2013 compromised over a billion accounts while the breach of 2014 included about 500 million accounts. The data compromised in the breaches included personally identifiable information such as phone numbers, email addresses, and birth dates as well as information like security questions (used to reset passwords) and encrypted passwords. Yahoo made a statement saying that their breaches were a result of state sponsored actors, and in 2017, two Russian intelligence officers were indicted by the United States Department of Justice as part of a conspiracy to hack Yahoo and steal user data. As of 2016, the Yahoo breaches of 2013 and 2014 were the largest of all time.In October 2018, there was a Google+ data breach that potentially affected about 500,000 accounts which led to the shutdown of the Google+ platform.\n\n\n*** Government subpoenas of data ***\nThe government may want to subpoena user data from search engines for any number of reasons, which is why it a big threat to user privacy. In 2006, they wanted it as part of their defense of COPA, and only Google refused to comply. While protecting the online privacy of children may be an honorable goal, there are concerns about whether the government should have access to such personal data to achieve it. At other times, they may want it for national security purposes; access to big databases of search queries in order to prevent terrorist attacks is a common example of this.Whatever the reason, it is clear that the fact that search engines do create and maintain these databases of user data is what makes it possible for the government to access it. Another concern regarding government access to search engine user data is \"function creep\", a term that here refers to how data originally collected by the government for national security purposes may eventually be used for other purposes, such as debt collection. This would indicate to many a government overreach. While protections for search engine user privacy have started developing recently, the government has increasingly been on the side that wants to ensure search engines retain data, making users less protected and their data more available for anyone to subpoena.\n\n== Methods for increasing privacy ==\n\n\n*** Switching search engines ***\nA different, although popular, route for a privacy centered user to take is to simply start using a privacy oriented search engine, such as DuckDuckGo. This search engine maintains the privacy of its users by not collecting data on or tracking its users. While this may sound simple, users must take into account the trade-off between privacy and relevant results when deciding to switch search engines. Results to search queries can be very different when the search engine has no search history to aid it in personalization.\n\n\n*** Using privacy oriented browsers ***\nMozilla is known for its beliefs in protecting user privacy on Firefox. Mozilla Firefox users have the capability to delete the tracking cookie that Google places on their computer, making it much harder for Google to group data. Firefox also has a button called \"Clear Private Data\", which allows users to have more control over their settings. Internet Explorer users have this option as well. When using a browser like Google Chrome or Safari, users also have the option to browse in \"incognito\" or \"private browsing\" modes respectively. When in these modes, the user's browsing history and cookies are not collected.\n\n\n*** Opting out ***\nThe Google, Yahoo!, AOL, and MSN search engines all allow users to opt out of the behavioral targeting they use. Users can also delete search and browsing history at any time. The Ask.com search engine also has AskEraser, which, when used, purges user data from their servers. Deleting a user's profile and history of data from search engine logs also helps protect user privacy in the event a government agency wants to subpoena it. If there are no records, there is nothing the government can access. It is important to note that simply deleting your browsing history does not delete all the information the search engine has on you, some companies do not delete the data associated with your account when you clear your browsing history. For companies that do delete user data, they usually do not delete all of it keeping records of how you used the search engine.\n\n\n*** Social network solution ***\nAn innovative solution, proposed by researchers Viejo and Castell\u00e0-Roca, is a social network solution whereby user profiles are distorted. In their plan, each user would belong to a group, or network, of people who all use the search engine. Every time somebody wanted to submit a search query, it would be passed on to another member of the group to submit on their behalf until someone submitted it. This would ideally lead to all search queries being divvied up equally between all members of the network. This way, the search engine cannot make a useful profile of any individual user in the group since it has no way to discern which query actually belonged to each user.\n\n\n*** Delisting and reordering ***\nAfter the Google Spain v. AEPD case, it was established that people had the right to request that search engines delete personal information from their search results in compliance with other European data protection regulations. This process of simply removing certain search results is called de-listing. While effective in protecting the privacy of those who wish information about them to not be accessed by anyone using a search engine, it does not necessarily protect the contextual integrity of search results. For data that is not highly sensitive or compromising, reordering search results is another option where people would be able to rank how relevant certain data is at any given point in time, which would then alter results given when someone searched their name.\n\n\n*** Anonymity networks ***\nA sort of DIY option for privacy minded users is to use a software like Tor, which is an anonymity network. Tor functions by encrypting user data and routing queries through thousands of relays. While this process is effective at masking IP addresses, it can slow the speed of results. While Tor may work to mask IP addresses, there have also been studies that show that a simulated attacker software could still match search queries to users even when anonymized using Tor.\n\n\n*** Unlinkability and indistinguishability ***\nUnlinkability and indistinguishability are also well-known solutions to search engine privacy, although they have proven somewhat ineffective in actually providing users with anonymity from their search queries. Both unlinkability and indistinguishability solutions try to anonymize search queries from the user who made them, therefore making it impossible for the search engine to definitively link a specific query with a specific user and create a useful profile on them. This can be done in a couple of different ways.\n\n\n**** Unlinkability ****\nAnother way for the user to hide information such as their IP address from the search engine is an unlinkability solution. This is perhaps more simple and easy for the user because any user can do this by using a VPN, although it still does not guarantee total privacy from the search engine.\n\n\n**** Indistinguishability ****\nOne way is for the user to use a plugin or software that generates multiple different search queries for every real search query the user makes. This is an indistinguishability solution, and it functions by obscuring the real searches a user makes so that a search engine cannot tell which queries are the software's and which are the user's. Then, it is more difficult for the search engine to use the data it collects on a user to do things like target ads.\n\n== Legal rights and court cases ==\nBeing that the internet and search engines are relatively recent creations, no solid legal framework for privacy protections in terms of search engines has been put in place. However, scholars do write about the implications of existing laws on privacy in general to inform what right to privacy search engine users have. As this is a developing field of law, there have been several lawsuits with respect to the privacy search engines are expected to afford to their users.\n\n\n*** United States ***\n\n\n**** The Fourth Amendment ****\n\nThe Fourth Amendment is well known for the protections it offers citizens from unreasonable searches and seizures, but in Katz v. United States (1967), these protections were extended to cover intrusions of privacy of individuals, in addition to simply intrusion of property and people. Privacy of individuals is a broad term, but it is not hard to imagine that it includes the online privacy of an individual.\n\n\n**** The Sixth Amendment ****\n\nThe Confrontation Clause of the Sixth Amendment is applicable to the protection of big data from government surveillance. The Confrontation Clause essentially states that defendants in criminal cases have the right to confront witnesses who provide testimonial statements. If a search engine company like Google gives information to the government to prosecute a case, these witnesses are the Google employees involved in the process of selecting which data to hand over to the government. The specific employees who must be available to be confronted under the Confrontation Clause are the producer who decides what data is relevant and provides the government with what they've asked for, the Google analyst who certifies the proper collection and transmission of data, and the custodian who keeps records. The data these employees of Google curate for trial use is then thought of as testimonial statement. The overall effectiveness of the Confrontation Clause on search engine privacy is that it places a check on how the government can use big data and provides defendants with protection from human error.\n\n\n**** Katz v. United States ****\n\nThis 1967 case is prominent because it established a new interpretation of privacy under the Fourth Amendment, specifically that people had a reasonable expectation of it. Katz v. United States was about whether or not it was constitutional for the government to listen to and record, electronically using a pen register, a conversation Katz had from a public phone booth. The court ruled that it did violate the Fourth Amendment because the actions of the government were considered a \"search\" and that the government needed a warrant. When thinking about search engine data collected about users, the way telephone communications were classified under Katz v. United States could be a precedent for how it should be handled. In Katz v. United States, public telephones were deemed to have a \"vital role\" in private communications. This case took place in 1967, but surely nowadays, the internet and search engines have this vital role in private communications, and people's search queries and IP addresses can be thought of as analogous to the private phone calls placed from public booths.\n\n\n**** United States v. Miller ****\n\nThis 1976 Supreme Court case is relevant to search engine privacy because the court ruled that when third parties gathered or had information given to them, the Fourth Amendment was not applicable. Jayni Foley argues that the ruling of United States v. Miller implies that people cannot have an expectation of privacy when they provide information to third parties. When thinking about search engine privacy, this is important because people willingly provide search engines with information in the form of their search queries and various other data points that they may not realize are being collected.\n\n\n**** Smith v. Maryland ****\n\nIn the Supreme Court case Smith v. Maryland of 1979, the Supreme Court went off the precedent set in the 1976 United States v. Miller case about assumption of risk. The court ruled that the Fourth Amendment did not prevent the government from monitoring who dialed which phone numbers by using a pen register because it did not qualify as a \"search\".Both the United States v. Miller and the Smith v. Maryland cases have been used to prevent users from the privacy protections offered under the Fourth Amendment from the records that internet service providers (ISPs) keep. This is also articulated in the Sixth Circuit Guest v. Leis case as well as the United States v. Kennedy case where the courts ruled that Fourth Amendment protections did not apply to ISP customer data since they willingly provided ISPs with their information just by using the services of ISPs. Similarly, the current legal structure regarding privacy and assumption of risk can be interpreted to mean that users of search engines cannot expect privacy in regards to the data they communicate by using search engines.\n\n\n**** Electronic Communication Privacy Act ****\nThe Electronic Communications Privacy Act (ECPA) of 1986 was passed by Congress in an effort to start creating a legal structure for privacy protections in the face of new forms of technologies, although it was by no means comprehensive because there are considerations for current technologies that Congress never imagined in 1986 and could account for. The EPCA does little to regulate ISPs and mainly prevents government agencies from gathering information stored by ISPs without a warrant. What the EPCA does not do, unsurprisingly because it was enacted before internet usage became a common occurrence, is say anything about search engine privacy and the protections users are afforded in terms of their search queries.\n\n\n**** Gonzales v. Google Inc. ****\nThe background of this 2006 case is that the government was trying to bolster its defense for the Child Online Protection Act (COPA). It was doing a study to see how effective its filtering software was in regards to child pornography. To do this, the government subpoenaed search data from Google, AOL, Yahoo!, and Microsoft to use in its analysis and to show that people search information that is potentially compromising to children. This search data that the government wanted included both the URLs that appeared to users and the actual search queries of users. Of the search engines the government subpoenaed to produce search queries and URLs, only Google refused to comply with the government, even after the request was reduced in size. Google itself claimed that handing over these logs was to hand over personally identifiable information and user identities. The court ruled that Google had to hand over 50,000 randomly selected URLs to the government but not search queries because that could seed public distrust of the company and therefore compromise its business.\n\n\n**** Law of Confidentiality ****\nWhile not a strictly defined law enacted by Congress, the Law of Confidentiality is common law that protects information shared by a party who has trust and an expectation of privacy from the party they share the information with. If the content of search queries and the logs they are stored in is thought of in the same manner as information shared with a physician, as it is similarly confidential, then it ought to be afforded the same privacy protections.\n\n\n*** Europe ***\n\n\n**** Google Spain v. AEPD ****\n\nThe European Court of Justice ruled in 2014 that its citizens had the \"Right to Be Forgotten\" in the Google Spain SL v. Agencia Espa\u00f1ola de Protecci\u00f3n de Datos case, which meant that they had the right to demand search engines wipe any data collected on them. While this single court decision did not directly establish the \"right to be forgotten\", the court interpreted existing law to mean that people had the right to request that some information about them be wiped from search results provided by search engine companies like Google. The background of this case is that one Spanish citizen, Mario Costeja Gonzalez, set out to erase himself from Google's search results because they revealed potentially compromising information about his past debts. In the ruling in favor of Mario Costeja Gonzalez, the court noted that search engines can significantly impact the privacy rights of many people and that Google controlled the dissemination of personal data. This court decision did not claim that all citizens should be able to request that information about them be completely wiped from Google at any time, but rather that there are specific types of information, particularly information that is obstructing one's right to be forgotten, that do not need to be so easily accessible on search engines.\n\n\n**** General Data Protection Regulation (GDPR) ****\nThe GDPR is a European regulation that was put in place to protect data and provide privacy to European citizens, regardless of whether they are physically in the European Union. This means that countries around the globe have had to comply with their rules so that any European citizen residing in them is afforded the proper protections. The regulation became enforceable in May 2018.\nQuestion: How can users protect their privacy when using email services provided by search engines like Google and Yahoo?. Whats the answer?",
    "context": "",
    "output": "Users can protect their privacy when using email services provided by search engines like Google and Yahoo by being aware that these services may collect and use their data for targeted advertising and other purposes. Users should read the privacy policies carefully, use strong and unique passwords, and consider using encryption or other security measures to protect their communications.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How can users protect their privacy when using email services provided by search engines like Google and Yahoo?",
      "answer": "Users can protect their privacy when using email services provided by search engines like Google and Yahoo by being aware that these services may collect and use their data for targeted advertising and other purposes. Users should read the privacy policies carefully, use strong and unique passwords, and consider using encryption or other security measures to protect their communications.",
      "context": "Search engine privacy\n\n==Introduction==\nSearch engine privacy is a subset of internet privacy that deals with user data being collected by search engines. Both types of privacy fall under the umbrella of information privacy. Privacy concerns regarding search engines can take many forms, such as the ability for search engines to log individual search queries, browsing history, IP addresses, and cookies of users, and conducting user profiling in general. The collection of personally identifiable information (PII) of users by search engines is referred to as \"tracking\".This is controversial because search engines often claim to collect a user's data in order to better tailor results to that specific user and to provide the user with a better searching experience. However, search engines can also abuse and compromise its users' privacy by selling their data to advertisers for profit. In the absence of regulations, users must decide what is more important to their search engine experience: relevance and speed of results or their privacy, and choose a search engine accordingly.The legal framework for protecting user privacy is not very solid. The most popular search engines collect personal information, but other search engines that are focused on privacy have cropped up recently. There have been several well publicized breaches of search engine user privacy that occurred with companies like AOL and Yahoo. For individuals interested in preserving their privacy, there are options available to them, such as using software like Tor which makes the user's location and personal information anonymous or using a privacy focused search engine.\n\n\n\n== Privacy policies ==\nSearch engines generally publish privacy policies to inform users about what data of theirs may be collected and what purposes it may be used for. While these policies may be an attempt at transparency by search engines, many people never read them and are therefore unaware of how much of their private information, like passwords and saved files, are collected from cookies and may be logged and kept by the search engine. This ties in with the phenomenon of notice and consent, which is how many privacy policies are structured.\nNotice and consent policies essentially consist of a site showing the user a privacy policy and having them click to agree. This is intended to let the user freely decide whether or not to go ahead and use the website. This decision, however, may not actually be made so freely because the costs of opting out can be very high. Another big issue with putting the privacy policy in front of users and having them accept quickly is that they are often very hard to understand, even in the unlikely case that a user decides to read them. Privacy minded search engines, such as DuckDuckGo, state in their privacy policies that they collect much less data than search engines such as Google or Yahoo, and may not collect any. As of 2008, search engines were not in the business of selling user data to third parties, though they do note in their privacy policies that they comply with government subpoenas.\n\n\n*** Google and Yahoo ***\nGoogle, founded in 1998, is the most widely used search engine, receiving billions and billions of search queries every month. Google logs all search terms in a database along with the date and time of search, browser and operating system, IP address of user, the Google cookie, and the URL that shows the search engine and search query. The privacy policy of Google states that they pass user data on to various affiliates, subsidiaries, and \"trusted\" business partners.Yahoo, founded in 1995, also collects user data. It is a well-known fact that users do not read privacy policies, even for services that they use daily, such as Yahoo! Mail and Gmail. This persistent failure of consumers to read these privacy policies can be disadvantageous to them because while they may not pick up on differences in the language of privacy policies, judges in court cases certainly do. This means that search engine and email companies like Google and Yahoo are technically able to keep up the practice of targeting advertisements based on email content since they declare that they do so in their privacy policies. A study was done to see how much consumers cared about privacy policies of Google, specifically Gmail, and their detail, and it determined that users often thought that Google's practices were somewhat intrusive but that users would not often be willing to counteract this by paying a premium for their privacy.\n\n\n*** DuckDuckGo ***\nDuckDuckGo, founded in 2008, claims to be privacy focused. DuckDuckGo does not collect or share any personal information of users, such as IP addresses or cookies, which other search engines usually do log and keep for some time. It also does not have spam, and protects user privacy further by anonymizing search queries from the website the user chooses and using encryption. Similarly privacy oriented search engines include Startpage and Disconnect.\n\n== Types of data collected by search engines ==\nMost search engines can, and do, collect personal information about their users according to their own privacy policies. This user data could be anything from location information to cookies, IP addresses, search query histories, click-through history, and online fingerprints. This data is often stored in large databases, and users may be assigned numbers in an attempt to provide them with anonymity.\nData can be stored for an extended period of time. For example, the data collected by Google on its users is retained for up to 9 months. Some studies state that this number is actually 18 months. This data is used for various reasons such as optimizing and personalizing search results for users, targeting advertising, and trying to protect users from scams and phishing attacks. Such data can be collected even when a user is not logged in to their account or when using a different IP address by using cookies.\n\n\n*** Uses ***\n\n\n**** User profiling and personalization ****\nWhat search engines often do once they have collected information about a user's habits is to create a profile of them, which helps the search engine decide which links to show for different search queries submitted by that user or which ads to target them with. An interesting development in this field is the invention of automated learning, also known as machine learning. Using this, search engines can refine their profiling models to more accurately predict what any given user may want to click on by doing A/B testing of results offered to users and measuring the reactions of users.Companies like Google, Netflix, YouTube, and Amazon have all started personalizing results more and more. One notable example is how Google Scholar takes into account the publication history of a user in order to produce results it deems relevant. Personalization also occurs when Amazon recommends books or when IMDb suggests movies by using previously collected information about a user to predict their tastes. For personalization to occur, a user need not even be logged into their account.\n\n\n**** Targeted advertising ****\nThe internet advertising company DoubleClick, which helps advertisers target users for specific ads, was bought by Google in 2008 and was a subsidiary until June 2018, when Google rebranded and merged DoubleClick into its Google Marketing Platform. DoubleClick worked by depositing cookies on user's computers that would track sites they visited with DoubleClick ads on them. There was a privacy concern when Google was in the process of acquiring DoubleClick that the acquisition would let Google create even more comprehensive profiles of its users since they would be collecting data about search queries and additionally tracking websites visited. This could lead to users being shown ads that are increasingly effective with the use of behavioral targeting. With more effective ads comes the possibility of more purchases from consumers that they may not have made otherwise. In 1994, a conflict between selling ads and relevance of results on search engines began. This was sparked by the development of the cost-per-click model, which challenged the methods of the already-created cost-per-mille model. The cost-per-click method was directly related to what users searched, whereas the cost-per-mille method was directly influenced by how much a company could pay for an ad, no matter how many times people interacted with it.\n\n\n**** Improving search quality ****\nBesides ad targeting and personalization, Google also uses data collected on users to improve the quality of searches. Search result click histories and query logs are crucial in helping search engines optimize search results for individual users. Search logs also help search engines in the development of the algorithms they use to return results, such as Google's well known PageRank. An example of this is how Google uses databases of information to refine Google Spell Checker.\n\n\n*** Privacy organizations ***\nThere are many who believe that user profiling is a severe invasion of user privacy, and there are organizations such as the Electronic Privacy Information Center (EPIC) and Privacy International that are focused on advocating for user privacy rights. In fact, EPIC filed a complaint in 2007 with the Federal Trade Commission claiming that Google should not be able to acquire DoubleClick on the grounds that it would compromise user privacy.\n\n== Users' perception of privacy ==\nExperiments have been done to examine consumer behavior when given information on the privacy of retailers by integrating privacy ratings with search engines. Researchers used a search engine for the treatment group called Privacy Finder, which scans websites and automatically generates an icon to show the level of privacy the site will give the consumer as it compares to the privacy policies that consumer has specified that they prefer. The results of the experiment were that subjects in the treatment group, those who were using a search engine that indicated privacy levels of websites, purchased products from websites that gave them higher levels of privacy, whereas the participants in the control groups opted for the products that were simply the cheapest. The study participants also were given financial incentive because they would get to keep leftover money from purchases. This study suggests that since participants had to use their own credit cards, they had a significant aversion to purchasing products from sites that did not offer the level of privacy they wanted, indicating that consumers value their privacy monetarily.\n\n== Ethical debates ==\nMany individuals and scholars have recognized the ethical concerns regarding search engine privacy.\n\n\n*** Pro data collection ***\nThe collection of user data by search engines can be viewed as a positive practice because it allows the search engine to personalize results. This implies that users would receive more relevant results, and be shown more relevant advertisements, when their data, such as past search queries, location information, and clicks, is used to create a profile for them. Also, search engines are generally free of charge for users and can remain afloat because one of their main sources of revenue is advertising, which can be more effective when targeted.\n\n\n*** Anti-data collection ***\nThis collection of user data can also be seen as an overreach by private companies for their own financial gain or as an intrusive surveillance tactic. Search engines can make money using targeted advertising because advertisers are willing to pay a premium to present their ads to the most receptive consumers. Also, when a search engine collects and catalogs large amounts of data about its users, there is the potential for it to be leaked accidentally or breached. The government can also subpoena user data from search engines when they have databases of it. Search query database information may also be subpoenaed by private litigants for use in civil cases, such as divorces or employment disputes.\n\n== Data and privacy breaches ==\n\n\n*** AOL search data leak ***\nOne major controversy regarding search engine privacy was the AOL search data leak of 2006. For academic and research purposes, AOL made public a list of about 20 million search queries made by about 650,000 unique users. Although they assigned unique identification numbers to the users instead of attaching names to each query, it was still possible to ascertain the true identities of many users simply by analyzing what they had searched, including locations near them and names of friends and family members. A notable example of this was how the New York Times identified Thelma Arnold through \"reverse searching\". Users also sometimes do \"ego searches\" where they search themselves to see what information about them is on the internet, making it even easier to identify supposedly anonymous users. Many of the search queries released by AOL were incriminating or seemingly extremely private, such as \"how to kill your wife\" and \"can you adopt after a suicide attempt\". This data has since been used in several experiments that attempt to measure the effectiveness of user privacy solutions.\n\n\n*** Google and Yahoo ***\nBoth Google and Yahoo were subjects of a Chinese hack in 2010. While Google responded to the situation seriously by hiring new cybersecurity engineers and investing heavily into securing user data, Yahoo took a much more lax approach. Google started paying hackers to find vulnerabilities in 2010 while it took Yahoo until 2013 to follow suit. Yahoo was also identified in the Snowden data leaks as a common hacking target for spies of various nations, and Yahoo still did not give its newly hired chief information security officer the resources to really effect change within the company. In 2012, Yahoo hired Marissa Mayer, previously a Google employee, to be the new CEO, but she chose not to invest much in the security infrastructure of Yahoo and went as far as to refuse the implementation of a basic and standard security measure to force the reset of all passwords after a breach.Yahoo is known for being the subject of multiple breaches and hacks that have compromised large amounts of user data. As of late 2016, Yahoo had announced that at least 1.5 billion user accounts had been breached during 2013 and 2014. The breach of 2013 compromised over a billion accounts while the breach of 2014 included about 500 million accounts. The data compromised in the breaches included personally identifiable information such as phone numbers, email addresses, and birth dates as well as information like security questions (used to reset passwords) and encrypted passwords. Yahoo made a statement saying that their breaches were a result of state sponsored actors, and in 2017, two Russian intelligence officers were indicted by the United States Department of Justice as part of a conspiracy to hack Yahoo and steal user data. As of 2016, the Yahoo breaches of 2013 and 2014 were the largest of all time.In October 2018, there was a Google+ data breach that potentially affected about 500,000 accounts which led to the shutdown of the Google+ platform.\n\n\n*** Government subpoenas of data ***\nThe government may want to subpoena user data from search engines for any number of reasons, which is why it a big threat to user privacy. In 2006, they wanted it as part of their defense of COPA, and only Google refused to comply. While protecting the online privacy of children may be an honorable goal, there are concerns about whether the government should have access to such personal data to achieve it. At other times, they may want it for national security purposes; access to big databases of search queries in order to prevent terrorist attacks is a common example of this.Whatever the reason, it is clear that the fact that search engines do create and maintain these databases of user data is what makes it possible for the government to access it. Another concern regarding government access to search engine user data is \"function creep\", a term that here refers to how data originally collected by the government for national security purposes may eventually be used for other purposes, such as debt collection. This would indicate to many a government overreach. While protections for search engine user privacy have started developing recently, the government has increasingly been on the side that wants to ensure search engines retain data, making users less protected and their data more available for anyone to subpoena.\n\n== Methods for increasing privacy ==\n\n\n*** Switching search engines ***\nA different, although popular, route for a privacy centered user to take is to simply start using a privacy oriented search engine, such as DuckDuckGo. This search engine maintains the privacy of its users by not collecting data on or tracking its users. While this may sound simple, users must take into account the trade-off between privacy and relevant results when deciding to switch search engines. Results to search queries can be very different when the search engine has no search history to aid it in personalization.\n\n\n*** Using privacy oriented browsers ***\nMozilla is known for its beliefs in protecting user privacy on Firefox. Mozilla Firefox users have the capability to delete the tracking cookie that Google places on their computer, making it much harder for Google to group data. Firefox also has a button called \"Clear Private Data\", which allows users to have more control over their settings. Internet Explorer users have this option as well. When using a browser like Google Chrome or Safari, users also have the option to browse in \"incognito\" or \"private browsing\" modes respectively. When in these modes, the user's browsing history and cookies are not collected.\n\n\n*** Opting out ***\nThe Google, Yahoo!, AOL, and MSN search engines all allow users to opt out of the behavioral targeting they use. Users can also delete search and browsing history at any time. The Ask.com search engine also has AskEraser, which, when used, purges user data from their servers. Deleting a user's profile and history of data from search engine logs also helps protect user privacy in the event a government agency wants to subpoena it. If there are no records, there is nothing the government can access. It is important to note that simply deleting your browsing history does not delete all the information the search engine has on you, some companies do not delete the data associated with your account when you clear your browsing history. For companies that do delete user data, they usually do not delete all of it keeping records of how you used the search engine.\n\n\n*** Social network solution ***\nAn innovative solution, proposed by researchers Viejo and Castell\u00e0-Roca, is a social network solution whereby user profiles are distorted. In their plan, each user would belong to a group, or network, of people who all use the search engine. Every time somebody wanted to submit a search query, it would be passed on to another member of the group to submit on their behalf until someone submitted it. This would ideally lead to all search queries being divvied up equally between all members of the network. This way, the search engine cannot make a useful profile of any individual user in the group since it has no way to discern which query actually belonged to each user.\n\n\n*** Delisting and reordering ***\nAfter the Google Spain v. AEPD case, it was established that people had the right to request that search engines delete personal information from their search results in compliance with other European data protection regulations. This process of simply removing certain search results is called de-listing. While effective in protecting the privacy of those who wish information about them to not be accessed by anyone using a search engine, it does not necessarily protect the contextual integrity of search results. For data that is not highly sensitive or compromising, reordering search results is another option where people would be able to rank how relevant certain data is at any given point in time, which would then alter results given when someone searched their name.\n\n\n*** Anonymity networks ***\nA sort of DIY option for privacy minded users is to use a software like Tor, which is an anonymity network. Tor functions by encrypting user data and routing queries through thousands of relays. While this process is effective at masking IP addresses, it can slow the speed of results. While Tor may work to mask IP addresses, there have also been studies that show that a simulated attacker software could still match search queries to users even when anonymized using Tor.\n\n\n*** Unlinkability and indistinguishability ***\nUnlinkability and indistinguishability are also well-known solutions to search engine privacy, although they have proven somewhat ineffective in actually providing users with anonymity from their search queries. Both unlinkability and indistinguishability solutions try to anonymize search queries from the user who made them, therefore making it impossible for the search engine to definitively link a specific query with a specific user and create a useful profile on them. This can be done in a couple of different ways.\n\n\n**** Unlinkability ****\nAnother way for the user to hide information such as their IP address from the search engine is an unlinkability solution. This is perhaps more simple and easy for the user because any user can do this by using a VPN, although it still does not guarantee total privacy from the search engine.\n\n\n**** Indistinguishability ****\nOne way is for the user to use a plugin or software that generates multiple different search queries for every real search query the user makes. This is an indistinguishability solution, and it functions by obscuring the real searches a user makes so that a search engine cannot tell which queries are the software's and which are the user's. Then, it is more difficult for the search engine to use the data it collects on a user to do things like target ads.\n\n== Legal rights and court cases ==\nBeing that the internet and search engines are relatively recent creations, no solid legal framework for privacy protections in terms of search engines has been put in place. However, scholars do write about the implications of existing laws on privacy in general to inform what right to privacy search engine users have. As this is a developing field of law, there have been several lawsuits with respect to the privacy search engines are expected to afford to their users.\n\n\n*** United States ***\n\n\n**** The Fourth Amendment ****\n\nThe Fourth Amendment is well known for the protections it offers citizens from unreasonable searches and seizures, but in Katz v. United States (1967), these protections were extended to cover intrusions of privacy of individuals, in addition to simply intrusion of property and people. Privacy of individuals is a broad term, but it is not hard to imagine that it includes the online privacy of an individual.\n\n\n**** The Sixth Amendment ****\n\nThe Confrontation Clause of the Sixth Amendment is applicable to the protection of big data from government surveillance. The Confrontation Clause essentially states that defendants in criminal cases have the right to confront witnesses who provide testimonial statements. If a search engine company like Google gives information to the government to prosecute a case, these witnesses are the Google employees involved in the process of selecting which data to hand over to the government. The specific employees who must be available to be confronted under the Confrontation Clause are the producer who decides what data is relevant and provides the government with what they've asked for, the Google analyst who certifies the proper collection and transmission of data, and the custodian who keeps records. The data these employees of Google curate for trial use is then thought of as testimonial statement. The overall effectiveness of the Confrontation Clause on search engine privacy is that it places a check on how the government can use big data and provides defendants with protection from human error.\n\n\n**** Katz v. United States ****\n\nThis 1967 case is prominent because it established a new interpretation of privacy under the Fourth Amendment, specifically that people had a reasonable expectation of it. Katz v. United States was about whether or not it was constitutional for the government to listen to and record, electronically using a pen register, a conversation Katz had from a public phone booth. The court ruled that it did violate the Fourth Amendment because the actions of the government were considered a \"search\" and that the government needed a warrant. When thinking about search engine data collected about users, the way telephone communications were classified under Katz v. United States could be a precedent for how it should be handled. In Katz v. United States, public telephones were deemed to have a \"vital role\" in private communications. This case took place in 1967, but surely nowadays, the internet and search engines have this vital role in private communications, and people's search queries and IP addresses can be thought of as analogous to the private phone calls placed from public booths.\n\n\n**** United States v. Miller ****\n\nThis 1976 Supreme Court case is relevant to search engine privacy because the court ruled that when third parties gathered or had information given to them, the Fourth Amendment was not applicable. Jayni Foley argues that the ruling of United States v. Miller implies that people cannot have an expectation of privacy when they provide information to third parties. When thinking about search engine privacy, this is important because people willingly provide search engines with information in the form of their search queries and various other data points that they may not realize are being collected.\n\n\n**** Smith v. Maryland ****\n\nIn the Supreme Court case Smith v. Maryland of 1979, the Supreme Court went off the precedent set in the 1976 United States v. Miller case about assumption of risk. The court ruled that the Fourth Amendment did not prevent the government from monitoring who dialed which phone numbers by using a pen register because it did not qualify as a \"search\".Both the United States v. Miller and the Smith v. Maryland cases have been used to prevent users from the privacy protections offered under the Fourth Amendment from the records that internet service providers (ISPs) keep. This is also articulated in the Sixth Circuit Guest v. Leis case as well as the United States v. Kennedy case where the courts ruled that Fourth Amendment protections did not apply to ISP customer data since they willingly provided ISPs with their information just by using the services of ISPs. Similarly, the current legal structure regarding privacy and assumption of risk can be interpreted to mean that users of search engines cannot expect privacy in regards to the data they communicate by using search engines.\n\n\n**** Electronic Communication Privacy Act ****\nThe Electronic Communications Privacy Act (ECPA) of 1986 was passed by Congress in an effort to start creating a legal structure for privacy protections in the face of new forms of technologies, although it was by no means comprehensive because there are considerations for current technologies that Congress never imagined in 1986 and could account for. The EPCA does little to regulate ISPs and mainly prevents government agencies from gathering information stored by ISPs without a warrant. What the EPCA does not do, unsurprisingly because it was enacted before internet usage became a common occurrence, is say anything about search engine privacy and the protections users are afforded in terms of their search queries.\n\n\n**** Gonzales v. Google Inc. ****\nThe background of this 2006 case is that the government was trying to bolster its defense for the Child Online Protection Act (COPA). It was doing a study to see how effective its filtering software was in regards to child pornography. To do this, the government subpoenaed search data from Google, AOL, Yahoo!, and Microsoft to use in its analysis and to show that people search information that is potentially compromising to children. This search data that the government wanted included both the URLs that appeared to users and the actual search queries of users. Of the search engines the government subpoenaed to produce search queries and URLs, only Google refused to comply with the government, even after the request was reduced in size. Google itself claimed that handing over these logs was to hand over personally identifiable information and user identities. The court ruled that Google had to hand over 50,000 randomly selected URLs to the government but not search queries because that could seed public distrust of the company and therefore compromise its business.\n\n\n**** Law of Confidentiality ****\nWhile not a strictly defined law enacted by Congress, the Law of Confidentiality is common law that protects information shared by a party who has trust and an expectation of privacy from the party they share the information with. If the content of search queries and the logs they are stored in is thought of in the same manner as information shared with a physician, as it is similarly confidential, then it ought to be afforded the same privacy protections.\n\n\n*** Europe ***\n\n\n**** Google Spain v. AEPD ****\n\nThe European Court of Justice ruled in 2014 that its citizens had the \"Right to Be Forgotten\" in the Google Spain SL v. Agencia Espa\u00f1ola de Protecci\u00f3n de Datos case, which meant that they had the right to demand search engines wipe any data collected on them. While this single court decision did not directly establish the \"right to be forgotten\", the court interpreted existing law to mean that people had the right to request that some information about them be wiped from search results provided by search engine companies like Google. The background of this case is that one Spanish citizen, Mario Costeja Gonzalez, set out to erase himself from Google's search results because they revealed potentially compromising information about his past debts. In the ruling in favor of Mario Costeja Gonzalez, the court noted that search engines can significantly impact the privacy rights of many people and that Google controlled the dissemination of personal data. This court decision did not claim that all citizens should be able to request that information about them be completely wiped from Google at any time, but rather that there are specific types of information, particularly information that is obstructing one's right to be forgotten, that do not need to be so easily accessible on search engines.\n\n\n**** General Data Protection Regulation (GDPR) ****\nThe GDPR is a European regulation that was put in place to protect data and provide privacy to European citizens, regardless of whether they are physically in the European Union. This means that countries around the globe have had to comply with their rules so that any European citizen residing in them is afforded the proper protections. The regulation became enforceable in May 2018."
    }
  },
  {
    "instruction": "The Pikachu virus was distributed primarily through Microsoft Outlook email attachments and possibly through a near-clone of the official Pok\u00e9mon website.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How was the Pikachu virus distributed?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How was the Pikachu virus distributed?",
      "answer": "The Pikachu virus was distributed primarily through Microsoft Outlook email attachments and possibly through a near-clone of the official Pok\u00e9mon website."
    }
  },
  {
    "instruction": "IPsec is a set of security extensions developed by the Internet Engineering Task Force (IETF) that provides security and authentication at the IP layer by transforming data using encryption.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the role of IPsec in securing TCP/IP communication?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the role of IPsec in securing TCP/IP communication?",
      "answer": "IPsec is a set of security extensions developed by the Internet Engineering Task Force (IETF) that provides security and authentication at the IP layer by transforming data using encryption."
    }
  },
  {
    "instruction": "Rubber-hose cryptanalysis\n\n==Introduction==\nIn cryptography, rubber-hose cryptanalysis is a euphemism for the extraction of cryptographic secrets (e.g. the password to an encrypted file) from a person by coercion or torture\u2014such as beating that person with a rubber hose, hence the name\u2014in contrast to a mathematical or technical cryptanalytic attack.\n\n\n\n== Details ==\nAccording to Amnesty International and the UN, many countries in the world routinely torture people. It is therefore logical to assume that at least some of those countries use (or would be willing to use) some form of rubber-hose cryptanalysis.  In practice, psychological coercion can prove as effective as physical torture. Not physically violent but highly intimidating methods include such tactics as the threat of harsh legal penalties. The incentive to cooperate may be some form of plea bargain, such as an offer to drop or reduce criminal charges against a suspect in return for full co-operation with investigators. Alternatively, in some countries threats may be made to prosecute as co-conspirators (or inflict violence upon) close relatives (e.g. spouse, children, or parents) of the person being questioned unless they co-operate.In some contexts, rubber-hose cryptanalysis may not be a viable attack because of a need to decrypt data covertly; information such as a password may lose its value if it is known to have been compromised.  It has been argued that one of the purposes of strong cryptography is to force adversaries to resort to less covert attacks.The earliest known use of the term was on the sci.crypt newsgroup, in a message posted 16 October 1990 by Marcus J. Ranum, alluding to corporal punishment:\n\n...the rubber-hose technique of cryptanalysis. (in which a rubber hose is applied forcefully and frequently to the soles of the feet until the key to the cryptosystem is discovered, a process that can take a surprisingly short time and is quite computationally inexpensive).\nAlthough the term is used tongue-in-cheek, its implications are serious: in modern cryptosystems, the weakest link is often the human user. A direct attack on a cipher algorithm, or the cryptographic protocols used, is likely to be much more expensive and difficult than targeting the people who use or manage the system. Thus, many cryptosystems and security systems are designed with special emphasis on keeping human vulnerability to a minimum. For example, in public-key cryptography, the defender may hold the key to encrypt the message, but not the decryption key needed to decipher it. The problem here is that the defender may be unable to convince the attacker to stop coercion. In plausibly deniable encryption, a second key is created which unlocks a second convincing but relatively harmless message (for example, apparently personal writings expressing \"deviant\" thoughts or desires of some type that are lawful but taboo), so the defender can prove to have handed over the keys whilst the attacker remains unaware of the primary hidden message. In this case, the designer's expectation is that the attacker will not realize this, and forego threats or actual torture. The risk, however, is that the attacker may be aware of deniable encryption and will assume the defender knows more than one key, meaning the attacker may refuse to stop coercing the defender even if one or more keys are revealed: on the assumption the defender is still withholding additional keys which hold additional information.\n\n== In law ==\nIn some jurisdictions, statutes assume the opposite\u2014that human operators know (or have access to) such things as session keys, an assumption which parallels that made by rubber-hose practitioners. An example is the United Kingdom's Regulation of Investigatory Powers Act, which makes it a crime not to surrender encryption keys on demand from a government official authorized by the act.\nAccording to the Home Office, the burden of proof that an accused person is in possession of a key rests on the prosecution; moreover, the act contains a defense for operators who have lost or forgotten a key, and they are not liable if they are judged to have done what they can to recover a key.\n\n== Possible case ==\nIn the lead-up to the 2017 Kenyan general election, the head of information, communication, and technology at the Independent Electoral and Boundaries Commission, Christopher Msando, was murdered. He had played a major role in developing the new voting system for the election. His body showed apparent marks of torture, and there were concerns that the murderers had tried to get password information out of him.\n\n== In popular culture ==\nA well-known xkcd comic (xkcd 538: Security) describes the issue.  In the first panel a crypto nerd imagines that due to his advanced encryption (4096-bit RSA), the crackers will be ultimately defeated, despite having access to million-dollar hardware. In the second panel, the people with the desire to access this information use a five-dollar wrench and torture to coerce the nerd to give them the password.\n\nAnswer this question \"What is the defense for operators who have lost or forgotten encryption keys in the United Kingdom's Regulation of Investigatory Powers Act?\" using the text above.",
    "context": "",
    "output": "The defense for operators who have lost or forgotten encryption keys in the United Kingdom's Regulation of Investigatory Powers Act is that they are not liable if they are judged to have done what they can to recover a key.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the defense for operators who have lost or forgotten encryption keys in the United Kingdom's Regulation of Investigatory Powers Act?",
      "answer": "The defense for operators who have lost or forgotten encryption keys in the United Kingdom's Regulation of Investigatory Powers Act is that they are not liable if they are judged to have done what they can to recover a key.",
      "context": "Rubber-hose cryptanalysis\n\n==Introduction==\nIn cryptography, rubber-hose cryptanalysis is a euphemism for the extraction of cryptographic secrets (e.g. the password to an encrypted file) from a person by coercion or torture\u2014such as beating that person with a rubber hose, hence the name\u2014in contrast to a mathematical or technical cryptanalytic attack.\n\n\n\n== Details ==\nAccording to Amnesty International and the UN, many countries in the world routinely torture people. It is therefore logical to assume that at least some of those countries use (or would be willing to use) some form of rubber-hose cryptanalysis.  In practice, psychological coercion can prove as effective as physical torture. Not physically violent but highly intimidating methods include such tactics as the threat of harsh legal penalties. The incentive to cooperate may be some form of plea bargain, such as an offer to drop or reduce criminal charges against a suspect in return for full co-operation with investigators. Alternatively, in some countries threats may be made to prosecute as co-conspirators (or inflict violence upon) close relatives (e.g. spouse, children, or parents) of the person being questioned unless they co-operate.In some contexts, rubber-hose cryptanalysis may not be a viable attack because of a need to decrypt data covertly; information such as a password may lose its value if it is known to have been compromised.  It has been argued that one of the purposes of strong cryptography is to force adversaries to resort to less covert attacks.The earliest known use of the term was on the sci.crypt newsgroup, in a message posted 16 October 1990 by Marcus J. Ranum, alluding to corporal punishment:\n\n...the rubber-hose technique of cryptanalysis. (in which a rubber hose is applied forcefully and frequently to the soles of the feet until the key to the cryptosystem is discovered, a process that can take a surprisingly short time and is quite computationally inexpensive).\nAlthough the term is used tongue-in-cheek, its implications are serious: in modern cryptosystems, the weakest link is often the human user. A direct attack on a cipher algorithm, or the cryptographic protocols used, is likely to be much more expensive and difficult than targeting the people who use or manage the system. Thus, many cryptosystems and security systems are designed with special emphasis on keeping human vulnerability to a minimum. For example, in public-key cryptography, the defender may hold the key to encrypt the message, but not the decryption key needed to decipher it. The problem here is that the defender may be unable to convince the attacker to stop coercion. In plausibly deniable encryption, a second key is created which unlocks a second convincing but relatively harmless message (for example, apparently personal writings expressing \"deviant\" thoughts or desires of some type that are lawful but taboo), so the defender can prove to have handed over the keys whilst the attacker remains unaware of the primary hidden message. In this case, the designer's expectation is that the attacker will not realize this, and forego threats or actual torture. The risk, however, is that the attacker may be aware of deniable encryption and will assume the defender knows more than one key, meaning the attacker may refuse to stop coercing the defender even if one or more keys are revealed: on the assumption the defender is still withholding additional keys which hold additional information.\n\n== In law ==\nIn some jurisdictions, statutes assume the opposite\u2014that human operators know (or have access to) such things as session keys, an assumption which parallels that made by rubber-hose practitioners. An example is the United Kingdom's Regulation of Investigatory Powers Act, which makes it a crime not to surrender encryption keys on demand from a government official authorized by the act.\nAccording to the Home Office, the burden of proof that an accused person is in possession of a key rests on the prosecution; moreover, the act contains a defense for operators who have lost or forgotten a key, and they are not liable if they are judged to have done what they can to recover a key.\n\n== Possible case ==\nIn the lead-up to the 2017 Kenyan general election, the head of information, communication, and technology at the Independent Electoral and Boundaries Commission, Christopher Msando, was murdered. He had played a major role in developing the new voting system for the election. His body showed apparent marks of torture, and there were concerns that the murderers had tried to get password information out of him.\n\n== In popular culture ==\nA well-known xkcd comic (xkcd 538: Security) describes the issue.  In the first panel a crypto nerd imagines that due to his advanced encryption (4096-bit RSA), the crackers will be ultimately defeated, despite having access to million-dollar hardware. In the second panel, the people with the desire to access this information use a five-dollar wrench and torture to coerce the nerd to give them the password."
    }
  },
  {
    "instruction": "Context: Identity driven networking\n\n==Introduction==\nIdentity driven networking (IDN) is the process of applying network controls to a network device access based on the identity of an individual or a group of individuals responsible to or operating the device. Individuals are identified, and the network is tuned to respond to their presence by context.\nThe OSI model provides a method to deliver network traffic, not only to the system but to the application that requested or is listening for data. These applications can operate either as a system based user-daemon process, or as a user application such as a web browser.\nInternet security is built around the idea that the ability to request or respond to requests should be subjected to some degree of authentication, validation, authorization, and policy enforcement. Identity driven networking endeavors to resolve user and system based policy into a single management paradigm.\nSince the internet comprises a vast range of devices and applications there are also many boundaries and therefore ideas on how to resolve connectivity to users within those boundaries. An endeavor to overlay the system with an identity framework must first decide what an Identity is, determine it, and only then use existing controls to decide what is intended with this new information.\n\n\n\n== The Identity ==\nA digital identity represents the connectedness between the real and some projection of an identity; and it may incorporate references to devices as well as resources and policies.\nIn some systems, policies provide the entitlements that an identity can claim at any particular point in time and space. For example, a person may be entitled to some privileges during work from their workplace that may be denied from home out of hours.\n\n== How it might work ==\nBefore a user gets to the network there is usually some form of machine authentication, this probably verifies and configures the system for some basic level of access. Short of mapping a user to a MAC address prior or during this process (802.1x) it is not simple to have users authenticate at this point. It is more usual for a user to attempt to authenticate once the system processes (daemons) are started, and this may well require the network configuration to have already been performed.\nIt follows that, in principle, the network identity of a device should be established before permitting network connectivity, for example by using digital certificates in place of hardware addresses which are trivial to spoof as device identifiers.  Furthermore, a consistent identity model has to account for typical network devices such as routers and switches which can't depend on user identity, since no distinctive user is associated with the device.  Absent this capability in practice, however, strong identity is not asserted at the network level.\nThe first task when seeking to apply Identity Driven Network controls comprises some form of authentication, if not at the device level then further up the stack.  Since the first piece of infrastructure placed upon a network is often a network operating system (NOS) there will often be an Identity Authority that controls the resources that the NOS contains (usually printers and file shares). There will also be procedures to authenticate users onto it. Incorporating some form of single sign-on means that the flow on effect to other controls can be seamless.\nMany network capabilities can be made to rely upon authentication technologies for the provisioning of an access control policy.\nFor instance; Packet filtering -firewall, content-control software, Quota Management systems and Quality of service (QoS) systems are good examples of where controls can be made dependent upon authentication.\nQuestion: How can network identity be established before permitting network connectivity?. Whats the answer?",
    "context": "",
    "output": "Network identity can be established before permitting network connectivity by using digital certificates in place of hardware addresses, which are trivial to spoof as device identifiers.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How can network identity be established before permitting network connectivity?",
      "answer": "Network identity can be established before permitting network connectivity by using digital certificates in place of hardware addresses, which are trivial to spoof as device identifiers.",
      "context": "Identity driven networking\n\n==Introduction==\nIdentity driven networking (IDN) is the process of applying network controls to a network device access based on the identity of an individual or a group of individuals responsible to or operating the device. Individuals are identified, and the network is tuned to respond to their presence by context.\nThe OSI model provides a method to deliver network traffic, not only to the system but to the application that requested or is listening for data. These applications can operate either as a system based user-daemon process, or as a user application such as a web browser.\nInternet security is built around the idea that the ability to request or respond to requests should be subjected to some degree of authentication, validation, authorization, and policy enforcement. Identity driven networking endeavors to resolve user and system based policy into a single management paradigm.\nSince the internet comprises a vast range of devices and applications there are also many boundaries and therefore ideas on how to resolve connectivity to users within those boundaries. An endeavor to overlay the system with an identity framework must first decide what an Identity is, determine it, and only then use existing controls to decide what is intended with this new information.\n\n\n\n== The Identity ==\nA digital identity represents the connectedness between the real and some projection of an identity; and it may incorporate references to devices as well as resources and policies.\nIn some systems, policies provide the entitlements that an identity can claim at any particular point in time and space. For example, a person may be entitled to some privileges during work from their workplace that may be denied from home out of hours.\n\n== How it might work ==\nBefore a user gets to the network there is usually some form of machine authentication, this probably verifies and configures the system for some basic level of access. Short of mapping a user to a MAC address prior or during this process (802.1x) it is not simple to have users authenticate at this point. It is more usual for a user to attempt to authenticate once the system processes (daemons) are started, and this may well require the network configuration to have already been performed.\nIt follows that, in principle, the network identity of a device should be established before permitting network connectivity, for example by using digital certificates in place of hardware addresses which are trivial to spoof as device identifiers.  Furthermore, a consistent identity model has to account for typical network devices such as routers and switches which can't depend on user identity, since no distinctive user is associated with the device.  Absent this capability in practice, however, strong identity is not asserted at the network level.\nThe first task when seeking to apply Identity Driven Network controls comprises some form of authentication, if not at the device level then further up the stack.  Since the first piece of infrastructure placed upon a network is often a network operating system (NOS) there will often be an Identity Authority that controls the resources that the NOS contains (usually printers and file shares). There will also be procedures to authenticate users onto it. Incorporating some form of single sign-on means that the flow on effect to other controls can be seamless.\nMany network capabilities can be made to rely upon authentication technologies for the provisioning of an access control policy.\nFor instance; Packet filtering -firewall, content-control software, Quota Management systems and Quality of service (QoS) systems are good examples of where controls can be made dependent upon authentication."
    }
  },
  {
    "instruction": "Microsoft took down the Waledac botnet by winning a court order that resulted in the temporary cut-off of 277 domain names used as command and control servers, and by being granted ownership of the 277 domains used by Waledac to broadcast spam email.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How did Microsoft manage to take down the Waledac botnet?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How did Microsoft manage to take down the Waledac botnet?",
      "answer": "Microsoft took down the Waledac botnet by winning a court order that resulted in the temporary cut-off of 277 domain names used as command and control servers, and by being granted ownership of the 277 domains used by Waledac to broadcast spam email."
    }
  },
  {
    "instruction": "Bitvise software provides a GUI as well as a command-line interface to support SFTP, SSH, SCP, and VPN using the TCP/IP tunneling feature, allowing remote-based access using a tool like WinVNC.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the feature of Bitvise software that allows remote-based access using a tool like WinVNC?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the feature of Bitvise software that allows remote-based access using a tool like WinVNC?",
      "answer": "Bitvise software provides a GUI as well as a command-line interface to support SFTP, SSH, SCP, and VPN using the TCP/IP tunneling feature, allowing remote-based access using a tool like WinVNC."
    }
  },
  {
    "instruction": "FIRST, as a global forum of incident response and security teams, plays a crucial role in the response to major cybersecurity incidents by improving cooperation between security teams, building trust, and exchanging best practices and tools during these incidents.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How has FIRST been involved in the response to major cybersecurity incidents?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How has FIRST been involved in the response to major cybersecurity incidents?",
      "answer": "FIRST, as a global forum of incident response and security teams, plays a crucial role in the response to major cybersecurity incidents by improving cooperation between security teams, building trust, and exchanging best practices and tools during these incidents."
    }
  },
  {
    "instruction": "The discovery of biases in the Dragon stream cipher's primary non-linear component by Cho and Pieprzyk has led some to question the security of the cipher. However, the methods used to detect these biases require an impractical amount of data, which would not be feasible in actual use cases. This suggests that the cipher remains secure in practice, as the published analysis does not pose an immediate threat to its security. Nonetheless, the presence of biases indicates that further investigation and potential improvements to the design may be warranted.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What are the implications of the biases found in the Dragon stream cipher's primary non-linear component?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What are the implications of the biases found in the Dragon stream cipher's primary non-linear component?",
      "answer": "The discovery of biases in the Dragon stream cipher's primary non-linear component by Cho and Pieprzyk has led some to question the security of the cipher. However, the methods used to detect these biases require an impractical amount of data, which would not be feasible in actual use cases. This suggests that the cipher remains secure in practice, as the published analysis does not pose an immediate threat to its security. Nonetheless, the presence of biases indicates that further investigation and potential improvements to the design may be warranted."
    }
  },
  {
    "instruction": "The Magecart software uses the WebGL API to check for software renderers such as \"swiftshader\", \"llvmpipe\" or \"virtualbox\", which are typically used in virtual machines. If these renderers are detected, the software can assume that it is running in a virtual machine and take steps to evade detection.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How can the use of the WebGL API by the Magecart software be used to evade detection in a virtual machine?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How can the use of the WebGL API by the Magecart software be used to evade detection in a virtual machine?",
      "answer": "The Magecart software uses the WebGL API to check for software renderers such as \"swiftshader\", \"llvmpipe\" or \"virtualbox\", which are typically used in virtual machines. If these renderers are detected, the software can assume that it is running in a virtual machine and take steps to evade detection."
    }
  },
  {
    "instruction": "The initial Panda Cloud Antivirus 1.0 review found the software to have 100.00% detection rate for malware and 100.0% for malicious URLs.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What were the detection rates for malware and malicious URLs in the initial Panda Cloud Antivirus 1.0 review?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What were the detection rates for malware and malicious URLs in the initial Panda Cloud Antivirus 1.0 review?",
      "answer": "The initial Panda Cloud Antivirus 1.0 review found the software to have 100.00% detection rate for malware and 100.0% for malicious URLs."
    }
  },
  {
    "instruction": "The reflector's limitation in rotor cipher machines, that the encrypted version of a given letter can never be that letter itself, was a valuable aid for World War II code breakers in cracking Enigma encryption.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the significance of the reflector's limitation in rotor cipher machines?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the significance of the reflector's limitation in rotor cipher machines?",
      "answer": "The reflector's limitation in rotor cipher machines, that the encrypted version of a given letter can never be that letter itself, was a valuable aid for World War II code breakers in cracking Enigma encryption."
    }
  },
  {
    "instruction": "The EU Trust List is a registry established under eIDAS that lists trust service providers and their qualified services. To provide qualified trust services, trust service providers must be included on the EU Trust List and adhere to the stringent guidelines established by eIDAS.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the EU Trust List, and what is its role in relation to trust service providers?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the EU Trust List, and what is its role in relation to trust service providers?",
      "answer": "The EU Trust List is a registry established under eIDAS that lists trust service providers and their qualified services. To provide qualified trust services, trust service providers must be included on the EU Trust List and adhere to the stringent guidelines established by eIDAS."
    }
  },
  {
    "instruction": "Context: Nothing-up-my-sleeve number\n\n==Introduction==\nIn cryptography, nothing-up-my-sleeve numbers are any numbers which, by their construction, are above suspicion of hidden properties. They are used in creating cryptographic functions such as hashes and ciphers.  These algorithms often need randomized constants for mixing or initialization purposes. The cryptographer may wish to pick these values in a way that demonstrates the constants were not selected for a nefarious purpose, for example, to create a backdoor to the algorithm. These fears can be allayed by using numbers created in a way that leaves little room for adjustment.  An example would be the use of initial digits from the number \u03c0 as the constants. Using digits of \u03c0 millions of places after the decimal point would not be considered trustworthy because the algorithm designer might have selected that starting point because it created a secret weakness the designer could later exploit.\nDigits in the positional representations of real numbers such as \u03c0, e, and irrational roots are believed to appear with equal frequency (see normal number). Such numbers can be viewed as the opposite extreme of Chaitin\u2013Kolmogorov random numbers in that they appear random but have very low information entropy. Their use is motivated by early controversy over the U.S. Government's 1975 Data Encryption Standard, which came under criticism because no explanation was supplied for the constants used in its S-box (though they were later found to have been carefully selected to protect against the then-classified technique of differential cryptanalysis). Thus a need was felt for a more transparent way to generate constants used in cryptography.\n\"Nothing up my sleeve\" is a phrase associated with magicians, who sometimes preface a magic trick by holding open their sleeves to show they have no objects hidden inside.\n\n== Examples ==\nRon Rivest used the trigonometric sine function to generate constants for the widely used MD5 hash.\nThe U.S. National Security Agency used the square roots of small integers to produce the constants used in its \"Secure Hash Algorithm\" SHA-1. The SHA-2 functions use the square roots and cube roots of small primes. SHA-1 also uses 0123456789ABCDEFFEDCBA9876543210F0E1D2C3 as its initial hash value.\nThe Blowfish encryption algorithm uses the binary representation of \u03c0 (without the initial 3) to initialize its key schedule.\nRFC 3526 describes prime numbers for internet key exchange that are also generated from \u03c0.\nThe S-box of the NewDES cipher is derived from the United States Declaration of Independence.\nThe AES candidate DFC derives all of its arbitrary constants, including all entries of the S-box, from the binary expansion of e.\nThe ARIA key schedule uses the binary expansion of 1/\u03c0.\nThe key schedule of the RC5 cipher uses binary digits from both e and the golden ratio.\nMultiple ciphers including TEA and Red Pike use 2654435769 or 0x9e3779b9 which is \u230a232/\u03d5\u230b, where \u03d5 is the golden ratio.\nThe BLAKE hash function, a finalist in the SHA-3 competition, uses a table of 16 constant words which are the leading 512 or 1024 bits of the fractional part of \u03c0.\nThe key schedule of the KASUMI cipher uses 0x123456789ABCDEFFEDCBA9876543210 to derive the modified key.\nThe Salsa20 family of ciphers use the ASCII string \"expand 32-byte k\" as constants in its block initialization process.\nBcrypt uses the string \"OrpheanBeholderScryDoubt\" as an initialization string\n\n== Counterexamples ==\nThe Streebog hash function S-box was claimed to be generated randomly, but was reverse-engineered and proven to be generated algorithmically with some \"puzzling\" weaknesses.\nThe Data Encryption Standard (DES) has constants that were given out by NSA. They turned out to be far from random, but instead made the algorithm resilient against differential cryptanalysis, a method not publicly known at the time.\nDual_EC_DRBG, a NIST-recommended cryptographic pseudo-random bit generator, came under criticism in 2007 because constants recommended for use in the algorithm could have been selected in a way that would permit their author to predict future outputs given a sample of past generated values. In September 2013 The New York Times wrote that \"internal memos leaked by a former NSA contractor, Edward Snowden, suggest that the NSA generated one of the random number generators used in a 2006 NIST standard\u2014called the Dual EC DRBG standard\u2014which contains a back door for the NSA.\"\nP curves are standardized by NIST for elliptic curve cryptography. The coefficients in these curves are generated by hashing unexplained random seeds, such as:\nP-224: bd713447 99d5c7fc dc45b59f a3b9ab8f 6a948bc5.\nP-256: c49d3608 86e70493 6a6678e1 139d26b7 819f7e90.\nP-384: a335926a a319a27a 1d00896a 6773a482 7acdac73.Although not directly related, after the backdoor in Dual_EC_DRBG had been exposed, suspicious aspects of the NIST's P curve constants led to concerns that the NSA had chosen values that gave them an advantage in finding private keys. Since then, many protocols and programs started to use Curve25519 as an alternative to NIST P-256 curve.\n\nI no longer trust the constants. I believe the NSA has manipulated them through their relationships with industry.\n\n== Limitations ==\nBernstein and coauthors demonstrate that use of nothing-up-my-sleeve numbers as the starting point in a complex procedure for generating cryptographic objects, such as elliptic curves, may not be sufficient to prevent insertion of back doors. For example, many candidates of seemingly harmless and \"uninteresting\" simple mathematical constants exist, such as \u03c0, e, Euler gamma, \u221a2, \u221a3, \u221a5, \u221a7, log(2), (1 + \u221a5)/2, \u03b6(3), \u03b6(5), sin(1), sin(2), cos(1), cos(2), tan(1), or tan(2). For these constants, there also exists several different binary representations to choose. If a constant is used as a random seed, a large number of hash function candidates also exist for selection, such as SHA-1, SHA-256, SHA-384, SHA-512, SHA-512/256, SHA3-256, or SHA3-384.\nIf there are enough adjustable parameters in the object selection procedure, combinatorial explosion ensures that the universe of possible design choices and of apparently simple constants can be large enough so that an automatic search of the possibilities allows construction of an object with desired backdoor properties.\n\n== Footnotes ==\nQuestion: What is the initial hash value used in SHA-1 and what is its significance?\n\nAnswer:",
    "context": "",
    "output": "The initial hash value used in SHA-1 is 0123456789ABCDEFFEDCBA9876543210F0E1D2C3. This value was chosen to demonstrate that the constants were not selected for a nefarious purpose.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the initial hash value used in SHA-1 and what is its significance?",
      "answer": "The initial hash value used in SHA-1 is 0123456789ABCDEFFEDCBA9876543210F0E1D2C3. This value was chosen to demonstrate that the constants were not selected for a nefarious purpose.",
      "context": "Nothing-up-my-sleeve number\n\n==Introduction==\nIn cryptography, nothing-up-my-sleeve numbers are any numbers which, by their construction, are above suspicion of hidden properties. They are used in creating cryptographic functions such as hashes and ciphers.  These algorithms often need randomized constants for mixing or initialization purposes. The cryptographer may wish to pick these values in a way that demonstrates the constants were not selected for a nefarious purpose, for example, to create a backdoor to the algorithm. These fears can be allayed by using numbers created in a way that leaves little room for adjustment.  An example would be the use of initial digits from the number \u03c0 as the constants. Using digits of \u03c0 millions of places after the decimal point would not be considered trustworthy because the algorithm designer might have selected that starting point because it created a secret weakness the designer could later exploit.\nDigits in the positional representations of real numbers such as \u03c0, e, and irrational roots are believed to appear with equal frequency (see normal number). Such numbers can be viewed as the opposite extreme of Chaitin\u2013Kolmogorov random numbers in that they appear random but have very low information entropy. Their use is motivated by early controversy over the U.S. Government's 1975 Data Encryption Standard, which came under criticism because no explanation was supplied for the constants used in its S-box (though they were later found to have been carefully selected to protect against the then-classified technique of differential cryptanalysis). Thus a need was felt for a more transparent way to generate constants used in cryptography.\n\"Nothing up my sleeve\" is a phrase associated with magicians, who sometimes preface a magic trick by holding open their sleeves to show they have no objects hidden inside.\n\n== Examples ==\nRon Rivest used the trigonometric sine function to generate constants for the widely used MD5 hash.\nThe U.S. National Security Agency used the square roots of small integers to produce the constants used in its \"Secure Hash Algorithm\" SHA-1. The SHA-2 functions use the square roots and cube roots of small primes. SHA-1 also uses 0123456789ABCDEFFEDCBA9876543210F0E1D2C3 as its initial hash value.\nThe Blowfish encryption algorithm uses the binary representation of \u03c0 (without the initial 3) to initialize its key schedule.\nRFC 3526 describes prime numbers for internet key exchange that are also generated from \u03c0.\nThe S-box of the NewDES cipher is derived from the United States Declaration of Independence.\nThe AES candidate DFC derives all of its arbitrary constants, including all entries of the S-box, from the binary expansion of e.\nThe ARIA key schedule uses the binary expansion of 1/\u03c0.\nThe key schedule of the RC5 cipher uses binary digits from both e and the golden ratio.\nMultiple ciphers including TEA and Red Pike use 2654435769 or 0x9e3779b9 which is \u230a232/\u03d5\u230b, where \u03d5 is the golden ratio.\nThe BLAKE hash function, a finalist in the SHA-3 competition, uses a table of 16 constant words which are the leading 512 or 1024 bits of the fractional part of \u03c0.\nThe key schedule of the KASUMI cipher uses 0x123456789ABCDEFFEDCBA9876543210 to derive the modified key.\nThe Salsa20 family of ciphers use the ASCII string \"expand 32-byte k\" as constants in its block initialization process.\nBcrypt uses the string \"OrpheanBeholderScryDoubt\" as an initialization string\n\n== Counterexamples ==\nThe Streebog hash function S-box was claimed to be generated randomly, but was reverse-engineered and proven to be generated algorithmically with some \"puzzling\" weaknesses.\nThe Data Encryption Standard (DES) has constants that were given out by NSA. They turned out to be far from random, but instead made the algorithm resilient against differential cryptanalysis, a method not publicly known at the time.\nDual_EC_DRBG, a NIST-recommended cryptographic pseudo-random bit generator, came under criticism in 2007 because constants recommended for use in the algorithm could have been selected in a way that would permit their author to predict future outputs given a sample of past generated values. In September 2013 The New York Times wrote that \"internal memos leaked by a former NSA contractor, Edward Snowden, suggest that the NSA generated one of the random number generators used in a 2006 NIST standard\u2014called the Dual EC DRBG standard\u2014which contains a back door for the NSA.\"\nP curves are standardized by NIST for elliptic curve cryptography. The coefficients in these curves are generated by hashing unexplained random seeds, such as:\nP-224: bd713447 99d5c7fc dc45b59f a3b9ab8f 6a948bc5.\nP-256: c49d3608 86e70493 6a6678e1 139d26b7 819f7e90.\nP-384: a335926a a319a27a 1d00896a 6773a482 7acdac73.Although not directly related, after the backdoor in Dual_EC_DRBG had been exposed, suspicious aspects of the NIST's P curve constants led to concerns that the NSA had chosen values that gave them an advantage in finding private keys. Since then, many protocols and programs started to use Curve25519 as an alternative to NIST P-256 curve.\n\nI no longer trust the constants. I believe the NSA has manipulated them through their relationships with industry.\n\n== Limitations ==\nBernstein and coauthors demonstrate that use of nothing-up-my-sleeve numbers as the starting point in a complex procedure for generating cryptographic objects, such as elliptic curves, may not be sufficient to prevent insertion of back doors. For example, many candidates of seemingly harmless and \"uninteresting\" simple mathematical constants exist, such as \u03c0, e, Euler gamma, \u221a2, \u221a3, \u221a5, \u221a7, log(2), (1 + \u221a5)/2, \u03b6(3), \u03b6(5), sin(1), sin(2), cos(1), cos(2), tan(1), or tan(2). For these constants, there also exists several different binary representations to choose. If a constant is used as a random seed, a large number of hash function candidates also exist for selection, such as SHA-1, SHA-256, SHA-384, SHA-512, SHA-512/256, SHA3-256, or SHA3-384.\nIf there are enough adjustable parameters in the object selection procedure, combinatorial explosion ensures that the universe of possible design choices and of apparently simple constants can be large enough so that an automatic search of the possibilities allows construction of an object with desired backdoor properties.\n\n== Footnotes =="
    }
  },
  {
    "instruction": "The source code of StealthNet contains no documentation at all, making it difficult for developers to understand and modify the code.\n\nWrite a question about the text above.",
    "context": "",
    "output": "Why is the source code of StealthNet lacking in documentation?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "Why is the source code of StealthNet lacking in documentation?",
      "answer": "The source code of StealthNet contains no documentation at all, making it difficult for developers to understand and modify the code."
    }
  },
  {
    "instruction": "After discontinuing Onavo Protect and Facebook Research, Facebook released a new market research app named Facebook Study, which addresses concerns with previous incarnations of the research app by not using a VPN or a root certificate to conduct its data collection.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What measures has Facebook taken to address concerns about data privacy in its market research programs?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What measures has Facebook taken to address concerns about data privacy in its market research programs?",
      "answer": "After discontinuing Onavo Protect and Facebook Research, Facebook released a new market research app named Facebook Study, which addresses concerns with previous incarnations of the research app by not using a VPN or a root certificate to conduct its data collection."
    }
  },
  {
    "instruction": "HBSS administrators are required to satisfactorily complete online or in-class HBSS training and be identified as an HBSS administrator. They are commonly appointed by the unit or section commander in writing.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What are the requirements for HBSS administrators in terms of training and appointment?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What are the requirements for HBSS administrators in terms of training and appointment?",
      "answer": "HBSS administrators are required to satisfactorily complete online or in-class HBSS training and be identified as an HBSS administrator. They are commonly appointed by the unit or section commander in writing."
    }
  },
  {
    "instruction": "An example of a narrowband subliminal channel for normal human-language text is defining that an even word count in a sentence is associated with the bit \"0\" and an odd word count with the bit \"1\".\n\nWrite a question about the text above.",
    "context": "",
    "output": "Can you give an example of a narrowband subliminal channel for normal human-language text?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "Can you give an example of a narrowband subliminal channel for normal human-language text?",
      "answer": "An example of a narrowband subliminal channel for normal human-language text is defining that an even word count in a sentence is associated with the bit \"0\" and an odd word count with the bit \"1\"."
    }
  },
  {
    "instruction": "Netcat\n\n==Introduction==\nnetcat (often abbreviated to nc) is a computer networking utility for reading from and writing to network connections using TCP or UDP. The command is designed to be a dependable back-end that can be used directly or easily driven by other programs and scripts. At the same time, it is a feature-rich network debugging and investigation tool, since it can produce almost any kind of connection its user could need and has a number of built-in capabilities.\nIts list of features includes port scanning, transferring files, and port listening: as with any server, it can be used as a backdoor.\n\n== Features ==\nThe original netcat's features include:\nOutbound or inbound connections, TCP or UDP, to or from any ports\nFull DNS forward/reverse checking, with appropriate warnings\nAbility to use any local source port\nAbility to use any locally configured network source address\nBuilt-in port-scanning capabilities, with randomization\nBuilt-in loose source-routing capability\nCan read command line arguments from standard input\nSlow-send mode, one line every N seconds\nHex dump of transmitted and received data\nOptional ability to let another program service establish connections\nOptional telnet-options responderRewrites like GNU's and OpenBSD's support additional features. For example, OpenBSD's nc supports TLS, and GNU netcat natively supports a tunneling mode supporting UDP and TCP (optionally allowing one to be tunneled over the other) in a single command, where other versions may require piping data from one netcat instance to another.\n\n== Examples ==\n\n\n*** Opening a raw connection to port 25 ***\nnc mail.server.net 25\n\n\n*** Performing an HTTP request ***\n\nThe full response (including HTTP headers) will be dumped to standard output.\n\n\n*** Setting up a one-shot webserver on port 8080 to present the content of a file ***\n\nThe file can then be accessed via a web browser under http://servername:8080/. Netcat only serves the file once to the first client that connects and then exits; it also provides the content length for browsers that expect it. (This should work fine in a LAN, but may potentially fail with any kind of firewall between.) In some versions of netcat like netcat-traditional in Debian 8.6, you need to specify -p before the port number.\n\n\n*** Checking whether UDP ports (-u) 80\u201390 are open on 192.168.0.1 using zero mode I/O (-z) ***\nnc -vzu 192.168.0.1 80-90\n\nUDP tests will always show as \"open\".\n\n\n*** Test whether UDP port is open: simple UDP server and client ***\nThis test is useful, if you have shell access to the server that should be tested, but you do not know whether there is a firewall blocking a specific UDP port on the server.\nOn the listening host, i.e. on the server whose port needs to be checked, do the following:\n\nnc -l -u -p 4172\n\nOn the sending host, do the following \u2013 servname is the hostname of the listening host:\n\nnc -u servname 4172\n\nIf text typed on the sending host (type something and hit enter) is displayed also on the listening host, then the UDP port 4172 is open. If it is not open, you will get an error such as \"Connection refused\".\nThere is a caveat. On some machines, IPv6 may be the default IP version to use by netcat. Thus, the host specified by the hostname is contacted using IPv6, and the user might not know about this. Ports may appear closed in the test, even though they would be open when using IPv4. This can be difficult to notice and may cause the false impression that the port is blocked, while it is actually open. You can force the use of IPv4 by adding -4 to the options of the nc commands.\n\n\n*** Pipe via UDP (-u) with a wait time (-w) of 1 second to \"loggerhost\" on port 514 ***\necho '<0>message' | nc -w 1 -u loggerhost 514\n\n\n*** Port scanning ***\nAn uncommon use of netcat is port scanning. Netcat is not considered the best tool for this job, but it can be sufficient (a more advanced tool is nmap)\n\nnc -v -n -z -w 1 192.168.1.2 1-1000\n\nThe -n parameter here prevents DNS lookup, -z makes nc not receive any data from the server, and -w 1 makes the connection timeout after 1 second of inactivity.\n\n\n*** Proxying ***\nAnother useful behaviour is using netcat as a proxy. Both ports and hosts can be redirected. Look at this example:\n\nnc -l 12345 | nc www.google.com 80\n\nPort 12345 represents the request.\nThis starts a nc server on port 12345 and all the connections get redirected to google.com:80. If a web browser makes a request to nc, the request will be sent to google but the response will not be sent to the web browser. That is because pipes are unidirectional. This can be worked around with a named pipe to redirect the input and output.\n\nThe -c option may also be used with the ncat implementation:\n\nUsing a named pipe is a more reliable method because using -c option provides only a one-shot proxy.\nAnother useful feature is to proxy SSL connections. This way, the traffic can not be viewed in wire sniffing applications such as wireshark. This can be accomplished on UNIXes by utilizing mkfifo, netcat, and openssl.\n\n\n*** Making any process a server ***\nnetcat can be used to make any process a network server. It can listen on a port and pipe the input it receives to that process.\nThe -e option spawns the executable with its input and output redirected via network socket.\nFor example, it is possible to expose a bourne shell process to remote computers.\nTo do so, on a computer A with IP address 192.168.1.2, run this command:\n\nThen, from any other computer on the same network, one could run this nc command:\n\nIn this way, the -e option can be used to create a rudimentary backdoor. Some administrators perceive this as a risk and thus do not allow netcat on a computer. The version of netcat developed by OpenBSD that is often installed by default on distributions such as Debian and Ubuntu lacks this option due to this potential as a security risk.\n\n== ncat ==\nNcat is a similar tool to netcat provided by Nmap suite. \"While Ncat isn't built on any code from the \u201ctraditional\u201d Netcat (or any other implementation), Ncat is most definitely based on Netcat in spirit and functionality.\"Ncat features includes: ability to chain Ncats together, redirect both TCP and UDP ports to other sites, SSL support, and proxy connections via SOCKS4 or HTTP (CONNECT method) proxies (with optional proxy authentication as well).\nConnect to example.org on TCP port 8080. :  ncat example.org 8080\nListen for connections on TCP port 8080. : ncat -l 8080\nRedirect TCP port 8080 on the local machine to host on port 80. : $ ncat --sh-exec \"ncat example.org 80\" -l 8080 --keep-open\nBind to TCP port 8081 and attach /bin/bash for the world to access freely. : $ ncat --exec \"/bin/bash\" -l 8081 --keep-open\nBind a shell to TCP port 8081, limit access to hosts on a local network, and limit the maximum number of simultaneous connections to 3:\n$ ncat --exec \"/bin/bash\" --max-conns 3 --allow 192.168.0.0/24 -l 8081 --keep-open\nConnect to smtphost:25 through a SOCKS4 server on port 1080: ncat --proxy socks4host --proxy-type socks4 --proxy-auth user smtphost 25\nCreate an HTTP proxy server on localhost port 8888. : ncat -l --proxy-type http localhost 8888\nSend a file over TCP port 9899 from host2 (client) to host1 (server).\nTransfer in the other direction, turning Ncat into a \u201cone file\u201d server.\n\n\n*** Encrypted file transfer ***\nSuppose you have an SSH tunnel, and you want to copy a file to the remote machine. You could just scp it directly, but that opens up another connection. The goal is to re-use the existing connection. You can use ncat to do this:\nWhen you SSH in, add in -L 31000:127.0.0.1:31000 (this is port forwarding, sending everything from port 31000 on the remote machine to the same port on the local machine)\n\nOn the remote: ncat -lvnp 31000 127.0.0.1 > file\nOn the local: ncat -v -w 2 127.0.0.1 31000 < fileNo extra overhead. TCP takes care of error correction. SSH has already encrypted the pipe.\n\n== Ports and reimplementations ==\nThe original version of netcat was a Unix program. The last version (1.10) was released in March 1996.There are several implementations on POSIX systems, including rewrites from scratch like GNU netcat or OpenBSD netcat,\nthe latter of which supports IPv6 and TLS. The OpenBSD version has been ported to the FreeBSD base,\nWindows/Cygwin,\nand Linux.Mac OS X comes with netcat installed as of OSX 10.13 or users can use MacPorts to install a variant.A DOS version of netcat called NTOOL is included in the FreeDOS Package group Networking. It is based on the WatTCP stack and licensed under the European Union Public Licence Version 1.1.Known ports for embedded systems includes versions for Windows CE (named \"Netcat 4 wince\") or for the iPhone.BusyBox includes by default a lightweight version of netcat.\nSolaris 11 includes netcat implementation based on OpenBSD netcat.\nSocat is a more complex variant of netcat. It is larger and more flexible and has more options that must be configured for a given task.  On February 1, 2016, Santiago Zanella-Beguelin and Microsoft Vulnerability Research issued a security advisory regarding a composite Diffie-Hellman parameter which had been hard-coded into the OpenSSL implementation of socat. The implausibility that a composite might have been unintentionally introduced where a prime number is required has led to the suspicion of sabotage to introduce a backdoor software vulnerability. This socat bug affected version 1.7.3.0 and 2.0.0-b8 it was corrected in following releases from 1.7.3.1 and 2.0.0-b9.Cryptcat is a version of netcat with integrated transport encryption capabilities.\nIn the middle of 2005, Nmap announced another netcat incarnation called Ncat. It features new possibilities such as \"Connection Brokering\", TCP/UDP Redirection, SOCKS4 client and server support, ability to \"Chain\" Ncat processes, HTTP CONNECT proxying (and proxy chaining), SSL connect/listen support and IP address/connection filtering. Like Nmap, Ncat is cross-platform.\nOn some systems, modified versions or similar netcat utilities go by the command name(s) nc, ncat, pnetcat, socat, sock, socket, sbd.\n\nAnswer this question \"How can netcat be used to create a simple backdoor on a remote host, and what are the associated security risks and concerns?\" using the text above.",
    "context": "",
    "output": "Netcat can be used to create a simple backdoor on a remote host by exposing a shell process to remote computers. This can be done using the -e option in netcat. However, this practice raises significant security risks and concerns, as it can be exploited for malicious purposes and may lead to unauthorized access and data breaches.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How can netcat be used to create a simple backdoor on a remote host, and what are the associated security risks and concerns?",
      "answer": "Netcat can be used to create a simple backdoor on a remote host by exposing a shell process to remote computers. This can be done using the -e option in netcat. However, this practice raises significant security risks and concerns, as it can be exploited for malicious purposes and may lead to unauthorized access and data breaches.",
      "context": "Netcat\n\n==Introduction==\nnetcat (often abbreviated to nc) is a computer networking utility for reading from and writing to network connections using TCP or UDP. The command is designed to be a dependable back-end that can be used directly or easily driven by other programs and scripts. At the same time, it is a feature-rich network debugging and investigation tool, since it can produce almost any kind of connection its user could need and has a number of built-in capabilities.\nIts list of features includes port scanning, transferring files, and port listening: as with any server, it can be used as a backdoor.\n\n== Features ==\nThe original netcat's features include:\nOutbound or inbound connections, TCP or UDP, to or from any ports\nFull DNS forward/reverse checking, with appropriate warnings\nAbility to use any local source port\nAbility to use any locally configured network source address\nBuilt-in port-scanning capabilities, with randomization\nBuilt-in loose source-routing capability\nCan read command line arguments from standard input\nSlow-send mode, one line every N seconds\nHex dump of transmitted and received data\nOptional ability to let another program service establish connections\nOptional telnet-options responderRewrites like GNU's and OpenBSD's support additional features. For example, OpenBSD's nc supports TLS, and GNU netcat natively supports a tunneling mode supporting UDP and TCP (optionally allowing one to be tunneled over the other) in a single command, where other versions may require piping data from one netcat instance to another.\n\n== Examples ==\n\n\n*** Opening a raw connection to port 25 ***\nnc mail.server.net 25\n\n\n*** Performing an HTTP request ***\n\nThe full response (including HTTP headers) will be dumped to standard output.\n\n\n*** Setting up a one-shot webserver on port 8080 to present the content of a file ***\n\nThe file can then be accessed via a web browser under http://servername:8080/. Netcat only serves the file once to the first client that connects and then exits; it also provides the content length for browsers that expect it. (This should work fine in a LAN, but may potentially fail with any kind of firewall between.) In some versions of netcat like netcat-traditional in Debian 8.6, you need to specify -p before the port number.\n\n\n*** Checking whether UDP ports (-u) 80\u201390 are open on 192.168.0.1 using zero mode I/O (-z) ***\nnc -vzu 192.168.0.1 80-90\n\nUDP tests will always show as \"open\".\n\n\n*** Test whether UDP port is open: simple UDP server and client ***\nThis test is useful, if you have shell access to the server that should be tested, but you do not know whether there is a firewall blocking a specific UDP port on the server.\nOn the listening host, i.e. on the server whose port needs to be checked, do the following:\n\nnc -l -u -p 4172\n\nOn the sending host, do the following \u2013 servname is the hostname of the listening host:\n\nnc -u servname 4172\n\nIf text typed on the sending host (type something and hit enter) is displayed also on the listening host, then the UDP port 4172 is open. If it is not open, you will get an error such as \"Connection refused\".\nThere is a caveat. On some machines, IPv6 may be the default IP version to use by netcat. Thus, the host specified by the hostname is contacted using IPv6, and the user might not know about this. Ports may appear closed in the test, even though they would be open when using IPv4. This can be difficult to notice and may cause the false impression that the port is blocked, while it is actually open. You can force the use of IPv4 by adding -4 to the options of the nc commands.\n\n\n*** Pipe via UDP (-u) with a wait time (-w) of 1 second to \"loggerhost\" on port 514 ***\necho '<0>message' | nc -w 1 -u loggerhost 514\n\n\n*** Port scanning ***\nAn uncommon use of netcat is port scanning. Netcat is not considered the best tool for this job, but it can be sufficient (a more advanced tool is nmap)\n\nnc -v -n -z -w 1 192.168.1.2 1-1000\n\nThe -n parameter here prevents DNS lookup, -z makes nc not receive any data from the server, and -w 1 makes the connection timeout after 1 second of inactivity.\n\n\n*** Proxying ***\nAnother useful behaviour is using netcat as a proxy. Both ports and hosts can be redirected. Look at this example:\n\nnc -l 12345 | nc www.google.com 80\n\nPort 12345 represents the request.\nThis starts a nc server on port 12345 and all the connections get redirected to google.com:80. If a web browser makes a request to nc, the request will be sent to google but the response will not be sent to the web browser. That is because pipes are unidirectional. This can be worked around with a named pipe to redirect the input and output.\n\nThe -c option may also be used with the ncat implementation:\n\nUsing a named pipe is a more reliable method because using -c option provides only a one-shot proxy.\nAnother useful feature is to proxy SSL connections. This way, the traffic can not be viewed in wire sniffing applications such as wireshark. This can be accomplished on UNIXes by utilizing mkfifo, netcat, and openssl.\n\n\n*** Making any process a server ***\nnetcat can be used to make any process a network server. It can listen on a port and pipe the input it receives to that process.\nThe -e option spawns the executable with its input and output redirected via network socket.\nFor example, it is possible to expose a bourne shell process to remote computers.\nTo do so, on a computer A with IP address 192.168.1.2, run this command:\n\nThen, from any other computer on the same network, one could run this nc command:\n\nIn this way, the -e option can be used to create a rudimentary backdoor. Some administrators perceive this as a risk and thus do not allow netcat on a computer. The version of netcat developed by OpenBSD that is often installed by default on distributions such as Debian and Ubuntu lacks this option due to this potential as a security risk.\n\n== ncat ==\nNcat is a similar tool to netcat provided by Nmap suite. \"While Ncat isn't built on any code from the \u201ctraditional\u201d Netcat (or any other implementation), Ncat is most definitely based on Netcat in spirit and functionality.\"Ncat features includes: ability to chain Ncats together, redirect both TCP and UDP ports to other sites, SSL support, and proxy connections via SOCKS4 or HTTP (CONNECT method) proxies (with optional proxy authentication as well).\nConnect to example.org on TCP port 8080. :  ncat example.org 8080\nListen for connections on TCP port 8080. : ncat -l 8080\nRedirect TCP port 8080 on the local machine to host on port 80. : $ ncat --sh-exec \"ncat example.org 80\" -l 8080 --keep-open\nBind to TCP port 8081 and attach /bin/bash for the world to access freely. : $ ncat --exec \"/bin/bash\" -l 8081 --keep-open\nBind a shell to TCP port 8081, limit access to hosts on a local network, and limit the maximum number of simultaneous connections to 3:\n$ ncat --exec \"/bin/bash\" --max-conns 3 --allow 192.168.0.0/24 -l 8081 --keep-open\nConnect to smtphost:25 through a SOCKS4 server on port 1080: ncat --proxy socks4host --proxy-type socks4 --proxy-auth user smtphost 25\nCreate an HTTP proxy server on localhost port 8888. : ncat -l --proxy-type http localhost 8888\nSend a file over TCP port 9899 from host2 (client) to host1 (server).\nTransfer in the other direction, turning Ncat into a \u201cone file\u201d server.\n\n\n*** Encrypted file transfer ***\nSuppose you have an SSH tunnel, and you want to copy a file to the remote machine. You could just scp it directly, but that opens up another connection. The goal is to re-use the existing connection. You can use ncat to do this:\nWhen you SSH in, add in -L 31000:127.0.0.1:31000 (this is port forwarding, sending everything from port 31000 on the remote machine to the same port on the local machine)\n\nOn the remote: ncat -lvnp 31000 127.0.0.1 > file\nOn the local: ncat -v -w 2 127.0.0.1 31000 < fileNo extra overhead. TCP takes care of error correction. SSH has already encrypted the pipe.\n\n== Ports and reimplementations ==\nThe original version of netcat was a Unix program. The last version (1.10) was released in March 1996.There are several implementations on POSIX systems, including rewrites from scratch like GNU netcat or OpenBSD netcat,\nthe latter of which supports IPv6 and TLS. The OpenBSD version has been ported to the FreeBSD base,\nWindows/Cygwin,\nand Linux.Mac OS X comes with netcat installed as of OSX 10.13 or users can use MacPorts to install a variant.A DOS version of netcat called NTOOL is included in the FreeDOS Package group Networking. It is based on the WatTCP stack and licensed under the European Union Public Licence Version 1.1.Known ports for embedded systems includes versions for Windows CE (named \"Netcat 4 wince\") or for the iPhone.BusyBox includes by default a lightweight version of netcat.\nSolaris 11 includes netcat implementation based on OpenBSD netcat.\nSocat is a more complex variant of netcat. It is larger and more flexible and has more options that must be configured for a given task.  On February 1, 2016, Santiago Zanella-Beguelin and Microsoft Vulnerability Research issued a security advisory regarding a composite Diffie-Hellman parameter which had been hard-coded into the OpenSSL implementation of socat. The implausibility that a composite might have been unintentionally introduced where a prime number is required has led to the suspicion of sabotage to introduce a backdoor software vulnerability. This socat bug affected version 1.7.3.0 and 2.0.0-b8 it was corrected in following releases from 1.7.3.1 and 2.0.0-b9.Cryptcat is a version of netcat with integrated transport encryption capabilities.\nIn the middle of 2005, Nmap announced another netcat incarnation called Ncat. It features new possibilities such as \"Connection Brokering\", TCP/UDP Redirection, SOCKS4 client and server support, ability to \"Chain\" Ncat processes, HTTP CONNECT proxying (and proxy chaining), SSL connect/listen support and IP address/connection filtering. Like Nmap, Ncat is cross-platform.\nOn some systems, modified versions or similar netcat utilities go by the command name(s) nc, ncat, pnetcat, socat, sock, socket, sbd."
    }
  },
  {
    "instruction": "SCAP validation for a vendor of a computer system configuration scanner demonstrates that their product interoperates with other scanners and expresses scan results in a standardized way, which is beneficial for customers who need to ensure FISMA compliance.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the significance of SCAP validation for a vendor of a computer system configuration scanner?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the significance of SCAP validation for a vendor of a computer system configuration scanner?",
      "answer": "SCAP validation for a vendor of a computer system configuration scanner demonstrates that their product interoperates with other scanners and expresses scan results in a standardized way, which is beneficial for customers who need to ensure FISMA compliance."
    }
  },
  {
    "instruction": "The legacy of Anonym.OS is in its successors, Incognito OS and FreeSBIE, which also focused on providing secure and anonymous web browsing to users.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does the legacy of Anonym.OS relate to its original goal of providing secure and anonymous web browsing?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does the legacy of Anonym.OS relate to its original goal of providing secure and anonymous web browsing?",
      "answer": "The legacy of Anonym.OS is in its successors, Incognito OS and FreeSBIE, which also focused on providing secure and anonymous web browsing to users."
    }
  },
  {
    "instruction": "IASME\n\n==Introduction==\nIASME Governance is an Information Assurance standard that is designed to be simple and affordable to help improve the cyber security of Small and medium-sized enterprises (SMEs).\nThe IASME Governance technical controls are aligned with the Cyber Essentials scheme and certification to the IASME standard includes certification to Cyber Essentials. The IASME Governance standard was developed in 2010 and has proven to be very effective at improving the security of supply chains for large organisations.. The standard maps closely to the international ISO/IEC 27001 information assurance standard.\n\n\n\n== Background ==\nIASME Governance was originally developed as an academic-SME partnership that attracted a lot of interest from government and small businessesResearch towards the IASME model was undertaken in the UK during 2009\u201310, after an acknowledgement that the current international information assurance standard (ISO/IEC 27001) was complex for resource-strapped SMEs, providing a weakness in the supply chain. IASME was developed during 2010-11 and was launched later that year. It has been revised regularly to keep pace with changes to the risk environment of SMEs. The development process with SMEs was explained in a published international SME conference paper.The IASME Governance standard follows the same implementation pattern used by the international standards community including PDCA (Plan-Do-Check-Act) principles  and the Information Security Management System (ISMS) which provides a management framework. Both are refined and expressed in business terms recognisable by organisations of all sizes.\nThe IASME Governance standard was developed and piloted with the help of small businesses mostly in the West Midlands of the UK with encouraging results. The standard has been shown to be useful to SMEs both in the UK and internationally.Large organisations can use the IASME Governance standard in their supply chains to understand and reduce supplier risk. An article explaining the supply chain benefits has been written by its developer, David Booth. Both large and small organisations can use the IASME certification as an alternative to the ISO/IEC 27001 standard.\n\n== Structure of the standard ==\nThe standard is managed by The IASME Consortium Ltd who operate a network of over 150 Certification Bodies who are licensed to certify candidate organisations. The question set is free for anyone to download without registration and is licensed under a Creative Commons BY-NC-ND license.The standard is available at two levels of assurance: \n\nIASME Governance Self-assessment\nCandidates complete an online questionnaire with around 160 simple questions about their organisation. This is marked by a Certification Body who awards the certification if all of the answers given are compliant with the standard.\nThe assessment includes certification to the Cyber Essentials standard.\nIASME Governance Audited (or \"IASME Gold\")\nThe candidate organisation is visited by an IASME Certification Body who verifies compliance with the standard and, if appropriate, issues certification.In 2017, the standard was updated to include additional questions to enable organisations comply with the General Data Protection Regulations (GDPR).\n\n== Topics covered by the standard ==\nThe IASME Governance standard covers the following information security topics:\n\nManaging Security\nInformation Assets\nCloud Services\nRisk Management\nData Protection (including GDPR)\nPeople\nSecurity Policy\nPhysical and Environmental\nFirewalls and Internet Gateways\nSecure Configuration\nPatches and Updates\nOperations and Management\nUser Accounts\nAdministrative Access\nMalware Protection\nVulnerability Scanning\nMonitoring\nBackup and Restore\nIncident Management\nBusiness Continuity\n\n== Comparison with other standards ==\n\n\n*** ISO/IEC 27001/2 ***\nIASME Governance is a risk-led standard with a similar set of controls to Annex A of the ISO/IEC 27001 standard.\n\n\n*** NCSC 10 Steps to Cyber Security ***\nIASME Governance maps very closely to the UK Government's NCSC 10 Steps to Cyber Security. A mapping between the two standards is available\n\n\n*** Cyber Assessment Framework ***\nThe Cyber Assessment Framework (CAF) has been developed by the UK Government to allow organisations to demonstrate their compliance to the NIS Directive. The IASME Governance Standard maps closely to the CAF.\n\n\n*** NHS Digital Data Security and Protection Toolkit ***\nThe NHS Digital Data Security and Protection Toolkit is an online self-assessment tool that allows organisations to measure their performance against the National Data Guardian's 10 data security standards.  IASME Governance maps closely to the toolkit for the majority of topics\n\n== Usage of the standard and awards ==\nThe IASME standard has become a focus of attention, as the information security threat to UK businesses continues to increase, and vulnerabilities in their systems continue to cause expensive data breaches and system failures. The increasing number of newspaper and journal articles on this subject reflect an increased security awareness.It is recognised by the States of Jersey as suitable security standard for the government supply chain.IASME was specifically mentioned in a keynote speech at the Infosec Europe 2013 event held in London and received an innovation award from Computer Weekly Europe shortly afterwards. In April 2019, IASME was awarded Cyber Business of the Year at the prestigious UK National Cyber Awards\n\nAnswer this question \"What is the implementation pattern used by the IASME Governance standard?\" using the text above.",
    "context": "",
    "output": "The IASME Governance standard follows the same implementation pattern used by the international standards community, including PDCA (Plan-Do-Check-Act) principles and the Information Security Management System (ISMS), which provides a management framework. Both are refined and expressed in business terms recognisable by organizations of all sizes.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the implementation pattern used by the IASME Governance standard?",
      "answer": "The IASME Governance standard follows the same implementation pattern used by the international standards community, including PDCA (Plan-Do-Check-Act) principles and the Information Security Management System (ISMS), which provides a management framework. Both are refined and expressed in business terms recognisable by organizations of all sizes.",
      "context": "IASME\n\n==Introduction==\nIASME Governance is an Information Assurance standard that is designed to be simple and affordable to help improve the cyber security of Small and medium-sized enterprises (SMEs).\nThe IASME Governance technical controls are aligned with the Cyber Essentials scheme and certification to the IASME standard includes certification to Cyber Essentials. The IASME Governance standard was developed in 2010 and has proven to be very effective at improving the security of supply chains for large organisations.. The standard maps closely to the international ISO/IEC 27001 information assurance standard.\n\n\n\n== Background ==\nIASME Governance was originally developed as an academic-SME partnership that attracted a lot of interest from government and small businessesResearch towards the IASME model was undertaken in the UK during 2009\u201310, after an acknowledgement that the current international information assurance standard (ISO/IEC 27001) was complex for resource-strapped SMEs, providing a weakness in the supply chain. IASME was developed during 2010-11 and was launched later that year. It has been revised regularly to keep pace with changes to the risk environment of SMEs. The development process with SMEs was explained in a published international SME conference paper.The IASME Governance standard follows the same implementation pattern used by the international standards community including PDCA (Plan-Do-Check-Act) principles  and the Information Security Management System (ISMS) which provides a management framework. Both are refined and expressed in business terms recognisable by organisations of all sizes.\nThe IASME Governance standard was developed and piloted with the help of small businesses mostly in the West Midlands of the UK with encouraging results. The standard has been shown to be useful to SMEs both in the UK and internationally.Large organisations can use the IASME Governance standard in their supply chains to understand and reduce supplier risk. An article explaining the supply chain benefits has been written by its developer, David Booth. Both large and small organisations can use the IASME certification as an alternative to the ISO/IEC 27001 standard.\n\n== Structure of the standard ==\nThe standard is managed by The IASME Consortium Ltd who operate a network of over 150 Certification Bodies who are licensed to certify candidate organisations. The question set is free for anyone to download without registration and is licensed under a Creative Commons BY-NC-ND license.The standard is available at two levels of assurance: \n\nIASME Governance Self-assessment\nCandidates complete an online questionnaire with around 160 simple questions about their organisation. This is marked by a Certification Body who awards the certification if all of the answers given are compliant with the standard.\nThe assessment includes certification to the Cyber Essentials standard.\nIASME Governance Audited (or \"IASME Gold\")\nThe candidate organisation is visited by an IASME Certification Body who verifies compliance with the standard and, if appropriate, issues certification.In 2017, the standard was updated to include additional questions to enable organisations comply with the General Data Protection Regulations (GDPR).\n\n== Topics covered by the standard ==\nThe IASME Governance standard covers the following information security topics:\n\nManaging Security\nInformation Assets\nCloud Services\nRisk Management\nData Protection (including GDPR)\nPeople\nSecurity Policy\nPhysical and Environmental\nFirewalls and Internet Gateways\nSecure Configuration\nPatches and Updates\nOperations and Management\nUser Accounts\nAdministrative Access\nMalware Protection\nVulnerability Scanning\nMonitoring\nBackup and Restore\nIncident Management\nBusiness Continuity\n\n== Comparison with other standards ==\n\n\n*** ISO/IEC 27001/2 ***\nIASME Governance is a risk-led standard with a similar set of controls to Annex A of the ISO/IEC 27001 standard.\n\n\n*** NCSC 10 Steps to Cyber Security ***\nIASME Governance maps very closely to the UK Government's NCSC 10 Steps to Cyber Security. A mapping between the two standards is available\n\n\n*** Cyber Assessment Framework ***\nThe Cyber Assessment Framework (CAF) has been developed by the UK Government to allow organisations to demonstrate their compliance to the NIS Directive. The IASME Governance Standard maps closely to the CAF.\n\n\n*** NHS Digital Data Security and Protection Toolkit ***\nThe NHS Digital Data Security and Protection Toolkit is an online self-assessment tool that allows organisations to measure their performance against the National Data Guardian's 10 data security standards.  IASME Governance maps closely to the toolkit for the majority of topics\n\n== Usage of the standard and awards ==\nThe IASME standard has become a focus of attention, as the information security threat to UK businesses continues to increase, and vulnerabilities in their systems continue to cause expensive data breaches and system failures. The increasing number of newspaper and journal articles on this subject reflect an increased security awareness.It is recognised by the States of Jersey as suitable security standard for the government supply chain.IASME was specifically mentioned in a keynote speech at the Infosec Europe 2013 event held in London and received an innovation award from Computer Weekly Europe shortly afterwards. In April 2019, IASME was awarded Cyber Business of the Year at the prestigious UK National Cyber Awards"
    }
  },
  {
    "instruction": "Context: Software Guard Extensions\n\n==Introduction==\nIntel Software Guard Extensions (SGX) is a set of security-related instruction codes that are built into some Intel central processing units (CPUs). They allow user-level and operating system code to define protected private regions of memory, called enclaves. SGX is designed to be useful for implementing secure remote computation, secure web browsing, and digital rights management (DRM). Other applications include concealment of proprietary algorithms and of encryption keys.SGX involves encryption by the CPU of a portion of memory (the enclave). Data and code originating in the enclave are decrypted on the fly within the CPU, protecting them from being examined or read by other code, including code running at higher privilege levels such the operating system and any underlying hypervisors. While this can mitigate many kinds of attacks, it does not protect against side-channel attacks.A pivot by Intel in 2021 resulted in the deprecation of SGX from the 11th and 12th generation Intel Core Processors, but development continues on Intel Xeon for cloud and enterprise use.\n\n\n\n== Details ==\nSGX was first introduced in 2015 with the sixth generation Intel Core microprocessors based on the Skylake microarchitecture.\nSupport for SGX in the CPU is indicated in CPUID \"Structured Extended feature Leaf\", EBX bit 02, but its availability to applications requires BIOS/UEFI support and opt-in enabling which is not reflected in CPUID bits. This complicates the feature detection logic for applications.Emulation of SGX was added to an experimental version of the QEMU system emulator in 2014. In 2015, researchers at the Georgia Institute of Technology released an open-source simulator named \"OpenSGX\".One example of SGX used in security was a demo application from wolfSSL using it for cryptography algorithms.\nIntel Goldmont Plus (Gemini Lake) microarchitecture also contains support for Intel SGX.Both in the 11th and 12th generations of Intel Core processors, SGX is listed as \"Deprecated\" and thereby not supported on \"client platform\" processors.\n This means Ultra HD Blu-ray disc playback is not supported.\n\n== List of SGX vulnerabilities ==\n\n\n*** Prime+Probe attack ***\nOn 27 March 2017 researchers at Austria's Graz University of Technology developed a proof-of-concept that can grab RSA keys from SGX enclaves running on the same system within five minutes by using certain CPU instructions in lieu of a fine-grained timer to exploit cache DRAM side-channels.  One countermeasure for this type of attack was presented and published by Daniel Gruss et al. at the USENIX Security Symposium in 2017. Among other published countermeasures, one countermeasure to this type of attack was published on September 28, 2017, a compiler-based tool, DR.SGX, that claims to have superior performance with the elimination of the implementation complexity of other proposed solutions.\n\n\n*** Spectre-like attack ***\n\nThe LSDS group at Imperial College London showed a proof of concept that the Spectre speculative execution security vulnerability can be adapted to attack the secure enclave.  The Foreshadow attack, disclosed in August 2018, combines speculative execution and buffer overflow to bypass the SGX. A security advisory and mitigation for this attack, also called an L1 Terminal Fault, was originally issued on August 14, 2018 and updated May 11, 2021.\n\n\n*** Enclave attack ***\nOn 8 February 2019, researchers at Austria's Graz University of Technology published findings, which showed that in some cases it is possible to run malicious code from within the enclave itself. The exploit involves scanning through process memory, in order to reconstruct a payload, which can then run code on the system. The paper claims that due to the confidential and protected nature of the enclave, it is impossible for antivirus software to detect and remove malware residing within it. However, since modern anti-malware and antivirus solutions monitor system calls, and the interaction of the application with the operating system, it should be possible to identify malicious enclaves by their behavior, and this issue is unlikely to be a concern for state-of-the-art antiviruses. Intel issued a statement, stating that this attack was outside the threat model of SGX, that they cannot guarantee that code run by the user comes from trusted sources, and urged consumers to only run trusted code.\n\n\n*** MicroScope replay attack ***\nThere is a proliferation of side-channel attacks plaguing modern computer architectures. Many of these attacks measure slight, nondeterministic variations in the execution of code, so the attacker needs many, possibly tens of thousands, of measurements to learn secrets. However, the MicroScope attack allows a malicious OS to replay code an arbitrary number of times regardless of the programs actual structure, enabling dozens of side-channel attacks. In July 2022, Intel submitted a Linux patch called AEX-Notify to allow the SGX enclave programmer to write a handler for these types of events.\n\n\n*** Plundervolt ***\nSecurity researchers were able to inject timing specific faults into execution within the enclave, resulting in leakage of information. The attack can be executed remotely, but requires\naccess to the privileged control of the processor's voltage and frequency. A security advisory and mitigation for this attack was originally issued on August 14, 2018 and updated on March 20, 2020.\n\n\n*** LVI ***\n\nLoad Value Injection injects data into a program aiming to replace the value loaded from memory which is then used for a short time before the mistake is spotted and rolled back, during which LVI controls data and control flow. A security advisory and mitigation for this attack was originally issued on March 10, 2020 and updated on May 11, 2021.\n\n\n*** SGAxe ***\nSGAxe, an SGX vulnerability published in 2020, extends a speculative execution attack on cache, leaking content of the enclave. This allows an attacker to access private CPU keys used for remote attestation. In other words, a threat actor can bypass Intel's countermeasures to breach SGX enclaves' confidentiality. The SGAxe attack is carried out by extracting attestation keys from SGX's private quoting enclave that are signed by Intel. The attacker can then masquerade as legitimate Intel machines by signing arbitrary SGX attestation quotes. A security advisory and mitigation for this attack, also called a Processor Data Leakage or Cache Eviction, was originally issued January 27, 2020 and updated May 11, 2021.\n\n\n*** \u00c6PIC leak ***\nIn 2022, security researchers discovered a vulnerability in the Advanced Programmable Interrupt Controller (APIC) that allows for an attacker with root/admin privileges to gain access to encryption keys via the APIC by inspecting data transfers from L1 and L2 cache. This vulnerability is the first architectural attack discovered on x86 CPUs. This differs from Spectre and Meltdown which uses a noisy side channel. This exploit currently affects Intel Core 10th, 11th and 12th, and Xeon Ice Lake microprocessors.\n\n== SGX malware arguments ==\nThere has been a long debate on whether SGX enables creation of superior malware. Oxford University researchers published an article in October 2022 considering attackers' potential advantages and the disadvantages by abusing SGX for malware development. Researchers conclude that while there might be temporary zero day vulnerabilities to abuse in SGX ecosystem, the core principles and design features of Trusted Execution Environments (TEEs) make malware weaker than a malware-in-the-wild, TEEs make no major contributions to malware otherwise.\nQuestion: When was Intel SGX first introduced, and what microarchitecture was it based on?\n\nAnswer:",
    "context": "",
    "output": "Intel SGX was first introduced in 2015 with the sixth generation Intel Core microprocessors based on the Skylake microarchitecture.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "When was Intel SGX first introduced, and what microarchitecture was it based on?",
      "answer": "Intel SGX was first introduced in 2015 with the sixth generation Intel Core microprocessors based on the Skylake microarchitecture.",
      "context": "Software Guard Extensions\n\n==Introduction==\nIntel Software Guard Extensions (SGX) is a set of security-related instruction codes that are built into some Intel central processing units (CPUs). They allow user-level and operating system code to define protected private regions of memory, called enclaves. SGX is designed to be useful for implementing secure remote computation, secure web browsing, and digital rights management (DRM). Other applications include concealment of proprietary algorithms and of encryption keys.SGX involves encryption by the CPU of a portion of memory (the enclave). Data and code originating in the enclave are decrypted on the fly within the CPU, protecting them from being examined or read by other code, including code running at higher privilege levels such the operating system and any underlying hypervisors. While this can mitigate many kinds of attacks, it does not protect against side-channel attacks.A pivot by Intel in 2021 resulted in the deprecation of SGX from the 11th and 12th generation Intel Core Processors, but development continues on Intel Xeon for cloud and enterprise use.\n\n\n\n== Details ==\nSGX was first introduced in 2015 with the sixth generation Intel Core microprocessors based on the Skylake microarchitecture.\nSupport for SGX in the CPU is indicated in CPUID \"Structured Extended feature Leaf\", EBX bit 02, but its availability to applications requires BIOS/UEFI support and opt-in enabling which is not reflected in CPUID bits. This complicates the feature detection logic for applications.Emulation of SGX was added to an experimental version of the QEMU system emulator in 2014. In 2015, researchers at the Georgia Institute of Technology released an open-source simulator named \"OpenSGX\".One example of SGX used in security was a demo application from wolfSSL using it for cryptography algorithms.\nIntel Goldmont Plus (Gemini Lake) microarchitecture also contains support for Intel SGX.Both in the 11th and 12th generations of Intel Core processors, SGX is listed as \"Deprecated\" and thereby not supported on \"client platform\" processors.\n This means Ultra HD Blu-ray disc playback is not supported.\n\n== List of SGX vulnerabilities ==\n\n\n*** Prime+Probe attack ***\nOn 27 March 2017 researchers at Austria's Graz University of Technology developed a proof-of-concept that can grab RSA keys from SGX enclaves running on the same system within five minutes by using certain CPU instructions in lieu of a fine-grained timer to exploit cache DRAM side-channels.  One countermeasure for this type of attack was presented and published by Daniel Gruss et al. at the USENIX Security Symposium in 2017. Among other published countermeasures, one countermeasure to this type of attack was published on September 28, 2017, a compiler-based tool, DR.SGX, that claims to have superior performance with the elimination of the implementation complexity of other proposed solutions.\n\n\n*** Spectre-like attack ***\n\nThe LSDS group at Imperial College London showed a proof of concept that the Spectre speculative execution security vulnerability can be adapted to attack the secure enclave.  The Foreshadow attack, disclosed in August 2018, combines speculative execution and buffer overflow to bypass the SGX. A security advisory and mitigation for this attack, also called an L1 Terminal Fault, was originally issued on August 14, 2018 and updated May 11, 2021.\n\n\n*** Enclave attack ***\nOn 8 February 2019, researchers at Austria's Graz University of Technology published findings, which showed that in some cases it is possible to run malicious code from within the enclave itself. The exploit involves scanning through process memory, in order to reconstruct a payload, which can then run code on the system. The paper claims that due to the confidential and protected nature of the enclave, it is impossible for antivirus software to detect and remove malware residing within it. However, since modern anti-malware and antivirus solutions monitor system calls, and the interaction of the application with the operating system, it should be possible to identify malicious enclaves by their behavior, and this issue is unlikely to be a concern for state-of-the-art antiviruses. Intel issued a statement, stating that this attack was outside the threat model of SGX, that they cannot guarantee that code run by the user comes from trusted sources, and urged consumers to only run trusted code.\n\n\n*** MicroScope replay attack ***\nThere is a proliferation of side-channel attacks plaguing modern computer architectures. Many of these attacks measure slight, nondeterministic variations in the execution of code, so the attacker needs many, possibly tens of thousands, of measurements to learn secrets. However, the MicroScope attack allows a malicious OS to replay code an arbitrary number of times regardless of the programs actual structure, enabling dozens of side-channel attacks. In July 2022, Intel submitted a Linux patch called AEX-Notify to allow the SGX enclave programmer to write a handler for these types of events.\n\n\n*** Plundervolt ***\nSecurity researchers were able to inject timing specific faults into execution within the enclave, resulting in leakage of information. The attack can be executed remotely, but requires\naccess to the privileged control of the processor's voltage and frequency. A security advisory and mitigation for this attack was originally issued on August 14, 2018 and updated on March 20, 2020.\n\n\n*** LVI ***\n\nLoad Value Injection injects data into a program aiming to replace the value loaded from memory which is then used for a short time before the mistake is spotted and rolled back, during which LVI controls data and control flow. A security advisory and mitigation for this attack was originally issued on March 10, 2020 and updated on May 11, 2021.\n\n\n*** SGAxe ***\nSGAxe, an SGX vulnerability published in 2020, extends a speculative execution attack on cache, leaking content of the enclave. This allows an attacker to access private CPU keys used for remote attestation. In other words, a threat actor can bypass Intel's countermeasures to breach SGX enclaves' confidentiality. The SGAxe attack is carried out by extracting attestation keys from SGX's private quoting enclave that are signed by Intel. The attacker can then masquerade as legitimate Intel machines by signing arbitrary SGX attestation quotes. A security advisory and mitigation for this attack, also called a Processor Data Leakage or Cache Eviction, was originally issued January 27, 2020 and updated May 11, 2021.\n\n\n*** \u00c6PIC leak ***\nIn 2022, security researchers discovered a vulnerability in the Advanced Programmable Interrupt Controller (APIC) that allows for an attacker with root/admin privileges to gain access to encryption keys via the APIC by inspecting data transfers from L1 and L2 cache. This vulnerability is the first architectural attack discovered on x86 CPUs. This differs from Spectre and Meltdown which uses a noisy side channel. This exploit currently affects Intel Core 10th, 11th and 12th, and Xeon Ice Lake microprocessors.\n\n== SGX malware arguments ==\nThere has been a long debate on whether SGX enables creation of superior malware. Oxford University researchers published an article in October 2022 considering attackers' potential advantages and the disadvantages by abusing SGX for malware development. Researchers conclude that while there might be temporary zero day vulnerabilities to abuse in SGX ecosystem, the core principles and design features of Trusted Execution Environments (TEEs) make malware weaker than a malware-in-the-wild, TEEs make no major contributions to malware otherwise."
    }
  },
  {
    "instruction": "The 'e' symbol in the definition of a cryptographic multilinear map refers to the map itself, which takes inputs from 'n' different groups and maps them to a target group.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the role of the 'e' symbol in the definition of a cryptographic multilinear map?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the role of the 'e' symbol in the definition of a cryptographic multilinear map?",
      "answer": "The 'e' symbol in the definition of a cryptographic multilinear map refers to the map itself, which takes inputs from 'n' different groups and maps them to a target group."
    }
  },
  {
    "instruction": "The Microsoft Malware Protection Center detected Dorkbot on an average of 100,000 infected machines each month between May and December 2015.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How many infected machines were detected by the Microsoft Malware Protection Center on average per month during the second half of 2015?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How many infected machines were detected by the Microsoft Malware Protection Center on average per month during the second half of 2015?",
      "answer": "The Microsoft Malware Protection Center detected Dorkbot on an average of 100,000 infected machines each month between May and December 2015."
    }
  },
  {
    "instruction": "The goal of achieving a long-term shift in employees' attitudes towards security is to promote cultural and behavioral change within an organization.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the goal of achieving a long-term shift in employees' attitudes towards security?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the goal of achieving a long-term shift in employees' attitudes towards security?",
      "answer": "The goal of achieving a long-term shift in employees' attitudes towards security is to promote cultural and behavioral change within an organization."
    }
  },
  {
    "instruction": "Magic Lantern is a trojan horse intended to obtain passwords to encrypted e-mail and other documents during criminal investigations. Major antivirus vendors, including Norton AntiVirus, have whitelisted the Magic Lantern trojan, rendering their antivirus products incapable of detecting it. This has raised concerns around the full surveillance potential of Magic Lantern and the possibility of hackers subverting it for malicious purposes.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does Magic Lantern, a keylogger developed by the FBI, affect Norton AntiVirus and other major antivirus vendors?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does Magic Lantern, a keylogger developed by the FBI, affect Norton AntiVirus and other major antivirus vendors?",
      "answer": "Magic Lantern is a trojan horse intended to obtain passwords to encrypted e-mail and other documents during criminal investigations. Major antivirus vendors, including Norton AntiVirus, have whitelisted the Magic Lantern trojan, rendering their antivirus products incapable of detecting it. This has raised concerns around the full surveillance potential of Magic Lantern and the possibility of hackers subverting it for malicious purposes."
    }
  },
  {
    "instruction": "Kernel randomization in OpenBSD involves modifying the linker so that on every boot, the kernel is relinked, as well as all other randomizations. This ensures that every new kernel is unique and the relative offsets between functions and data are unique, making it harder for attackers to exploit known kernel vulnerabilities.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the significance of kernel randomization in OpenBSD and how does it improve system security?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the significance of kernel randomization in OpenBSD and how does it improve system security?",
      "answer": "Kernel randomization in OpenBSD involves modifying the linker so that on every boot, the kernel is relinked, as well as all other randomizations. This ensures that every new kernel is unique and the relative offsets between functions and data are unique, making it harder for attackers to exploit known kernel vulnerabilities."
    }
  },
  {
    "instruction": "Context: Rubberhose (file system)\n\n==Introduction==\nIn computing, rubberhose (also known by its development codename Marutukku) is a deniable encryption archive containing multiple file systems whose existence can only be verified using the appropriate cryptographic key.\n\n\n\n== Name and history ==\nThe project was originally named Rubberhose, as it was designed to be resistant to attacks by people willing to use torture on those who knew the encryption keys. This is a reference to the rubber-hose cryptanalysis euphemism.\nIt was written in 1997\u20132000 by Julian Assange, Suelette Dreyfus, and Ralf Weinmann.\n\n== Technical ==\nThe following paragraphs are extracts from the project's documentation:\n\nRubberhose works by initially writing random characters to an entire hard drive or other dynamic storage device.  This random noise is indistinguishable from the encrypted data to be stored on that disk.  If you have a 1 GB drive and want to have two Rubberhose encrypted portions of 400 MB and 200 MB, it assumes that each aspect (as the encrypted partitions are called) will be 1 GB and fill the entire drive.  It will keep doing this until the drive is really filled to capacity with encrypted material.  It breaks up the pieces of each aspect into small pieces and scatters them across the entire 1 GB drive in a random manner, with each aspect looking as if it is actually 1 GB in size upon decryption.\nEach aspect has its own passphrase that must be separately decrypted, and if a hard drive is seized neither mathematical analysis nor physical disk testing can reveal how many aspects actually exist.  Internal maps are used to locate where the data is stored amongst the random characters, with each aspect having its own map which can only be decrypted via its specific passphrase.  Therefore, a Rubberhose disk can only be safely written to after all the passphrases have been entered.  Everything works on a \"need to know\" basis, i.e. each aspect knows nothing about the others other than when to avoid writing over the top of another.\n\n== Status ==\nRubberhose is not actively maintained, although it is available for Linux kernel 2.2, NetBSD and FreeBSD. The latest version available, still in alpha stage, is v0.8.3.\nQuestion: What is the purpose of breaking up encrypted data into small pieces in Rubberhose?\n\nAnswer:",
    "context": "",
    "output": "Breaking up encrypted data into small pieces and scattering them across the entire storage device in a random manner ensures that each aspect appears to be of a specific size upon decryption, even if the actual size is different.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the purpose of breaking up encrypted data into small pieces in Rubberhose?",
      "answer": "Breaking up encrypted data into small pieces and scattering them across the entire storage device in a random manner ensures that each aspect appears to be of a specific size upon decryption, even if the actual size is different.",
      "context": "Rubberhose (file system)\n\n==Introduction==\nIn computing, rubberhose (also known by its development codename Marutukku) is a deniable encryption archive containing multiple file systems whose existence can only be verified using the appropriate cryptographic key.\n\n\n\n== Name and history ==\nThe project was originally named Rubberhose, as it was designed to be resistant to attacks by people willing to use torture on those who knew the encryption keys. This is a reference to the rubber-hose cryptanalysis euphemism.\nIt was written in 1997\u20132000 by Julian Assange, Suelette Dreyfus, and Ralf Weinmann.\n\n== Technical ==\nThe following paragraphs are extracts from the project's documentation:\n\nRubberhose works by initially writing random characters to an entire hard drive or other dynamic storage device.  This random noise is indistinguishable from the encrypted data to be stored on that disk.  If you have a 1 GB drive and want to have two Rubberhose encrypted portions of 400 MB and 200 MB, it assumes that each aspect (as the encrypted partitions are called) will be 1 GB and fill the entire drive.  It will keep doing this until the drive is really filled to capacity with encrypted material.  It breaks up the pieces of each aspect into small pieces and scatters them across the entire 1 GB drive in a random manner, with each aspect looking as if it is actually 1 GB in size upon decryption.\nEach aspect has its own passphrase that must be separately decrypted, and if a hard drive is seized neither mathematical analysis nor physical disk testing can reveal how many aspects actually exist.  Internal maps are used to locate where the data is stored amongst the random characters, with each aspect having its own map which can only be decrypted via its specific passphrase.  Therefore, a Rubberhose disk can only be safely written to after all the passphrases have been entered.  Everything works on a \"need to know\" basis, i.e. each aspect knows nothing about the others other than when to avoid writing over the top of another.\n\n== Status ==\nRubberhose is not actively maintained, although it is available for Linux kernel 2.2, NetBSD and FreeBSD. The latest version available, still in alpha stage, is v0.8.3."
    }
  },
  {
    "instruction": "The Xinjiang internment camps are described as secret facilities used for forced ideological and behavioral reeducation of Muslim Uyghurs. Detainees are held for a minimum of a year and are scored on their use of Mandarin and adherence to strict rules. The camps are intended to control infectious disease outbreaks and provide vocational training after release in separate facilities.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How are the Xinjiang internment camps described in the China Cables and what is their purpose?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How are the Xinjiang internment camps described in the China Cables and what is their purpose?",
      "answer": "The Xinjiang internment camps are described as secret facilities used for forced ideological and behavioral reeducation of Muslim Uyghurs. Detainees are held for a minimum of a year and are scored on their use of Mandarin and adherence to strict rules. The camps are intended to control infectious disease outbreaks and provide vocational training after release in separate facilities."
    }
  },
  {
    "instruction": "The Industroyer malware was discovered by Slovak internet security company ESET.\n\nWrite a question about the text above.",
    "context": "",
    "output": "Who discovered the Industroyer malware?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "Who discovered the Industroyer malware?",
      "answer": "The Industroyer malware was discovered by Slovak internet security company ESET."
    }
  },
  {
    "instruction": "TE gives priority to MAC over DAC in SELinux.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does TE relate to mandatory access control (MAC) in SELinux?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does TE relate to mandatory access control (MAC) in SELinux?",
      "answer": "TE gives priority to MAC over DAC in SELinux."
    }
  },
  {
    "instruction": "Some of the emerging trends and technologies in firewall appliances and software include artificial intelligence (AI), machine learning (ML), automation, orchestration, and cloud-based services. These trends and technologies offer potential benefits, such as improved detection and response, reduced costs and complexity, and increased agility and scalability. However, they also introduce potential challenges, such as privacy concerns, legal and regulatory compliance, and security risks. Therefore, it is important to carefully evaluate and adopt these trends and technologies based on the specific requirements and constraints of the network environment.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What are some of the emerging trends and technologies in firewall appliances and software, and how do they impact the overall security posture?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What are some of the emerging trends and technologies in firewall appliances and software, and how do they impact the overall security posture?",
      "answer": "Some of the emerging trends and technologies in firewall appliances and software include artificial intelligence (AI), machine learning (ML), automation, orchestration, and cloud-based services. These trends and technologies offer potential benefits, such as improved detection and response, reduced costs and complexity, and increased agility and scalability. However, they also introduce potential challenges, such as privacy concerns, legal and regulatory compliance, and security risks. Therefore, it is important to carefully evaluate and adopt these trends and technologies based on the specific requirements and constraints of the network environment."
    }
  },
  {
    "instruction": "Context: SMBRelay\n\n==Introduction==\nSMBRelay and SMBRelay2 are computer programs that can be used to carry out SMB man-in-the-middle (mitm) attacks on Windows machines.  They were written by Sir Dystic of CULT OF THE DEAD COW (cDc) and released March 21, 2001 at the @lantacon convention in Atlanta, Georgia.  More than seven years after its release, Microsoft released a patch that fixed the hole exploited by SMBRelay. This fix only fixes the vulnerability when the SMB is reflected back to the client. If it is forwarded to another host, the vulnerability can be still exploited.\n\n\n\n== SMBRelay ==\nSMBrelay receives a connection on UDP port 139 and relays the packets between the client and server of the connecting Windows machine to the originating computer's port 139. It modifies these packets when necessary.\nAfter connecting and authenticating, the target's client is disconnected and SMBRelay binds to port 139 on a new IP address. This relay address can then be connected to directly using \"net use \\\\192.1.1.1\" and then used by all of the networking functions built into Windows. The program relays all of the SMB traffic, excluding negotiation and authentication. As long as the target host remains connected, the user can disconnect from and reconnect to this virtual IP.\nSMBRelay collects the NTLM password hashes and writes them to hashes.txt in a format usable by L0phtCrack for cracking at a later time.\nAs port 139 is a privileged port and requires administrator access for use, SMBRelay must run as an administrator access account.  However, since port 139 is needed for NetBIOS sessions, it is difficult to block.\nAccording to Sir Dystic, \"The problem is that from a marketing standpoint, Microsoft wants their products to have as much backward compatibility as possible; but by continuing to use protocols that have known issues, they continue to leave their customers at risk to exploitation... These are, yet again, known issues that have existed since day one of this protocol. This is not a bug but a fundamental design flaw. To assume that nobody has used this method to exploit people is silly; it took me less than two weeks to write SMBRelay.\"\n\n== SMBRelay2 ==\nSMBRelay2 works at the NetBIOS level across any protocol to which NetBIOS is bound (such as NBF or NBT). It differs from SMBrelay in that it uses NetBIOS names rather than IP addresses.\nSMBRelay2 also supports man-in-the-middling to a third host. However, it only supports listening on one name at a time.\nQuestion: What is the impact of SMBRelay and SMBRelay2 on the target Windows machine?\n\nAnswer:",
    "context": "",
    "output": "SMBRelay and SMBRelay2 disconnect the target's client and bind to port 139 on a new IP address. This relay address can then be connected to directly using \"net use \\\\192.1.1.1\" and used by all of the networking functions built into Windows.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the impact of SMBRelay and SMBRelay2 on the target Windows machine?",
      "answer": "SMBRelay and SMBRelay2 disconnect the target's client and bind to port 139 on a new IP address. This relay address can then be connected to directly using \"net use \\\\192.1.1.1\" and used by all of the networking functions built into Windows.",
      "context": "SMBRelay\n\n==Introduction==\nSMBRelay and SMBRelay2 are computer programs that can be used to carry out SMB man-in-the-middle (mitm) attacks on Windows machines.  They were written by Sir Dystic of CULT OF THE DEAD COW (cDc) and released March 21, 2001 at the @lantacon convention in Atlanta, Georgia.  More than seven years after its release, Microsoft released a patch that fixed the hole exploited by SMBRelay. This fix only fixes the vulnerability when the SMB is reflected back to the client. If it is forwarded to another host, the vulnerability can be still exploited.\n\n\n\n== SMBRelay ==\nSMBrelay receives a connection on UDP port 139 and relays the packets between the client and server of the connecting Windows machine to the originating computer's port 139. It modifies these packets when necessary.\nAfter connecting and authenticating, the target's client is disconnected and SMBRelay binds to port 139 on a new IP address. This relay address can then be connected to directly using \"net use \\\\192.1.1.1\" and then used by all of the networking functions built into Windows. The program relays all of the SMB traffic, excluding negotiation and authentication. As long as the target host remains connected, the user can disconnect from and reconnect to this virtual IP.\nSMBRelay collects the NTLM password hashes and writes them to hashes.txt in a format usable by L0phtCrack for cracking at a later time.\nAs port 139 is a privileged port and requires administrator access for use, SMBRelay must run as an administrator access account.  However, since port 139 is needed for NetBIOS sessions, it is difficult to block.\nAccording to Sir Dystic, \"The problem is that from a marketing standpoint, Microsoft wants their products to have as much backward compatibility as possible; but by continuing to use protocols that have known issues, they continue to leave their customers at risk to exploitation... These are, yet again, known issues that have existed since day one of this protocol. This is not a bug but a fundamental design flaw. To assume that nobody has used this method to exploit people is silly; it took me less than two weeks to write SMBRelay.\"\n\n== SMBRelay2 ==\nSMBRelay2 works at the NetBIOS level across any protocol to which NetBIOS is bound (such as NBF or NBT). It differs from SMBrelay in that it uses NetBIOS names rather than IP addresses.\nSMBRelay2 also supports man-in-the-middling to a third host. However, it only supports listening on one name at a time."
    }
  },
  {
    "instruction": "The use of SMAP in an operating system may lead to a larger kernel size and slower user-space memory accesses from supervisor code, as SMAP must be temporarily disabled when supervisor code intends to access user-space memory.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What are the potential downsides of using SMAP in an operating system?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What are the potential downsides of using SMAP in an operating system?",
      "answer": "The use of SMAP in an operating system may lead to a larger kernel size and slower user-space memory accesses from supervisor code, as SMAP must be temporarily disabled when supervisor code intends to access user-space memory."
    }
  },
  {
    "instruction": "The ground stations that have, or have had, a role in intercepting transmissions from Satellite and other means of communication include RAF Little Sai Wan (Closed) (Hong Kong), Australian Defence Satellite Communications Station (Geraldton, Western Australia), RAF Menwith Hill (Yorkshire, England), Misawa Security Operations Center (Oura, Misawa, Aomori, T\u014dhoku, Japan), GCHQ Bude (formerly CSO Morwenstow) (Cornwall, UK), Pine Gap (Outside Alice Springs, Northern Territory, Australia), Sugar Grove (Closed) (West Virginia, US), Yakima Training Center (Closed) (Washington State, US), Buckley Space Force Base (Aurora, Colorado), GCSB Waihopai (Marlborough, New Zealand), GCSB Tangimoana (Manawatu-Wanganui, New Zealand), CFS Leitrim (Ottawa, Ontario, Canada), Teufelsberg (Closed 1992), Berlin, Germany \u2013 Responsible for listening in to the Eastern Bloc, Fort Gordon (Georgia, US), CFB Gander (Newfoundland and Labrador, Canada), Guam (Pacific Ocean, US), Kunia Regional SIGINT Operations Center (Hawaii, US), Lackland Air Force Base, Medina Annex (San Antonio, Texas, US), RAF Edzell (Closed 1996) (Scotland), RAF Boulmer (England), SNICK International Processing Center (Seeb, Oman), Ayios Nikolaos (British Sovereign Base area of Dhekelia, Cyprus), Gibraltar (UK) and Diego Garcia (UK).\n\nWrite a question about the text above.",
    "context": "",
    "output": "What are the ground stations that have, or have had, a role in intercepting transmissions from Satellite and other means of communication?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What are the ground stations that have, or have had, a role in intercepting transmissions from Satellite and other means of communication?",
      "answer": "The ground stations that have, or have had, a role in intercepting transmissions from Satellite and other means of communication include RAF Little Sai Wan (Closed) (Hong Kong), Australian Defence Satellite Communications Station (Geraldton, Western Australia), RAF Menwith Hill (Yorkshire, England), Misawa Security Operations Center (Oura, Misawa, Aomori, T\u014dhoku, Japan), GCHQ Bude (formerly CSO Morwenstow) (Cornwall, UK), Pine Gap (Outside Alice Springs, Northern Territory, Australia), Sugar Grove (Closed) (West Virginia, US), Yakima Training Center (Closed) (Washington State, US), Buckley Space Force Base (Aurora, Colorado), GCSB Waihopai (Marlborough, New Zealand), GCSB Tangimoana (Manawatu-Wanganui, New Zealand), CFS Leitrim (Ottawa, Ontario, Canada), Teufelsberg (Closed 1992), Berlin, Germany \u2013 Responsible for listening in to the Eastern Bloc, Fort Gordon (Georgia, US), CFB Gander (Newfoundland and Labrador, Canada), Guam (Pacific Ocean, US), Kunia Regional SIGINT Operations Center (Hawaii, US), Lackland Air Force Base, Medina Annex (San Antonio, Texas, US), RAF Edzell (Closed 1996) (Scotland), RAF Boulmer (England), SNICK International Processing Center (Seeb, Oman), Ayios Nikolaos (British Sovereign Base area of Dhekelia, Cyprus), Gibraltar (UK) and Diego Garcia (UK)."
    }
  },
  {
    "instruction": "WS-Federation addresses the key challenges of cross-realm authentication and authorization, identity information sharing, and secure communication between different security realms.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What are some of the key challenges that WS-Federation addresses in the context of Web Services Security?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What are some of the key challenges that WS-Federation addresses in the context of Web Services Security?",
      "answer": "WS-Federation addresses the key challenges of cross-realm authentication and authorization, identity information sharing, and secure communication between different security realms."
    }
  },
  {
    "instruction": "The point-counting formula for the zeta-function of a hyperelliptic curve is a formula that expresses the coefficients of the zeta-function as sums of terms that depend on the number of points on the curve over each finite field extension. The formula is derived from the Weil conjectures and can be used to compute the zeta-function and hence the order of the Jacobian.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the point-counting formula for the zeta-function of a hyperelliptic curve?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the point-counting formula for the zeta-function of a hyperelliptic curve?",
      "answer": "The point-counting formula for the zeta-function of a hyperelliptic curve is a formula that expresses the coefficients of the zeta-function as sums of terms that depend on the number of points on the curve over each finite field extension. The formula is derived from the Weil conjectures and can be used to compute the zeta-function and hence the order of the Jacobian."
    }
  },
  {
    "instruction": "The BIOS, responsible for handling keyboard events, can be reprogrammed to record keystrokes as they are processed, functioning as a hardware keylogger.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What aspect of a computer's BIOS can be reprogrammed to function as a hardware keylogger?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What aspect of a computer's BIOS can be reprogrammed to function as a hardware keylogger?",
      "answer": "The BIOS, responsible for handling keyboard events, can be reprogrammed to record keystrokes as they are processed, functioning as a hardware keylogger."
    }
  },
  {
    "instruction": "In port triggering, the forwarding rule is disabled after a period of inactivity, while in port forwarding, the forwarded port is open permanently.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does the forwarding rule differ in port triggering compared to port forwarding?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does the forwarding rule differ in port triggering compared to port forwarding?",
      "answer": "In port triggering, the forwarding rule is disabled after a period of inactivity, while in port forwarding, the forwarded port is open permanently."
    }
  },
  {
    "instruction": "Trusted repeaters in a quantum network can only be used to perform quantum key distribution with the additional assumption that the repeater is trusted. They cannot be used to transmit qubits over long distances.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How do trusted repeaters work in a quantum network?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How do trusted repeaters work in a quantum network?",
      "answer": "Trusted repeaters in a quantum network can only be used to perform quantum key distribution with the additional assumption that the repeater is trusted. They cannot be used to transmit qubits over long distances."
    }
  },
  {
    "instruction": "Cryptographic keys, including session keys, must be chosen randomly to avoid predictability by an attacker. This is crucial because predictable keys weaken the security of the encryption system, making it vulnerable to attacks. Failure to choose session keys (or any key) properly is a common design flaw, highlighting the importance of randomness in key generation to ensure robust security in the encryption process.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What requirement must cryptographic keys, including session keys, meet to prevent security vulnerabilities, and why is this essential?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What requirement must cryptographic keys, including session keys, meet to prevent security vulnerabilities, and why is this essential?",
      "answer": "Cryptographic keys, including session keys, must be chosen randomly to avoid predictability by an attacker. This is crucial because predictable keys weaken the security of the encryption system, making it vulnerable to attacks. Failure to choose session keys (or any key) properly is a common design flaw, highlighting the importance of randomness in key generation to ensure robust security in the encryption process."
    }
  },
  {
    "instruction": "2021 Iranian fuel cyberattack\n\n==Introduction==\nThe Iranian fuel 2021 cyberstrike was an attack on the Iranian fuel system, government-issued cards used for buying subsidized fuel, and digital road billboards. The attack took place on 26 October 2021. The government announced that people had to buy gas without their ration card. According to the Supreme Council of Cyberspace, the attacks were similar to the attack on the Iranian rail road transit system in July. Iranian President Ebrahim Raisi stated, \"this cyberattack is neither the first time nor will it be the last.\"Network infrastructure is a semi-isolated system not connected to the Internet but instead uses the National Internet (National Information Network).Gholamreza Jalali, the head of Iranian civil defense, accused the United States and Israel of being behind the attack in an interview with state TV.\n\n\n\n== Scale and Details ==\nIran's 4300 gas stations were unable to process payments. Initially, the Ministry of Petroleum blamed a technical error, though it was later revealed to be a cyberattack. Users trying to purchase fuel at affected gas stations received a display reading \"cyberattack 64411\" which is associated with a hotline to the Ayatollah's office which responds to questions about Islamic law, though a possible connection was not commented on by official Iranian agencies. Cybersecurity industry firms noted the similarity to a 2020 rail attack in which a similar message was displayed, prompting speculation of a possible connection between the two attacks. The previous attack was attributed by security researchers at Check Point to the hacking group INDRA, which claims to be an anti-government partisan resistance group.Digital billboards in Iranian cities were seen displaying messages such as \"Khameini! Where is our fuel?\" as news about the attack spread. A group called Predatory Sparrow claimed credit for the attack along with a previous cyberattacks against Iranian rail assets earlier in 2021, although Iranian officials simply attributed it to an unnamed state actor. Answer this question using the following article:\n\nWho is accused by the head of Iranian civil defense of being behind the 2021 Iranian fuel cyberattack?",
    "context": "",
    "output": "The head of Iranian civil defense, Gholamreza Jalali, accused the United States and Israel of being behind the 2021 Iranian fuel cyberattack.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "Who is accused by the head of Iranian civil defense of being behind the 2021 Iranian fuel cyberattack?",
      "answer": "The head of Iranian civil defense, Gholamreza Jalali, accused the United States and Israel of being behind the 2021 Iranian fuel cyberattack.",
      "context": "2021 Iranian fuel cyberattack\n\n==Introduction==\nThe Iranian fuel 2021 cyberstrike was an attack on the Iranian fuel system, government-issued cards used for buying subsidized fuel, and digital road billboards. The attack took place on 26 October 2021. The government announced that people had to buy gas without their ration card. According to the Supreme Council of Cyberspace, the attacks were similar to the attack on the Iranian rail road transit system in July. Iranian President Ebrahim Raisi stated, \"this cyberattack is neither the first time nor will it be the last.\"Network infrastructure is a semi-isolated system not connected to the Internet but instead uses the National Internet (National Information Network).Gholamreza Jalali, the head of Iranian civil defense, accused the United States and Israel of being behind the attack in an interview with state TV.\n\n\n\n== Scale and Details ==\nIran's 4300 gas stations were unable to process payments. Initially, the Ministry of Petroleum blamed a technical error, though it was later revealed to be a cyberattack. Users trying to purchase fuel at affected gas stations received a display reading \"cyberattack 64411\" which is associated with a hotline to the Ayatollah's office which responds to questions about Islamic law, though a possible connection was not commented on by official Iranian agencies. Cybersecurity industry firms noted the similarity to a 2020 rail attack in which a similar message was displayed, prompting speculation of a possible connection between the two attacks. The previous attack was attributed by security researchers at Check Point to the hacking group INDRA, which claims to be an anti-government partisan resistance group.Digital billboards in Iranian cities were seen displaying messages such as \"Khameini! Where is our fuel?\" as news about the attack spread. A group called Predatory Sparrow claimed credit for the attack along with a previous cyberattacks against Iranian rail assets earlier in 2021, although Iranian officials simply attributed it to an unnamed state actor."
    }
  },
  {
    "instruction": "ClamAV (versions 0.99 and later) supports real-time protection on Linux systems via the Fanotify add-on for the Linux kernel (version 3.8 and later). This feature allows ClamAV to monitor and scan files for viruses as they are accessed or modified.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does ClamAV's real-time protection work on Linux systems?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does ClamAV's real-time protection work on Linux systems?",
      "answer": "ClamAV (versions 0.99 and later) supports real-time protection on Linux systems via the Fanotify add-on for the Linux kernel (version 3.8 and later). This feature allows ClamAV to monitor and scan files for viruses as they are accessed or modified."
    }
  },
  {
    "instruction": "Yes, WindowsSCOPE can provide information about the behavior of malware in a Windows system by analyzing the memory snapshot and displaying information about processes, DLLs, drivers, open network sockets, file handles, and registry key handles.\n\nWrite a question about the text above.",
    "context": "",
    "output": "Can WindowsSCOPE provide information about the behavior of malware in a Windows system?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "Can WindowsSCOPE provide information about the behavior of malware in a Windows system?",
      "answer": "Yes, WindowsSCOPE can provide information about the behavior of malware in a Windows system by analyzing the memory snapshot and displaying information about processes, DLLs, drivers, open network sockets, file handles, and registry key handles."
    }
  },
  {
    "instruction": "Introduced in 2013, AEG is a platform that automates PKI management, certificate provisioning, and deployment. It integrates with Windows Active Directory and is designed for companies to streamline their PKI management processes.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the Auto Enrollment Gateway (AEG) solution, and what are its key features?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the Auto Enrollment Gateway (AEG) solution, and what are its key features?",
      "answer": "Introduced in 2013, AEG is a platform that automates PKI management, certificate provisioning, and deployment. It integrates with Windows Active Directory and is designed for companies to streamline their PKI management processes."
    }
  },
  {
    "instruction": "Home Affairs and Cyber Security Minister Clare O'Neil alleged that Optus was at fault for the attack and stated that the breach should not have happened.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What was the response of Home Affairs and Cyber Security Minister Clare O'Neil to the Optus data breach?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What was the response of Home Affairs and Cyber Security Minister Clare O'Neil to the Optus data breach?",
      "answer": "Home Affairs and Cyber Security Minister Clare O'Neil alleged that Optus was at fault for the attack and stated that the breach should not have happened."
    }
  },
  {
    "instruction": "Norton Security\n\n==Introduction==\nNorton Security is a cross-platform security suite that provides subscription-based real-time malware prevention and removal in addition to identity theft protection and performance tuning tools. Other features include a personal firewall, email spam filtering, and phishing protection. It was released on September 23, 2014. In April 2019 it has been replaced by the Norton 360 brand.\n\n\n\n== Version history ==\nIn 2014, in an effort to streamline its Norton product line, Symantec combined nine standalone Norton products into one all-purpose suite.\nNorton Security superseded Norton Internet Security (and the pre-2019 versions of Norton 360), with an overlapping release cycle that saw version 22 as the initial release of the former and the final release of the latter. However, version 22 of Norton 360 and Norton Internet Security were updates as opposed to full releases.\nIn terms of similarities and differences with its predecessors, Norton Security retained all components of Norton Internet Security (including the antivirus, firewall and identity theft components) and added the optimization tools from Norton 360.\nNorton Security is available in three editions: Norton Security Standard with one license (valid for a single device), Norton Security Deluxe with five licenses and Norton Security Premium which offers ten licenses, 25 GB of hosted online backup, and a premium subscription to Symantec's parental control system. All editions include protection for Windows, OS X, Android and iOS devices. However, features may vary based on the operating system.\nIn April 2019, the Norton 360 brand was reinstated as a replacement, maintaining a similar plan structure but with the addition of VPN and, on the premium tiers, LifeLock (which was acquired by Symantec in 2017).\n\n== System requirements ==\nOperating Systems Supported (Norton Security 22.23.1.21 for Windows)\nMicrosoft Windows 7 (all versions) with Service Pack 1 (SP 1) or later\nMicrosoft Windows 8/8.1 (all versions). Some protection features are not available in Windows 8 Start screen browsers.\nMicrosoft Windows 10 (all versions).\nMac Operating Systems (Norton Security 8.8.3 for Mac)\nmacOS 10.10 or later. Older macOS Versions may get the latest virus definitons, but not the latest product updates.\nAndroid Operating Systems (Norton Mobile Security for Android was replaced by Norton360 Antivirus & Security)\niOS Operating Systems (Norton Security for iOS was replaced by Norton360 Antivirus & Security)\n\nAnswer this question \"What is Norton Security and how does it differ from its predecessors?\" using the text above.",
    "context": "",
    "output": "Norton Security is a cross-platform security suite that combines real-time malware prevention and removal with identity theft protection and performance tuning tools. It differs from its predecessors, such as Norton Internet Security and Norton 360, in that it integrates all their components, including antivirus, firewall, and identity theft protection, and adds optimization tools.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is Norton Security and how does it differ from its predecessors?",
      "answer": "Norton Security is a cross-platform security suite that combines real-time malware prevention and removal with identity theft protection and performance tuning tools. It differs from its predecessors, such as Norton Internet Security and Norton 360, in that it integrates all their components, including antivirus, firewall, and identity theft protection, and adds optimization tools.",
      "context": "Norton Security\n\n==Introduction==\nNorton Security is a cross-platform security suite that provides subscription-based real-time malware prevention and removal in addition to identity theft protection and performance tuning tools. Other features include a personal firewall, email spam filtering, and phishing protection. It was released on September 23, 2014. In April 2019 it has been replaced by the Norton 360 brand.\n\n\n\n== Version history ==\nIn 2014, in an effort to streamline its Norton product line, Symantec combined nine standalone Norton products into one all-purpose suite.\nNorton Security superseded Norton Internet Security (and the pre-2019 versions of Norton 360), with an overlapping release cycle that saw version 22 as the initial release of the former and the final release of the latter. However, version 22 of Norton 360 and Norton Internet Security were updates as opposed to full releases.\nIn terms of similarities and differences with its predecessors, Norton Security retained all components of Norton Internet Security (including the antivirus, firewall and identity theft components) and added the optimization tools from Norton 360.\nNorton Security is available in three editions: Norton Security Standard with one license (valid for a single device), Norton Security Deluxe with five licenses and Norton Security Premium which offers ten licenses, 25 GB of hosted online backup, and a premium subscription to Symantec's parental control system. All editions include protection for Windows, OS X, Android and iOS devices. However, features may vary based on the operating system.\nIn April 2019, the Norton 360 brand was reinstated as a replacement, maintaining a similar plan structure but with the addition of VPN and, on the premium tiers, LifeLock (which was acquired by Symantec in 2017).\n\n== System requirements ==\nOperating Systems Supported (Norton Security 22.23.1.21 for Windows)\nMicrosoft Windows 7 (all versions) with Service Pack 1 (SP 1) or later\nMicrosoft Windows 8/8.1 (all versions). Some protection features are not available in Windows 8 Start screen browsers.\nMicrosoft Windows 10 (all versions).\nMac Operating Systems (Norton Security 8.8.3 for Mac)\nmacOS 10.10 or later. Older macOS Versions may get the latest virus definitons, but not the latest product updates.\nAndroid Operating Systems (Norton Mobile Security for Android was replaced by Norton360 Antivirus & Security)\niOS Operating Systems (Norton Security for iOS was replaced by Norton360 Antivirus & Security)"
    }
  },
  {
    "instruction": "A possible initial public offering (IPO) for AT&T Cybersecurity would indicate that the company is preparing to become a publicly traded company, which would provide it with access to additional capital and increase its visibility in the market.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the significance of AT&T Cybersecurity's possible initial public offering (IPO)?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the significance of AT&T Cybersecurity's possible initial public offering (IPO)?",
      "answer": "A possible initial public offering (IPO) for AT&T Cybersecurity would indicate that the company is preparing to become a publicly traded company, which would provide it with access to additional capital and increase its visibility in the market."
    }
  },
  {
    "instruction": "Email encryption\n\n==Introduction==\nEmail encryption is encryption of email messages to protect the content from being read by entities other than the intended recipients. Email encryption may also include authentication.\nEmail is prone to the disclosure of information. Most emails are encrypted during transmission, but they are stored in clear text, making them readable by third parties such as email providers. By default, popular email services such as Gmail and Outlook do not enable end-to-end encryption. By means of some available tools, persons other than the designated recipients can read the email contents.Email encryption can rely on public-key cryptography, in which users can each publish a public key that others can use to encrypt messages to them, while keeping secret a private key they can use to decrypt such messages or to digitally encrypt and sign messages they send.\n\n== Encryption protocols ==\nWith the original design of email protocol, the communication between email servers was in plain text, which posed a huge security risk. Over the years, various mechanisms have been proposed to encrypt the communication between email servers. Encryption may occur at the transport level (aka \"hop by hop\") or end-to-end. Transport layer encryption is often easier to set up and use; end-to-end encryption provides stronger defenses, but can be more difficult to set up and use.\n\n\n*** Transport-level encryption ***\nOne of the most commonly used email encryption extensions is STARTTLS. It is a TLS (SSL) layer over the plaintext communication, allowing email servers to upgrade their plaintext communication to encrypted communication. Assuming that the email servers on both the sender and the recipient side support encrypted communication, an eavesdropper snooping on the communication between the mail servers cannot use a sniffer to see the email contents. Similar STARTTLS extensions exist for the communication between an email client and the email server (see IMAP4 and POP3, as stated by RFC 2595).  STARTTLS may be used regardless of whether the email's contents are encrypted using another protocol.\nThe encrypted message is revealed, and can be altered by, intermediate email relays. In other words, the encryption takes place between individual SMTP relays, not between the sender and the recipient.  This has both good and bad consequences.  A key positive trait of transport layer encryption is that users do not need to do or change anything; the encryption automatically occurs when they send email.  In addition, since receiving organizations can decrypt the email without cooperation of the end user, receiving organizations can run virus scanners and spam filters before delivering the email to the recipient.  However, it also means that the receiving organization and anyone who breaks into that organization's email system (unless further steps are taken) can easily read or modify the email.  If the receiving organization is considered a threat, then end-to-end encryption is necessary.\nThe Electronic Frontier Foundation encourages the use of STARTTLS, and has launched the 'STARTTLS Everywhere' initiative to \"make it simple and easy for everyone to help ensure their communications (over email) aren\u2019t vulnerable to mass surveillance.\"  Support for STARTTLS has become quite common; Google reports that on Gmail, 90% of incoming email and 90% of outgoing email was encrypted using STARTTLS by July 24, 2018.Mandatory certificate verification is historically not viable for Internet mail delivery without additional information, because many certificates are not verifiable and few want email delivery to fail in that case. As a result, most email that is delivered over TLS uses only opportunistic encryption. DANE is a proposed standard that makes an incremental transition to verified encryption for Internet mail delivery possible.  The STARTTLS Everywhere project uses an alternative approach: they support a \u201cpreload list\u201d of email servers that have promised to support STARTTLS, which can help detect and prevent downgrade attacks.\n\n\n*** End-to-end encryption ***\nIn end-to-end encryption, the data is encrypted and decrypted only at the end points. In other words, an email sent with end-to-end encryption would be encrypted at the source, unreadable to service providers like Gmail in transit, and then decrypted at its endpoint. Crucially, the email would only be decrypted for the end user on their computer and would remain in encrypted, unreadable form to an email service like Gmail, which wouldn't have the keys available to decrypt it. Some email services integrate end-to-end encryption automatically.\nNotable protocols for end-to-end email encryption include:\n\nBitmessage\nGNU Privacy Guard (GPG)\nPretty Good Privacy (PGP)\nS/MIMEOpenPGP is a data encryption standard that allows end-users to encrypt the email contents. There are various software and email-client plugins that allow users to encrypt the message using the recipient's public key before sending it. At its core, OpenPGP uses a Public Key Cryptography scheme where each email address is associated with a public/private key pair.\nOpenPGP provides a way for the end users to encrypt the email without any support from the server and be sure that only the intended recipient can read it. However, there are usability issues with OpenPGP \u2014 it requires users to set up public/private key pairs and make the public keys available widely. Also, it protects only the content of the email, and not metadata \u2014 an untrusted party can still observe who sent an email to whom. A general downside of end to end encryption schemes\u2014where the server does not have decryption keys\u2014is that it makes server side search almost impossible, thus impacting usability.\nThe content of an email can also be end-to-end encrypted by putting it in an encrypted file (using any kind of file encryption tool) and sending that encrypted file as an email attachment.\n\n== Demonstrations ==\nThe Signed and Encrypted Email Over The Internet demonstration has shown that organizations can collaborate effectively using secure email. Previous barriers to adoption were overcome, including the use of a PKI bridge to provide a scalable public key infrastructure (PKI) and the use of network security guards checking encrypted content passing in and out of corporate network boundaries to avoid encryption being used to hide malware introduction and information leakage.\n\n== Setting up and using email encryption ==\nTransport layer encryption using STARTTLS must be set up by the receiving organization.  This is typically straightforward; a valid certificate must be obtained and STARTTLS must be enabled on the receiving organization's email server.  To prevent downgrade attacks organizations can send their domain to the 'STARTTLS Policy List'Most full-featured email clients provide native support for S/MIME secure email (digital signing and message encryption using certificates). Other encryption options include PGP and GNU Privacy Guard (GnuPG). Free and commercial software (desktop application, webmail and add-ons) are available as well.While PGP can protect messages, it can also be hard to use in the correct way. Researchers at Carnegie Mellon University published a paper in 1999 showing that most people couldn't figure out how to sign and encrypt messages using the current version of PGP. Eight years later, another group of Carnegie Mellon researchers published a follow-up paper saying that, although a newer version of PGP made it easy to decrypt messages, most people still struggled with encrypting and signing messages, finding and verifying other people's public encryption keys, and sharing their own keys.Because encryption can be difficult for users, security and compliance managers at companies and government agencies automate the process for employees and executives by using encryption appliances and services that automate encryption. Instead of relying on voluntary co-operation, automated encryption, based on defined policies, takes the decision and the process out of the users' hands. Emails are routed through a gateway appliance that has been configured to ensure compliance with regulatory and security policies. Emails that require it are automatically encrypted and sent.If the recipient works at an organization that uses the same encryption gateway appliance, emails are automatically decrypted, making the process transparent to the user. Recipients who are not behind an encryption gateway then need to take an extra step, either procuring the public key, or logging into an online portal to retrieve the message.\n\n== Encrypted email providers ==\nSince 2000, the number of available encrypted email providers has increased significantly. Notable providers include:\n\nHushmail\nMailfence\nProtonMail\nTutanota\nSkiff_(email_service) Answer this question using the following article:\n\nWhat is the difference between transport-level encryption and end-to-end encryption in email?",
    "context": "",
    "output": "Transport-level encryption, such as STARTTLS, encrypts the communication between email servers, while end-to-end encryption encrypts the data and decrypts it only at the end points, ensuring that the email is unreadable in transit.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the difference between transport-level encryption and end-to-end encryption in email?",
      "answer": "Transport-level encryption, such as STARTTLS, encrypts the communication between email servers, while end-to-end encryption encrypts the data and decrypts it only at the end points, ensuring that the email is unreadable in transit.",
      "context": "Email encryption\n\n==Introduction==\nEmail encryption is encryption of email messages to protect the content from being read by entities other than the intended recipients. Email encryption may also include authentication.\nEmail is prone to the disclosure of information. Most emails are encrypted during transmission, but they are stored in clear text, making them readable by third parties such as email providers. By default, popular email services such as Gmail and Outlook do not enable end-to-end encryption. By means of some available tools, persons other than the designated recipients can read the email contents.Email encryption can rely on public-key cryptography, in which users can each publish a public key that others can use to encrypt messages to them, while keeping secret a private key they can use to decrypt such messages or to digitally encrypt and sign messages they send.\n\n== Encryption protocols ==\nWith the original design of email protocol, the communication between email servers was in plain text, which posed a huge security risk. Over the years, various mechanisms have been proposed to encrypt the communication between email servers. Encryption may occur at the transport level (aka \"hop by hop\") or end-to-end. Transport layer encryption is often easier to set up and use; end-to-end encryption provides stronger defenses, but can be more difficult to set up and use.\n\n\n*** Transport-level encryption ***\nOne of the most commonly used email encryption extensions is STARTTLS. It is a TLS (SSL) layer over the plaintext communication, allowing email servers to upgrade their plaintext communication to encrypted communication. Assuming that the email servers on both the sender and the recipient side support encrypted communication, an eavesdropper snooping on the communication between the mail servers cannot use a sniffer to see the email contents. Similar STARTTLS extensions exist for the communication between an email client and the email server (see IMAP4 and POP3, as stated by RFC 2595).  STARTTLS may be used regardless of whether the email's contents are encrypted using another protocol.\nThe encrypted message is revealed, and can be altered by, intermediate email relays. In other words, the encryption takes place between individual SMTP relays, not between the sender and the recipient.  This has both good and bad consequences.  A key positive trait of transport layer encryption is that users do not need to do or change anything; the encryption automatically occurs when they send email.  In addition, since receiving organizations can decrypt the email without cooperation of the end user, receiving organizations can run virus scanners and spam filters before delivering the email to the recipient.  However, it also means that the receiving organization and anyone who breaks into that organization's email system (unless further steps are taken) can easily read or modify the email.  If the receiving organization is considered a threat, then end-to-end encryption is necessary.\nThe Electronic Frontier Foundation encourages the use of STARTTLS, and has launched the 'STARTTLS Everywhere' initiative to \"make it simple and easy for everyone to help ensure their communications (over email) aren\u2019t vulnerable to mass surveillance.\"  Support for STARTTLS has become quite common; Google reports that on Gmail, 90% of incoming email and 90% of outgoing email was encrypted using STARTTLS by July 24, 2018.Mandatory certificate verification is historically not viable for Internet mail delivery without additional information, because many certificates are not verifiable and few want email delivery to fail in that case. As a result, most email that is delivered over TLS uses only opportunistic encryption. DANE is a proposed standard that makes an incremental transition to verified encryption for Internet mail delivery possible.  The STARTTLS Everywhere project uses an alternative approach: they support a \u201cpreload list\u201d of email servers that have promised to support STARTTLS, which can help detect and prevent downgrade attacks.\n\n\n*** End-to-end encryption ***\nIn end-to-end encryption, the data is encrypted and decrypted only at the end points. In other words, an email sent with end-to-end encryption would be encrypted at the source, unreadable to service providers like Gmail in transit, and then decrypted at its endpoint. Crucially, the email would only be decrypted for the end user on their computer and would remain in encrypted, unreadable form to an email service like Gmail, which wouldn't have the keys available to decrypt it. Some email services integrate end-to-end encryption automatically.\nNotable protocols for end-to-end email encryption include:\n\nBitmessage\nGNU Privacy Guard (GPG)\nPretty Good Privacy (PGP)\nS/MIMEOpenPGP is a data encryption standard that allows end-users to encrypt the email contents. There are various software and email-client plugins that allow users to encrypt the message using the recipient's public key before sending it. At its core, OpenPGP uses a Public Key Cryptography scheme where each email address is associated with a public/private key pair.\nOpenPGP provides a way for the end users to encrypt the email without any support from the server and be sure that only the intended recipient can read it. However, there are usability issues with OpenPGP \u2014 it requires users to set up public/private key pairs and make the public keys available widely. Also, it protects only the content of the email, and not metadata \u2014 an untrusted party can still observe who sent an email to whom. A general downside of end to end encryption schemes\u2014where the server does not have decryption keys\u2014is that it makes server side search almost impossible, thus impacting usability.\nThe content of an email can also be end-to-end encrypted by putting it in an encrypted file (using any kind of file encryption tool) and sending that encrypted file as an email attachment.\n\n== Demonstrations ==\nThe Signed and Encrypted Email Over The Internet demonstration has shown that organizations can collaborate effectively using secure email. Previous barriers to adoption were overcome, including the use of a PKI bridge to provide a scalable public key infrastructure (PKI) and the use of network security guards checking encrypted content passing in and out of corporate network boundaries to avoid encryption being used to hide malware introduction and information leakage.\n\n== Setting up and using email encryption ==\nTransport layer encryption using STARTTLS must be set up by the receiving organization.  This is typically straightforward; a valid certificate must be obtained and STARTTLS must be enabled on the receiving organization's email server.  To prevent downgrade attacks organizations can send their domain to the 'STARTTLS Policy List'Most full-featured email clients provide native support for S/MIME secure email (digital signing and message encryption using certificates). Other encryption options include PGP and GNU Privacy Guard (GnuPG). Free and commercial software (desktop application, webmail and add-ons) are available as well.While PGP can protect messages, it can also be hard to use in the correct way. Researchers at Carnegie Mellon University published a paper in 1999 showing that most people couldn't figure out how to sign and encrypt messages using the current version of PGP. Eight years later, another group of Carnegie Mellon researchers published a follow-up paper saying that, although a newer version of PGP made it easy to decrypt messages, most people still struggled with encrypting and signing messages, finding and verifying other people's public encryption keys, and sharing their own keys.Because encryption can be difficult for users, security and compliance managers at companies and government agencies automate the process for employees and executives by using encryption appliances and services that automate encryption. Instead of relying on voluntary co-operation, automated encryption, based on defined policies, takes the decision and the process out of the users' hands. Emails are routed through a gateway appliance that has been configured to ensure compliance with regulatory and security policies. Emails that require it are automatically encrypted and sent.If the recipient works at an organization that uses the same encryption gateway appliance, emails are automatically decrypted, making the process transparent to the user. Recipients who are not behind an encryption gateway then need to take an extra step, either procuring the public key, or logging into an online portal to retrieve the message.\n\n== Encrypted email providers ==\nSince 2000, the number of available encrypted email providers has increased significantly. Notable providers include:\n\nHushmail\nMailfence\nProtonMail\nTutanota\nSkiff_(email_service)"
    }
  },
  {
    "instruction": "Cryptojacking malware is designed to remain completely hidden from the user, unlike other malicious attacks that may display symptoms or seek to steal sensitive information.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is unique about cryptojacking malware compared to other malicious attacks?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is unique about cryptojacking malware compared to other malicious attacks?",
      "answer": "Cryptojacking malware is designed to remain completely hidden from the user, unlike other malicious attacks that may display symptoms or seek to steal sensitive information."
    }
  },
  {
    "instruction": "The CGA generation process increases the cost of generating an address by the same factor depending on the value of Sec, but the cost of using and verifying a CGA remains constant.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does the CGA specification affect the cost of generating an address and the cost of using and verifying a CGA?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does the CGA specification affect the cost of generating an address and the cost of using and verifying a CGA?",
      "answer": "The CGA generation process increases the cost of generating an address by the same factor depending on the value of Sec, but the cost of using and verifying a CGA remains constant."
    }
  },
  {
    "instruction": "LDAP only supports EAP-GTC.\n\nWrite a question about the text above.",
    "context": "",
    "output": "Which authentication system does LDAP support?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "Which authentication system does LDAP support?",
      "answer": "LDAP only supports EAP-GTC."
    }
  },
  {
    "instruction": "REDOC II and REDOC III are both block ciphers designed for software use, but they differ in their design and optimization. REDOC II is optimized for use in software and uses key-dependent S-boxes and masks in its 10 rounds of encryption. However, it is vulnerable to differential cryptanalysis, and attacks have been found to recover masks and break one round. REDOC III is a more efficient cipher than REDOC II and uses a variable-length key of up to 20,480 bits. It encrypts by XORing key bytes with message bytes, without using any permutations or substitutions, making it more secure against differential cryptanalysis.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How do REDOC II and REDOC III differ in terms of their design and optimization?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How do REDOC II and REDOC III differ in terms of their design and optimization?",
      "answer": "REDOC II and REDOC III are both block ciphers designed for software use, but they differ in their design and optimization. REDOC II is optimized for use in software and uses key-dependent S-boxes and masks in its 10 rounds of encryption. However, it is vulnerable to differential cryptanalysis, and attacks have been found to recover masks and break one round. REDOC III is a more efficient cipher than REDOC II and uses a variable-length key of up to 20,480 bits. It encrypts by XORing key bytes with message bytes, without using any permutations or substitutions, making it more secure against differential cryptanalysis."
    }
  },
  {
    "instruction": "Magecart is a software used by hacking groups to inject malicious code into ecommerce sites to steal payment details. This software has been used in targeted attacks on major companies such as Newegg, as well as in combination with commodity Magento extension attacks.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is Magecart software and how is it used by hacking groups to steal payment details?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is Magecart software and how is it used by hacking groups to steal payment details?",
      "answer": "Magecart is a software used by hacking groups to inject malicious code into ecommerce sites to steal payment details. This software has been used in targeted attacks on major companies such as Newegg, as well as in combination with commodity Magento extension attacks."
    }
  },
  {
    "instruction": "Timeline of computer viruses and worms\n\n==Introduction==\nThis timeline of computer viruses and worms presents a chronological timeline of noteworthy computer viruses, computer worms, Trojan horses, similar malware, related research and events.\n\n\n\n== 1960s ==\nJohn von Neumann's article on the \"Theory of self-reproducing automata\" is published in 1966. The article is based on lectures given by von Neumann at the University of Illinois about the \"Theory and Organization of Complicated Automata\" in 1949.\n\n== 1970s ==\n\n\n*** 1970 ***\nThe first story written about a computer virus is The Scarred Man by Gregory Benford.\n\n\n*** 1971 ***\nThe Creeper system, an experimental self-replicating program, is written by Bob Thomas at BBN Technologies to test John von Neumann's theory. Creeper infected DEC PDP-10 computers running the TENEX operating system. Creeper gained access via the ARPANET and copied itself to the remote system where the message \"I'm the creeper, catch me if you can!\" was displayed. The Reaper program was later created to delete Creeper.\nAt the University of Illinois at Urbana-Champaign, a graduate student named Alan Davis (working for Prof. Donald Gillies) created a process on a PDP-11 that (a) checked to see if an identical copy of itself was currently running as an active process, and if not, created a copy of itself and started it running; (b) checked to see if any disk space (which all users shared) was available, and if so, created a file the size of that space; and (c) looped back to step (a). As a result, the process stole all available disk space. When users tried to save files, the operating system advised them that the disk was full and that they needed to delete some existing files. Of course, if they did delete a file, this process would immediately snatch up the available space. When users called in a system administrator (A. Ian Stocks) to fix the problem, he examined the active processes, discovered the offending process, and deleted it. Of course, before he left the room, the still existing process would create another copy of itself, and the problem wouldn't go away. The only way to make the computer work again was to reboot.\n\n\n*** 1972 ***\nThe science fiction novel, When HARLIE Was One, by David Gerrold, contains one of the first fictional representations of a computer virus, as well as one of the first uses of the word \"virus\" to denote a program that infects a computer.\n\n\n*** 1973 ***\nIn fiction, the 1973 Michael Crichton movie Westworld made an early mention of the concept of a computer virus, being a central plot theme that causes androids to run amok. Alan Oppenheimer's character summarizes the problem by stating that \"...there's a clear pattern here which suggests an analogy to an infectious disease process, spreading from one...area to the next.\"  To which the replies are stated: \"Perhaps there are superficial similarities to disease\" and, \"I must confess I find it difficult to believe in a disease of machinery.\" (Crichton's earlier work, the 1969 novel The Andromeda Strain and 1971 film were about an extraterrestrial biological virus-like disease that threatened the human race.)\n\n\n*** 1974 ***\nThe Rabbit (or Wabbit) virus, more a fork bomb than a virus, is written. The Rabbit virus makes multiple copies of itself on a single computer (and was named \"Rabbit\" for the speed at which it did so) until it clogs the system, reducing system performance, before finally reaching a threshold and crashing the computer.\n\n\n*** 1975 ***\nApril: ANIMAL is written by John Walker for the UNIVAC 1108. ANIMAL asked several questions of the user in an attempt to guess the type of animal the user was thinking of, while the related program PERVADE would create a copy of itself and ANIMAL in every directory to which the current user had access. It spread across the multi-user UNIVACs when users with overlapping permissions discovered the game, and to other computers when tapes were shared. The program was carefully written to avoid damaging existing file or directory structures, and to avoid copying itself if permissions did not exist or if harm would result. Its spread was halted by an OS upgrade that changed the format of the file status tables PERVADE used. Though non-malicious, \"Pervading Animal\" represents the first Trojan \"in the wild\".\nThe novel The Shockwave Rider by John Brunner is published, coining the word \"worm\" to describe a program that propagates itself through a computer network.\n\n\n*** 1977 ***\n\"The Adolescence of P-1\" novel, describes a worm program which propagates through modem-based networks, eventually developing its own strategy-developing AI, which deals with cross-hardware and cross-os issues, eventually infecting hardware manufactures and defense organizations.\n\n== 1980s ==\n\n\n*** 1982 ***\nA program called Elk Cloner, written for Apple II systems, was created by high school student Richard Skrenta, originally as a prank. The Apple II was particularly vulnerable due to the storage of its operating system on a floppy disk. Elk Cloner's design combined with public ignorance about what malware was and how to protect against it led to Elk Cloner being responsible for the first large-scale computer virus outbreak in history.\n\n\n*** 1983 ***\nNovember: The term \"virus\" is re-coined by Frederick B. Cohen in describing self-replicating computer programs. In 1984 Cohen uses the phrase \"computer virus\" (suggested by his teacher Leonard Adleman) to describe the operation of such programs in terms of \"infection\". He defines a \"virus\" as \"a program that can 'infect' other programs by modifying them to include a possibly evolved copy of itself.\" Cohen demonstrates a virus-like program on a VAX11/750 system at Lehigh University. The program could install itself in, or infect, other system objects.\n\n\n*** 1984 ***\nAugust: Ken Thompson publishes his seminal paper, Reflections on Trusting Trust, in which he describes how he modified a C compiler so that when used to compile a specific version of the Unix operating system, it inserts a backdoor into the login command, and when used to compile a new copy of itself, it inserts the backdoor insertion code, even if neither the backdoor nor the backdoor insertion code is present in the source code of this new copy.\n\n\n*** 1986 ***\nJanuary: The Brain boot sector virus is released. Brain is considered the first IBM PC compatible virus, and the program responsible for the first IBM PC compatible virus epidemic. The virus is also known as Lahore, Pakistani, Pakistani Brain, and Pakistani flu as it was created in Lahore, Pakistan by 19-year-old Pakistani programmer, Basit Farooq Alvi, and his brother, Amjad Farooq Alvi.\nDecember: Ralf Burger presented the Virdem model of programs at a meeting of the underground Chaos Computer Club in Germany. The Virdem model represented the first programs that could replicate themselves via addition of their code to executable DOS files in COM format.\n\n\n*** 1987 ***\nAppearance of the Vienna virus, which was subsequently neutralized \u2013 the first time this had happened on the IBM platform.\nAppearance of Lehigh virus (discovered at its namesake university), boot sector viruses such as Yale from the US, Stoned from New Zealand, Ping Pong from Italy, and appearance of the first self-encrypting file virus, Cascade. Lehigh was stopped on campus before it spread to the \"wild\" (to computers beyond the university), and as a result, has never been found elsewhere. A subsequent infection of Cascade in the offices of IBM Belgium led to IBM responding with its own antivirus product development. Prior to this, antivirus solutions developed at IBM were intended for staff use only.\nOctober: The Jerusalem virus, part of the (at that time unknown) Suriv family, is detected in the city of Jerusalem. The virus destroys all executable files on infected machines upon every occurrence of Friday the 13th (except Friday 13 November 1987 making its first trigger date May 13, 1988). Jerusalem caused a worldwide epidemic in 1988.\nNovember: The SCA virus, a boot sector virus for Amiga computers, appears.  It immediately creates a pandemic virus-writer storm. A short time later, SCA releases another, considerably more destructive virus, the Byte Bandit.\nDecember: Christmas Tree EXEC was the first widely disruptive replicating network program, which paralyzed several international computer networks in December 1987. It was written in Rexx on the VM/CMS operating system and originated in what was then West Germany. It re-emerged in 1990.\n\n\n*** 1988 ***\nMarch 1: The Ping-Pong virus (also called Boot, Bouncing Ball, Bouncing Dot, Italian, Italian-A or VeraCruz), an MS-DOS boot sector virus, is discovered at the University of Turin in Italy.\nJune: The CyberAIDS and Festering Hate Apple ProDOS viruses spreads from underground pirate BBS systems and starts infecting mainstream networks. Festering Hate was the last iteration of the CyberAIDS series extending back to 1985 and 1986. Unlike the few Apple viruses that had come before which were essentially annoying, but did no damage, the Festering Hate series of viruses was extremely destructive, spreading to all system files it could find on the host computer (hard drive, floppy, and system memory) and then destroying everything when it could no longer find any uninfected files.\nNovember 2: The Morris worm, created by Robert Tappan Morris, infects DEC VAX and Sun machines running BSD UNIX that are connected to the Internet, and becomes the first worm to spread extensively \"in the wild\", and one of the first well-known programs exploiting buffer overrun vulnerabilities.\nDecember: The Father Christmas worm attacks DEC VAX machines running VMS that are connected to the DECnet Internet (an international scientific research network using DECnet protocols), affecting NASA and other research centers. Its purpose was to deliver a Christmas greeting to all affected users.\n\n\n*** 1989 ***\nOctober: Ghostball, the first multipartite virus, is discovered by Fri\u00f0rik Sk\u00falason. It infects both executable .COM files and boot sectors on MS-DOS systems.\nDecember: Several thousand floppy disks containing the AIDS Trojan, the first known ransomware, are mailed to subscribers of PC Business World magazine and a WHO AIDS conference mailing list. This DOS Trojan lies dormant for 90 boot cycles, then encrypts all filenames on the system, displaying a notice asking for $189 to be sent to a post office box in Panama in order to receive a decryption program.\n\n== 1990s ==\n\n\n*** 1990 ***\nMark Washburn, working on an analysis of the Vienna and Cascade viruses with Ralf Burger, develops the first family of polymorphic viruses, the Chameleon family. Chameleon series debuted with the release of 1260.\nJune: The Form computer virus is isolated in Switzerland. It would remain in the wild for almost 20 years and reappear afterward; during the 1990s it tended to be the most common virus in the wild with 20 to more than 50 percent of reported infections.\n\n\n*** 1992 ***\nMarch: The Michelangelo virus was expected to create a digital apocalypse on March 6, with millions of computers having their information wiped, according to mass media hysteria surrounding the virus. Later assessments of the damage showed the aftermath to be minimal. John McAfee had been quoted by the media as saying that five million computers would be affected. He later said that pressed by the interviewer to come up with a number, he had estimated a range from five thousand to five million, but the media naturally went with just the higher number.\n\n\n*** 1993 ***\n\"Leandro\" or \"Leandro & Kelly\" and \"Freddy Krueger\" spread quickly due to popularity of BBS and shareware distribution.\n\n\n*** 1994 ***\nApril: OneHalf is a DOS-based polymorphic computer virus.\nSeptember: ReBoot first airs, containing another memorable fictional, sentient computer virus, Megabyte.\n\n\n*** 1995 ***\nThe first Macro virus, called \"Concept\", is created. It attacked Microsoft Word documents.\n\n\n*** 1996 ***\n\"Ply\" \u2013 DOS 16-bit based complicated polymorphic virus appeared with a built-in permutation engine.\nBoza, the first virus designed specifically for Windows 95 files arrives.\nLaroux, the first Excel macro virus appears.\nStaog, the first Linux virus attacks Linux machines\n\n\n*** 1998 ***\nJune 2: The first version of the CIH virus appears. It is the first known virus able to erase flash ROM BIOS content.\n\n\n*** 1999 ***\nJanuary 20: The Happy99 worm first appeared. It invisibly attaches itself to emails, displays fireworks to hide the changes being made, and wishes the user a happy New Year. It modifies system files related to Outlook Express and Internet Explorer (IE) on Windows 95 and Windows 98.\nMarch 26: The Melissa worm was released, targeting Microsoft Word and Outlook-based systems, and creating considerable network traffic.\nJune 6: The ExploreZip worm, which destroys Microsoft Office documents, was first detected.\nSeptember: the CTX virus is isolated\nDecember 30: The Kak worm is a JavaScript computer worm that spread itself by exploiting a bug in Outlook Express.\n\n== 2000s ==\n\n\n*** 2000 ***\nMay 5: The ILOVEYOU worm (also known as the Love Letter, VBS, or Love Bug worm), a computer worm written in VBScript and using social engineering techniques, infected millions of Windows computers worldwide within a few hours of its release.\nJune 28: The Pikachu virus is believed to be the first computer virus geared at children. It contains the character \"Pikachu\" from the Pok\u00e9mon series. The operating systems affected by this worm are Windows 95, Windows 98, and Windows ME.\n\n\n*** 2001 ***\nFebruary 11: The Anna Kournikova virus hits e-mail servers hard by sending e-mail to contacts in the Microsoft Outlook addressbook. Its creator, Jan de Wit, was sentenced to 150 hours of community service.\nMarch 13: Magistr, also called Disembowler, is discovered. It is a complex email worm for Windows systems with multiple payloads that trigger months apart from each other. It targets members of the Law profession by searching the files on a user's computer for various keywords relating to court proceedings, activating if such are found.\nMay 8: The Sadmind worm spreads by exploiting holes in both Sun Solaris and Microsoft IIS.\nJuly: The Sircam worm is released, spreading through Microsoft systems via e-mail and unprotected network shares.\nJuly 13: The Code Red worm attacking the Index Server ISAPI Extension in Microsoft Internet Information Services is released.\nAugust 4: A complete re-write of the Code Red worm, Code Red II begins aggressively spreading onto Microsoft systems, primarily in China.\nSeptember 18: The Nimda worm is discovered and spreads through a variety of means including vulnerabilities in Microsoft Windows and backdoors left by Code Red II and Sadmind worm.\nOctober 26: The Klez worm is first identified. It exploits a vulnerability in Microsoft Internet Explorer and Microsoft Outlook and Outlook Express.\n\n\n*** 2002 ***\nFebruary 11: The Simile virus is a metamorphic computer virus written in assembly.\nBeast is a Windows-based backdoor Trojan horse, more commonly known as a RAT (Remote Administration Tool). It is capable of infecting almost all versions of Windows. Written in Delphi and released first by its author Tataye in 2002, its most current version was released on October 3, 2004.\nMarch 7: Mylife is a computer worm that spread itself by sending malicious emails to all the contacts in Microsoft Outlook.\n\n\n*** 2003 ***\nJanuary 24: The SQL Slammer worm, aka Sapphire worm, Helkern and other names, attacks vulnerabilities in Microsoft SQL Server and MSDE becomes the fastest spreading worm of all time (measured by doubling time at the peak rate of growth), causing massive Internet access disruptions worldwide just fifteen minutes after infecting its first victim.\nApril 2: Graybird is a trojan horse also known as Backdoor.Graybird.\nJune 13: ProRat is a Turkish-made Microsoft Windows based backdoor trojan horse, more commonly known as a RAT (Remote Administration Tool).\nAugust 12: The Blaster worm, aka the Lovesan worm, rapidly spreads by exploiting a vulnerability in system services present on Windows computers.\nAugust 18: The Welchia (Nachi) worm is discovered. The worm tries to remove the Blaster worm and patch Windows.\nAugust 19: The Sobig worm (technically the Sobig.F worm) spreads rapidly through Microsoft systems via mail and network shares.\nSeptember 18: Swen is a computer worm written in C++.\nOctober 24: The Sober worm is first seen on Microsoft systems and maintains its presence until 2005 with many new variants. The simultaneous attacks on network weak points by the Blaster and Sobig worms cause massive damage.\nNovember 10: Agobot is a computer worm that can spread itself by exploiting vulnerabilities on Microsoft Windows. Some of the vulnerabilities are MS03-026 and MS05-039.\nNovember 20: Bolgimo is a computer worm that spread itself by exploiting a buffer overflow vulnerability at Microsoft Windows DCOM RPC Interface.\n\n\n*** 2004 ***\nJanuary 18: Bagle is a mass-mailing worm affecting all versions of Microsoft Windows. There were 2 variants of Bagle worm, Bagle.A and Bagle.B. Bagle.B was discovered on February 17, 2004.\nJanuary 26: The MyDoom worm emerges, and currently holds the record for the fastest-spreading mass mailer worm. The worm was most notable for performing a distributed denial-of-service (DDoS) attack on www.sco.com, which belonged to The SCO Group.\nFebruary 16: The Netsky worm is discovered. The worm spreads by email and by copying itself to folders on the local hard drive as well as on mapped network drives if available. Many variants of the Netsky worm appeared.\nMarch 19: The Witty worm is a record-breaking worm in many regards. It exploited holes in several Internet Security Systems (ISS) products. It was the fastest computer issue to be categorized as a worm, and it was the first internet worm to carry a destructive payload. It spread rapidly using a pre-populated list of ground-zero hosts.\nMay 1: The Sasser worm emerges by exploiting a vulnerability in the Microsoft Windows LSASS service and causes problems in networks, while removing MyDoom and Bagle variants, even interrupting business.\nJune 15: Caribe or Cabir is a computer worm that is designed to infect mobile phones that run Symbian OS. It is the first computer worm that can infect mobile phones. It spread itself through Bluetooth. More information can be found on F-Secure and Symantec.\nAugust 16: Nuclear RAT (short for Nuclear Remote Administration Tool) is a backdoor trojan that infects Windows NT family systems (Windows 2000, Windows XP, Windows 2003).\nAugust 20: Vundo, or the Vundo Trojan (also known as Virtumonde or Virtumondo and sometimes referred to as MS Juan) is a trojan known to cause popups and advertising for rogue antispyware programs, and sporadically other misbehavior including performance degradation and denial of service with some websites including Google and Facebook.\nOctober 12: Bifrost, also known as Bifrose, is a backdoor trojan which can infect Windows 95 through Vista. Bifrost uses the typical server, server builder, and client backdoor program configuration to allow a remote attack.\nDecember: Santy, the first known \"webworm\" is launched. It exploited a vulnerability in phpBB and used Google to find new targets. It infected around 40000 sites before Google filtered the search query used by the worm, preventing it from spreading.\n\n\n*** 2005 ***\nAugust 2005: Zotob is a computer worm which exploits security vulnerabilities in Microsoft operating systems like Windows 2000, including the MS05-039 plug-and-play vulnerability. This worm has been known to spread on Microsoft-ds or TCP port 445.\nOctober 2005: The copy protection rootkit deliberately and surreptitiously included on music CDs sold by Sony BMG is exposed.  The rootkit creates vulnerabilities on affected computers, making them susceptible to infection by worms and viruses.\nLate 2005: The Zlob Trojan, is a Trojan horse program that masquerades as a required video codec in the form of the Microsoft Windows ActiveX component. It was first detected in late 2005.\n\n\n*** 2006 ***\nJanuary 20: The Nyxem worm was discovered. It spread by mass-mailing. Its payload, which activates on the third of every month, starting on February 3, attempts to disable security-related and file-sharing software, and destroy files of certain types, such as Microsoft Office files.\nFebruary 16: Discovery of the first-ever malware for Mac OS X, a low-threat trojan-horse known as OSX/Leap-A or OSX/Oompa-A, is announced.\nLate March: Brontok variant N was found in late March. Brontok was a mass-email worm and the origin for the worm was from Indonesia.\nJune: Starbucks is a virus that infects StarOffice and OpenOffice.\nLate September: Stration or Warezov worm first discovered.\nDevelopment of Stuxnet is presumed to have been started between 2005 and 2006.\n\n\n*** 2007 ***\nJanuary 17: Storm Worm identified as a fast-spreading email spamming threat to Microsoft systems. It begins gathering infected computers into the Storm botnet. By around June 30, it had infected 1.7 million computers, and it had compromised between 1 and 10 million computers by September. Thought to have originated from Russia, it disguises itself as a news email containing a film about bogus news stories asking you to download the attachment which it claims is a film.\nJuly: Zeus is a trojan that targets Microsoft Windows to steal banking information by keystroke logging.\n\n\n*** 2008 ***\nFebruary 17: Mocmex is a trojan, which was found in a digital photo frame in February 2008. It was the first serious computer virus on a digital photo frame. The virus was traced back to a group in China.\nMarch 3: Torpig, also known as Sinowal and Mebroot, is a Trojan horse that affects Windows, turning off anti-virus applications. It allows others to access the computer, modifies data, steals confidential information (such as user passwords and other sensitive data) and installs more malware on the victim's computer.\nMay 6: Rustock.C, a hitherto-rumored spambot-type malware with advanced rootkit capabilities, was announced to have been detected on Microsoft systems and analyzed, having been in the wild and undetected since October 2007 at the very least.\nJuly 6: Bohmini.A is a configurable remote access tool or trojan that exploits security flaws in Adobe Flash 9.0.115 with Internet Explorer 7.0 and Firefox 2.0 under Windows XP SP2.\nJuly 31: The Koobface computer worm targets users of Facebook and Myspace. New variants constantly appear.\nNovember 21: Computer worm Conficker infects anywhere from 9 to 15 million Microsoft server systems running everything from Windows 2000 to the Windows 7 Beta. The French Navy, UK Ministry of Defence (including Royal Navy warships and submarines), Sheffield Hospital network, German Bundeswehr and Norwegian Police were all affected. Microsoft sets a bounty of US$250,000 for information leading to the capture of the worm's author(s). Five main variants of the Conficker worm are known and have been dubbed Conficker A, B, C, D and E. They were discovered 21 November 2008, 29 December 2008, 20 February 2009, 4 March 2009 and 7 April 2009, respectively. On December 16, 2008, Microsoft releases KB958644 patching the server service vulnerability responsible for the spread of Conficker.\n\n\n*** 2009 ***\nJuly 4: The July 2009 cyber attacks occur and the emergence of the W32.Dozer attack the United States and South Korea.\nJuly 15: Symantec discovered Daprosy Worm, a trojan worm is intended to steal online-game passwords in internet cafes. It could intercept all keystrokes and send them to its author, making it potentially a very dangerous worm to infect B2B (business-to-business) systems.\nAugust 24: Source code for MegaPanzer is released by its author under GPLv3. and appears to have been apparently detected in the wild.\nNovember 27: The virus Kenzero is a virus that spreads online from peer-to-peer networks (P2P) taking browsing history.\n\n== 2010s ==\n\n\n*** 2010 ***\nJanuary: The Waledac botnet sent spam emails. In February 2010, an international group of security researchers and Microsoft took Waledac down.\nJanuary: The Psyb0t worm is discovered.  It is thought to be unique in that it can infect routers and high-speed modems.\nFebruary 18: Microsoft announced that a BSoD problem on some Windows machines which was triggered by a batch of Patch Tuesday updates was caused by the Alureon Trojan.\nJune 17: Stuxnet, a Windows Trojan, was detected. It is the first worm to attack SCADA systems. There are suggestions that it was designed to target Iranian nuclear facilities. It uses a valid certificate from Realtek.\nSeptember 9: The virus, called \"here you have\" or \"VBMania\", is a simple Trojan horse that arrives in the inbox with the odd-but-suggestive subject line \"here you have\". The body reads \"This is The Document I told you about, you can find it Here\" or \"This is The Free Download Sex Movies, you can find it Here\".\n\n\n*** 2011 ***\nSpyEye and Zeus merged code is seen. New variants attack mobile phone banking information.\nAnti-Spyware 2011, a Trojan horse that attacks Windows 9x, 2000, XP, Vista, and Windows 7, posing as an anti-spyware program. It disables security-related processes of anti-virus programs, while also blocking access to the Internet, which prevents updates.\nSummer 2011: The Morto worm attempts to propagate itself to additional computers via the Microsoft Windows Remote Desktop Protocol (RDP). Morto spreads by forcing infected systems to scan for Windows servers allowing RDP login. Once Morto finds an RDP-accessible system, it attempts to log into a domain or local system account named 'Administrator' using several common passwords.  A detailed overview of how the worm works \u2013 along with the password dictionary Morto uses \u2013 was done by Imperva.\nJuly 13: the ZeroAccess rootkit (also known as Sirefef or max++) was discovered.\nSeptember 1: Duqu is a worm thought to be related to the Stuxnet worm. The Laboratory of Cryptography and System Security (CrySyS Lab) of the Budapest University of Technology and Economics in Hungary discovered the threat, analysed the malware, and wrote a 60-page report naming the threat Duqu. Duqu gets its name from the prefix \"~DQ\" it gives to the names of files it creates.\n\n\n*** 2012 ***\nMay: Flame \u2013 also known as Flamer, sKyWIper, and Skywiper \u2013  a modular computer malware that attacks computers running Microsoft Windows. Used for targeted cyber espionage in Middle Eastern countries. Its discovery was announced on 28 May 2012 by MAHER Center of Iranian National Computer Emergency Response Team (CERT), Kaspersky Lab and CrySyS Lab of the Budapest University of Technology and Economics. CrySyS stated in their report that \"sKyWIper is certainly the most sophisticated malware we encountered during our practice; arguably, it is the most complex malware ever found\".\nAugust 16: Shamoon is a computer virus designed to target computers running Microsoft Windows in the energy sector. Symantec, Kaspersky Lab, and Seculert announced its discovery on August 16, 2012.\nSeptember 20: NGRBot is a worm that uses the IRC network for file transfer, sending and receiving commands between zombie network machines and the attacker's IRC server, and monitoring and controlling network connectivity and intercept. It employs a user-mode rootkit technique to hide and steal its victim's information. This family of bot is also designed to infect HTML pages with inline frames (iframes), causing redirections, blocking victims from getting updates from security/antimalware products, and killing those services. The bot is designed to connect via a predefined IRC channel and communicate with a remote botnet.\n\n\n*** 2013 ***\nSeptember: The CryptoLocker Trojan horse is discovered. CryptoLocker encrypts the files on a user's hard drive, then prompts them to pay a ransom to the developer to receive the decryption key. In the following months, several copycat ransomware Trojans were also discovered.\nDecember: The Gameover ZeuS Trojan is discovered. This type of virus steals one's login details on popular Web sites that involve monetary transactions. It works by detecting a login page, then proceeds to inject malicious code into the page, keystroke logging the computer user's details.\nDecember: Linux.Darlloz targets the Internet of things and infects routers, security cameras, set-top boxes by exploiting a PHP vulnerability.\n\n\n*** 2014 ***\nNovember: The Regin Trojan horse is discovered. Regin is a dropper, primarily spread via spoofed Web pages. Once installed, it quietly downloads additional malware, making it difficult for signature-based anti-virus programs to detect. It is believed to have been created by the United States and United Kingdom as a tool for espionage and mass surveillance.\n\n\n*** 2015 ***\nThe BASHLITE malware is leaked leading to a massive spike in DDoS attacks.\nLinux.Wifatch is revealed to the general public. It is found to attempt to secure devices from other more malicious malware.\n\n\n*** 2016 ***\nJanuary: A trojan named \"MEMZ\" is created. The creator, Leurak, explained that the trojan was intended merely as a joke. The trojan alerts the user to the fact that it is a trojan and warns them that if they proceed, the computer may no longer be usable. It contains complex payloads that corrupt the system, displaying artifacts on the screen as it runs. Once run, the application cannot be closed without causing further damage to the computer, which will stop functioning properly regardless. When the computer is restarted, in place of the bootsplash is a message that reads \"Your computer has been trashed by the MEMZ Trojan. Now enjoy the Nyan cat\u2026\", which follows with an animation of the Nyan Cat.\nFebruary: Ransomware Locky with its over 60 derivatives spread throughout Europe and infected several million computers. At the height of the spread over five thousand computers per hour were infected in Germany alone. Although ransomware was not a new thing at the time, insufficient cyber security as well as a lack of standards in IT was responsible for the high number of infections. Unfortunately, even up to date antivirus and internet security software was unable to protect systems from early versions of Locky.\nFebruary: Tiny Banker Trojan (Tinba) makes headlines. Since its discovery, it has been found to have infected more than two dozen major banking institutions in the United States, including TD Bank, Chase, HSBC, Wells Fargo, PNC and Bank of America. Tiny Banker Trojan uses HTTP injection to force the user's computer to believe that it is on the bank's website. This spoof page will look and function just as the real one. The user then enters their information to log on, at which point Tinba can launch the bank webpage's \"incorrect login information\" return, and redirect the user to the real website. This is to trick the user into thinking they had entered the wrong information and proceed as normal, although now Tinba has captured the credentials and sent them to its host.\nAugust: Journalists and researchers report the discovery of spyware, called Pegasus, developed and distributed by a private company which can and has been used to infect iOS and Android smartphones often \u2013 based on 0-day exploits \u2013 without the need for any user-interaction or significant clues to the user and then be used to exfiltrate data, track user locations, capture film through its camera, and activate the microphone at any time. The investigation suggests it was used on many targets worldwide and revealed its use for e.g. governments' espionage on journalists, opposition politicians, activists, business people and others.\nSeptember: Mirai creates headlines by launching some of the most powerful and disruptive DDoS attacks seen to date by infecting the Internet of Things. Mirai ends up being used in the DDoS attack on 20 September 2016 on the Krebs on Security site which reached 620 Gbit/s. Ars Technica also reported a 1 Tbit/s attack on French web host OVH. On 21 October 2016 multiple major DDoS attacks in DNS services of DNS service provider Dyn occurred using Mirai malware installed on a large number of IoT devices, resulting in the inaccessibility of several high-profile websites such as GitHub, Twitter, Reddit, Netflix, Airbnb and many others. The attribution of the attack to the Mirai botnet was originally reported by BackConnect Inc., a security firm.\n\n\n*** 2017 ***\nMay: The WannaCry ransomware attack spreads globally. Exploits revealed in the NSA hacking toolkit leak of late 2016 were used to enable the propagation of the malware. Shortly after the news of the infections broke online, a UK cybersecurity researcher in collaboration with others found and activated a \"kill switch\" hidden within the ransomware, effectively halting the initial wave of its global propagation. The next day, researchers announced that they had found new variants of the malware without the kill switch.\nJune: The Petya (malware) attack spreads globally affecting Windows systems. Researchers at Symantec reveal that this ransomware uses the EternalBlue exploit, similar to the one used in the WannaCry ransomware attack.\nSeptember: The Xafecopy Trojan attacks 47 countries, affecting only Android operating systems. Kaspersky Lab identified it as a malware from the Ubsod family, stealing money through click based WAP billing systems.\nSeptember: A new variety of Remote Access Trojan (RAT), Kedi RAT, is distributed in a Spear Phishing Campaign. The attack targeted Citrix users. The Trojan was able to evade usual system scanners. Kedi Trojan had all the characteristics of a common Remote Access Trojan and it could communicate to its Command and Control center via Gmail using common HTML, HTTP protocols.\n\n\n*** 2018 ***\nFebruary: Thanatos, a ransomware, becomes the first ransomware program to accept ransom payment in Bitcoin Cash.\n\n\n*** 2019 ***\nNovember: Titanium is an advanced backdoor malware, developed by the PLATINUM APT. Answer this question using the following article:\n\nWhat was the first computer virus to infect IBM PC compatible computers and when was it released?",
    "context": "",
    "output": "The Brain boot sector virus, also known as Lahore or Pakistani, was the first computer virus to infect IBM PC compatible computers. It was released in January 1986 by 19-year-old Pakistani programmer, Basit Farooq Alvi, and his brother, Amjad Farooq Alvi.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What was the first computer virus to infect IBM PC compatible computers and when was it released?",
      "answer": "The Brain boot sector virus, also known as Lahore or Pakistani, was the first computer virus to infect IBM PC compatible computers. It was released in January 1986 by 19-year-old Pakistani programmer, Basit Farooq Alvi, and his brother, Amjad Farooq Alvi.",
      "context": "Timeline of computer viruses and worms\n\n==Introduction==\nThis timeline of computer viruses and worms presents a chronological timeline of noteworthy computer viruses, computer worms, Trojan horses, similar malware, related research and events.\n\n\n\n== 1960s ==\nJohn von Neumann's article on the \"Theory of self-reproducing automata\" is published in 1966. The article is based on lectures given by von Neumann at the University of Illinois about the \"Theory and Organization of Complicated Automata\" in 1949.\n\n== 1970s ==\n\n\n*** 1970 ***\nThe first story written about a computer virus is The Scarred Man by Gregory Benford.\n\n\n*** 1971 ***\nThe Creeper system, an experimental self-replicating program, is written by Bob Thomas at BBN Technologies to test John von Neumann's theory. Creeper infected DEC PDP-10 computers running the TENEX operating system. Creeper gained access via the ARPANET and copied itself to the remote system where the message \"I'm the creeper, catch me if you can!\" was displayed. The Reaper program was later created to delete Creeper.\nAt the University of Illinois at Urbana-Champaign, a graduate student named Alan Davis (working for Prof. Donald Gillies) created a process on a PDP-11 that (a) checked to see if an identical copy of itself was currently running as an active process, and if not, created a copy of itself and started it running; (b) checked to see if any disk space (which all users shared) was available, and if so, created a file the size of that space; and (c) looped back to step (a). As a result, the process stole all available disk space. When users tried to save files, the operating system advised them that the disk was full and that they needed to delete some existing files. Of course, if they did delete a file, this process would immediately snatch up the available space. When users called in a system administrator (A. Ian Stocks) to fix the problem, he examined the active processes, discovered the offending process, and deleted it. Of course, before he left the room, the still existing process would create another copy of itself, and the problem wouldn't go away. The only way to make the computer work again was to reboot.\n\n\n*** 1972 ***\nThe science fiction novel, When HARLIE Was One, by David Gerrold, contains one of the first fictional representations of a computer virus, as well as one of the first uses of the word \"virus\" to denote a program that infects a computer.\n\n\n*** 1973 ***\nIn fiction, the 1973 Michael Crichton movie Westworld made an early mention of the concept of a computer virus, being a central plot theme that causes androids to run amok. Alan Oppenheimer's character summarizes the problem by stating that \"...there's a clear pattern here which suggests an analogy to an infectious disease process, spreading from one...area to the next.\"  To which the replies are stated: \"Perhaps there are superficial similarities to disease\" and, \"I must confess I find it difficult to believe in a disease of machinery.\" (Crichton's earlier work, the 1969 novel The Andromeda Strain and 1971 film were about an extraterrestrial biological virus-like disease that threatened the human race.)\n\n\n*** 1974 ***\nThe Rabbit (or Wabbit) virus, more a fork bomb than a virus, is written. The Rabbit virus makes multiple copies of itself on a single computer (and was named \"Rabbit\" for the speed at which it did so) until it clogs the system, reducing system performance, before finally reaching a threshold and crashing the computer.\n\n\n*** 1975 ***\nApril: ANIMAL is written by John Walker for the UNIVAC 1108. ANIMAL asked several questions of the user in an attempt to guess the type of animal the user was thinking of, while the related program PERVADE would create a copy of itself and ANIMAL in every directory to which the current user had access. It spread across the multi-user UNIVACs when users with overlapping permissions discovered the game, and to other computers when tapes were shared. The program was carefully written to avoid damaging existing file or directory structures, and to avoid copying itself if permissions did not exist or if harm would result. Its spread was halted by an OS upgrade that changed the format of the file status tables PERVADE used. Though non-malicious, \"Pervading Animal\" represents the first Trojan \"in the wild\".\nThe novel The Shockwave Rider by John Brunner is published, coining the word \"worm\" to describe a program that propagates itself through a computer network.\n\n\n*** 1977 ***\n\"The Adolescence of P-1\" novel, describes a worm program which propagates through modem-based networks, eventually developing its own strategy-developing AI, which deals with cross-hardware and cross-os issues, eventually infecting hardware manufactures and defense organizations.\n\n== 1980s ==\n\n\n*** 1982 ***\nA program called Elk Cloner, written for Apple II systems, was created by high school student Richard Skrenta, originally as a prank. The Apple II was particularly vulnerable due to the storage of its operating system on a floppy disk. Elk Cloner's design combined with public ignorance about what malware was and how to protect against it led to Elk Cloner being responsible for the first large-scale computer virus outbreak in history.\n\n\n*** 1983 ***\nNovember: The term \"virus\" is re-coined by Frederick B. Cohen in describing self-replicating computer programs. In 1984 Cohen uses the phrase \"computer virus\" (suggested by his teacher Leonard Adleman) to describe the operation of such programs in terms of \"infection\". He defines a \"virus\" as \"a program that can 'infect' other programs by modifying them to include a possibly evolved copy of itself.\" Cohen demonstrates a virus-like program on a VAX11/750 system at Lehigh University. The program could install itself in, or infect, other system objects.\n\n\n*** 1984 ***\nAugust: Ken Thompson publishes his seminal paper, Reflections on Trusting Trust, in which he describes how he modified a C compiler so that when used to compile a specific version of the Unix operating system, it inserts a backdoor into the login command, and when used to compile a new copy of itself, it inserts the backdoor insertion code, even if neither the backdoor nor the backdoor insertion code is present in the source code of this new copy.\n\n\n*** 1986 ***\nJanuary: The Brain boot sector virus is released. Brain is considered the first IBM PC compatible virus, and the program responsible for the first IBM PC compatible virus epidemic. The virus is also known as Lahore, Pakistani, Pakistani Brain, and Pakistani flu as it was created in Lahore, Pakistan by 19-year-old Pakistani programmer, Basit Farooq Alvi, and his brother, Amjad Farooq Alvi.\nDecember: Ralf Burger presented the Virdem model of programs at a meeting of the underground Chaos Computer Club in Germany. The Virdem model represented the first programs that could replicate themselves via addition of their code to executable DOS files in COM format.\n\n\n*** 1987 ***\nAppearance of the Vienna virus, which was subsequently neutralized \u2013 the first time this had happened on the IBM platform.\nAppearance of Lehigh virus (discovered at its namesake university), boot sector viruses such as Yale from the US, Stoned from New Zealand, Ping Pong from Italy, and appearance of the first self-encrypting file virus, Cascade. Lehigh was stopped on campus before it spread to the \"wild\" (to computers beyond the university), and as a result, has never been found elsewhere. A subsequent infection of Cascade in the offices of IBM Belgium led to IBM responding with its own antivirus product development. Prior to this, antivirus solutions developed at IBM were intended for staff use only.\nOctober: The Jerusalem virus, part of the (at that time unknown) Suriv family, is detected in the city of Jerusalem. The virus destroys all executable files on infected machines upon every occurrence of Friday the 13th (except Friday 13 November 1987 making its first trigger date May 13, 1988). Jerusalem caused a worldwide epidemic in 1988.\nNovember: The SCA virus, a boot sector virus for Amiga computers, appears.  It immediately creates a pandemic virus-writer storm. A short time later, SCA releases another, considerably more destructive virus, the Byte Bandit.\nDecember: Christmas Tree EXEC was the first widely disruptive replicating network program, which paralyzed several international computer networks in December 1987. It was written in Rexx on the VM/CMS operating system and originated in what was then West Germany. It re-emerged in 1990.\n\n\n*** 1988 ***\nMarch 1: The Ping-Pong virus (also called Boot, Bouncing Ball, Bouncing Dot, Italian, Italian-A or VeraCruz), an MS-DOS boot sector virus, is discovered at the University of Turin in Italy.\nJune: The CyberAIDS and Festering Hate Apple ProDOS viruses spreads from underground pirate BBS systems and starts infecting mainstream networks. Festering Hate was the last iteration of the CyberAIDS series extending back to 1985 and 1986. Unlike the few Apple viruses that had come before which were essentially annoying, but did no damage, the Festering Hate series of viruses was extremely destructive, spreading to all system files it could find on the host computer (hard drive, floppy, and system memory) and then destroying everything when it could no longer find any uninfected files.\nNovember 2: The Morris worm, created by Robert Tappan Morris, infects DEC VAX and Sun machines running BSD UNIX that are connected to the Internet, and becomes the first worm to spread extensively \"in the wild\", and one of the first well-known programs exploiting buffer overrun vulnerabilities.\nDecember: The Father Christmas worm attacks DEC VAX machines running VMS that are connected to the DECnet Internet (an international scientific research network using DECnet protocols), affecting NASA and other research centers. Its purpose was to deliver a Christmas greeting to all affected users.\n\n\n*** 1989 ***\nOctober: Ghostball, the first multipartite virus, is discovered by Fri\u00f0rik Sk\u00falason. It infects both executable .COM files and boot sectors on MS-DOS systems.\nDecember: Several thousand floppy disks containing the AIDS Trojan, the first known ransomware, are mailed to subscribers of PC Business World magazine and a WHO AIDS conference mailing list. This DOS Trojan lies dormant for 90 boot cycles, then encrypts all filenames on the system, displaying a notice asking for $189 to be sent to a post office box in Panama in order to receive a decryption program.\n\n== 1990s ==\n\n\n*** 1990 ***\nMark Washburn, working on an analysis of the Vienna and Cascade viruses with Ralf Burger, develops the first family of polymorphic viruses, the Chameleon family. Chameleon series debuted with the release of 1260.\nJune: The Form computer virus is isolated in Switzerland. It would remain in the wild for almost 20 years and reappear afterward; during the 1990s it tended to be the most common virus in the wild with 20 to more than 50 percent of reported infections.\n\n\n*** 1992 ***\nMarch: The Michelangelo virus was expected to create a digital apocalypse on March 6, with millions of computers having their information wiped, according to mass media hysteria surrounding the virus. Later assessments of the damage showed the aftermath to be minimal. John McAfee had been quoted by the media as saying that five million computers would be affected. He later said that pressed by the interviewer to come up with a number, he had estimated a range from five thousand to five million, but the media naturally went with just the higher number.\n\n\n*** 1993 ***\n\"Leandro\" or \"Leandro & Kelly\" and \"Freddy Krueger\" spread quickly due to popularity of BBS and shareware distribution.\n\n\n*** 1994 ***\nApril: OneHalf is a DOS-based polymorphic computer virus.\nSeptember: ReBoot first airs, containing another memorable fictional, sentient computer virus, Megabyte.\n\n\n*** 1995 ***\nThe first Macro virus, called \"Concept\", is created. It attacked Microsoft Word documents.\n\n\n*** 1996 ***\n\"Ply\" \u2013 DOS 16-bit based complicated polymorphic virus appeared with a built-in permutation engine.\nBoza, the first virus designed specifically for Windows 95 files arrives.\nLaroux, the first Excel macro virus appears.\nStaog, the first Linux virus attacks Linux machines\n\n\n*** 1998 ***\nJune 2: The first version of the CIH virus appears. It is the first known virus able to erase flash ROM BIOS content.\n\n\n*** 1999 ***\nJanuary 20: The Happy99 worm first appeared. It invisibly attaches itself to emails, displays fireworks to hide the changes being made, and wishes the user a happy New Year. It modifies system files related to Outlook Express and Internet Explorer (IE) on Windows 95 and Windows 98.\nMarch 26: The Melissa worm was released, targeting Microsoft Word and Outlook-based systems, and creating considerable network traffic.\nJune 6: The ExploreZip worm, which destroys Microsoft Office documents, was first detected.\nSeptember: the CTX virus is isolated\nDecember 30: The Kak worm is a JavaScript computer worm that spread itself by exploiting a bug in Outlook Express.\n\n== 2000s ==\n\n\n*** 2000 ***\nMay 5: The ILOVEYOU worm (also known as the Love Letter, VBS, or Love Bug worm), a computer worm written in VBScript and using social engineering techniques, infected millions of Windows computers worldwide within a few hours of its release.\nJune 28: The Pikachu virus is believed to be the first computer virus geared at children. It contains the character \"Pikachu\" from the Pok\u00e9mon series. The operating systems affected by this worm are Windows 95, Windows 98, and Windows ME.\n\n\n*** 2001 ***\nFebruary 11: The Anna Kournikova virus hits e-mail servers hard by sending e-mail to contacts in the Microsoft Outlook addressbook. Its creator, Jan de Wit, was sentenced to 150 hours of community service.\nMarch 13: Magistr, also called Disembowler, is discovered. It is a complex email worm for Windows systems with multiple payloads that trigger months apart from each other. It targets members of the Law profession by searching the files on a user's computer for various keywords relating to court proceedings, activating if such are found.\nMay 8: The Sadmind worm spreads by exploiting holes in both Sun Solaris and Microsoft IIS.\nJuly: The Sircam worm is released, spreading through Microsoft systems via e-mail and unprotected network shares.\nJuly 13: The Code Red worm attacking the Index Server ISAPI Extension in Microsoft Internet Information Services is released.\nAugust 4: A complete re-write of the Code Red worm, Code Red II begins aggressively spreading onto Microsoft systems, primarily in China.\nSeptember 18: The Nimda worm is discovered and spreads through a variety of means including vulnerabilities in Microsoft Windows and backdoors left by Code Red II and Sadmind worm.\nOctober 26: The Klez worm is first identified. It exploits a vulnerability in Microsoft Internet Explorer and Microsoft Outlook and Outlook Express.\n\n\n*** 2002 ***\nFebruary 11: The Simile virus is a metamorphic computer virus written in assembly.\nBeast is a Windows-based backdoor Trojan horse, more commonly known as a RAT (Remote Administration Tool). It is capable of infecting almost all versions of Windows. Written in Delphi and released first by its author Tataye in 2002, its most current version was released on October 3, 2004.\nMarch 7: Mylife is a computer worm that spread itself by sending malicious emails to all the contacts in Microsoft Outlook.\n\n\n*** 2003 ***\nJanuary 24: The SQL Slammer worm, aka Sapphire worm, Helkern and other names, attacks vulnerabilities in Microsoft SQL Server and MSDE becomes the fastest spreading worm of all time (measured by doubling time at the peak rate of growth), causing massive Internet access disruptions worldwide just fifteen minutes after infecting its first victim.\nApril 2: Graybird is a trojan horse also known as Backdoor.Graybird.\nJune 13: ProRat is a Turkish-made Microsoft Windows based backdoor trojan horse, more commonly known as a RAT (Remote Administration Tool).\nAugust 12: The Blaster worm, aka the Lovesan worm, rapidly spreads by exploiting a vulnerability in system services present on Windows computers.\nAugust 18: The Welchia (Nachi) worm is discovered. The worm tries to remove the Blaster worm and patch Windows.\nAugust 19: The Sobig worm (technically the Sobig.F worm) spreads rapidly through Microsoft systems via mail and network shares.\nSeptember 18: Swen is a computer worm written in C++.\nOctober 24: The Sober worm is first seen on Microsoft systems and maintains its presence until 2005 with many new variants. The simultaneous attacks on network weak points by the Blaster and Sobig worms cause massive damage.\nNovember 10: Agobot is a computer worm that can spread itself by exploiting vulnerabilities on Microsoft Windows. Some of the vulnerabilities are MS03-026 and MS05-039.\nNovember 20: Bolgimo is a computer worm that spread itself by exploiting a buffer overflow vulnerability at Microsoft Windows DCOM RPC Interface.\n\n\n*** 2004 ***\nJanuary 18: Bagle is a mass-mailing worm affecting all versions of Microsoft Windows. There were 2 variants of Bagle worm, Bagle.A and Bagle.B. Bagle.B was discovered on February 17, 2004.\nJanuary 26: The MyDoom worm emerges, and currently holds the record for the fastest-spreading mass mailer worm. The worm was most notable for performing a distributed denial-of-service (DDoS) attack on www.sco.com, which belonged to The SCO Group.\nFebruary 16: The Netsky worm is discovered. The worm spreads by email and by copying itself to folders on the local hard drive as well as on mapped network drives if available. Many variants of the Netsky worm appeared.\nMarch 19: The Witty worm is a record-breaking worm in many regards. It exploited holes in several Internet Security Systems (ISS) products. It was the fastest computer issue to be categorized as a worm, and it was the first internet worm to carry a destructive payload. It spread rapidly using a pre-populated list of ground-zero hosts.\nMay 1: The Sasser worm emerges by exploiting a vulnerability in the Microsoft Windows LSASS service and causes problems in networks, while removing MyDoom and Bagle variants, even interrupting business.\nJune 15: Caribe or Cabir is a computer worm that is designed to infect mobile phones that run Symbian OS. It is the first computer worm that can infect mobile phones. It spread itself through Bluetooth. More information can be found on F-Secure and Symantec.\nAugust 16: Nuclear RAT (short for Nuclear Remote Administration Tool) is a backdoor trojan that infects Windows NT family systems (Windows 2000, Windows XP, Windows 2003).\nAugust 20: Vundo, or the Vundo Trojan (also known as Virtumonde or Virtumondo and sometimes referred to as MS Juan) is a trojan known to cause popups and advertising for rogue antispyware programs, and sporadically other misbehavior including performance degradation and denial of service with some websites including Google and Facebook.\nOctober 12: Bifrost, also known as Bifrose, is a backdoor trojan which can infect Windows 95 through Vista. Bifrost uses the typical server, server builder, and client backdoor program configuration to allow a remote attack.\nDecember: Santy, the first known \"webworm\" is launched. It exploited a vulnerability in phpBB and used Google to find new targets. It infected around 40000 sites before Google filtered the search query used by the worm, preventing it from spreading.\n\n\n*** 2005 ***\nAugust 2005: Zotob is a computer worm which exploits security vulnerabilities in Microsoft operating systems like Windows 2000, including the MS05-039 plug-and-play vulnerability. This worm has been known to spread on Microsoft-ds or TCP port 445.\nOctober 2005: The copy protection rootkit deliberately and surreptitiously included on music CDs sold by Sony BMG is exposed.  The rootkit creates vulnerabilities on affected computers, making them susceptible to infection by worms and viruses.\nLate 2005: The Zlob Trojan, is a Trojan horse program that masquerades as a required video codec in the form of the Microsoft Windows ActiveX component. It was first detected in late 2005.\n\n\n*** 2006 ***\nJanuary 20: The Nyxem worm was discovered. It spread by mass-mailing. Its payload, which activates on the third of every month, starting on February 3, attempts to disable security-related and file-sharing software, and destroy files of certain types, such as Microsoft Office files.\nFebruary 16: Discovery of the first-ever malware for Mac OS X, a low-threat trojan-horse known as OSX/Leap-A or OSX/Oompa-A, is announced.\nLate March: Brontok variant N was found in late March. Brontok was a mass-email worm and the origin for the worm was from Indonesia.\nJune: Starbucks is a virus that infects StarOffice and OpenOffice.\nLate September: Stration or Warezov worm first discovered.\nDevelopment of Stuxnet is presumed to have been started between 2005 and 2006.\n\n\n*** 2007 ***\nJanuary 17: Storm Worm identified as a fast-spreading email spamming threat to Microsoft systems. It begins gathering infected computers into the Storm botnet. By around June 30, it had infected 1.7 million computers, and it had compromised between 1 and 10 million computers by September. Thought to have originated from Russia, it disguises itself as a news email containing a film about bogus news stories asking you to download the attachment which it claims is a film.\nJuly: Zeus is a trojan that targets Microsoft Windows to steal banking information by keystroke logging.\n\n\n*** 2008 ***\nFebruary 17: Mocmex is a trojan, which was found in a digital photo frame in February 2008. It was the first serious computer virus on a digital photo frame. The virus was traced back to a group in China.\nMarch 3: Torpig, also known as Sinowal and Mebroot, is a Trojan horse that affects Windows, turning off anti-virus applications. It allows others to access the computer, modifies data, steals confidential information (such as user passwords and other sensitive data) and installs more malware on the victim's computer.\nMay 6: Rustock.C, a hitherto-rumored spambot-type malware with advanced rootkit capabilities, was announced to have been detected on Microsoft systems and analyzed, having been in the wild and undetected since October 2007 at the very least.\nJuly 6: Bohmini.A is a configurable remote access tool or trojan that exploits security flaws in Adobe Flash 9.0.115 with Internet Explorer 7.0 and Firefox 2.0 under Windows XP SP2.\nJuly 31: The Koobface computer worm targets users of Facebook and Myspace. New variants constantly appear.\nNovember 21: Computer worm Conficker infects anywhere from 9 to 15 million Microsoft server systems running everything from Windows 2000 to the Windows 7 Beta. The French Navy, UK Ministry of Defence (including Royal Navy warships and submarines), Sheffield Hospital network, German Bundeswehr and Norwegian Police were all affected. Microsoft sets a bounty of US$250,000 for information leading to the capture of the worm's author(s). Five main variants of the Conficker worm are known and have been dubbed Conficker A, B, C, D and E. They were discovered 21 November 2008, 29 December 2008, 20 February 2009, 4 March 2009 and 7 April 2009, respectively. On December 16, 2008, Microsoft releases KB958644 patching the server service vulnerability responsible for the spread of Conficker.\n\n\n*** 2009 ***\nJuly 4: The July 2009 cyber attacks occur and the emergence of the W32.Dozer attack the United States and South Korea.\nJuly 15: Symantec discovered Daprosy Worm, a trojan worm is intended to steal online-game passwords in internet cafes. It could intercept all keystrokes and send them to its author, making it potentially a very dangerous worm to infect B2B (business-to-business) systems.\nAugust 24: Source code for MegaPanzer is released by its author under GPLv3. and appears to have been apparently detected in the wild.\nNovember 27: The virus Kenzero is a virus that spreads online from peer-to-peer networks (P2P) taking browsing history.\n\n== 2010s ==\n\n\n*** 2010 ***\nJanuary: The Waledac botnet sent spam emails. In February 2010, an international group of security researchers and Microsoft took Waledac down.\nJanuary: The Psyb0t worm is discovered.  It is thought to be unique in that it can infect routers and high-speed modems.\nFebruary 18: Microsoft announced that a BSoD problem on some Windows machines which was triggered by a batch of Patch Tuesday updates was caused by the Alureon Trojan.\nJune 17: Stuxnet, a Windows Trojan, was detected. It is the first worm to attack SCADA systems. There are suggestions that it was designed to target Iranian nuclear facilities. It uses a valid certificate from Realtek.\nSeptember 9: The virus, called \"here you have\" or \"VBMania\", is a simple Trojan horse that arrives in the inbox with the odd-but-suggestive subject line \"here you have\". The body reads \"This is The Document I told you about, you can find it Here\" or \"This is The Free Download Sex Movies, you can find it Here\".\n\n\n*** 2011 ***\nSpyEye and Zeus merged code is seen. New variants attack mobile phone banking information.\nAnti-Spyware 2011, a Trojan horse that attacks Windows 9x, 2000, XP, Vista, and Windows 7, posing as an anti-spyware program. It disables security-related processes of anti-virus programs, while also blocking access to the Internet, which prevents updates.\nSummer 2011: The Morto worm attempts to propagate itself to additional computers via the Microsoft Windows Remote Desktop Protocol (RDP). Morto spreads by forcing infected systems to scan for Windows servers allowing RDP login. Once Morto finds an RDP-accessible system, it attempts to log into a domain or local system account named 'Administrator' using several common passwords.  A detailed overview of how the worm works \u2013 along with the password dictionary Morto uses \u2013 was done by Imperva.\nJuly 13: the ZeroAccess rootkit (also known as Sirefef or max++) was discovered.\nSeptember 1: Duqu is a worm thought to be related to the Stuxnet worm. The Laboratory of Cryptography and System Security (CrySyS Lab) of the Budapest University of Technology and Economics in Hungary discovered the threat, analysed the malware, and wrote a 60-page report naming the threat Duqu. Duqu gets its name from the prefix \"~DQ\" it gives to the names of files it creates.\n\n\n*** 2012 ***\nMay: Flame \u2013 also known as Flamer, sKyWIper, and Skywiper \u2013  a modular computer malware that attacks computers running Microsoft Windows. Used for targeted cyber espionage in Middle Eastern countries. Its discovery was announced on 28 May 2012 by MAHER Center of Iranian National Computer Emergency Response Team (CERT), Kaspersky Lab and CrySyS Lab of the Budapest University of Technology and Economics. CrySyS stated in their report that \"sKyWIper is certainly the most sophisticated malware we encountered during our practice; arguably, it is the most complex malware ever found\".\nAugust 16: Shamoon is a computer virus designed to target computers running Microsoft Windows in the energy sector. Symantec, Kaspersky Lab, and Seculert announced its discovery on August 16, 2012.\nSeptember 20: NGRBot is a worm that uses the IRC network for file transfer, sending and receiving commands between zombie network machines and the attacker's IRC server, and monitoring and controlling network connectivity and intercept. It employs a user-mode rootkit technique to hide and steal its victim's information. This family of bot is also designed to infect HTML pages with inline frames (iframes), causing redirections, blocking victims from getting updates from security/antimalware products, and killing those services. The bot is designed to connect via a predefined IRC channel and communicate with a remote botnet.\n\n\n*** 2013 ***\nSeptember: The CryptoLocker Trojan horse is discovered. CryptoLocker encrypts the files on a user's hard drive, then prompts them to pay a ransom to the developer to receive the decryption key. In the following months, several copycat ransomware Trojans were also discovered.\nDecember: The Gameover ZeuS Trojan is discovered. This type of virus steals one's login details on popular Web sites that involve monetary transactions. It works by detecting a login page, then proceeds to inject malicious code into the page, keystroke logging the computer user's details.\nDecember: Linux.Darlloz targets the Internet of things and infects routers, security cameras, set-top boxes by exploiting a PHP vulnerability.\n\n\n*** 2014 ***\nNovember: The Regin Trojan horse is discovered. Regin is a dropper, primarily spread via spoofed Web pages. Once installed, it quietly downloads additional malware, making it difficult for signature-based anti-virus programs to detect. It is believed to have been created by the United States and United Kingdom as a tool for espionage and mass surveillance.\n\n\n*** 2015 ***\nThe BASHLITE malware is leaked leading to a massive spike in DDoS attacks.\nLinux.Wifatch is revealed to the general public. It is found to attempt to secure devices from other more malicious malware.\n\n\n*** 2016 ***\nJanuary: A trojan named \"MEMZ\" is created. The creator, Leurak, explained that the trojan was intended merely as a joke. The trojan alerts the user to the fact that it is a trojan and warns them that if they proceed, the computer may no longer be usable. It contains complex payloads that corrupt the system, displaying artifacts on the screen as it runs. Once run, the application cannot be closed without causing further damage to the computer, which will stop functioning properly regardless. When the computer is restarted, in place of the bootsplash is a message that reads \"Your computer has been trashed by the MEMZ Trojan. Now enjoy the Nyan cat\u2026\", which follows with an animation of the Nyan Cat.\nFebruary: Ransomware Locky with its over 60 derivatives spread throughout Europe and infected several million computers. At the height of the spread over five thousand computers per hour were infected in Germany alone. Although ransomware was not a new thing at the time, insufficient cyber security as well as a lack of standards in IT was responsible for the high number of infections. Unfortunately, even up to date antivirus and internet security software was unable to protect systems from early versions of Locky.\nFebruary: Tiny Banker Trojan (Tinba) makes headlines. Since its discovery, it has been found to have infected more than two dozen major banking institutions in the United States, including TD Bank, Chase, HSBC, Wells Fargo, PNC and Bank of America. Tiny Banker Trojan uses HTTP injection to force the user's computer to believe that it is on the bank's website. This spoof page will look and function just as the real one. The user then enters their information to log on, at which point Tinba can launch the bank webpage's \"incorrect login information\" return, and redirect the user to the real website. This is to trick the user into thinking they had entered the wrong information and proceed as normal, although now Tinba has captured the credentials and sent them to its host.\nAugust: Journalists and researchers report the discovery of spyware, called Pegasus, developed and distributed by a private company which can and has been used to infect iOS and Android smartphones often \u2013 based on 0-day exploits \u2013 without the need for any user-interaction or significant clues to the user and then be used to exfiltrate data, track user locations, capture film through its camera, and activate the microphone at any time. The investigation suggests it was used on many targets worldwide and revealed its use for e.g. governments' espionage on journalists, opposition politicians, activists, business people and others.\nSeptember: Mirai creates headlines by launching some of the most powerful and disruptive DDoS attacks seen to date by infecting the Internet of Things. Mirai ends up being used in the DDoS attack on 20 September 2016 on the Krebs on Security site which reached 620 Gbit/s. Ars Technica also reported a 1 Tbit/s attack on French web host OVH. On 21 October 2016 multiple major DDoS attacks in DNS services of DNS service provider Dyn occurred using Mirai malware installed on a large number of IoT devices, resulting in the inaccessibility of several high-profile websites such as GitHub, Twitter, Reddit, Netflix, Airbnb and many others. The attribution of the attack to the Mirai botnet was originally reported by BackConnect Inc., a security firm.\n\n\n*** 2017 ***\nMay: The WannaCry ransomware attack spreads globally. Exploits revealed in the NSA hacking toolkit leak of late 2016 were used to enable the propagation of the malware. Shortly after the news of the infections broke online, a UK cybersecurity researcher in collaboration with others found and activated a \"kill switch\" hidden within the ransomware, effectively halting the initial wave of its global propagation. The next day, researchers announced that they had found new variants of the malware without the kill switch.\nJune: The Petya (malware) attack spreads globally affecting Windows systems. Researchers at Symantec reveal that this ransomware uses the EternalBlue exploit, similar to the one used in the WannaCry ransomware attack.\nSeptember: The Xafecopy Trojan attacks 47 countries, affecting only Android operating systems. Kaspersky Lab identified it as a malware from the Ubsod family, stealing money through click based WAP billing systems.\nSeptember: A new variety of Remote Access Trojan (RAT), Kedi RAT, is distributed in a Spear Phishing Campaign. The attack targeted Citrix users. The Trojan was able to evade usual system scanners. Kedi Trojan had all the characteristics of a common Remote Access Trojan and it could communicate to its Command and Control center via Gmail using common HTML, HTTP protocols.\n\n\n*** 2018 ***\nFebruary: Thanatos, a ransomware, becomes the first ransomware program to accept ransom payment in Bitcoin Cash.\n\n\n*** 2019 ***\nNovember: Titanium is an advanced backdoor malware, developed by the PLATINUM APT."
    }
  },
  {
    "instruction": "The US Army denoted the adapter as the ASAM 5 and the US Navy referred to the entire ECM machine with CCM adapter as the CSP 1700.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What were the US Army and US Navy's denotations for the adapter used to convert the ECM into the CCM?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What were the US Army and US Navy's denotations for the adapter used to convert the ECM into the CCM?",
      "answer": "The US Army denoted the adapter as the ASAM 5 and the US Navy referred to the entire ECM machine with CCM adapter as the CSP 1700."
    }
  },
  {
    "instruction": "Pierre Omidyar, the founder of eBay, requested leniency for the PayPal 14.\n\nWrite a question about the text above.",
    "context": "",
    "output": "Who was the founder of eBay that requested leniency for the PayPal 14?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "Who was the founder of eBay that requested leniency for the PayPal 14?",
      "answer": "Pierre Omidyar, the founder of eBay, requested leniency for the PayPal 14."
    }
  },
  {
    "instruction": "Martin Hellman received the RSA Conference's lifetime achievement award in the field of information security in 2012.\n\nWrite a question about the text above.",
    "context": "",
    "output": "When did Martin Hellman receive the RSA Conference's lifetime achievement award in the field of information security?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "When did Martin Hellman receive the RSA Conference's lifetime achievement award in the field of information security?",
      "answer": "Martin Hellman received the RSA Conference's lifetime achievement award in the field of information security in 2012."
    }
  },
  {
    "instruction": "The TAG\\_END (0x01) indicates the end of all of the tagged fields. It does not have a tag length nor any associated data.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the role of the TAG\\_END in a TZSP packet?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the role of the TAG\\_END in a TZSP packet?",
      "answer": "The TAG\\_END (0x01) indicates the end of all of the tagged fields. It does not have a tag length nor any associated data."
    }
  },
  {
    "instruction": "The Digital Signature Standard (DSS) has gone through four revisions since its initial specification in 1994. FIPS 186-1, released in 1996, approved the Digital Signature Algorithm (DSA) and RSA signatures based on PKCS #1 version 2.1 and X9.31. FIPS 186-2, released in 2000, added support for elliptic curve cryptography through the Elliptic Curve Digital Signature Algorithm (ECDSA) based on X9.62. FIPS 186-3, released in 2009, recommended additional elliptic curves for use with ECDSA. FIPS 186-4, released in 2013, further updated the recommended elliptic curves for ECDSA.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What are the different versions of the Digital Signature Standard (DSS) and how do they differ in terms of the approved algorithms?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What are the different versions of the Digital Signature Standard (DSS) and how do they differ in terms of the approved algorithms?",
      "answer": "The Digital Signature Standard (DSS) has gone through four revisions since its initial specification in 1994. FIPS 186-1, released in 1996, approved the Digital Signature Algorithm (DSA) and RSA signatures based on PKCS #1 version 2.1 and X9.31. FIPS 186-2, released in 2000, added support for elliptic curve cryptography through the Elliptic Curve Digital Signature Algorithm (ECDSA) based on X9.62. FIPS 186-3, released in 2009, recommended additional elliptic curves for use with ECDSA. FIPS 186-4, released in 2013, further updated the recommended elliptic curves for ECDSA."
    }
  },
  {
    "instruction": "Context: Broker injection\n\n==Introduction==\nBroker injection attack is a type of vulnerability that exploits misconfigured brokers, potentially allowing an attacker to read, write and inject information from/into their flow.\n\n\n\n== Description ==\nThere are many scenarios in which a broker is used to transport the information between tasks.\nOne of the most typical use cases is send e-mails in background. In this scenario we'll have two actors:\n\nAn information producer (a website, for example).\nA worker or background process who actually sends the e-mail.The producer needs an asynchronous and non-blocking way to send the email information to the worker.\nThis system is usually a broker. It takes the information from the web front-end and passes it to the worker, generating a new task in the worker. So, the worker has all the information to send the e-mail.\nTaking the above scenario as an example, if we could access the broker, we would be able to make the worker generate new tasks with arbitrary data, unleashing a broker injection.\n\n== Attacks ==\nWith this in mind, we could make the following attacks:\n\nListing remote tasks.\nReading a remote task's contents.\nInjection of tasks into remote processes.\nRemoving remote outstanding tasks.\n\n== Origin ==\nThe broker injection attack is not new, but it didn't have a name. This name was coined by Daniel Garc\u00eda (cr0hn) at the RootedCON 2016 conference in Spain.\nQuestion: How can a misconfigured broker lead to a vulnerability?\n\nAnswer:",
    "context": "",
    "output": "A misconfigured broker can lead to a vulnerability by allowing unauthorized access to the broker, which can result in data leaks, data manipulation, or service disruption.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How can a misconfigured broker lead to a vulnerability?",
      "answer": "A misconfigured broker can lead to a vulnerability by allowing unauthorized access to the broker, which can result in data leaks, data manipulation, or service disruption.",
      "context": "Broker injection\n\n==Introduction==\nBroker injection attack is a type of vulnerability that exploits misconfigured brokers, potentially allowing an attacker to read, write and inject information from/into their flow.\n\n\n\n== Description ==\nThere are many scenarios in which a broker is used to transport the information between tasks.\nOne of the most typical use cases is send e-mails in background. In this scenario we'll have two actors:\n\nAn information producer (a website, for example).\nA worker or background process who actually sends the e-mail.The producer needs an asynchronous and non-blocking way to send the email information to the worker.\nThis system is usually a broker. It takes the information from the web front-end and passes it to the worker, generating a new task in the worker. So, the worker has all the information to send the e-mail.\nTaking the above scenario as an example, if we could access the broker, we would be able to make the worker generate new tasks with arbitrary data, unleashing a broker injection.\n\n== Attacks ==\nWith this in mind, we could make the following attacks:\n\nListing remote tasks.\nReading a remote task's contents.\nInjection of tasks into remote processes.\nRemoving remote outstanding tasks.\n\n== Origin ==\nThe broker injection attack is not new, but it didn't have a name. This name was coined by Daniel Garc\u00eda (cr0hn) at the RootedCON 2016 conference in Spain."
    }
  },
  {
    "instruction": "DarkSide is believed to be based in Eastern Europe, likely Russia, and avoids targets in certain geographic locations by checking their system language settings. The exclusion list includes the languages of the 12 current, former, or founding CIS countries, as well as Syrian Arabic.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the geographical location of the suspected origin of DarkSide, and how do they avoid targeting certain regions?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the geographical location of the suspected origin of DarkSide, and how do they avoid targeting certain regions?",
      "answer": "DarkSide is believed to be based in Eastern Europe, likely Russia, and avoids targets in certain geographic locations by checking their system language settings. The exclusion list includes the languages of the 12 current, former, or founding CIS countries, as well as Syrian Arabic."
    }
  },
  {
    "instruction": "Context: Comparison of VoIP software\n\n==Introduction==\nThis is a comparison of voice over IP (VoIP) software used to conduct telephone-like voice conversations across Internet Protocol (IP) based networks. For residential markets, voice over IP phone service is often cheaper than traditional public switched telephone network (PSTN) service and can remove geographic restrictions to telephone numbers, e.g., have a PSTN phone number in a New York area code ring in Tokyo.\nFor businesses, VoIP obviates separate voice and data pipelines, channelling both types of traffic through the IP network while giving the telephony user a range of advanced abilities.\nSoftphones are client devices for making and receiving voice and video calls over the IP network with the standard functions of most original telephones and usually allow integration with VoIP phones and USB phones instead of using a computer's microphone and speakers (or headset). Most softphone clients run on the open Session Initiation Protocol (SIP) supporting various codecs. Skype runs on a closed proprietary networking protocol but additional business telephone system (PBX) software can allow a SIP based telephone system to connect to the Skype network. Online chat programs now also incorporate voice and video communications.\nOther VoIP software applications include conferencing servers, intercom systems, virtual foreign exchange services (FXOs) and adapted telephony software which concurrently support VoIP and public switched telephone network (PSTN) like Interactive Voice Response (IVR) systems, dial in dictation, on hold and call recording servers.\nSome entries below are Web-based VoIP; most are standalone Desktop applications.\n\n\n\n== Desktop applications ==\n\n\n*** Discontinued softphone service ***\n\n== Mobile phones ==\nFor mobile VoIP clients:\n\n== Frameworks and libraries ==\n\n== Server software ==\n\n== Secure VoIP software ==\n\n\n*** VoIP software with client-to-client encryption ***\nThe following table is an overview of those VoIP clients which (can) provide end-to-end encryption.\n\n\n*** VoIP software with client-to-server encryption ***\nThe following table is an overview of those VoIP clients which (normally) provide client-to-server encryption.\n\nNotes\nQuestion: What are some examples of other VoIP software applications, besides softphones?. Whats the answer?",
    "context": "",
    "output": "Other VoIP software applications include conferencing servers, intercom systems, virtual foreign exchange services (FXOs), and adapted telephony software which concurrently support VoIP and public switched telephone network (PSTN) like Interactive Voice Response (IVR) systems, dial in dictation, on hold and call recording servers.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What are some examples of other VoIP software applications, besides softphones?",
      "answer": "Other VoIP software applications include conferencing servers, intercom systems, virtual foreign exchange services (FXOs), and adapted telephony software which concurrently support VoIP and public switched telephone network (PSTN) like Interactive Voice Response (IVR) systems, dial in dictation, on hold and call recording servers.",
      "context": "Comparison of VoIP software\n\n==Introduction==\nThis is a comparison of voice over IP (VoIP) software used to conduct telephone-like voice conversations across Internet Protocol (IP) based networks. For residential markets, voice over IP phone service is often cheaper than traditional public switched telephone network (PSTN) service and can remove geographic restrictions to telephone numbers, e.g., have a PSTN phone number in a New York area code ring in Tokyo.\nFor businesses, VoIP obviates separate voice and data pipelines, channelling both types of traffic through the IP network while giving the telephony user a range of advanced abilities.\nSoftphones are client devices for making and receiving voice and video calls over the IP network with the standard functions of most original telephones and usually allow integration with VoIP phones and USB phones instead of using a computer's microphone and speakers (or headset). Most softphone clients run on the open Session Initiation Protocol (SIP) supporting various codecs. Skype runs on a closed proprietary networking protocol but additional business telephone system (PBX) software can allow a SIP based telephone system to connect to the Skype network. Online chat programs now also incorporate voice and video communications.\nOther VoIP software applications include conferencing servers, intercom systems, virtual foreign exchange services (FXOs) and adapted telephony software which concurrently support VoIP and public switched telephone network (PSTN) like Interactive Voice Response (IVR) systems, dial in dictation, on hold and call recording servers.\nSome entries below are Web-based VoIP; most are standalone Desktop applications.\n\n\n\n== Desktop applications ==\n\n\n*** Discontinued softphone service ***\n\n== Mobile phones ==\nFor mobile VoIP clients:\n\n== Frameworks and libraries ==\n\n== Server software ==\n\n== Secure VoIP software ==\n\n\n*** VoIP software with client-to-client encryption ***\nThe following table is an overview of those VoIP clients which (can) provide end-to-end encryption.\n\n\n*** VoIP software with client-to-server encryption ***\nThe following table is an overview of those VoIP clients which (normally) provide client-to-server encryption.\n\nNotes"
    }
  },
  {
    "instruction": "The F9 microkernel is a BSD-licensed L4 implementation dedicated to ARM Cortex-M processors for deeply embedded devices with memory protection. By providing a small trusted computing base and focusing on ARM Cortex-M processors, F9 illustrates the potential for L4 microkernels to be used in resource-constrained environments where memory protection is a critical concern.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does the F9 microkernel contribute to the development of deeply embedded devices with memory protection?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does the F9 microkernel contribute to the development of deeply embedded devices with memory protection?",
      "answer": "The F9 microkernel is a BSD-licensed L4 implementation dedicated to ARM Cortex-M processors for deeply embedded devices with memory protection. By providing a small trusted computing base and focusing on ARM Cortex-M processors, F9 illustrates the potential for L4 microkernels to be used in resource-constrained environments where memory protection is a critical concern."
    }
  },
  {
    "instruction": "TweetNaCl is an alternative implementation of NaCl that is a tiny C library, which fits in just 100 tweets (140 symbols each), but supports all NaCl functions.\n\nWrite a question about the text above.",
    "context": "",
    "output": "Which alternative implementation of NaCl is a tiny C library, which fits in just 100 tweets (140 symbols each), but supports all NaCl functions?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "Which alternative implementation of NaCl is a tiny C library, which fits in just 100 tweets (140 symbols each), but supports all NaCl functions?",
      "answer": "TweetNaCl is an alternative implementation of NaCl that is a tiny C library, which fits in just 100 tweets (140 symbols each), but supports all NaCl functions."
    }
  },
  {
    "instruction": "IBM hosts many of its own public cloud services, including IBM Cloud Hyper Protect Services, using IBM SSC technologies.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does IBM use SSCs in its own public cloud services?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does IBM use SSCs in its own public cloud services?",
      "answer": "IBM hosts many of its own public cloud services, including IBM Cloud Hyper Protect Services, using IBM SSC technologies."
    }
  },
  {
    "instruction": "Wizard Spider has simultaneously transferred Bitcoin from Ryuk and Conti ransomware attacks into their own wallets, implying they carry out several attacks using different malware.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does Wizard Spider transfer Bitcoin from Ryuk and Conti ransomware attacks, and what does this imply?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does Wizard Spider transfer Bitcoin from Ryuk and Conti ransomware attacks, and what does this imply?",
      "answer": "Wizard Spider has simultaneously transferred Bitcoin from Ryuk and Conti ransomware attacks into their own wallets, implying they carry out several attacks using different malware."
    }
  },
  {
    "instruction": "The fact that Stuxnet uses four zero-day exploits, plus the CPLINK vulnerability and a vulnerability used by the Conficker worm, is significant because it suggests that the creators of the malware had advanced knowledge of software vulnerabilities and were able to use multiple zero-day exploits to achieve their objectives, making the malware more effective and difficult to detect and defend against.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the significance of the fact that Stuxnet uses four zero-day exploits, plus the CPLINK vulnerability and a vulnerability used by the Conficker worm?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the significance of the fact that Stuxnet uses four zero-day exploits, plus the CPLINK vulnerability and a vulnerability used by the Conficker worm?",
      "answer": "The fact that Stuxnet uses four zero-day exploits, plus the CPLINK vulnerability and a vulnerability used by the Conficker worm, is significant because it suggests that the creators of the malware had advanced knowledge of software vulnerabilities and were able to use multiple zero-day exploits to achieve their objectives, making the malware more effective and difficult to detect and defend against."
    }
  },
  {
    "instruction": "Attackers can exploit the end host without alerting the IDS by obfuscating or encoding the attack payload in a way that the target computer will reverse but the IDS will not. An IDS must be aware of all possible encodings that its end hosts accept to match network traffic to known-malicious signatures.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How can an IDS be evaded by obfuscating or encoding the attack payload in a way that the target computer will reverse but the IDS will not?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How can an IDS be evaded by obfuscating or encoding the attack payload in a way that the target computer will reverse but the IDS will not?",
      "answer": "Attackers can exploit the end host without alerting the IDS by obfuscating or encoding the attack payload in a way that the target computer will reverse but the IDS will not. An IDS must be aware of all possible encodings that its end hosts accept to match network traffic to known-malicious signatures."
    }
  },
  {
    "instruction": "Context: Canvas fingerprinting\n\n==Introduction==\nCanvas fingerprinting is one of a number of browser fingerprinting techniques for tracking online users that allow websites to identify and track visitors using the HTML5 canvas element instead of browser cookies or other similar means. The technique received wide media coverage in 2014 after researchers from Princeton University and KU Leuven University described it in their paper The Web never forgets.\n\n\n\n== Description ==\nCanvas fingerprinting works by exploiting the HTML5 canvas element. As described by Acar et al. in: When a user visits a page, the fingerprinting script first draws text with the font and size of its choice and adds background colors (1).  Next, the script calls Canvas API\u2019s ToDataURL method to get the canvas pixel data in dataURL format (2), which is basically a Base64 encoded representation of the binary pixel data.  Finally, the script takes the hash of the text-encoded pixel data (3), which serves as the fingerprint ...\nVariations in which the graphics processing unit (GPU), or the graphics driver, is installed may cause the fingerprint variation. The fingerprint can be stored and shared with advertising partners to identify users when they visit affiliated websites. A profile can be created from the user's browsing activity, allowing advertisers to target advertise to the user's inferred demographics and preferences.By January 2022, the concept was extended to fingerprinting performance characteristics of the graphics hardware, called DrawnApart by the researchers.\n\n\n*** Uniqueness ***\nSince the fingerprint is primarily based on the browser, operating system, and installed graphics hardware, it does not uniquely identify users. In a small-scale study with 294 participants from Amazon's Mechanical Turk, an experimental entropy of 5.7 bits was observed. The authors of the study suggest more entropy could likely be observed in the wild and with more patterns used in the fingerprint. While not sufficient to identify individual users by itself, this fingerprint could be combined with other entropy sources to provide a unique identifier. It is claimed that because the technique is effectively fingerprinting the GPU, the entropy is \"orthogonal\" to the entropy of previous browser fingerprint techniques such as screen resolution and browser JavaScript capabilities.Much more unique identification becomes possible with DrawnApart, published in 2022, which was shown to boost tracking duration of individual fingerprints by 67% when used to enhance other methods.\n\n== Mitigation ==\nTor Project reference documentation states, \"After plugins and plugin-provided information, we believe that the HTML5 Canvas is the single largest fingerprinting threat browsers face today.\" Tor Browser notifies the user of canvas read attempts and provides the option to return blank image data to prevent fingerprinting. However, Tor Browser is currently unable to distinguish between legitimate uses of the canvas element and fingerprinting efforts, so its warning cannot be taken as proof of a website's intent to identify and track its visitors. Browser add-ons like Privacy Badger, DoNotTrackMe, or Adblock Plus manually enhanced with EasyPrivacy list are able to block third-party ad network trackers and can be configured to block canvas fingerprinting, provided that the tracker is served by a third party server (as opposed to being implemented by the visited website itself). Canvas Defender, a browser add-on, spoofs Canvas fingerprints.The LibreWolf browser project includes technology to block access to the HTML5 canvas by default, only allowing it in specific instances green-lit by the user.\nQuestion: How does the DrawnApart technique extend the concept of canvas fingerprinting?\n\nAnswer:",
    "context": "",
    "output": "The DrawnApart technique extends the concept of canvas fingerprinting by fingerprinting performance characteristics of the graphics hardware, allowing for much more unique identification and boosting tracking duration of individual fingerprints.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does the DrawnApart technique extend the concept of canvas fingerprinting?",
      "answer": "The DrawnApart technique extends the concept of canvas fingerprinting by fingerprinting performance characteristics of the graphics hardware, allowing for much more unique identification and boosting tracking duration of individual fingerprints.",
      "context": "Canvas fingerprinting\n\n==Introduction==\nCanvas fingerprinting is one of a number of browser fingerprinting techniques for tracking online users that allow websites to identify and track visitors using the HTML5 canvas element instead of browser cookies or other similar means. The technique received wide media coverage in 2014 after researchers from Princeton University and KU Leuven University described it in their paper The Web never forgets.\n\n\n\n== Description ==\nCanvas fingerprinting works by exploiting the HTML5 canvas element. As described by Acar et al. in: When a user visits a page, the fingerprinting script first draws text with the font and size of its choice and adds background colors (1).  Next, the script calls Canvas API\u2019s ToDataURL method to get the canvas pixel data in dataURL format (2), which is basically a Base64 encoded representation of the binary pixel data.  Finally, the script takes the hash of the text-encoded pixel data (3), which serves as the fingerprint ...\nVariations in which the graphics processing unit (GPU), or the graphics driver, is installed may cause the fingerprint variation. The fingerprint can be stored and shared with advertising partners to identify users when they visit affiliated websites. A profile can be created from the user's browsing activity, allowing advertisers to target advertise to the user's inferred demographics and preferences.By January 2022, the concept was extended to fingerprinting performance characteristics of the graphics hardware, called DrawnApart by the researchers.\n\n\n*** Uniqueness ***\nSince the fingerprint is primarily based on the browser, operating system, and installed graphics hardware, it does not uniquely identify users. In a small-scale study with 294 participants from Amazon's Mechanical Turk, an experimental entropy of 5.7 bits was observed. The authors of the study suggest more entropy could likely be observed in the wild and with more patterns used in the fingerprint. While not sufficient to identify individual users by itself, this fingerprint could be combined with other entropy sources to provide a unique identifier. It is claimed that because the technique is effectively fingerprinting the GPU, the entropy is \"orthogonal\" to the entropy of previous browser fingerprint techniques such as screen resolution and browser JavaScript capabilities.Much more unique identification becomes possible with DrawnApart, published in 2022, which was shown to boost tracking duration of individual fingerprints by 67% when used to enhance other methods.\n\n== Mitigation ==\nTor Project reference documentation states, \"After plugins and plugin-provided information, we believe that the HTML5 Canvas is the single largest fingerprinting threat browsers face today.\" Tor Browser notifies the user of canvas read attempts and provides the option to return blank image data to prevent fingerprinting. However, Tor Browser is currently unable to distinguish between legitimate uses of the canvas element and fingerprinting efforts, so its warning cannot be taken as proof of a website's intent to identify and track its visitors. Browser add-ons like Privacy Badger, DoNotTrackMe, or Adblock Plus manually enhanced with EasyPrivacy list are able to block third-party ad network trackers and can be configured to block canvas fingerprinting, provided that the tracker is served by a third party server (as opposed to being implemented by the visited website itself). Canvas Defender, a browser add-on, spoofs Canvas fingerprints.The LibreWolf browser project includes technology to block access to the HTML5 canvas by default, only allowing it in specific instances green-lit by the user."
    }
  },
  {
    "instruction": "Cybersex trafficking affects different regions of the world in various ways. In Australia and Oceania, the Australian Federal Police investigates the crime domestically and in the Asia-Pacific region. In Europe, the European Union Agency for Law Enforcement Cooperation (Europol) investigates and spreads awareness about the crime. In Southeast Asia, the Philippines is identified as the global center of cybersex trafficking, with the United Nations Children's Fund (UNICEF) fighting the crime in the country.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does the crime of cybersex trafficking affect different regions of the world?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does the crime of cybersex trafficking affect different regions of the world?",
      "answer": "Cybersex trafficking affects different regions of the world in various ways. In Australia and Oceania, the Australian Federal Police investigates the crime domestically and in the Asia-Pacific region. In Europe, the European Union Agency for Law Enforcement Cooperation (Europol) investigates and spreads awareness about the crime. In Southeast Asia, the Philippines is identified as the global center of cybersex trafficking, with the United Nations Children's Fund (UNICEF) fighting the crime in the country."
    }
  },
  {
    "instruction": "Phorm's Webwise service affected website publishers by inviting them to upload a web widget which would provide a small frame to display recommended web links based on the tracked interests of any Phorm-tracked website visitors.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How did Phorm's Webwise service affect website publishers?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How did Phorm's Webwise service affect website publishers?",
      "answer": "Phorm's Webwise service affected website publishers by inviting them to upload a web widget which would provide a small frame to display recommended web links based on the tracked interests of any Phorm-tracked website visitors."
    }
  },
  {
    "instruction": "Context: ZeroNet\n\n==Introduction==\nZeroNet is a decentralized web-like network of peer-to-peer users, created by Tamas Kocsis in 2015, programming for the network was based in Budapest, Hungary; is built in Python; and is fully open source. Instead of having an IP address, sites are identified by a public key (specifically a bitcoin address). The private key allows the owner of a site to sign and publish changes, which propagate through the network. Sites can be accessed through an ordinary web browser when using the ZeroNet application, which acts as a local webhost for such pages. In addition to using bitcoin cryptography, ZeroNet uses trackers from the BitTorrent network to negotiate connections between peers. ZeroNet is not anonymous by default, but it supports routing traffic through the Tor network.The ZeroNet website and bittorrent tracker are blocked in mainland China. Despite the censorship, however, it is still possible to access ZeroNet from behind the Great Firewall of China, even over Tor, by bootstrapping over Meek, and connecting to peers directly.\nThere is no way to take down a ZeroNet page which still has seeders, thus making such pages immune to third-party methods of taking them down, including DMCA takedown notices.\n\n== Hiatus and forks ==\nDevelopment has stopped for several months after stable release of v0.7.1 on Github. The zeronet-conservancy fork maintains existing codebase and adds features aimed at gradually migrating to a new p2p network designed from scratch\n\n== Development of the network ==\nThe feasibility of peer-to-peer online web-sites had been hypothesised for some time, with The Pirate Bay suggesting they would build a network, as well as BitTorrent Inc. which created the closed-source Project Maelstrom.Sites on ZeroNet are known as \"zites\" by its users.\nZeroNet supports HTML, CSS and JavaScript.\nServer-side languages like PHP are not supported, although ZeroNet creates and gives API to interact with SQLite databases, their data also distributed (as JSON files) via P2P.\nBy default, sites have a size limit of 10 megabytes, but users may grant a site permission to use more storage space if they wish.\nWith plugins and the ZeroFrame API, sites can communicate with ZeroNet calling Python by JavaScript.\nQuestion: How can one access ZeroNet from behind the Great Firewall of China?\n\nAnswer:",
    "context": "",
    "output": "It is still possible to access ZeroNet from behind the Great Firewall of China by bootstrapping over Meek, and connecting to peers directly.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How can one access ZeroNet from behind the Great Firewall of China?",
      "answer": "It is still possible to access ZeroNet from behind the Great Firewall of China by bootstrapping over Meek, and connecting to peers directly.",
      "context": "ZeroNet\n\n==Introduction==\nZeroNet is a decentralized web-like network of peer-to-peer users, created by Tamas Kocsis in 2015, programming for the network was based in Budapest, Hungary; is built in Python; and is fully open source. Instead of having an IP address, sites are identified by a public key (specifically a bitcoin address). The private key allows the owner of a site to sign and publish changes, which propagate through the network. Sites can be accessed through an ordinary web browser when using the ZeroNet application, which acts as a local webhost for such pages. In addition to using bitcoin cryptography, ZeroNet uses trackers from the BitTorrent network to negotiate connections between peers. ZeroNet is not anonymous by default, but it supports routing traffic through the Tor network.The ZeroNet website and bittorrent tracker are blocked in mainland China. Despite the censorship, however, it is still possible to access ZeroNet from behind the Great Firewall of China, even over Tor, by bootstrapping over Meek, and connecting to peers directly.\nThere is no way to take down a ZeroNet page which still has seeders, thus making such pages immune to third-party methods of taking them down, including DMCA takedown notices.\n\n== Hiatus and forks ==\nDevelopment has stopped for several months after stable release of v0.7.1 on Github. The zeronet-conservancy fork maintains existing codebase and adds features aimed at gradually migrating to a new p2p network designed from scratch\n\n== Development of the network ==\nThe feasibility of peer-to-peer online web-sites had been hypothesised for some time, with The Pirate Bay suggesting they would build a network, as well as BitTorrent Inc. which created the closed-source Project Maelstrom.Sites on ZeroNet are known as \"zites\" by its users.\nZeroNet supports HTML, CSS and JavaScript.\nServer-side languages like PHP are not supported, although ZeroNet creates and gives API to interact with SQLite databases, their data also distributed (as JSON files) via P2P.\nBy default, sites have a size limit of 10 megabytes, but users may grant a site permission to use more storage space if they wish.\nWith plugins and the ZeroFrame API, sites can communicate with ZeroNet calling Python by JavaScript."
    }
  },
  {
    "instruction": "Context: NSA Suite A Cryptography\n\n==Introduction==\nNSA Suite A Cryptography is NSA cryptography which \"contains classified algorithms that will not be released.\" \"Suite A will be used for the protection of some categories of especially sensitive information (a small percentage of the overall national security-related information assurance market).\"\nIncomplete list of Suite A algorithms:\nACCORDION\nBATON\nCDL 1\nCDL 2\nFFC\nFIREFLY\nJOSEKI\nKEESEE\nMAYFLY\nMEDLEY\nMERCATOR\nSAVILLE\nSHILLELAGH\nWALBURN\nWEASEL\n\n\nQuestion: What are some of the implications of using classified algorithms in cryptography, such as those found in NSA Suite A?\n\nAnswer:",
    "context": "",
    "output": "The use of classified algorithms in cryptography, such as those found in NSA Suite A, has several implications. Firstly, it creates a barrier to entry for organizations and individuals who are not authorized to use the algorithms, as they are not publicly available. This can limit the interoperability and compatibility of systems and applications that rely on these algorithms. Secondly, the secrecy surrounding classified algorithms can undermine trust in the security of the systems and applications that use them. Finally, the use of classified algorithms can also raise concerns about the potential for government surveillance and the infringement of privacy rights.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What are some of the implications of using classified algorithms in cryptography, such as those found in NSA Suite A?",
      "answer": "The use of classified algorithms in cryptography, such as those found in NSA Suite A, has several implications. Firstly, it creates a barrier to entry for organizations and individuals who are not authorized to use the algorithms, as they are not publicly available. This can limit the interoperability and compatibility of systems and applications that rely on these algorithms. Secondly, the secrecy surrounding classified algorithms can undermine trust in the security of the systems and applications that use them. Finally, the use of classified algorithms can also raise concerns about the potential for government surveillance and the infringement of privacy rights.",
      "context": "NSA Suite A Cryptography\n\n==Introduction==\nNSA Suite A Cryptography is NSA cryptography which \"contains classified algorithms that will not be released.\" \"Suite A will be used for the protection of some categories of especially sensitive information (a small percentage of the overall national security-related information assurance market).\"\nIncomplete list of Suite A algorithms:\nACCORDION\nBATON\nCDL 1\nCDL 2\nFFC\nFIREFLY\nJOSEKI\nKEESEE\nMAYFLY\nMEDLEY\nMERCATOR\nSAVILLE\nSHILLELAGH\nWALBURN\nWEASEL\n\n"
    }
  },
  {
    "instruction": "The National Privacy Commission (NPC) ensures that the personal data of individuals in the Philippines is protected in accordance with internationally recognized norms and standards by monitoring and ensuring compliance of the country with international standards set for data protection. The NPC works to align the Philippines' data protection policies and practices with internationally recognized best practices and standards. This helps to ensure that the personal data of individuals in the Philippines is protected in accordance with internationally recognized norms and standards.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does the National Privacy Commission ensure that the personal data of individuals in the Philippines is protected in accordance with internationally recognized norms and standards?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does the National Privacy Commission ensure that the personal data of individuals in the Philippines is protected in accordance with internationally recognized norms and standards?",
      "answer": "The National Privacy Commission (NPC) ensures that the personal data of individuals in the Philippines is protected in accordance with internationally recognized norms and standards by monitoring and ensuring compliance of the country with international standards set for data protection. The NPC works to align the Philippines' data protection policies and practices with internationally recognized best practices and standards. This helps to ensure that the personal data of individuals in the Philippines is protected in accordance with internationally recognized norms and standards."
    }
  },
  {
    "instruction": "The fact that VBA32 Antivirus is used as one of the antivirus engines at VirusTotal indicates that it is a reputable and effective antivirus software.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the significance of VBA32 Antivirus being used as one of the antivirus engines at VirusTotal?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the significance of VBA32 Antivirus being used as one of the antivirus engines at VirusTotal?",
      "answer": "The fact that VBA32 Antivirus is used as one of the antivirus engines at VirusTotal indicates that it is a reputable and effective antivirus software."
    }
  },
  {
    "instruction": "Passwordless authentication improves the user experience by eliminating the need for users to remember complicated passwords and comply with different security policies. Additionally, users do not have to periodically renew their passwords.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does passwordless authentication improve user experience?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does passwordless authentication improve user experience?",
      "answer": "Passwordless authentication improves the user experience by eliminating the need for users to remember complicated passwords and comply with different security policies. Additionally, users do not have to periodically renew their passwords."
    }
  },
  {
    "instruction": "The DDoS attacks on Burmese opposition media sites were around the anniversary of the Saffron Revolution in 2009 and 2010.\n\nWrite a question about the text above.",
    "context": "",
    "output": "When were the DDoS attacks on Burmese opposition media sites around the anniversary of the Saffron Revolution?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "When were the DDoS attacks on Burmese opposition media sites around the anniversary of the Saffron Revolution?",
      "answer": "The DDoS attacks on Burmese opposition media sites were around the anniversary of the Saffron Revolution in 2009 and 2010."
    }
  },
  {
    "instruction": "Context: Ecash\n\n==Introduction==\nEcash was conceived by David Chaum as an anonymous cryptographic electronic money or electronic cash system in 1982. It was realized through his corporation Digicash and used as micropayment system at one US bank from 1995 to 1998.\n\n\n\n== Design ==\nChaum published the idea of anonymous electronic money in a 1983 paper; eCash software on the user's local computer stored money in a digital format, cryptographically signed by a bank. The user could spend the digital money at any shop accepting eCash, without having to open an account with the vendor first, or transmitting credit card numbers. Security was ensured by public key digital signature schemes.  The RSA blind signatures achieved unlinkability between withdrawal and spend transactions. Depending on the payment transactions, one distinguishes between on-line and off-line electronic cash: If the payee has to contact a third party (e.g., the bank or the credit-card company acting as an acquirer) before accepting a payment, the system is called an on-line system. In 1990, Chaum together with Moni Naor proposed the first off-line e-cash system, which was also based on blind signatures.\n\n== Literature ==\nSchneier, Bruce. Applied Cryptography, Second Edition, John Wiley & Sons, 1996. ISBN 0-471-11709-9 (Chapter 6.4)\nRichard A. Mollin: RSA and Public-key Cryptography. p. 143-148. 2002, ISBN 1-58488-338-3, ISBN 978-1-58488-338-8.\nGoldwasser, S. and Bellare, M. \"Lecture Notes on Cryptography\". Summer course on cryptography, MIT, 1996-2001. pp. 233.\nQuestion: How did eCash revolutionize the idea of electronic money?\n\nAnswer:",
    "context": "",
    "output": "eCash brought forth the concept of anonymous electronic money by storing money in a digital format, cryptographically signed by a bank, allowing users to spend it anonymously and securely.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How did eCash revolutionize the idea of electronic money?",
      "answer": "eCash brought forth the concept of anonymous electronic money by storing money in a digital format, cryptographically signed by a bank, allowing users to spend it anonymously and securely.",
      "context": "Ecash\n\n==Introduction==\nEcash was conceived by David Chaum as an anonymous cryptographic electronic money or electronic cash system in 1982. It was realized through his corporation Digicash and used as micropayment system at one US bank from 1995 to 1998.\n\n\n\n== Design ==\nChaum published the idea of anonymous electronic money in a 1983 paper; eCash software on the user's local computer stored money in a digital format, cryptographically signed by a bank. The user could spend the digital money at any shop accepting eCash, without having to open an account with the vendor first, or transmitting credit card numbers. Security was ensured by public key digital signature schemes.  The RSA blind signatures achieved unlinkability between withdrawal and spend transactions. Depending on the payment transactions, one distinguishes between on-line and off-line electronic cash: If the payee has to contact a third party (e.g., the bank or the credit-card company acting as an acquirer) before accepting a payment, the system is called an on-line system. In 1990, Chaum together with Moni Naor proposed the first off-line e-cash system, which was also based on blind signatures.\n\n== Literature ==\nSchneier, Bruce. Applied Cryptography, Second Edition, John Wiley & Sons, 1996. ISBN 0-471-11709-9 (Chapter 6.4)\nRichard A. Mollin: RSA and Public-key Cryptography. p. 143-148. 2002, ISBN 1-58488-338-3, ISBN 978-1-58488-338-8.\nGoldwasser, S. and Bellare, M. \"Lecture Notes on Cryptography\". Summer course on cryptography, MIT, 1996-2001. pp. 233."
    }
  },
  {
    "instruction": "In November 2012, Foreign Policy magazine named Dingledine, Mathewson, and Syverson among its Top 100 Global Thinkers \"for making the web safe for whistleblowers\".\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the recognition received by Roger Dingledine, Nick Mathewson, and Syverson in November 2012 and who awarded it?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the recognition received by Roger Dingledine, Nick Mathewson, and Syverson in November 2012 and who awarded it?",
      "answer": "In November 2012, Foreign Policy magazine named Dingledine, Mathewson, and Syverson among its Top 100 Global Thinkers \"for making the web safe for whistleblowers\"."
    }
  },
  {
    "instruction": "The latest version of the AEG platform was released in May 2022. It automatically configures S/MIME certificates in Outlook for Windows using GlobalSign's cross-platform agent, XPA, which sets policies, enrolls, provisions, and installs certificates automatically.\n\nWrite a question about the text above.",
    "context": "",
    "output": "When was the latest version of GlobalSign's AEG platform released, and what are its new features?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "When was the latest version of GlobalSign's AEG platform released, and what are its new features?",
      "answer": "The latest version of the AEG platform was released in May 2022. It automatically configures S/MIME certificates in Outlook for Windows using GlobalSign's cross-platform agent, XPA, which sets policies, enrolls, provisions, and installs certificates automatically."
    }
  },
  {
    "instruction": "In security testing, a Penetration Test simulates an attack by a malicious party and involves exploitation of found vulnerabilities to gain further access, while a Security Assessment does not exploit vulnerabilities and focuses on gaining broad coverage of the systems under test.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does a Penetration Test differ from a Security Assessment in security testing?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does a Penetration Test differ from a Security Assessment in security testing?",
      "answer": "In security testing, a Penetration Test simulates an attack by a malicious party and involves exploitation of found vulnerabilities to gain further access, while a Security Assessment does not exploit vulnerabilities and focuses on gaining broad coverage of the systems under test."
    }
  },
  {
    "instruction": "APT pinning allows users to force APT to choose particular versions of packages, ensuring that packages are not upgraded to versions that may conflict with other packages or have not been sufficiently tested.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is APT pinning in APT, and what is its purpose?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is APT pinning in APT, and what is its purpose?",
      "answer": "APT pinning allows users to force APT to choose particular versions of packages, ensuring that packages are not upgraded to versions that may conflict with other packages or have not been sufficiently tested."
    }
  },
  {
    "instruction": "The golden standard for security in cryptography is to show the system secure without relying on the Random Oracle idealization.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the golden standard for security in cryptography?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the golden standard for security in cryptography?",
      "answer": "The golden standard for security in cryptography is to show the system secure without relying on the Random Oracle idealization."
    }
  },
  {
    "instruction": "The Gamaredon group has been active since at least 2013.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How long has the Gamaredon group been active?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How long has the Gamaredon group been active?",
      "answer": "The Gamaredon group has been active since at least 2013."
    }
  },
  {
    "instruction": "The New York Attorney General's office was in communication with MediaDefender, as revealed in a leaked 25-minute phone conversation released on The Pirate Bay. The conversation suggested that MediaDefender-Defenders had infiltrated the \"internals\" of the company.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What was the New York Attorney General's involvement in the MediaDefender controversy, and what did the leaked phone conversation reveal?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What was the New York Attorney General's involvement in the MediaDefender controversy, and what did the leaked phone conversation reveal?",
      "answer": "The New York Attorney General's office was in communication with MediaDefender, as revealed in a leaked 25-minute phone conversation released on The Pirate Bay. The conversation suggested that MediaDefender-Defenders had infiltrated the \"internals\" of the company."
    }
  },
  {
    "instruction": "The concern was that North Korea would think the transfer of data was an intrusion by the U.S. Air Force and threaten physical retaliation for the espionage.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What was the concern if North Korea had noticed the transfer of data from the Korean Atomic Research Institute's database?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What was the concern if North Korea had noticed the transfer of data from the Korean Atomic Research Institute's database?",
      "answer": "The concern was that North Korea would think the transfer of data was an intrusion by the U.S. Air Force and threaten physical retaliation for the espionage."
    }
  },
  {
    "instruction": "The purpose of Magic Lantern's logging capabilities is to log the PGP password, which allows the FBI to decrypt user communications.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the purpose of Magic Lantern's logging capabilities?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the purpose of Magic Lantern's logging capabilities?",
      "answer": "The purpose of Magic Lantern's logging capabilities is to log the PGP password, which allows the FBI to decrypt user communications."
    }
  },
  {
    "instruction": "The Access control matrix is the protection system implemented in Lampson's Protection Model, and it restricts access to Objects based on the protection policies of the system.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What does the Access control matrix refer to in Lampson's Protection Model?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What does the Access control matrix refer to in Lampson's Protection Model?",
      "answer": "The Access control matrix is the protection system implemented in Lampson's Protection Model, and it restricts access to Objects based on the protection policies of the system."
    }
  },
  {
    "instruction": "The use of a variable digest size in HAS-V allows it to be tailored to the specific security needs of different systems, making it more versatile than fixed-length hash functions. This variable digest size enables HAS-V to be used in a wider range of security applications and provide a higher level of security for sensitive applications.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does the use of a variable digest size in HAS-V make it more versatile than fixed-length hash functions?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does the use of a variable digest size in HAS-V make it more versatile than fixed-length hash functions?",
      "answer": "The use of a variable digest size in HAS-V allows it to be tailored to the specific security needs of different systems, making it more versatile than fixed-length hash functions. This variable digest size enables HAS-V to be used in a wider range of security applications and provide a higher level of security for sensitive applications."
    }
  },
  {
    "instruction": "Moises Luis Zagala Gonzalez is a 55-year-old cardiologist who is known to be self-taught in computer programming.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is Moises Luis Zagala Gonzalez's profession?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is Moises Luis Zagala Gonzalez's profession?",
      "answer": "Moises Luis Zagala Gonzalez is a 55-year-old cardiologist who is known to be self-taught in computer programming."
    }
  },
  {
    "instruction": "The University of New Mexico School of Law in Albuquerque, NM, has been affected by a virus.\n\nWrite a question about the text above.",
    "context": "",
    "output": "Which school in Albuquerque, NM, has been affected by a virus?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "Which school in Albuquerque, NM, has been affected by a virus?",
      "answer": "The University of New Mexico School of Law in Albuquerque, NM, has been affected by a virus."
    }
  },
  {
    "instruction": "TippingPoint technology's user awareness feature differs from traditional firewall technology in that it monitors user activity and behavior, allowing it to detect and prevent unauthorized access or potentially malicious activity. Traditional firewall technology may not provide this level of user awareness.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does TippingPoint technology's user awareness feature differ from traditional firewall technology?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does TippingPoint technology's user awareness feature differ from traditional firewall technology?",
      "answer": "TippingPoint technology's user awareness feature differs from traditional firewall technology in that it monitors user activity and behavior, allowing it to detect and prevent unauthorized access or potentially malicious activity. Traditional firewall technology may not provide this level of user awareness."
    }
  },
  {
    "instruction": "Context: Session border controller\n\n==Introduction==\nA session border controller (SBC) is a network element deployed to protect SIP based voice over Internet Protocol (VoIP) networks.\nEarly deployments of SBCs were focused on the borders between two service provider networks in a peering environment.  This role has now expanded to include significant deployments between a service provider's access network and a backbone network to provide service to residential and/or enterprise customers.The term \"session\" refers to a communication between two or more parties \u2013 in the context of telephony, this would be a call. Each call consists of one or more call signaling message exchanges that control the call, and one or more call media streams which carry the call's audio, video, or other data along with information of call statistics and quality. Together, these streams make up a session. It is the job of a session border controller to exert influence over the data flows of sessions.\nThe term \"border\" refers to a point of demarcation between one part of a network and another. As a simple example, at the edge of a corporate network, a firewall demarcates the local network (inside the corporation) from the rest of the Internet (outside the corporation). A more complex example is that of a large corporation where different departments have security needs for each location and perhaps for each kind of data. In this case, filtering routers or other network elements are used to control the flow of data streams. It is the job of a session border controller to assist policy administrators in managing the flow of session data across these borders.\nThe term \"controller\" refers to the influence that session border controllers have on the data streams that comprise sessions, as they traverse borders between one part of a network and another. Additionally, session border controllers often provide measurement, access control, and data conversion facilities for the calls they control.\n\n== Functions ==\nSBCs commonly maintain full session state and offer the following functions:\n\nSecurity \u2013 protect the network and other devices from:\nMalicious attacks such as a denial-of-service attack (DoS) or distributed DoS\nToll fraud via rogue media streams\nMalformed packet protection\nEncryption of signaling (via TLS and IPSec) and media (SRTP)\nConnectivity \u2013 allow different parts of the network to communicate through the use of a variety of techniques such as:\nNAT traversal\nSIP normalization via SIP message and header manipulation\nIPv4 to IPv6 interworking\nVPN connectivity\nProtocol translations between SIP, SIP-I, H.323\nQuality of service \u2013 the QoS policy of a network and prioritization of flows is usually implemented by the SBC. It can include such functions as:\nTraffic policing\nResource allocation\nRate limiting\nCall admission control\nToS/DSCP bit setting\nRegulatory \u2013 many times the SBC is expected to provide support for regulatory requirements such as:\nemergency calls prioritization and\nlawful interception\nMedia services \u2013 many of the new generation of SBCs also provide built-in digital signal processors (DSPs) to enable them to offer border-based media control and services such as:\nDTMF relay and interworking\nMedia transcoding\nTones and announcements\nData and fax interworking\nSupport for voice and video calls\nStatistics and billing information \u2013 since all sessions that pass through the edge of the network pass through the SBC, it is a natural point to gather statistics and usage-based information on these sessions.With the advent of WebRTC some SBCs have also assumed the role of SIP to WebRTC Gateway and translate SIP.  While no one signalling protocol is mandated by the WebRTC specifications, SIP over WebSockets (RFC 7118) is often used partially due to the applicability of SIP to most of the envisaged communication scenarios as well as the availability of open source software such as JsSIP. In such a case the SBC acts as a gateway between the WebRTC applications and SIP end points.\n\n== Applications ==\nSBCs are inserted into the signaling and/or media paths between calling and called parties in a VoIP call, predominantly those using the Session Initiation Protocol (SIP), H.323, and MGCP call-signaling protocols.\nIn many cases the SBC hides the network topology and protects the service provider or enterprise packet networks. The SBC terminates an inbound call and initiates the second call leg to the destination party. In technical terms, when used with the SIP protocol, this defines a back-to-back user agent (B2BUA). The effect of this behavior is that not only the signaling traffic, but also the media traffic (voice, video) is controlled by the SBC.  In cases where the SBC does not have the capability to provide media services, SBCs are also able to redirect media traffic to a different element elsewhere in the network, for recording, generation of music-on-hold, or other media-related purposes. Conversely, without an SBC, the media traffic travels directly between the endpoints, without the in-network call signaling elements having control over their path.\nIn other cases, the SBC simply modifies the stream of call control (signaling) data involved in each call, perhaps limiting the kinds of calls that can be conducted, changing the codec choices, and so on. Ultimately, SBCs allow the network operators to manage the calls that are made on their networks, fix or change protocols and protocol syntax to achieve interoperability, and also overcome some of the problems that firewalls and network address translators (NATs) present for VoIP calls.\nTo show the operation of an SBC, one can compare a simple call establishment sequence with a call establishment sequence with an SBC.  In the simplest session establishment sequence with only one proxy between the user agents the proxy\u2019s task is to identify the callee\u2019s location and forward the request to it. The proxy also adds a Via header with its own address to indicate the path that the response should traverse. The proxy does not change any dialog identification information present in the message such as the tag in the From header, the Call-Id or the Cseq. Proxies also do not alter any information in the SIP message bodies. Note that during the session initiation phase the user agents exchange SIP messages with the SDP bodies that include addresses at which the agents expect the media traffic. After successfully finishing the session initiation phase the user agents can exchange the media traffic directly between each other without the involvement of the proxy.\nSBCs are designed for many applications and are used by operators and enterprises to achieve a variety of goals. Even the same SBC implementation might act differently depending on its configuration and the use case. Hence, it is not easily possible to describe an exact SBC behavior that would apply to all SBC implementations. In general it is possible to identify certain features that are common to SBCs. For example, most SBCs are implemented as back-to-back user agent. \nA B2BUA is a proxy-like server that splits a SIP transaction in two call legs: on the side facing the user agent client (UAC), it acts as server, on the side facing user agent server (UAS) it acts as a client. While a proxy usually keeps only state information related to active transactions, B2BUAs keep state information about active dialogs, e.g., calls. That is, once a proxy receives a SIP request it will save some state information. Once the transaction is over, e.g., after receiving a response, the state information will soon after be deleted. A B2BUA will maintain state information for active calls and only delete this information once the call is terminated.\nWhen an SBC is included in the call path, the SBC acts as a B2BUA that behaves as a user agent server towards the caller and as user agent client towards the callee. In this sense, the SBC actually terminates that call that was generated by the caller and starts a new call towards the callee. The INVITE message sent by the SBC contains no longer a clear reference to the caller. The INVITE sent by the SBC to the proxy includes Via and Contact headers that point to the SBC itself and not the caller. SBCs often also manipulate the dialog identification information listed in the Call-Id and From tag. Further, in case the SBC is configured to also control the media traffic then the SBC also changes the media addressing information included in the c and m lines of the SDP body. Thereby, not only will all SIP messages traverse the SBC but also all audio and video packets. As the INVITE sent by the SBC establishes a new dialog, the SBC also manipulates the message sequence number (CSeq) as well the Max-Forwards value.  \nNote that the list of header manipulations listed here is only a subset of the possible changes that an SBC might introduce to a SIP message. Furthermore, some SBCs might not do all of the listed manipulations. If the SBC is not expected to control the media traffic then there might be no need to change anything in the SDP body. Some SBCs do not change the dialog identification information and others might even not change the addressing information.\nSBCs are often used by corporations along with firewalls and intrusion prevention systems (IPS) to enable VoIP calls to and from a protected enterprise network. VoIP service providers use SBCs to allow the use of VoIP protocols from private networks with Internet connections using NAT, and also to implement strong security measures that are necessary to maintain a high quality of service. SBCs also replace the function of application-level gateways. In larger enterprises, SBCs can also be used in conjunction with SIP trunks to provide call control and make routing/policy decisions on how calls are routed through the LAN/WAN. There are often tremendous cost savings associated with routing traffic through the internal IP networks of an enterprise, rather than routing calls through a traditional circuit-switched phone network.\nAdditionally, some SBCs can allow VoIP calls to be set up between two phones using different VoIP signaling protocols (e.g., SIP, H.323, Megaco/MGCP) as well as performing transcoding of the media stream when different codecs are in use. Most SBCs also provide firewall features for VoIP traffic (denial of service protection, call filtering, bandwidth management). Protocol normalization and header manipulation is also commonly provided by SBCs, enabling communication between different vendors and networks.\nFrom an IP Multimedia Subsystem (IMS) or 3GPP (3rd Generation Partnership Project) architecture perspective, the SBC is the integration of the P-CSCF and IMS-ALG at the signaling plane and the IMS Access Gateway at the media plane on the access side. On the interconnect side, the SBC maps to the IBCF, IWF at the signaling plane and TrGW (Transition Gateway) at the media plane.\nFrom an IMS/TISPAN architecture perspective, the SBC is the integration of the P-CSCF and C-BGF functions on the access side, and the IBCF, IWF, THIG, and I-BGF functions on the peering side.  Some SBCs can be \"decomposed\", meaning the signaling functions can be located on a separate hardware platform than the media relay functions \u2013 in other words the P-CSCF can be separated from the C-BGF, or the IBCF/IWF can be separated from the I-BGF functions physically. Standards-based protocol, such as the H.248 Ia profile, can be used by the signaling platform to control the media one while a few SBCs use proprietary protocols.\n\n== Controversy ==\nDuring its infancy, the concept of SBC was controversial to proponents of end-to-end systems and peer-to-peer networking because:\n\nSBCs can extend the length of the media path (the way of media packets through the network) significantly. A long media path is undesirable, as it increases the delay of voice packets and the probability of packet loss. Both effects deteriorate the voice/video quality. However,  many times there are obstacles to communication such as firewalls between the call parties, and in these cases SBCs offer an efficient method to guide media streams towards an acceptable path between caller and callee; without the SBC the call media would be blocked. Some SBCs can detect if the ends of the call are in the same subnetwork and release control of the media enabling it to flow directly between the clients, this is anti-tromboning or media release. Also, some SBCs can create a media path where none would otherwise be allowed to exist (by virtue of various firewalls and other security apparatus between the two endpoints). Lastly, for specific VoIP network models where the service provider owns the network, SBCs can actually decrease the media path by shortcut routing approaches. For example, a service provider that provides trunking services to several enterprises would usually allocate each enterprise a VPN. It is often desirable to have the option to interconnect the VPN through SBCs. A VPN-aware SBC may perform this function at the edge of the VPN network, rather than sending all the traffic to the core.\nSBCs can restrict the flow of information between call endpoints, potentially reducing end-to-end transparency. VoIP phones may not be able to use new protocol features unless they are understood by the SBC. However, the SBCs are usually able to cope with the majority of new, and unanticipated protocol features.\nSometimes end-to-end encryption can't be used if the SBC does not have the key, although some portions of the information stream in an encrypted call are not encrypted, and those portions can be used and influenced by the SBC. However, the new generations of SBCs, armed with sufficient computing capacity, are able to offload this encryption function from other elements in the network by terminating SIP-TLS, IPsec, and/or SRTP. Furthermore, SBCs can actually make calls and other SIP scenarios work when they couldn't have before, by performing specific protocol \"normalization\" or \"fix-up\".\nIn most cases, far-end or hosted NAT traversal can be done without SBCs if the VoIP phones support protocols like STUN, TURN, ICE, or Universal Plug and Play (UPnP).Most of the controversy surrounding SBCs pertains to whether call control should remain solely with the two endpoints in a call (in service to their owners), or should rather be shared with other network elements owned by the organizations managing various networks involved in connecting the two call endpoints. For example, should call control remain with Alice and Bob (two callers), or should call control be shared with the operators of all the IP networks involved in connecting Alice and Bob's VoIP phones together. The debate of this point was vigorous, almost religious, in nature. Those who wanted unfettered control in the endpoints only, were also greatly frustrated by the various realities of modern networks, such as firewalls and filtering/throttling. On the other side, network operators are typically concerned about overall network performance, interoperability and quality, and want to ensure it is secure.\n\n== Lawful intercept and CALEA ==\nAn SBC may provide session media (usually RTP) and signaling (often SIP) wiretap services, which can be used by providers to enforce requests for the lawful interception of network sessions. Standards for the interception of such services are provided by ATIS, TIA, CableLabs and ETSI, among others.\n\n== History and market ==\nAccording to Jonathan Rosenberg, the author of RFC 3261 (SIP) and numerous other related RFCs, Dynamicsoft developed the first working SBC in conjunction with Aravox, but the product never truly gained marketshare. .\nNewport Networks was the first to have an IPO on the London Stock Exchange's AIM in May 2004 (NNG), while Cisco has been publicly traded since 1990. Acme Packet followed in October 2006 by floating on the NASDAQ. With the field narrowed by acquisition, NexTone merged with Reefpoint becoming Nextpoint, which was subsequently acquired in 2008 by Genband. At this same time, there emerged the \u201cintegrated\u201d SBC where the border control function was integrated into another edge device. In 2009, Ingate Systems\u2019 Firewall became the first SBC to earn certification from ICSA Labs, a milestone in certifying the VoIP security capabilities of an SBC.\nThe continuing growth of VoIP networks pushes SBCs further to the edge, mandating adaptation in capacity and complexity. As the VoIP network grows and traffic volume increases, more and more sessions are passing through SBC. Vendors are addressing these new scale requirements in a variety of ways. Some have developed separate, load balancing systems to sit in front of SBC clusters. Others, have developed new architectures using the latest generation chipsets offering higher performance SBCs and scalability using service cards.\nQuestion: What is the role of a session border controller in managing the flow of session data across network borders?\n\nAnswer:",
    "context": "",
    "output": "The role of a session border controller is to assist policy administrators in managing the flow of session data across network borders by demarcating one part of a network from another and controlling the flow of data streams.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the role of a session border controller in managing the flow of session data across network borders?",
      "answer": "The role of a session border controller is to assist policy administrators in managing the flow of session data across network borders by demarcating one part of a network from another and controlling the flow of data streams.",
      "context": "Session border controller\n\n==Introduction==\nA session border controller (SBC) is a network element deployed to protect SIP based voice over Internet Protocol (VoIP) networks.\nEarly deployments of SBCs were focused on the borders between two service provider networks in a peering environment.  This role has now expanded to include significant deployments between a service provider's access network and a backbone network to provide service to residential and/or enterprise customers.The term \"session\" refers to a communication between two or more parties \u2013 in the context of telephony, this would be a call. Each call consists of one or more call signaling message exchanges that control the call, and one or more call media streams which carry the call's audio, video, or other data along with information of call statistics and quality. Together, these streams make up a session. It is the job of a session border controller to exert influence over the data flows of sessions.\nThe term \"border\" refers to a point of demarcation between one part of a network and another. As a simple example, at the edge of a corporate network, a firewall demarcates the local network (inside the corporation) from the rest of the Internet (outside the corporation). A more complex example is that of a large corporation where different departments have security needs for each location and perhaps for each kind of data. In this case, filtering routers or other network elements are used to control the flow of data streams. It is the job of a session border controller to assist policy administrators in managing the flow of session data across these borders.\nThe term \"controller\" refers to the influence that session border controllers have on the data streams that comprise sessions, as they traverse borders between one part of a network and another. Additionally, session border controllers often provide measurement, access control, and data conversion facilities for the calls they control.\n\n== Functions ==\nSBCs commonly maintain full session state and offer the following functions:\n\nSecurity \u2013 protect the network and other devices from:\nMalicious attacks such as a denial-of-service attack (DoS) or distributed DoS\nToll fraud via rogue media streams\nMalformed packet protection\nEncryption of signaling (via TLS and IPSec) and media (SRTP)\nConnectivity \u2013 allow different parts of the network to communicate through the use of a variety of techniques such as:\nNAT traversal\nSIP normalization via SIP message and header manipulation\nIPv4 to IPv6 interworking\nVPN connectivity\nProtocol translations between SIP, SIP-I, H.323\nQuality of service \u2013 the QoS policy of a network and prioritization of flows is usually implemented by the SBC. It can include such functions as:\nTraffic policing\nResource allocation\nRate limiting\nCall admission control\nToS/DSCP bit setting\nRegulatory \u2013 many times the SBC is expected to provide support for regulatory requirements such as:\nemergency calls prioritization and\nlawful interception\nMedia services \u2013 many of the new generation of SBCs also provide built-in digital signal processors (DSPs) to enable them to offer border-based media control and services such as:\nDTMF relay and interworking\nMedia transcoding\nTones and announcements\nData and fax interworking\nSupport for voice and video calls\nStatistics and billing information \u2013 since all sessions that pass through the edge of the network pass through the SBC, it is a natural point to gather statistics and usage-based information on these sessions.With the advent of WebRTC some SBCs have also assumed the role of SIP to WebRTC Gateway and translate SIP.  While no one signalling protocol is mandated by the WebRTC specifications, SIP over WebSockets (RFC 7118) is often used partially due to the applicability of SIP to most of the envisaged communication scenarios as well as the availability of open source software such as JsSIP. In such a case the SBC acts as a gateway between the WebRTC applications and SIP end points.\n\n== Applications ==\nSBCs are inserted into the signaling and/or media paths between calling and called parties in a VoIP call, predominantly those using the Session Initiation Protocol (SIP), H.323, and MGCP call-signaling protocols.\nIn many cases the SBC hides the network topology and protects the service provider or enterprise packet networks. The SBC terminates an inbound call and initiates the second call leg to the destination party. In technical terms, when used with the SIP protocol, this defines a back-to-back user agent (B2BUA). The effect of this behavior is that not only the signaling traffic, but also the media traffic (voice, video) is controlled by the SBC.  In cases where the SBC does not have the capability to provide media services, SBCs are also able to redirect media traffic to a different element elsewhere in the network, for recording, generation of music-on-hold, or other media-related purposes. Conversely, without an SBC, the media traffic travels directly between the endpoints, without the in-network call signaling elements having control over their path.\nIn other cases, the SBC simply modifies the stream of call control (signaling) data involved in each call, perhaps limiting the kinds of calls that can be conducted, changing the codec choices, and so on. Ultimately, SBCs allow the network operators to manage the calls that are made on their networks, fix or change protocols and protocol syntax to achieve interoperability, and also overcome some of the problems that firewalls and network address translators (NATs) present for VoIP calls.\nTo show the operation of an SBC, one can compare a simple call establishment sequence with a call establishment sequence with an SBC.  In the simplest session establishment sequence with only one proxy between the user agents the proxy\u2019s task is to identify the callee\u2019s location and forward the request to it. The proxy also adds a Via header with its own address to indicate the path that the response should traverse. The proxy does not change any dialog identification information present in the message such as the tag in the From header, the Call-Id or the Cseq. Proxies also do not alter any information in the SIP message bodies. Note that during the session initiation phase the user agents exchange SIP messages with the SDP bodies that include addresses at which the agents expect the media traffic. After successfully finishing the session initiation phase the user agents can exchange the media traffic directly between each other without the involvement of the proxy.\nSBCs are designed for many applications and are used by operators and enterprises to achieve a variety of goals. Even the same SBC implementation might act differently depending on its configuration and the use case. Hence, it is not easily possible to describe an exact SBC behavior that would apply to all SBC implementations. In general it is possible to identify certain features that are common to SBCs. For example, most SBCs are implemented as back-to-back user agent. \nA B2BUA is a proxy-like server that splits a SIP transaction in two call legs: on the side facing the user agent client (UAC), it acts as server, on the side facing user agent server (UAS) it acts as a client. While a proxy usually keeps only state information related to active transactions, B2BUAs keep state information about active dialogs, e.g., calls. That is, once a proxy receives a SIP request it will save some state information. Once the transaction is over, e.g., after receiving a response, the state information will soon after be deleted. A B2BUA will maintain state information for active calls and only delete this information once the call is terminated.\nWhen an SBC is included in the call path, the SBC acts as a B2BUA that behaves as a user agent server towards the caller and as user agent client towards the callee. In this sense, the SBC actually terminates that call that was generated by the caller and starts a new call towards the callee. The INVITE message sent by the SBC contains no longer a clear reference to the caller. The INVITE sent by the SBC to the proxy includes Via and Contact headers that point to the SBC itself and not the caller. SBCs often also manipulate the dialog identification information listed in the Call-Id and From tag. Further, in case the SBC is configured to also control the media traffic then the SBC also changes the media addressing information included in the c and m lines of the SDP body. Thereby, not only will all SIP messages traverse the SBC but also all audio and video packets. As the INVITE sent by the SBC establishes a new dialog, the SBC also manipulates the message sequence number (CSeq) as well the Max-Forwards value.  \nNote that the list of header manipulations listed here is only a subset of the possible changes that an SBC might introduce to a SIP message. Furthermore, some SBCs might not do all of the listed manipulations. If the SBC is not expected to control the media traffic then there might be no need to change anything in the SDP body. Some SBCs do not change the dialog identification information and others might even not change the addressing information.\nSBCs are often used by corporations along with firewalls and intrusion prevention systems (IPS) to enable VoIP calls to and from a protected enterprise network. VoIP service providers use SBCs to allow the use of VoIP protocols from private networks with Internet connections using NAT, and also to implement strong security measures that are necessary to maintain a high quality of service. SBCs also replace the function of application-level gateways. In larger enterprises, SBCs can also be used in conjunction with SIP trunks to provide call control and make routing/policy decisions on how calls are routed through the LAN/WAN. There are often tremendous cost savings associated with routing traffic through the internal IP networks of an enterprise, rather than routing calls through a traditional circuit-switched phone network.\nAdditionally, some SBCs can allow VoIP calls to be set up between two phones using different VoIP signaling protocols (e.g., SIP, H.323, Megaco/MGCP) as well as performing transcoding of the media stream when different codecs are in use. Most SBCs also provide firewall features for VoIP traffic (denial of service protection, call filtering, bandwidth management). Protocol normalization and header manipulation is also commonly provided by SBCs, enabling communication between different vendors and networks.\nFrom an IP Multimedia Subsystem (IMS) or 3GPP (3rd Generation Partnership Project) architecture perspective, the SBC is the integration of the P-CSCF and IMS-ALG at the signaling plane and the IMS Access Gateway at the media plane on the access side. On the interconnect side, the SBC maps to the IBCF, IWF at the signaling plane and TrGW (Transition Gateway) at the media plane.\nFrom an IMS/TISPAN architecture perspective, the SBC is the integration of the P-CSCF and C-BGF functions on the access side, and the IBCF, IWF, THIG, and I-BGF functions on the peering side.  Some SBCs can be \"decomposed\", meaning the signaling functions can be located on a separate hardware platform than the media relay functions \u2013 in other words the P-CSCF can be separated from the C-BGF, or the IBCF/IWF can be separated from the I-BGF functions physically. Standards-based protocol, such as the H.248 Ia profile, can be used by the signaling platform to control the media one while a few SBCs use proprietary protocols.\n\n== Controversy ==\nDuring its infancy, the concept of SBC was controversial to proponents of end-to-end systems and peer-to-peer networking because:\n\nSBCs can extend the length of the media path (the way of media packets through the network) significantly. A long media path is undesirable, as it increases the delay of voice packets and the probability of packet loss. Both effects deteriorate the voice/video quality. However,  many times there are obstacles to communication such as firewalls between the call parties, and in these cases SBCs offer an efficient method to guide media streams towards an acceptable path between caller and callee; without the SBC the call media would be blocked. Some SBCs can detect if the ends of the call are in the same subnetwork and release control of the media enabling it to flow directly between the clients, this is anti-tromboning or media release. Also, some SBCs can create a media path where none would otherwise be allowed to exist (by virtue of various firewalls and other security apparatus between the two endpoints). Lastly, for specific VoIP network models where the service provider owns the network, SBCs can actually decrease the media path by shortcut routing approaches. For example, a service provider that provides trunking services to several enterprises would usually allocate each enterprise a VPN. It is often desirable to have the option to interconnect the VPN through SBCs. A VPN-aware SBC may perform this function at the edge of the VPN network, rather than sending all the traffic to the core.\nSBCs can restrict the flow of information between call endpoints, potentially reducing end-to-end transparency. VoIP phones may not be able to use new protocol features unless they are understood by the SBC. However, the SBCs are usually able to cope with the majority of new, and unanticipated protocol features.\nSometimes end-to-end encryption can't be used if the SBC does not have the key, although some portions of the information stream in an encrypted call are not encrypted, and those portions can be used and influenced by the SBC. However, the new generations of SBCs, armed with sufficient computing capacity, are able to offload this encryption function from other elements in the network by terminating SIP-TLS, IPsec, and/or SRTP. Furthermore, SBCs can actually make calls and other SIP scenarios work when they couldn't have before, by performing specific protocol \"normalization\" or \"fix-up\".\nIn most cases, far-end or hosted NAT traversal can be done without SBCs if the VoIP phones support protocols like STUN, TURN, ICE, or Universal Plug and Play (UPnP).Most of the controversy surrounding SBCs pertains to whether call control should remain solely with the two endpoints in a call (in service to their owners), or should rather be shared with other network elements owned by the organizations managing various networks involved in connecting the two call endpoints. For example, should call control remain with Alice and Bob (two callers), or should call control be shared with the operators of all the IP networks involved in connecting Alice and Bob's VoIP phones together. The debate of this point was vigorous, almost religious, in nature. Those who wanted unfettered control in the endpoints only, were also greatly frustrated by the various realities of modern networks, such as firewalls and filtering/throttling. On the other side, network operators are typically concerned about overall network performance, interoperability and quality, and want to ensure it is secure.\n\n== Lawful intercept and CALEA ==\nAn SBC may provide session media (usually RTP) and signaling (often SIP) wiretap services, which can be used by providers to enforce requests for the lawful interception of network sessions. Standards for the interception of such services are provided by ATIS, TIA, CableLabs and ETSI, among others.\n\n== History and market ==\nAccording to Jonathan Rosenberg, the author of RFC 3261 (SIP) and numerous other related RFCs, Dynamicsoft developed the first working SBC in conjunction with Aravox, but the product never truly gained marketshare. .\nNewport Networks was the first to have an IPO on the London Stock Exchange's AIM in May 2004 (NNG), while Cisco has been publicly traded since 1990. Acme Packet followed in October 2006 by floating on the NASDAQ. With the field narrowed by acquisition, NexTone merged with Reefpoint becoming Nextpoint, which was subsequently acquired in 2008 by Genband. At this same time, there emerged the \u201cintegrated\u201d SBC where the border control function was integrated into another edge device. In 2009, Ingate Systems\u2019 Firewall became the first SBC to earn certification from ICSA Labs, a milestone in certifying the VoIP security capabilities of an SBC.\nThe continuing growth of VoIP networks pushes SBCs further to the edge, mandating adaptation in capacity and complexity. As the VoIP network grows and traffic volume increases, more and more sessions are passing through SBC. Vendors are addressing these new scale requirements in a variety of ways. Some have developed separate, load balancing systems to sit in front of SBC clusters. Others, have developed new architectures using the latest generation chipsets offering higher performance SBCs and scalability using service cards."
    }
  },
  {
    "instruction": "The \"RADIUS Extensions\" working group of the Internet Engineering Task Force (IETF) specified RadSec. The RadSec protocol specifications can be found in RFC 6614, which defines the RadSec protocol for securely transporting RADIUS datagrams over TCP and TLS.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What working group of the IETF was responsible for specifying RadSec, and which RFC details the RadSec protocol specifications?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What working group of the IETF was responsible for specifying RadSec, and which RFC details the RadSec protocol specifications?",
      "answer": "The \"RADIUS Extensions\" working group of the Internet Engineering Task Force (IETF) specified RadSec. The RadSec protocol specifications can be found in RFC 6614, which defines the RadSec protocol for securely transporting RADIUS datagrams over TCP and TLS."
    }
  },
  {
    "instruction": "The access matrix model is a generalized description of operating system protection mechanisms, which was first introduced in 1971. It provides a framework for organizing and managing the access rights and privileges of different users and processes in a computer system.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the significance of the access matrix model in the context of operating system protection mechanisms, and when was it first introduced?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the significance of the access matrix model in the context of operating system protection mechanisms, and when was it first introduced?",
      "answer": "The access matrix model is a generalized description of operating system protection mechanisms, which was first introduced in 1971. It provides a framework for organizing and managing the access rights and privileges of different users and processes in a computer system."
    }
  },
  {
    "instruction": "The primary argument in favor of coordinated vulnerability disclosure is that users cannot make use of advanced knowledge of vulnerabilities without guidance from the vendor. Advocates of this approach argue that low-skilled attackers can use vulnerability information to perform sophisticated attacks that would otherwise be beyond their ability, and the potential benefit does not outweigh the potential harm caused by malevolent actors. Most vendors prefer coordinated disclosure over full disclosure.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the primary argument in favor of coordinated vulnerability disclosure, and who are its main proponents?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the primary argument in favor of coordinated vulnerability disclosure, and who are its main proponents?",
      "answer": "The primary argument in favor of coordinated vulnerability disclosure is that users cannot make use of advanced knowledge of vulnerabilities without guidance from the vendor. Advocates of this approach argue that low-skilled attackers can use vulnerability information to perform sophisticated attacks that would otherwise be beyond their ability, and the potential benefit does not outweigh the potential harm caused by malevolent actors. Most vendors prefer coordinated disclosure over full disclosure."
    }
  },
  {
    "instruction": "The fact that plaintext-aware encryption is known to exist when a public-key infrastructure is assumed is significant because it suggests that it is possible to provide an additional layer of security against chosen-ciphertext attacks in systems that use public-key infrastructure. This is important because public-key infrastructure is a critical component of many secure communication systems, including secure email and secure web browsing. By using plaintext-aware encryption in a public-key infrastructure, it is possible to provide stronger security guarantees.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the significance of the fact that plaintext-aware encryption is known to exist when a public-key infrastructure is assumed?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the significance of the fact that plaintext-aware encryption is known to exist when a public-key infrastructure is assumed?",
      "answer": "The fact that plaintext-aware encryption is known to exist when a public-key infrastructure is assumed is significant because it suggests that it is possible to provide an additional layer of security against chosen-ciphertext attacks in systems that use public-key infrastructure. This is important because public-key infrastructure is a critical component of many secure communication systems, including secure email and secure web browsing. By using plaintext-aware encryption in a public-key infrastructure, it is possible to provide stronger security guarantees."
    }
  },
  {
    "instruction": "Footprinting\n\n==Introduction==\nFootprinting (also known as reconnaissance) is the technique used for gathering information about computer systems and the entities they belong to. To get this information, a hacker might use various tools and technologies. This information is very useful to a hacker who is trying to crack a whole system.When used in the computer security lexicon, \"Footprinting\" generally refers to one of the pre-attack phases; tasks performed before doing the actual attack.  Some of the tools used for Footprinting are Sam Spade, nslookup, traceroute, Nmap and neotrace.\n\n\n\n== Techniques used for Footprinting ==\nDNS queries\nNetwork enumeration\nNetwork queries\nOperating system identification\n\n== Software used for Footprinting to get entity information ==\nWireshark\n\n== Uses of Footprinting ==\nIt allows a hacker to gain information about the target system or network. This information can be used to carry out attacks on the system. That is the reason by which it may be named a Pre-Attack, since all the information is reviewed in order to get a complete and successful resolution of the attack. Footprinting is also used by ethical hackers and penetration testers to find security flaws and vulnerabilities within their own company's network before a malicious hacker does.\n\n== Types of Footprinting ==\nThere are two types of Footprinting that can be used: active Footprinting and passive Footprinting. Active Footprinting is the process of using tools and techniques, such as performing a ping sweep or using the traceroute command, to gather information on a target. Active Footprinting can trigger a target's Intrusion Detection System (IDS) and may be logged, and thus requires a level of stealth to successfully do. Passive Footprinting is the process of gathering information on a target by innocuous, or, passive, means. Browsing the target's website, visiting social media profiles of employees, searching for the website on WHOIS, and performing a Google search of the target are all ways of passive Footprinting. Passive Footprinting is the stealthier method since it will not trigger a target's IDS or otherwise alert the target of information being gathered.\n\n== Crawling ==\nCrawling is the process of surfing the internet to get the required information about the target. The sites surfed can include the target's website, blogs and social networks. The information obtained by this method will be helpful in other methods.\n\n== WHOIS ==\nWHOIS is a web application used to get information about the target website, such as the administrator's e-mail address and details about the registration. WHOIS is a very large database and contains information of approximately all clearnet websites. It can be searched by domain name.\n\n== Search engines ==\nSearch engines such as Google can also be used to gather information about the target system. It depends on how well one knows how to use search engines to collect information. If used properly, the attacker can gather much information about a company, its career, its policies, etc.\n\n== Traceroute ==\nInformation can also be gathered using the command Tracert (\"traceroute\"), which is used to trace a path between a user and the target system on the networks. That way it becomes clear where a request is being forwarded and through which devices. In Linux systems, the tracepath and traceroute commands are also available for doing traceroute operations.\n\n== Negative web search ==\nNegative web search will reveal some other websites when performed on the target website. Negative websites can act as resources for insight about the flaws of the target website.\n\n== Information to be Gathered ==\nIf the attack is to be performed on a company, then the following information will be gathered.\n\nCompany details, employee details and their email addresses.\nRelation with other companies.\nProject details involving other companies.\nLegal documents of the company.\nNews relating company website.\nPatents and trademarks regarding that particular company.\nImportant dates regarding new projects. Answer this question using the following article:\n\nWhat is the purpose of crawling in the context of Footprinting?",
    "context": "",
    "output": "Crawling is the process of surfing the internet to gather information about the target from sources such as the target's website, blogs, and social networks.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the purpose of crawling in the context of Footprinting?",
      "answer": "Crawling is the process of surfing the internet to gather information about the target from sources such as the target's website, blogs, and social networks.",
      "context": "Footprinting\n\n==Introduction==\nFootprinting (also known as reconnaissance) is the technique used for gathering information about computer systems and the entities they belong to. To get this information, a hacker might use various tools and technologies. This information is very useful to a hacker who is trying to crack a whole system.When used in the computer security lexicon, \"Footprinting\" generally refers to one of the pre-attack phases; tasks performed before doing the actual attack.  Some of the tools used for Footprinting are Sam Spade, nslookup, traceroute, Nmap and neotrace.\n\n\n\n== Techniques used for Footprinting ==\nDNS queries\nNetwork enumeration\nNetwork queries\nOperating system identification\n\n== Software used for Footprinting to get entity information ==\nWireshark\n\n== Uses of Footprinting ==\nIt allows a hacker to gain information about the target system or network. This information can be used to carry out attacks on the system. That is the reason by which it may be named a Pre-Attack, since all the information is reviewed in order to get a complete and successful resolution of the attack. Footprinting is also used by ethical hackers and penetration testers to find security flaws and vulnerabilities within their own company's network before a malicious hacker does.\n\n== Types of Footprinting ==\nThere are two types of Footprinting that can be used: active Footprinting and passive Footprinting. Active Footprinting is the process of using tools and techniques, such as performing a ping sweep or using the traceroute command, to gather information on a target. Active Footprinting can trigger a target's Intrusion Detection System (IDS) and may be logged, and thus requires a level of stealth to successfully do. Passive Footprinting is the process of gathering information on a target by innocuous, or, passive, means. Browsing the target's website, visiting social media profiles of employees, searching for the website on WHOIS, and performing a Google search of the target are all ways of passive Footprinting. Passive Footprinting is the stealthier method since it will not trigger a target's IDS or otherwise alert the target of information being gathered.\n\n== Crawling ==\nCrawling is the process of surfing the internet to get the required information about the target. The sites surfed can include the target's website, blogs and social networks. The information obtained by this method will be helpful in other methods.\n\n== WHOIS ==\nWHOIS is a web application used to get information about the target website, such as the administrator's e-mail address and details about the registration. WHOIS is a very large database and contains information of approximately all clearnet websites. It can be searched by domain name.\n\n== Search engines ==\nSearch engines such as Google can also be used to gather information about the target system. It depends on how well one knows how to use search engines to collect information. If used properly, the attacker can gather much information about a company, its career, its policies, etc.\n\n== Traceroute ==\nInformation can also be gathered using the command Tracert (\"traceroute\"), which is used to trace a path between a user and the target system on the networks. That way it becomes clear where a request is being forwarded and through which devices. In Linux systems, the tracepath and traceroute commands are also available for doing traceroute operations.\n\n== Negative web search ==\nNegative web search will reveal some other websites when performed on the target website. Negative websites can act as resources for insight about the flaws of the target website.\n\n== Information to be Gathered ==\nIf the attack is to be performed on a company, then the following information will be gathered.\n\nCompany details, employee details and their email addresses.\nRelation with other companies.\nProject details involving other companies.\nLegal documents of the company.\nNews relating company website.\nPatents and trademarks regarding that particular company.\nImportant dates regarding new projects."
    }
  },
  {
    "instruction": "Confidentiality in security testing involves protecting against the disclosure of information to unauthorized parties. This aspect is crucial for safeguarding sensitive data and maintaining privacy within the system.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the role of confidentiality in security testing?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the role of confidentiality in security testing?",
      "answer": "Confidentiality in security testing involves protecting against the disclosure of information to unauthorized parties. This aspect is crucial for safeguarding sensitive data and maintaining privacy within the system."
    }
  },
  {
    "instruction": "The software that controls the collection and distribution of civilian telecommunications traffic conveyed using communication satellites in the ECHELON system is called SILKWORTH and SIRE.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the software that controls the collection and distribution of civilian telecommunications traffic conveyed using communication satellites in the ECHELON system?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the software that controls the collection and distribution of civilian telecommunications traffic conveyed using communication satellites in the ECHELON system?",
      "answer": "The software that controls the collection and distribution of civilian telecommunications traffic conveyed using communication satellites in the ECHELON system is called SILKWORTH and SIRE."
    }
  },
  {
    "instruction": "No, the same cipher cannot be used in consecutive transactions in Dynamic Encryption, as the principle of the system requires the cipher to change for every new data transaction.\n\nWrite a question about the text above.",
    "context": "",
    "output": "Can the same cipher be used in consecutive transactions in Dynamic Encryption?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "Can the same cipher be used in consecutive transactions in Dynamic Encryption?",
      "answer": "No, the same cipher cannot be used in consecutive transactions in Dynamic Encryption, as the principle of the system requires the cipher to change for every new data transaction."
    }
  },
  {
    "instruction": "Both the Bitvise server and client support all desktop and server versions of Windows.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What are the operating systems that Bitvise server and client support?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What are the operating systems that Bitvise server and client support?",
      "answer": "Both the Bitvise server and client support all desktop and server versions of Windows."
    }
  },
  {
    "instruction": "Albert Gonzalez\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the name of the American citizen charged with the theft of 130 million credit card numbers using an SQL injection attack in 2009?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the name of the American citizen charged with the theft of 130 million credit card numbers using an SQL injection attack in 2009?",
      "answer": "Albert Gonzalez"
    }
  },
  {
    "instruction": "The FIN7 hacking group maintains its operations by using a front company called Combi Security, allowing them to blend in with legitimate cybersecurity activities. This tactic helps them evade detection and maintain their criminal enterprise, primarily targeting the U.S. retail, restaurant, and hospitality sectors.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does the FIN7 hacking group maintain its operations while avoiding detection?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does the FIN7 hacking group maintain its operations while avoiding detection?",
      "answer": "The FIN7 hacking group maintains its operations by using a front company called Combi Security, allowing them to blend in with legitimate cybersecurity activities. This tactic helps them evade detection and maintain their criminal enterprise, primarily targeting the U.S. retail, restaurant, and hospitality sectors."
    }
  },
  {
    "instruction": "No, Exclu did not offer yearly or monthly licenses. The available options were a three-month or six-month license.\n\nWrite a question about the text above.",
    "context": "",
    "output": "Was it possible to obtain a yearly or a monthly license for Exclu?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "Was it possible to obtain a yearly or a monthly license for Exclu?",
      "answer": "No, Exclu did not offer yearly or monthly licenses. The available options were a three-month or six-month license."
    }
  },
  {
    "instruction": "Some datasets available for anomaly detection benchmarking include the anomaly detection benchmark data repository with carefully chosen data sets of the Ludwig-Maximilians-Universit\u00e4t M\u00fcnchen, ODDS \u2013 ODDS: A large collection of publicly available outlier detection datasets with ground truth in different domains, the Unsupervised Anomaly Detection Benchmark at Harvard Dataverse: Datasets for Unsupervised Anomaly Detection with ground truth, and the KMASH Data Repository at Research Data Australia, which has more than 12,000 anomaly detection datasets with ground truth.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What are some datasets available for anomaly detection benchmarking?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What are some datasets available for anomaly detection benchmarking?",
      "answer": "Some datasets available for anomaly detection benchmarking include the anomaly detection benchmark data repository with carefully chosen data sets of the Ludwig-Maximilians-Universit\u00e4t M\u00fcnchen, ODDS \u2013 ODDS: A large collection of publicly available outlier detection datasets with ground truth in different domains, the Unsupervised Anomaly Detection Benchmark at Harvard Dataverse: Datasets for Unsupervised Anomaly Detection with ground truth, and the KMASH Data Repository at Research Data Australia, which has more than 12,000 anomaly detection datasets with ground truth."
    }
  },
  {
    "instruction": "MPA is a proactive solution that prevents the initial undesirable act, while other methods such as auditing, job rotation, and separation of duties are reactive or limiting techniques meant to discover or minimize prolonged access to sensitive data or systems.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does MPA differ from other methods used to protect data and systems from malicious insiders?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does MPA differ from other methods used to protect data and systems from malicious insiders?",
      "answer": "MPA is a proactive solution that prevents the initial undesirable act, while other methods such as auditing, job rotation, and separation of duties are reactive or limiting techniques meant to discover or minimize prolonged access to sensitive data or systems."
    }
  },
  {
    "instruction": "Context: Trusted computing base\n\n==Introduction==\nThe trusted computing base (TCB) of a computer system is the set of all hardware, firmware, and/or software components that are critical to its security, in the sense that bugs or vulnerabilities occurring inside the TCB might jeopardize the security properties of the entire system. By contrast, parts of a computer system that lie outside the TCB must not be able to misbehave in a way that would leak any more privileges than are granted to them in accordance to the system's security policy.\nThe careful design and implementation of a system's trusted computing base is paramount to its overall security. Modern operating systems strive to reduce the size of the TCB so that an exhaustive examination of its code base (by means of manual or computer-assisted software audit or program verification) becomes feasible.\n\n== Definition and characterization ==\nThe term trusted computing base goes back to John Rushby, who defined it as the combination of operating system kernel and trusted processes. The latter refers to processes which are allowed to violate the system's access-control rules.\nIn the classic paper Authentication in Distributed Systems: Theory and Practice Lampson et al. define the TCB of a computer system as simply\n\na small amount of software and hardware that security depends on and that we distinguish from a much larger amount that can misbehave without affecting security.Both definitions, while clear and convenient, are neither theoretically exact nor intended to be, as e.g. a network server process under a UNIX-like operating system might fall victim to a security breach and compromise an important part of the system's security, yet is not part of the operating system's TCB. The Orange Book, another classic computer security literature reference, therefore provides a more formal definition of the TCB of a computer system, as\n\nthe totality of protection mechanisms within it, including hardware, firmware, and software, the combination of which is responsible for enforcing a computer security policy.In other words, trusted computing base (TCB) is a combination of hardware, software, and controls that work together to form a trusted base to enforce your security policy.\nThe Orange Book further explains that\n\n[t]he ability of a trusted computing base to enforce correctly a unified security policy depends on the correctness of the mechanisms within the trusted computing base, the protection of those mechanisms to ensure their correctness, and the correct input of parameters related to the security policy.In other words, a given piece of hardware or software is a part of the TCB if and only if it has been designed to be a part of the mechanism that provides its security to the computer system. In operating systems, this typically consists of the kernel (or microkernel) and a select set of system utilities (for example, setuid programs and daemons in UNIX systems). In programming languages designed with built-in security features, such as Java and E, the TCB is formed of the language runtime and standard library.\n\n== Properties ==\n\n\n*** Predicated upon the security policy ***\nAs a consequence of the above Orange Book definition, the boundaries of the TCB depend closely upon the specifics of how the security policy is fleshed out. In the network server example above, even though, say, a Web server that serves a multi-user application is not part of the operating system's TCB, it has the responsibility of performing access control so that the users cannot usurp the identity and privileges of each other. In this sense, it definitely is part of the TCB of the larger computer system that comprises the UNIX server, the user's browsers and the Web application; in other words, breaching into the Web server through e.g. a buffer overflow may not be regarded as a compromise of the operating system proper, but it certainly constitutes a damaging exploit on the Web application.\nThis fundamental relativity of the boundary of the TCB is exemplified by the concept of the 'target of evaluation' ('TOE') in the Common Criteria security process: in the course of a Common Criteria security evaluation, one of the first decisions that must be made is the boundary of the audit in terms of the list of system components that will come under scrutiny.\n\n\n*** A prerequisite to security ***\nSystems that don't have a trusted computing base as part of their design do not provide security of their own: they are only secure insofar as security is provided to them by external means (e.g. a computer sitting in a locked room without a network connection may be considered secure depending on the policy, regardless of the software it runs). This is because, as David J. Farber et al. put it, [i]n a computer system, the integrity of lower layers is typically treated as axiomatic by higher layers. As far as computer security is concerned, reasoning about the security properties of a computer system requires being able to make sound assumptions about what it can, and more importantly, cannot do; however, barring any reason to believe otherwise, a computer is able to do everything that a general Von Neumann machine can. This obviously includes operations that would be deemed contrary to all but the simplest security policies, such as divulging an email or password that should be kept secret; however, barring special provisions in the architecture of the system, there is no denying that the computer could be programmed to perform these undesirable tasks.\nThese special provisions that aim at preventing certain kinds of actions from being executed, in essence, constitute the trusted computing base. For this reason, the Orange Book (still a reference on the design of secure operating systems as of 2007) characterizes the various security assurance levels that it defines mainly in terms of the structure and security features of the TCB.\n\n\n*** Software parts of the TCB need to protect themselves ***\nAs outlined by the aforementioned Orange Book, software portions of the trusted computing base need to protect themselves against tampering to be of any effect. This is due to the von Neumann architecture implemented by virtually all modern computers: since machine code can be processed as just another kind of data, it can be read and overwritten by any program. This can be prevented by special memory management provisions that subsequently have to be treated as part of the TCB. Specifically, the trusted computing base must at least prevent its own software from being written to.\nIn many modern CPUs, the protection of the memory that hosts the TCB is achieved by adding in a specialized piece of hardware called the memory management unit (MMU), which is programmable by the operating system to allow and deny a running program's access to specific ranges of the system memory. Of course, the operating system is also able to disallow such programming to the other programs. This technique is called supervisor mode; compared to more crude approaches (such as storing the TCB in ROM, or equivalently, using the Harvard architecture), it has the advantage of allowing security-critical software to be upgraded in the field, although allowing secure upgrades of the trusted computing base poses bootstrap problems of its own.\n\n\n*** Trusted vs. trustworthy ***\nAs stated above, trust in the trusted computing base is required to make any progress in ascertaining the security of the computer system. In other words, the trusted computing base is \u201ctrusted\u201d first and foremost in the sense that it has to be trusted, and not necessarily that it is trustworthy. Real-world operating systems routinely have security-critical bugs discovered in them, which attests to the practical limits of such trust.The alternative is formal software verification, which uses mathematical proof techniques to show the absence of bugs. Researchers at NICTA and its spinout Open Kernel Labs have recently performed such a formal verification of seL4, a member of the L4 microkernel family, proving functional correctness of the C implementation of the kernel.\nThis makes seL4 the first operating-system kernel which closes the gap between trust and trustworthiness, assuming the mathematical proof is free from error.\n\n\n*** TCB size ***\nDue to the aforementioned need to apply costly techniques such as formal verification or manual review, the size of the TCB has immediate consequences on the economics of the TCB assurance process, and the trustworthiness of the resulting product (in terms of the mathematical expectation of the number of bugs not found during the verification or review). In order to reduce costs and security risks, the TCB should therefore be kept as small as possible. This is a key argument in the debate preferring microkernels to monolithic kernels.\n\n== Examples ==\nAIX materializes the trusted computing base as an optional component in its install-time package management system.\nQuestion: How does the trustworthiness of the trusted computing base affect the security properties of a computer system?. Whats the answer?",
    "context": "",
    "output": "The trustworthiness of the trusted computing base is critical to the security properties of a computer system. The more trustworthy the TCB, the more secure the computer system will be, as it reduces the likelihood of security-critical bugs being discovered in the TCB.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does the trustworthiness of the trusted computing base affect the security properties of a computer system?",
      "answer": "The trustworthiness of the trusted computing base is critical to the security properties of a computer system. The more trustworthy the TCB, the more secure the computer system will be, as it reduces the likelihood of security-critical bugs being discovered in the TCB.",
      "context": "Trusted computing base\n\n==Introduction==\nThe trusted computing base (TCB) of a computer system is the set of all hardware, firmware, and/or software components that are critical to its security, in the sense that bugs or vulnerabilities occurring inside the TCB might jeopardize the security properties of the entire system. By contrast, parts of a computer system that lie outside the TCB must not be able to misbehave in a way that would leak any more privileges than are granted to them in accordance to the system's security policy.\nThe careful design and implementation of a system's trusted computing base is paramount to its overall security. Modern operating systems strive to reduce the size of the TCB so that an exhaustive examination of its code base (by means of manual or computer-assisted software audit or program verification) becomes feasible.\n\n== Definition and characterization ==\nThe term trusted computing base goes back to John Rushby, who defined it as the combination of operating system kernel and trusted processes. The latter refers to processes which are allowed to violate the system's access-control rules.\nIn the classic paper Authentication in Distributed Systems: Theory and Practice Lampson et al. define the TCB of a computer system as simply\n\na small amount of software and hardware that security depends on and that we distinguish from a much larger amount that can misbehave without affecting security.Both definitions, while clear and convenient, are neither theoretically exact nor intended to be, as e.g. a network server process under a UNIX-like operating system might fall victim to a security breach and compromise an important part of the system's security, yet is not part of the operating system's TCB. The Orange Book, another classic computer security literature reference, therefore provides a more formal definition of the TCB of a computer system, as\n\nthe totality of protection mechanisms within it, including hardware, firmware, and software, the combination of which is responsible for enforcing a computer security policy.In other words, trusted computing base (TCB) is a combination of hardware, software, and controls that work together to form a trusted base to enforce your security policy.\nThe Orange Book further explains that\n\n[t]he ability of a trusted computing base to enforce correctly a unified security policy depends on the correctness of the mechanisms within the trusted computing base, the protection of those mechanisms to ensure their correctness, and the correct input of parameters related to the security policy.In other words, a given piece of hardware or software is a part of the TCB if and only if it has been designed to be a part of the mechanism that provides its security to the computer system. In operating systems, this typically consists of the kernel (or microkernel) and a select set of system utilities (for example, setuid programs and daemons in UNIX systems). In programming languages designed with built-in security features, such as Java and E, the TCB is formed of the language runtime and standard library.\n\n== Properties ==\n\n\n*** Predicated upon the security policy ***\nAs a consequence of the above Orange Book definition, the boundaries of the TCB depend closely upon the specifics of how the security policy is fleshed out. In the network server example above, even though, say, a Web server that serves a multi-user application is not part of the operating system's TCB, it has the responsibility of performing access control so that the users cannot usurp the identity and privileges of each other. In this sense, it definitely is part of the TCB of the larger computer system that comprises the UNIX server, the user's browsers and the Web application; in other words, breaching into the Web server through e.g. a buffer overflow may not be regarded as a compromise of the operating system proper, but it certainly constitutes a damaging exploit on the Web application.\nThis fundamental relativity of the boundary of the TCB is exemplified by the concept of the 'target of evaluation' ('TOE') in the Common Criteria security process: in the course of a Common Criteria security evaluation, one of the first decisions that must be made is the boundary of the audit in terms of the list of system components that will come under scrutiny.\n\n\n*** A prerequisite to security ***\nSystems that don't have a trusted computing base as part of their design do not provide security of their own: they are only secure insofar as security is provided to them by external means (e.g. a computer sitting in a locked room without a network connection may be considered secure depending on the policy, regardless of the software it runs). This is because, as David J. Farber et al. put it, [i]n a computer system, the integrity of lower layers is typically treated as axiomatic by higher layers. As far as computer security is concerned, reasoning about the security properties of a computer system requires being able to make sound assumptions about what it can, and more importantly, cannot do; however, barring any reason to believe otherwise, a computer is able to do everything that a general Von Neumann machine can. This obviously includes operations that would be deemed contrary to all but the simplest security policies, such as divulging an email or password that should be kept secret; however, barring special provisions in the architecture of the system, there is no denying that the computer could be programmed to perform these undesirable tasks.\nThese special provisions that aim at preventing certain kinds of actions from being executed, in essence, constitute the trusted computing base. For this reason, the Orange Book (still a reference on the design of secure operating systems as of 2007) characterizes the various security assurance levels that it defines mainly in terms of the structure and security features of the TCB.\n\n\n*** Software parts of the TCB need to protect themselves ***\nAs outlined by the aforementioned Orange Book, software portions of the trusted computing base need to protect themselves against tampering to be of any effect. This is due to the von Neumann architecture implemented by virtually all modern computers: since machine code can be processed as just another kind of data, it can be read and overwritten by any program. This can be prevented by special memory management provisions that subsequently have to be treated as part of the TCB. Specifically, the trusted computing base must at least prevent its own software from being written to.\nIn many modern CPUs, the protection of the memory that hosts the TCB is achieved by adding in a specialized piece of hardware called the memory management unit (MMU), which is programmable by the operating system to allow and deny a running program's access to specific ranges of the system memory. Of course, the operating system is also able to disallow such programming to the other programs. This technique is called supervisor mode; compared to more crude approaches (such as storing the TCB in ROM, or equivalently, using the Harvard architecture), it has the advantage of allowing security-critical software to be upgraded in the field, although allowing secure upgrades of the trusted computing base poses bootstrap problems of its own.\n\n\n*** Trusted vs. trustworthy ***\nAs stated above, trust in the trusted computing base is required to make any progress in ascertaining the security of the computer system. In other words, the trusted computing base is \u201ctrusted\u201d first and foremost in the sense that it has to be trusted, and not necessarily that it is trustworthy. Real-world operating systems routinely have security-critical bugs discovered in them, which attests to the practical limits of such trust.The alternative is formal software verification, which uses mathematical proof techniques to show the absence of bugs. Researchers at NICTA and its spinout Open Kernel Labs have recently performed such a formal verification of seL4, a member of the L4 microkernel family, proving functional correctness of the C implementation of the kernel.\nThis makes seL4 the first operating-system kernel which closes the gap between trust and trustworthiness, assuming the mathematical proof is free from error.\n\n\n*** TCB size ***\nDue to the aforementioned need to apply costly techniques such as formal verification or manual review, the size of the TCB has immediate consequences on the economics of the TCB assurance process, and the trustworthiness of the resulting product (in terms of the mathematical expectation of the number of bugs not found during the verification or review). In order to reduce costs and security risks, the TCB should therefore be kept as small as possible. This is a key argument in the debate preferring microkernels to monolithic kernels.\n\n== Examples ==\nAIX materializes the trusted computing base as an optional component in its install-time package management system."
    }
  },
  {
    "instruction": "OpenPuff's use of deniable steganography protects the communicating parties by hiding messages in a way that does not attract attention to themselves. This is in contrast to plainly visible encrypted messages, which may be incriminating in countries where encryption is illegal.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does OpenPuff's use of deniable steganography protect the communicating parties?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does OpenPuff's use of deniable steganography protect the communicating parties?",
      "answer": "OpenPuff's use of deniable steganography protects the communicating parties by hiding messages in a way that does not attract attention to themselves. This is in contrast to plainly visible encrypted messages, which may be incriminating in countries where encryption is illegal."
    }
  },
  {
    "instruction": "Microsoft released a cryptographic specification and open-source API implementation code for part of the U-Prove technology as a Community Technology Preview in March 2010.\n\nWrite a question about the text above.",
    "context": "",
    "output": "When did Microsoft make the U-Prove technology available as a Community Technology Preview?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "When did Microsoft make the U-Prove technology available as a Community Technology Preview?",
      "answer": "Microsoft released a cryptographic specification and open-source API implementation code for part of the U-Prove technology as a Community Technology Preview in March 2010."
    }
  },
  {
    "instruction": "Cyber defenders can use Lateral Movement to detect the location of attackers and respond more effectively to an attack. By monitoring network traffic and identifying patterns of movement, they can quickly identify and contain security breaches, reducing the damage caused by cyber attackers.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How can cyber defenders use Lateral Movement to their advantage in responding to cyber attacks?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How can cyber defenders use Lateral Movement to their advantage in responding to cyber attacks?",
      "answer": "Cyber defenders can use Lateral Movement to detect the location of attackers and respond more effectively to an attack. By monitoring network traffic and identifying patterns of movement, they can quickly identify and contain security breaches, reducing the damage caused by cyber attackers."
    }
  },
  {
    "instruction": "Context: Web of trust\n\n==Introduction==\nIn cryptography, a web of trust is a concept used in PGP, GnuPG, and other OpenPGP-compatible systems to establish the authenticity of the binding between a public key and its owner. Its decentralized trust model is an alternative to the centralized trust model of a public key infrastructure (PKI), which relies exclusively on a certificate authority (or a hierarchy of such). As with computer networks, there are many independent webs of trust, and any user (through their public key certificate) can be a part of, and a link between, multiple webs.\nThe web of trust concept was first put forth by PGP creator Phil Zimmermann in 1992 in the manual for PGP version 2.0:\n\nAs time goes on, you will accumulate keys from other people that you may want to designate as trusted introducers. Everyone else will each choose their own trusted introducers. And everyone will gradually accumulate and distribute with their key a collection of certifying signatures from other people, with the expectation that anyone receiving it will trust at least one or two of the signatures. This will cause the emergence of a decentralized fault-tolerant web of confidence for all public keys.\nNote the use of the word emergence in this context.  The web of trust makes use of the concept of emergence.\n\n== Operation of a web of trust ==\nAll OpenPGP-compliant implementations include a certificate vetting scheme to assist with this; its operation has been termed a web of trust. OpenPGP certificates (which include one or more public keys along with owner information) can be digitally signed by other users who, by that act, endorse the association of that public key with the person or entity listed in the certificate. This is commonly done at key signing parties.OpenPGP-compliant implementations also include a vote counting scheme which can be used to determine which public key \u2013 owner association a user will trust while using PGP. For instance, if three partially trusted endorsers have vouched for a certificate (and so its included public key \u2013 owner binding), or if one fully trusted endorser has done so, the association between owner and public key in that certificate will be trusted to be correct. The parameters are user-adjustable (e.g., no partials at all, or perhaps six partials) and can be completely bypassed if desired.\nThe scheme is flexible, unlike most public key infrastructure designs, and leaves trust decisions in the hands of individual users. It is not perfect and requires both caution and intelligent supervision by users. Essentially all PKI designs are less flexible and require users to follow the trust endorsement of the PKI generated, certificate authority (CA)-signed, certificates.\n\n\n*** Simplified explanation ***\nThere are two keys pertaining to a person: a public key which is shared openly and a private key that is withheld by the owner. The owner's private key will decrypt any information encrypted with its public key. In the web of trust, each user has a key ring with other people's public keys.\nSenders encrypt their information with the recipient's public key, and only the recipient's private key will decrypt it. Each sender then digitally signs the encrypted information with their private key.  When the recipient verifies the received encrypted information against the sender's public key, they can confirm that it is from the sender. Doing this will ensure that the encrypted information came from the specific user and has not been tampered with, and only the intended recipient can decrypt the information (because only they know their private key).\n\n== Contrast with typical PKI ==\nUnlike WOT, a typical X.509 PKI enables each certificate to be signed by a single party: a certificate authority (CA). The CA's certificate may itself be signed by a different CA, all the way up to a 'self-signed' root certificate. Root certificates must be available to those who use a lower-level CA certificate and so are typically distributed widely. They are for instance, distributed with such applications as browsers and email clients. In this way SSL/TLS-protected Web pages, email messages, etc. can be authenticated without requiring users to manually install root certificates. Applications commonly include over one hundred root certificates from dozens of PKIs, thus by default bestowing trust throughout the hierarchy of certificates which lead back to them.\nWOT favors the decentralization of trust anchors to prevent a single point of failure from compromising the CA hierarchy. A notable project that uses WOT against PKI to provide a framework for authentication in other areas of Internet is Monkeysphere utilities.\n\n== Problems ==\n\n\n*** Loss of private keys ***\nThe OpenPGP web of trust is essentially unaffected by such things as company failures, and has continued to function with little change. However, a related problem does occur: users, whether individuals or organizations, who lose track of a private key can no longer decrypt messages sent to them produced using the matching public key found in an OpenPGP certificate. Early PGP certificates did not include expiry dates, and those certificates had unlimited lives. Users had to prepare a signed cancellation certificate against the time when the matching private key was lost or compromised. One very prominent cryptographer is still getting messages encrypted using a public key for which he long ago lost track of the private key. They can't do much with those messages except discard them after notifying the sender that they were unreadable and requesting resending with a public key for which they still have the matching private key. Later PGP, and all OpenPGP compliant certificates include expiry dates which automatically preclude such troubles (eventually) when used sensibly. This problem can also be easily avoided by the use of \"designated revokers\", which were introduced in the early 1990s. A key owner may designate a third party that has permission to revoke the key owner's key (in case the key owner loses his own private key and thus loses the ability to revoke his own public key).\n\n\n*** Public key authenticity check ***\nA non-technical, social difficulty with a Web of Trust like the one built into PGP/OpenPGP type systems is that every web of trust without a central controller (e.g., a CA) depends on other users for trust. Those with new certificates (i.e., produced in the process of generating a new key pair) will not likely be readily trusted by other users' systems, that is by those they have not personally met, until they find enough endorsements for the new certificate. This is because many other Web of Trust users will have their certificate vetting set to require one or more fully trusted endorsers of an otherwise unknown certificate (or perhaps several partial endorsers) before using the public key in that certificate to prepare messages, believe signatures, etc.\nDespite the wide use of OpenPGP compliant systems and easy availability of on-line multiple key servers, it is possible in practice to be unable to readily find someone (or several people) to endorse a new certificate (e.g., by comparing physical identification to key owner information and then digitally signing the new certificate). Users in remote areas or undeveloped ones, for instance, may find other users scarce. And, if the other's certificate is also new (and with no or few endorsements from others), then its signature on any new certificate can offer only marginal benefit toward becoming trusted by still other parties' systems and so able to securely exchange messages with them. Key signing parties are a relatively popular mechanism to resolve this problem of finding other users who can install one's certificate in existing webs of trust by endorsing it. Websites also exist to facilitate the location of other OpenPGP users to arrange keysignings. The Gossamer Spider Web of Trust also makes key verification easier by linking OpenPGP users via a hierarchical style web of trust where end users can benefit by coincidental or determined trust of someone who is endorsed as an introducer, or by explicitly trusting GSWoT's top-level key minimally as a level 2 introducer (the top-level key endorses level 1 introducers).\nThe possibility of finding chains of certificates is often justified by the \"small world phenomenon\": given two individuals, it is often possible to find a short chain of people between them such that each person in the chain knows the preceding and following links. However, such a chain is not necessarily useful: the person encrypting an email or verifying a signature not only has to find a chain of signatures from their private key to their correspondent's, but also to trust each person of the chain to be honest and competent about signing keys (that is, they have to judge whether these people are likely to honestly follow the guidelines about verifying the identity of people before signing keys). This is a much stronger constraint.\nAnother obstacle is the requirement to physically meet with someone (for example, at a key signing party) to verify their identity and ownership of a public key and email address, which may involve travel expenses and scheduling constraints affecting both sides. A software user may need to verify hundreds of software components produced by thousands of developers located around the world. As the general population of software users cannot meet in person with all software developers to establish direct trust, they must instead rely on the comparatively slower propagation of indirect trust.Obtaining the PGP/GPG key of an author (or developer, publisher, etc.) from a public key server also presents risks, since the key server is a third-party middle-man, itself vulnerable to abuse or attacks. To avoid this risk, an author can instead choose to publish their public key on their own key server (i.e., a web server accessible through a domain name owned by them, and securely located in their private office or home) and require the use of HKPS-encrypted connections for the transmission of their public key. For details, see WOT Assisting Solutions below.\n\n== Strong set ==\nThe strong set refers to the largest collection of strongly connected PGP keys. This forms the basis for the global web of trust. Any two keys in the strong set have a path between them; while islands of sets of keys that only sign each other in a disconnected group can and do exist, only one member of that group needs to exchange signatures with the strong set for that group to also become a part of the strong set. The strong set had a size of about 55000 Keys at the beginning of the year 2015.\n\n== Mean shortest distance ==\n\nIn statistical analysis of the PGP/GnuPG/OpenPGP Web of trust the mean shortest distance (MSD) is one measurement of how \"trusted\" a given PGP key is within the strongly connected set of PGP keys that make up the Web of trust.\nMSD has become a common metric for analysis of sets of PGP keys. Very often you will see the MSD being calculated for a given subset of keys and compared with the global MSD which generally refers to the keys ranking within one of the larger key analyses of the global Web of trust.\n\n== WOT assisting solutions ==\nPhysically meeting with original developer or author, is always the best way to obtain and distribute and verify and trust PGP/GPG Keys with highest trust level, and will remain as the best level of best trustworthy way. Publishing of GPG/PGP full Key or full Key fingerprint on/with widely known (physical/paper-material based) book, by the original author/developer, is the 2nd best form of sharing trustworthy key with and for users. Before meeting a developer or author, users should research on their own on the developer or author in book library and via internet, and aware of developer's or author's photo, work, pub-key fingerprint, email-address, etc.\nHowever, it is not practical for millions of users who want to communicate or message securely to physically meet with each recipient users, and it is also not practical for millions of software users who need to physically meet with hundreds of software developers or authors, whose software or file signing PGP/GPG public Key they want to verify and trust and ultimately use in their computers. Therefore, one or more trusted third-party authority (TTPA) type of entity or group need to be available for users and be usable by users, and such entity/group need to be capable of providing trusted-verification or trust-delegation services for millions of users around the world, at any time.\nPractically, to verify any downloaded or received content or data or email or file's authenticity, a user need to verify their downloaded main content or main data/email or main file's PGP/GPG signature code/file (ASC, SIG). So users would need to use original developer's or original author's trustworthy and verified public-key, or users would need to use trustworthy file-signing public-key trusted-by the original owner of that public-key. And to really trust a specific PGP/GPG key, users would need to physically meet with every specific original author or developer, or users would need to physically meet with the original-releaser of file-signing pub-key, or, users would need to find another alternative trustworthy user, who is in trusted-chain of WOT (aka, another user or another developer or another author, who is trusted by that very specific original author or developer), and then physically meet with that person, to verify their real ID with his/her PGP/GPG key (and also provide your own ID and key to the other user, so that both side can sign/certify and trust each other's PGP/GPG key). Whether a software is popular or not, software users are usually located around the world in different locations. It is physically not possible for an original author or developer or file-releaser to provide public-key or trust or ID verification services to millions of users. Neither is it practical for millions of software users to physically meet with each and every software or every software-library or every piece of code's developer or author or releaser, which they will (use or) need to use in their computers. Even with multiple trusted people/person (by original-author) in trusted-chain from WOT, its still not physically or practically possible for every developer or author to meet with every other users, and it is also not possible for every users to meet with hundreds of developers whose software they will be using or working on. When this decentralized hierarchy based WoT chain model will become popular and used by most nearby users, only then physical meeting and pub-key certify and sign procedure of WoT will be easier.\nA few solutions are: original author/developer need to first set a trust-level to sign/certify their own file-signing key. Then updated public-keys and updated file-signing public-keys must also have to be published and distributed (or made accessible) to users, via online secure and encrypted mediums, so that any user from any location in world, can get the correct and trusted and unmodified public-key. To make sure that each users are getting the correct and trusted public-keys and signed-code/file, original dev/author or original-releaser must publish their updated public-keys on their own key server and force HKPS encrypted connection usage, or publish their updated and full public-keys (and signed-code/file) on their own HTTPS encrypted webpage, under their own web server, from their own primary domain website, (not-from any sub-domains which are located in external-servers, not-from any mirror, not-from any external/shared forum/wiki etc website servers, not-from any public or external/shared cloud or hosting service servers), and must have to be located and kept securely inside their own premises: own-home, own-home-office, or own-office. In that way, those small pieces of original keys/code, will travel intact through internet and will remain unmodified during transit (because of encrypted connection) and will reach destination without being eavesdropped or modified, into user's side, and can be treated as trustworthy public-keys because of single or multi channel TTPA based verification. When a public-key is obtained (from original developer's own web-server) via more than one TTPA (trusted third party authority) based secured, verified and encrypted connection, then it is more trustworthy.\nWhen original public-keys/signed-codes are shown in original dev's or author's own web server or key server, over encrypted connection or encrypted webpage, then any other files, data or content can be transferred over any type of non-encrypted connection, like: HTTP/FTP etc from any sub-domain server or from any mirror or from any shared cloud/hosting servers, because, non-encrypted connection based downloaded items/data/files can be authenticated later, by using the original public-keys/signed-codes, which were obtained from the original author's/developer's own server over secured, encrypted, and trusted (aka, verified) connection/channels.\nUsing encrypted connection to transfer keys or signed/signature code/files, allow software users to delegate their trust with a PKI TTPA (trusted third party authority), like public CA (Certificate Authority), to help in providing trusted connection in between the original developer/author's web server, and millions of worldwide users' computers, at any time.\nWhen the original author/developer's domain-name and name-server is signed by DNSSEC, and when used SSL/TLS public certificate is declared/shown in TLSA/DANE DNSSec DNS resource-record, (and when SSL/TLS Certs in the trust chain are pinned and used via HPKP technique by web servers), then a web-server's webpage or data can also be verified via another PKI TTPA: DNSSEC and DNS namespace maintainer ICANN, other than a public CA. DNSSEC is another form of PGP/GPG WOT but for name-servers; it creates a trusted-chain for name-servers first (instead of people/person), and then people/person's PGP/GPG Keys and fingerprints can also be added into a server's DNSSEC DNS records. So any users who want to communicate securely (or any software users), can effectively get/receive their data/key/code/webpage etc. verified (aka, authenticated) via two (aka, dual/double) trusted PKI TTPAs/Channels at the same time: ICANN (DNSSEC) and CA (SSL/TLS Certificate). So PGP/GPG key/signed-code data (or file) can be trusted, when such solutions and techniques are used: HKPS, HKPS+DNSSEC+DANE, HTTPS, HTTPS+HPKP or HTTPS+HPKP+DNSSEC+DANE.\nIf a vast number of user's group create their own new DLV based DNSSEC registry, and if users use that new DLV (along with ICANN-DNSSEC) root-key in their own local DNSSEC-based DNS Resolver/Server, and if domain-owners also use it for additional signing of their own domain-names, then there can be a new third TTPA. In such case, any PGP/GPG Key/signed-code data or a webpage or web data can be three/triple-channel verified. ISC's DLV itself can be used as a third TTPA as its still used widely and active, so availability of another new DLV will become fourth TTPA.\nQuestion: How does the web of trust model address the issue of trust in the absence of a central controller?\n\nAnswer:",
    "context": "",
    "output": "In the web of trust model, trust is established through a decentralized network of users who digitally sign each other's public keys. Users must find enough endorsements for their certificates, typically from one or more fully trusted endorsers, before other users will trust their public keys. This allows for the emergence of a web of confidence for all public keys.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does the web of trust model address the issue of trust in the absence of a central controller?",
      "answer": "In the web of trust model, trust is established through a decentralized network of users who digitally sign each other's public keys. Users must find enough endorsements for their certificates, typically from one or more fully trusted endorsers, before other users will trust their public keys. This allows for the emergence of a web of confidence for all public keys.",
      "context": "Web of trust\n\n==Introduction==\nIn cryptography, a web of trust is a concept used in PGP, GnuPG, and other OpenPGP-compatible systems to establish the authenticity of the binding between a public key and its owner. Its decentralized trust model is an alternative to the centralized trust model of a public key infrastructure (PKI), which relies exclusively on a certificate authority (or a hierarchy of such). As with computer networks, there are many independent webs of trust, and any user (through their public key certificate) can be a part of, and a link between, multiple webs.\nThe web of trust concept was first put forth by PGP creator Phil Zimmermann in 1992 in the manual for PGP version 2.0:\n\nAs time goes on, you will accumulate keys from other people that you may want to designate as trusted introducers. Everyone else will each choose their own trusted introducers. And everyone will gradually accumulate and distribute with their key a collection of certifying signatures from other people, with the expectation that anyone receiving it will trust at least one or two of the signatures. This will cause the emergence of a decentralized fault-tolerant web of confidence for all public keys.\nNote the use of the word emergence in this context.  The web of trust makes use of the concept of emergence.\n\n== Operation of a web of trust ==\nAll OpenPGP-compliant implementations include a certificate vetting scheme to assist with this; its operation has been termed a web of trust. OpenPGP certificates (which include one or more public keys along with owner information) can be digitally signed by other users who, by that act, endorse the association of that public key with the person or entity listed in the certificate. This is commonly done at key signing parties.OpenPGP-compliant implementations also include a vote counting scheme which can be used to determine which public key \u2013 owner association a user will trust while using PGP. For instance, if three partially trusted endorsers have vouched for a certificate (and so its included public key \u2013 owner binding), or if one fully trusted endorser has done so, the association between owner and public key in that certificate will be trusted to be correct. The parameters are user-adjustable (e.g., no partials at all, or perhaps six partials) and can be completely bypassed if desired.\nThe scheme is flexible, unlike most public key infrastructure designs, and leaves trust decisions in the hands of individual users. It is not perfect and requires both caution and intelligent supervision by users. Essentially all PKI designs are less flexible and require users to follow the trust endorsement of the PKI generated, certificate authority (CA)-signed, certificates.\n\n\n*** Simplified explanation ***\nThere are two keys pertaining to a person: a public key which is shared openly and a private key that is withheld by the owner. The owner's private key will decrypt any information encrypted with its public key. In the web of trust, each user has a key ring with other people's public keys.\nSenders encrypt their information with the recipient's public key, and only the recipient's private key will decrypt it. Each sender then digitally signs the encrypted information with their private key.  When the recipient verifies the received encrypted information against the sender's public key, they can confirm that it is from the sender. Doing this will ensure that the encrypted information came from the specific user and has not been tampered with, and only the intended recipient can decrypt the information (because only they know their private key).\n\n== Contrast with typical PKI ==\nUnlike WOT, a typical X.509 PKI enables each certificate to be signed by a single party: a certificate authority (CA). The CA's certificate may itself be signed by a different CA, all the way up to a 'self-signed' root certificate. Root certificates must be available to those who use a lower-level CA certificate and so are typically distributed widely. They are for instance, distributed with such applications as browsers and email clients. In this way SSL/TLS-protected Web pages, email messages, etc. can be authenticated without requiring users to manually install root certificates. Applications commonly include over one hundred root certificates from dozens of PKIs, thus by default bestowing trust throughout the hierarchy of certificates which lead back to them.\nWOT favors the decentralization of trust anchors to prevent a single point of failure from compromising the CA hierarchy. A notable project that uses WOT against PKI to provide a framework for authentication in other areas of Internet is Monkeysphere utilities.\n\n== Problems ==\n\n\n*** Loss of private keys ***\nThe OpenPGP web of trust is essentially unaffected by such things as company failures, and has continued to function with little change. However, a related problem does occur: users, whether individuals or organizations, who lose track of a private key can no longer decrypt messages sent to them produced using the matching public key found in an OpenPGP certificate. Early PGP certificates did not include expiry dates, and those certificates had unlimited lives. Users had to prepare a signed cancellation certificate against the time when the matching private key was lost or compromised. One very prominent cryptographer is still getting messages encrypted using a public key for which he long ago lost track of the private key. They can't do much with those messages except discard them after notifying the sender that they were unreadable and requesting resending with a public key for which they still have the matching private key. Later PGP, and all OpenPGP compliant certificates include expiry dates which automatically preclude such troubles (eventually) when used sensibly. This problem can also be easily avoided by the use of \"designated revokers\", which were introduced in the early 1990s. A key owner may designate a third party that has permission to revoke the key owner's key (in case the key owner loses his own private key and thus loses the ability to revoke his own public key).\n\n\n*** Public key authenticity check ***\nA non-technical, social difficulty with a Web of Trust like the one built into PGP/OpenPGP type systems is that every web of trust without a central controller (e.g., a CA) depends on other users for trust. Those with new certificates (i.e., produced in the process of generating a new key pair) will not likely be readily trusted by other users' systems, that is by those they have not personally met, until they find enough endorsements for the new certificate. This is because many other Web of Trust users will have their certificate vetting set to require one or more fully trusted endorsers of an otherwise unknown certificate (or perhaps several partial endorsers) before using the public key in that certificate to prepare messages, believe signatures, etc.\nDespite the wide use of OpenPGP compliant systems and easy availability of on-line multiple key servers, it is possible in practice to be unable to readily find someone (or several people) to endorse a new certificate (e.g., by comparing physical identification to key owner information and then digitally signing the new certificate). Users in remote areas or undeveloped ones, for instance, may find other users scarce. And, if the other's certificate is also new (and with no or few endorsements from others), then its signature on any new certificate can offer only marginal benefit toward becoming trusted by still other parties' systems and so able to securely exchange messages with them. Key signing parties are a relatively popular mechanism to resolve this problem of finding other users who can install one's certificate in existing webs of trust by endorsing it. Websites also exist to facilitate the location of other OpenPGP users to arrange keysignings. The Gossamer Spider Web of Trust also makes key verification easier by linking OpenPGP users via a hierarchical style web of trust where end users can benefit by coincidental or determined trust of someone who is endorsed as an introducer, or by explicitly trusting GSWoT's top-level key minimally as a level 2 introducer (the top-level key endorses level 1 introducers).\nThe possibility of finding chains of certificates is often justified by the \"small world phenomenon\": given two individuals, it is often possible to find a short chain of people between them such that each person in the chain knows the preceding and following links. However, such a chain is not necessarily useful: the person encrypting an email or verifying a signature not only has to find a chain of signatures from their private key to their correspondent's, but also to trust each person of the chain to be honest and competent about signing keys (that is, they have to judge whether these people are likely to honestly follow the guidelines about verifying the identity of people before signing keys). This is a much stronger constraint.\nAnother obstacle is the requirement to physically meet with someone (for example, at a key signing party) to verify their identity and ownership of a public key and email address, which may involve travel expenses and scheduling constraints affecting both sides. A software user may need to verify hundreds of software components produced by thousands of developers located around the world. As the general population of software users cannot meet in person with all software developers to establish direct trust, they must instead rely on the comparatively slower propagation of indirect trust.Obtaining the PGP/GPG key of an author (or developer, publisher, etc.) from a public key server also presents risks, since the key server is a third-party middle-man, itself vulnerable to abuse or attacks. To avoid this risk, an author can instead choose to publish their public key on their own key server (i.e., a web server accessible through a domain name owned by them, and securely located in their private office or home) and require the use of HKPS-encrypted connections for the transmission of their public key. For details, see WOT Assisting Solutions below.\n\n== Strong set ==\nThe strong set refers to the largest collection of strongly connected PGP keys. This forms the basis for the global web of trust. Any two keys in the strong set have a path between them; while islands of sets of keys that only sign each other in a disconnected group can and do exist, only one member of that group needs to exchange signatures with the strong set for that group to also become a part of the strong set. The strong set had a size of about 55000 Keys at the beginning of the year 2015.\n\n== Mean shortest distance ==\n\nIn statistical analysis of the PGP/GnuPG/OpenPGP Web of trust the mean shortest distance (MSD) is one measurement of how \"trusted\" a given PGP key is within the strongly connected set of PGP keys that make up the Web of trust.\nMSD has become a common metric for analysis of sets of PGP keys. Very often you will see the MSD being calculated for a given subset of keys and compared with the global MSD which generally refers to the keys ranking within one of the larger key analyses of the global Web of trust.\n\n== WOT assisting solutions ==\nPhysically meeting with original developer or author, is always the best way to obtain and distribute and verify and trust PGP/GPG Keys with highest trust level, and will remain as the best level of best trustworthy way. Publishing of GPG/PGP full Key or full Key fingerprint on/with widely known (physical/paper-material based) book, by the original author/developer, is the 2nd best form of sharing trustworthy key with and for users. Before meeting a developer or author, users should research on their own on the developer or author in book library and via internet, and aware of developer's or author's photo, work, pub-key fingerprint, email-address, etc.\nHowever, it is not practical for millions of users who want to communicate or message securely to physically meet with each recipient users, and it is also not practical for millions of software users who need to physically meet with hundreds of software developers or authors, whose software or file signing PGP/GPG public Key they want to verify and trust and ultimately use in their computers. Therefore, one or more trusted third-party authority (TTPA) type of entity or group need to be available for users and be usable by users, and such entity/group need to be capable of providing trusted-verification or trust-delegation services for millions of users around the world, at any time.\nPractically, to verify any downloaded or received content or data or email or file's authenticity, a user need to verify their downloaded main content or main data/email or main file's PGP/GPG signature code/file (ASC, SIG). So users would need to use original developer's or original author's trustworthy and verified public-key, or users would need to use trustworthy file-signing public-key trusted-by the original owner of that public-key. And to really trust a specific PGP/GPG key, users would need to physically meet with every specific original author or developer, or users would need to physically meet with the original-releaser of file-signing pub-key, or, users would need to find another alternative trustworthy user, who is in trusted-chain of WOT (aka, another user or another developer or another author, who is trusted by that very specific original author or developer), and then physically meet with that person, to verify their real ID with his/her PGP/GPG key (and also provide your own ID and key to the other user, so that both side can sign/certify and trust each other's PGP/GPG key). Whether a software is popular or not, software users are usually located around the world in different locations. It is physically not possible for an original author or developer or file-releaser to provide public-key or trust or ID verification services to millions of users. Neither is it practical for millions of software users to physically meet with each and every software or every software-library or every piece of code's developer or author or releaser, which they will (use or) need to use in their computers. Even with multiple trusted people/person (by original-author) in trusted-chain from WOT, its still not physically or practically possible for every developer or author to meet with every other users, and it is also not possible for every users to meet with hundreds of developers whose software they will be using or working on. When this decentralized hierarchy based WoT chain model will become popular and used by most nearby users, only then physical meeting and pub-key certify and sign procedure of WoT will be easier.\nA few solutions are: original author/developer need to first set a trust-level to sign/certify their own file-signing key. Then updated public-keys and updated file-signing public-keys must also have to be published and distributed (or made accessible) to users, via online secure and encrypted mediums, so that any user from any location in world, can get the correct and trusted and unmodified public-key. To make sure that each users are getting the correct and trusted public-keys and signed-code/file, original dev/author or original-releaser must publish their updated public-keys on their own key server and force HKPS encrypted connection usage, or publish their updated and full public-keys (and signed-code/file) on their own HTTPS encrypted webpage, under their own web server, from their own primary domain website, (not-from any sub-domains which are located in external-servers, not-from any mirror, not-from any external/shared forum/wiki etc website servers, not-from any public or external/shared cloud or hosting service servers), and must have to be located and kept securely inside their own premises: own-home, own-home-office, or own-office. In that way, those small pieces of original keys/code, will travel intact through internet and will remain unmodified during transit (because of encrypted connection) and will reach destination without being eavesdropped or modified, into user's side, and can be treated as trustworthy public-keys because of single or multi channel TTPA based verification. When a public-key is obtained (from original developer's own web-server) via more than one TTPA (trusted third party authority) based secured, verified and encrypted connection, then it is more trustworthy.\nWhen original public-keys/signed-codes are shown in original dev's or author's own web server or key server, over encrypted connection or encrypted webpage, then any other files, data or content can be transferred over any type of non-encrypted connection, like: HTTP/FTP etc from any sub-domain server or from any mirror or from any shared cloud/hosting servers, because, non-encrypted connection based downloaded items/data/files can be authenticated later, by using the original public-keys/signed-codes, which were obtained from the original author's/developer's own server over secured, encrypted, and trusted (aka, verified) connection/channels.\nUsing encrypted connection to transfer keys or signed/signature code/files, allow software users to delegate their trust with a PKI TTPA (trusted third party authority), like public CA (Certificate Authority), to help in providing trusted connection in between the original developer/author's web server, and millions of worldwide users' computers, at any time.\nWhen the original author/developer's domain-name and name-server is signed by DNSSEC, and when used SSL/TLS public certificate is declared/shown in TLSA/DANE DNSSec DNS resource-record, (and when SSL/TLS Certs in the trust chain are pinned and used via HPKP technique by web servers), then a web-server's webpage or data can also be verified via another PKI TTPA: DNSSEC and DNS namespace maintainer ICANN, other than a public CA. DNSSEC is another form of PGP/GPG WOT but for name-servers; it creates a trusted-chain for name-servers first (instead of people/person), and then people/person's PGP/GPG Keys and fingerprints can also be added into a server's DNSSEC DNS records. So any users who want to communicate securely (or any software users), can effectively get/receive their data/key/code/webpage etc. verified (aka, authenticated) via two (aka, dual/double) trusted PKI TTPAs/Channels at the same time: ICANN (DNSSEC) and CA (SSL/TLS Certificate). So PGP/GPG key/signed-code data (or file) can be trusted, when such solutions and techniques are used: HKPS, HKPS+DNSSEC+DANE, HTTPS, HTTPS+HPKP or HTTPS+HPKP+DNSSEC+DANE.\nIf a vast number of user's group create their own new DLV based DNSSEC registry, and if users use that new DLV (along with ICANN-DNSSEC) root-key in their own local DNSSEC-based DNS Resolver/Server, and if domain-owners also use it for additional signing of their own domain-names, then there can be a new third TTPA. In such case, any PGP/GPG Key/signed-code data or a webpage or web data can be three/triple-channel verified. ISC's DLV itself can be used as a third TTPA as its still used widely and active, so availability of another new DLV will become fourth TTPA."
    }
  },
  {
    "instruction": "Singularity addresses this need by providing native support for high-performance interconnects, PCIe-attached devices, and Open MPI library, enabling seamless integration, efficient resource utilization, and reproducible environments in HPC and scientific computing environments.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does Singularity address the need for using containers to move applications from system to system in the scientific computing and HPC world?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does Singularity address the need for using containers to move applications from system to system in the scientific computing and HPC world?",
      "answer": "Singularity addresses this need by providing native support for high-performance interconnects, PCIe-attached devices, and Open MPI library, enabling seamless integration, efficient resource utilization, and reproducible environments in HPC and scientific computing environments."
    }
  },
  {
    "instruction": "The Advisory Board provides strategic and other input to AMTSO's Board of Directors, contributing to the organization's overall direction and decision-making process. The Advisory Board is a crucial component of AMTSO's organizational structure, ensuring that a diverse range of perspectives and expertise are considered.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the role of AMTSO's Advisory Board in the organization's decision-making process?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the role of AMTSO's Advisory Board in the organization's decision-making process?",
      "answer": "The Advisory Board provides strategic and other input to AMTSO's Board of Directors, contributing to the organization's overall direction and decision-making process. The Advisory Board is a crucial component of AMTSO's organizational structure, ensuring that a diverse range of perspectives and expertise are considered."
    }
  },
  {
    "instruction": "Larger SEO providers depend on search engine scraping, which involves automating the process of extracting URLs, descriptions, or other information from search engines like Google, Bing, Yahoo, or Yandex. This is achieved through specialized tools or scripts that mimic human behavior while navigating and extracting data from these search engines.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How do larger SEO providers regularly scrape keywords from search engines, especially Google, to monitor the competitive position of their customers' websites for relevant keywords or their indexing status?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How do larger SEO providers regularly scrape keywords from search engines, especially Google, to monitor the competitive position of their customers' websites for relevant keywords or their indexing status?",
      "answer": "Larger SEO providers depend on search engine scraping, which involves automating the process of extracting URLs, descriptions, or other information from search engines like Google, Bing, Yahoo, or Yandex. This is achieved through specialized tools or scripts that mimic human behavior while navigating and extracting data from these search engines."
    }
  },
  {
    "instruction": "The headquarters of NetCentrics Corporation are located inside the Dulles Technology Corridor of NoVA, providing the company with a strategic location in the heart of the U.S. federal government's technology hub.\n\nWrite a question about the text above.",
    "context": "",
    "output": "Where are the headquarters of NetCentrics located?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "Where are the headquarters of NetCentrics located?",
      "answer": "The headquarters of NetCentrics Corporation are located inside the Dulles Technology Corridor of NoVA, providing the company with a strategic location in the heart of the U.S. federal government's technology hub."
    }
  },
  {
    "instruction": "Context: Session fixation\n\n==Introduction==\nIn computer network security, session fixation attacks attempt to exploit the vulnerability of a system that allows one person to fixate (find or set) another person's session identifier.  Most session fixation attacks are web based, and most rely on session identifiers being accepted from URLs (query string) or POST data.\n\n\n\n== Attack scenarios ==\nAlice has an account at the bank http://unsafe.example.com/\nMallory intends to target Alice's money from her bank.\nAlice has a reasonable level of trust in Mallory, and will visit links Mallory sends her.\n\n\n*** A simple attack scenario ***\nStraightforward scenario:\n\nMallory has determined that http://unsafe.example.com/ accepts any session identifier, accepts session identifiers from query strings and has no security validation. http://unsafe.example.com/ is thus not secure.\nMallory sends Alice an e-mail: \"Hey, check this out, there is a cool new account summary feature on our bank, http://unsafe.example.com/?SID\n\n== Countermeasures ==\n\n\n*** Do not accept session identifiers from GET / POST variables ***\nSession identifiers in URL (query string, GET variables) or POST variables are not recommended as they simplify this attack \u2013 it is easy to make links or forms that set GET / POST variables.\n\nThe SID is leaked to other people as users cut & paste \"interesting links\" from the address bar into chats, forums, communities, etc.\nThe SID is stored in many places (browser history log, web server log, proxy logs, ...)Note: Cookies are shared between tabs and popped up browser windows. If your system requires to be hit with the same domain (www.example.com/?code\n\n== Defense in depth ==\n\nDefense in depth is to combine several countermeasures. The idea is simple: if one obstacle is trivial to overcome, several obstacles could be very hard to overcome.\nA defense in depth strategy could involve:\n\nEnable HTTPS (to protect against other problems)\nCorrect configuration (do not accept external SIDs, set time-out, etc.)\nPerform session_regeneration, support log-out, etc.HTTP referrers are not passed with SSL/TLS (HTTPS).\nThe following PHP script demonstrates several such countermeasures combined in a defense in depth manner:\n\nNote that this code checks the current REMOTE_ADDR (the user's IP address) and User-agent against the REMOTE_ADDR and User-agent of the previous request. This might be inconvenient for some sites as discussed above.\nQuestion: How do HTTP referrers work in the context of session fixation attacks?. Whats the answer?",
    "context": "",
    "output": "HTTP referrers are not passed with SSL/TLS (HTTPS) in the context of session fixation attacks. This means that if a website uses HTTPS, attackers cannot use the HTTP referrer to track the victim's movements between websites, making it more difficult for them to launch a session fixation attack.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How do HTTP referrers work in the context of session fixation attacks?",
      "answer": "HTTP referrers are not passed with SSL/TLS (HTTPS) in the context of session fixation attacks. This means that if a website uses HTTPS, attackers cannot use the HTTP referrer to track the victim's movements between websites, making it more difficult for them to launch a session fixation attack.",
      "context": "Session fixation\n\n==Introduction==\nIn computer network security, session fixation attacks attempt to exploit the vulnerability of a system that allows one person to fixate (find or set) another person's session identifier.  Most session fixation attacks are web based, and most rely on session identifiers being accepted from URLs (query string) or POST data.\n\n\n\n== Attack scenarios ==\nAlice has an account at the bank http://unsafe.example.com/\nMallory intends to target Alice's money from her bank.\nAlice has a reasonable level of trust in Mallory, and will visit links Mallory sends her.\n\n\n*** A simple attack scenario ***\nStraightforward scenario:\n\nMallory has determined that http://unsafe.example.com/ accepts any session identifier, accepts session identifiers from query strings and has no security validation. http://unsafe.example.com/ is thus not secure.\nMallory sends Alice an e-mail: \"Hey, check this out, there is a cool new account summary feature on our bank, http://unsafe.example.com/?SID\n\n== Countermeasures ==\n\n\n*** Do not accept session identifiers from GET / POST variables ***\nSession identifiers in URL (query string, GET variables) or POST variables are not recommended as they simplify this attack \u2013 it is easy to make links or forms that set GET / POST variables.\n\nThe SID is leaked to other people as users cut & paste \"interesting links\" from the address bar into chats, forums, communities, etc.\nThe SID is stored in many places (browser history log, web server log, proxy logs, ...)Note: Cookies are shared between tabs and popped up browser windows. If your system requires to be hit with the same domain (www.example.com/?code\n\n== Defense in depth ==\n\nDefense in depth is to combine several countermeasures. The idea is simple: if one obstacle is trivial to overcome, several obstacles could be very hard to overcome.\nA defense in depth strategy could involve:\n\nEnable HTTPS (to protect against other problems)\nCorrect configuration (do not accept external SIDs, set time-out, etc.)\nPerform session_regeneration, support log-out, etc.HTTP referrers are not passed with SSL/TLS (HTTPS).\nThe following PHP script demonstrates several such countermeasures combined in a defense in depth manner:\n\nNote that this code checks the current REMOTE_ADDR (the user's IP address) and User-agent against the REMOTE_ADDR and User-agent of the previous request. This might be inconvenient for some sites as discussed above."
    }
  },
  {
    "instruction": "According to the IEEE Annals of the History of Computing, Willis Ware's 1967 Spring Joint Computer Conference session and the 1970 Ware report marked the start of the field of computer security.\n\nWrite a question about the text above.",
    "context": "",
    "output": "According to the IEEE Annals of the History of Computing, what marked the start of the field of computer security?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "According to the IEEE Annals of the History of Computing, what marked the start of the field of computer security?",
      "answer": "According to the IEEE Annals of the History of Computing, Willis Ware's 1967 Spring Joint Computer Conference session and the 1970 Ware report marked the start of the field of computer security."
    }
  },
  {
    "instruction": "Context: Apache SpamAssassin\n\n==Introduction==\nApache SpamAssassin is a computer program used for e-mail spam filtering. It uses a variety of spam-detection techniques, including DNS and fuzzy checksum techniques, Bayesian filtering, external programs, blacklists and online databases. It is released under the Apache License 2.0 and is a part of the Apache Foundation since 2004.\nThe program can be integrated with the mail server to automatically filter all mail for a site. It can also be run by individual users on their own mailbox and integrates with several mail programs. Apache SpamAssassin is highly configurable; if used as a system-wide filter it can still be configured to support per-user preferences.\n\n== Methods of usage ==\nApache SpamAssassin is a Perl-based application (Mail::SpamAssassin in CPAN) which is usually used to filter all incoming mail for one or several users. It can be run as a standalone application or as a subprogram of another application (such as a Milter, SA-Exim, Exiscan, MailScanner, MIMEDefang, Amavis) or as a client (spamc) that communicates with a daemon (spamd). The client/server or embedded mode of operation has performance benefits, but under certain circumstances may introduce additional security risks.\nTypically either variant of the application is set up in a generic mail filter program, or it is called directly from a mail user agent that supports this, whenever new mail arrives. Mail filter programs such as procmail can be made to pipe all incoming mail through Apache SpamAssassin with an adjustment to a user's procmailrc file.\n\n== Operation ==\nApache SpamAssassin comes with a large set of rules which are applied to determine whether an email is spam or not. Most rules are based on regular expressions that are matched against the body or header fields of the message, but Apache SpamAssassin also employs a number of other spam-fighting techniques. The rules are called \"tests\" in the SpamAssassin documentation.\nEach test has a score value that will be assigned to a message if it matches the test's criteria. The scores can be positive or negative, with positive values indicating \"spam\" and negative \"ham\" (non-spam messages). A message is matched against all tests and Apache SpamAssassin combines the results into a global score which is assigned to the message. The higher the score, the higher the probability that the message is spam.\nApache SpamAssassin has an internal (configurable) score threshold to classify a message as spam. Usually a message will only be considered as spam if it matches multiple criteria; matching just a single test will not usually be enough to reach the threshold.\nIf Apache SpamAssassin considers a message to be spam, it can be further rewritten. In the default configuration, the content of the mail is appended as a MIME attachment, with a brief excerpt in the message body, and a description of the tests which resulted in the mail being classified as spam. If the score is lower than the defined settings, by default the information about the tests passed and total score is still added to the email headers and can be used in post-processing for less severe actions, such as tagging the mail as suspicious.\nApache SpamAssassin allows for a per-user configuration of its behavior, even if installed as system-wide service; the configuration can be read from a file or a database.  In their configuration users can specify individuals whose emails are never considered spam, or change the scores for certain rules. The user can also define a list of languages which they want to receive mail in, and Apache SpamAssassin then assigns a higher score to all mails that appear to be written in another language.\nApache SpamAssassin is based on heuristics (pattern recognition), and such software exhibits false positives and false negatives.\n\n== Network-based filtering methods ==\nApache SpamAssassin also supports:\n\nDNS-based blacklists and DNS-based whitelists\nFuzzy-checksum-based spam detection filters such as the Distributed Checksum Clearinghouse, Vipul's Razor and the Cloudmark Authority plugins (commercial)\nHashcash email stamps based on proof-of-work\nSender Policy Framework and DomainKeys Identified Mail\nURI blacklists such as SURBL or URIBL which track spam websitesMore methods can be added reasonably easily by writing a Perl plug-in for Apache SpamAssassin.\n\n== Bayesian filtering ==\nApache SpamAssassin reinforces its rules through Bayesian filtering where a user or administrator \"feeds\" examples of good (ham) and bad (spam) into the filter in order to learn the difference between the two. For this purpose, Apache SpamAssassin provides the command-line tool sa-learn, which can be instructed to learn a single mail or an entire mailbox as either ham or spam.\nTypically, the user will move unrecognized spam to a separate folder, and then run sa-learn on the folder of non-spam and on the folder of spam separately. Alternatively, if the mail user agent supports it, sa-learn can be called for individual emails. Regardless of the method used to perform the learning, SpamAssassin's Bayesian test will help score future e-mails based on this learning to improve the accuracy.\n\n== Licensing ==\nApache SpamAssassin is free/open source software, licensed under the Apache License 2.0. Versions prior to 3.0 are dual-licensed under the Artistic License and the GNU General Public License.\n\n== sa-compile ==\nsa-compile is a utility distributed with Apache SpamAssassin that compiles a SpamAssassin ruleset into a deterministic finite automaton that allows Apache SpamAssassin to use processor power more efficiently.\n\n== Testing Apache SpamAssassin ==\nApache SpamAssassin is designed to trigger on the GTUBE, a 68-byte string similar to the antivirus EICAR test file. If this string is inserted in an RFC 5322 formatted message and passed through the Apache SpamAssassin engine, Apache SpamAssassin will trigger with a weight of 1000.\nQuestion: What is the purpose of the sa-compile utility in Apache SpamAssassin?\n\nAnswer:",
    "context": "",
    "output": "The sa-compile utility is distributed with Apache SpamAssassin to compile a SpamAssassin ruleset into a deterministic finite automaton that allows Apache SpamAssassin to use processor power more efficiently.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the purpose of the sa-compile utility in Apache SpamAssassin?",
      "answer": "The sa-compile utility is distributed with Apache SpamAssassin to compile a SpamAssassin ruleset into a deterministic finite automaton that allows Apache SpamAssassin to use processor power more efficiently.",
      "context": "Apache SpamAssassin\n\n==Introduction==\nApache SpamAssassin is a computer program used for e-mail spam filtering. It uses a variety of spam-detection techniques, including DNS and fuzzy checksum techniques, Bayesian filtering, external programs, blacklists and online databases. It is released under the Apache License 2.0 and is a part of the Apache Foundation since 2004.\nThe program can be integrated with the mail server to automatically filter all mail for a site. It can also be run by individual users on their own mailbox and integrates with several mail programs. Apache SpamAssassin is highly configurable; if used as a system-wide filter it can still be configured to support per-user preferences.\n\n== Methods of usage ==\nApache SpamAssassin is a Perl-based application (Mail::SpamAssassin in CPAN) which is usually used to filter all incoming mail for one or several users. It can be run as a standalone application or as a subprogram of another application (such as a Milter, SA-Exim, Exiscan, MailScanner, MIMEDefang, Amavis) or as a client (spamc) that communicates with a daemon (spamd). The client/server or embedded mode of operation has performance benefits, but under certain circumstances may introduce additional security risks.\nTypically either variant of the application is set up in a generic mail filter program, or it is called directly from a mail user agent that supports this, whenever new mail arrives. Mail filter programs such as procmail can be made to pipe all incoming mail through Apache SpamAssassin with an adjustment to a user's procmailrc file.\n\n== Operation ==\nApache SpamAssassin comes with a large set of rules which are applied to determine whether an email is spam or not. Most rules are based on regular expressions that are matched against the body or header fields of the message, but Apache SpamAssassin also employs a number of other spam-fighting techniques. The rules are called \"tests\" in the SpamAssassin documentation.\nEach test has a score value that will be assigned to a message if it matches the test's criteria. The scores can be positive or negative, with positive values indicating \"spam\" and negative \"ham\" (non-spam messages). A message is matched against all tests and Apache SpamAssassin combines the results into a global score which is assigned to the message. The higher the score, the higher the probability that the message is spam.\nApache SpamAssassin has an internal (configurable) score threshold to classify a message as spam. Usually a message will only be considered as spam if it matches multiple criteria; matching just a single test will not usually be enough to reach the threshold.\nIf Apache SpamAssassin considers a message to be spam, it can be further rewritten. In the default configuration, the content of the mail is appended as a MIME attachment, with a brief excerpt in the message body, and a description of the tests which resulted in the mail being classified as spam. If the score is lower than the defined settings, by default the information about the tests passed and total score is still added to the email headers and can be used in post-processing for less severe actions, such as tagging the mail as suspicious.\nApache SpamAssassin allows for a per-user configuration of its behavior, even if installed as system-wide service; the configuration can be read from a file or a database.  In their configuration users can specify individuals whose emails are never considered spam, or change the scores for certain rules. The user can also define a list of languages which they want to receive mail in, and Apache SpamAssassin then assigns a higher score to all mails that appear to be written in another language.\nApache SpamAssassin is based on heuristics (pattern recognition), and such software exhibits false positives and false negatives.\n\n== Network-based filtering methods ==\nApache SpamAssassin also supports:\n\nDNS-based blacklists and DNS-based whitelists\nFuzzy-checksum-based spam detection filters such as the Distributed Checksum Clearinghouse, Vipul's Razor and the Cloudmark Authority plugins (commercial)\nHashcash email stamps based on proof-of-work\nSender Policy Framework and DomainKeys Identified Mail\nURI blacklists such as SURBL or URIBL which track spam websitesMore methods can be added reasonably easily by writing a Perl plug-in for Apache SpamAssassin.\n\n== Bayesian filtering ==\nApache SpamAssassin reinforces its rules through Bayesian filtering where a user or administrator \"feeds\" examples of good (ham) and bad (spam) into the filter in order to learn the difference between the two. For this purpose, Apache SpamAssassin provides the command-line tool sa-learn, which can be instructed to learn a single mail or an entire mailbox as either ham or spam.\nTypically, the user will move unrecognized spam to a separate folder, and then run sa-learn on the folder of non-spam and on the folder of spam separately. Alternatively, if the mail user agent supports it, sa-learn can be called for individual emails. Regardless of the method used to perform the learning, SpamAssassin's Bayesian test will help score future e-mails based on this learning to improve the accuracy.\n\n== Licensing ==\nApache SpamAssassin is free/open source software, licensed under the Apache License 2.0. Versions prior to 3.0 are dual-licensed under the Artistic License and the GNU General Public License.\n\n== sa-compile ==\nsa-compile is a utility distributed with Apache SpamAssassin that compiles a SpamAssassin ruleset into a deterministic finite automaton that allows Apache SpamAssassin to use processor power more efficiently.\n\n== Testing Apache SpamAssassin ==\nApache SpamAssassin is designed to trigger on the GTUBE, a 68-byte string similar to the antivirus EICAR test file. If this string is inserted in an RFC 5322 formatted message and passed through the Apache SpamAssassin engine, Apache SpamAssassin will trigger with a weight of 1000."
    }
  },
  {
    "instruction": "The GNU Name System (GNS) is a decentralized alternative to DNS based on the principle of a petname system, which uses a petname system to provide a more secure and user-friendly naming system.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the GNU Name System (GNS) and how does it relate to petname systems?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the GNU Name System (GNS) and how does it relate to petname systems?",
      "answer": "The GNU Name System (GNS) is a decentralized alternative to DNS based on the principle of a petname system, which uses a petname system to provide a more secure and user-friendly naming system."
    }
  },
  {
    "instruction": "Context: PUSH and ACK floods\n\n==Introduction==\nPUSH floods and ACK floods are denial of service attacks based on the PSH and ACK flags.\nSince these flags require additional processing it may be possible to overwhelm a service by setting these flags on numerous requests.\n\n== Mitigation ==\nProxy filters may drop appropriate packets with these flags set when the system is considered to be under attack.\nQuestion: How do PUSH and ACK floods affect network communications?\n\nAnswer:",
    "context": "",
    "output": "PUSH and ACK floods affect network communications by exploiting the requirement of additional processing for the PSH and ACK flags, potentially overwhelming the service.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How do PUSH and ACK floods affect network communications?",
      "answer": "PUSH and ACK floods affect network communications by exploiting the requirement of additional processing for the PSH and ACK flags, potentially overwhelming the service.",
      "context": "PUSH and ACK floods\n\n==Introduction==\nPUSH floods and ACK floods are denial of service attacks based on the PSH and ACK flags.\nSince these flags require additional processing it may be possible to overwhelm a service by setting these flags on numerous requests.\n\n== Mitigation ==\nProxy filters may drop appropriate packets with these flags set when the system is considered to be under attack."
    }
  },
  {
    "instruction": "An ideal permutation is an idealized object sometimes used in cryptography to model the behavior of a permutation whose outputs are indistinguishable from those of a random permutation.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is an ideal permutation in cryptography?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is an ideal permutation in cryptography?",
      "answer": "An ideal permutation is an idealized object sometimes used in cryptography to model the behavior of a permutation whose outputs are indistinguishable from those of a random permutation."
    }
  },
  {
    "instruction": "A thesaurus program can be used to shuffle through synonyms, making every copy of the document unique in a refined canary trap technique. This makes it more difficult for the suspect to identify and remove the unique language or false statement, increasing the chances of them repeating it verbatim in a leak and, thus, getting caught.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does a thesaurus program enhance the effectiveness of a canary trap?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does a thesaurus program enhance the effectiveness of a canary trap?",
      "answer": "A thesaurus program can be used to shuffle through synonyms, making every copy of the document unique in a refined canary trap technique. This makes it more difficult for the suspect to identify and remove the unique language or false statement, increasing the chances of them repeating it verbatim in a leak and, thus, getting caught."
    }
  },
  {
    "instruction": "The primary focus of Tomoyo Linux is on system behavior. It allows each process to declare behaviors and resources needed to achieve their purpose, and when protection is enabled, it restricts each process to the behaviors and resources allowed by the administrator.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the primary focus of Tomoyo Linux?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the primary focus of Tomoyo Linux?",
      "answer": "The primary focus of Tomoyo Linux is on system behavior. It allows each process to declare behaviors and resources needed to achieve their purpose, and when protection is enabled, it restricts each process to the behaviors and resources allowed by the administrator."
    }
  },
  {
    "instruction": "In a CL.TE attack, the front-end server processes the request using the Content-Length header, while the back-end server processes the request using the Transfer-Encoding header. The attack is carried out with the first part of the request declaring a zero-length chunk, causing the front-end server to only read the first part of the request and pass the second part to the back-end server. The back-end server then treats the second part as the next request and processes it, carrying out the attacker's hidden request.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What happens when a hacker carries out a CL.TE attack?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What happens when a hacker carries out a CL.TE attack?",
      "answer": "In a CL.TE attack, the front-end server processes the request using the Content-Length header, while the back-end server processes the request using the Transfer-Encoding header. The attack is carried out with the first part of the request declaring a zero-length chunk, causing the front-end server to only read the first part of the request and pass the second part to the back-end server. The back-end server then treats the second part as the next request and processes it, carrying out the attacker's hidden request."
    }
  },
  {
    "instruction": "PEAPv1/EAP-GTC is a protocol created by Cisco to provide interoperability with existing token card and directory-based authentication systems via a protected channel. However, it has not been widely adopted due to a lack of interest from Microsoft and a lack of promotion from Cisco.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is PEAPv1/EAP-GTC and why is it not widely adopted?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is PEAPv1/EAP-GTC and why is it not widely adopted?",
      "answer": "PEAPv1/EAP-GTC is a protocol created by Cisco to provide interoperability with existing token card and directory-based authentication systems via a protected channel. However, it has not been widely adopted due to a lack of interest from Microsoft and a lack of promotion from Cisco."
    }
  },
  {
    "instruction": "Nmap\n\n==Introduction==\nNmap (Network Mapper) is a network scanner created by Gordon Lyon (also known by his pseudonym Fyodor Vaskovich). Nmap is used to discover hosts and services on a computer network by sending packets and analyzing the responses.Nmap provides a number of features for probing computer networks, including host discovery and service and operating system detection. These features are extensible by scripts that provide more advanced service detection, vulnerability detection, and other features. Nmap can adapt to network conditions including latency and congestion during a scan.\nNmap started as a Linux utility and was ported to other systems including Windows, macOS, and BSD. It is most popular on Linux, followed by Windows.\n\n== Features ==\nNmap features include:\n\nFast scan (nmap -F [target]) \u2013 Performing a basic port scan for fast result.\nHost discovery \u2013 Identifying hosts on a network. For example, listing the hosts that respond to TCP and/or ICMP requests or have a particular port open.\nPort scanning \u2013 Enumerating the open ports on target hosts.\nVersion detection \u2013 Interrogating network services on remote devices to determine application name and version number.\nPing  Scan \u2013 Check host by sending ping requests.\nTCP/IP stack fingerprinting \u2013 Determining the operating system and hardware characteristics of network devices based on observations of network activity of said devices.\nScriptable interaction with the target \u2013 using Nmap Scripting Engine (NSE) and Lua programming language.Nmap can provide further information on targets, including reverse DNS names, device types, and MAC addresses.Typical uses of Nmap:\n\nAuditing the security of a device or firewall by identifying the network connections which can be made to, or through it.\nIdentifying open ports on a target host in preparation for auditing.\nNetwork inventory, network mapping, maintenance and asset management.\nAuditing the security of a network by identifying new servers.\nGenerating traffic to hosts on a network, response analysis  and response time measurement.\nFinding and exploiting vulnerabilities in a network.\nDNS queries and subdomain search\n\n== User interfaces ==\nNmapFE, originally written by Kanchan, was Nmap's official GUI for Nmap versions 2.2 to 4.22. For Nmap 4.50 (originally in the 4.22SOC development series) NmapFE was replaced with Zenmap, a new official graphical user interface based on UMIT, developed by Adriano Monteiro Marques.\nWeb-based interfaces exist that allow either controlling Nmap or analysing Nmap results from a web browser, such as IVRE.\n\n== Output ==\nFour different output formats are offered by Nmap. Everything is saved to a file except the interactive output. Text processing software can be used to modify Nmap output, allowing the user to customize reports.\nInteractive\npresented and updated real time when a user runs Nmap from the command line. Various options can be entered during the scan to facilitate monitoring.\nXML\na format that can be further processed by XML tools. It can be converted into a HTML report using XSLT.\nGrepable\noutput that is tailored to line-oriented processing tools such as grep, sed, or awk.\nNormal\nthe output as seen while running Nmap from the command line, but saved to a file.\nScript kiddie\nmeant to be an amusing way to format the interactive output replacing letters with their visually alike number representations. For example, Interesting ports becomes Int3rest1ng p0rtz. This is known as Leet.\n\n== Legal issues ==\nNmap is a tool that can be used to discover services running on Internet connected systems. Like any tool, it could potentially be used for black hat hacking, as a precursor to attempts to gain unauthorized access to computer systems. On the contrary, Nmap is also used by security and systems administrators to assess their own networks for vulnerabilities (i.e. white hat hacking).\nSystem administrators can use Nmap to search for unauthorized servers, or for computers that do not conform to security standards.\nIn 2003 Supreme Court of Finland has ruled that port scanning has amounted to an attempted computer break in, which was illegal under Finnish Penal code at the time:In its ruling the Supreme Court stated that the defendant had systematically carried out port scanning operations to gather information for the purpose of unauthorised break-in to the bank's computer network. This amounted to an attempted computer break in.\n\n== License ==\nNmap was originally distributed under the GNU Public License (GPL). In later releases, Nmap's authors added clarifications and specific interpretations to the license where they felt the GPL was unclear or lacking. For instance, Nmap 3.50 specifically revoked the license of SCO Group to distribute Nmap software because of their views on the SCO-Linux controversies.Starting with version 7.90, Nmap transitions to a new custom license NPSL, dual-licensing versions 7.90, 7.91, and 7.92 under both old and new licenses. Several Linux distributions consider the new license non-free.\n\n== In popular culture ==\nIn The Matrix Reloaded, Trinity is seen using Nmap to access a power plant's computer system, allowing Neo to \"physically\" break into a building. The appearance of Nmap in the film was widely discussed on Internet forums and hailed as an unusually realistic example of hacking.Nmap and NmapFE were used in The Listening, a 2006 movie about a former NSA officer who defects and mounts a clandestine counter-listening station high in the Italian alps.\nNmap source code can be seen in the movie Battle Royale, as well as brief views of the command line version of Nmap executing in Live Free or Die Hard and Bourne Ultimatum. In 2013, Nmap continued to make appearances in movies including popular sci-fi movie Elysium.\nThe film Dredd, a film adaptation of the famous Judge Dredd comics, was released in 2012 and also contains multiple Nmap scenes. Nmap is used for network reconnaissance and exploitation of the slum tower network. It is even seen briefly in the movie's trailer.\nThe command Nmap is widely used in the video game Hacknet, allowing to probe the network ports of a target system to hack it.\nIn Snowden, Nmap is used in the aptitude test scene about 14 minutes into the movie.\n\n== In academia ==\nNmap is an integral part of academic activities. It has been used for research involving the TCP/IP protocol suite and networking in general. Besides being a research tool, Nmap has also become a research topic.\n\n== Examples ==\n\n== Bibliography ==\n\nAnswer this question \"What is the legal status of port scanning, as related to Nmap usage?\" using the text above.",
    "context": "",
    "output": "The legal status of port scanning varies depending on jurisdiction. In Finland, for example, the Supreme Court has ruled that port scanning can amount to an attempted computer break-in, which was illegal under Finnish Penal code at the time. Nmap's developers emphasize responsible usage of their tool and encourage users to adhere to local laws and regulations regarding network scanning and security assessment.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the legal status of port scanning, as related to Nmap usage?",
      "answer": "The legal status of port scanning varies depending on jurisdiction. In Finland, for example, the Supreme Court has ruled that port scanning can amount to an attempted computer break-in, which was illegal under Finnish Penal code at the time. Nmap's developers emphasize responsible usage of their tool and encourage users to adhere to local laws and regulations regarding network scanning and security assessment.",
      "context": "Nmap\n\n==Introduction==\nNmap (Network Mapper) is a network scanner created by Gordon Lyon (also known by his pseudonym Fyodor Vaskovich). Nmap is used to discover hosts and services on a computer network by sending packets and analyzing the responses.Nmap provides a number of features for probing computer networks, including host discovery and service and operating system detection. These features are extensible by scripts that provide more advanced service detection, vulnerability detection, and other features. Nmap can adapt to network conditions including latency and congestion during a scan.\nNmap started as a Linux utility and was ported to other systems including Windows, macOS, and BSD. It is most popular on Linux, followed by Windows.\n\n== Features ==\nNmap features include:\n\nFast scan (nmap -F [target]) \u2013 Performing a basic port scan for fast result.\nHost discovery \u2013 Identifying hosts on a network. For example, listing the hosts that respond to TCP and/or ICMP requests or have a particular port open.\nPort scanning \u2013 Enumerating the open ports on target hosts.\nVersion detection \u2013 Interrogating network services on remote devices to determine application name and version number.\nPing  Scan \u2013 Check host by sending ping requests.\nTCP/IP stack fingerprinting \u2013 Determining the operating system and hardware characteristics of network devices based on observations of network activity of said devices.\nScriptable interaction with the target \u2013 using Nmap Scripting Engine (NSE) and Lua programming language.Nmap can provide further information on targets, including reverse DNS names, device types, and MAC addresses.Typical uses of Nmap:\n\nAuditing the security of a device or firewall by identifying the network connections which can be made to, or through it.\nIdentifying open ports on a target host in preparation for auditing.\nNetwork inventory, network mapping, maintenance and asset management.\nAuditing the security of a network by identifying new servers.\nGenerating traffic to hosts on a network, response analysis  and response time measurement.\nFinding and exploiting vulnerabilities in a network.\nDNS queries and subdomain search\n\n== User interfaces ==\nNmapFE, originally written by Kanchan, was Nmap's official GUI for Nmap versions 2.2 to 4.22. For Nmap 4.50 (originally in the 4.22SOC development series) NmapFE was replaced with Zenmap, a new official graphical user interface based on UMIT, developed by Adriano Monteiro Marques.\nWeb-based interfaces exist that allow either controlling Nmap or analysing Nmap results from a web browser, such as IVRE.\n\n== Output ==\nFour different output formats are offered by Nmap. Everything is saved to a file except the interactive output. Text processing software can be used to modify Nmap output, allowing the user to customize reports.\nInteractive\npresented and updated real time when a user runs Nmap from the command line. Various options can be entered during the scan to facilitate monitoring.\nXML\na format that can be further processed by XML tools. It can be converted into a HTML report using XSLT.\nGrepable\noutput that is tailored to line-oriented processing tools such as grep, sed, or awk.\nNormal\nthe output as seen while running Nmap from the command line, but saved to a file.\nScript kiddie\nmeant to be an amusing way to format the interactive output replacing letters with their visually alike number representations. For example, Interesting ports becomes Int3rest1ng p0rtz. This is known as Leet.\n\n== Legal issues ==\nNmap is a tool that can be used to discover services running on Internet connected systems. Like any tool, it could potentially be used for black hat hacking, as a precursor to attempts to gain unauthorized access to computer systems. On the contrary, Nmap is also used by security and systems administrators to assess their own networks for vulnerabilities (i.e. white hat hacking).\nSystem administrators can use Nmap to search for unauthorized servers, or for computers that do not conform to security standards.\nIn 2003 Supreme Court of Finland has ruled that port scanning has amounted to an attempted computer break in, which was illegal under Finnish Penal code at the time:In its ruling the Supreme Court stated that the defendant had systematically carried out port scanning operations to gather information for the purpose of unauthorised break-in to the bank's computer network. This amounted to an attempted computer break in.\n\n== License ==\nNmap was originally distributed under the GNU Public License (GPL). In later releases, Nmap's authors added clarifications and specific interpretations to the license where they felt the GPL was unclear or lacking. For instance, Nmap 3.50 specifically revoked the license of SCO Group to distribute Nmap software because of their views on the SCO-Linux controversies.Starting with version 7.90, Nmap transitions to a new custom license NPSL, dual-licensing versions 7.90, 7.91, and 7.92 under both old and new licenses. Several Linux distributions consider the new license non-free.\n\n== In popular culture ==\nIn The Matrix Reloaded, Trinity is seen using Nmap to access a power plant's computer system, allowing Neo to \"physically\" break into a building. The appearance of Nmap in the film was widely discussed on Internet forums and hailed as an unusually realistic example of hacking.Nmap and NmapFE were used in The Listening, a 2006 movie about a former NSA officer who defects and mounts a clandestine counter-listening station high in the Italian alps.\nNmap source code can be seen in the movie Battle Royale, as well as brief views of the command line version of Nmap executing in Live Free or Die Hard and Bourne Ultimatum. In 2013, Nmap continued to make appearances in movies including popular sci-fi movie Elysium.\nThe film Dredd, a film adaptation of the famous Judge Dredd comics, was released in 2012 and also contains multiple Nmap scenes. Nmap is used for network reconnaissance and exploitation of the slum tower network. It is even seen briefly in the movie's trailer.\nThe command Nmap is widely used in the video game Hacknet, allowing to probe the network ports of a target system to hack it.\nIn Snowden, Nmap is used in the aptitude test scene about 14 minutes into the movie.\n\n== In academia ==\nNmap is an integral part of academic activities. It has been used for research involving the TCP/IP protocol suite and networking in general. Besides being a research tool, Nmap has also become a research topic.\n\n== Examples ==\n\n== Bibliography =="
    }
  },
  {
    "instruction": "The man traceroute command on Linux systems presents more details about the traceroute command, including the displayed error flags.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the purpose of the man traceroute command on Linux systems?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the purpose of the man traceroute command on Linux systems?",
      "answer": "The man traceroute command on Linux systems presents more details about the traceroute command, including the displayed error flags."
    }
  },
  {
    "instruction": "The endorsement key is a 2048-bit RSA public and private key pair that is created randomly on the chip at manufacture time and cannot be changed. The private key never leaves the chip, while the public key is used for attestation and for encryption of sensitive data sent to the chip. This key is used to allow the execution of secure transactions by signing a random number using a particular protocol, ensuring compliance with the TCG standard and proving the identity of the TPM.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How is the endorsement key used to allow secure transactions in Trusted Computing?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How is the endorsement key used to allow secure transactions in Trusted Computing?",
      "answer": "The endorsement key is a 2048-bit RSA public and private key pair that is created randomly on the chip at manufacture time and cannot be changed. The private key never leaves the chip, while the public key is used for attestation and for encryption of sensitive data sent to the chip. This key is used to allow the execution of secure transactions by signing a random number using a particular protocol, ensuring compliance with the TCG standard and proving the identity of the TPM."
    }
  },
  {
    "instruction": "Ignition interlock devices require the driver to blow into a breathalyzer before starting the vehicle, preventing drunk driving by repeat offenders.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the purpose of ignition interlock devices in vehicles?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the purpose of ignition interlock devices in vehicles?",
      "answer": "Ignition interlock devices require the driver to blow into a breathalyzer before starting the vehicle, preventing drunk driving by repeat offenders."
    }
  },
  {
    "instruction": "Network forensics\n\n==Introduction==\nNetwork forensics is a sub-branch of digital forensics relating to the monitoring and analysis of computer network traffic for the purposes of information gathering, legal evidence, or intrusion detection. Unlike other areas of digital forensics, network investigations deal with volatile and dynamic information. Network traffic is transmitted and then lost, so network forensics is often a pro-active investigation.Network forensics generally has two uses. The first, relating to security, involves monitoring a network for anomalous traffic and identifying intrusions. An attacker might be able to erase all log files on a compromised host; network-based evidence might therefore be the only evidence available for forensic analysis. The second form relates to law enforcement. In this case analysis of captured network traffic can include tasks such as reassembling transferred files, searching for keywords and parsing human communication such as emails or chat sessions.\nTwo systems are commonly used to collect network data; a brute force \"catch it as you can\" and a more intelligent \"stop look listen\" method.\n\n== Overview ==\nNetwork forensics is a comparatively new field of forensic science. The growing popularity of the Internet in homes means that computing has become network-centric and data is now available outside of disk-based digital evidence. Network forensics can be performed as a standalone investigation or alongside a computer forensics analysis (where it is often used to reveal links between digital devices or reconstruct how a crime was committed).Marcus Ranum is credited with defining Network forensics as \"the capture, recording, and analysis of network events in order to discover the source of security attacks or other problem incidents\".Compared to computer forensics, where evidence is usually preserved on disk, network data is more volatile and unpredictable. Investigators often only have material to examine if packet filters, firewalls, and intrusion detection systems were set up to anticipate breaches of security.Systems used to collect network data for forensics use usually come in two forms:\n\"Catch-it-as-you-can\" \u2013 This is where all packets passing through a certain traffic point are captured and written to storage with analysis being done subsequently in batch mode. This approach requires large amounts of storage.\n\"Stop, look and listen\" \u2013 This is where each packet is analyzed in a rudimentary way in memory and only certain information saved for future analysis. This approach requires a faster processor to keep up with incoming traffic.\n\n== Types ==\n\n\n*** Ethernet ***\n\nApt all data on this layer and allows the user to filter for different events. With these tools, website pages, email attachments, and other network traffic can be reconstructed only if they are transmitted or received unencrypted. An advantage of collecting this data is that it is directly connected to a host. If, for example the IP address or the MAC address of a host at a certain time is known, all data sent to or from this IP or MAC address can be filtered.\nTo establish the connection between IP and MAC address, it is useful to take a closer look at auxiliary network protocols. The Address Resolution Protocol (ARP) tables list the MAC addresses with the corresponding IP addresses.\nTo collect data on this layer, the network interface card (NIC) of a host can be put into \"promiscuous mode\". In so doing, all traffic will be passed to the CPU, not only the traffic meant for the host.\nHowever, if an intruder or attacker is aware that his connection might be eavesdropped, he might use encryption to secure his connection. It is almost impossible nowadays to break encryption but the fact that a suspect's connection to another host is encrypted all the time might indicate that the other host is an accomplice of the suspect.\n\n\n*** TCP/IP ***\nOn the network layer the Internet Protocol (IP) is responsible for directing the packets generated by TCP through the network (e.g., the Internet) by adding source and destination information which can be interpreted by routers all over the network. Cellular digital packet networks, like GPRS, use similar protocols like IP, so the methods described for IP work with them as well.\nFor the correct routing, every intermediate router must have a routing table to know where to send the packet next.\nThese routing tables are one of the best sources of information if investigating a digital crime and trying to track down an attacker. To do this, it is necessary to follow the packets of the attacker, reverse the sending route and find the computer the packet came from (i.e., the attacker).\n\n\n*** Encrypted Traffic Analytics ***\nGiven the proliferation of TLS encryption on the internet, as of April 2021 it is estimated that half of all malware uses TLS to evade detection. Encrypted traffic analysis inspects traffic to identify encrypted traffic coming from malware and other threats by detecting suspicious combinations of TLS characteristics, usually to uncommon networks or servers. Another approach to encrypted traffic analysis uses a generated database of fingerprints, although these techniques have been criticized as being easily bypassed by hackers and inaccurate.\n\n\n*** The Internet ***\nThe internet can be a rich source of digital evidence including web browsing, email, newsgroup, synchronous chat and peer-to-peer traffic. For example, web server logs can be used to show when (or if) a suspect accessed information related to criminal activity. Email accounts can often contain useful evidence; but email headers are easily faked and, so, network forensics may be used to prove the exact origin of incriminating material. Network forensics can also be used in order to find out who is using a particular computer by extracting user account information from the network traffic.\n\n== Wireless forensics ==\nWireless forensics is a sub-discipline of network forensics. The main goal of wireless forensics is to provide the methodology and tools required to collect and analyze (wireless) network traffic that can be presented as valid digital evidence in a court of law. The evidence collected can correspond to plain data or, with the broad usage of Voice-over-IP (VoIP) technologies, especially over wireless, can include voice conversations.\nAnalysis of wireless network traffic is similar to that on wired networks, however there may be the added consideration of wireless security measures. Answer this question using the following article:\n\nWhat is the role of Ethernet in network forensics?",
    "context": "",
    "output": "Ethernet is used to capture and record network events in order to discover the source of security attacks or other problem incidents. It allows the user to filter for different events, and if the IP address or the MAC address of a host at a certain time is known, all data sent to or from this IP or MAC address can be filtered.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the role of Ethernet in network forensics?",
      "answer": "Ethernet is used to capture and record network events in order to discover the source of security attacks or other problem incidents. It allows the user to filter for different events, and if the IP address or the MAC address of a host at a certain time is known, all data sent to or from this IP or MAC address can be filtered.",
      "context": "Network forensics\n\n==Introduction==\nNetwork forensics is a sub-branch of digital forensics relating to the monitoring and analysis of computer network traffic for the purposes of information gathering, legal evidence, or intrusion detection. Unlike other areas of digital forensics, network investigations deal with volatile and dynamic information. Network traffic is transmitted and then lost, so network forensics is often a pro-active investigation.Network forensics generally has two uses. The first, relating to security, involves monitoring a network for anomalous traffic and identifying intrusions. An attacker might be able to erase all log files on a compromised host; network-based evidence might therefore be the only evidence available for forensic analysis. The second form relates to law enforcement. In this case analysis of captured network traffic can include tasks such as reassembling transferred files, searching for keywords and parsing human communication such as emails or chat sessions.\nTwo systems are commonly used to collect network data; a brute force \"catch it as you can\" and a more intelligent \"stop look listen\" method.\n\n== Overview ==\nNetwork forensics is a comparatively new field of forensic science. The growing popularity of the Internet in homes means that computing has become network-centric and data is now available outside of disk-based digital evidence. Network forensics can be performed as a standalone investigation or alongside a computer forensics analysis (where it is often used to reveal links between digital devices or reconstruct how a crime was committed).Marcus Ranum is credited with defining Network forensics as \"the capture, recording, and analysis of network events in order to discover the source of security attacks or other problem incidents\".Compared to computer forensics, where evidence is usually preserved on disk, network data is more volatile and unpredictable. Investigators often only have material to examine if packet filters, firewalls, and intrusion detection systems were set up to anticipate breaches of security.Systems used to collect network data for forensics use usually come in two forms:\n\"Catch-it-as-you-can\" \u2013 This is where all packets passing through a certain traffic point are captured and written to storage with analysis being done subsequently in batch mode. This approach requires large amounts of storage.\n\"Stop, look and listen\" \u2013 This is where each packet is analyzed in a rudimentary way in memory and only certain information saved for future analysis. This approach requires a faster processor to keep up with incoming traffic.\n\n== Types ==\n\n\n*** Ethernet ***\n\nApt all data on this layer and allows the user to filter for different events. With these tools, website pages, email attachments, and other network traffic can be reconstructed only if they are transmitted or received unencrypted. An advantage of collecting this data is that it is directly connected to a host. If, for example the IP address or the MAC address of a host at a certain time is known, all data sent to or from this IP or MAC address can be filtered.\nTo establish the connection between IP and MAC address, it is useful to take a closer look at auxiliary network protocols. The Address Resolution Protocol (ARP) tables list the MAC addresses with the corresponding IP addresses.\nTo collect data on this layer, the network interface card (NIC) of a host can be put into \"promiscuous mode\". In so doing, all traffic will be passed to the CPU, not only the traffic meant for the host.\nHowever, if an intruder or attacker is aware that his connection might be eavesdropped, he might use encryption to secure his connection. It is almost impossible nowadays to break encryption but the fact that a suspect's connection to another host is encrypted all the time might indicate that the other host is an accomplice of the suspect.\n\n\n*** TCP/IP ***\nOn the network layer the Internet Protocol (IP) is responsible for directing the packets generated by TCP through the network (e.g., the Internet) by adding source and destination information which can be interpreted by routers all over the network. Cellular digital packet networks, like GPRS, use similar protocols like IP, so the methods described for IP work with them as well.\nFor the correct routing, every intermediate router must have a routing table to know where to send the packet next.\nThese routing tables are one of the best sources of information if investigating a digital crime and trying to track down an attacker. To do this, it is necessary to follow the packets of the attacker, reverse the sending route and find the computer the packet came from (i.e., the attacker).\n\n\n*** Encrypted Traffic Analytics ***\nGiven the proliferation of TLS encryption on the internet, as of April 2021 it is estimated that half of all malware uses TLS to evade detection. Encrypted traffic analysis inspects traffic to identify encrypted traffic coming from malware and other threats by detecting suspicious combinations of TLS characteristics, usually to uncommon networks or servers. Another approach to encrypted traffic analysis uses a generated database of fingerprints, although these techniques have been criticized as being easily bypassed by hackers and inaccurate.\n\n\n*** The Internet ***\nThe internet can be a rich source of digital evidence including web browsing, email, newsgroup, synchronous chat and peer-to-peer traffic. For example, web server logs can be used to show when (or if) a suspect accessed information related to criminal activity. Email accounts can often contain useful evidence; but email headers are easily faked and, so, network forensics may be used to prove the exact origin of incriminating material. Network forensics can also be used in order to find out who is using a particular computer by extracting user account information from the network traffic.\n\n== Wireless forensics ==\nWireless forensics is a sub-discipline of network forensics. The main goal of wireless forensics is to provide the methodology and tools required to collect and analyze (wireless) network traffic that can be presented as valid digital evidence in a court of law. The evidence collected can correspond to plain data or, with the broad usage of Voice-over-IP (VoIP) technologies, especially over wireless, can include voice conversations.\nAnalysis of wireless network traffic is similar to that on wired networks, however there may be the added consideration of wireless security measures."
    }
  },
  {
    "instruction": "Inherence factors in passwordless authentication are something the user is, such as fingerprints, retinal scans, face or voice recognition, and other biometric identifiers.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What are inherence factors in passwordless authentication?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What are inherence factors in passwordless authentication?",
      "answer": "Inherence factors in passwordless authentication are something the user is, such as fingerprints, retinal scans, face or voice recognition, and other biometric identifiers."
    }
  },
  {
    "instruction": "The Masque Attack vulnerability is a security flaw identified in the iOS operating system that allows malicious parties to replace legitimate apps with malicious ones, as long as the apps share the same bundle identifier. This vulnerability affects both jailbroken and non-jailbroken devices running iOS 7.1.1, 7.1.2, 8.0, 8.1, and 8.1.1 beta.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the Masque Attack vulnerability and what kind of devices does it affect?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the Masque Attack vulnerability and what kind of devices does it affect?",
      "answer": "The Masque Attack vulnerability is a security flaw identified in the iOS operating system that allows malicious parties to replace legitimate apps with malicious ones, as long as the apps share the same bundle identifier. This vulnerability affects both jailbroken and non-jailbroken devices running iOS 7.1.1, 7.1.2, 8.0, 8.1, and 8.1.1 beta."
    }
  },
  {
    "instruction": "The main objective of the ADAMS project was to identify patterns and anomalies in large data sets to detect and prevent insider threats. The project was funded by DARPA with a total budget of $35 million.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What was the main objective of the ADAMS project and what was its total budget?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What was the main objective of the ADAMS project and what was its total budget?",
      "answer": "The main objective of the ADAMS project was to identify patterns and anomalies in large data sets to detect and prevent insider threats. The project was funded by DARPA with a total budget of $35 million."
    }
  },
  {
    "instruction": "The increasing computerization of vital records has made ghosting more difficult. In the past, each state in the U.S. maintained its birth and death records in separate registries with no cross-referencing. However, modern search engines now enable government clerks to establish quickly if a death certificate has ever been issued to the person named on a given birth certificate. This makes it more difficult for ghosters to avoid detection.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How has the increasing computerization of vital records affected the ease of ghosting?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How has the increasing computerization of vital records affected the ease of ghosting?",
      "answer": "The increasing computerization of vital records has made ghosting more difficult. In the past, each state in the U.S. maintained its birth and death records in separate registries with no cross-referencing. However, modern search engines now enable government clerks to establish quickly if a death certificate has ever been issued to the person named on a given birth certificate. This makes it more difficult for ghosters to avoid detection."
    }
  },
  {
    "instruction": "Yes, the killbit feature applies to all web browsers based on Microsoft's Trident engine, such as Internet Explorer, that respect the killbit.\n\nWrite a question about the text above.",
    "context": "",
    "output": "Does the killbit feature apply to all web browsers based on Microsoft's Trident engine?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "Does the killbit feature apply to all web browsers based on Microsoft's Trident engine?",
      "answer": "Yes, the killbit feature applies to all web browsers based on Microsoft's Trident engine, such as Internet Explorer, that respect the killbit."
    }
  },
  {
    "instruction": "Only eleven Chinese companies had access to the WAPI standard when it was first issued as a Chinese national standard.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How many Chinese companies had access to the WAPI standard when it was first issued as a Chinese national standard?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How many Chinese companies had access to the WAPI standard when it was first issued as a Chinese national standard?",
      "answer": "Only eleven Chinese companies had access to the WAPI standard when it was first issued as a Chinese national standard."
    }
  },
  {
    "instruction": "Risk-based authentication improves user validation accuracy without inconveniencing the user by only requiring additional steps when something is out of the ordinary, such as the login attempt is from a new machine.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does risk-based authentication improve user validation accuracy without inconveniencing the user?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does risk-based authentication improve user validation accuracy without inconveniencing the user?",
      "answer": "Risk-based authentication improves user validation accuracy without inconveniencing the user by only requiring additional steps when something is out of the ordinary, such as the login attempt is from a new machine."
    }
  },
  {
    "instruction": "Low tech devices such as a typewriter or a Memex can be used to defend against TEMPEST in situations where encrypted signals are not used. This method can be effective in preventing the monitoring of plaintext data that are being processed.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How can low tech devices be used to defend against TEMPEST?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How can low tech devices be used to defend against TEMPEST?",
      "answer": "Low tech devices such as a typewriter or a Memex can be used to defend against TEMPEST in situations where encrypted signals are not used. This method can be effective in preventing the monitoring of plaintext data that are being processed."
    }
  },
  {
    "instruction": "Context: Host Based Security System\n\n==Introduction==\nHost Based Security System (HBSS) is the official name given to the United States Department of Defense (DOD) commercial off-the-shelf (COTS) suite of software applications used within the DOD to monitor, detect, and defend the DOD computer networks and systems.  The Enterprise-wide Information Assurance and computer Network Defense Solutions Steering Group (ESSG) sponsored the acquisition of the HBSS System for use within the DOD Enterprise Network.  HBSS is deployed on both the Non-Classified Internet Protocol Routed Network (NIPRNet) and Secret Internet Protocol Routed Network (SIPRNet) networks, with priority given to installing it on the NIPRNet.  HBSS is based on McAfee, Inc's ePolicy Orchestrator (ePO) and other McAfee point product security applications such as Host Intrusion Prevention System (HIPS).\n\n\n\n== HBSS components ==\nThroughout its lifetime, HBSS has undergone several major baseline updates as well as minor maintenance releases.  The first major release of HBSS was known as Baseline 1.0 and contained the McAfee ePolicy orchestrator engine, HIPS, software compliance profiler (SCP), rogue system detection (RSD), asset baseline manager (ABM), and assets software.  As new releases were introduced, these software products have evolved, had new products added, and in some cases, been completely replaced for different products.\n\n\n*** HBSS Baseline 4.5 MR2 components ***\nAs of January, 2011, HBSS is  currently at Baseline 4.5, Maintenance Release 2.0 (MR2).  MR2 contains  the following software:\n\n\n**** Microsoft products ****\n\n\n**** Optional products/components ****\n\n\n**** SIPRNet-only products/components ****\n\n== How HBSS works ==\nThe heart of HBSS is the McAfee ePolicy orchestrator (ePO) management engine.  The McAfee tools are responsible for:\n\nProviding a consistent front-end to the point products\nConsolidating point product data for analysis\nPresenting point product reports\nManaging the point product updates and communications\nEnsure application patch compliance\n\n\n*** McAfee point products ***\nMcAfee considers a  point product to be the individual software applications controlled by  the ePO server.  The HBSS point products consist of the following:\n\nHost  intrusion prevention system (HIPS)\nPolicy auditor (PA)\nAssets  baseline module (ABM)\nRogue system detection (RSD)\nDevice  control module (DCM)\nAsset publishing service (APS)\n\n\n**** Host intrusion prevention system ****\nThe host intrusion prevention  system (HIPS) consists of a host-based firewall and application-level blocking consolidated in a single product.  The HIPS component is one of the most  significant components of the HBSS, as it provides for the capability  to block known intrusion signatures and restrict unauthorized services  and applications running on the host machines.\n\n\n**** Policy auditor ****\nPolicy auditor (PA) was  introduced in HBSS Baseline 2.0.  Policy auditor is responsible for ensuring compliance with mandates such as: Payment Card Industry Data Security Standard (PCI DSS), Sarbanes\u2013Oxley Act of 2002 (SOX), Gramm\u2013Leach\u2013Bliley Act of 1999 (GLBA), Health Insurance Portability and Accountability Act of 1996 (HIPAA), Federal Information Security Management Act of 2002 (FISMA), as well as the best practice frameworks ISO 27001:2005 and Control Objectives for Information and related technology (COBIT).  PA maps IT controls against predefined policy content, McAfee Policy Auditor helps report consistently and accurately against key industry mandates and internal policies across your infrastructure or on specific targeted systems. Policy Auditor is an agent-based IT audit solution that leverages the Security Content Automation Protocol (SCAP) to automate the processes required for internal and external IT audits.\n\n\n**** Assets baseline module ****\nThe assets  baseline module, released in Baseline 1.0 as a government off-the-shelf (GOTS) product, is used to  address system baseline configurations and changes in order to respond  to information operations condition (INFOCON) (INFOCON) changes necessary during times of  heightened security threats to the system.  During the initial  deployment stages of HBSS, the assets module was juvenile and lacked  much of the products intended capabilities.  However, the application  has fully evolved into a robust and feature packed version capable of  handling the original software's design goals.  ABM was originally known  as Assets 1.0.  It was upgraded to Assets 2.0 in HBSS Baseline 2.0.   Later it was called Assets 3000 in HBSS Baseline 3.0.\n\n\n**** Rogue system detection ****\nThe rogue system  detector (RSD) component of HBSS is used to provide real-time detection  of new hosts attaching to the network.  RSD monitors network segments  and reports all hosts seen on the network to the ePO Server.  The ePO  Server then determines whether the system is connected to the ePO server, has a McAfee agent installed, has been identified as an  exception, or is considered rogue.  The ePO server can then take the  appropriate action(s) concerning the rogue host, as specified in the RSD  policy.  HBSS Baseline 1.0 introduced RSD 1.0.  RSD was updated to 2.0  in HBSS Baseline 2.0.\n\n\n**** Device control module/data loss prevention ****\nThe DCM component of HBSS was  introduced in HBSS Baseline 2.0 specifically to address the use of USB  devices on DOD networks.  JTF-GNO CTO 09-xxx, removable flash media device implementation within and between Department of Defense (DOD) networks was released in March, 2009 and  allowed the use of USB removable media, provided it meets all of the conditions stated within the CTO.  One of these conditions requires the use of HBSS with the DCM module installed and configured to manage the USB devices attached to the system. The DCM was renamed to the data loss prevention (DLP) in HBSS Baseline 3.0 MR3.\n\n\n**** Assets publishing service ****\nThe assets publishing service (APS) of HBSS was introduced in HBSS Baseline 4.0 to allow for enclaves to report on asset information to a third-party DoD entity in a standards-compliant format.  It adds contextual information to HBSS assets and allows for improved reporting features on systems relying on HBSS data.\n\n== Obtaining HBSS ==\nAccording to JTF-GNO CTO 07-12, all DOD agencies are required to deploy HBSS to their networks.  DISA has made HBSS software available for download on their PKI protected patch server.  Users attempting to download the software are required to have a Common Access Card (CAC) and be on a .mil network.  DISA provides software and updates free of charge to DOD entities.\nAdditionally, HBSS administrators require the satisfactory completion of HBSS training and are commonly appointed by the unit or section commander in writing.\n\n== Learning HBSS ==\nIn order to receive and administer an HBSS system, system administrators must satisfactorily complete online or in class HBSS training as well as be identified as an HBSS administrator.  Online training takes 30 hours to complete while in class training requires four days, excluding travel.  An advanced HBSS class is also available to HBSS administrators wishing to acquire a more in-depth knowledge of the system.  HBSS online and in class training is managed by DISA.\n\n== HBSS support ==\nThe DISA Risk Management Executive Office (RE) formerly field security office (FSO) provides free technical support for all HBSS Administrators through their help desk.  DISA has three tiers of support, from Tier I to Tier III.  Tier I and Tier II support is provided by DISA FSO, while Tier III support is provided by McAfee.  DISA FSO Support is available using one of the following methods:\n\n== The future of HBSS ==\nAt its current pace, HBSS has been updated several times from the original Baseline 1.0 to the current Baseline 3.0, MR3 version.  Within Baseline 3.0, maintenance releases have been introduced every two to four months, bringing better stability and security with each release.  HBSS follows McAfee ePO version updates closely and it is expected to continue this trend as ePO is continuously developed.\nQuestion: How can DOD agencies obtain the HBSS system?. Whats the answer?",
    "context": "",
    "output": "DOD agencies can obtain the HBSS system by downloading the software from the DISA PKI protected patch server, which requires a Common Access Card (CAC) and a .mil network. The software and updates are provided free of charge to DOD entities.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How can DOD agencies obtain the HBSS system?",
      "answer": "DOD agencies can obtain the HBSS system by downloading the software from the DISA PKI protected patch server, which requires a Common Access Card (CAC) and a .mil network. The software and updates are provided free of charge to DOD entities.",
      "context": "Host Based Security System\n\n==Introduction==\nHost Based Security System (HBSS) is the official name given to the United States Department of Defense (DOD) commercial off-the-shelf (COTS) suite of software applications used within the DOD to monitor, detect, and defend the DOD computer networks and systems.  The Enterprise-wide Information Assurance and computer Network Defense Solutions Steering Group (ESSG) sponsored the acquisition of the HBSS System for use within the DOD Enterprise Network.  HBSS is deployed on both the Non-Classified Internet Protocol Routed Network (NIPRNet) and Secret Internet Protocol Routed Network (SIPRNet) networks, with priority given to installing it on the NIPRNet.  HBSS is based on McAfee, Inc's ePolicy Orchestrator (ePO) and other McAfee point product security applications such as Host Intrusion Prevention System (HIPS).\n\n\n\n== HBSS components ==\nThroughout its lifetime, HBSS has undergone several major baseline updates as well as minor maintenance releases.  The first major release of HBSS was known as Baseline 1.0 and contained the McAfee ePolicy orchestrator engine, HIPS, software compliance profiler (SCP), rogue system detection (RSD), asset baseline manager (ABM), and assets software.  As new releases were introduced, these software products have evolved, had new products added, and in some cases, been completely replaced for different products.\n\n\n*** HBSS Baseline 4.5 MR2 components ***\nAs of January, 2011, HBSS is  currently at Baseline 4.5, Maintenance Release 2.0 (MR2).  MR2 contains  the following software:\n\n\n**** Microsoft products ****\n\n\n**** Optional products/components ****\n\n\n**** SIPRNet-only products/components ****\n\n== How HBSS works ==\nThe heart of HBSS is the McAfee ePolicy orchestrator (ePO) management engine.  The McAfee tools are responsible for:\n\nProviding a consistent front-end to the point products\nConsolidating point product data for analysis\nPresenting point product reports\nManaging the point product updates and communications\nEnsure application patch compliance\n\n\n*** McAfee point products ***\nMcAfee considers a  point product to be the individual software applications controlled by  the ePO server.  The HBSS point products consist of the following:\n\nHost  intrusion prevention system (HIPS)\nPolicy auditor (PA)\nAssets  baseline module (ABM)\nRogue system detection (RSD)\nDevice  control module (DCM)\nAsset publishing service (APS)\n\n\n**** Host intrusion prevention system ****\nThe host intrusion prevention  system (HIPS) consists of a host-based firewall and application-level blocking consolidated in a single product.  The HIPS component is one of the most  significant components of the HBSS, as it provides for the capability  to block known intrusion signatures and restrict unauthorized services  and applications running on the host machines.\n\n\n**** Policy auditor ****\nPolicy auditor (PA) was  introduced in HBSS Baseline 2.0.  Policy auditor is responsible for ensuring compliance with mandates such as: Payment Card Industry Data Security Standard (PCI DSS), Sarbanes\u2013Oxley Act of 2002 (SOX), Gramm\u2013Leach\u2013Bliley Act of 1999 (GLBA), Health Insurance Portability and Accountability Act of 1996 (HIPAA), Federal Information Security Management Act of 2002 (FISMA), as well as the best practice frameworks ISO 27001:2005 and Control Objectives for Information and related technology (COBIT).  PA maps IT controls against predefined policy content, McAfee Policy Auditor helps report consistently and accurately against key industry mandates and internal policies across your infrastructure or on specific targeted systems. Policy Auditor is an agent-based IT audit solution that leverages the Security Content Automation Protocol (SCAP) to automate the processes required for internal and external IT audits.\n\n\n**** Assets baseline module ****\nThe assets  baseline module, released in Baseline 1.0 as a government off-the-shelf (GOTS) product, is used to  address system baseline configurations and changes in order to respond  to information operations condition (INFOCON) (INFOCON) changes necessary during times of  heightened security threats to the system.  During the initial  deployment stages of HBSS, the assets module was juvenile and lacked  much of the products intended capabilities.  However, the application  has fully evolved into a robust and feature packed version capable of  handling the original software's design goals.  ABM was originally known  as Assets 1.0.  It was upgraded to Assets 2.0 in HBSS Baseline 2.0.   Later it was called Assets 3000 in HBSS Baseline 3.0.\n\n\n**** Rogue system detection ****\nThe rogue system  detector (RSD) component of HBSS is used to provide real-time detection  of new hosts attaching to the network.  RSD monitors network segments  and reports all hosts seen on the network to the ePO Server.  The ePO  Server then determines whether the system is connected to the ePO server, has a McAfee agent installed, has been identified as an  exception, or is considered rogue.  The ePO server can then take the  appropriate action(s) concerning the rogue host, as specified in the RSD  policy.  HBSS Baseline 1.0 introduced RSD 1.0.  RSD was updated to 2.0  in HBSS Baseline 2.0.\n\n\n**** Device control module/data loss prevention ****\nThe DCM component of HBSS was  introduced in HBSS Baseline 2.0 specifically to address the use of USB  devices on DOD networks.  JTF-GNO CTO 09-xxx, removable flash media device implementation within and between Department of Defense (DOD) networks was released in March, 2009 and  allowed the use of USB removable media, provided it meets all of the conditions stated within the CTO.  One of these conditions requires the use of HBSS with the DCM module installed and configured to manage the USB devices attached to the system. The DCM was renamed to the data loss prevention (DLP) in HBSS Baseline 3.0 MR3.\n\n\n**** Assets publishing service ****\nThe assets publishing service (APS) of HBSS was introduced in HBSS Baseline 4.0 to allow for enclaves to report on asset information to a third-party DoD entity in a standards-compliant format.  It adds contextual information to HBSS assets and allows for improved reporting features on systems relying on HBSS data.\n\n== Obtaining HBSS ==\nAccording to JTF-GNO CTO 07-12, all DOD agencies are required to deploy HBSS to their networks.  DISA has made HBSS software available for download on their PKI protected patch server.  Users attempting to download the software are required to have a Common Access Card (CAC) and be on a .mil network.  DISA provides software and updates free of charge to DOD entities.\nAdditionally, HBSS administrators require the satisfactory completion of HBSS training and are commonly appointed by the unit or section commander in writing.\n\n== Learning HBSS ==\nIn order to receive and administer an HBSS system, system administrators must satisfactorily complete online or in class HBSS training as well as be identified as an HBSS administrator.  Online training takes 30 hours to complete while in class training requires four days, excluding travel.  An advanced HBSS class is also available to HBSS administrators wishing to acquire a more in-depth knowledge of the system.  HBSS online and in class training is managed by DISA.\n\n== HBSS support ==\nThe DISA Risk Management Executive Office (RE) formerly field security office (FSO) provides free technical support for all HBSS Administrators through their help desk.  DISA has three tiers of support, from Tier I to Tier III.  Tier I and Tier II support is provided by DISA FSO, while Tier III support is provided by McAfee.  DISA FSO Support is available using one of the following methods:\n\n== The future of HBSS ==\nAt its current pace, HBSS has been updated several times from the original Baseline 1.0 to the current Baseline 3.0, MR3 version.  Within Baseline 3.0, maintenance releases have been introduced every two to four months, bringing better stability and security with each release.  HBSS follows McAfee ePO version updates closely and it is expected to continue this trend as ePO is continuously developed."
    }
  },
  {
    "instruction": "Dynamic application security testing\n\n==Introduction==\nA dynamic application security testing (DAST) is a non functional testing process where one can assess an application using certain techniques and the end result of such testing process covers security weaknesses and vulnerabilities present in an application. This testing process can be carried out either in manual way or by using automated tools. Manual assessment of an application involves a more human intervention to identify the security flaws which might slip from an automated tool. Usually business logic errors, race condition checks, and certain zero day vulnerabilities can only be identified using manual assessments. On the other side, a DAST tool is a program which communicates with a web application through the web front-end in order to identify potential security vulnerabilities in the web application and architectural weaknesses. It performs a black-box test. Unlike static application security testing tools, DAST tools do not have access to the source code and therefore detect vulnerabilities by actually performing attacks.\nDAST tools allow sophisticated scans, detecting vulnerabilities with minimal user interactions once configured with host name, crawling parameters and authentication credentials. These tools will attempt to detect vulnerabilities in query strings, headers, fragments, verbs (GET/POST/PUT) and DOM injection.\n\n== Overview ==\nDAST tools facilitate the automated review of a web application with the express purpose of discovering security vulnerabilities and are required to comply with various regulatory requirements. Web application scanners can look for a wide variety of vulnerabilities, such as input/output validation: (e.g. cross-site scripting and SQL injection), specific application problems and server configuration mistakes.\nIn a copyrighted report published in March 2012 by security vendor Cenzic, the most common application vulnerabilities in recently tested applications include:\n\n== Commercial and open-source scanners ==\nCommercial scanners are a category of web-assessment tools which need to be purchased. Some scanners include some free features but most need to be bought for full access to the tool's power.\nOpen-source scanners are often free of cost to the user.\nSecurity researcher Shay Chen has previously compiled an exhaustive list of both commercial and open-source web application security scanners. The list also highlights how each of the scanners performed during his benchmarking tests against the Web Application Vulnerability Scanner Evaluation Project (WAVSEP).\nThe WAVSEP platform is publicly available and can be used to evaluate the various aspects of web application scanners: technology support, performance, accuracy, coverage and result consistency.\n\n\n*** DAST strengths ***\nThese tools can detect vulnerabilities of the finalized release candidate versions prior to shipping. Scanners simulate a malicious user by attacking and probing, identifying results which are not part of the expected result set, allowing for a realistic attack simulation. The big advantage of these types of tools are that they can scan year-round to be constantly searching for vulnerabilities. With new vulnerabilities being discovered regularly this allows companies to find and patch vulnerabilities before they can become exploited.As a dynamic testing tool, web scanners are not language-dependent. A web application scanner is able to scan engine-driven web applications. Attackers use the same tools, so if the tools can find a vulnerability, so can attackers.\n\n\n*** DAST weaknesses ***\nWhile scanning with a DAST tool, data may be overwritten or malicious payloads injected into the subject site. Sites should be scanned in a production-like but non-production environment to ensure accurate results while protecting the data in the production environment.\nBecause the tool is implementing a dynamic testing method, it cannot cover 100% of the source code of the application and then, the application itself. The penetration tester should look at the coverage of the web application or of its attack surface to know if the tool was configured correctly or was able to understand the web application.\nThe tool cannot implement all variants of attacks for a given vulnerability. So the tools generally have a predefined list of attacks and do not generate the attack payloads depending on the tested web application. Some tools are also quite limited in their understanding of the behavior of applications with dynamic content such as JavaScript and Flash.\nA report from 2012 found that the top application technologies overlooked by most Web application scanners includes jQuery, REST, and Google WebToolkit in AJAX applications, Flash Remoting (AMF) and HTML5, as well as mobile apps and Web Services using JSON and REST. XML-RPC and SOAP technologies used in Web services, and complex workflows such as shopping cart, and XSRF/CSRF tokens.\n\nAnswer this question \"How do DAST tools perform automated reviews of web applications?\" using the text above.",
    "context": "",
    "output": "DAST tools facilitate the automated review of a web application by looking for a wide variety of vulnerabilities, such as input/output validation, specific application problems, and server configuration mistakes. They can detect vulnerabilities of the finalized release candidate versions prior to shipping, simulate a malicious user by attacking and probing, and scan year-round to be constantly searching for vulnerabilities.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How do DAST tools perform automated reviews of web applications?",
      "answer": "DAST tools facilitate the automated review of a web application by looking for a wide variety of vulnerabilities, such as input/output validation, specific application problems, and server configuration mistakes. They can detect vulnerabilities of the finalized release candidate versions prior to shipping, simulate a malicious user by attacking and probing, and scan year-round to be constantly searching for vulnerabilities.",
      "context": "Dynamic application security testing\n\n==Introduction==\nA dynamic application security testing (DAST) is a non functional testing process where one can assess an application using certain techniques and the end result of such testing process covers security weaknesses and vulnerabilities present in an application. This testing process can be carried out either in manual way or by using automated tools. Manual assessment of an application involves a more human intervention to identify the security flaws which might slip from an automated tool. Usually business logic errors, race condition checks, and certain zero day vulnerabilities can only be identified using manual assessments. On the other side, a DAST tool is a program which communicates with a web application through the web front-end in order to identify potential security vulnerabilities in the web application and architectural weaknesses. It performs a black-box test. Unlike static application security testing tools, DAST tools do not have access to the source code and therefore detect vulnerabilities by actually performing attacks.\nDAST tools allow sophisticated scans, detecting vulnerabilities with minimal user interactions once configured with host name, crawling parameters and authentication credentials. These tools will attempt to detect vulnerabilities in query strings, headers, fragments, verbs (GET/POST/PUT) and DOM injection.\n\n== Overview ==\nDAST tools facilitate the automated review of a web application with the express purpose of discovering security vulnerabilities and are required to comply with various regulatory requirements. Web application scanners can look for a wide variety of vulnerabilities, such as input/output validation: (e.g. cross-site scripting and SQL injection), specific application problems and server configuration mistakes.\nIn a copyrighted report published in March 2012 by security vendor Cenzic, the most common application vulnerabilities in recently tested applications include:\n\n== Commercial and open-source scanners ==\nCommercial scanners are a category of web-assessment tools which need to be purchased. Some scanners include some free features but most need to be bought for full access to the tool's power.\nOpen-source scanners are often free of cost to the user.\nSecurity researcher Shay Chen has previously compiled an exhaustive list of both commercial and open-source web application security scanners. The list also highlights how each of the scanners performed during his benchmarking tests against the Web Application Vulnerability Scanner Evaluation Project (WAVSEP).\nThe WAVSEP platform is publicly available and can be used to evaluate the various aspects of web application scanners: technology support, performance, accuracy, coverage and result consistency.\n\n\n*** DAST strengths ***\nThese tools can detect vulnerabilities of the finalized release candidate versions prior to shipping. Scanners simulate a malicious user by attacking and probing, identifying results which are not part of the expected result set, allowing for a realistic attack simulation. The big advantage of these types of tools are that they can scan year-round to be constantly searching for vulnerabilities. With new vulnerabilities being discovered regularly this allows companies to find and patch vulnerabilities before they can become exploited.As a dynamic testing tool, web scanners are not language-dependent. A web application scanner is able to scan engine-driven web applications. Attackers use the same tools, so if the tools can find a vulnerability, so can attackers.\n\n\n*** DAST weaknesses ***\nWhile scanning with a DAST tool, data may be overwritten or malicious payloads injected into the subject site. Sites should be scanned in a production-like but non-production environment to ensure accurate results while protecting the data in the production environment.\nBecause the tool is implementing a dynamic testing method, it cannot cover 100% of the source code of the application and then, the application itself. The penetration tester should look at the coverage of the web application or of its attack surface to know if the tool was configured correctly or was able to understand the web application.\nThe tool cannot implement all variants of attacks for a given vulnerability. So the tools generally have a predefined list of attacks and do not generate the attack payloads depending on the tested web application. Some tools are also quite limited in their understanding of the behavior of applications with dynamic content such as JavaScript and Flash.\nA report from 2012 found that the top application technologies overlooked by most Web application scanners includes jQuery, REST, and Google WebToolkit in AJAX applications, Flash Remoting (AMF) and HTML5, as well as mobile apps and Web Services using JSON and REST. XML-RPC and SOAP technologies used in Web services, and complex workflows such as shopping cart, and XSRF/CSRF tokens."
    }
  },
  {
    "instruction": "The Hebern rotor machine was a device for encryption that Edward Hugh Hebern patented in 1918. He started a company to market the machine and employed Agnes Meyer, who left the Navy in Washington, D.C., to work for him in California.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What was the Hebern rotor machine, and how did Edward Hugh Hebern market it?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What was the Hebern rotor machine, and how did Edward Hugh Hebern market it?",
      "answer": "The Hebern rotor machine was a device for encryption that Edward Hugh Hebern patented in 1918. He started a company to market the machine and employed Agnes Meyer, who left the Navy in Washington, D.C., to work for him in California."
    }
  },
  {
    "instruction": "Using large prime numbers in trapdoor functions makes it more difficult to guess the trapdoor information. This increase in difficulty is due to the fact that there are more possible combinations of large prime numbers.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the significance of using large prime numbers in trapdoor functions?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the significance of using large prime numbers in trapdoor functions?",
      "answer": "Using large prime numbers in trapdoor functions makes it more difficult to guess the trapdoor information. This increase in difficulty is due to the fact that there are more possible combinations of large prime numbers."
    }
  },
  {
    "instruction": "Most CSRF prevention techniques work by embedding additional authentication data into requests that allows the web application to detect requests from unauthorized locations. This can include the synchronizer token pattern, the cookie-to-header token method, or other methods.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How can websites prevent cross-site request forgery attacks?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How can websites prevent cross-site request forgery attacks?",
      "answer": "Most CSRF prevention techniques work by embedding additional authentication data into requests that allows the web application to detect requests from unauthorized locations. This can include the synchronizer token pattern, the cookie-to-header token method, or other methods."
    }
  },
  {
    "instruction": "Lastline has gone through four funding rounds since its founding in 2011.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How many funding rounds has Lastline gone through since its founding in 2011?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How many funding rounds has Lastline gone through since its founding in 2011?",
      "answer": "Lastline has gone through four funding rounds since its founding in 2011."
    }
  },
  {
    "instruction": "An organization can detect the presence of an intercepting proxy server by comparing the client's external IP address to the address seen by an external web server, comparing the result of online IP checkers when accessed using HTTPS vs HTTP, comparing the sequence of network hops reported by a tool such as traceroute for a proxied protocol such as HTTP with that for a non-proxied protocol such as SMTP, attempting to make a connection to an IP address at which there is known to be no server, or serving the end-user specially programmed Adobe Flash SWF applications or Sun Java applets that send HTTP calls back to their server.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How can an organization detect the presence of an intercepting proxy server?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How can an organization detect the presence of an intercepting proxy server?",
      "answer": "An organization can detect the presence of an intercepting proxy server by comparing the client's external IP address to the address seen by an external web server, comparing the result of online IP checkers when accessed using HTTPS vs HTTP, comparing the sequence of network hops reported by a tool such as traceroute for a proxied protocol such as HTTP with that for a non-proxied protocol such as SMTP, attempting to make a connection to an IP address at which there is known to be no server, or serving the end-user specially programmed Adobe Flash SWF applications or Sun Java applets that send HTTP calls back to their server."
    }
  },
  {
    "instruction": "A Protection Profile (PP) is a document that provides an implementation-independent specification of information assurance security requirements for a given family of information system products. It combines threats, security objectives, assumptions, security functional requirements (SFRs), security assurance requirements (SARs), and rationales to specify generic security evaluation criteria. A PP may inherit requirements from other PPs and typically specifies an Evaluation Assurance Level (EAL) indicating the depth and rigor of the security evaluation that a product meets the security requirements specified in the PP.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is a Protection Profile (PP) used for in the context of the Common Criteria (CC) certification process?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is a Protection Profile (PP) used for in the context of the Common Criteria (CC) certification process?",
      "answer": "A Protection Profile (PP) is a document that provides an implementation-independent specification of information assurance security requirements for a given family of information system products. It combines threats, security objectives, assumptions, security functional requirements (SFRs), security assurance requirements (SARs), and rationales to specify generic security evaluation criteria. A PP may inherit requirements from other PPs and typically specifies an Evaluation Assurance Level (EAL) indicating the depth and rigor of the security evaluation that a product meets the security requirements specified in the PP."
    }
  },
  {
    "instruction": "TrueCrypt is based on Encryption for the Masses (E4M), which was discontinued in 2000. The version history of TrueCrypt likely begins after the discontinuation of E4M.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does the version history of TrueCrypt relate to the discontinuation of Encryption for the Masses (E4M)?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does the version history of TrueCrypt relate to the discontinuation of Encryption for the Masses (E4M)?",
      "answer": "TrueCrypt is based on Encryption for the Masses (E4M), which was discontinued in 2000. The version history of TrueCrypt likely begins after the discontinuation of E4M."
    }
  },
  {
    "instruction": "Visibility and transparency in privacy by design assure all stakeholders that the system or technology involved is operating according to the stated promises and objectives, subject to independent verification.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the importance of Visibility and transparency in privacy by design?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the importance of Visibility and transparency in privacy by design?",
      "answer": "Visibility and transparency in privacy by design assure all stakeholders that the system or technology involved is operating according to the stated promises and objectives, subject to independent verification."
    }
  },
  {
    "instruction": "The President's Commission on Enhancing National Cybersecurity recommended nationally supported training programs to produce an adequate workforce, increasing the level of expertise in the existing workforce, and addressing the shortage of technicians who know cybersecurity and can protect systems.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What was the focus of the President's Commission on Enhancing National Cybersecurity in building the cybersecurity workforce?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What was the focus of the President's Commission on Enhancing National Cybersecurity in building the cybersecurity workforce?",
      "answer": "The President's Commission on Enhancing National Cybersecurity recommended nationally supported training programs to produce an adequate workforce, increasing the level of expertise in the existing workforce, and addressing the shortage of technicians who know cybersecurity and can protect systems."
    }
  },
  {
    "instruction": "Context: Tempest (codename)\n\n==Introduction==\nTEMPEST is a U.S. National Security Agency specification and a NATO certification referring to spying on information systems through leaking emanations, including unintentional radio or electrical signals, sounds, and vibrations. TEMPEST covers both methods to spy upon others and how to shield equipment against such spying. The protection efforts are also known as emission security (EMSEC), which is a subset of communications security (COMSEC).The NSA methods for spying on computer emissions are classified, but some of the protection standards have been released by either the NSA or the Department of Defense. Protecting equipment from spying is done with distance, shielding, filtering, and masking. The TEMPEST standards mandate elements such as equipment distance from walls, amount of shielding in buildings and equipment, and distance separating wires carrying classified vs. unclassified materials, filters on cables, and even distance and shielding between wires or equipment and building pipes. Noise can also protect information by masking the actual data.\n\nWhile much of TEMPEST is about leaking electromagnetic emanations, it also encompasses sounds and mechanical vibrations. For example, it is possible to log a user's keystrokes using the motion sensor inside smartphones. Compromising emissions are defined as unintentional intelligence-bearing signals which, if intercepted and analyzed (side-channel attack), may disclose the information transmitted, received, handled, or otherwise processed by any information-processing equipment.\n\n== Shielding standards ==\nMany specifics of the TEMPEST standards are classified, but some elements are public. Current United States and NATO Tempest standards define three levels of protection requirements:\nNATO SDIP-27 Level A (formerly AMSG 720B) and USA NSTISSAM Level I\"Compromising Emanations Laboratory Test Standard\"\nThis is the strictest standard for devices that will be operated in NATO Zone 0 environments, where it is assumed that an attacker has almost immediate access (e.g. neighbouring room, 1 metre; 3' distance).NATO SDIP-27 Level B (formerly AMSG 788A) and USA NSTISSAM Level II\"Laboratory Test Standard for Protected Facility Equipment\"\nThis is a slightly relaxed standard for devices that are operated in NATO Zone 1 environments, where it is assumed that an attacker cannot get closer than about 20 metres (65') (or where building materials ensure an attenuation equivalent to the free-space attenuation of this distance).NATO SDIP-27 Level C (formerly AMSG 784) and USA NSTISSAM Level III\"Laboratory Test Standard for Tactical Mobile Equipment/Systems\"\nAn even more relaxed standard for devices operated in NATO Zone 2 environments, where attackers have to deal with the equivalent of 100 metres (300') of free-space attenuation (or equivalent attenuation through building materials).Additional standards include:\n\nNATO SDIP-29 (formerly AMSG 719G)\"Installation of Electrical Equipment for the Processing of Classified Information\"\nThis standard defines installation requirements, for example in respect to grounding and cable distances.AMSG 799B\"NATO Zoning Procedures\"\nDefines an attenuation measurement procedure, according to which individual rooms within a security perimeter can be classified into Zone 0, Zone 1, Zone 2, or Zone 3, which then determines what shielding test standard is required for equipment that processes secret data in these rooms.The NSA and Department of Defense have declassified some TEMPEST elements after Freedom of Information Act requests, but the documents black out many key values and descriptions. The declassified version of the TEMPEST test standard is heavily redacted, with emanation limits and test procedures blacked out. A redacted version of the introductory Tempest handbook NACSIM 5000 was publicly released in December 2000. Additionally, the current NATO standard SDIP-27 (before 2006 known as AMSG 720B, AMSG 788A, and AMSG 784) is still classified.\n\nDespite this, some declassified documents give information on the shielding required by TEMPEST standards. For example, Military Handbook 1195 includes the chart at the right, showing electromagnetic shielding requirements at different frequencies. A declassified NSA specification for shielded enclosures offers similar shielding values, requiring, \"a minimum of 100 dB insertion loss from 1 KHz to 10 GHz.\" Since much of the current requirements are still classified, there are no publicly available correlations between this 100 dB shielding requirement and the newer zone-based shielding standards.\nIn addition, many separation distance requirements and other elements are provided by the declassified NSA red-black installation guidance, NSTISSAM TEMPEST/2-95.\n\n== Certification ==\nThe information-security agencies of several NATO countries publish lists of accredited testing labs and of equipment that has passed these tests:\n\nIn Canada: Canadian Industrial TEMPEST Program\nIn Germany: BSI German Zoned Products List\nIn the UK: UK CESG Directory of Infosec Assured Products, Section 12\nIn the U.S.: NSA TEMPEST Certification ProgramThe United States Army also has a Tempest testing facility, as part of the U.S. Army Information Systems Engineering Command, at Fort Huachuca, Arizona. Similar lists and facilities exist in other NATO countries.\nTempest certification must apply to entire systems, not just to individual components, since connecting a single unshielded component (such as a cable or device) to an otherwise secure system could dramatically alter the system RF characteristics.\n\n== RED/BLACK separation ==\nTEMPEST standards require \"RED/BLACK separation\", i.e., maintaining distance or installing shielding between circuits and equipment used to handle plaintext classified or sensitive information that is not encrypted (RED) and secured circuits and equipment (BLACK), the latter including those carrying encrypted signals. Manufacture of TEMPEST-approved equipment must be done under careful quality control to ensure that additional units are built exactly the same as the units that were tested. Changing even a single wire can invalidate the tests.\n\n== Correlated emanations ==\nOne aspect of Tempest testing that distinguishes it from limits on spurious emissions (e.g., FCC Part 15) is a requirement of absolute minimal correlation between radiated energy or detectable emissions and any plaintext data that are being processed.\n\n== Public research ==\nIn 1985, Wim van Eck published the first unclassified technical analysis of the security risks of emanations from computer monitors. This paper caused some consternation in the security community, which had previously believed that such monitoring was a highly sophisticated attack available only to governments; van Eck successfully eavesdropped on a real system, at a range of hundreds of metres, using just $15 worth of equipment plus a television set.\nAs a consequence of this research, such emanations are sometimes called \"van Eck radiation\", and the eavesdropping technique van Eck phreaking, although government researchers were already aware of the danger, as Bell Labs noted this vulnerability to secure teleprinter communications during World War II and was able to produce 75% of the plaintext being processed in a secure facility from a distance of 80 feet (24 metres) Additionally the NSA published Tempest Fundamentals, NSA-82-89, NACSIM 5000, National Security Agency (Classified) on February 1, 1982. In addition, the van Eck technique was successfully demonstrated to non-TEMPEST personnel in Korea during the Korean War in the 1950s.Markus Kuhn has discovered several low-cost techniques for reducing the chances that emanations from computer displays can be monitored remotely. With CRT displays and analog video cables, filtering out high-frequency components from fonts before rendering them on a computer screen will attenuate the energy at which text characters are broadcast. With modern flat panel displays, the high-speed digital serial interface (DVI) cables from the graphics controller are a main source of compromising emanations. Adding random noise to the least significant bits of pixel values may render the emanations from flat-panel displays unintelligible to eavesdroppers but is not a secure method. Since DVI uses a certain bit code scheme that tries to transport a balanced signal of 0 bits and 1 bits, there may not be much difference between two pixel colors that differ very much in their color or intensity. The emanations can differ drastically even if only the last bit of a pixel's color is changed. The signal received by the eavesdropper also depends on the frequency where the emanations are detected. The signal can be received on many frequencies at once and each frequency's signal differs in contrast and brightness related to a certain color on the screen. Usually, the technique of smothering the RED signal with noise is not effective unless the power of the noise is sufficient to drive the eavesdropper's receiver into saturation thus overwhelming the receiver input.\nLED indicators on computer equipment can be a source of compromising optical emanations. One such technique involves the monitoring of the lights on a dial-up modem. Almost all modems flash an LED to show activity, and it is common for the flashes to be directly taken from the data line. As such, a fast optical system can easily see the changes in the flickers from the data being transmitted down the wire.\nRecent research has shown it is possible to detect the radiation corresponding to a keypress event from not only wireless (radio) keyboards, but also from traditional wired keyboards, and even from laptop keyboards. From the 1970s onward, Soviet bugging of US Embassy IBM Selectric typewriters allowed the keypress-derived mechanical motion of bails, with attached magnets, to be detected by implanted magnetometers, and converted via hidden electronics to a digital radio frequency signal. Each eight character transmission provided Soviet access to sensitive documents, as they were being typed, at US facilities in Moscow and Leningrad.In 2014, researchers introduced \"AirHopper\", a bifurcated attack pattern showing the feasibility of data exfiltration from an isolated computer to a nearby mobile phone, using FM frequency signals.In 2015, \"BitWhisper\", a Covert Signaling Channel between Air-Gapped Computers using Thermal Manipulations was introduced. \"BitWhisper\" supports bidirectional communication and requires no additional dedicated peripheral hardware. Later in 2015, researchers introduced GSMem, a method for exfiltrating data from air-gapped computers over cellular frequencies. The transmission - generated by a standard internal bus - renders the computer into a small cellular transmitter antenna. In February 2018, research was published describing how low frequency magnetic fields can be used to escape sensitive data from Faraday-caged, air-gapped computers with malware code-named \u2019ODINI\u2019 that can control the low frequency magnetic fields emitted from infected computers by regulating the load of CPU cores.In 2018, a class of side-channel attack was introduced at ACM and Black Hat by Eurecom's researchers: \"Screaming Channels\". This kind of attack targets mix-signal chips \u2014 containing an analog and digital circuit on the same silicon die \u2014 with a radio transmitter. The results of this architecture, often found in connected objects, is that the digital part of the chip will leak some metadata on its computations into the analog part, which leads to metadata's leak being encoded in the noise of the radio transmission. Thanks to signal-processing techniques, researchers were able to extract cryptographic keys used during the communication and decrypt the content. This attack class is supposed, by the authors, to being already known since many years by governmental intelligence agencies.\n\n== In popular culture ==\nIn the television series Numb3rs, season 1 episode \"Sacrifice\", a wire connected to a high gain antenna was used to \"read\" from a computer monitor.\nIn the television series Spooks, season 4 episode \"The Sting\", a failed attempt to read information from a computer that has no network link is described.\nIn the novel Cryptonomicon by Neal Stephenson, characters use Van Eck phreaking to likewise read information from a computer monitor in a neighboring room.\nIn the television series Agents of S.H.I.E.L.D., season 1 episode \"Ragtag\", an office is scanned for digital signatures in the UHF spectrum.\nIn the video game Tom Clancy's Splinter Cell: Chaos Theory, part of the final mission involves spying on a meeting in a Tempest-hardened war room. Throughout the entire Splinter Cell series, a laser microphone is used as well.\nIn the video game Rainbow Six: Siege, the operator Mute has experience in TEMPEST specifications. He designed a Signal Disrupter initially to ensure that hidden microphones in sensitive meetings would not transmit, and adapted them for combat, capable of disrupting remotely activated devices like breaching charges.\nIn the novel series The Laundry Files by Charles Stross, the character James Angleton (high-ranking officer of an ultra-secret intelligence agency) always uses low tech devices such as a typewriter or a Memex to defend against TEMPEST (despite the building being tempest-shielded).\nQuestion: How can LED indicators on computer equipment pose a security risk?. Whats the answer?",
    "context": "",
    "output": "LED indicators on computer equipment can be a source of compromising optical emanations. For example, the lights on a dial-up modem can be monitored to see changes in the flickers from the data being transmitted down the wire.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How can LED indicators on computer equipment pose a security risk?",
      "answer": "LED indicators on computer equipment can be a source of compromising optical emanations. For example, the lights on a dial-up modem can be monitored to see changes in the flickers from the data being transmitted down the wire.",
      "context": "Tempest (codename)\n\n==Introduction==\nTEMPEST is a U.S. National Security Agency specification and a NATO certification referring to spying on information systems through leaking emanations, including unintentional radio or electrical signals, sounds, and vibrations. TEMPEST covers both methods to spy upon others and how to shield equipment against such spying. The protection efforts are also known as emission security (EMSEC), which is a subset of communications security (COMSEC).The NSA methods for spying on computer emissions are classified, but some of the protection standards have been released by either the NSA or the Department of Defense. Protecting equipment from spying is done with distance, shielding, filtering, and masking. The TEMPEST standards mandate elements such as equipment distance from walls, amount of shielding in buildings and equipment, and distance separating wires carrying classified vs. unclassified materials, filters on cables, and even distance and shielding between wires or equipment and building pipes. Noise can also protect information by masking the actual data.\n\nWhile much of TEMPEST is about leaking electromagnetic emanations, it also encompasses sounds and mechanical vibrations. For example, it is possible to log a user's keystrokes using the motion sensor inside smartphones. Compromising emissions are defined as unintentional intelligence-bearing signals which, if intercepted and analyzed (side-channel attack), may disclose the information transmitted, received, handled, or otherwise processed by any information-processing equipment.\n\n== Shielding standards ==\nMany specifics of the TEMPEST standards are classified, but some elements are public. Current United States and NATO Tempest standards define three levels of protection requirements:\nNATO SDIP-27 Level A (formerly AMSG 720B) and USA NSTISSAM Level I\"Compromising Emanations Laboratory Test Standard\"\nThis is the strictest standard for devices that will be operated in NATO Zone 0 environments, where it is assumed that an attacker has almost immediate access (e.g. neighbouring room, 1 metre; 3' distance).NATO SDIP-27 Level B (formerly AMSG 788A) and USA NSTISSAM Level II\"Laboratory Test Standard for Protected Facility Equipment\"\nThis is a slightly relaxed standard for devices that are operated in NATO Zone 1 environments, where it is assumed that an attacker cannot get closer than about 20 metres (65') (or where building materials ensure an attenuation equivalent to the free-space attenuation of this distance).NATO SDIP-27 Level C (formerly AMSG 784) and USA NSTISSAM Level III\"Laboratory Test Standard for Tactical Mobile Equipment/Systems\"\nAn even more relaxed standard for devices operated in NATO Zone 2 environments, where attackers have to deal with the equivalent of 100 metres (300') of free-space attenuation (or equivalent attenuation through building materials).Additional standards include:\n\nNATO SDIP-29 (formerly AMSG 719G)\"Installation of Electrical Equipment for the Processing of Classified Information\"\nThis standard defines installation requirements, for example in respect to grounding and cable distances.AMSG 799B\"NATO Zoning Procedures\"\nDefines an attenuation measurement procedure, according to which individual rooms within a security perimeter can be classified into Zone 0, Zone 1, Zone 2, or Zone 3, which then determines what shielding test standard is required for equipment that processes secret data in these rooms.The NSA and Department of Defense have declassified some TEMPEST elements after Freedom of Information Act requests, but the documents black out many key values and descriptions. The declassified version of the TEMPEST test standard is heavily redacted, with emanation limits and test procedures blacked out. A redacted version of the introductory Tempest handbook NACSIM 5000 was publicly released in December 2000. Additionally, the current NATO standard SDIP-27 (before 2006 known as AMSG 720B, AMSG 788A, and AMSG 784) is still classified.\n\nDespite this, some declassified documents give information on the shielding required by TEMPEST standards. For example, Military Handbook 1195 includes the chart at the right, showing electromagnetic shielding requirements at different frequencies. A declassified NSA specification for shielded enclosures offers similar shielding values, requiring, \"a minimum of 100 dB insertion loss from 1 KHz to 10 GHz.\" Since much of the current requirements are still classified, there are no publicly available correlations between this 100 dB shielding requirement and the newer zone-based shielding standards.\nIn addition, many separation distance requirements and other elements are provided by the declassified NSA red-black installation guidance, NSTISSAM TEMPEST/2-95.\n\n== Certification ==\nThe information-security agencies of several NATO countries publish lists of accredited testing labs and of equipment that has passed these tests:\n\nIn Canada: Canadian Industrial TEMPEST Program\nIn Germany: BSI German Zoned Products List\nIn the UK: UK CESG Directory of Infosec Assured Products, Section 12\nIn the U.S.: NSA TEMPEST Certification ProgramThe United States Army also has a Tempest testing facility, as part of the U.S. Army Information Systems Engineering Command, at Fort Huachuca, Arizona. Similar lists and facilities exist in other NATO countries.\nTempest certification must apply to entire systems, not just to individual components, since connecting a single unshielded component (such as a cable or device) to an otherwise secure system could dramatically alter the system RF characteristics.\n\n== RED/BLACK separation ==\nTEMPEST standards require \"RED/BLACK separation\", i.e., maintaining distance or installing shielding between circuits and equipment used to handle plaintext classified or sensitive information that is not encrypted (RED) and secured circuits and equipment (BLACK), the latter including those carrying encrypted signals. Manufacture of TEMPEST-approved equipment must be done under careful quality control to ensure that additional units are built exactly the same as the units that were tested. Changing even a single wire can invalidate the tests.\n\n== Correlated emanations ==\nOne aspect of Tempest testing that distinguishes it from limits on spurious emissions (e.g., FCC Part 15) is a requirement of absolute minimal correlation between radiated energy or detectable emissions and any plaintext data that are being processed.\n\n== Public research ==\nIn 1985, Wim van Eck published the first unclassified technical analysis of the security risks of emanations from computer monitors. This paper caused some consternation in the security community, which had previously believed that such monitoring was a highly sophisticated attack available only to governments; van Eck successfully eavesdropped on a real system, at a range of hundreds of metres, using just $15 worth of equipment plus a television set.\nAs a consequence of this research, such emanations are sometimes called \"van Eck radiation\", and the eavesdropping technique van Eck phreaking, although government researchers were already aware of the danger, as Bell Labs noted this vulnerability to secure teleprinter communications during World War II and was able to produce 75% of the plaintext being processed in a secure facility from a distance of 80 feet (24 metres) Additionally the NSA published Tempest Fundamentals, NSA-82-89, NACSIM 5000, National Security Agency (Classified) on February 1, 1982. In addition, the van Eck technique was successfully demonstrated to non-TEMPEST personnel in Korea during the Korean War in the 1950s.Markus Kuhn has discovered several low-cost techniques for reducing the chances that emanations from computer displays can be monitored remotely. With CRT displays and analog video cables, filtering out high-frequency components from fonts before rendering them on a computer screen will attenuate the energy at which text characters are broadcast. With modern flat panel displays, the high-speed digital serial interface (DVI) cables from the graphics controller are a main source of compromising emanations. Adding random noise to the least significant bits of pixel values may render the emanations from flat-panel displays unintelligible to eavesdroppers but is not a secure method. Since DVI uses a certain bit code scheme that tries to transport a balanced signal of 0 bits and 1 bits, there may not be much difference between two pixel colors that differ very much in their color or intensity. The emanations can differ drastically even if only the last bit of a pixel's color is changed. The signal received by the eavesdropper also depends on the frequency where the emanations are detected. The signal can be received on many frequencies at once and each frequency's signal differs in contrast and brightness related to a certain color on the screen. Usually, the technique of smothering the RED signal with noise is not effective unless the power of the noise is sufficient to drive the eavesdropper's receiver into saturation thus overwhelming the receiver input.\nLED indicators on computer equipment can be a source of compromising optical emanations. One such technique involves the monitoring of the lights on a dial-up modem. Almost all modems flash an LED to show activity, and it is common for the flashes to be directly taken from the data line. As such, a fast optical system can easily see the changes in the flickers from the data being transmitted down the wire.\nRecent research has shown it is possible to detect the radiation corresponding to a keypress event from not only wireless (radio) keyboards, but also from traditional wired keyboards, and even from laptop keyboards. From the 1970s onward, Soviet bugging of US Embassy IBM Selectric typewriters allowed the keypress-derived mechanical motion of bails, with attached magnets, to be detected by implanted magnetometers, and converted via hidden electronics to a digital radio frequency signal. Each eight character transmission provided Soviet access to sensitive documents, as they were being typed, at US facilities in Moscow and Leningrad.In 2014, researchers introduced \"AirHopper\", a bifurcated attack pattern showing the feasibility of data exfiltration from an isolated computer to a nearby mobile phone, using FM frequency signals.In 2015, \"BitWhisper\", a Covert Signaling Channel between Air-Gapped Computers using Thermal Manipulations was introduced. \"BitWhisper\" supports bidirectional communication and requires no additional dedicated peripheral hardware. Later in 2015, researchers introduced GSMem, a method for exfiltrating data from air-gapped computers over cellular frequencies. The transmission - generated by a standard internal bus - renders the computer into a small cellular transmitter antenna. In February 2018, research was published describing how low frequency magnetic fields can be used to escape sensitive data from Faraday-caged, air-gapped computers with malware code-named \u2019ODINI\u2019 that can control the low frequency magnetic fields emitted from infected computers by regulating the load of CPU cores.In 2018, a class of side-channel attack was introduced at ACM and Black Hat by Eurecom's researchers: \"Screaming Channels\". This kind of attack targets mix-signal chips \u2014 containing an analog and digital circuit on the same silicon die \u2014 with a radio transmitter. The results of this architecture, often found in connected objects, is that the digital part of the chip will leak some metadata on its computations into the analog part, which leads to metadata's leak being encoded in the noise of the radio transmission. Thanks to signal-processing techniques, researchers were able to extract cryptographic keys used during the communication and decrypt the content. This attack class is supposed, by the authors, to being already known since many years by governmental intelligence agencies.\n\n== In popular culture ==\nIn the television series Numb3rs, season 1 episode \"Sacrifice\", a wire connected to a high gain antenna was used to \"read\" from a computer monitor.\nIn the television series Spooks, season 4 episode \"The Sting\", a failed attempt to read information from a computer that has no network link is described.\nIn the novel Cryptonomicon by Neal Stephenson, characters use Van Eck phreaking to likewise read information from a computer monitor in a neighboring room.\nIn the television series Agents of S.H.I.E.L.D., season 1 episode \"Ragtag\", an office is scanned for digital signatures in the UHF spectrum.\nIn the video game Tom Clancy's Splinter Cell: Chaos Theory, part of the final mission involves spying on a meeting in a Tempest-hardened war room. Throughout the entire Splinter Cell series, a laser microphone is used as well.\nIn the video game Rainbow Six: Siege, the operator Mute has experience in TEMPEST specifications. He designed a Signal Disrupter initially to ensure that hidden microphones in sensitive meetings would not transmit, and adapted them for combat, capable of disrupting remotely activated devices like breaching charges.\nIn the novel series The Laundry Files by Charles Stross, the character James Angleton (high-ranking officer of an ultra-secret intelligence agency) always uses low tech devices such as a typewriter or a Memex to defend against TEMPEST (despite the building being tempest-shielded)."
    }
  },
  {
    "instruction": "PlayStation 3 Jailbreak is the first USB chipset that enabled the unauthorized execution of code on the PlayStation 3. It functions by bypassing a system security check using a memory exploit, specifically a heap overflow, which occurs with USB devices, thereby allowing the execution of unsigned code.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is PlayStation 3 Jailbreak, and how does it work?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is PlayStation 3 Jailbreak, and how does it work?",
      "answer": "PlayStation 3 Jailbreak is the first USB chipset that enabled the unauthorized execution of code on the PlayStation 3. It functions by bypassing a system security check using a memory exploit, specifically a heap overflow, which occurs with USB devices, thereby allowing the execution of unsigned code."
    }
  },
  {
    "instruction": "GpgEX supports all versions of Microsoft Outlook.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What versions of Microsoft Outlook does GpgEX support?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What versions of Microsoft Outlook does GpgEX support?",
      "answer": "GpgEX supports all versions of Microsoft Outlook."
    }
  },
  {
    "instruction": "The purpose of the Using the Secure Remote Password (SRP) Protocol for TLS Authentication RFC standard in TLS-SRP is to define how the SRP protocol is used for TLS authentication in TLS-SRP.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the purpose of the Using the Secure Remote Password (SRP) Protocol for TLS Authentication RFC standard in TLS-SRP?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the purpose of the Using the Secure Remote Password (SRP) Protocol for TLS Authentication RFC standard in TLS-SRP?",
      "answer": "The purpose of the Using the Secure Remote Password (SRP) Protocol for TLS Authentication RFC standard in TLS-SRP is to define how the SRP protocol is used for TLS authentication in TLS-SRP."
    }
  },
  {
    "instruction": "The Beaufort cipher differs from the Vigen\u00e8re cipher in that it is a reciprocal cipher, meaning the encryption and decryption algorithms are the same. This is different from the Vigen\u00e8re cipher, where the decryption algorithm is different from the encryption algorithm.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How is the Beaufort cipher different from the Vigen\u00e8re cipher?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How is the Beaufort cipher different from the Vigen\u00e8re cipher?",
      "answer": "The Beaufort cipher differs from the Vigen\u00e8re cipher in that it is a reciprocal cipher, meaning the encryption and decryption algorithms are the same. This is different from the Vigen\u00e8re cipher, where the decryption algorithm is different from the encryption algorithm."
    }
  },
  {
    "instruction": "The xkcd comic 538: Security contrasts the technical and physical aspects of cryptanalysis by showing a crypto nerd imagining that they have defeated crackers with advanced encryption, while in reality, people with a desire to access the information use physical torture to coerce the nerd into giving up the password.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does the xkcd comic 538: Security contrast the technical and physical aspects of cryptanalysis?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does the xkcd comic 538: Security contrast the technical and physical aspects of cryptanalysis?",
      "answer": "The xkcd comic 538: Security contrasts the technical and physical aspects of cryptanalysis by showing a crypto nerd imagining that they have defeated crackers with advanced encryption, while in reality, people with a desire to access the information use physical torture to coerce the nerd into giving up the password."
    }
  },
  {
    "instruction": "TLS-SRP can be considered more secure than traditional TLS due to its use of password-based authentication, mutual authentication, and reduced vulnerability to certain types of configuration mistakes.\n\nWrite a question about the text above.",
    "context": "",
    "output": "Is TLS-SRP more secure than traditional TLS?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "Is TLS-SRP more secure than traditional TLS?",
      "answer": "TLS-SRP can be considered more secure than traditional TLS due to its use of password-based authentication, mutual authentication, and reduced vulnerability to certain types of configuration mistakes."
    }
  },
  {
    "instruction": "Yes, compression can always be disabled in Microsoft SEAL.\n\nWrite a question about the text above.",
    "context": "",
    "output": "Is it possible to disable compression in Microsoft SEAL?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "Is it possible to disable compression in Microsoft SEAL?",
      "answer": "Yes, compression can always be disabled in Microsoft SEAL."
    }
  },
  {
    "instruction": "Marvell and Avago/LSI SandForce flash controllers are among the storage controller companies that implement the Opal SSC.\n\nWrite a question about the text above.",
    "context": "",
    "output": "Which storage controller companies implement the Opal SSC in their products?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "Which storage controller companies implement the Opal SSC in their products?",
      "answer": "Marvell and Avago/LSI SandForce flash controllers are among the storage controller companies that implement the Opal SSC."
    }
  },
  {
    "instruction": "Code Access Security (CAS) uses the zone evidence to determine the security zone where the assembly resides and grants or denies permissions based on that.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does Code Access Security (CAS) handle security zones in .NET framework?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does Code Access Security (CAS) handle security zones in .NET framework?",
      "answer": "Code Access Security (CAS) uses the zone evidence to determine the security zone where the assembly resides and grants or denies permissions based on that."
    }
  },
  {
    "instruction": "The US Secret Service conducted Operation Cybersnare in 1995, which involved setting up an undercover bulletin board system in Bergen County, New Jersey. They advertised the bulletin board across the internet, discussing topics such as cellular telephone cloning and computer hacking. The operation led to the arrest of six hackers in September, who were charged with various crimes related to telecommunications. Richard Lacap and Kevin Watkins were charged with conspiring to break into the computer system of an Oregon Cellular Telephone company. Jeremy Cushing, Frank Natoli, and Al Bradford were charged with trafficking in stolen access devices used to program cellular telephones. Michael Clarkson was charged with possessing and trafficking in hardware used to obtain unauthorized access to telecommunications services.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How did the US Secret Service use an undercover operation to arrest hackers, and what kind of equipment were they charged with trafficking?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How did the US Secret Service use an undercover operation to arrest hackers, and what kind of equipment were they charged with trafficking?",
      "answer": "The US Secret Service conducted Operation Cybersnare in 1995, which involved setting up an undercover bulletin board system in Bergen County, New Jersey. They advertised the bulletin board across the internet, discussing topics such as cellular telephone cloning and computer hacking. The operation led to the arrest of six hackers in September, who were charged with various crimes related to telecommunications. Richard Lacap and Kevin Watkins were charged with conspiring to break into the computer system of an Oregon Cellular Telephone company. Jeremy Cushing, Frank Natoli, and Al Bradford were charged with trafficking in stolen access devices used to program cellular telephones. Michael Clarkson was charged with possessing and trafficking in hardware used to obtain unauthorized access to telecommunications services."
    }
  },
  {
    "instruction": "The Board of Directors for RENIC in 2018 included Universidad de M\u00e1laga as the President, CSIC as the Vicepresident, Universidad Polit\u00e9cnica de Madrid as the Treasurer, Universidad de Granada as the Secretary, and Tecnalia, Universidad de La Laguna, and Universidad de Modrag\u00f3n as Vocals.\n\nWrite a question about the text above.",
    "context": "",
    "output": "Who were the members of the Board of Directors for RENIC in 2018?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "Who were the members of the Board of Directors for RENIC in 2018?",
      "answer": "The Board of Directors for RENIC in 2018 included Universidad de M\u00e1laga as the President, CSIC as the Vicepresident, Universidad Polit\u00e9cnica de Madrid as the Treasurer, Universidad de Granada as the Secretary, and Tecnalia, Universidad de La Laguna, and Universidad de Modrag\u00f3n as Vocals."
    }
  },
  {
    "instruction": "Modern remote keyless-entry systems protect against replay attacks by using buffered replay attacks, which are performed by placing a device that can receive and transmit radio waves within range of the target vehicle, but these systems are still vulnerable to this type of attack.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How do modern remote keyless-entry systems protect against replay attacks?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How do modern remote keyless-entry systems protect against replay attacks?",
      "answer": "Modern remote keyless-entry systems protect against replay attacks by using buffered replay attacks, which are performed by placing a device that can receive and transmit radio waves within range of the target vehicle, but these systems are still vulnerable to this type of attack."
    }
  },
  {
    "instruction": "The second authorized user in MPA is responsible for reviewing and approving of activity involving critical or sensitive data or systems before the action takes place, providing an extra layer of security.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the role of the second authorized user in MPA?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the role of the second authorized user in MPA?",
      "answer": "The second authorized user in MPA is responsible for reviewing and approving of activity involving critical or sensitive data or systems before the action takes place, providing an extra layer of security."
    }
  },
  {
    "instruction": "StarDust, a major revision of Dexter, compromised 20,000 cards in an active campaign targeting US merchants.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How did StarDust affect US merchants?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How did StarDust affect US merchants?",
      "answer": "StarDust, a major revision of Dexter, compromised 20,000 cards in an active campaign targeting US merchants."
    }
  },
  {
    "instruction": "The cognitive trapdoor game is a method used for countermeasure testing in which a human prover inputs a PIN by answering questions posed by a machine verifier while an observer attempts to shoulder surf the PIN. The countermeasures are designed to be difficult to easily usurp, making it challenging for the observer to remember the whole login process without a recording device.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the cognitive trapdoor game and how is it used for countermeasure testing?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the cognitive trapdoor game and how is it used for countermeasure testing?",
      "answer": "The cognitive trapdoor game is a method used for countermeasure testing in which a human prover inputs a PIN by answering questions posed by a machine verifier while an observer attempts to shoulder surf the PIN. The countermeasures are designed to be difficult to easily usurp, making it challenging for the observer to remember the whole login process without a recording device."
    }
  },
  {
    "instruction": "Pakbugs had a significant impact on the banking industry, as it was responsible for hacking and defacing websites of five major Pakistani banks, as well as a few Indian and Middle Eastern banks. This highlights the seriousness of the threat that such forums pose to the banking industry and the need for robust cybersecurity measures to protect against such attacks.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What was the impact of the Pakbugs forum on the banking industry?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What was the impact of the Pakbugs forum on the banking industry?",
      "answer": "Pakbugs had a significant impact on the banking industry, as it was responsible for hacking and defacing websites of five major Pakistani banks, as well as a few Indian and Middle Eastern banks. This highlights the seriousness of the threat that such forums pose to the banking industry and the need for robust cybersecurity measures to protect against such attacks."
    }
  },
  {
    "instruction": "The lack of formal definitions provided by MAPS can contribute to confusion among subscribers because it makes it difficult for them to understand the specific criteria used to categorize and list addresses or IP blocks. This confusion may lead to subscribers making uninformed decisions when subscribing to the different lists.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How can the lack of formal definitions provided by MAPS contribute to confusion among subscribers?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How can the lack of formal definitions provided by MAPS contribute to confusion among subscribers?",
      "answer": "The lack of formal definitions provided by MAPS can contribute to confusion among subscribers because it makes it difficult for them to understand the specific criteria used to categorize and list addresses or IP blocks. This confusion may lead to subscribers making uninformed decisions when subscribing to the different lists."
    }
  },
  {
    "instruction": "A \"not particularly sophisticated\" malware for data exfiltration was used in Operation Newscaster, as described in the iSIGHT Partners report.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What kind of malware was used in Operation Newscaster, as described in the iSIGHT Partners report?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What kind of malware was used in Operation Newscaster, as described in the iSIGHT Partners report?",
      "answer": "A \"not particularly sophisticated\" malware for data exfiltration was used in Operation Newscaster, as described in the iSIGHT Partners report."
    }
  },
  {
    "instruction": "Network ACLs provide rules that are applied to port numbers or IP addresses that are available on a host or other layer 3, each with a list of hosts and/or networks permitted to use the service. They can be used to control both inbound and outbound traffic, and are similar to firewalls in this context.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the purpose of network ACLs and how are they used in computer security?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the purpose of network ACLs and how are they used in computer security?",
      "answer": "Network ACLs provide rules that are applied to port numbers or IP addresses that are available on a host or other layer 3, each with a list of hosts and/or networks permitted to use the service. They can be used to control both inbound and outbound traffic, and are similar to firewalls in this context."
    }
  },
  {
    "instruction": "The new command and control servers of the Lethic Botnet were located in the United States.\n\nWrite a question about the text above.",
    "context": "",
    "output": "Where were the new command and control servers of the Lethic Botnet located?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "Where were the new command and control servers of the Lethic Botnet located?",
      "answer": "The new command and control servers of the Lethic Botnet were located in the United States."
    }
  },
  {
    "instruction": "Context: Blinding (cryptography)\n\n==Introduction==\nIn cryptography, blinding is a technique by which an agent can provide a service to (i.e., compute a function for) a client in an encoded form without knowing either the real input or the real output.  Blinding techniques also have applications to preventing side-channel attacks on encryption devices.\nMore precisely, Alice has an input x and Oscar has a function f. Alice would like Oscar to compute y = f(x) for her without revealing either x or y to him. The reason for her wanting this might be that she doesn't know the function f or that she does not have the resources to compute it.\nAlice \"blinds\" the message by encoding it into some other input E(x);  the encoding E must be a bijection on the input space of f, ideally a random permutation. Oscar gives her f(E(x)), to which she applies a decoding D to obtain D(f(E(x))) = y.\nNot all functions allow for blind computation. At other times, blinding must be applied with care. An example of the latter is Rabin\u2013Williams signatures. If blinding is applied to the formatted message but the random value does not honor Jacobi requirements on p and q, then it could lead to private key recovery. A demonstration of the recovery can be seen in CVE-2015-2141 discovered by Evgeny Sidorov.\nThe most common application of blinding is the blind signature. In a blind signature protocol, the signer digitally signs a message without being able to learn its content.\nThe one-time pad (OTP) is an application of blinding to the secure communication problem, by its very nature. Alice would like to send a message to Bob secretly, however all of their communication can be read by Oscar. Therefore, Alice sends the message after blinding it with a secret key or OTP that she shares with Bob. Bob reverses the blinding after receiving the message. In this example, the function \nf is the identity and E and D are both typically the XOR operation.\nBlinding can also be used to prevent certain side-channel attacks on asymmetric encryption schemes.  Side-channel attacks allow an adversary to recover information about the input to a cryptographic operation, by measuring something other than the algorithm's result, e.g., power consumption, computation time, or radio-frequency emanations by a device.  Typically these attacks depend on the attacker knowing the characteristics of the algorithm, as well as (some) inputs.  In this setting, blinding serves to alter the algorithm's input into some unpredictable state.  Depending on the characteristics of the blinding function, this can prevent some or all leakage of useful information.  Note that security depends also on the resistance of the blinding functions themselves to side-channel attacks.\nFor example, in RSA blinding involves computing the blinding operation E(x) = (xr)e mod N, where r is a random integer between 1 and N and relatively prime to N (i.e. gcd(r, N) = 1), x is the plaintext, e is the public RSA exponent and N is the RSA modulus.  As usual, the decryption function f(z) = zd mod N is applied thus giving f(E(x)) = (xr)ed mod N =  xr mod N. Finally it is unblinded using the function D(z) = zr\u22121 mod N. Multiplying xr mod N by r\u22121 mod N yields x, as desired. When decrypting in this manner, an adversary who is able to measure time taken by this operation would not be able to make use of this information (by applying timing attacks RSA is known to be vulnerable to) as she does not know the constant r and hence has no knowledge of the real input fed to the RSA primitives.\n\n== Examples ==\nBlinding in GPG 1.x\nQuestion: How does the one-time pad (OTP) utilize blinding for secure communication?\n\nAnswer:",
    "context": "",
    "output": "In the OTP, Alice sends a message to Bob after blinding it with a shared secret key or OTP. Bob then reverses the blinding after receiving the message, ensuring secure communication between the two parties.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does the one-time pad (OTP) utilize blinding for secure communication?",
      "answer": "In the OTP, Alice sends a message to Bob after blinding it with a shared secret key or OTP. Bob then reverses the blinding after receiving the message, ensuring secure communication between the two parties.",
      "context": "Blinding (cryptography)\n\n==Introduction==\nIn cryptography, blinding is a technique by which an agent can provide a service to (i.e., compute a function for) a client in an encoded form without knowing either the real input or the real output.  Blinding techniques also have applications to preventing side-channel attacks on encryption devices.\nMore precisely, Alice has an input x and Oscar has a function f. Alice would like Oscar to compute y = f(x) for her without revealing either x or y to him. The reason for her wanting this might be that she doesn't know the function f or that she does not have the resources to compute it.\nAlice \"blinds\" the message by encoding it into some other input E(x);  the encoding E must be a bijection on the input space of f, ideally a random permutation. Oscar gives her f(E(x)), to which she applies a decoding D to obtain D(f(E(x))) = y.\nNot all functions allow for blind computation. At other times, blinding must be applied with care. An example of the latter is Rabin\u2013Williams signatures. If blinding is applied to the formatted message but the random value does not honor Jacobi requirements on p and q, then it could lead to private key recovery. A demonstration of the recovery can be seen in CVE-2015-2141 discovered by Evgeny Sidorov.\nThe most common application of blinding is the blind signature. In a blind signature protocol, the signer digitally signs a message without being able to learn its content.\nThe one-time pad (OTP) is an application of blinding to the secure communication problem, by its very nature. Alice would like to send a message to Bob secretly, however all of their communication can be read by Oscar. Therefore, Alice sends the message after blinding it with a secret key or OTP that she shares with Bob. Bob reverses the blinding after receiving the message. In this example, the function \nf is the identity and E and D are both typically the XOR operation.\nBlinding can also be used to prevent certain side-channel attacks on asymmetric encryption schemes.  Side-channel attacks allow an adversary to recover information about the input to a cryptographic operation, by measuring something other than the algorithm's result, e.g., power consumption, computation time, or radio-frequency emanations by a device.  Typically these attacks depend on the attacker knowing the characteristics of the algorithm, as well as (some) inputs.  In this setting, blinding serves to alter the algorithm's input into some unpredictable state.  Depending on the characteristics of the blinding function, this can prevent some or all leakage of useful information.  Note that security depends also on the resistance of the blinding functions themselves to side-channel attacks.\nFor example, in RSA blinding involves computing the blinding operation E(x) = (xr)e mod N, where r is a random integer between 1 and N and relatively prime to N (i.e. gcd(r, N) = 1), x is the plaintext, e is the public RSA exponent and N is the RSA modulus.  As usual, the decryption function f(z) = zd mod N is applied thus giving f(E(x)) = (xr)ed mod N =  xr mod N. Finally it is unblinded using the function D(z) = zr\u22121 mod N. Multiplying xr mod N by r\u22121 mod N yields x, as desired. When decrypting in this manner, an adversary who is able to measure time taken by this operation would not be able to make use of this information (by applying timing attacks RSA is known to be vulnerable to) as she does not know the constant r and hence has no knowledge of the real input fed to the RSA primitives.\n\n== Examples ==\nBlinding in GPG 1.x"
    }
  },
  {
    "instruction": "Context: EFAIL\n\n==Introduction==\nEfail, also written EFAIL, is a security hole in email systems with which content can be transmitted in encrypted form. This gap allows attackers to access the decrypted content of an email if it contains active content like HTML or JavaScript, or if loading of external content has been enabled in the client. Affected email clients include Gmail, Apple Mail, and Microsoft Outlook.Two related Common Vulnerabilities and Exposures IDs, CVE-2017-17688 and CVE-2017-17689, have been issued. The security gap was made public on 13 May 2018 by Damian Poddebniak, Christian Dresen, Jens M\u00fcller, Fabian Ising, Sebastian Schinzel, Simon Friedberger, Juraj Somorovsky and J\u00f6rg Schwenk as part of a contribution to the 27th USENIX Security Symposium, Baltimore, August 2018. \nAs a result of the vulnerability, the content of an attacked encrypted email can be transmitted to the attacker in plain text by a vulnerable email client. The used encryption keys are not disclosed.\n\n\n\n== Description ==\nThe security gap concerns many common email programs when used with the email encryption systems OpenPGP and S/MIME. An attacker needs access to the attacked email message in its encrypted form, as well as the ability to send an email to at least one regular recipient of this original email. To exploit the security gap, the attacker modifies the encrypted email, causing the recipient's email program to send the decrypted content of the email to the attacker.\nTo access the decrypted content of an encrypted email, the attacker modifies the email to be attacked to contain text prepared by the attacker in a specific way. The attacker then sends the changed email to one of the regular recipients.\nThe attacker inserts additional text before and after the encrypted text in the encrypted email, thereby changing the message so that a multipart/mixed (MIME) message is created and the encrypted part of the message appears together with the limit marks of the MIME message as a parameter value of an HTML tag.\nExample of a modified S/MIME mail:\n\nThe email client first breaks down the multipart message into its individual parts using the --BOUNDARY tag and then decrypts the encrypted parts. It then reassembles the multipart message, and receives the message in this way:\n\nThis message now contains the decrypted content of the email in the src\n\n== Mitigations ==\nSince the vulnerability is directed against the content of the email and not against the recipient, it is necessary that all recipients implement the countermeasures. These include:\n\nDisable active content such as HTML or JavaScript when viewing emails.\nSuppress automatic reloading of external content, such as images.To what extent even the senders of encrypted content can reduce the vulnerability, e.g. by electronic signatures or the limitation to a subset of MIME formats, has not yet been conclusively clarified.\n\n== Critique ==\nAnnouncing the security vulnerability on 13 May 2018 the Electronic Frontier Foundation (EFF) recommended to stop using any PGP plugins in email programs even though the vulnerability does not directly relate to PGP but to the configuration of an email program. A coordinated publication was originally scheduled for the 15 May. The EFF was criticized for ignoring this by various parties.As a consequence of this, Robert Hansen recommended to establish a closed group or mailing list to better coordinate the publication of future security issues. Still, he saw the EFF and its director Danny O'Brien as the best entity to administer such an \"OpenPGP Disclosure Group\".\nQuestion: Why was the EFF criticized for its initial recommendation regarding the EFAIL vulnerability?. Whats the answer?",
    "context": "",
    "output": "The EFF was criticized for ignoring the coordinated publication schedule and for recommending to stop using any PGP plugins in email programs, even though the vulnerability does not directly relate to PGP but to the configuration of an email program.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "Why was the EFF criticized for its initial recommendation regarding the EFAIL vulnerability?",
      "answer": "The EFF was criticized for ignoring the coordinated publication schedule and for recommending to stop using any PGP plugins in email programs, even though the vulnerability does not directly relate to PGP but to the configuration of an email program.",
      "context": "EFAIL\n\n==Introduction==\nEfail, also written EFAIL, is a security hole in email systems with which content can be transmitted in encrypted form. This gap allows attackers to access the decrypted content of an email if it contains active content like HTML or JavaScript, or if loading of external content has been enabled in the client. Affected email clients include Gmail, Apple Mail, and Microsoft Outlook.Two related Common Vulnerabilities and Exposures IDs, CVE-2017-17688 and CVE-2017-17689, have been issued. The security gap was made public on 13 May 2018 by Damian Poddebniak, Christian Dresen, Jens M\u00fcller, Fabian Ising, Sebastian Schinzel, Simon Friedberger, Juraj Somorovsky and J\u00f6rg Schwenk as part of a contribution to the 27th USENIX Security Symposium, Baltimore, August 2018. \nAs a result of the vulnerability, the content of an attacked encrypted email can be transmitted to the attacker in plain text by a vulnerable email client. The used encryption keys are not disclosed.\n\n\n\n== Description ==\nThe security gap concerns many common email programs when used with the email encryption systems OpenPGP and S/MIME. An attacker needs access to the attacked email message in its encrypted form, as well as the ability to send an email to at least one regular recipient of this original email. To exploit the security gap, the attacker modifies the encrypted email, causing the recipient's email program to send the decrypted content of the email to the attacker.\nTo access the decrypted content of an encrypted email, the attacker modifies the email to be attacked to contain text prepared by the attacker in a specific way. The attacker then sends the changed email to one of the regular recipients.\nThe attacker inserts additional text before and after the encrypted text in the encrypted email, thereby changing the message so that a multipart/mixed (MIME) message is created and the encrypted part of the message appears together with the limit marks of the MIME message as a parameter value of an HTML tag.\nExample of a modified S/MIME mail:\n\nThe email client first breaks down the multipart message into its individual parts using the --BOUNDARY tag and then decrypts the encrypted parts. It then reassembles the multipart message, and receives the message in this way:\n\nThis message now contains the decrypted content of the email in the src\n\n== Mitigations ==\nSince the vulnerability is directed against the content of the email and not against the recipient, it is necessary that all recipients implement the countermeasures. These include:\n\nDisable active content such as HTML or JavaScript when viewing emails.\nSuppress automatic reloading of external content, such as images.To what extent even the senders of encrypted content can reduce the vulnerability, e.g. by electronic signatures or the limitation to a subset of MIME formats, has not yet been conclusively clarified.\n\n== Critique ==\nAnnouncing the security vulnerability on 13 May 2018 the Electronic Frontier Foundation (EFF) recommended to stop using any PGP plugins in email programs even though the vulnerability does not directly relate to PGP but to the configuration of an email program. A coordinated publication was originally scheduled for the 15 May. The EFF was criticized for ignoring this by various parties.As a consequence of this, Robert Hansen recommended to establish a closed group or mailing list to better coordinate the publication of future security issues. Still, he saw the EFF and its director Danny O'Brien as the best entity to administer such an \"OpenPGP Disclosure Group\"."
    }
  },
  {
    "instruction": "The National Vulnerability Database (NVD) is the U.S. government content repository for SCAP.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the role of the National Vulnerability Database (NVD) in SCAP?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the role of the National Vulnerability Database (NVD) in SCAP?",
      "answer": "The National Vulnerability Database (NVD) is the U.S. government content repository for SCAP."
    }
  },
  {
    "instruction": "The production and/or distribution of warez is illegal in most countries due to the protections provided in the TRIPS Agreement. Software infringers generally exploit the international nature of the copyright issue to avoid law enforcement in specific countries.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the legal status of the production and distribution of warez?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the legal status of the production and distribution of warez?",
      "answer": "The production and/or distribution of warez is illegal in most countries due to the protections provided in the TRIPS Agreement. Software infringers generally exploit the international nature of the copyright issue to avoid law enforcement in specific countries."
    }
  },
  {
    "instruction": "The software vendor may invalidate the user's serial number (disabling that user's software in the process) and may take legal action against the user for violating the license agreement.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does the software vendor respond to giving away the registration code in some expensive software?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does the software vendor respond to giving away the registration code in some expensive software?",
      "answer": "The software vendor may invalidate the user's serial number (disabling that user's software in the process) and may take legal action against the user for violating the license agreement."
    }
  },
  {
    "instruction": "The golden ratio is used to generate the constant 2654435769 or 0x9e3779b9 in multiple ciphers including TEA and Red Pike. This use demonstrates that the constants were not selected for a nefarious purpose.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the role of the golden ratio in the multiple ciphers including TEA and Red Pike?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the role of the golden ratio in the multiple ciphers including TEA and Red Pike?",
      "answer": "The golden ratio is used to generate the constant 2654435769 or 0x9e3779b9 in multiple ciphers including TEA and Red Pike. This use demonstrates that the constants were not selected for a nefarious purpose."
    }
  },
  {
    "instruction": "Co-managed Security\n\n==Introduction==\nThe Co-Managed IT security service model entails security monitoring, event correlation, incident response, system tuning, and compliance support across an organization's entire IT environment. Co-Management allows organizations to collaborate with their managed security service providers by blending security expertise of the provider with the contextual knowledge of the customer to optimise security posture.Outsourcing all IT security affairs can leave clients in the dark in regards to major security breaches or events.The combined involvement of the client and managed security service providers (MSSP) in relation to SIEM softwares allow for immediate response to security breaches, increased transparency and reduce workload for internal IT security teams.\nThe cooperative management of SIEM softwares can allow for the sharing of expert knowledge between internal IT security teams and the MSSP.\nCo-Managed security services also allow for organizations\u2019 critical data and tools to be remotely managed by a team of certified engineers and security analysts from a 24/7/365 Security Operations Center (SOC). This service approach allows for customer data to remain in-house while the SIEM platform is either on-site or cloud-hosted. The service provider's staff work in conjunction with customer security teams to outline the rules of engagement inside the environment to provide monitoring and response to alerts in real-time. The Security Operation Center also provide the \u201ccare and feeding\u201d, and development of a variety of security solutions. The co-managed approach also allows organizations to focus on emerging internal projects and other critical areas of IT.\nAccording to Gartner's How and When to Use Co-managed Security Information and Event Management report, \u201cCo-managed SIEM services enable security and risk management leaders to maximize value from SIEM and enhance security monitoring capabilities, while retaining control and flexibility.\u201d and \"Co-management is on the rise and expected to grow five-fold by 2020.\"\nSIEM, IDS/IPS, Compliance Automation, Network Configuration Management Tools, Advanced Threat Intelligence, Network Access Control, Endpoint Threat Detection and Response, Application Security, File Integrity Monitoring, Forensic Investigation, and Vulnerability Scanning and Assessment, are all examples of cyber security solutions that co-managed service providers support.\n\n\n\n\n\nAnswer this question \"How does co-managed security services impact the collaboration between an organization's IT security team and their managed security service providers (MSSP)?\" using the text above.",
    "context": "",
    "output": "Co-managed security services allow for a closer collaboration between an organization's IT security team and their MSSP, as it combines the security expertise of the provider with the contextual knowledge of the customer. This partnership enables immediate response to security breaches, increased transparency, and reduces the workload for internal IT security teams. Additionally, the cooperative management of SIEM software allows for the sharing of expert knowledge, resulting in enhanced security monitoring capabilities.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does co-managed security services impact the collaboration between an organization's IT security team and their managed security service providers (MSSP)?",
      "answer": "Co-managed security services allow for a closer collaboration between an organization's IT security team and their MSSP, as it combines the security expertise of the provider with the contextual knowledge of the customer. This partnership enables immediate response to security breaches, increased transparency, and reduces the workload for internal IT security teams. Additionally, the cooperative management of SIEM software allows for the sharing of expert knowledge, resulting in enhanced security monitoring capabilities.",
      "context": "Co-managed Security\n\n==Introduction==\nThe Co-Managed IT security service model entails security monitoring, event correlation, incident response, system tuning, and compliance support across an organization's entire IT environment. Co-Management allows organizations to collaborate with their managed security service providers by blending security expertise of the provider with the contextual knowledge of the customer to optimise security posture.Outsourcing all IT security affairs can leave clients in the dark in regards to major security breaches or events.The combined involvement of the client and managed security service providers (MSSP) in relation to SIEM softwares allow for immediate response to security breaches, increased transparency and reduce workload for internal IT security teams.\nThe cooperative management of SIEM softwares can allow for the sharing of expert knowledge between internal IT security teams and the MSSP.\nCo-Managed security services also allow for organizations\u2019 critical data and tools to be remotely managed by a team of certified engineers and security analysts from a 24/7/365 Security Operations Center (SOC). This service approach allows for customer data to remain in-house while the SIEM platform is either on-site or cloud-hosted. The service provider's staff work in conjunction with customer security teams to outline the rules of engagement inside the environment to provide monitoring and response to alerts in real-time. The Security Operation Center also provide the \u201ccare and feeding\u201d, and development of a variety of security solutions. The co-managed approach also allows organizations to focus on emerging internal projects and other critical areas of IT.\nAccording to Gartner's How and When to Use Co-managed Security Information and Event Management report, \u201cCo-managed SIEM services enable security and risk management leaders to maximize value from SIEM and enhance security monitoring capabilities, while retaining control and flexibility.\u201d and \"Co-management is on the rise and expected to grow five-fold by 2020.\"\nSIEM, IDS/IPS, Compliance Automation, Network Configuration Management Tools, Advanced Threat Intelligence, Network Access Control, Endpoint Threat Detection and Response, Application Security, File Integrity Monitoring, Forensic Investigation, and Vulnerability Scanning and Assessment, are all examples of cyber security solutions that co-managed service providers support.\n\n\n\n"
    }
  },
  {
    "instruction": "The proxy web server acts as an intermediary between the client and the internet content, filtering internet content using SpamBayes based on the predefined rules or policies.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the role of the proxy web server in applying SpamBayes as a web filter?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the role of the proxy web server in applying SpamBayes as a web filter?",
      "answer": "The proxy web server acts as an intermediary between the client and the internet content, filtering internet content using SpamBayes based on the predefined rules or policies."
    }
  },
  {
    "instruction": "The client can authenticate with the EST server during the enrollment process using one of the authentication mechanisms specified in EST, such as username/password or client certificate. The authentication mechanism used depends on the specific implementation and configuration of the EST server. Once authenticated, the client can send the PKCS#10 CSR to the EST server to request a new client certificate.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does the client authenticate with the EST server during the enrollment process?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does the client authenticate with the EST server during the enrollment process?",
      "answer": "The client can authenticate with the EST server during the enrollment process using one of the authentication mechanisms specified in EST, such as username/password or client certificate. The authentication mechanism used depends on the specific implementation and configuration of the EST server. Once authenticated, the client can send the PKCS#10 CSR to the EST server to request a new client certificate."
    }
  },
  {
    "instruction": "Passwordless authentication is a method of accessing a computer system without entering a password or any other knowledge-based secret, using public-key cryptography and authentication factors such as ownership factors or inherence factors. MFA, on the other hand, uses a variety of authentication factors in addition to a memorized password, while passwordless authentication does not require a memorized secret. \"Passwordless MFA\" refers to the combination of both approaches, providing a high level of security.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is passwordless authentication and how does it differ from multi-factor authentication (MFA)?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is passwordless authentication and how does it differ from multi-factor authentication (MFA)?",
      "answer": "Passwordless authentication is a method of accessing a computer system without entering a password or any other knowledge-based secret, using public-key cryptography and authentication factors such as ownership factors or inherence factors. MFA, on the other hand, uses a variety of authentication factors in addition to a memorized password, while passwordless authentication does not require a memorized secret. \"Passwordless MFA\" refers to the combination of both approaches, providing a high level of security."
    }
  },
  {
    "instruction": "Yes, a static key can be used for key wrapping, data encryption or MAC keys but it is less secure than using ephemeral keys.\n\nWrite a question about the text above.",
    "context": "",
    "output": "Can a static key be used for key wrapping, data encryption or MAC keys?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "Can a static key be used for key wrapping, data encryption or MAC keys?",
      "answer": "Yes, a static key can be used for key wrapping, data encryption or MAC keys but it is less secure than using ephemeral keys."
    }
  },
  {
    "instruction": "The IASME information assurance standard incorporates the Cyber Essentials standard, and organizations may choose to limit the scope of certification to a certain subset of their business.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does the IASME information assurance standard relate to the Cyber Essentials program?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does the IASME information assurance standard relate to the Cyber Essentials program?",
      "answer": "The IASME information assurance standard incorporates the Cyber Essentials standard, and organizations may choose to limit the scope of certification to a certain subset of their business."
    }
  },
  {
    "instruction": "ISO/IEC 27001 and ISO/IEC 27002 are closely related. ISO/IEC 27001 provides the requirements for an ISMS, while ISO/IEC 27002 offers guidance on information security management best practices. ISO/IEC 27001 is a normative standard, while ISO/IEC 27002 is advisory, providing recommendations on implementing the controls outlined in ISO/IEC 27001 Annex A.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the relationship between ISO/IEC 27001 and ISO/IEC 27002?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the relationship between ISO/IEC 27001 and ISO/IEC 27002?",
      "answer": "ISO/IEC 27001 and ISO/IEC 27002 are closely related. ISO/IEC 27001 provides the requirements for an ISMS, while ISO/IEC 27002 offers guidance on information security management best practices. ISO/IEC 27001 is a normative standard, while ISO/IEC 27002 is advisory, providing recommendations on implementing the controls outlined in ISO/IEC 27001 Annex A."
    }
  },
  {
    "instruction": "The Linear Feedback Shift Register (LFSR) is a type of pseudorandom number generator that is used in the Turing cipher to generate the output sequence.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the Linear Feedback Shift Register (LFSR) used in the Turing cipher?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the Linear Feedback Shift Register (LFSR) used in the Turing cipher?",
      "answer": "The Linear Feedback Shift Register (LFSR) is a type of pseudorandom number generator that is used in the Turing cipher to generate the output sequence."
    }
  },
  {
    "instruction": "Users can create filters that sort messages into folders based on specified criteria, such as the sender's email address or the subject of the message.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How can users sort messages into folders using mail filters?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How can users sort messages into folders using mail filters?",
      "answer": "Users can create filters that sort messages into folders based on specified criteria, such as the sender's email address or the subject of the message."
    }
  },
  {
    "instruction": "The movement of users from ShadowCrew to Mazafaka suggests that the cybercrime landscape is constantly evolving. As law enforcement agencies crack down on cybercrime forums and marketplaces, cybercriminals are forced to find new platforms to carry out their activities. Mazafaka's offer of customized Zeus malware indicates that it may be more sophisticated and better equipped to evade detection than its predecessors. This highlights the need for organizations and individuals to stay up-to-date with the latest cyber threats and to implement robust cybersecurity measures to protect themselves.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does the movement of users from ShadowCrew to Mazafaka reflect the evolution of the cybercrime landscape?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does the movement of users from ShadowCrew to Mazafaka reflect the evolution of the cybercrime landscape?",
      "answer": "The movement of users from ShadowCrew to Mazafaka suggests that the cybercrime landscape is constantly evolving. As law enforcement agencies crack down on cybercrime forums and marketplaces, cybercriminals are forced to find new platforms to carry out their activities. Mazafaka's offer of customized Zeus malware indicates that it may be more sophisticated and better equipped to evade detection than its predecessors. This highlights the need for organizations and individuals to stay up-to-date with the latest cyber threats and to implement robust cybersecurity measures to protect themselves."
    }
  },
  {
    "instruction": "Data transfers between the outside world and air-gapped systems typically involve writing data to a physical medium, such as a thumbdrive, and physically moving it between computers. This approach is easier to control than a direct full network interface, which can be attacked from the exterior insecure system.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How are data transfers handled between the outside world and air-gapped systems?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How are data transfers handled between the outside world and air-gapped systems?",
      "answer": "Data transfers between the outside world and air-gapped systems typically involve writing data to a physical medium, such as a thumbdrive, and physically moving it between computers. This approach is easier to control than a direct full network interface, which can be attacked from the exterior insecure system."
    }
  },
  {
    "instruction": "The NCIIPC is responsible for evolving protection strategies, policies, vulnerability assessment and auditing methodologies and plans for their dissemination and implementation for protection of Critical Information Infrastructure, but the text does not provide further details on this role.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the role of the NCIIPC in evolving protection strategies, policies, vulnerability assessment and auditing methodologies and plans for their dissemination and implementation for protection of Critical Information Infrastructure?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the role of the NCIIPC in evolving protection strategies, policies, vulnerability assessment and auditing methodologies and plans for their dissemination and implementation for protection of Critical Information Infrastructure?",
      "answer": "The NCIIPC is responsible for evolving protection strategies, policies, vulnerability assessment and auditing methodologies and plans for their dissemination and implementation for protection of Critical Information Infrastructure, but the text does not provide further details on this role."
    }
  },
  {
    "instruction": "Qualified electronic signatures are a type of electronic signature that requires using a qualified trust service provider and signature creation device. They are given the same power as a physical signature in the European Union for legal documents.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What are qualified electronic signatures and how are they used in the European Union?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What are qualified electronic signatures and how are they used in the European Union?",
      "answer": "Qualified electronic signatures are a type of electronic signature that requires using a qualified trust service provider and signature creation device. They are given the same power as a physical signature in the European Union for legal documents."
    }
  },
  {
    "instruction": "Autopsy is designed to be extensible, meaning that users can add new functionality by creating plugins that can analyze all or part of the underlying data source.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does Autopsy enable investigators to add new functionality to the software?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does Autopsy enable investigators to add new functionality to the software?",
      "answer": "Autopsy is designed to be extensible, meaning that users can add new functionality by creating plugins that can analyze all or part of the underlying data source."
    }
  },
  {
    "instruction": "The Florida Department of Law Enforcement is responsible for investigating cyber crimes, including DDoS attacks, in the state of Florida, and provides assistance to other law enforcement agencies in their investigations.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the role of the Florida Department of Law Enforcement in investigating cyber crimes like the DDoS attacks on Miami-Dade County Public Schools?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the role of the Florida Department of Law Enforcement in investigating cyber crimes like the DDoS attacks on Miami-Dade County Public Schools?",
      "answer": "The Florida Department of Law Enforcement is responsible for investigating cyber crimes, including DDoS attacks, in the state of Florida, and provides assistance to other law enforcement agencies in their investigations."
    }
  },
  {
    "instruction": "TEMPEST is a set of standards and specifications developed by the U.S. National Security Agency and NATO. It refers to spying on information systems through leaking emanations, including unintentional radio or electrical signals, sounds, and vibrations. TEMPEST covers both methods to spy upon others and how to shield equipment against such spying. It encompasses electromagnetic emanations, sounds, and mechanical vibrations.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is TEMPEST and what does it cover?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is TEMPEST and what does it cover?",
      "answer": "TEMPEST is a set of standards and specifications developed by the U.S. National Security Agency and NATO. It refers to spying on information systems through leaking emanations, including unintentional radio or electrical signals, sounds, and vibrations. TEMPEST covers both methods to spy upon others and how to shield equipment against such spying. It encompasses electromagnetic emanations, sounds, and mechanical vibrations."
    }
  },
  {
    "instruction": "The Zardoz list became a perennial target for computer hackers because it identified weaknesses in systems and gave directions on where to find them. Hackers sought archives of the list for information on undisclosed software vulnerabilities.\n\nWrite a question about the text above.",
    "context": "",
    "output": "Why did the Zardoz list become a perennial target for computer hackers?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "Why did the Zardoz list become a perennial target for computer hackers?",
      "answer": "The Zardoz list became a perennial target for computer hackers because it identified weaknesses in systems and gave directions on where to find them. Hackers sought archives of the list for information on undisclosed software vulnerabilities."
    }
  },
  {
    "instruction": "LSM is designed to answer all the requirements for successfully implementing a mandatory access control module while imposing the fewest possible changes to the Linux kernel.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the main design principle of Linux Security Modules (LSM)?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the main design principle of Linux Security Modules (LSM)?",
      "answer": "LSM is designed to answer all the requirements for successfully implementing a mandatory access control module while imposing the fewest possible changes to the Linux kernel."
    }
  },
  {
    "instruction": "The initial targets of the Nitro hacking attacks in April and May 2011 were human rights organizations.\n\nWrite a question about the text above.",
    "context": "",
    "output": "Who were the initial targets of the Nitro hacking attacks in April and May 2011?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "Who were the initial targets of the Nitro hacking attacks in April and May 2011?",
      "answer": "The initial targets of the Nitro hacking attacks in April and May 2011 were human rights organizations."
    }
  },
  {
    "instruction": "The purpose of using randomly chosen instructions in a NOP-sled is to make it more difficult for vendors of intrusion prevention systems to detect shellcode in use. Any instruction that does not corrupt the machine state to a point where the shellcode will not run can be used in place of the hardware assisted no-op.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the purpose of using randomly chosen instructions in a NOP-sled?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the purpose of using randomly chosen instructions in a NOP-sled?",
      "answer": "The purpose of using randomly chosen instructions in a NOP-sled is to make it more difficult for vendors of intrusion prevention systems to detect shellcode in use. Any instruction that does not corrupt the machine state to a point where the shellcode will not run can be used in place of the hardware assisted no-op."
    }
  },
  {
    "instruction": "It is challenging to make a computer system with the noninterference property because it requires the system to not have any covert channels, which is difficult to achieve in practice.\n\nWrite a question about the text above.",
    "context": "",
    "output": "Why is it challenging to make a computer system with the noninterference property?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "Why is it challenging to make a computer system with the noninterference property?",
      "answer": "It is challenging to make a computer system with the noninterference property because it requires the system to not have any covert channels, which is difficult to achieve in practice."
    }
  },
  {
    "instruction": "It remains unknown if the Zombie Zero attack was carried out by organized crime or a nation state.\n\nWrite a question about the text above.",
    "context": "",
    "output": "Who is believed to be behind the Zombie Zero attack?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "Who is believed to be behind the Zombie Zero attack?",
      "answer": "It remains unknown if the Zombie Zero attack was carried out by organized crime or a nation state."
    }
  },
  {
    "instruction": "Team Xecuter\n\n==Introduction==\nTeam Xecuter is a hacker group known for making mod chips and jailbreaking game consoles. Among console hackers, who primarily consist of hobbyists testing boundaries and believe in the open-source model, Team Xecuter was controversial for selling hacking tools for profit. Console systems targeted by the group include the Nintendo Switch, Nintendo 3DS, GameCube, NES Classic Edition, Sony PlayStation, Microsoft Xbox and the Microsoft Xbox 360.In September 2020, Canadian national Gary \"GaryOPA\" Bowser and French national Max \"MAXiMiLiEN\" Louarn were arrested for designing and selling \"circumvention devices\", specifically products to circumvent Nintendo Switch copy protection, and were named, along with Chinese citizen Yuanning Chen, in a federal indictment filed in U.S. District Court in Seattle, WA on August 20, 2020. Each of the three men named in the indictment faced 11 felony counts, including conspiracy to commit wire fraud, conspiracy to circumvent technological measures and to traffic in circumvention devices, trafficking in circumvention devices, and conspiracy to commit money laundering. Bowser handled public relations for the group, which has been in operation since \"at least\" 2013. By October 2021, Bowser pled guilty to conspiracy to circumvent technological measures and trafficking in circumvention devices, agreeing to pay a $4.5 million penalty and to continue to work with authorities in their continued investigation of Team Xecuter in exchange for dropping the other nine charges against him. In December, he was ordered to pay another $10 million to Nintendo. On February 10, 2022, Bowser was sentenced to 40 months in prison.Nintendo separately filed a civil lawsuit against Bowser in April 2021 related to three counts of copyright infringement, seeking damages of $2500 per trafficked device, and $150,000 for each copyright violation.Nintendo has also successfully prevailed in another lawsuit involving resellers of Team Xecuter devices, winning $2 million with a settlement.\n\n\n\n\n\nAnswer this question \"How has Nintendo responded to the activities of Team Xecuter, and what steps have they taken to protect their intellectual property?\" using the text above.",
    "context": "",
    "output": "Nintendo has taken a strong stance against the activities of Team Xecuter, filing both criminal and civil legal actions against the group and its members. In addition to the legal actions described in my previous answer, Nintendo has also successfully prevailed in a lawsuit involving resellers of Team Xecuter devices, winning $2 million with a settlement. These actions demonstrate Nintendo's commitment to protecting its intellectual property and preventing the sale of circumvention devices that can be used to infringe on its copyrights. By taking legal action and seeking significant penalties and damages, Nintendo is sending a clear message that it will not tolerate the sale of hacking tools and devices that can be used to circumvent its copy protection measures. This sends a strong deterrent signal to other groups and individuals who may be considering similar activities, and helps to protect Nintendo's intellectual property and the interests of its customers and partners.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How has Nintendo responded to the activities of Team Xecuter, and what steps have they taken to protect their intellectual property?",
      "answer": "Nintendo has taken a strong stance against the activities of Team Xecuter, filing both criminal and civil legal actions against the group and its members. In addition to the legal actions described in my previous answer, Nintendo has also successfully prevailed in a lawsuit involving resellers of Team Xecuter devices, winning $2 million with a settlement. These actions demonstrate Nintendo's commitment to protecting its intellectual property and preventing the sale of circumvention devices that can be used to infringe on its copyrights. By taking legal action and seeking significant penalties and damages, Nintendo is sending a clear message that it will not tolerate the sale of hacking tools and devices that can be used to circumvent its copy protection measures. This sends a strong deterrent signal to other groups and individuals who may be considering similar activities, and helps to protect Nintendo's intellectual property and the interests of its customers and partners.",
      "context": "Team Xecuter\n\n==Introduction==\nTeam Xecuter is a hacker group known for making mod chips and jailbreaking game consoles. Among console hackers, who primarily consist of hobbyists testing boundaries and believe in the open-source model, Team Xecuter was controversial for selling hacking tools for profit. Console systems targeted by the group include the Nintendo Switch, Nintendo 3DS, GameCube, NES Classic Edition, Sony PlayStation, Microsoft Xbox and the Microsoft Xbox 360.In September 2020, Canadian national Gary \"GaryOPA\" Bowser and French national Max \"MAXiMiLiEN\" Louarn were arrested for designing and selling \"circumvention devices\", specifically products to circumvent Nintendo Switch copy protection, and were named, along with Chinese citizen Yuanning Chen, in a federal indictment filed in U.S. District Court in Seattle, WA on August 20, 2020. Each of the three men named in the indictment faced 11 felony counts, including conspiracy to commit wire fraud, conspiracy to circumvent technological measures and to traffic in circumvention devices, trafficking in circumvention devices, and conspiracy to commit money laundering. Bowser handled public relations for the group, which has been in operation since \"at least\" 2013. By October 2021, Bowser pled guilty to conspiracy to circumvent technological measures and trafficking in circumvention devices, agreeing to pay a $4.5 million penalty and to continue to work with authorities in their continued investigation of Team Xecuter in exchange for dropping the other nine charges against him. In December, he was ordered to pay another $10 million to Nintendo. On February 10, 2022, Bowser was sentenced to 40 months in prison.Nintendo separately filed a civil lawsuit against Bowser in April 2021 related to three counts of copyright infringement, seeking damages of $2500 per trafficked device, and $150,000 for each copyright violation.Nintendo has also successfully prevailed in another lawsuit involving resellers of Team Xecuter devices, winning $2 million with a settlement.\n\n\n\n"
    }
  },
  {
    "instruction": "Initially, seven certified companies were selected to provide identity verification services for GOV.UK Verify.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How many certified companies were initially selected to provide identity verification services for GOV.UK Verify?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How many certified companies were initially selected to provide identity verification services for GOV.UK Verify?",
      "answer": "Initially, seven certified companies were selected to provide identity verification services for GOV.UK Verify."
    }
  },
  {
    "instruction": "Netcat and Ncat are similar tools, but Ncat features additional functionalities such as the ability to chain Ncats together, redirect both TCP and UDP ports to other sites, support SSL, and proxy connections via SOCKS4 or HTTP (CONNECT method) proxies. Ncat is also cross-platform, supporting various operating systems and configurations.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the difference between netcat and Ncat, and what are some of Ncat's unique features?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the difference between netcat and Ncat, and what are some of Ncat's unique features?",
      "answer": "Netcat and Ncat are similar tools, but Ncat features additional functionalities such as the ability to chain Ncats together, redirect both TCP and UDP ports to other sites, support SSL, and proxy connections via SOCKS4 or HTTP (CONNECT method) proxies. Ncat is also cross-platform, supporting various operating systems and configurations."
    }
  },
  {
    "instruction": "Matt Curtin is a computer scientist and cryptography expert with a number of notable achievements and contributions to the field. He is the founder of Interhack Corporation and has helped to prove the weakness of the Data Encryption Standard. In addition to his technical work, Curtin is also the author of two books, Developing Trust: Online Privacy and Security and Brute Force: Cracking the Data Encryption Standard. He has also provided expert testimony in legal cases, including Blumofe v. Pharmatrak, which had important implications for the application of the Electronic Communications Privacy Act (ECPA) to web technology.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What are some of Matt Curtin's notable achievements and contributions in the field of computer science and cryptography?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What are some of Matt Curtin's notable achievements and contributions in the field of computer science and cryptography?",
      "answer": "Matt Curtin is a computer scientist and cryptography expert with a number of notable achievements and contributions to the field. He is the founder of Interhack Corporation and has helped to prove the weakness of the Data Encryption Standard. In addition to his technical work, Curtin is also the author of two books, Developing Trust: Online Privacy and Security and Brute Force: Cracking the Data Encryption Standard. He has also provided expert testimony in legal cases, including Blumofe v. Pharmatrak, which had important implications for the application of the Electronic Communications Privacy Act (ECPA) to web technology."
    }
  },
  {
    "instruction": "The winner of the 2014 Best Server-Side Bug category is Heartbleed (Neel Mehta and Codenomicon, CVE-2014-0160) which is a vulnerability in the OpenSSL cryptographic software library that allows attackers to read the memory of the host system, potentially exposing sensitive information.\n\nWrite a question about the text above.",
    "context": "",
    "output": "Who is the winner of the 2014 Best Server-Side Bug category and what was the exploit they discovered?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "Who is the winner of the 2014 Best Server-Side Bug category and what was the exploit they discovered?",
      "answer": "The winner of the 2014 Best Server-Side Bug category is Heartbleed (Neel Mehta and Codenomicon, CVE-2014-0160) which is a vulnerability in the OpenSSL cryptographic software library that allows attackers to read the memory of the host system, potentially exposing sensitive information."
    }
  },
  {
    "instruction": "The four main varieties of hardware-based FDE are: Hard disk drive (HDD) FDE (also known as self-encrypting drives or SEDs), Enclosed hard disk drive FDE, Removable hard disk drive FDE, and Bridge and Chipset (BC) FDE.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What are the four main varieties of hardware-based FDE in common use?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What are the four main varieties of hardware-based FDE in common use?",
      "answer": "The four main varieties of hardware-based FDE are: Hard disk drive (HDD) FDE (also known as self-encrypting drives or SEDs), Enclosed hard disk drive FDE, Removable hard disk drive FDE, and Bridge and Chipset (BC) FDE."
    }
  },
  {
    "instruction": "Polymorphic attacks involve encoding the payload in some fashion, typically with XOR additive feedback, before placing a decoder in front of the payload. When the target executes the code, the decoder rewrites the payload into its original form, which the target then executes. Since polymorphic attacks don't have a single detectable signature, they are challenging for signature-based IDS and even some anomaly-based IDS to detect.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How do polymorphic attacks make it difficult for signature-based IDS to detect them?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How do polymorphic attacks make it difficult for signature-based IDS to detect them?",
      "answer": "Polymorphic attacks involve encoding the payload in some fashion, typically with XOR additive feedback, before placing a decoder in front of the payload. When the target executes the code, the decoder rewrites the payload into its original form, which the target then executes. Since polymorphic attacks don't have a single detectable signature, they are challenging for signature-based IDS and even some anomaly-based IDS to detect."
    }
  },
  {
    "instruction": "Dorkbot (malware)\n\n==Introduction==\nDorkbot is a family of malware worms that spreads through instant messaging, USB drives, websites or social media channels like Facebook. It originated in 2015 and infected systems were variously used to send spam, participate in DDoS attacks, or harvest users' credentials.\n\n\n\n== Functionality ==\nDorkbot\u2019s backdoor functionality allows a remote attacker to exploit infected systems. According to an analysis by Microsoft and Check Point Research, a remote attacker may be able to:\nDownload and run a file from a specified URL;\nCollect login information and passwords through form grabbing, FTP, POP3, or Internet Explorer and Firefox cached login details; or\nBlock or redirect certain domains and websites (e.g., security sites).\n\n== Impact ==\nA system infected with Dorkbot may be used to send spam, participate in DDoS attacks, or harvest users' credentials for online services, including banking services.\n\n== Prevalence ==\nBetween May and December 2015, the Microsoft Malware Protection Center detected Dorkbot on an average of 100,000 infected machines each month.\n\n== Remediation ==\nIn 2015, the U.S. Department of Homeland Security advised the following action to remediate Dorkbot infections:\nUse and maintain anti-virus software\nChange your passwords\nKeep your operating system and application software up-to-date\nUse anti-malware tools\nDisable AutoRun Answer this question using the following article:\n\nHow can Dorkbot be used to participate in DDoS attacks?",
    "context": "",
    "output": "Dorkbot can be used to participate in DDoS attacks by remotely controlling infected systems to send large amounts of traffic to targeted websites or servers, overwhelming them and causing them to become unavailable.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How can Dorkbot be used to participate in DDoS attacks?",
      "answer": "Dorkbot can be used to participate in DDoS attacks by remotely controlling infected systems to send large amounts of traffic to targeted websites or servers, overwhelming them and causing them to become unavailable.",
      "context": "Dorkbot (malware)\n\n==Introduction==\nDorkbot is a family of malware worms that spreads through instant messaging, USB drives, websites or social media channels like Facebook. It originated in 2015 and infected systems were variously used to send spam, participate in DDoS attacks, or harvest users' credentials.\n\n\n\n== Functionality ==\nDorkbot\u2019s backdoor functionality allows a remote attacker to exploit infected systems. According to an analysis by Microsoft and Check Point Research, a remote attacker may be able to:\nDownload and run a file from a specified URL;\nCollect login information and passwords through form grabbing, FTP, POP3, or Internet Explorer and Firefox cached login details; or\nBlock or redirect certain domains and websites (e.g., security sites).\n\n== Impact ==\nA system infected with Dorkbot may be used to send spam, participate in DDoS attacks, or harvest users' credentials for online services, including banking services.\n\n== Prevalence ==\nBetween May and December 2015, the Microsoft Malware Protection Center detected Dorkbot on an average of 100,000 infected machines each month.\n\n== Remediation ==\nIn 2015, the U.S. Department of Homeland Security advised the following action to remediate Dorkbot infections:\nUse and maintain anti-virus software\nChange your passwords\nKeep your operating system and application software up-to-date\nUse anti-malware tools\nDisable AutoRun"
    }
  },
  {
    "instruction": "Token Binding's evolution of TLS Channel ID can benefit users and organizations by providing a more secure TLS connection. This helps protect sensitive data from interception and manipulation, reducing the risk of related attacks and enhancing overall cybersecurity.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How can Token Binding's evolution of TLS Channel ID benefit users and organizations?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How can Token Binding's evolution of TLS Channel ID benefit users and organizations?",
      "answer": "Token Binding's evolution of TLS Channel ID can benefit users and organizations by providing a more secure TLS connection. This helps protect sensitive data from interception and manipulation, reducing the risk of related attacks and enhancing overall cybersecurity."
    }
  },
  {
    "instruction": "Spies rely on COVCOM or covert communication through technically advanced spy devices. This can include encrypted messaging apps, dead drops, or other methods that are difficult for the adversary to detect or intercept.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How do spies communicate securely and covertly with their handlers?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How do spies communicate securely and covertly with their handlers?",
      "answer": "Spies rely on COVCOM or covert communication through technically advanced spy devices. This can include encrypted messaging apps, dead drops, or other methods that are difficult for the adversary to detect or intercept."
    }
  },
  {
    "instruction": "Selective TLB flushing enabled by process-context identifier (PCID) or address space number (ASN) isolates the TLB behavior crucial to the exploit across processes, reducing the constant flushing of the entire TLB.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How can selective TLB flushing reduce the cost of Spectre mitigation?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How can selective TLB flushing reduce the cost of Spectre mitigation?",
      "answer": "Selective TLB flushing enabled by process-context identifier (PCID) or address space number (ASN) isolates the TLB behavior crucial to the exploit across processes, reducing the constant flushing of the entire TLB."
    }
  },
  {
    "instruction": "The Srizbi trojan is fully executed in kernel mode, employs rootkit technologies, patches NTFS file system drivers, and hides network traffic to prevent detection and maintain persistence.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does the Srizbi trojan maintain persistence on an infected computer?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does the Srizbi trojan maintain persistence on an infected computer?",
      "answer": "The Srizbi trojan is fully executed in kernel mode, employs rootkit technologies, patches NTFS file system drivers, and hides network traffic to prevent detection and maintain persistence."
    }
  },
  {
    "instruction": "The SCIP signalling plan handles longer fades and allows a station to join a multi station net and be synchronized within 1.5 seconds by sending part of the rest of the state vector with every sync block so that with receipt of three sync blocks, the entire state vector is recovered.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does the SCIP signalling plan handle longer fades and allow a station to join a multi station net and be synchronized within 1.5 seconds?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does the SCIP signalling plan handle longer fades and allow a station to join a multi station net and be synchronized within 1.5 seconds?",
      "answer": "The SCIP signalling plan handles longer fades and allows a station to join a multi station net and be synchronized within 1.5 seconds by sending part of the rest of the state vector with every sync block so that with receipt of three sync blocks, the entire state vector is recovered."
    }
  },
  {
    "instruction": "Session hijacking is significant in web development because the HTTP cookies used to maintain a session on many websites can be easily stolen by an attacker. This is often done through HTTP cookie theft, where an attacker uses an intermediary computer or gains access to the victim's computer to steal the session cookies.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the significance of session hijacking in web development and how is it relevant to HTTP cookies?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the significance of session hijacking in web development and how is it relevant to HTTP cookies?",
      "answer": "Session hijacking is significant in web development because the HTTP cookies used to maintain a session on many websites can be easily stolen by an attacker. This is often done through HTTP cookie theft, where an attacker uses an intermediary computer or gains access to the victim's computer to steal the session cookies."
    }
  },
  {
    "instruction": "GlobalSign's SSL Configuration Checker evaluates the effectiveness of a website's SSL configuration, providing remediation steps for websites to improve their security and address any exploitable SSL configurations.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does GlobalSign's SSL Configuration Checker help websites improve their SSL configurations?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does GlobalSign's SSL Configuration Checker help websites improve their SSL configurations?",
      "answer": "GlobalSign's SSL Configuration Checker evaluates the effectiveness of a website's SSL configuration, providing remediation steps for websites to improve their security and address any exploitable SSL configurations."
    }
  },
  {
    "instruction": "The Lastline Breach Detection Platform benefits businesses by providing automated detection of active data breaches, helping to quickly and efficiently identify and address security threats.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does the Lastline Breach Detection Platform benefit businesses?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does the Lastline Breach Detection Platform benefit businesses?",
      "answer": "The Lastline Breach Detection Platform benefits businesses by providing automated detection of active data breaches, helping to quickly and efficiently identify and address security threats."
    }
  },
  {
    "instruction": "SMTP proxies do not store messages, allowing them to reject SMTP connections or message content in real-time and avoid the need for out-of-band non-delivery reports (NDRs), which are the cause of backscatter email, a serious problem in the Internet email system.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How do SMTP proxies help in implementing real-time message rejection and avoiding NDRs?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How do SMTP proxies help in implementing real-time message rejection and avoiding NDRs?",
      "answer": "SMTP proxies do not store messages, allowing them to reject SMTP connections or message content in real-time and avoid the need for out-of-band non-delivery reports (NDRs), which are the cause of backscatter email, a serious problem in the Internet email system."
    }
  },
  {
    "instruction": "The OWASP Mantra Security Framework is a collection of hacking tools, add-ons, and scripts based on Firefox, included in BackTrack for web application security testing.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the purpose of the OWASP Mantra Security Framework included in BackTrack?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the purpose of the OWASP Mantra Security Framework included in BackTrack?",
      "answer": "The OWASP Mantra Security Framework is a collection of hacking tools, add-ons, and scripts based on Firefox, included in BackTrack for web application security testing."
    }
  },
  {
    "instruction": "Distributed denial-of-service attacks impact the victim site by overwhelming the website's server with large numbers of simultaneous requests, causing it to crash and preventing legitimate users from accessing the site.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How do distributed denial-of-service attacks impact the victim site?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How do distributed denial-of-service attacks impact the victim site?",
      "answer": "Distributed denial-of-service attacks impact the victim site by overwhelming the website's server with large numbers of simultaneous requests, causing it to crash and preventing legitimate users from accessing the site."
    }
  },
  {
    "instruction": "The Eastin-Knill theorem is a no-go theorem that states that no quantum error correcting code can have a continuous symmetry which acts transversely on physical qubits, and therefore can't transversely implement a universal gate set. This means that it is not possible to perform gates on encoded data without the risk of decoding errors, and fault tolerant quantum computation is necessary to avoid this.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the significance of the Eastin-Knill theorem in the context of quantum error correcting codes and universal gate sets?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the significance of the Eastin-Knill theorem in the context of quantum error correcting codes and universal gate sets?",
      "answer": "The Eastin-Knill theorem is a no-go theorem that states that no quantum error correcting code can have a continuous symmetry which acts transversely on physical qubits, and therefore can't transversely implement a universal gate set. This means that it is not possible to perform gates on encoded data without the risk of decoding errors, and fault tolerant quantum computation is necessary to avoid this."
    }
  },
  {
    "instruction": "The ICAO/NATO alphabet is significant in numbers stations because it is often used to transmit letter groups. This allows for a more secure transmission, as the letters are not transmitted directly, but rather through a code word.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the significance of the ICAO/NATO alphabet in numbers stations?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the significance of the ICAO/NATO alphabet in numbers stations?",
      "answer": "The ICAO/NATO alphabet is significant in numbers stations because it is often used to transmit letter groups. This allows for a more secure transmission, as the letters are not transmitted directly, but rather through a code word."
    }
  },
  {
    "instruction": "A proxy is a network service for making indirect connections to other network services. Spammers use open proxies to conceal their identity and make it difficult to trace the source of the spam.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is a proxy and how do spammers use it to send spam emails?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is a proxy and how do spammers use it to send spam emails?",
      "answer": "A proxy is a network service for making indirect connections to other network services. Spammers use open proxies to conceal their identity and make it difficult to trace the source of the spam."
    }
  },
  {
    "instruction": "FreeRADIUS\n\n==Introduction==\nFreeRADIUS is a modular, high performance free RADIUS suite developed and distributed under the GNU General Public License, version 2, and is free for download and use. The FreeRADIUS Suite includes a RADIUS server, a BSD-licensed RADIUS client library, a PAM library, an Apache module, and numerous additional RADIUS related utilities and development libraries.In most cases, the word \"FreeRADIUS\" refers to the free open-source RADIUS server from this suite.\nFreeRADIUS is the most popular open source RADIUS server and the most widely deployed RADIUS server in the world. It supports all common authentication protocols, and the server comes with a PHP-based web user administration tool called dialupadmin. It is the basis for many commercial RADIUS products and services, such as embedded systems, RADIUS appliances that support Network Access Control, and WiMAX. It supplies the AAA needs of many Fortune-500 companies, telcos, and Tier 1 ISPs. It is also widely used in the academic community, including eduroam. The server is fast, feature-rich, modular, and scalable.\n\n== Features ==\nModules included with the server core support LDAP, MySQL, PostgreSQL, Oracle, and many other databases. It supports all popular EAP authentication types, including PEAP and EAP-TTLS. More than 100 vendor dictionaries are included, ensuring compatibility with a wide range of NAS devices.\nVersion 2.0.0 added support for virtual hosting, IPv6, VMPS, and a new policy language that simplifies many complex configurations.\n\n== Administration tools ==\ndaloRADIUS: a web based management application aimed at managing hotspots and ISP deployments. With easy user management interface, pretty graphical reporting, accounting, also billing engine and integrates with GoogleMaps for geo-locating.\nphpRADmin: a tool written in PHP intended to handle the administration and provisioning of FreeRADIUS over the Web with MySQL as backend.\nDialup Admin: a powerful web interface written in PHP comes with FreeRADIUS to administer radius users. Dialup Admin supports users either in SQL (MySQL or PostgreSQL are supported) or in LDAP. No longer under active development.\nezRadius: web-based management app. The main aim is to provide radius server or hotspot administrator a simple web-based management application. FreeRADIUS must be configured to use MySQL as backend.\nRADIUSdesk:RADIUSdesk has been developed since 2012 as tool to manage wireless Internet and has been under active development ever since.\n\nAnswer this question \"How does FreeRADIUS integrate with GoogleMaps?\" using the text above.",
    "context": "",
    "output": "FreeRADIUS integrates with GoogleMaps through the daloRADIUS administration tool. This tool uses GoogleMaps to provide geo-locating capabilities, allowing administrators to visualize the location of users and devices on a map.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does FreeRADIUS integrate with GoogleMaps?",
      "answer": "FreeRADIUS integrates with GoogleMaps through the daloRADIUS administration tool. This tool uses GoogleMaps to provide geo-locating capabilities, allowing administrators to visualize the location of users and devices on a map.",
      "context": "FreeRADIUS\n\n==Introduction==\nFreeRADIUS is a modular, high performance free RADIUS suite developed and distributed under the GNU General Public License, version 2, and is free for download and use. The FreeRADIUS Suite includes a RADIUS server, a BSD-licensed RADIUS client library, a PAM library, an Apache module, and numerous additional RADIUS related utilities and development libraries.In most cases, the word \"FreeRADIUS\" refers to the free open-source RADIUS server from this suite.\nFreeRADIUS is the most popular open source RADIUS server and the most widely deployed RADIUS server in the world. It supports all common authentication protocols, and the server comes with a PHP-based web user administration tool called dialupadmin. It is the basis for many commercial RADIUS products and services, such as embedded systems, RADIUS appliances that support Network Access Control, and WiMAX. It supplies the AAA needs of many Fortune-500 companies, telcos, and Tier 1 ISPs. It is also widely used in the academic community, including eduroam. The server is fast, feature-rich, modular, and scalable.\n\n== Features ==\nModules included with the server core support LDAP, MySQL, PostgreSQL, Oracle, and many other databases. It supports all popular EAP authentication types, including PEAP and EAP-TTLS. More than 100 vendor dictionaries are included, ensuring compatibility with a wide range of NAS devices.\nVersion 2.0.0 added support for virtual hosting, IPv6, VMPS, and a new policy language that simplifies many complex configurations.\n\n== Administration tools ==\ndaloRADIUS: a web based management application aimed at managing hotspots and ISP deployments. With easy user management interface, pretty graphical reporting, accounting, also billing engine and integrates with GoogleMaps for geo-locating.\nphpRADmin: a tool written in PHP intended to handle the administration and provisioning of FreeRADIUS over the Web with MySQL as backend.\nDialup Admin: a powerful web interface written in PHP comes with FreeRADIUS to administer radius users. Dialup Admin supports users either in SQL (MySQL or PostgreSQL are supported) or in LDAP. No longer under active development.\nezRadius: web-based management app. The main aim is to provide radius server or hotspot administrator a simple web-based management application. FreeRADIUS must be configured to use MySQL as backend.\nRADIUSdesk:RADIUSdesk has been developed since 2012 as tool to manage wireless Internet and has been under active development ever since."
    }
  },
  {
    "instruction": "SM3 can be used to detect tampering and ensure message integrity in data storage applications by computing a hash value of the data at the time of storage. The hash value can then be compared to the hash value computed at a later time to ensure that the data has not been modified.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How can SM3 be used to detect tampering and ensure message integrity in data storage applications?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How can SM3 be used to detect tampering and ensure message integrity in data storage applications?",
      "answer": "SM3 can be used to detect tampering and ensure message integrity in data storage applications by computing a hash value of the data at the time of storage. The hash value can then be compared to the hash value computed at a later time to ensure that the data has not been modified."
    }
  },
  {
    "instruction": "The vulnerability in OpenID related to authentication hijacking in unsecured connections is present in the last step in the authentication scheme, where the identity provider redirects the user to the relying party. If TLS/SSL are not used, anyone who can obtain this redirect URL (e.g. by sniffing the wire) can replay it and get logged into the site as the victim user.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the vulnerability in OpenID related to authentication hijacking in unsecured connections?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the vulnerability in OpenID related to authentication hijacking in unsecured connections?",
      "answer": "The vulnerability in OpenID related to authentication hijacking in unsecured connections is present in the last step in the authentication scheme, where the identity provider redirects the user to the relying party. If TLS/SSL are not used, anyone who can obtain this redirect URL (e.g. by sniffing the wire) can replay it and get logged into the site as the victim user."
    }
  },
  {
    "instruction": "The first provably-secure PAKE protocols were given in work by M. Bellare, D. Pointcheval, and P. Rogaway in 2000, and V. Boyko, P. MacKenzie, and S. Patel in 2000. These protocols were proven secure in the random oracle model or even stronger variants.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What were the first provably-secure PAKE protocols and when were they given?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What were the first provably-secure PAKE protocols and when were they given?",
      "answer": "The first provably-secure PAKE protocols were given in work by M. Bellare, D. Pointcheval, and P. Rogaway in 2000, and V. Boyko, P. MacKenzie, and S. Patel in 2000. These protocols were proven secure in the random oracle model or even stronger variants."
    }
  },
  {
    "instruction": "Fault attacks involve applying temperature extremes, excessively high or low clock frequencies or supply voltage that exceeds the specifications in order to induce a fault. The internal design of the cryptoprocessor can be tailored to prevent these attacks.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How can fault attacks be used against secure cryptoprocessors?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How can fault attacks be used against secure cryptoprocessors?",
      "answer": "Fault attacks involve applying temperature extremes, excessively high or low clock frequencies or supply voltage that exceeds the specifications in order to induce a fault. The internal design of the cryptoprocessor can be tailored to prevent these attacks."
    }
  },
  {
    "instruction": "Medical data breaches can negatively impact the healthcare industry by undermining patient trust, leading to financial losses, and increasing the cost of healthcare. They can also hinder the development and implementation of medical AI technologies.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How do medical data breaches affect the healthcare industry as a whole?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How do medical data breaches affect the healthcare industry as a whole?",
      "answer": "Medical data breaches can negatively impact the healthcare industry by undermining patient trust, leading to financial losses, and increasing the cost of healthcare. They can also hinder the development and implementation of medical AI technologies."
    }
  },
  {
    "instruction": "Key exchange is performed during the initial handshake, and the validity or invalidity of peers' keys may be replaced anytime later without user interaction or verification.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does Autocrypt handle key exchange during the initial handshake?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does Autocrypt handle key exchange during the initial handshake?",
      "answer": "Key exchange is performed during the initial handshake, and the validity or invalidity of peers' keys may be replaced anytime later without user interaction or verification."
    }
  },
  {
    "instruction": "Context: OpenPuff\n\n==Introduction==\nOpenPuff Steganography and Watermarking, sometimes abbreviated OpenPuff or Puff, is a free steganography tool for Microsoft Windows created by Cosimo Oliboni and still maintained as independent software. The program is notable for being the first steganography tool (version 1.01 released in December 2004) that:\n\nlets users hide data in more than a single carrier file. When hidden data are split among a set of carrier files you get a carrier chain, with no enforced hidden data theoretical size limit (256MB, 512MB, ... depending only on the implementation)\nimplements 3 layers of hidden data obfuscation (cryptography, whitening and encoding)\nextends deniable cryptography into deniable steganographyLast revision supports a wide range of carrier formats\n\nImages Bmp, Jpg, Png, Tga\nAudios Aiff, Mp3, Wav\nVideos 3gp, Mp4, Mpeg I, Mpeg II, Vob\nFlash-Adobe Flv, Pdf, Swf\n\n\n\n== Use ==\nOpenPuff is used primarily for anonymous asynchronous data sharing:\n\nthe sender hides a hidden stream inside some public available carrier files (password + carrier files + carrier order are the secret key)\nthe receiver unhides the hidden stream knowing the secret keyThe advantage of steganography, over cryptography alone,  is that messages do not attract attention to themselves. Plainly visible encrypted messages \u2014 no matter how unbreakable \u2014 will arouse suspicion, and may in themselves be incriminating in countries where encryption is illegal. Therefore, whereas cryptography protects the contents of a message, steganography can be said to protect both messages and communicating parties.\nWatermarking is the action of signing a file with an ID or copyright mark. OpenPuff does it in an invisible steganographic way, applied to any supported carrier. The invisible mark, being not password protected, is accessible by everyone (using the program).\n\n== Multi-cryptography ==\nOpenPuff is a semi-open source program:\n\ncryptography, CSPRNG, hashing (used in password hexadecimal extension), and scrambling are open sourceCryptographic algorithms (16 taken from AES, NESSIE and CRYPTREC) are joined into a unique multi-cryptography algorithm:\n\nkeys and internal static data are initialized for each algorithm f\neach data block D [ i ] (128bit) will be encrypted using a different algorithm f [ i ]\nf [ i ] is chosen with a pseudorandom oracle, seeded with a second independent password1. Choosing the cryptography algorithm for data block i\nf [ i ]\n\n== Statistical resistance ==\nExtensive testing has been performed on the statistical resistance properties of the CSPRNG and multi-cryptography modules, using the ENT, NIST  and DIEHARD test suites. Provided results are taken from 64KB, 128KB, ... 256MB samples:\n\nbit entropy test: >7.9999xx / 8.000000\ncompression test: 0% size reduction after compression\nchi square distribution test: 40% < deviation < 60%\nmean value test: 127.4x / 127.5\nMonte Carlo test: error < 0.01%\nserial correlation test: < 0.0001\n\n== Steganalysis resistance ==\nSecurity, performance and steganalysis resistance are conflicting trade-offs.[Security vs. Performance]: Whitening\n\nPro: ensures higher data security\nPro: allows deniable steganography\nCon1: requires a lot of extra carrier bits[Security vs. Steganalysis]: Cryptography + Whitening\n\nPro: ensure higher data security\nCon2: their random statistical response marks carriers as more \"suspicious\"Data, before carrier injection, is encrypted and whitened: a small amount of hidden data turns into a big chunk of pseudorandom \"suspicious data\". Carrier injection encodes it using a non linear covering function that takes also original carrier bits as input. Modified carriers will need much less change (Con1) and, lowering their random-like statistical response, deceive many steganalysis tests (Con2).\n\n== Deniable steganography ==\nThere will always be a non-negligible probability of being detected, even if the hidden stream behaves like a \u201cnatural container\u201d (unpredictable side-effects, being caught in Flagrante delicto, etc.).  Resisting these unpredictable attacks is also possible, even when the user is forced (by legal or physical coercion) to provide a valid password. Deniable steganography (a decoy-based technique) allows the user to deny convincingly the fact that sensitive data is being hidden.  The user needs to provide some expendable decoy data that he would plausibly want to keep confidential and reveal it to the attacker, claiming that this is all there is.\nQuestion: What is the purpose of watermarking in OpenPuff?\n\nAnswer:",
    "context": "",
    "output": "The purpose of watermarking in OpenPuff is to sign a file with an ID or copyright mark in an invisible steganographic way. This mark is not password protected and is accessible by anyone using the program.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the purpose of watermarking in OpenPuff?",
      "answer": "The purpose of watermarking in OpenPuff is to sign a file with an ID or copyright mark in an invisible steganographic way. This mark is not password protected and is accessible by anyone using the program.",
      "context": "OpenPuff\n\n==Introduction==\nOpenPuff Steganography and Watermarking, sometimes abbreviated OpenPuff or Puff, is a free steganography tool for Microsoft Windows created by Cosimo Oliboni and still maintained as independent software. The program is notable for being the first steganography tool (version 1.01 released in December 2004) that:\n\nlets users hide data in more than a single carrier file. When hidden data are split among a set of carrier files you get a carrier chain, with no enforced hidden data theoretical size limit (256MB, 512MB, ... depending only on the implementation)\nimplements 3 layers of hidden data obfuscation (cryptography, whitening and encoding)\nextends deniable cryptography into deniable steganographyLast revision supports a wide range of carrier formats\n\nImages Bmp, Jpg, Png, Tga\nAudios Aiff, Mp3, Wav\nVideos 3gp, Mp4, Mpeg I, Mpeg II, Vob\nFlash-Adobe Flv, Pdf, Swf\n\n\n\n== Use ==\nOpenPuff is used primarily for anonymous asynchronous data sharing:\n\nthe sender hides a hidden stream inside some public available carrier files (password + carrier files + carrier order are the secret key)\nthe receiver unhides the hidden stream knowing the secret keyThe advantage of steganography, over cryptography alone,  is that messages do not attract attention to themselves. Plainly visible encrypted messages \u2014 no matter how unbreakable \u2014 will arouse suspicion, and may in themselves be incriminating in countries where encryption is illegal. Therefore, whereas cryptography protects the contents of a message, steganography can be said to protect both messages and communicating parties.\nWatermarking is the action of signing a file with an ID or copyright mark. OpenPuff does it in an invisible steganographic way, applied to any supported carrier. The invisible mark, being not password protected, is accessible by everyone (using the program).\n\n== Multi-cryptography ==\nOpenPuff is a semi-open source program:\n\ncryptography, CSPRNG, hashing (used in password hexadecimal extension), and scrambling are open sourceCryptographic algorithms (16 taken from AES, NESSIE and CRYPTREC) are joined into a unique multi-cryptography algorithm:\n\nkeys and internal static data are initialized for each algorithm f\neach data block D [ i ] (128bit) will be encrypted using a different algorithm f [ i ]\nf [ i ] is chosen with a pseudorandom oracle, seeded with a second independent password1. Choosing the cryptography algorithm for data block i\nf [ i ]\n\n== Statistical resistance ==\nExtensive testing has been performed on the statistical resistance properties of the CSPRNG and multi-cryptography modules, using the ENT, NIST  and DIEHARD test suites. Provided results are taken from 64KB, 128KB, ... 256MB samples:\n\nbit entropy test: >7.9999xx / 8.000000\ncompression test: 0% size reduction after compression\nchi square distribution test: 40% < deviation < 60%\nmean value test: 127.4x / 127.5\nMonte Carlo test: error < 0.01%\nserial correlation test: < 0.0001\n\n== Steganalysis resistance ==\nSecurity, performance and steganalysis resistance are conflicting trade-offs.[Security vs. Performance]: Whitening\n\nPro: ensures higher data security\nPro: allows deniable steganography\nCon1: requires a lot of extra carrier bits[Security vs. Steganalysis]: Cryptography + Whitening\n\nPro: ensure higher data security\nCon2: their random statistical response marks carriers as more \"suspicious\"Data, before carrier injection, is encrypted and whitened: a small amount of hidden data turns into a big chunk of pseudorandom \"suspicious data\". Carrier injection encodes it using a non linear covering function that takes also original carrier bits as input. Modified carriers will need much less change (Con1) and, lowering their random-like statistical response, deceive many steganalysis tests (Con2).\n\n== Deniable steganography ==\nThere will always be a non-negligible probability of being detected, even if the hidden stream behaves like a \u201cnatural container\u201d (unpredictable side-effects, being caught in Flagrante delicto, etc.).  Resisting these unpredictable attacks is also possible, even when the user is forced (by legal or physical coercion) to provide a valid password. Deniable steganography (a decoy-based technique) allows the user to deny convincingly the fact that sensitive data is being hidden.  The user needs to provide some expendable decoy data that he would plausibly want to keep confidential and reveal it to the attacker, claiming that this is all there is."
    }
  },
  {
    "instruction": "The internet can be used in economic or industrial espionage for sabotage by targeting energy power systems, such as those used to monitor power grids or water flow. These systems, which were historically isolated from other computer networks, are now being connected to the internet, leaving them vulnerable to attacks.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How can the internet be used in economic or industrial espionage for sabotage?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How can the internet be used in economic or industrial espionage for sabotage?",
      "answer": "The internet can be used in economic or industrial espionage for sabotage by targeting energy power systems, such as those used to monitor power grids or water flow. These systems, which were historically isolated from other computer networks, are now being connected to the internet, leaving them vulnerable to attacks."
    }
  },
  {
    "instruction": "CA-signed certificates can verify the identity of the person to whom they issue a certificate, while self-signed certificates do not have this capability. This means that the trust of the values in a self-signed certificate is more complicated, as the entity possesses the signing key and can always generate a new certificate with different values.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How are self-signed certificates different from CA-signed certificates in terms of trust?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How are self-signed certificates different from CA-signed certificates in terms of trust?",
      "answer": "CA-signed certificates can verify the identity of the person to whom they issue a certificate, while self-signed certificates do not have this capability. This means that the trust of the values in a self-signed certificate is more complicated, as the entity possesses the signing key and can always generate a new certificate with different values."
    }
  },
  {
    "instruction": "Context: Locky\n\n==Introduction==\nLocky is ransomware malware released in 2016. It is delivered by email (that is allegedly an invoice requiring payment) with an attached Microsoft Word document that contains malicious macros. When the user opens the document, it appears to be full of gibberish, and includes the phrase \"Enable macro if data encoding is incorrect,\" a social engineering technique. If the user does enable macros, they save and run a binary file that downloads the actual encryption Trojan, which will encrypt all files that match particular extensions. Filenames are converted to a unique 16 letter and number combination. Initially, only the .locky file extension was used for these encrypted files. Subsequently, other file extensions have been used, including .zepto, .odin, .aesir, .thor, and .zzzzz. After encryption, a message (displayed on the user's desktop) instructs them to download the Tor browser and visit a specific criminal-operated Web site for further information. The Web site contain instructions that demand a payment of between 0.5 and 1 bitcoin (as of November 2017, one bitcoin varies in value between $9,000 and $10,000 via a bitcoin exchange). Since the criminals possess the private key and the remote servers are controlled by them, the victims are motivated to pay to decrypt their files.\n\n== Operation ==\nThe most commonly reported mechanism of infection involves receiving an email with a Microsoft Word document attachment that contains the code.  The document is gibberish, and prompts the user to enable macros to view the document.  Enabling macros and opening the document launch the Locky virus.\nOnce the virus is launched, it loads into the memory of the users system, encrypts documents as hash.locky files, installs .bmp and .txt files, and can encrypt network files that the user has access to.\nThis has been a different route than most ransomware since it uses macros and attachments to spread rather than being installed by a Trojan or using a previous exploit.\n\n== Updates ==\nOn June 22, 2016, Necurs released a new version of Locky with a new loader component, which includes several detection-avoiding techniques, such as detecting whether it is running within a virtual machine or within a physical machine, and relocation of instruction code.Since Locky was released there have been numerous variants released that used different extensions for encrypted files. Many of these extensions are named after gods of Norse and Egyptian mythology. When first released, the extension used for encrypted files was .Locky. Other versions utilized the .zepto, .odin, .shit, .thor, .aesir, and .zzzzz extensions for encrypted files. The current version, released in December 2016, utilizes the .osiris extension for encrypted files.\n\n== Distribution methods ==\nMany different distribution methods for Locky have been used since the ransomware was released. These distribution methods include exploit kits, Word and Excel attachments with malicious macros, DOCM attachments, and zipped JS attachments.The general consensus among security experts to protect yourself from ransomware, including Locky, is to keep your installed programs updated and to only open attachments from known senders.\n\n== Encryption ==\nThe Locky uses RSA-2048 + AES-128 cipher with ECB mode to encrypt files. Keys are generated on the server side, making manual decryption impossible, and Locky ransomware can encrypt files on all fixed drives, removable drives, network and RAM disk drives.\n\n== Prevalence ==\nLocky is reported to have been sent to about a half-million users on February 16, 2016, and for the period immediately after the attackers increased their distribution to millions of users. Despite the newer version, Google Trend data indicates that infections have dropped off around June 2016.\n\n== Notable incidents ==\nOn February 18, 2016, the Hollywood Presbyterian Medical Center paid a $17,000 ransom in the form of bitcoins for the decryption key for patient data.  The hospital was infected by the delivery of an email attachment disguised as a Microsoft Word invoice.\nThis has led to increased fear and knowledge about ransomware in general and has brought ransomware into public spotlight once again.\nThere appears to be a trend in ransomware being used to attack hospitals and it appears to be growing.\nOn May 31, Necurs went dormant, perhaps due to a glitch in the C&C server.  According to Softpedia, there were less spam emails with Locky or Dridex attached to it.  On June 22, however, MalwareTech discovered Necurs's bots consistently polled the DGA until a C&C server replied with a digitally signed response.  This signified Necurs was no longer dormant.  The cybercriminal group also started sending a very large quantity of spam emails with new and improved versions of Locky and Dridex attached to them, as well as a new message and zipped JavaScript code in the emails.In Spring 2016, the Dartford Grammar School and Dartford Science & Technology College computers were infected with the virus. In both schools, a student had opened an infected email which quickly spread and encrypted many school files. The virus stayed on the computer for several weeks. Eventually, they managed to remove the virus by using System Restore for all of the computers.\n\n== Spam email vector ==\nAn example message with Locky as an attachment is the following:\nDear (random name):\nPlease find attached our invoice for services rendered and additional disbursements in the above-mentioned matter.\nHoping the above to your satisfaction, we remain\nSincerely,\n(random name)\n(random title)\nQuestion: How does Locky ransomware gain access to a user's system?\n\nAnswer:",
    "context": "",
    "output": "Locky ransomware primarily gains access to a user's system through emails containing Microsoft Word documents with malicious macros. Once the user opens the document and enables macros, the Locky virus is launched and infects the system.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does Locky ransomware gain access to a user's system?",
      "answer": "Locky ransomware primarily gains access to a user's system through emails containing Microsoft Word documents with malicious macros. Once the user opens the document and enables macros, the Locky virus is launched and infects the system.",
      "context": "Locky\n\n==Introduction==\nLocky is ransomware malware released in 2016. It is delivered by email (that is allegedly an invoice requiring payment) with an attached Microsoft Word document that contains malicious macros. When the user opens the document, it appears to be full of gibberish, and includes the phrase \"Enable macro if data encoding is incorrect,\" a social engineering technique. If the user does enable macros, they save and run a binary file that downloads the actual encryption Trojan, which will encrypt all files that match particular extensions. Filenames are converted to a unique 16 letter and number combination. Initially, only the .locky file extension was used for these encrypted files. Subsequently, other file extensions have been used, including .zepto, .odin, .aesir, .thor, and .zzzzz. After encryption, a message (displayed on the user's desktop) instructs them to download the Tor browser and visit a specific criminal-operated Web site for further information. The Web site contain instructions that demand a payment of between 0.5 and 1 bitcoin (as of November 2017, one bitcoin varies in value between $9,000 and $10,000 via a bitcoin exchange). Since the criminals possess the private key and the remote servers are controlled by them, the victims are motivated to pay to decrypt their files.\n\n== Operation ==\nThe most commonly reported mechanism of infection involves receiving an email with a Microsoft Word document attachment that contains the code.  The document is gibberish, and prompts the user to enable macros to view the document.  Enabling macros and opening the document launch the Locky virus.\nOnce the virus is launched, it loads into the memory of the users system, encrypts documents as hash.locky files, installs .bmp and .txt files, and can encrypt network files that the user has access to.\nThis has been a different route than most ransomware since it uses macros and attachments to spread rather than being installed by a Trojan or using a previous exploit.\n\n== Updates ==\nOn June 22, 2016, Necurs released a new version of Locky with a new loader component, which includes several detection-avoiding techniques, such as detecting whether it is running within a virtual machine or within a physical machine, and relocation of instruction code.Since Locky was released there have been numerous variants released that used different extensions for encrypted files. Many of these extensions are named after gods of Norse and Egyptian mythology. When first released, the extension used for encrypted files was .Locky. Other versions utilized the .zepto, .odin, .shit, .thor, .aesir, and .zzzzz extensions for encrypted files. The current version, released in December 2016, utilizes the .osiris extension for encrypted files.\n\n== Distribution methods ==\nMany different distribution methods for Locky have been used since the ransomware was released. These distribution methods include exploit kits, Word and Excel attachments with malicious macros, DOCM attachments, and zipped JS attachments.The general consensus among security experts to protect yourself from ransomware, including Locky, is to keep your installed programs updated and to only open attachments from known senders.\n\n== Encryption ==\nThe Locky uses RSA-2048 + AES-128 cipher with ECB mode to encrypt files. Keys are generated on the server side, making manual decryption impossible, and Locky ransomware can encrypt files on all fixed drives, removable drives, network and RAM disk drives.\n\n== Prevalence ==\nLocky is reported to have been sent to about a half-million users on February 16, 2016, and for the period immediately after the attackers increased their distribution to millions of users. Despite the newer version, Google Trend data indicates that infections have dropped off around June 2016.\n\n== Notable incidents ==\nOn February 18, 2016, the Hollywood Presbyterian Medical Center paid a $17,000 ransom in the form of bitcoins for the decryption key for patient data.  The hospital was infected by the delivery of an email attachment disguised as a Microsoft Word invoice.\nThis has led to increased fear and knowledge about ransomware in general and has brought ransomware into public spotlight once again.\nThere appears to be a trend in ransomware being used to attack hospitals and it appears to be growing.\nOn May 31, Necurs went dormant, perhaps due to a glitch in the C&C server.  According to Softpedia, there were less spam emails with Locky or Dridex attached to it.  On June 22, however, MalwareTech discovered Necurs's bots consistently polled the DGA until a C&C server replied with a digitally signed response.  This signified Necurs was no longer dormant.  The cybercriminal group also started sending a very large quantity of spam emails with new and improved versions of Locky and Dridex attached to them, as well as a new message and zipped JavaScript code in the emails.In Spring 2016, the Dartford Grammar School and Dartford Science & Technology College computers were infected with the virus. In both schools, a student had opened an infected email which quickly spread and encrypted many school files. The virus stayed on the computer for several weeks. Eventually, they managed to remove the virus by using System Restore for all of the computers.\n\n== Spam email vector ==\nAn example message with Locky as an attachment is the following:\nDear (random name):\nPlease find attached our invoice for services rendered and additional disbursements in the above-mentioned matter.\nHoping the above to your satisfaction, we remain\nSincerely,\n(random name)\n(random title)"
    }
  },
  {
    "instruction": "Yes, information can still be considered PII even if it lacks context, such as the name John Smith or a Social Security Number (SSN) without a name or any other associated identity or context information.\n\nWrite a question about the text above.",
    "context": "",
    "output": "In the context of the OMB definition of PII, can information lack context and still be considered PII?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "In the context of the OMB definition of PII, can information lack context and still be considered PII?",
      "answer": "Yes, information can still be considered PII even if it lacks context, such as the name John Smith or a Social Security Number (SSN) without a name or any other associated identity or context information."
    }
  },
  {
    "instruction": "The state of JH cryptographic hash function has 1024 bits.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How many bits does the state of JH cryptographic hash function have?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How many bits does the state of JH cryptographic hash function have?",
      "answer": "The state of JH cryptographic hash function has 1024 bits."
    }
  },
  {
    "instruction": "TIM 4.5.1 was released in September 2003, which was the first version of IBM Tivoli Identity Manager released after IBM's acquisition of Access360.\n\nWrite a question about the text above.",
    "context": "",
    "output": "When was the first version of IBM Tivoli Identity Manager released after IBM's acquisition of Access360?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "When was the first version of IBM Tivoli Identity Manager released after IBM's acquisition of Access360?",
      "answer": "TIM 4.5.1 was released in September 2003, which was the first version of IBM Tivoli Identity Manager released after IBM's acquisition of Access360."
    }
  },
  {
    "instruction": "Certificate revocation list\n\n==Introduction==\nIn cryptography, a certificate revocation list (or CRL) is \"a list of digital certificates that have been revoked by the issuing certificate authority (CA) before their scheduled expiration date and should no longer be trusted\". CRLs are no longer required by the CA/Browser forum, as alternate certificate revocation technologies (such as OCSP) are increasingly used instead. Nevertheless, CRLs are still widely used by the CAs.\n\n\n\n== Revocation states ==\nThere are two different states of revocation defined in RFC 5280:\n\nRevoked\nA certificate is irreversibly revoked if, for example, it is discovered that the certificate authority (CA) had improperly issued a certificate, or if a private-key is thought to have been compromised. Certificates may also be revoked for failure of the identified entity to adhere to policy requirements, such as publication of false documents, misrepresentation of software behaviour, or violation of any other policy specified by the CA operator or its customer. The most common reason for revocation is the user no longer being in sole possession of the private key (e.g., the token containing the private key has been lost or stolen).\nHold\nThis reversible status can be used to note the temporary invalidity of the certificate (e.g., if the user is unsure if the private key has been lost). If, in this example, the private key was found and nobody had access to it, the status could be reinstated, and the certificate is valid again, thus removing the certificate from future CRLs.\n\n== Reasons for revocation ==\nReasons to revoke, hold, or unlist a certificate according to RFC 5280 are:\n\nunspecified (0)\nkeyCompromise (1)\ncACompromise (2)\naffiliationChanged (3)\nsuperseded (4)\ncessationOfOperation (5)\ncertificateHold (6)\nremoveFromCRL (8)\nprivilegeWithdrawn (9)\naACompromise (10)Note that value 7 is not used.\n\n== Publishing revocation lists ==\nA CRL is generated and published periodically, often at a defined interval. A CRL can also be published immediately after a certificate has been revoked. A CRL is issued by a CRL issuer, which is typically the CA which also issued the corresponding certificates, but could alternatively be some other trusted authority. All CRLs have a lifetime during which they are valid; this timeframe is often 24 hours or less. During a CRL's validity period, it may be consulted by a PKI-enabled application to verify a certificate prior to use.\nTo prevent spoofing or denial-of-service attacks, CRLs usually carry a digital signature associated with the CA by which they are published. To validate a specific CRL prior to relying on it, the certificate of its corresponding CA is needed.\nThe certificates for which a CRL should be maintained are often X.509/public key certificates, as this format is commonly used by PKI schemes.\n\n== Revocation versus expiration ==\nExpiration dates are not a substitute for a CRL. While all expired certificates are considered invalid, not all unexpired certificates should be valid. CRLs or other certificate validation techniques are a necessary part of any properly operated PKI, as mistakes in certificate vetting and key management are expected to occur in real world operations.\nIn a noteworthy example, a certificate for Microsoft was mistakenly issued to an unknown individual, who had successfully posed as Microsoft to the CA contracted to maintain the ActiveX 'publisher certificate' system (VeriSign). Microsoft saw the need to patch their cryptography subsystem so it would check the status of certificates before trusting them. As a short-term fix, a patch was issued for the relevant Microsoft software (most importantly Windows) specifically listing the two certificates in question as \"revoked\".\n\n== Problems with certificate revocation lists ==\nBest practices require that wherever and however certificate status is maintained, it must be checked whenever one wants to rely on a certificate. Failing this, a revoked certificate may be incorrectly accepted as valid. This means that to use a PKI effectively, one must have access to current CRLs. This requirement of on-line validation negates one of the original major advantages of PKI over symmetric cryptography protocols, namely that the certificate is \"self-authenticating\". Symmetric systems such as Kerberos also depend on the existence of on-line services (a key distribution center in the case of Kerberos).\nThe existence of a CRL implies the need for someone (or some organization) to enforce policy and revoke certificates deemed counter to operational policy. If a certificate is mistakenly revoked, significant problems can arise. As the certificate authority is tasked with enforcing the operational policy for issuing certificates, they typically are responsible for determining if and when revocation is appropriate by interpreting the operational policy.\nThe necessity of consulting a CRL (or other certificate status service) prior to accepting a certificate raises a potential denial-of-service attack against the PKI. If acceptance of a certificate fails in the absence of an available valid CRL, then no operations depending upon certificate acceptance can take place. This issue exists for Kerberos systems as well, where failure to retrieve a current authentication token will prevent system access.\nAn alternative to using CRLs is the certificate validation protocol known as Online Certificate Status Protocol (OCSP). OCSP has the primary benefit of requiring less network bandwidth, enabling real-time and near real-time status checks for high volume or high-value operations.\nAs of Firefox 28, Mozilla has announced they are deprecating CRL in favour of OCSP.CRL files may grow quite large over time e.g. in US government, for certain institution multiple megabytes. Therefore, incremental CRLs have been designed sometimes referred to as \"delta CRLs\". However, only a few clients implement them.\n\n== Authority revocation lists ==\nAn authority revocation list (ARL) is a form of CRL containing revoked certificates issued to certificate authorities, contrary to CRLs which contain revoked end-entity certificates.\n\nAnswer this question \"How is a CRL published and what is its lifetime?\" using the text above.",
    "context": "",
    "output": "A CRL is generated and published periodically, often at a defined interval, by a CRL issuer which is typically the CA that issued the corresponding certificates. A CRL has a lifetime during which it is valid, often 24 hours or less. During its validity period, it may be consulted by a PKI-enabled application to verify a certificate prior to use.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How is a CRL published and what is its lifetime?",
      "answer": "A CRL is generated and published periodically, often at a defined interval, by a CRL issuer which is typically the CA that issued the corresponding certificates. A CRL has a lifetime during which it is valid, often 24 hours or less. During its validity period, it may be consulted by a PKI-enabled application to verify a certificate prior to use.",
      "context": "Certificate revocation list\n\n==Introduction==\nIn cryptography, a certificate revocation list (or CRL) is \"a list of digital certificates that have been revoked by the issuing certificate authority (CA) before their scheduled expiration date and should no longer be trusted\". CRLs are no longer required by the CA/Browser forum, as alternate certificate revocation technologies (such as OCSP) are increasingly used instead. Nevertheless, CRLs are still widely used by the CAs.\n\n\n\n== Revocation states ==\nThere are two different states of revocation defined in RFC 5280:\n\nRevoked\nA certificate is irreversibly revoked if, for example, it is discovered that the certificate authority (CA) had improperly issued a certificate, or if a private-key is thought to have been compromised. Certificates may also be revoked for failure of the identified entity to adhere to policy requirements, such as publication of false documents, misrepresentation of software behaviour, or violation of any other policy specified by the CA operator or its customer. The most common reason for revocation is the user no longer being in sole possession of the private key (e.g., the token containing the private key has been lost or stolen).\nHold\nThis reversible status can be used to note the temporary invalidity of the certificate (e.g., if the user is unsure if the private key has been lost). If, in this example, the private key was found and nobody had access to it, the status could be reinstated, and the certificate is valid again, thus removing the certificate from future CRLs.\n\n== Reasons for revocation ==\nReasons to revoke, hold, or unlist a certificate according to RFC 5280 are:\n\nunspecified (0)\nkeyCompromise (1)\ncACompromise (2)\naffiliationChanged (3)\nsuperseded (4)\ncessationOfOperation (5)\ncertificateHold (6)\nremoveFromCRL (8)\nprivilegeWithdrawn (9)\naACompromise (10)Note that value 7 is not used.\n\n== Publishing revocation lists ==\nA CRL is generated and published periodically, often at a defined interval. A CRL can also be published immediately after a certificate has been revoked. A CRL is issued by a CRL issuer, which is typically the CA which also issued the corresponding certificates, but could alternatively be some other trusted authority. All CRLs have a lifetime during which they are valid; this timeframe is often 24 hours or less. During a CRL's validity period, it may be consulted by a PKI-enabled application to verify a certificate prior to use.\nTo prevent spoofing or denial-of-service attacks, CRLs usually carry a digital signature associated with the CA by which they are published. To validate a specific CRL prior to relying on it, the certificate of its corresponding CA is needed.\nThe certificates for which a CRL should be maintained are often X.509/public key certificates, as this format is commonly used by PKI schemes.\n\n== Revocation versus expiration ==\nExpiration dates are not a substitute for a CRL. While all expired certificates are considered invalid, not all unexpired certificates should be valid. CRLs or other certificate validation techniques are a necessary part of any properly operated PKI, as mistakes in certificate vetting and key management are expected to occur in real world operations.\nIn a noteworthy example, a certificate for Microsoft was mistakenly issued to an unknown individual, who had successfully posed as Microsoft to the CA contracted to maintain the ActiveX 'publisher certificate' system (VeriSign). Microsoft saw the need to patch their cryptography subsystem so it would check the status of certificates before trusting them. As a short-term fix, a patch was issued for the relevant Microsoft software (most importantly Windows) specifically listing the two certificates in question as \"revoked\".\n\n== Problems with certificate revocation lists ==\nBest practices require that wherever and however certificate status is maintained, it must be checked whenever one wants to rely on a certificate. Failing this, a revoked certificate may be incorrectly accepted as valid. This means that to use a PKI effectively, one must have access to current CRLs. This requirement of on-line validation negates one of the original major advantages of PKI over symmetric cryptography protocols, namely that the certificate is \"self-authenticating\". Symmetric systems such as Kerberos also depend on the existence of on-line services (a key distribution center in the case of Kerberos).\nThe existence of a CRL implies the need for someone (or some organization) to enforce policy and revoke certificates deemed counter to operational policy. If a certificate is mistakenly revoked, significant problems can arise. As the certificate authority is tasked with enforcing the operational policy for issuing certificates, they typically are responsible for determining if and when revocation is appropriate by interpreting the operational policy.\nThe necessity of consulting a CRL (or other certificate status service) prior to accepting a certificate raises a potential denial-of-service attack against the PKI. If acceptance of a certificate fails in the absence of an available valid CRL, then no operations depending upon certificate acceptance can take place. This issue exists for Kerberos systems as well, where failure to retrieve a current authentication token will prevent system access.\nAn alternative to using CRLs is the certificate validation protocol known as Online Certificate Status Protocol (OCSP). OCSP has the primary benefit of requiring less network bandwidth, enabling real-time and near real-time status checks for high volume or high-value operations.\nAs of Firefox 28, Mozilla has announced they are deprecating CRL in favour of OCSP.CRL files may grow quite large over time e.g. in US government, for certain institution multiple megabytes. Therefore, incremental CRLs have been designed sometimes referred to as \"delta CRLs\". However, only a few clients implement them.\n\n== Authority revocation lists ==\nAn authority revocation list (ARL) is a form of CRL containing revoked certificates issued to certificate authorities, contrary to CRLs which contain revoked end-entity certificates."
    }
  },
  {
    "instruction": "Under the Safe Harbor, adoptee organizations need to carefully consider their compliance with the onward transfer obligations, where personal data originating in the EU is transferred to the US Safe Harbor, and then onward to a third country. The alternative compliance approach of \"binding corporate rules\" is recommended by many EU privacy regulators.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What are the onward transfer obligations under the Safe Harbor program?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What are the onward transfer obligations under the Safe Harbor program?",
      "answer": "Under the Safe Harbor, adoptee organizations need to carefully consider their compliance with the onward transfer obligations, where personal data originating in the EU is transferred to the US Safe Harbor, and then onward to a third country. The alternative compliance approach of \"binding corporate rules\" is recommended by many EU privacy regulators."
    }
  },
  {
    "instruction": "ForgeRock Access Management provides access management and ForgeRock Directory Services is an LDAP directory service.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the use case of ForgeRock Access Management and Directory Services?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the use case of ForgeRock Access Management and Directory Services?",
      "answer": "ForgeRock Access Management provides access management and ForgeRock Directory Services is an LDAP directory service."
    }
  },
  {
    "instruction": "The E language and its standard library are designed based on a capability-based design philosophy, which helps programmers build secure software and enables software components to cooperate even if they don't fully trust each other.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the primary design philosophy of the E language and its standard library?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the primary design philosophy of the E language and its standard library?",
      "answer": "The E language and its standard library are designed based on a capability-based design philosophy, which helps programmers build secure software and enables software components to cooperate even if they don't fully trust each other."
    }
  },
  {
    "instruction": "Hack Forums is an Internet forum dedicated to discussions related to hacker culture and computer security. It facilitates discussions on a wide range of topics related to hacking, cybersecurity, and computer systems.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is Hack Forums and what kind of discussions does it facilitate?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is Hack Forums and what kind of discussions does it facilitate?",
      "answer": "Hack Forums is an Internet forum dedicated to discussions related to hacker culture and computer security. It facilitates discussions on a wide range of topics related to hacking, cybersecurity, and computer systems."
    }
  },
  {
    "instruction": "XSL attack\n\n==Introduction==\nIn cryptography, the eXtended Sparse Linearization (XSL) attack is a method of cryptanalysis for block ciphers. The attack was first published in 2002 by researchers Nicolas Courtois and Josef Pieprzyk. It has caused some controversy as it was claimed to have the potential to break the Advanced Encryption Standard (AES) cipher, also known as Rijndael, faster than an exhaustive search. Since AES is already widely used in commerce and government for the transmission of secret information, finding a technique that can shorten the amount of time it takes to retrieve the secret message without having the key could have wide implications.\nThe method has a high work-factor, which unless lessened, means the technique does not reduce the effort to break AES in comparison to an exhaustive search. Therefore, it does not affect the real-world security of block ciphers in the near future. Nonetheless, the attack has caused some experts to express greater unease at the algebraic simplicity of the current AES.\nIn overview, the XSL attack relies on first analyzing the internals of a cipher and deriving a system of quadratic simultaneous equations. These systems of equations are typically very large, for example 8,000 equations with 1,600 variables for the 128-bit AES. Several methods for solving such systems are known. In the XSL attack, a specialized algorithm, termed eXtended Sparse Linearization, is then applied to solve these equations and recover the key.\nThe attack is notable for requiring only a handful of known plaintexts to perform; previous methods of cryptanalysis, such as linear and differential cryptanalysis, often require unrealistically large numbers of known or chosen plaintexts.\n\n== Solving multivariate quadratic equations ==\nSolving multivariate quadratic equations (MQ) over a finite set of numbers is an NP-hard problem (in the general case) with several applications in cryptography. The XSL attack requires an efficient algorithm for tackling MQ. In 1999, Kipnis and Shamir showed that a particular public key algorithm, known as the Hidden Field Equations scheme (HFE), could be reduced to an overdetermined system of quadratic equations (more equations than unknowns). One technique for solving such systems is linearization, which involves replacing each quadratic term with an independent variable and solving the resultant linear system using an algorithm such as Gaussian elimination. To succeed, linearization requires enough linearly independent equations (approximately as many as the number of terms). However, for the cryptanalysis of HFE there were too few equations, so Kipnis and Shamir proposed re-linearization, a technique where extra non-linear equations are added after linearization, and the resultant system is solved by a second application of linearization. Re-linearization proved general enough to be applicable to other schemes.\nIn 2000, Courtois et al. proposed an improved algorithm for MQ known as XL (for eXtended Linearization), which increases the number of equations by multiplying them with all monomials of a certain degree. Complexity estimates showed that the XL attack would not work against the equations derived from block ciphers such as AES. However, the systems of equations produced had a special structure, and the XSL algorithm was developed as a refinement of XL which could take advantage of this structure. In XSL, the equations are multiplied only by carefully selected monomials, and several variants have been proposed.\nResearch into the efficiency of XL and its derivative algorithms remains ongoing (Yang and Chen, 2004).\n\n== Application to block ciphers ==\nCourtois and Pieprzyk (2002) observed that AES (Rijndael) and partially also Serpent could be expressed as a system of quadratic equations. The variables represent not just the plaintext, ciphertext and key bits, but also various intermediate values within the algorithm. The S-box of AES appears to be especially vulnerable to this type of analysis, as it is based on the algebraically simple inverse function. Subsequently, other ciphers have been studied to see what systems of equations can be produced (Biryukov and De Canni\u00e8re, 2003), including Camellia, KHAZAD, MISTY1 and KASUMI. Unlike other forms of cryptanalysis, such as differential and linear cryptanalysis, only one or two known plaintexts are required.\nThe XSL algorithm is tailored to solve the type of equation systems that are produced. Courtois and Pieprzyk estimate that an \"optimistic evaluation shows that the XSL attack might be able to break Rijndael [with] 256 bits and Serpent for key lengths [of] 192 and 256 bits.\" Their analysis, however, is not universally accepted. For example:\n\nI believe that the Courtois\u2013Pieprzyk work is flawed. They overcount the number of linearly independent equations. The result is that they do not in fact have enough linear equations to solve the system, and the method does not break Rijndael\u2026 The method has some merit, and is worth investigating, but it does not break Rijndael as it stands.\nIn AES 4 Conference, Bonn 2004, one of the inventors of Rijndael, Vincent Rijmen, commented, \"The XSL attack is not an attack. It is a dream.\" Promptly Courtois answered, \"XSL may be a dream. It may also be a very bad dream and turn into a nightmare.\" However neither any later paper or any actions by the NSA or NIST give any support to this remark by Courtois.\nIn 2003, Murphy and Robshaw discovered an alternative description of AES, embedding it in a larger cipher called \"BES\", which can be described using very simple operations over a single field, GF(28). An XSL attack mounted on this system yields a simpler set of equations which would break AES with complexity of around 2100, if the Courtois and Pieprzyk analysis is correct. In 2005 Cid and Leurent gave evidence that, in its proposed form, the XSL algorithm does not provide an efficient method for solving the AES system of equations; however Courtois disputed their findings. At FSE 2007, Chu-Wee Lim and Khoongming Khoo showed that it cannot possibly work as presented.Even if XSL works against some modern algorithms, the attack currently poses little danger in terms of practical security. Like many modern cryptanalytic results, it would be a so-called \"certificational weakness\": while faster than a brute force attack, the resources required are still huge, and it is very unlikely that real-world systems could be compromised by using it. Future improvements could increase the practicality of an attack, however. Because this type of attack is new and unexpected, some cryptographers have expressed unease at the algebraic simplicity of ciphers like Rijndael. Bruce Schneier and Niels Ferguson write, \"We have one criticism of AES: we don't quite trust the security\u2026 What concerns us the most about AES is its simple algebraic structure\u2026 No other block cipher we know of has such a simple algebraic representation. We have no idea whether this leads to an attack or not, but not knowing is reason enough to be skeptical about the use of AES.\" (Practical Cryptography, 2003, pp. 56\u201357)\n\nAnswer this question \"How does the XSL attack compare to other forms of cryptanalysis like differential and linear cryptanalysis?\" using the text above.",
    "context": "",
    "output": "Unlike differential and linear cryptanalysis, the XSL attack only requires one or two known plaintexts to perform its analysis, making it a unique and unexpected approach to cryptographic attacks.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does the XSL attack compare to other forms of cryptanalysis like differential and linear cryptanalysis?",
      "answer": "Unlike differential and linear cryptanalysis, the XSL attack only requires one or two known plaintexts to perform its analysis, making it a unique and unexpected approach to cryptographic attacks.",
      "context": "XSL attack\n\n==Introduction==\nIn cryptography, the eXtended Sparse Linearization (XSL) attack is a method of cryptanalysis for block ciphers. The attack was first published in 2002 by researchers Nicolas Courtois and Josef Pieprzyk. It has caused some controversy as it was claimed to have the potential to break the Advanced Encryption Standard (AES) cipher, also known as Rijndael, faster than an exhaustive search. Since AES is already widely used in commerce and government for the transmission of secret information, finding a technique that can shorten the amount of time it takes to retrieve the secret message without having the key could have wide implications.\nThe method has a high work-factor, which unless lessened, means the technique does not reduce the effort to break AES in comparison to an exhaustive search. Therefore, it does not affect the real-world security of block ciphers in the near future. Nonetheless, the attack has caused some experts to express greater unease at the algebraic simplicity of the current AES.\nIn overview, the XSL attack relies on first analyzing the internals of a cipher and deriving a system of quadratic simultaneous equations. These systems of equations are typically very large, for example 8,000 equations with 1,600 variables for the 128-bit AES. Several methods for solving such systems are known. In the XSL attack, a specialized algorithm, termed eXtended Sparse Linearization, is then applied to solve these equations and recover the key.\nThe attack is notable for requiring only a handful of known plaintexts to perform; previous methods of cryptanalysis, such as linear and differential cryptanalysis, often require unrealistically large numbers of known or chosen plaintexts.\n\n== Solving multivariate quadratic equations ==\nSolving multivariate quadratic equations (MQ) over a finite set of numbers is an NP-hard problem (in the general case) with several applications in cryptography. The XSL attack requires an efficient algorithm for tackling MQ. In 1999, Kipnis and Shamir showed that a particular public key algorithm, known as the Hidden Field Equations scheme (HFE), could be reduced to an overdetermined system of quadratic equations (more equations than unknowns). One technique for solving such systems is linearization, which involves replacing each quadratic term with an independent variable and solving the resultant linear system using an algorithm such as Gaussian elimination. To succeed, linearization requires enough linearly independent equations (approximately as many as the number of terms). However, for the cryptanalysis of HFE there were too few equations, so Kipnis and Shamir proposed re-linearization, a technique where extra non-linear equations are added after linearization, and the resultant system is solved by a second application of linearization. Re-linearization proved general enough to be applicable to other schemes.\nIn 2000, Courtois et al. proposed an improved algorithm for MQ known as XL (for eXtended Linearization), which increases the number of equations by multiplying them with all monomials of a certain degree. Complexity estimates showed that the XL attack would not work against the equations derived from block ciphers such as AES. However, the systems of equations produced had a special structure, and the XSL algorithm was developed as a refinement of XL which could take advantage of this structure. In XSL, the equations are multiplied only by carefully selected monomials, and several variants have been proposed.\nResearch into the efficiency of XL and its derivative algorithms remains ongoing (Yang and Chen, 2004).\n\n== Application to block ciphers ==\nCourtois and Pieprzyk (2002) observed that AES (Rijndael) and partially also Serpent could be expressed as a system of quadratic equations. The variables represent not just the plaintext, ciphertext and key bits, but also various intermediate values within the algorithm. The S-box of AES appears to be especially vulnerable to this type of analysis, as it is based on the algebraically simple inverse function. Subsequently, other ciphers have been studied to see what systems of equations can be produced (Biryukov and De Canni\u00e8re, 2003), including Camellia, KHAZAD, MISTY1 and KASUMI. Unlike other forms of cryptanalysis, such as differential and linear cryptanalysis, only one or two known plaintexts are required.\nThe XSL algorithm is tailored to solve the type of equation systems that are produced. Courtois and Pieprzyk estimate that an \"optimistic evaluation shows that the XSL attack might be able to break Rijndael [with] 256 bits and Serpent for key lengths [of] 192 and 256 bits.\" Their analysis, however, is not universally accepted. For example:\n\nI believe that the Courtois\u2013Pieprzyk work is flawed. They overcount the number of linearly independent equations. The result is that they do not in fact have enough linear equations to solve the system, and the method does not break Rijndael\u2026 The method has some merit, and is worth investigating, but it does not break Rijndael as it stands.\nIn AES 4 Conference, Bonn 2004, one of the inventors of Rijndael, Vincent Rijmen, commented, \"The XSL attack is not an attack. It is a dream.\" Promptly Courtois answered, \"XSL may be a dream. It may also be a very bad dream and turn into a nightmare.\" However neither any later paper or any actions by the NSA or NIST give any support to this remark by Courtois.\nIn 2003, Murphy and Robshaw discovered an alternative description of AES, embedding it in a larger cipher called \"BES\", which can be described using very simple operations over a single field, GF(28). An XSL attack mounted on this system yields a simpler set of equations which would break AES with complexity of around 2100, if the Courtois and Pieprzyk analysis is correct. In 2005 Cid and Leurent gave evidence that, in its proposed form, the XSL algorithm does not provide an efficient method for solving the AES system of equations; however Courtois disputed their findings. At FSE 2007, Chu-Wee Lim and Khoongming Khoo showed that it cannot possibly work as presented.Even if XSL works against some modern algorithms, the attack currently poses little danger in terms of practical security. Like many modern cryptanalytic results, it would be a so-called \"certificational weakness\": while faster than a brute force attack, the resources required are still huge, and it is very unlikely that real-world systems could be compromised by using it. Future improvements could increase the practicality of an attack, however. Because this type of attack is new and unexpected, some cryptographers have expressed unease at the algebraic simplicity of ciphers like Rijndael. Bruce Schneier and Niels Ferguson write, \"We have one criticism of AES: we don't quite trust the security\u2026 What concerns us the most about AES is its simple algebraic structure\u2026 No other block cipher we know of has such a simple algebraic representation. We have no idea whether this leads to an attack or not, but not knowing is reason enough to be skeptical about the use of AES.\" (Practical Cryptography, 2003, pp. 56\u201357)"
    }
  },
  {
    "instruction": "The Black Hat talk in 2014 by Karsten Nohl, Sascha Kri\u00dfler and Jakob Lell was significant because it was the first time the BadUSB attack was revealed to the public. The talk highlighted the vulnerability of USB devices to this type of attack and the potential for malicious software to be hidden within them.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What was the significance of the Black Hat talk in 2014 regarding BadUSB attacks?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What was the significance of the Black Hat talk in 2014 regarding BadUSB attacks?",
      "answer": "The Black Hat talk in 2014 by Karsten Nohl, Sascha Kri\u00dfler and Jakob Lell was significant because it was the first time the BadUSB attack was revealed to the public. The talk highlighted the vulnerability of USB devices to this type of attack and the potential for malicious software to be hidden within them."
    }
  },
  {
    "instruction": "Zscaler\n\n==Introduction==\nZscaler () is a cloud security company, with headquarters in San Jose, California. The company offers enterprise cloud security services.\n\n\n\n== Acquisitions == Answer this question using the following article:\n\nHow has Zscaler's acquisition of Cloudneeti impacted its cloud security posture management capabilities?",
    "context": "",
    "output": "Zscaler's acquisition of Cloudneeti has improved its cloud security posture management capabilities, enabling customers to better secure their cloud infrastructure and applications.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How has Zscaler's acquisition of Cloudneeti impacted its cloud security posture management capabilities?",
      "answer": "Zscaler's acquisition of Cloudneeti has improved its cloud security posture management capabilities, enabling customers to better secure their cloud infrastructure and applications.",
      "context": "Zscaler\n\n==Introduction==\nZscaler () is a cloud security company, with headquarters in San Jose, California. The company offers enterprise cloud security services.\n\n\n\n== Acquisitions =="
    }
  },
  {
    "instruction": "Unlike many of their competitors, INC maintained a moral high ground and refrained from engaging in unethical practices such as credit card fraud and lying. Their primary method of competition involved \"leaking\" a new game to a rival group like The Humble Guys, only to infect it with a trojan that dialed 9-1-1 when the modem was detected. This allowed INC to undermine their rivals while still maintaining an ethical stance compared to other groups in the scene.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What set INC apart from its rivals in terms of their approach to acquiring and releasing software?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What set INC apart from its rivals in terms of their approach to acquiring and releasing software?",
      "answer": "Unlike many of their competitors, INC maintained a moral high ground and refrained from engaging in unethical practices such as credit card fraud and lying. Their primary method of competition involved \"leaking\" a new game to a rival group like The Humble Guys, only to infect it with a trojan that dialed 9-1-1 when the modem was detected. This allowed INC to undermine their rivals while still maintaining an ethical stance compared to other groups in the scene."
    }
  },
  {
    "instruction": "Team Xecuter was a hacker group that was known for making mod chips and jailbreaking game consoles. While most console hackers are hobbyists who test boundaries and believe in the open-source model, Team Xecuter was controversial because they sold hacking tools for profit. This put them at odds with the prevailing ethos of the console hacking community, which tends to frown upon commercialization of hacking tools.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What kind of controversy was Team Xecuter involved in, in the console hacking community?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What kind of controversy was Team Xecuter involved in, in the console hacking community?",
      "answer": "Team Xecuter was a hacker group that was known for making mod chips and jailbreaking game consoles. While most console hackers are hobbyists who test boundaries and believe in the open-source model, Team Xecuter was controversial because they sold hacking tools for profit. This put them at odds with the prevailing ethos of the console hacking community, which tends to frown upon commercialization of hacking tools."
    }
  },
  {
    "instruction": "Context: Bootloader unlocking\n\n==Introduction==\nBootloader unlocking is the process of disabling the bootloader security that makes secure boot possible. It can make advanced customizations possible, such as installing a custom firmware. On smartphones this can be a custom Android distribution or another mobile operating system. Some bootloaders are not locked at all, others can be unlocked using a standard command, others need assistance from the manufacturer. Some do not include an unlocking method and can only be unlocked through a software exploit.\nBootloader unlocking is also done for mobile forensics purposes, to extract digital evidence from mobile devices, using tools such as Cellebrite UFED.\n\n== Background ==\nUnlocking the bootloader usually voids any warranties and may make the device susceptible to data theft. On Chromebooks, enabling developer mode makes the system less secure than a standard laptop running Linux. Unlocking the bootloader may lead to data loss on Android and ChromeOS devices, as some data is impossible to back up without root permission.\nSascha Segan from PCMag considered a locked bootloader a mistake on the Qualcomm Snapdragon Insiders phone, which is targeted at advanced users.\n\n== Platforms ==\n\n\n*** Android ***\nUnlocking the bootloader is typically done during the process to obtain root access.\n\n\n**** History ****\nThe bootloaders of Nexus and Pixel devices can be unlocked by using the fastboot command fastboot oem unlock or if it doesn't recognize the command fastboot flashing unlock.When Motorola released a bootloader unlocking tool for the Droid Razr, Verizon removed the tool from their models.In 2011, Sony Ericsson released an online bootloader unlocking tool. Sony requires the IMEI number to be filled in on their website. For the Asus Transformer Prime TF201, Asus has released a special bootloader unlock tool.In 2012, Motorola released a limited tool for unlocking bootloaders. They require accepting terms and conditions and creating an account before the bootloader can be unlocked for a Moto G.HTC phones have an additional layer of lock called \"S-OFF/S-ON\".\nBootloaders can be unlocked using an exploit or using a way that the vendor supplied. The latter method usually requires wiping all data on the device. In addition, some manufacturers prohibit unlocking on carrier locked phones. Samsung's US and Canadian Snapdragon phones do not allow unlocks regardless if the phone was bought from a carrier or not.\nIn 2018, a developer from XDA Developers launched a service which allowed users to unlock the bootloader of some Nokia smartphone models. Similarly, another developer from XDA Developers launched a service to allow users to unlock the bootloaders of Samsung Galaxy S20 and Samsung Galaxy S21 Phones.Huawei announced plans to allow users to unlock the bootloader of the Mate 30 series, but later retracted that. Huawei has stopped providing bootloader unlock codes since 2018. A bootloader exploit named checkm30 has been developed for HiSilicon based Huawei phones.When the bootloader of the Samsung Galaxy Z Fold 3 was unlocked, the camera became less functional. This could be restored by re-locking the bootloader. This issue was later fixed by Samsung. For the Samsung Galaxy S22 series, unlocking the bootloader has no effect on the camera.\n\n\n*** Others ***\n\n\n**** Microsoft ****\nThe WPInternals tool is able to unlock bootloaders of all Nokia Lumia phones running Windows Phone, but not phones like the Alcatel Idol 4 or HP Elite x3. Version 1.0 was released in November 2015. In October 2018, the tool was released as open source software when the main developer Ren\u00e9 Lergner (also known as HeathCliff74) stepped down.The slab bootloader used by Windows RT could be unlocked using a vulnerability, but was silently patched by Microsoft in 2016. UEFI Secure Boot on x86 systems can generally be unlocked.\n\n\n**** Apple ****\nThe boot ROM protection on iOS devices with an A11 processor or older can be bypassed with a hardware exploit known as checkm8, which makes it possible to run other operating systems including Linux.The bootloader on M1 based Macs can be unlocked.\n\n\n**** Google ****\nThe equivalent of bootloader unlocking is called developer mode in Chromebooks. Chromebooks use custom bootloaders that can be modified or overwritten by removing a Write-protect screw.In 2013, the bootloader of the Chromecast was hacked using an exploit. In 2021, it was hacked again for newer versions.\n\n\n**** SpaceX ****\nIn August 2022, security researcher Lennert Wouters applied a voltage injection attack to bypass firmware verification of a Starlink satellite dish from SpaceX.\n\n== Relocking ==\nOn Android, it is possible to relock the bootloader.\n\n== Shutdown of online services ==\nIn 2018, Huawei stopped providing bootloader unlock codes. On 31 December 2021, LG shut down their website which provided bootloader unlock codes.\n\n== Explanatory notes ==\nQuestion: How was the bootloader of the Chromecast hacked in 2013?. Whats the answer?",
    "context": "",
    "output": "The bootloader of the Chromecast was hacked in 2013 using an exploit, allowing users to modify the device's software.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How was the bootloader of the Chromecast hacked in 2013?",
      "answer": "The bootloader of the Chromecast was hacked in 2013 using an exploit, allowing users to modify the device's software.",
      "context": "Bootloader unlocking\n\n==Introduction==\nBootloader unlocking is the process of disabling the bootloader security that makes secure boot possible. It can make advanced customizations possible, such as installing a custom firmware. On smartphones this can be a custom Android distribution or another mobile operating system. Some bootloaders are not locked at all, others can be unlocked using a standard command, others need assistance from the manufacturer. Some do not include an unlocking method and can only be unlocked through a software exploit.\nBootloader unlocking is also done for mobile forensics purposes, to extract digital evidence from mobile devices, using tools such as Cellebrite UFED.\n\n== Background ==\nUnlocking the bootloader usually voids any warranties and may make the device susceptible to data theft. On Chromebooks, enabling developer mode makes the system less secure than a standard laptop running Linux. Unlocking the bootloader may lead to data loss on Android and ChromeOS devices, as some data is impossible to back up without root permission.\nSascha Segan from PCMag considered a locked bootloader a mistake on the Qualcomm Snapdragon Insiders phone, which is targeted at advanced users.\n\n== Platforms ==\n\n\n*** Android ***\nUnlocking the bootloader is typically done during the process to obtain root access.\n\n\n**** History ****\nThe bootloaders of Nexus and Pixel devices can be unlocked by using the fastboot command fastboot oem unlock or if it doesn't recognize the command fastboot flashing unlock.When Motorola released a bootloader unlocking tool for the Droid Razr, Verizon removed the tool from their models.In 2011, Sony Ericsson released an online bootloader unlocking tool. Sony requires the IMEI number to be filled in on their website. For the Asus Transformer Prime TF201, Asus has released a special bootloader unlock tool.In 2012, Motorola released a limited tool for unlocking bootloaders. They require accepting terms and conditions and creating an account before the bootloader can be unlocked for a Moto G.HTC phones have an additional layer of lock called \"S-OFF/S-ON\".\nBootloaders can be unlocked using an exploit or using a way that the vendor supplied. The latter method usually requires wiping all data on the device. In addition, some manufacturers prohibit unlocking on carrier locked phones. Samsung's US and Canadian Snapdragon phones do not allow unlocks regardless if the phone was bought from a carrier or not.\nIn 2018, a developer from XDA Developers launched a service which allowed users to unlock the bootloader of some Nokia smartphone models. Similarly, another developer from XDA Developers launched a service to allow users to unlock the bootloaders of Samsung Galaxy S20 and Samsung Galaxy S21 Phones.Huawei announced plans to allow users to unlock the bootloader of the Mate 30 series, but later retracted that. Huawei has stopped providing bootloader unlock codes since 2018. A bootloader exploit named checkm30 has been developed for HiSilicon based Huawei phones.When the bootloader of the Samsung Galaxy Z Fold 3 was unlocked, the camera became less functional. This could be restored by re-locking the bootloader. This issue was later fixed by Samsung. For the Samsung Galaxy S22 series, unlocking the bootloader has no effect on the camera.\n\n\n*** Others ***\n\n\n**** Microsoft ****\nThe WPInternals tool is able to unlock bootloaders of all Nokia Lumia phones running Windows Phone, but not phones like the Alcatel Idol 4 or HP Elite x3. Version 1.0 was released in November 2015. In October 2018, the tool was released as open source software when the main developer Ren\u00e9 Lergner (also known as HeathCliff74) stepped down.The slab bootloader used by Windows RT could be unlocked using a vulnerability, but was silently patched by Microsoft in 2016. UEFI Secure Boot on x86 systems can generally be unlocked.\n\n\n**** Apple ****\nThe boot ROM protection on iOS devices with an A11 processor or older can be bypassed with a hardware exploit known as checkm8, which makes it possible to run other operating systems including Linux.The bootloader on M1 based Macs can be unlocked.\n\n\n**** Google ****\nThe equivalent of bootloader unlocking is called developer mode in Chromebooks. Chromebooks use custom bootloaders that can be modified or overwritten by removing a Write-protect screw.In 2013, the bootloader of the Chromecast was hacked using an exploit. In 2021, it was hacked again for newer versions.\n\n\n**** SpaceX ****\nIn August 2022, security researcher Lennert Wouters applied a voltage injection attack to bypass firmware verification of a Starlink satellite dish from SpaceX.\n\n== Relocking ==\nOn Android, it is possible to relock the bootloader.\n\n== Shutdown of online services ==\nIn 2018, Huawei stopped providing bootloader unlock codes. On 31 December 2021, LG shut down their website which provided bootloader unlock codes.\n\n== Explanatory notes =="
    }
  },
  {
    "instruction": "The necessary and sufficient condition for a matrix to be an MDS matrix is that every possible n x n submatrix obtained by removing m rows from the augmented matrix is non-singular. This is equivalent to stating that all the sub-determinants of the matrix are non-zero.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the necessary and sufficient condition for a matrix to be an MDS matrix?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the necessary and sufficient condition for a matrix to be an MDS matrix?",
      "answer": "The necessary and sufficient condition for a matrix to be an MDS matrix is that every possible n x n submatrix obtained by removing m rows from the augmented matrix is non-singular. This is equivalent to stating that all the sub-determinants of the matrix are non-zero."
    }
  },
  {
    "instruction": "Once Linux.Wifatch has infected a device, it removes other malware, disables telnet access, and replaces it with a warning message encouraging users to update their firmware, change telnet passwords, or disable telnet entirely.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What actions does Linux.Wifatch take once it has infected a device?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What actions does Linux.Wifatch take once it has infected a device?",
      "answer": "Once Linux.Wifatch has infected a device, it removes other malware, disables telnet access, and replaces it with a warning message encouraging users to update their firmware, change telnet passwords, or disable telnet entirely."
    }
  },
  {
    "instruction": "Context: Fakesysdef\n\n==Introduction==\nTrojan:Win32/FakeSysdef, originally dispersed as an application called \"HDD Defragmenter\" hence the name \"FakeSysdef\" or \"Fake System Defragmenter\", is a Trojan targeting the Microsoft Windows operating system that was first documented in late 2010.Win32/FakeSysdef manifests as one or more of an array of programs that purport to scan one's computer for hardware failures related to system memory, hard drives and system functionality as a whole. They scan the computer, show false hardware issues, and present a remedy to defrag the hard drives and fine-tune the system performance. They then request the user to make a payment in order to activate the program so the user can download the new updates and to repair the hardware issues.The fictitious scanning program detects one or more of the most widespread varieties of risks prevalent on the internet today. Everyday numerous fake antivirus and security applications are published and released to unsuspecting end-users via a large assortment of distribution channels. Many times such software turn out to be clones of each other \u2013 developed from the same code base but packaged with a unique title and design through the use of a \"skin\".The branding strategy may look legitimate to computer users as the names are usually a combination of technical words such as \"HDD\", \"Disk\", \"Memory\" and action words such as \"Scanner\", \"Defragmenter\", \"Diagnostics\", \"Repair\", and \"Fix\".\n\n\n\n== Operation ==\nUsers may encounter this kind of threat when they visit websites that attempt to convince them to remove non-existent malware or security risks from their computers by installing the bogus software. The Trojan can also be installed by other malware, drive-by downloads, and when downloading and installing other software. Users may be directed to these sites by way of the following methods:\n\nSpam emails that contain links or attachments\npornography sites\nBlogs and forums that are spammed with links to adult videos\nUser-generated content spam (e.g. fake videos)\nMalicious banner advertisements\nUnauthorized software (\u2018warez\u2019)\nSearch engine optimization (SEO) poisoning\nFake torrents or other files on shared networks\nWeb pages containing exploitsThese programs intentionally misrepresent the security status of a computer by continually presenting fake scan dialog boxes and alert messages that prompt the user to buy the product.\nThe programs often have an icon in the notification area of the operating system desktop and constantly display pop-up messages alerting the user about fake security issues such as virus infections. These pop-up windows only disappear once the user has purchased the product and the non-existent threats have supposedly been removed from the compromised computer.\nIf the user decides to purchase the product, they are presented with a form within the application or are redirected to a website that requests credit card information.\n\n\n*** Initial infection ***\nThe Win32/FakeSysdef installer may arrive in the computer with various file names. When run, the installer drops and injects a DLL file (or sometimes and EXE file) into common processes, for example \"EXPLORER.EXE\", \"WINLOGON.EXE\", and \"WININET.EXE\".\nIn some instances, the main executable drops both DLL and EXE components. In this case, the EXE is set to run at every Windows restart and the DLL is injected into \"EXPLORER.EXE\" by the \"EXE\" component.\nTo ensure that it automatically runs every time Windows starts, it drops a copy of itself or its EXE component using a random file name into the %APPDATA% folder.Win32/FakeSysdef may make widespread changes to the system including: modifying several Internet Explorer settings, enabling submitting non-encrypted form data, changing the desktop wallpaper, displaying or hiding all shortcuts, hiding desktop and start menu links, disabling Windows Task Manager, disabling checking for signatures on downloaded programs, setting low risk file types\nAdditionally, some Win32/FakeSysdef variants that may terminate running processes during installation and may block launched application after the computer restarts. During the installation process, they may terminate all running processes and force the computer to restart. After the restart, FakeSysdef attempts to block every launched program, and may then display fake error messages offering to fix the problem. It then repeatedly restarts the computer until the user agrees to buy the fake software.\nIt then overwrites data on the hard drive/hard drive disk/HDD.\n\n== Symptoms ==\nWin32/FakeSysdef displays numerous false alerts indicating system errors while displaying the appearance of scanning the hard disk and defragmenting it, then prompts the user, with a \"Fix Errors\" button, to buy and activate it to fix discovered errors.\nWhen the \"Fix Errors\" button is selected, FakeSysdef pretends to scan and defragment the hard disk. It then displays more fake error messages, and tells the user that he needs to purchase an \"Advanced Module\" for the fix. If the user chooses to do so, the browser opens. It will open a custom web browser where the user can input card information to buy the software.\n\n== Removal and detection ==\nAnti-virus software makers responded to the threat of FakeSysdef by adding checks for it in their products. Simple removal of the software enabled by this is sometimes not enough to reverse the damage to configuration files that FakeSysdef was known to edit.\nQuestion: Can Trojan:Win32/FakeSysdef be removed manually?\n\nAnswer:",
    "context": "",
    "output": "Manual removal of Trojan:Win32/FakeSysdef can be difficult and is not recommended as it may not reverse the damage to configuration files that the Trojan was known to edit. It is recommended to use a reputable anti-virus software to detect and remove the Trojan.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "Can Trojan:Win32/FakeSysdef be removed manually?",
      "answer": "Manual removal of Trojan:Win32/FakeSysdef can be difficult and is not recommended as it may not reverse the damage to configuration files that the Trojan was known to edit. It is recommended to use a reputable anti-virus software to detect and remove the Trojan.",
      "context": "Fakesysdef\n\n==Introduction==\nTrojan:Win32/FakeSysdef, originally dispersed as an application called \"HDD Defragmenter\" hence the name \"FakeSysdef\" or \"Fake System Defragmenter\", is a Trojan targeting the Microsoft Windows operating system that was first documented in late 2010.Win32/FakeSysdef manifests as one or more of an array of programs that purport to scan one's computer for hardware failures related to system memory, hard drives and system functionality as a whole. They scan the computer, show false hardware issues, and present a remedy to defrag the hard drives and fine-tune the system performance. They then request the user to make a payment in order to activate the program so the user can download the new updates and to repair the hardware issues.The fictitious scanning program detects one or more of the most widespread varieties of risks prevalent on the internet today. Everyday numerous fake antivirus and security applications are published and released to unsuspecting end-users via a large assortment of distribution channels. Many times such software turn out to be clones of each other \u2013 developed from the same code base but packaged with a unique title and design through the use of a \"skin\".The branding strategy may look legitimate to computer users as the names are usually a combination of technical words such as \"HDD\", \"Disk\", \"Memory\" and action words such as \"Scanner\", \"Defragmenter\", \"Diagnostics\", \"Repair\", and \"Fix\".\n\n\n\n== Operation ==\nUsers may encounter this kind of threat when they visit websites that attempt to convince them to remove non-existent malware or security risks from their computers by installing the bogus software. The Trojan can also be installed by other malware, drive-by downloads, and when downloading and installing other software. Users may be directed to these sites by way of the following methods:\n\nSpam emails that contain links or attachments\npornography sites\nBlogs and forums that are spammed with links to adult videos\nUser-generated content spam (e.g. fake videos)\nMalicious banner advertisements\nUnauthorized software (\u2018warez\u2019)\nSearch engine optimization (SEO) poisoning\nFake torrents or other files on shared networks\nWeb pages containing exploitsThese programs intentionally misrepresent the security status of a computer by continually presenting fake scan dialog boxes and alert messages that prompt the user to buy the product.\nThe programs often have an icon in the notification area of the operating system desktop and constantly display pop-up messages alerting the user about fake security issues such as virus infections. These pop-up windows only disappear once the user has purchased the product and the non-existent threats have supposedly been removed from the compromised computer.\nIf the user decides to purchase the product, they are presented with a form within the application or are redirected to a website that requests credit card information.\n\n\n*** Initial infection ***\nThe Win32/FakeSysdef installer may arrive in the computer with various file names. When run, the installer drops and injects a DLL file (or sometimes and EXE file) into common processes, for example \"EXPLORER.EXE\", \"WINLOGON.EXE\", and \"WININET.EXE\".\nIn some instances, the main executable drops both DLL and EXE components. In this case, the EXE is set to run at every Windows restart and the DLL is injected into \"EXPLORER.EXE\" by the \"EXE\" component.\nTo ensure that it automatically runs every time Windows starts, it drops a copy of itself or its EXE component using a random file name into the %APPDATA% folder.Win32/FakeSysdef may make widespread changes to the system including: modifying several Internet Explorer settings, enabling submitting non-encrypted form data, changing the desktop wallpaper, displaying or hiding all shortcuts, hiding desktop and start menu links, disabling Windows Task Manager, disabling checking for signatures on downloaded programs, setting low risk file types\nAdditionally, some Win32/FakeSysdef variants that may terminate running processes during installation and may block launched application after the computer restarts. During the installation process, they may terminate all running processes and force the computer to restart. After the restart, FakeSysdef attempts to block every launched program, and may then display fake error messages offering to fix the problem. It then repeatedly restarts the computer until the user agrees to buy the fake software.\nIt then overwrites data on the hard drive/hard drive disk/HDD.\n\n== Symptoms ==\nWin32/FakeSysdef displays numerous false alerts indicating system errors while displaying the appearance of scanning the hard disk and defragmenting it, then prompts the user, with a \"Fix Errors\" button, to buy and activate it to fix discovered errors.\nWhen the \"Fix Errors\" button is selected, FakeSysdef pretends to scan and defragment the hard disk. It then displays more fake error messages, and tells the user that he needs to purchase an \"Advanced Module\" for the fix. If the user chooses to do so, the browser opens. It will open a custom web browser where the user can input card information to buy the software.\n\n== Removal and detection ==\nAnti-virus software makers responded to the threat of FakeSysdef by adding checks for it in their products. Simple removal of the software enabled by this is sometimes not enough to reverse the damage to configuration files that FakeSysdef was known to edit."
    }
  },
  {
    "instruction": "Non-repudiation\n\n==Introduction==\nIn law, non-repudiation is a situation where a statement's author cannot successfully dispute its authorship or the validity of an associated contract. The term is often seen in a legal setting when the authenticity of a signature is being challenged. In such an instance, the authenticity is being \"repudiated\".For example, Mallory buys a cell phone for $100, writes a paper cheque as payment, and signs the cheque with a pen.  Later, she finds that she can't afford it, and claims that the cheque is a forgery.  The signature guarantees that only Mallory could have signed the cheque, and so Mallory's bank must pay the cheque.  This is non-repudiation; Mallory cannot repudiate the cheque. In practice, pen-and-paper signatures aren't hard to forge, but digital signatures can be very hard to break.\n\n\n\n== In security ==\nIn general, non-repudiation involves associating actions or changes with a unique individual. For example, a secure area may use a key card access system where non-repudiation would be violated if key cards were shared or if lost and stolen cards were not immediately reported. Similarly, the owner of a computer account must not allow others to use it, such as by giving away their password, and a policy should be implemented to enforce this.\n\n\n*** In digital security ***\nIn digital security, non-repudiation means:\nA service that provides proof of the integrity and origin of data.\nAn authentication that can be said to be genuine with high confidence.\nAn authentication that the data is available under specific circumstances, or for a period of time: data availability.Proof of data integrity is typically the easiest of these requirements to accomplish. A data hash such as SHA2 usually ensures that the data will not be changed undetectably. Even with this safeguard, it is possible to tamper with data in transit, either through a man-in-the-middle attack or phishing. Because of this, data integrity is best asserted when the recipient already possesses the necessary verification information, such as after being mutually authenticated.The common method to provide non-repudiation in the context of digital communications or storage is Digital Signatures, a more powerful tool that provides non-repudiation in a publicly verifiable manner. Message Authentication Codes (MAC), useful when the communicating parties have arranged to use a shared secret that they both possess, does not give non-repudiation. A misconception is that encrypting, per se, provides authentication \"If the message decrypts properly then it is authentic\" - Wrong! MAC can be subject to several types of attacks, like: message reordering, block substitution, block repetition, .... Thus just providing message integrity and authentication, but not non-repudiation. To achieve non-repudiation one must trust a service (a certificate generated by a trusted third party (TTP) called certificate authority (CA)) which prevents an entity from denying previous commitments or actions (e.g. sending message A to B). The difference between MAC and Digital Signatures, one uses symmetric keys and the other asymmetric keys (provided by the CA). Note that the goal is not to achieve confidentiality: in both cases (MAC or digital signature), one simply appends a tag to the otherwise plaintext, visible message. If confidentiality is also required, then an encryption scheme can be combined with the digital signature, or some form of authenticated encryption could be used.  Verifying the digital origin means that the certified/signed data likely came from someone who possesses the private key corresponding to the signing certificate. If the key used to digitally sign a message is not properly safeguarded by the original owner, digital forgery can occur.\n\n== Trusted third parties (TTPs) ==\nTo mitigate the risk of people repudiating their own signatures, the standard approach is to involve a trusted third party.The two most common TTPs are forensic analysts and notaries. A forensic analyst specializing in handwriting can compare some signature to a known valid signature and assess its legitimacy. A notary is a witness who verifies an individual's identity by checking other credentials and affixing their certification that the person signing is who they claim to be. A notary provides the extra benefit of maintaining independent logs of their transactions, complete with the types of credentials checked, and another signature that can be verified by the forensic analyst. This double security makes notaries the preferred form of verification.For digital information, the most commonly employed TTP is a certificate authority, which issues public key certificates. A public key certificate can be used by anyone to verify digital signatures without a shared secret between the signer and the verifier. The role of the certificate authority is to authoritatively state to whom the certificate belongs, meaning that this person or entity possesses the corresponding private key. However, a digital signature is forensically identical in both legitimate and forged uses. Someone who possesses the private key can create a valid digital signature. Protecting the private key is the idea behind some smart cards such as the United States Department of Defense's Common Access Card (CAC), which never lets the key leave the card. That means that to use the card for encryption and digital signatures, a person needs the personal identification number (PIN) code necessary to unlock it.\n\nAnswer this question \"What is the main challenge in ensuring non-repudiation in digital communications or storage?\" using the text above.",
    "context": "",
    "output": "The main challenge in ensuring non-repudiation in digital communications or storage is the risk of digital forgery, which can occur if the private key used for digital signatures is not properly safeguarded.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the main challenge in ensuring non-repudiation in digital communications or storage?",
      "answer": "The main challenge in ensuring non-repudiation in digital communications or storage is the risk of digital forgery, which can occur if the private key used for digital signatures is not properly safeguarded.",
      "context": "Non-repudiation\n\n==Introduction==\nIn law, non-repudiation is a situation where a statement's author cannot successfully dispute its authorship or the validity of an associated contract. The term is often seen in a legal setting when the authenticity of a signature is being challenged. In such an instance, the authenticity is being \"repudiated\".For example, Mallory buys a cell phone for $100, writes a paper cheque as payment, and signs the cheque with a pen.  Later, she finds that she can't afford it, and claims that the cheque is a forgery.  The signature guarantees that only Mallory could have signed the cheque, and so Mallory's bank must pay the cheque.  This is non-repudiation; Mallory cannot repudiate the cheque. In practice, pen-and-paper signatures aren't hard to forge, but digital signatures can be very hard to break.\n\n\n\n== In security ==\nIn general, non-repudiation involves associating actions or changes with a unique individual. For example, a secure area may use a key card access system where non-repudiation would be violated if key cards were shared or if lost and stolen cards were not immediately reported. Similarly, the owner of a computer account must not allow others to use it, such as by giving away their password, and a policy should be implemented to enforce this.\n\n\n*** In digital security ***\nIn digital security, non-repudiation means:\nA service that provides proof of the integrity and origin of data.\nAn authentication that can be said to be genuine with high confidence.\nAn authentication that the data is available under specific circumstances, or for a period of time: data availability.Proof of data integrity is typically the easiest of these requirements to accomplish. A data hash such as SHA2 usually ensures that the data will not be changed undetectably. Even with this safeguard, it is possible to tamper with data in transit, either through a man-in-the-middle attack or phishing. Because of this, data integrity is best asserted when the recipient already possesses the necessary verification information, such as after being mutually authenticated.The common method to provide non-repudiation in the context of digital communications or storage is Digital Signatures, a more powerful tool that provides non-repudiation in a publicly verifiable manner. Message Authentication Codes (MAC), useful when the communicating parties have arranged to use a shared secret that they both possess, does not give non-repudiation. A misconception is that encrypting, per se, provides authentication \"If the message decrypts properly then it is authentic\" - Wrong! MAC can be subject to several types of attacks, like: message reordering, block substitution, block repetition, .... Thus just providing message integrity and authentication, but not non-repudiation. To achieve non-repudiation one must trust a service (a certificate generated by a trusted third party (TTP) called certificate authority (CA)) which prevents an entity from denying previous commitments or actions (e.g. sending message A to B). The difference between MAC and Digital Signatures, one uses symmetric keys and the other asymmetric keys (provided by the CA). Note that the goal is not to achieve confidentiality: in both cases (MAC or digital signature), one simply appends a tag to the otherwise plaintext, visible message. If confidentiality is also required, then an encryption scheme can be combined with the digital signature, or some form of authenticated encryption could be used.  Verifying the digital origin means that the certified/signed data likely came from someone who possesses the private key corresponding to the signing certificate. If the key used to digitally sign a message is not properly safeguarded by the original owner, digital forgery can occur.\n\n== Trusted third parties (TTPs) ==\nTo mitigate the risk of people repudiating their own signatures, the standard approach is to involve a trusted third party.The two most common TTPs are forensic analysts and notaries. A forensic analyst specializing in handwriting can compare some signature to a known valid signature and assess its legitimacy. A notary is a witness who verifies an individual's identity by checking other credentials and affixing their certification that the person signing is who they claim to be. A notary provides the extra benefit of maintaining independent logs of their transactions, complete with the types of credentials checked, and another signature that can be verified by the forensic analyst. This double security makes notaries the preferred form of verification.For digital information, the most commonly employed TTP is a certificate authority, which issues public key certificates. A public key certificate can be used by anyone to verify digital signatures without a shared secret between the signer and the verifier. The role of the certificate authority is to authoritatively state to whom the certificate belongs, meaning that this person or entity possesses the corresponding private key. However, a digital signature is forensically identical in both legitimate and forged uses. Someone who possesses the private key can create a valid digital signature. Protecting the private key is the idea behind some smart cards such as the United States Department of Defense's Common Access Card (CAC), which never lets the key leave the card. That means that to use the card for encryption and digital signatures, a person needs the personal identification number (PIN) code necessary to unlock it."
    }
  },
  {
    "instruction": "The support for FIPS 140 certification is important for the use of cryptography libraries in regulated industries, such as government and financial institutions. FIPS 140 certification provides a standard for evaluating the security of cryptography libraries and ensures that they meet certain requirements for use in these industries.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does the support for FIPS 140 certification impact the use of these cryptography libraries in regulated industries?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does the support for FIPS 140 certification impact the use of these cryptography libraries in regulated industries?",
      "answer": "The support for FIPS 140 certification is important for the use of cryptography libraries in regulated industries, such as government and financial institutions. FIPS 140 certification provides a standard for evaluating the security of cryptography libraries and ensures that they meet certain requirements for use in these industries."
    }
  },
  {
    "instruction": "The Competition for Authenticated Encryption: Security, Applicability, and Robustness (CAESAR) was organized by a group of international cryptologic researchers.\n\nWrite a question about the text above.",
    "context": "",
    "output": "Who organized the Competition for Authenticated Encryption: Security, Applicability, and Robustness (CAESAR)?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "Who organized the Competition for Authenticated Encryption: Security, Applicability, and Robustness (CAESAR)?",
      "answer": "The Competition for Authenticated Encryption: Security, Applicability, and Robustness (CAESAR) was organized by a group of international cryptologic researchers."
    }
  },
  {
    "instruction": "The Tor Project\n\n==Introduction==\nThe Tor Project, Inc. is a 501(c)(3) research-education nonprofit organization based in Winchester, New Hampshire. It is founded by computer scientists Roger Dingledine, Nick Mathewson, and five others. The Tor Project is primarily responsible for maintaining software for the Tor anonymity network.\n\n\n\n== Funding ==\nAs of 2012, 80% of the Tor Project's $2 million annual budget came from the United States government, with the U.S. State Department, the Broadcasting Board of Governors, and the National Science Foundation as major contributors, \"to aid democracy advocates in authoritarian states\". The Swedish government and other organizations provided the other 20%, including NGOs and thousands of individual sponsors. Dingledine said that the United States Department of Defense funds are more similar to a research grant than a procurement contract. Tor executive director Andrew Lewman said that even though it accepts funds from the U.S. federal government, the Tor service did not collaborate with the NSA to reveal identities of users.In June 2016, the Tor Project received an award from Mozilla's Open Source Support program (MOSS). The award was \"to significantly enhance the Tor network's metrics infrastructure so that the performance and stability of the network can be monitored and improvements made as appropriate.\"\n\n== Tools ==\nMetrics PortalAnalytics for the Tor network, including graphs of its available bandwidth and estimated userbase. This is a great resource for researchers interested in detailed statistics about Tor.Nyxa terminal (command line) application for monitoring and configuring Tor, intended for command-line enthusiasts and ssh connections. This functions much like top does for system usage, providing real time information on Tor's resource utilization and state.OnionooWeb-based protocol to learn about currently running Tor relays and bridges.OnionShareAn open source tool that allows users to securely and anonymously share a file of any size.OONI (Open Observatory of Network Interference (OONI))a global observation network, monitoring network censorship, which aims to collect high-quality data using open methodologies, using Free and Open Source Software (FL/OSS) to share observations and data about the various types, methods, and amounts of network tampering in the world.OrbotTor for Android and iOS devices, in collaboration with The Guardian ProjectOrliba library for use by any Android application to route Internet traffic through Orbot/Tor.Pluggable Transports (PT)helps circumvent censorship. Transforms the Tor traffic flow between the client and the bridge. This way, censors who monitor traffic between the client and the bridge will see innocent-looking transformed traffic instead of the actual Tor traffic.Relay SearchSite providing an overview of the Tor network.Shadowa discrete-event network simulator that runs the real Tor software as a plug-in. Shadow is open-source software that enables accurate, efficient, controlled, and repeatable Tor experimentation.StemPython Library for writing scripts and applications that interact with Tor.Tails (The Amnesic Incognito Live System)a live CD/USB distribution preconfigured so that everything is safely routed through Tor and leaves no trace on the local system.Torfree software and an open network that helps a user defend against traffic analysis, a form of network surveillance that threatens personal freedom and privacy, confidential business activities and relationships, and state security. The organization has also implemented the software in Rust named Arti.Tor Browsera customization of Mozilla Firefox which uses a Tor circuit for browsing anonymously and with other features consistent with the Tor mission.Tor PhoneA phone that routes its network traffic through tor network. Initially based on a CopperheadOS custom ROM prototype, using Tor with Orbot and Tor Browser are supported by custom Android operating systems CalyxOS and DivestOS. GrapheneOS supports using Orbot VPN but not Tor Browser.TorBirdyTorbutton for Thunderbird and related *bird forks.txtorconPython and Twisted event-based implementation of the Tor control protocol. Unit-tests, state and configuration abstractions, documentation. It is available on PyPI and in Debian.\n\n== Recognition ==\nIn March 2011, the Tor Project received the Free Software Foundation's 2010 Award for Projects of Social Benefit. The citation read, \"Using free software, Tor has enabled roughly 36 million people around the world to experience freedom of access and expression on the Internet while keeping them in control of their privacy and anonymity. Its network has proved pivotal in dissident movements in both Iran and more recently Egypt.\"In September 2012, the Tor Project received the 2012 EFF Pioneer Award, along with J\u00e9r\u00e9mie Zimmermann and Andrew Huang.In November 2012, Foreign Policy magazine named Dingledine, Mathewson, and Syverson among its Top 100 Global Thinkers \"for making the web safe for whistleblowers\".In 2014, Roger Dingledine, Nick Mathewson and Paul Syverson received the USENIX Test of Time Award for their paper titled \"Tor: The Second-Generation Onion Router\", which was published in the Proceedings of the 13th USENIX Security Symposium, August 2004.\n\nAnswer this question \"What is the recognition received by Roger Dingledine, Nick Mathewson, and Paul Syverson in 2014 and for what paper did they receive it?\" using the text above.",
    "context": "",
    "output": "Roger Dingledine, Nick Mathewson, and Paul Syverson received the USENIX Test of Time Award in 2014 for their paper titled \"Tor: The Second-Generation Onion Router\", which was published in the Proceedings of the 13th USENIX Security Symposium, August 2004.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the recognition received by Roger Dingledine, Nick Mathewson, and Paul Syverson in 2014 and for what paper did they receive it?",
      "answer": "Roger Dingledine, Nick Mathewson, and Paul Syverson received the USENIX Test of Time Award in 2014 for their paper titled \"Tor: The Second-Generation Onion Router\", which was published in the Proceedings of the 13th USENIX Security Symposium, August 2004.",
      "context": "The Tor Project\n\n==Introduction==\nThe Tor Project, Inc. is a 501(c)(3) research-education nonprofit organization based in Winchester, New Hampshire. It is founded by computer scientists Roger Dingledine, Nick Mathewson, and five others. The Tor Project is primarily responsible for maintaining software for the Tor anonymity network.\n\n\n\n== Funding ==\nAs of 2012, 80% of the Tor Project's $2 million annual budget came from the United States government, with the U.S. State Department, the Broadcasting Board of Governors, and the National Science Foundation as major contributors, \"to aid democracy advocates in authoritarian states\". The Swedish government and other organizations provided the other 20%, including NGOs and thousands of individual sponsors. Dingledine said that the United States Department of Defense funds are more similar to a research grant than a procurement contract. Tor executive director Andrew Lewman said that even though it accepts funds from the U.S. federal government, the Tor service did not collaborate with the NSA to reveal identities of users.In June 2016, the Tor Project received an award from Mozilla's Open Source Support program (MOSS). The award was \"to significantly enhance the Tor network's metrics infrastructure so that the performance and stability of the network can be monitored and improvements made as appropriate.\"\n\n== Tools ==\nMetrics PortalAnalytics for the Tor network, including graphs of its available bandwidth and estimated userbase. This is a great resource for researchers interested in detailed statistics about Tor.Nyxa terminal (command line) application for monitoring and configuring Tor, intended for command-line enthusiasts and ssh connections. This functions much like top does for system usage, providing real time information on Tor's resource utilization and state.OnionooWeb-based protocol to learn about currently running Tor relays and bridges.OnionShareAn open source tool that allows users to securely and anonymously share a file of any size.OONI (Open Observatory of Network Interference (OONI))a global observation network, monitoring network censorship, which aims to collect high-quality data using open methodologies, using Free and Open Source Software (FL/OSS) to share observations and data about the various types, methods, and amounts of network tampering in the world.OrbotTor for Android and iOS devices, in collaboration with The Guardian ProjectOrliba library for use by any Android application to route Internet traffic through Orbot/Tor.Pluggable Transports (PT)helps circumvent censorship. Transforms the Tor traffic flow between the client and the bridge. This way, censors who monitor traffic between the client and the bridge will see innocent-looking transformed traffic instead of the actual Tor traffic.Relay SearchSite providing an overview of the Tor network.Shadowa discrete-event network simulator that runs the real Tor software as a plug-in. Shadow is open-source software that enables accurate, efficient, controlled, and repeatable Tor experimentation.StemPython Library for writing scripts and applications that interact with Tor.Tails (The Amnesic Incognito Live System)a live CD/USB distribution preconfigured so that everything is safely routed through Tor and leaves no trace on the local system.Torfree software and an open network that helps a user defend against traffic analysis, a form of network surveillance that threatens personal freedom and privacy, confidential business activities and relationships, and state security. The organization has also implemented the software in Rust named Arti.Tor Browsera customization of Mozilla Firefox which uses a Tor circuit for browsing anonymously and with other features consistent with the Tor mission.Tor PhoneA phone that routes its network traffic through tor network. Initially based on a CopperheadOS custom ROM prototype, using Tor with Orbot and Tor Browser are supported by custom Android operating systems CalyxOS and DivestOS. GrapheneOS supports using Orbot VPN but not Tor Browser.TorBirdyTorbutton for Thunderbird and related *bird forks.txtorconPython and Twisted event-based implementation of the Tor control protocol. Unit-tests, state and configuration abstractions, documentation. It is available on PyPI and in Debian.\n\n== Recognition ==\nIn March 2011, the Tor Project received the Free Software Foundation's 2010 Award for Projects of Social Benefit. The citation read, \"Using free software, Tor has enabled roughly 36 million people around the world to experience freedom of access and expression on the Internet while keeping them in control of their privacy and anonymity. Its network has proved pivotal in dissident movements in both Iran and more recently Egypt.\"In September 2012, the Tor Project received the 2012 EFF Pioneer Award, along with J\u00e9r\u00e9mie Zimmermann and Andrew Huang.In November 2012, Foreign Policy magazine named Dingledine, Mathewson, and Syverson among its Top 100 Global Thinkers \"for making the web safe for whistleblowers\".In 2014, Roger Dingledine, Nick Mathewson and Paul Syverson received the USENIX Test of Time Award for their paper titled \"Tor: The Second-Generation Onion Router\", which was published in the Proceedings of the 13th USENIX Security Symposium, August 2004."
    }
  },
  {
    "instruction": "Context: APT (software)\n\n==Introduction==\nAdvanced package tool, or APT, is a free-software user interface that works with core libraries to handle the installation and removal of software on Debian, and Debian-based Linux distributions. APT simplifies the process of managing software on Unix-like computer systems by automating the retrieval, configuration and installation of software packages, either from precompiled files or by compiling source code.\n\n== Usage ==\nAPT is a collection of tools distributed in a package named apt. A significant part of APT is defined in a C++ library of functions; APT also includes command-line programs for dealing with packages, which use the library. Three such programs are apt, apt-get and apt-cache. They are commonly used in examples because they are simple and ubiquitous. The apt package is of \"important\" priority in all current Debian releases, and is therefore included in a default Debian installation. APT can be considered a front-end to dpkg, friendlier than the older dselect front-end. While dpkg performs actions on individual packages, APT manages relations (especially dependencies) between them, as well as sourcing and management of higher-level versioning decisions (release tracking and version pinning).\nAPT is often hailed as one of Debian's best features, which Debian developers attribute to the strict quality controls in Debian's policy.A major feature of APT is the way it calls dpkg \u2014 it does topological sorting of the list of packages to be installed or removed and calls dpkg in the best possible sequence. In some cases, it utilizes the --force options of dpkg. However, it only does this when it is unable to calculate how to avoid the reason dpkg requires the action to be forced.\n\n\n*** Installing software ***\nThe user indicates one or more packages to be installed. Each package name is phrased as just the name portion of the package, not a fully qualified filename (for instance, in a Debian system, libc6 would be the argument provided, not libc6_1.9.6-2.deb). Notably, APT automatically gets and installs packages upon which the indicated package depends (if necessary). This was an original distinguishing characteristic of APT-based package management systems, as it avoided installation failure due to missing dependencies, a type of dependency hell.\nAnother distinction is the retrieval of packages from remote repositories. APT uses a location configuration file (/etc/apt/sources.list) to locate the desired packages, which might be available on the network or a removable storage medium, for example, and retrieve them, and also obtain information about available (but not installed) packages.\nAPT provides other command options to override decisions made by apt-get's conflict resolution system. One option is to force a particular version of a package. This can downgrade a package and render dependent software inoperable, so the user must be careful.\nFinally, the apt_preferences mechanism allows the user to create an alternative installation policy for individual packages.\nThe user can specify packages using a POSIX regular expression.\nAPT searches its cached list of packages and lists the dependencies that must be installed or updated.\nAPT retrieves, configures and installs the dependencies automatically.\nTriggers are the treatment of deferred actions.\n\n\n*** Update, upgrade and dist-upgrade ***\nUsage modes of apt and apt-get that facilitate updating installed packages include:\n\nupdate is used to resynchronize the package index files from their sources. The lists of available packages are fetched from the location(s) specified in /etc/apt/sources.list. For example, when using a Debian archive, this command retrieves and scans the Packages.gz files, so that information about new and updated packages is available.\nupgrade is used to install the newest versions of all packages currently installed on the system from the sources enumerated in /etc/apt/sources.list. Packages currently installed with new versions available are retrieved and upgraded; under no circumstances are currently installed packages removed, or packages not already installed retrieved and installed. New versions of currently installed packages that cannot be upgraded without changing the install status of another package will be left at their current version.\nfull-upgrade (apt) and dist-upgrade (apt-get), in addition to performing the function of upgrade, also intelligently handles changing dependencies with new versions of packages; apt and apt-get have a \"smart\" conflict resolution system, and will attempt to upgrade the most important packages at the expense of less important ones if necessary. The /etc/apt/sources.list file contains a list of locations from which to retrieve desired package files. aptitude has a smarter dist-upgrade feature called full-upgrade.\n\n== Configuration and files ==\n/etc/apt contains the APT configuration folders and files.\napt-config is the APT Configuration Query program. apt-config dump shows the configuration.\n\n\n*** Files ***\n/etc/apt/sources.list: Locations to fetch packages from.\n/etc/apt/sources.list.d/: Additional source list fragments.\n/etc/apt/apt.conf: APT configuration file.\n/etc/apt/apt.conf.d/: APT configuration file fragments.\n/etc/apt/preferences.d/: Directory with version preferences files. This is where \"pinning\" is specified, i.e. a preference to get certain packages from a separate source or from a different version of a distribution.\n/var/cache/apt/archives/: Storage area for retrieved package files.\n/var/cache/apt/archives/partial/: Storage area for package files in transit.\n/var/lib/apt/lists/: Storage area for state information for each package resource specified in sources.list\n/var/lib/apt/lists/partial/: Storage area for state information in transit.\n\n== APT pinning ==\nThe APT pinning feature allows users to force APT to choose particular versions of packages which may be available in different versions from different repositories. This allows administrators to ensure that packages are not upgraded to versions which may conflict with other packages on the system, or that have not been sufficiently tested for unwelcome changes.\nIn order to do this, the pins in APT's preferences file (/etc/apt/preferences) must be modified, although graphical front-ends often make pinning simpler.\n\n== Front-ends ==\n\nSeveral other front-ends to APT exist, which provide more advanced installation functions and more intuitive interfaces. These include:\n\nSynaptic, a GTK graphical user interface\nUbuntu Software Center, a GTK graphical user interface developed by the Ubuntu project\naptitude, a console client with CLI and ncurses-based TUI interfaces\nKPackage, part of KDE\nAdept package manager, a graphical user interface for KDE (deb, rpm, bsd)\nPackageKit, a D-Bus frontend, maintained by freedesktop.org, powers GNOME Software and KDE Discover.\nGDebi, a GTK-based tool sponsored for Ubuntu. (There is also a Qt version, available in the Ubuntu repositories as gdebi-kde.)\napt-cdrom, a way to add a new CDROM to APT's list of available repositories (sources.lists). It is necessary to use apt-cdrom to add CDs to the APT system, it cannot be done by hand.\napt-zip, a way to use apt with removable media, specifically USB flash drives.\naptURL, an Ubuntu software package that enables end-user applications to install with a single-click through a browser.\nCydia, a package manager for jailbroken iOS based on APT (ported to iOS as part of the Telesphoreo project).\nSileo, like Cydia, a package manager for jailbroken iOS based on newer versions of APT (ported to iOS by the Electra team)\ngnome-apt, a GTK/GNOME-widget-based graphical front-end. Developed by Havoc Pennington\nMuon discover (previous Muon software center), a Qt-based graphical user interface\nHildon application manager (Maemo application), a Maemo front-end\napticron, a service designed to be run via cron to email notices of pending updates to a system administrator (sysadmin).\nAPT Daemon, a front-end that runs as a service to allow users to install software through PolicyKit and is in turn the framework used by Ubuntu software center (along with the Linux Mint software manager).\nPackage installer, part of MX Linux.[1]\nApt-offline: A convenient way to make any available non-containerized change to any Debian-type Linux installation without using a direct Internet connection. However, a temporary direct connection can be required, such as to install Apt-offline on some of the relevant types of Linux, and to add PPA's to the sources-list.APT front-ends can:\n\nsearch for new packages;\nupgrade packages;\ninstall or remove packages and\nupgrade the whole system to a new release.APT front-ends can list the dependencies of packages being installed or upgraded, ask the administrator if packages recommended or suggested by newly installed packages should be installed too, automatically install dependencies and perform other operations on the system such as removing obsolete files and packages.\n\n== Variants ==\nAPT was originally designed as a front-end for dpkg to work with Debian's .deb packages. A version of APT modified to also work with the RPM Package Manager system was released as APT-RPM. The Fink project has ported APT to Mac OS X for some of its own package management tasks, and APT is also available in OpenSolaris.\n\n== apt-file ==\napt-file is a command, packaged separately from APT, to find which package includes a specific file, or to list all files included in a package on remote repositories.\nQuestion: How does APT differ from other package management systems in handling dependencies?\n\nAnswer:",
    "context": "",
    "output": "APT automatically retrieves and installs dependencies that are necessary for the indicated package to function correctly, which was an original distinguishing characteristic of APT-based package management systems.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does APT differ from other package management systems in handling dependencies?",
      "answer": "APT automatically retrieves and installs dependencies that are necessary for the indicated package to function correctly, which was an original distinguishing characteristic of APT-based package management systems.",
      "context": "APT (software)\n\n==Introduction==\nAdvanced package tool, or APT, is a free-software user interface that works with core libraries to handle the installation and removal of software on Debian, and Debian-based Linux distributions. APT simplifies the process of managing software on Unix-like computer systems by automating the retrieval, configuration and installation of software packages, either from precompiled files or by compiling source code.\n\n== Usage ==\nAPT is a collection of tools distributed in a package named apt. A significant part of APT is defined in a C++ library of functions; APT also includes command-line programs for dealing with packages, which use the library. Three such programs are apt, apt-get and apt-cache. They are commonly used in examples because they are simple and ubiquitous. The apt package is of \"important\" priority in all current Debian releases, and is therefore included in a default Debian installation. APT can be considered a front-end to dpkg, friendlier than the older dselect front-end. While dpkg performs actions on individual packages, APT manages relations (especially dependencies) between them, as well as sourcing and management of higher-level versioning decisions (release tracking and version pinning).\nAPT is often hailed as one of Debian's best features, which Debian developers attribute to the strict quality controls in Debian's policy.A major feature of APT is the way it calls dpkg \u2014 it does topological sorting of the list of packages to be installed or removed and calls dpkg in the best possible sequence. In some cases, it utilizes the --force options of dpkg. However, it only does this when it is unable to calculate how to avoid the reason dpkg requires the action to be forced.\n\n\n*** Installing software ***\nThe user indicates one or more packages to be installed. Each package name is phrased as just the name portion of the package, not a fully qualified filename (for instance, in a Debian system, libc6 would be the argument provided, not libc6_1.9.6-2.deb). Notably, APT automatically gets and installs packages upon which the indicated package depends (if necessary). This was an original distinguishing characteristic of APT-based package management systems, as it avoided installation failure due to missing dependencies, a type of dependency hell.\nAnother distinction is the retrieval of packages from remote repositories. APT uses a location configuration file (/etc/apt/sources.list) to locate the desired packages, which might be available on the network or a removable storage medium, for example, and retrieve them, and also obtain information about available (but not installed) packages.\nAPT provides other command options to override decisions made by apt-get's conflict resolution system. One option is to force a particular version of a package. This can downgrade a package and render dependent software inoperable, so the user must be careful.\nFinally, the apt_preferences mechanism allows the user to create an alternative installation policy for individual packages.\nThe user can specify packages using a POSIX regular expression.\nAPT searches its cached list of packages and lists the dependencies that must be installed or updated.\nAPT retrieves, configures and installs the dependencies automatically.\nTriggers are the treatment of deferred actions.\n\n\n*** Update, upgrade and dist-upgrade ***\nUsage modes of apt and apt-get that facilitate updating installed packages include:\n\nupdate is used to resynchronize the package index files from their sources. The lists of available packages are fetched from the location(s) specified in /etc/apt/sources.list. For example, when using a Debian archive, this command retrieves and scans the Packages.gz files, so that information about new and updated packages is available.\nupgrade is used to install the newest versions of all packages currently installed on the system from the sources enumerated in /etc/apt/sources.list. Packages currently installed with new versions available are retrieved and upgraded; under no circumstances are currently installed packages removed, or packages not already installed retrieved and installed. New versions of currently installed packages that cannot be upgraded without changing the install status of another package will be left at their current version.\nfull-upgrade (apt) and dist-upgrade (apt-get), in addition to performing the function of upgrade, also intelligently handles changing dependencies with new versions of packages; apt and apt-get have a \"smart\" conflict resolution system, and will attempt to upgrade the most important packages at the expense of less important ones if necessary. The /etc/apt/sources.list file contains a list of locations from which to retrieve desired package files. aptitude has a smarter dist-upgrade feature called full-upgrade.\n\n== Configuration and files ==\n/etc/apt contains the APT configuration folders and files.\napt-config is the APT Configuration Query program. apt-config dump shows the configuration.\n\n\n*** Files ***\n/etc/apt/sources.list: Locations to fetch packages from.\n/etc/apt/sources.list.d/: Additional source list fragments.\n/etc/apt/apt.conf: APT configuration file.\n/etc/apt/apt.conf.d/: APT configuration file fragments.\n/etc/apt/preferences.d/: Directory with version preferences files. This is where \"pinning\" is specified, i.e. a preference to get certain packages from a separate source or from a different version of a distribution.\n/var/cache/apt/archives/: Storage area for retrieved package files.\n/var/cache/apt/archives/partial/: Storage area for package files in transit.\n/var/lib/apt/lists/: Storage area for state information for each package resource specified in sources.list\n/var/lib/apt/lists/partial/: Storage area for state information in transit.\n\n== APT pinning ==\nThe APT pinning feature allows users to force APT to choose particular versions of packages which may be available in different versions from different repositories. This allows administrators to ensure that packages are not upgraded to versions which may conflict with other packages on the system, or that have not been sufficiently tested for unwelcome changes.\nIn order to do this, the pins in APT's preferences file (/etc/apt/preferences) must be modified, although graphical front-ends often make pinning simpler.\n\n== Front-ends ==\n\nSeveral other front-ends to APT exist, which provide more advanced installation functions and more intuitive interfaces. These include:\n\nSynaptic, a GTK graphical user interface\nUbuntu Software Center, a GTK graphical user interface developed by the Ubuntu project\naptitude, a console client with CLI and ncurses-based TUI interfaces\nKPackage, part of KDE\nAdept package manager, a graphical user interface for KDE (deb, rpm, bsd)\nPackageKit, a D-Bus frontend, maintained by freedesktop.org, powers GNOME Software and KDE Discover.\nGDebi, a GTK-based tool sponsored for Ubuntu. (There is also a Qt version, available in the Ubuntu repositories as gdebi-kde.)\napt-cdrom, a way to add a new CDROM to APT's list of available repositories (sources.lists). It is necessary to use apt-cdrom to add CDs to the APT system, it cannot be done by hand.\napt-zip, a way to use apt with removable media, specifically USB flash drives.\naptURL, an Ubuntu software package that enables end-user applications to install with a single-click through a browser.\nCydia, a package manager for jailbroken iOS based on APT (ported to iOS as part of the Telesphoreo project).\nSileo, like Cydia, a package manager for jailbroken iOS based on newer versions of APT (ported to iOS by the Electra team)\ngnome-apt, a GTK/GNOME-widget-based graphical front-end. Developed by Havoc Pennington\nMuon discover (previous Muon software center), a Qt-based graphical user interface\nHildon application manager (Maemo application), a Maemo front-end\napticron, a service designed to be run via cron to email notices of pending updates to a system administrator (sysadmin).\nAPT Daemon, a front-end that runs as a service to allow users to install software through PolicyKit and is in turn the framework used by Ubuntu software center (along with the Linux Mint software manager).\nPackage installer, part of MX Linux.[1]\nApt-offline: A convenient way to make any available non-containerized change to any Debian-type Linux installation without using a direct Internet connection. However, a temporary direct connection can be required, such as to install Apt-offline on some of the relevant types of Linux, and to add PPA's to the sources-list.APT front-ends can:\n\nsearch for new packages;\nupgrade packages;\ninstall or remove packages and\nupgrade the whole system to a new release.APT front-ends can list the dependencies of packages being installed or upgraded, ask the administrator if packages recommended or suggested by newly installed packages should be installed too, automatically install dependencies and perform other operations on the system such as removing obsolete files and packages.\n\n== Variants ==\nAPT was originally designed as a front-end for dpkg to work with Debian's .deb packages. A version of APT modified to also work with the RPM Package Manager system was released as APT-RPM. The Fink project has ported APT to Mac OS X for some of its own package management tasks, and APT is also available in OpenSolaris.\n\n== apt-file ==\napt-file is a command, packaged separately from APT, to find which package includes a specific file, or to list all files included in a package on remote repositories."
    }
  },
  {
    "instruction": "The uncontrolled port is used by the 802.1X PAE (Port Access Entity) to transmit and receive EAPOL frames.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the purpose of the uncontrolled port in IEEE 802.1X-2001?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the purpose of the uncontrolled port in IEEE 802.1X-2001?",
      "answer": "The uncontrolled port is used by the 802.1X PAE (Port Access Entity) to transmit and receive EAPOL frames."
    }
  },
  {
    "instruction": "Microsoft Forefront TMG improves network performance by compressing web traffic to improve communication speed. It also offers web caching, where it can cache frequently-accessed web content so that users can access them faster from the local network cache. Additionally, Microsoft Forefront TMG 2010 can cache data received through Background Intelligent Transfer Service, such as updates of software published on Microsoft Update website.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does Microsoft Forefront TMG improve network performance?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does Microsoft Forefront TMG improve network performance?",
      "answer": "Microsoft Forefront TMG improves network performance by compressing web traffic to improve communication speed. It also offers web caching, where it can cache frequently-accessed web content so that users can access them faster from the local network cache. Additionally, Microsoft Forefront TMG 2010 can cache data received through Background Intelligent Transfer Service, such as updates of software published on Microsoft Update website."
    }
  },
  {
    "instruction": "Gr\u00f8stl's MixColumns operation uses an 8\u00d78 matrix, while Rijndael's MixColumns operation uses a 4\u00d74 matrix.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does Gr\u00f8stl's MixColumns operation differ from Rijndael's MixColumns operation?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does Gr\u00f8stl's MixColumns operation differ from Rijndael's MixColumns operation?",
      "answer": "Gr\u00f8stl's MixColumns operation uses an 8\u00d78 matrix, while Rijndael's MixColumns operation uses a 4\u00d74 matrix."
    }
  },
  {
    "instruction": "PLATINUM (cybercrime group)\n\n==Introduction==\nPLATINUM is the name given by Microsoft to a cybercrime collective active against governments and related organizations in South and Southeast Asia. They are secretive and not much is known about the members of the group. The group's skill means that its attacks sometimes go without detection for many years.The group, considered an advanced persistent threat, has been active since at least 2009, targeting victims via spear-phishing attacks against government officials' private email addresses, zero-day exploits, and hot-patching vulnerabilities. Upon gaining access to their victims' computers, the group steals economically sensitive information.PLATINUM succeeded in keeping a low profile until their abuse of the Microsoft Windows hot patching system was detected and publicly reported in April 2016. This hot patching method allows them to use Microsoft's own features to quickly patch, alter files or update an application, without rebooting the system altogether, this way, they can maintain the data they have stolen while masking their identity.In June 2017, PLATINUM became notable for exploiting the serial over LAN (SOL) capabilities of Intel's Active Management Technology to perform data exfiltration.\n\n\n\n== PLATINUM's techniques ==\nPLATINUM has been known to exploit web plugins, at one point infiltrating the computers of several Indian government officials 2009, using a website that provided an email service.Once in control of a target's computer, PLATINUM actors can move through the target's network using specially built malware modules.  These have either been written by one of the multiple teams working under the Platinum group umbrella, or they could have been sold through any number of outside sources that Platinum has been dealing with since 2009.Because of the diversity of this malware, the versions of which have little code in common, Microsoft's investigators have taxonomised it into families.The piece of malware most widely used by PLATINUM was nicknamed Dispind by Microsoft. This piece of malware can install a keylogger, a piece of software that records (and may also be able to inject) keystrokes.PLATINUM also uses other malware like \"JPIN\" which installs itself into the %appdata% folder of a computer so that it can obtain information, load a keylogger, download files and updates, and perform other tasks like extracting files that could contain sensitive information.\"Adbupd\" is another malware program utilised by PLATINUM, and is similar to the two previously mentioned. It is known for its ability to support plugins, so it can be specialised, making it versatile enough to adapt to various protection mechanisms.\n\n\n*** Intel Exploit ***\nIn 2017, Microsoft reported that PLATINUM had begun to exploit a feature of Intel CPUs. The feature in question is Intel's AMT Serial-over-LAN (SOL), which allows a user to remotely control another computer, bypassing the host operating system of the target, including firewalls and monitoring tools within the host operating system.\n\n== Security ==\nMicrosoft advises users to apply all of their security updates to minimize vulnerabilities and to keep highly sensitive data out of large networks. Because PLATINUM targets organizations, companies and government branches to acquire trade secrets, anyone working in or with such organizations can be a target for the group.\n\nAnswer this question \"What is the function of the \"Adbupd\" malware?\" using the text above.",
    "context": "",
    "output": "The \"Adbupd\" malware is known for its ability to support plugins, so it can be specialised, making it versatile enough to adapt to various protection mechanisms.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the function of the \"Adbupd\" malware?",
      "answer": "The \"Adbupd\" malware is known for its ability to support plugins, so it can be specialised, making it versatile enough to adapt to various protection mechanisms.",
      "context": "PLATINUM (cybercrime group)\n\n==Introduction==\nPLATINUM is the name given by Microsoft to a cybercrime collective active against governments and related organizations in South and Southeast Asia. They are secretive and not much is known about the members of the group. The group's skill means that its attacks sometimes go without detection for many years.The group, considered an advanced persistent threat, has been active since at least 2009, targeting victims via spear-phishing attacks against government officials' private email addresses, zero-day exploits, and hot-patching vulnerabilities. Upon gaining access to their victims' computers, the group steals economically sensitive information.PLATINUM succeeded in keeping a low profile until their abuse of the Microsoft Windows hot patching system was detected and publicly reported in April 2016. This hot patching method allows them to use Microsoft's own features to quickly patch, alter files or update an application, without rebooting the system altogether, this way, they can maintain the data they have stolen while masking their identity.In June 2017, PLATINUM became notable for exploiting the serial over LAN (SOL) capabilities of Intel's Active Management Technology to perform data exfiltration.\n\n\n\n== PLATINUM's techniques ==\nPLATINUM has been known to exploit web plugins, at one point infiltrating the computers of several Indian government officials 2009, using a website that provided an email service.Once in control of a target's computer, PLATINUM actors can move through the target's network using specially built malware modules.  These have either been written by one of the multiple teams working under the Platinum group umbrella, or they could have been sold through any number of outside sources that Platinum has been dealing with since 2009.Because of the diversity of this malware, the versions of which have little code in common, Microsoft's investigators have taxonomised it into families.The piece of malware most widely used by PLATINUM was nicknamed Dispind by Microsoft. This piece of malware can install a keylogger, a piece of software that records (and may also be able to inject) keystrokes.PLATINUM also uses other malware like \"JPIN\" which installs itself into the %appdata% folder of a computer so that it can obtain information, load a keylogger, download files and updates, and perform other tasks like extracting files that could contain sensitive information.\"Adbupd\" is another malware program utilised by PLATINUM, and is similar to the two previously mentioned. It is known for its ability to support plugins, so it can be specialised, making it versatile enough to adapt to various protection mechanisms.\n\n\n*** Intel Exploit ***\nIn 2017, Microsoft reported that PLATINUM had begun to exploit a feature of Intel CPUs. The feature in question is Intel's AMT Serial-over-LAN (SOL), which allows a user to remotely control another computer, bypassing the host operating system of the target, including firewalls and monitoring tools within the host operating system.\n\n== Security ==\nMicrosoft advises users to apply all of their security updates to minimize vulnerabilities and to keep highly sensitive data out of large networks. Because PLATINUM targets organizations, companies and government branches to acquire trade secrets, anyone working in or with such organizations can be a target for the group."
    }
  },
  {
    "instruction": "Yes, FreeOTFE supports several ciphers including Serpent, Twofish, Camellia, and AES.\n\nWrite a question about the text above.",
    "context": "",
    "output": "Does FreeOTFE support any encryption algorithms other than AES?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "Does FreeOTFE support any encryption algorithms other than AES?",
      "answer": "Yes, FreeOTFE supports several ciphers including Serpent, Twofish, Camellia, and AES."
    }
  },
  {
    "instruction": "In a 2009 assessment, VBA32 Antivirus detected 26 percent of unknown malware, which is lower than the detection rate of Avira's Antivir Premium but higher than that of MicroWorld's eScan Anti-Virus.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does VBA32 Antivirus perform in detecting unknown malware compared to other antivirus software?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does VBA32 Antivirus perform in detecting unknown malware compared to other antivirus software?",
      "answer": "In a 2009 assessment, VBA32 Antivirus detected 26 percent of unknown malware, which is lower than the detection rate of Avira's Antivir Premium but higher than that of MicroWorld's eScan Anti-Virus."
    }
  },
  {
    "instruction": "GlobalSign's PKI services include a managed PKI platform, S/MIME certification, SSL certificates, and a cloud-based certificate manager. These services can scale based on the velocity, variety, and volume of IoT platforms, addressing authentication needs in the Internet of Everything (IoE) market and identity management as a cloud-based service.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What are some of GlobalSign's PKI services, and how do they cater to the Internet of Things (IoT) market?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What are some of GlobalSign's PKI services, and how do they cater to the Internet of Things (IoT) market?",
      "answer": "GlobalSign's PKI services include a managed PKI platform, S/MIME certification, SSL certificates, and a cloud-based certificate manager. These services can scale based on the velocity, variety, and volume of IoT platforms, addressing authentication needs in the Internet of Everything (IoE) market and identity management as a cloud-based service."
    }
  },
  {
    "instruction": "Knox Asset Intelligence helps organizations improve the management, productivity, and lifecycle of mobile devices. It allows IT admins to monitor device battery management, app usage insights, comprehensive device tracking, and detailed Wi-Fi analytics through a web console.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the purpose of Knox Asset Intelligence in Samsung Knox?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the purpose of Knox Asset Intelligence in Samsung Knox?",
      "answer": "Knox Asset Intelligence helps organizations improve the management, productivity, and lifecycle of mobile devices. It allows IT admins to monitor device battery management, app usage insights, comprehensive device tracking, and detailed Wi-Fi analytics through a web console."
    }
  },
  {
    "instruction": "The commercial \"MailChannels Outbound\" product from MailChannels implements a transparent proxy that inserts itself into the network between clients and servers, masquerading itself in such a way that the client and server believe they are talking directly to each other.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does the MailChannels Outbound product implement a transparent SMTP proxy?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does the MailChannels Outbound product implement a transparent SMTP proxy?",
      "answer": "The commercial \"MailChannels Outbound\" product from MailChannels implements a transparent proxy that inserts itself into the network between clients and servers, masquerading itself in such a way that the client and server believe they are talking directly to each other."
    }
  },
  {
    "instruction": "SAE helps mitigate the impact of weak passwords in WPA3-Personal mode by establishing a secure initial key exchange between devices, which helps protect the Wi-Fi network from unauthorized access even if the password is weak or easily guessable.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does SAE help mitigate the impact of weak passwords in WPA3-Personal mode?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does SAE help mitigate the impact of weak passwords in WPA3-Personal mode?",
      "answer": "SAE helps mitigate the impact of weak passwords in WPA3-Personal mode by establishing a secure initial key exchange between devices, which helps protect the Wi-Fi network from unauthorized access even if the password is weak or easily guessable."
    }
  },
  {
    "instruction": "Differential cryptanalysis is primarily applicable to block ciphers, but it can also be applied to stream ciphers and cryptographic hash functions.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is differential cryptanalysis primarily applicable to?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is differential cryptanalysis primarily applicable to?",
      "answer": "Differential cryptanalysis is primarily applicable to block ciphers, but it can also be applied to stream ciphers and cryptographic hash functions."
    }
  },
  {
    "instruction": "Virus hoaxes spread due to fear, curiosity, and the desire to warn others. However, they can also cause harm by spreading misinformation and causing unnecessary panic.\n\nWrite a question about the text above.",
    "context": "",
    "output": "Why do virus hoaxes spread, as seen in the \"Antichrist\" virus hoax email?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "Why do virus hoaxes spread, as seen in the \"Antichrist\" virus hoax email?",
      "answer": "Virus hoaxes spread due to fear, curiosity, and the desire to warn others. However, they can also cause harm by spreading misinformation and causing unnecessary panic."
    }
  },
  {
    "instruction": "Aggregate reports in DMARC are sent to the address specified following the rua tag. They provide an overview of messages that pass and/or fail DMARC checks, and are used to monitor the effectiveness of DMARC policies.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What are aggregate reports in DMARC, and how are they used?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What are aggregate reports in DMARC, and how are they used?",
      "answer": "Aggregate reports in DMARC are sent to the address specified following the rua tag. They provide an overview of messages that pass and/or fail DMARC checks, and are used to monitor the effectiveness of DMARC policies."
    }
  },
  {
    "instruction": "Cryptocat\n\n==Introduction==\nCryptocat is a discontinued open-source desktop application intended to allow encrypted online chatting available for Windows, OS X, and Linux.  It uses end-to-end encryption to secure all communications to other Cryptocat users. Users are given the option of independently verifying their buddies' device lists and are notified when a buddy's device list is modified and all updates are verified through the built-in update downloader.Cryptocat was created by Nadim Kobeissi and further developed along with a community of open source contributors and is published under the terms of the GPLv3 license, although it has since been discontinued.\n\n== Features ==\nCryptocat allows its users to set up end-to-end encrypted chat conversations. Users can exchange one-to-one messages, encrypted files, photos as well as create and share audio/video recordings. All devices linked to Cryptocat accounts will receive forward secure messages, even when offline.\nAll messages, files and audio/video recordings sent over Cryptocat are end-to-end encrypted. Cryptocat users link their devices to their Cryptocat account upon connection, and can identify each other's devices via the client's device manager in order to prevent man-in-the-middle attacks. Cryptocat also employs a Trust on first use mechanism in order to help detect device identity key changes.\nCryptocat also includes a built-in auto-update mechanism that automatically performs a signature check on downloaded updates in order to verify authenticity, and employs TLS certificate pinning in order to prevent network impersonation attacks.\nOriginally in 2013, Cryptocat offered the ability to connect to Facebook Messenger to initiate encrypted chatting with other Cryptocat users. According to the developers, the feature was meant to help offer an alternative to the regular Cryptocat chat model which did not offer long-term contact lists. This feature was disconnected in November 2015.\n\n== Reception and usage ==\nIn June 2013, Cryptocat was used by journalist Glenn Greenwald while in Hong Kong to meet NSA whistleblower Edward Snowden for the first time, after other encryption software failed to work.In November 2013, Cryptocat was banned in Iran, shortly after the election of Iran's new president Hassan Rouhani who had promised more open Internet laws.Cryptocat was listed on the Electronic Frontier Foundation's \"Secure Messaging Scorecard\" from 4 November 2014 until 13 March 2016. During that time, Cryptocat had a score of 7 out of 7 points on the scorecard. It had received points for having communications encrypted in transit, having communications encrypted with keys the provider did not have access to (end-to-end encryption), making it possible for users to independently verify their correspondent's identities, having past communications secure if the keys were stolen (forward secrecy), having its code open to independent review (open-source), having its security designs well-documented, and having completed an independent security audit.\n\n== Architecture ==\n\n\n*** Encryption ***\nCryptocat uses a Double Ratchet Algorithm in order to obtain forward and future secrecy across messages, after a session is established using a four-way Elliptic-curve Diffie\u2013Hellman handshake. The handshake mixes in long-term identity keys, an intermediate-term signed pre-key, and a one-time use pre-key. The approach is similar to the encryption protocol adopted for encrypted messaging by the Signal mobile application. Cryptocat's goal is for its messages to obtain confidentiality, integrity, source authenticity, forward and future secrecy and indistinguishability even over a network controlled by an active attacker. The forward secrecy features of the protocol that Cryptocat uses are similar to those first introduced by Off-the-Record Messaging.\nCryptocat uses the Advanced Encryption Standard in Galois/Counter Mode for authenticated encryption, Curve25519 for Elliptic curve Diffie-Hellman shared secret agreement, HMAC-SHA256 for key derivation and Ed25519 for signing. In order to limit the effect of a long-term identity key compromise, long-term keys are used exclusively once for the initial Authenticated Key Exchange, and once for signing a newly generated intermediate-term signed pre-key.\nFor the transport layer, Cryptocat adopts the OMEMO Multi-End Message and Object Encryption standard, which also gives Cryptocat multi-device support and allows for offline messaging.\n\n\n*** Network ***\nCryptocat's network relies on a XMPP configuration served over WebSockets. According to the project's mission statement, Cryptocat's network only relays encrypted messages and does not store any data. In addition to the Cryptocat client's end-to-end encryption protocol, client-server communication is protected by TLS.\n\n\n**** Distribution ****\nFrom March 2011 until March 2016, Cryptocat was officially distributed through the Google Chrome Web Store, the Apple App Store and other official channels controlled by targeted platforms. After Cryptocat's re-write into desktop software in March 2016, the software became distributed exclusively through Cryptocat's own servers, which also handle signed update delivery. Answer this question using the following article:\n\nHow does Cryptocat ensure forward secrecy in its encryption protocol?",
    "context": "",
    "output": "Cryptocat ensures forward secrecy in its encryption protocol by using the Double Ratchet Algorithm, which generates new keys for each message, making it impossible for an attacker to decrypt past messages even if they compromise the current key.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does Cryptocat ensure forward secrecy in its encryption protocol?",
      "answer": "Cryptocat ensures forward secrecy in its encryption protocol by using the Double Ratchet Algorithm, which generates new keys for each message, making it impossible for an attacker to decrypt past messages even if they compromise the current key.",
      "context": "Cryptocat\n\n==Introduction==\nCryptocat is a discontinued open-source desktop application intended to allow encrypted online chatting available for Windows, OS X, and Linux.  It uses end-to-end encryption to secure all communications to other Cryptocat users. Users are given the option of independently verifying their buddies' device lists and are notified when a buddy's device list is modified and all updates are verified through the built-in update downloader.Cryptocat was created by Nadim Kobeissi and further developed along with a community of open source contributors and is published under the terms of the GPLv3 license, although it has since been discontinued.\n\n== Features ==\nCryptocat allows its users to set up end-to-end encrypted chat conversations. Users can exchange one-to-one messages, encrypted files, photos as well as create and share audio/video recordings. All devices linked to Cryptocat accounts will receive forward secure messages, even when offline.\nAll messages, files and audio/video recordings sent over Cryptocat are end-to-end encrypted. Cryptocat users link their devices to their Cryptocat account upon connection, and can identify each other's devices via the client's device manager in order to prevent man-in-the-middle attacks. Cryptocat also employs a Trust on first use mechanism in order to help detect device identity key changes.\nCryptocat also includes a built-in auto-update mechanism that automatically performs a signature check on downloaded updates in order to verify authenticity, and employs TLS certificate pinning in order to prevent network impersonation attacks.\nOriginally in 2013, Cryptocat offered the ability to connect to Facebook Messenger to initiate encrypted chatting with other Cryptocat users. According to the developers, the feature was meant to help offer an alternative to the regular Cryptocat chat model which did not offer long-term contact lists. This feature was disconnected in November 2015.\n\n== Reception and usage ==\nIn June 2013, Cryptocat was used by journalist Glenn Greenwald while in Hong Kong to meet NSA whistleblower Edward Snowden for the first time, after other encryption software failed to work.In November 2013, Cryptocat was banned in Iran, shortly after the election of Iran's new president Hassan Rouhani who had promised more open Internet laws.Cryptocat was listed on the Electronic Frontier Foundation's \"Secure Messaging Scorecard\" from 4 November 2014 until 13 March 2016. During that time, Cryptocat had a score of 7 out of 7 points on the scorecard. It had received points for having communications encrypted in transit, having communications encrypted with keys the provider did not have access to (end-to-end encryption), making it possible for users to independently verify their correspondent's identities, having past communications secure if the keys were stolen (forward secrecy), having its code open to independent review (open-source), having its security designs well-documented, and having completed an independent security audit.\n\n== Architecture ==\n\n\n*** Encryption ***\nCryptocat uses a Double Ratchet Algorithm in order to obtain forward and future secrecy across messages, after a session is established using a four-way Elliptic-curve Diffie\u2013Hellman handshake. The handshake mixes in long-term identity keys, an intermediate-term signed pre-key, and a one-time use pre-key. The approach is similar to the encryption protocol adopted for encrypted messaging by the Signal mobile application. Cryptocat's goal is for its messages to obtain confidentiality, integrity, source authenticity, forward and future secrecy and indistinguishability even over a network controlled by an active attacker. The forward secrecy features of the protocol that Cryptocat uses are similar to those first introduced by Off-the-Record Messaging.\nCryptocat uses the Advanced Encryption Standard in Galois/Counter Mode for authenticated encryption, Curve25519 for Elliptic curve Diffie-Hellman shared secret agreement, HMAC-SHA256 for key derivation and Ed25519 for signing. In order to limit the effect of a long-term identity key compromise, long-term keys are used exclusively once for the initial Authenticated Key Exchange, and once for signing a newly generated intermediate-term signed pre-key.\nFor the transport layer, Cryptocat adopts the OMEMO Multi-End Message and Object Encryption standard, which also gives Cryptocat multi-device support and allows for offline messaging.\n\n\n*** Network ***\nCryptocat's network relies on a XMPP configuration served over WebSockets. According to the project's mission statement, Cryptocat's network only relays encrypted messages and does not store any data. In addition to the Cryptocat client's end-to-end encryption protocol, client-server communication is protected by TLS.\n\n\n**** Distribution ****\nFrom March 2011 until March 2016, Cryptocat was officially distributed through the Google Chrome Web Store, the Apple App Store and other official channels controlled by targeted platforms. After Cryptocat's re-write into desktop software in March 2016, the software became distributed exclusively through Cryptocat's own servers, which also handle signed update delivery."
    }
  },
  {
    "instruction": "When CLAS closed, CCP became the only CESG-approved credential that applied to individual professionals, so CLAS consultants had to obtain CCP status if they wanted to continue working in the IA and cybersecurity sector.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What happened to CLAS consultants when the CLAS scheme closed in 2016?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What happened to CLAS consultants when the CLAS scheme closed in 2016?",
      "answer": "When CLAS closed, CCP became the only CESG-approved credential that applied to individual professionals, so CLAS consultants had to obtain CCP status if they wanted to continue working in the IA and cybersecurity sector."
    }
  },
  {
    "instruction": "The Operations Enablement Directorate (OED) conducts expert technical and all-source analysis, integrates disparate and emerging technologies to enhance collaboration, interoperability, and the collective capabilities of DoD and Federal LE/CI, cybersecurity, and acquisition communities, and provides focused oversight and integration with the LE/CI and intelligence communities through liaison officers and embeds with various organizations.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What services does the Operations Enablement Directorate (OED) provide?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What services does the Operations Enablement Directorate (OED) provide?",
      "answer": "The Operations Enablement Directorate (OED) conducts expert technical and all-source analysis, integrates disparate and emerging technologies to enhance collaboration, interoperability, and the collective capabilities of DoD and Federal LE/CI, cybersecurity, and acquisition communities, and provides focused oversight and integration with the LE/CI and intelligence communities through liaison officers and embeds with various organizations."
    }
  },
  {
    "instruction": "Yes, F-Secure will detect any program they see that might be used for terrorist activity or to benefit organized crime, as stated in the Controversies section.\n\nWrite a question about the text above.",
    "context": "",
    "output": "Will F-Secure detect programs that might be used for terrorist activity or to benefit organized crime?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "Will F-Secure detect programs that might be used for terrorist activity or to benefit organized crime?",
      "answer": "Yes, F-Secure will detect any program they see that might be used for terrorist activity or to benefit organized crime, as stated in the Controversies section."
    }
  },
  {
    "instruction": "As of May 2011, Coreflood remains a threat and is still present on infected computers.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the current status of Coreflood in terms of its threat level?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the current status of Coreflood in terms of its threat level?",
      "answer": "As of May 2011, Coreflood remains a threat and is still present on infected computers."
    }
  },
  {
    "instruction": "In a CA-based PKI system, parties engaged in secure communication must trust a CA, i.e. place the CA certificates in a whitelist of trusted certificates. Developers of web browsers may use procedures specified by the CA/Browser Forum to whitelist well-known, public certificate authorities, while individual groups and companies may whitelist additional, private CA certificates.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How do CA-based PKI systems establish trust between parties?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How do CA-based PKI systems establish trust between parties?",
      "answer": "In a CA-based PKI system, parties engaged in secure communication must trust a CA, i.e. place the CA certificates in a whitelist of trusted certificates. Developers of web browsers may use procedures specified by the CA/Browser Forum to whitelist well-known, public certificate authorities, while individual groups and companies may whitelist additional, private CA certificates."
    }
  },
  {
    "instruction": "Context: Cryptology ePrint Archive\n\n==Introduction==\nThe Cryptology ePrint Archive is an electronic archive (eprint) of new results in the field of cryptography, maintained by the International Association for Cryptologic Research. It contains articles covering many of the most recent advances in cryptography, that did not necessarily undergo any refereeing process (yet).\n\n\nQuestion: How does the Cryptology ePrint Archive facilitate the dissemination of cryptography research, and what is its relationship with the International Association for Cryptologic Research?. Whats the answer?",
    "context": "",
    "output": "The Cryptology ePrint Archive is an electronic archive that serves as a platform for sharing new results in the field of cryptography. It is maintained by the International Association for Cryptologic Research (IACR), which is a well-established organization dedicated to cryptography research. The archive contains articles that cover many recent advances in cryptography, and while these articles may not have undergone a formal refereeing process, their association with the IACR lends them credibility and increases their visibility in the research community.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does the Cryptology ePrint Archive facilitate the dissemination of cryptography research, and what is its relationship with the International Association for Cryptologic Research?",
      "answer": "The Cryptology ePrint Archive is an electronic archive that serves as a platform for sharing new results in the field of cryptography. It is maintained by the International Association for Cryptologic Research (IACR), which is a well-established organization dedicated to cryptography research. The archive contains articles that cover many recent advances in cryptography, and while these articles may not have undergone a formal refereeing process, their association with the IACR lends them credibility and increases their visibility in the research community.",
      "context": "Cryptology ePrint Archive\n\n==Introduction==\nThe Cryptology ePrint Archive is an electronic archive (eprint) of new results in the field of cryptography, maintained by the International Association for Cryptologic Research. It contains articles covering many of the most recent advances in cryptography, that did not necessarily undergo any refereeing process (yet).\n\n"
    }
  },
  {
    "instruction": "SAE provides a more secure initial key exchange compared to the pre-shared key (PSK) exchange in WPA2 in scenarios where weak passwords are used or when devices have no display interface, as SAE helps mitigate security issues posed by weak passwords and simplifies the process of setting up devices with no display interface.\n\nWrite a question about the text above.",
    "context": "",
    "output": "In what scenarios does SAE provide a more secure initial key exchange compared to the pre-shared key (PSK) exchange in WPA2?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "In what scenarios does SAE provide a more secure initial key exchange compared to the pre-shared key (PSK) exchange in WPA2?",
      "answer": "SAE provides a more secure initial key exchange compared to the pre-shared key (PSK) exchange in WPA2 in scenarios where weak passwords are used or when devices have no display interface, as SAE helps mitigate security issues posed by weak passwords and simplifies the process of setting up devices with no display interface."
    }
  },
  {
    "instruction": "Singularity (software)\n\n==Introduction==\nSingularity is a free and open-source computer program that performs operating-system-level virtualization also known as containerization.One of the main uses of Singularity is to bring containers and reproducibility to scientific computing and the high-performance computing (HPC) world.The need for reproducibility requires the ability to use containers to move applications from system to system.Using Singularity containers, developers can work in reproducible environments of their choosing and design, and these complete environments can easily be copied and executed on other platforms.In 2021 the Singularity open source project split into two projects called Apptainer and SingularityCE.\n\n== Features ==\nSingularity is able to support natively high-performance interconnects, such as InfiniBand and Intel Omni-Path Architecture (OPA).Similar to the support for InfiniBand and Intel OPA devices, Singularity can support any PCIe-attached device within the compute node, such as graphic accelerators.Singularity also has native support for Open MPI library by utilizing a hybrid MPI container approach where OpenMPI exists both inside and outside the container.These features make Singularity increasingly useful in areas such as machine learning, deep learning and most data-intensive workloads where the applications benefit from the high bandwidth and low latency characteristics of these technologies.\n\n== Integration ==\nHPC systems traditionally already have resource management and job scheduling systems in place, so the container runtime environments must be integrated into the existing system resource manager.\nUsing other enterprise container solutions like Docker in HPC systems would require modifications to the software.\nDocker containers can be automatically converted to stand-alone singularity files which can then be submitted to HPC resource managers.Singularity seamlessly integrates with many resource managers including:\n\nHTCondor\nOracle Grid Engine (SGE)\nSLURM (Simple Linux Utility for Resource Management)\nTORQUE (Terascale Open-source Resource and QUEue Manager)\nPBS Pro (PBS Professional)\nHashiCorp Nomad (A simple and flexible workload orchestrator) Answer this question using the following article:\n\nHow does Singularity address the challenge of using containers in scientific computing and HPC environments?",
    "context": "",
    "output": "Singularity addresses this challenge by providing native support for high-performance interconnects, PCIe-attached devices, Open MPI library, and seamless integration with various resource managers, ensuring efficient resource utilization and reproducible environments in HPC and scientific computing environments.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does Singularity address the challenge of using containers in scientific computing and HPC environments?",
      "answer": "Singularity addresses this challenge by providing native support for high-performance interconnects, PCIe-attached devices, Open MPI library, and seamless integration with various resource managers, ensuring efficient resource utilization and reproducible environments in HPC and scientific computing environments.",
      "context": "Singularity (software)\n\n==Introduction==\nSingularity is a free and open-source computer program that performs operating-system-level virtualization also known as containerization.One of the main uses of Singularity is to bring containers and reproducibility to scientific computing and the high-performance computing (HPC) world.The need for reproducibility requires the ability to use containers to move applications from system to system.Using Singularity containers, developers can work in reproducible environments of their choosing and design, and these complete environments can easily be copied and executed on other platforms.In 2021 the Singularity open source project split into two projects called Apptainer and SingularityCE.\n\n== Features ==\nSingularity is able to support natively high-performance interconnects, such as InfiniBand and Intel Omni-Path Architecture (OPA).Similar to the support for InfiniBand and Intel OPA devices, Singularity can support any PCIe-attached device within the compute node, such as graphic accelerators.Singularity also has native support for Open MPI library by utilizing a hybrid MPI container approach where OpenMPI exists both inside and outside the container.These features make Singularity increasingly useful in areas such as machine learning, deep learning and most data-intensive workloads where the applications benefit from the high bandwidth and low latency characteristics of these technologies.\n\n== Integration ==\nHPC systems traditionally already have resource management and job scheduling systems in place, so the container runtime environments must be integrated into the existing system resource manager.\nUsing other enterprise container solutions like Docker in HPC systems would require modifications to the software.\nDocker containers can be automatically converted to stand-alone singularity files which can then be submitted to HPC resource managers.Singularity seamlessly integrates with many resource managers including:\n\nHTCondor\nOracle Grid Engine (SGE)\nSLURM (Simple Linux Utility for Resource Management)\nTORQUE (Terascale Open-source Resource and QUEue Manager)\nPBS Pro (PBS Professional)\nHashiCorp Nomad (A simple and flexible workload orchestrator)"
    }
  },
  {
    "instruction": "Implementations of differentially private analyses\n\n==Introduction==\nSince the advent of differential privacy, a number of systems supporting differentially private data analyses have been implemented and deployed. This article tracks real-world deployments, production software packages, and research prototypes.\n\n\n\n== Real-world deployments ==\n\n== Production software packages ==\nThese software packages purport to be usable in production systems. They are split in two categories: those focused on answering statistical queries with differential privacy, and those focused on training machine learning models with differential privacy.\n\n\n*** Statistical analyses ***\n\n\n*** Machine learning ***\n\n== Research projects and prototypes ==\n\n== Attacks on implementations ==\nIn addition to standard defects of software artifacts that can be identified using testing or fuzzing, implementations of differentially private mechanisms may suffer from the following vulnerabilities:\n\nSubtle algorithmic or analytical mistakes.Timing side-channel attacks. In contrast with timing attacks against implementations of cryptographic algorithms that typically have low leakage rate and must be followed with non-trivial cryptanalysis, a timing channel may lead to a catastrophic compromise of a differentially private system, since a targeted attack can be used to exfiltrate the very bit that the system is designed to hide.Leakage through floating-point arithmetic. Differentially private algorithms are typically presented in the language of probability distributions, which most naturally lead to implementations using floating-point arithmetic. The abstraction of floating-point arithmetic is leaky, and without careful attention to details, a naive implementation may fail to provide differential privacy. (This is particularly the case for \u03b5-differential privacy, which does not allow any probability of failure, even in the worst case.) For example, the support of a textbook sampler of the Laplace distribution (required, for instance, for the Laplace mechanism) is less than 80% of all double-precision floating point numbers; moreover, the support for distributions with different means are not identical. A single sample from a na\u00efve implementation of the Laplace mechanism allows distinguishing between two adjacent datasets with probability more than 35%.Timing channel through floating-point arithmetic. Unlike operations over integers that are typically constant-time on modern CPUs, floating-point arithmetic exhibits significant input-dependent timing variability. Handling of subnormals can be particularly slow, as much as by \u00d7100 compared to the typical case.\n\nAnswer this question \"What is the primary concern with using floating-point arithmetic in implementations of differentially private algorithms?\" using the text above.",
    "context": "",
    "output": "The primary concern with using floating-point arithmetic in implementations of differentially private algorithms is that it can lead to leakage of sensitive information. The abstraction of floating-point arithmetic is leaky, and without careful attention to details, a naive implementation may fail to provide differential privacy.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the primary concern with using floating-point arithmetic in implementations of differentially private algorithms?",
      "answer": "The primary concern with using floating-point arithmetic in implementations of differentially private algorithms is that it can lead to leakage of sensitive information. The abstraction of floating-point arithmetic is leaky, and without careful attention to details, a naive implementation may fail to provide differential privacy.",
      "context": "Implementations of differentially private analyses\n\n==Introduction==\nSince the advent of differential privacy, a number of systems supporting differentially private data analyses have been implemented and deployed. This article tracks real-world deployments, production software packages, and research prototypes.\n\n\n\n== Real-world deployments ==\n\n== Production software packages ==\nThese software packages purport to be usable in production systems. They are split in two categories: those focused on answering statistical queries with differential privacy, and those focused on training machine learning models with differential privacy.\n\n\n*** Statistical analyses ***\n\n\n*** Machine learning ***\n\n== Research projects and prototypes ==\n\n== Attacks on implementations ==\nIn addition to standard defects of software artifacts that can be identified using testing or fuzzing, implementations of differentially private mechanisms may suffer from the following vulnerabilities:\n\nSubtle algorithmic or analytical mistakes.Timing side-channel attacks. In contrast with timing attacks against implementations of cryptographic algorithms that typically have low leakage rate and must be followed with non-trivial cryptanalysis, a timing channel may lead to a catastrophic compromise of a differentially private system, since a targeted attack can be used to exfiltrate the very bit that the system is designed to hide.Leakage through floating-point arithmetic. Differentially private algorithms are typically presented in the language of probability distributions, which most naturally lead to implementations using floating-point arithmetic. The abstraction of floating-point arithmetic is leaky, and without careful attention to details, a naive implementation may fail to provide differential privacy. (This is particularly the case for \u03b5-differential privacy, which does not allow any probability of failure, even in the worst case.) For example, the support of a textbook sampler of the Laplace distribution (required, for instance, for the Laplace mechanism) is less than 80% of all double-precision floating point numbers; moreover, the support for distributions with different means are not identical. A single sample from a na\u00efve implementation of the Laplace mechanism allows distinguishing between two adjacent datasets with probability more than 35%.Timing channel through floating-point arithmetic. Unlike operations over integers that are typically constant-time on modern CPUs, floating-point arithmetic exhibits significant input-dependent timing variability. Handling of subnormals can be particularly slow, as much as by \u00d7100 compared to the typical case."
    }
  },
  {
    "instruction": "Application-level encryption is the process of encrypting data by the application that has been used to generate or modify the data that is to be encrypted, before it is written to the database. This allows for the encryption process to be tailored to each user based on their information.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is application-level encryption and how does it work?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is application-level encryption and how does it work?",
      "answer": "Application-level encryption is the process of encrypting data by the application that has been used to generate or modify the data that is to be encrypted, before it is written to the database. This allows for the encryption process to be tailored to each user based on their information."
    }
  },
  {
    "instruction": "Most countermeasures against DFA are based on error detection schemes.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What are most countermeasures against DFA based on?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What are most countermeasures against DFA based on?",
      "answer": "Most countermeasures against DFA are based on error detection schemes."
    }
  },
  {
    "instruction": "HP Enterprise sold TippingPoint to Trend Micro for approximately $300 million.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What company did HP Enterprise sell TippingPoint to and for how much?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What company did HP Enterprise sell TippingPoint to and for how much?",
      "answer": "HP Enterprise sold TippingPoint to Trend Micro for approximately $300 million."
    }
  },
  {
    "instruction": "Resilience can be classified into proactive resilience, which focuses on preparing for a crisis and creating a solid foundation for the company, and post resilience, which includes continuing to maintain communication and check in with employees after an incident has happened.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How is resilience classified in terms of time and scale?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How is resilience classified in terms of time and scale?",
      "answer": "Resilience can be classified into proactive resilience, which focuses on preparing for a crisis and creating a solid foundation for the company, and post resilience, which includes continuing to maintain communication and check in with employees after an incident has happened."
    }
  },
  {
    "instruction": "Context: IT risk\n\n==Introduction==\nInformation technology risk, IT risk, IT-related risk, or cyber risk is any risk relating to information technology. While information has long been appreciated as a valuable and important asset, the rise of the knowledge economy and the Digital Revolution has led to organizations becoming increasingly dependent on information, information processing and especially IT.  Various events or incidents that compromise IT in some way can therefore cause adverse impacts on the organization's business processes or mission, ranging from inconsequential to catastrophic in scale.\nAssessing the probability or likelihood of various types of event/incident with their predicted impacts or consequences, should they occur, is a common way to assess and measure IT risks.  Alternative methods of measuring IT risk typically involve assessing other contributory factors such as the threats, vulnerabilities, exposures, and asset values.\n\n\n\n== Definitions ==\n\n\n*** ISO ***\nIT risk: the potential that a given threat will exploit vulnerabilities of an asset or group of assets and thereby cause harm to the organization. It is measured in terms of a combination of the probability of occurrence of an event and its consequence.\n\n\n*** Committee on National Security Systems ***\nThe Committee on National Security Systems of United States of America defined risk in different documents:\n\nFrom CNSS Instruction No. 4009 dated 26 April 2010 the basic and more technical focused definition:\nRisk \u2013 Possibility that a particular threat will adversely impact an IS by exploiting a particular vulnerability.\nNational Security Telecommunications and Information Systems Security Instruction (NSTISSI) No. 1000, introduces a probability aspect, quite similar to NIST SP 800-30 one:\nRisk \u2013 A combination of the likelihood that a threat will occur, the likelihood that a threat occurrence will result in an adverse impact, and the severity of the resulting impactNational Information Assurance Training and Education Center defines risk in the IT field as:\nThe loss potential that exists as the result of threat-vulnerability pairs. Reducing either the threat or the vulnerability reduces the risk.\nThe uncertainty of loss expressed in terms of probability of such loss.\nThe probability that a hostile entity will successfully exploit a particular telecommunications or COMSEC system for intelligence purposes; its factors are threat and vulnerability.\nA combination of the likelihood that a threat shall occur, the likelihood that a threat occurrence shall result in an adverse impact, and the severity of the resulting adverse impact.\nthe probability that a particular threat will exploit a particular vulnerability of the system.\n\n\n*** NIST ***\nMany NIST publications define risk in IT context in different publications: FISMApedia term provide a list. Between them:\n\nAccording to NIST SP 800-30:Risk is a function of the likelihood of a given threat-source\u2019s exercising a particular potential vulnerability, and the resulting impact of that adverse event on the organization.\nFrom NIST FIPS 200Risk \u2013 The level of impact on organizational operations (including mission, functions, image, or reputation), organizational assets, or individuals resulting from the operation of an information system given the potential impact of a threat and the likelihood of that threat occurring.NIST SP 800-30 defines:\n\nIT-related risk\n\nThe net mission impact considering:\nthe probability that a particular threat-source will exercise (accidentally trigger or intentionally exploit) a particular information system vulnerability and\nthe resulting impact if this should occur. IT-related risks arise from legal liability or mission loss due to:\nUnauthorized (malicious or accidental) disclosure, modification, or destruction of information\nUnintentional errors and omissions\nIT disruptions due to natural or man-made disasters\nFailure to exercise due care and diligence in the implementation and operation of the IT system.\n\n\n*** Risk management insight ***\nIT risk is the probable frequency and probable magnitude of future loss.\n\n\n*** ISACA ***\nISACA published the Risk IT Framework in order to provide an end-to-end, comprehensive view of all risks related to the use of IT. There, IT risk is defined as:\n\nThe business risk associated with the use, ownership, operation, involvement, influence and adoption of IT within an enterpriseAccording to Risk IT, IT risk has a broader meaning: it encompasses not just only the negative impact of operations and service delivery which can bring destruction or reduction of the value of the organization, but also the benefit\\value enabling risk associated to missing opportunities to use technology to enable or enhance business or the IT project management for aspects like overspending or late delivery with adverse business impact\n\n== Measuring IT risk ==\nYou can't effectively and consistently manage what you can't measure, and you can't measure what you haven't defined.Measuring IT risk (or cyber risk) can occur at many levels. At a business level, the risks are managed categorically. Front line IT departments and NOC's tend to measure more discrete, individual risks. Managing the nexus between them is a key role for modern CISO's.\n\nWhen measuring risk of any kind, selecting the correct equation for a given threat, asset, and available data is an important step. Doing so is subject unto itself, but there are common components of risk equations that are helpful to understand. There are four fundamental forces involved in risk management, which also apply to cybersecurity. They are assets, impact, threats, and likelihood. You have internal knowledge of and a fair amount of control over assets, which are tangible and intangible things that have value. You also have some control over impact, which refers to loss of, or damage to, an asset. However, threats that represent adversaries and their methods of attack are external to your control. Likelihood is the wild card in the bunch. Likelihoods determine if and when a threat will materialize, succeed, and do damage. While never fully under your control, likelihoods can be shaped and influenced to manage the risk.\nMathematically, the forces can be represented in a formula such as: \n  \n    \n      \n        R\n        i\n        s\n        k\n\n== IT risk management ==\n\nIT risk management can be considered a component of a wider enterprise risk management system.The establishment, maintenance and continuous update of an information security management system (ISMS) provide a strong indication that a company is using a systematic approach for the identification, assessment and management of information security risks.Different methodologies have been proposed to manage IT risks, each of them divided into processes and steps.The Certified Information Systems Auditor Review Manual 2006 produced by ISACA, an international professional association focused on IT Governance, provides the following definition of risk management: \"Risk management is the process of identifying vulnerabilities and threats to the information resources used by an organization in achieving business objectives, and deciding what countermeasures, if any, to take in reducing risk to an acceptable level, based on the value of the information resource to the organization.\"The NIST Cybersecurity Framework encourages organizations to manage IT risk as part the Identify (ID) function:Risk Assessment (ID.RA): The organization understands the cybersecurity risk to organizational operations (including mission, functions, image, or reputation), organizational assets, and individuals.\n\nID.RA-1: Asset vulnerabilities are identified and documented\nID.RA-2: Cyber threat intelligence and vulnerability information is received from information sharing forums and source\nID.RA-3: Threats, both internal and external, are identified and documented\nID.RA-4: Potential business impacts and likelihoods are identified\nID.RA-5: Threats, vulnerabilities, likelihoods, and impacts are used to determine risk\nID.RA-6: Risk responses are identified and prioritizedRisk Management Strategy (ID.RM): The organization\u2019s priorities, constraints, risk tolerances, and assumptions are established and used to support operational risk decisions. \n\nID.RM-1: Risk management processes are established, managed, and agreed to by organizational stakeholders\nID.RM-2: Organizational risk tolerance is determined and clearly expressed\nID.RM-3: The organization\u2019s determination of risk tolerance is informed by its role in critical infrastructure and sector specific risk analysis\n\n== IT risk laws and regulations ==\nIn the following a brief description of applicable rules organized by source.\n\n\n*** OECD ***\nOECD issued the following:\n\nOrganisation for Economic Co-operation and Development (OECD) Recommendation of the Council concerning guidelines governing the protection of privacy and trans-border flows of personal data (23 September 1980)\nOECD Guidelines for the Security of Information Systems and Networks: Towards a Culture of Security (25 July 2002). Topic: General information security. Scope: Non binding guidelines to any OECD entities (governments, businesses, other organisations and individual users who develop, own, provide, manage, service, and use information systems and networks). The OECD Guidelines state the basic principles underpinning risk management and information security practices. While no part of the text is binding as such, non-compliance with any of the principles is indicative of a serious breach of RM/RA good practices that can potentially incur liability.\n\n\n*** European Union ***\nThe European Union issued the following, divided by topic:\n\nPrivacy\nRegulation (EC) No 45/2001 on the protection of individuals with regard to the processing of personal data by the Community institutions and bodies and on the free movement of such data provide an internal regulation, which is a practical application of the principles of the Privacy Directive described below. Furthermore, article 35 of the Regulation requires the Community institutions and bodies to take similar precautions with regard to their telecommunications infrastructure, and to properly inform the users of any specific risks of security breaches.\nDirective 95/46/EC on the protection of individuals with regard to the processing of personal data and on the free movement of such data require that any personal data processing activity undergoes a prior risk analysis in order to determine the privacy implications of the activity, and to determine the appropriate legal, technical and organisation measures to protect such activities;is effectively protected by such measures, which must be state of the art keeping into account the sensitivity and privacy implications of the activity (including when a third party is charged with the processing task) is notified to a national data protection authority, including the measures taken to ensure the security of the activity. Furthermore, article 25 and following of the Directive requires Member States to ban the transfer of personal data to non-Member States, unless such countries have provided adequate legal protection for such personal data, or barring certain other exceptions.\nCommission Decision 2001/497/EC of 15 June 2001 on standard contractual clauses for the transfer of personal data to third countries, under Directive 95/46/EC; and Commission Decision 2004/915/EC of 27 December 2004 amending Decision 2001/497/EC as regards the introduction of an alternative set of standard contractual clauses for the transfer of personal data to third countries. Topic: Export of personal data to third countries, specifically non-E.U. countries which have not been recognised as having a data protection level that is adequate (i.e. equivalent to that of the E.U.). Both Commission Decisions provide a set of voluntary model clauses which can be used to export personal data from a data controller (who is subject to E.U. data protection rules) to a data processor outside the E.U. who is not subject to these rules or to a similar set of adequate rules.\nInternational Safe Harbor Privacy Principles (see below USA and International Safe Harbor Privacy Principles )\nDirective 2002/58/EC of 12 July 2002 concerning the processing of personal data and the protection of privacy in the electronic communications sector\nNational Security\nDirective 2006/24/EC of 15 March 2006 on the retention of data generated or processed in connection with the provision of publicly available electronic communications services or of public communications networks and amending Directive 2002/58/EC (\u2018Data Retention Directive\u2019). Topic: Requirement for the providers of public electronic telecommunications service providers to retain certain information for the purposes of the investigation, detection and prosecution of serious crime\nCouncil Directive 2008/114/EC of 8 December 2008 on the identification and designation of European critical infrastructures and the assessment of the need to improve their protection. Topic: Identification and protection of European Critical Infrastructures. Scope: Applicable to Member States and to the operators of European Critical Infrastructure (defined by the draft directive as \u2018critical infrastructures the disruption or destruction of which would significantly affect two or more Member States, or a single Member State if the critical infrastructure is located in another Member State. This includes effects resulting from cross-sector dependencies on other types of infrastructure\u2019). Requires Member States to identify critical infrastructures on their territories, and to designate them as ECIs. Following this designation, the owners/operators of ECIs are required to create Operator Security Plans (OSPs), which should establish relevant security solutions for their protection\nCivil and Penal law\nCouncil Framework Decision 2005/222/JHA of 24 February 2005 on attacks against information systems. Topic: General decision aiming to harmonise national provisions in the field of cyber crime, encompassing material criminal law (i.e. definitions of specific crimes), procedural criminal law (including investigative measures and international cooperation) and liability issues. Scope: Requires Member States to implement the provisions of the Framework Decision in their national legal frameworks. Framework decision is relevant to RM/RA because it contains the conditions under which legal liability can be imposed on legal entities for conduct of certain natural persons of authority within the legal entity. Thus, the Framework decision requires that the conduct of such figures within an organisation is adequately monitored, also because the Decision states that a legal entity can be held liable for acts of omission in this regard.\n\n\n*** Council of Europe ***\nCouncil of Europe Convention on Cybercrime, Budapest, 23.XI.2001, European Treaty Series-No. 185. Topic: General treaty aiming to harmonise national provisions in the field of cyber crime, encompassing material criminal law (i.e. definitions of specific crimes), procedural criminal law (including investigative measures and international cooperation), liability issues and data retention. Apart from the definitions of a series of criminal offences in articles 2 to 10, the Convention is relevant to RM/RA because it states the conditions under which legal liability can be imposed on legal entities for conduct of certain natural persons of authority within the legal entity. Thus, the Convention requires that the conduct of such figures within an organisation is adequately monitored, also because the Convention states that a legal entity can be held liable for acts of omission in this regard.\n\n\n*** United States ***\nUnited States issued the following, divided by topic:\n\nCivil and Penal law\nAmendments to the Federal Rules of Civil Procedure with regard to electronic discovery. Topic: U.S. Federal rules with regard to the production of electronic documents in civil proceedings. The discovery rules allow a party in civil proceedings to demand that the opposing party produce all relevant documentation (to be defined by the requesting party) in its possession, so as to allow the parties and the court to correctly assess the matter. Through the e-discovery amendment, which entered into force on 1 December 2006, such information may now include electronic information. This implies that any party being brought before a U.S. court in civil proceedings can be asked to produce such documents, which includes finalised reports, working documents, internal memos and e-mails with regard to a specific subject, which may or may not be specifically delineated. Any party whose activities imply a risk of being involved in such proceedings must therefore take adequate precautions for the management of such information, including the secure storage. Specifically: The party must be capable of initiating a \u2018litigation hold\u2019, a technical/organisational measure which must ensure that no relevant information can be modified any longer in any way. Storage policies must be responsible: while deletion of specific information of course remains allowed when this is a part of general information management policies (\u2018routine, good-faith operation of the information system\u2019, Rule 37 (f)), the wilful destruction of potentially relevant information can be punished by extremely high fines (in one specific case of 1.6 billion US$). Thus, in practice, any businesses who risk civil litigation before U.S. courts must implement adequate information management policies, and must implement the necessary measures to initiate a litigation hold.\nPrivacy\nCalifornia Consumer Privacy Act (CCPA)\nCalifornia Privacy Rights Act (CPRA)\nGramm\u2013Leach\u2013Bliley Act (GLBA)\nUSA PATRIOT Act, Title III\nHealth Insurance Portability and Accountability Act (HIPAA) From an RM/RA perspective, the Act is particularly known for its provisions with regard to Administrative Simplification (Title II of HIPAA). This title required the U.S. Department of Health and Human Services (HHS) to draft specific rule sets, each of which would provide specific standards which would improve the efficiency of the health care system and prevent abuse. As a result, the HHS has adopted five principal rules: the Privacy Rule, the Transactions and Code Sets Rule, the Unique Identifiers Rule, the Enforcement Rule, and the Security Rule. The latter, published in the Federal Register on 20 February 2003 (see: http://www.cms.hhs.gov/SecurityStandard/Downloads/securityfinalrule.pdf), is specifically relevant, as it specifies a series of administrative, technical, and physical security procedures to assure the confidentiality of electronic protected health information. These aspects have been further outlined in a set of Security Standards on Administrative, Physical, Organisational and Technical Safeguards, all of which have been published, along with a guidance document on the basics of HIPAA risk management and risk assessment <http://www.cms.hhs.gov/EducationMaterials/04_SecurityMaterials.asp>. European or other countries health care service providers will generally not be affected by HIPAA obligations if they are not active on the U.S. market. However, since their data processing activities are subject to similar obligations under general European law (including the Privacy Directive), and since the underlying trends of modernisation and evolution towards electronic health files are the same, the HHS safeguards can be useful as an initial yardstick for measuring RM/RA strategies put in place by European health care service providers, specifically with regard to the processing of electronic health information. HIPAA security standards include the following:\nAdministrative safeguards:\nSecurity Management Process\nAssigned Security Responsibility\nWorkforce Security\nInformation Access Management\nSecurity Awareness and Training\nSecurity Incident Procedures\nContingency Plan\nEvaluation\nBusiness Associate Contracts and Other Arrangements\nPhysical safeguards\nFacility Access Controls\nWorkstation Use\nWorkstation Security\nDevice and Media Controls\nTechnical safeguards\nAccess Control\nAudit Controls\nIntegrity\nPerson or Entity Authentication\nTransmission Security\nOrganisational requirements\nBusiness Associate Contracts & Other Arrangements\nRequirements for Group Health Plans\nInternational Safe Harbor Privacy Principles issued by the US Department of Commerce on July 21, 2000 Export of personal data from a data controller who is subject to E.U. privacy regulations to a U.S. based destination; before personal data may be exported from an entity subject to E.U. privacy regulations to a destination subject to U.S. law, the European entity must ensure that the receiving entity provides adequate safeguards to protect such data against a number of mishaps. One way of complying with this obligation is to require the receiving entity to join the Safe Harbor, by requiring that the entity self-certifies its compliance with the so-called Safe Harbor Principles. If this road is chosen, the data controller exporting the data must verify that the U.S. destination is indeed on the Safe Harbor list (see safe harbor list)\nThe United States Department of Homeland Security also utilizes Privacy Impact Assessment (PIA) as a decision making tool to identify and mitigate risks of privacy violations.\nSarbanes\u2013Oxley Act\nFISMA\nAs legislation evolves, there has been increased focus to require 'reasonable security' for information management. CCPA states that \"manufacturers of connected devices to equip the device with reasonable security.\" New York's SHIELD Act requires that organizations that manage NY residents' information \u201cdevelop, implement and maintain reasonable safeguards to protect the security, confidentiality and integrity of the private information including, but not limited to, disposal of data.\u201d This concept will influence how businesses manage their risk management plan as compliance requirements develop.\n\n== Standards organizations and standards ==\nInternational standard bodies:\nInternational Organization for Standardization \u2013 ISO\nPayment Card Industry Security Standards Council\nInformation Security Forum\nThe Open Group\nUnited States standard bodies:\nNational Institute of Standards and Technology \u2013 NIST\nFederal Information Processing Standards \u2013 FIPS by NIST devoted to Federal Government and Agencies\nUK standard bodies\nBritish Standard Institute\n\n\n*** Short description of standards ***\nThe list is chiefly based on:\n\n\n**** ISO ****\nISO/IEC 13335-1:2004 \u2013 Information technology\u2014Security techniques\u2014Management of information and communications technology security\u2014Part 1: Concepts and models for information and communications technology security management http://www.iso.org/iso/en/CatalogueDetailPage.CatalogueDetail?CSNUMBER\nQuestion: How does the Council of Europe define cybercrime in the Convention on Cybercrime?. Whats the answer?",
    "context": "",
    "output": "The Convention on Cybercrime defines cybercrime as a series of criminal offences in articles 2 to 10, and states the conditions under which legal liability can be imposed on legal entities for conduct of certain natural persons of authority within the legal entity.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does the Council of Europe define cybercrime in the Convention on Cybercrime?",
      "answer": "The Convention on Cybercrime defines cybercrime as a series of criminal offences in articles 2 to 10, and states the conditions under which legal liability can be imposed on legal entities for conduct of certain natural persons of authority within the legal entity.",
      "context": "IT risk\n\n==Introduction==\nInformation technology risk, IT risk, IT-related risk, or cyber risk is any risk relating to information technology. While information has long been appreciated as a valuable and important asset, the rise of the knowledge economy and the Digital Revolution has led to organizations becoming increasingly dependent on information, information processing and especially IT.  Various events or incidents that compromise IT in some way can therefore cause adverse impacts on the organization's business processes or mission, ranging from inconsequential to catastrophic in scale.\nAssessing the probability or likelihood of various types of event/incident with their predicted impacts or consequences, should they occur, is a common way to assess and measure IT risks.  Alternative methods of measuring IT risk typically involve assessing other contributory factors such as the threats, vulnerabilities, exposures, and asset values.\n\n\n\n== Definitions ==\n\n\n*** ISO ***\nIT risk: the potential that a given threat will exploit vulnerabilities of an asset or group of assets and thereby cause harm to the organization. It is measured in terms of a combination of the probability of occurrence of an event and its consequence.\n\n\n*** Committee on National Security Systems ***\nThe Committee on National Security Systems of United States of America defined risk in different documents:\n\nFrom CNSS Instruction No. 4009 dated 26 April 2010 the basic and more technical focused definition:\nRisk \u2013 Possibility that a particular threat will adversely impact an IS by exploiting a particular vulnerability.\nNational Security Telecommunications and Information Systems Security Instruction (NSTISSI) No. 1000, introduces a probability aspect, quite similar to NIST SP 800-30 one:\nRisk \u2013 A combination of the likelihood that a threat will occur, the likelihood that a threat occurrence will result in an adverse impact, and the severity of the resulting impactNational Information Assurance Training and Education Center defines risk in the IT field as:\nThe loss potential that exists as the result of threat-vulnerability pairs. Reducing either the threat or the vulnerability reduces the risk.\nThe uncertainty of loss expressed in terms of probability of such loss.\nThe probability that a hostile entity will successfully exploit a particular telecommunications or COMSEC system for intelligence purposes; its factors are threat and vulnerability.\nA combination of the likelihood that a threat shall occur, the likelihood that a threat occurrence shall result in an adverse impact, and the severity of the resulting adverse impact.\nthe probability that a particular threat will exploit a particular vulnerability of the system.\n\n\n*** NIST ***\nMany NIST publications define risk in IT context in different publications: FISMApedia term provide a list. Between them:\n\nAccording to NIST SP 800-30:Risk is a function of the likelihood of a given threat-source\u2019s exercising a particular potential vulnerability, and the resulting impact of that adverse event on the organization.\nFrom NIST FIPS 200Risk \u2013 The level of impact on organizational operations (including mission, functions, image, or reputation), organizational assets, or individuals resulting from the operation of an information system given the potential impact of a threat and the likelihood of that threat occurring.NIST SP 800-30 defines:\n\nIT-related risk\n\nThe net mission impact considering:\nthe probability that a particular threat-source will exercise (accidentally trigger or intentionally exploit) a particular information system vulnerability and\nthe resulting impact if this should occur. IT-related risks arise from legal liability or mission loss due to:\nUnauthorized (malicious or accidental) disclosure, modification, or destruction of information\nUnintentional errors and omissions\nIT disruptions due to natural or man-made disasters\nFailure to exercise due care and diligence in the implementation and operation of the IT system.\n\n\n*** Risk management insight ***\nIT risk is the probable frequency and probable magnitude of future loss.\n\n\n*** ISACA ***\nISACA published the Risk IT Framework in order to provide an end-to-end, comprehensive view of all risks related to the use of IT. There, IT risk is defined as:\n\nThe business risk associated with the use, ownership, operation, involvement, influence and adoption of IT within an enterpriseAccording to Risk IT, IT risk has a broader meaning: it encompasses not just only the negative impact of operations and service delivery which can bring destruction or reduction of the value of the organization, but also the benefit\\value enabling risk associated to missing opportunities to use technology to enable or enhance business or the IT project management for aspects like overspending or late delivery with adverse business impact\n\n== Measuring IT risk ==\nYou can't effectively and consistently manage what you can't measure, and you can't measure what you haven't defined.Measuring IT risk (or cyber risk) can occur at many levels. At a business level, the risks are managed categorically. Front line IT departments and NOC's tend to measure more discrete, individual risks. Managing the nexus between them is a key role for modern CISO's.\n\nWhen measuring risk of any kind, selecting the correct equation for a given threat, asset, and available data is an important step. Doing so is subject unto itself, but there are common components of risk equations that are helpful to understand. There are four fundamental forces involved in risk management, which also apply to cybersecurity. They are assets, impact, threats, and likelihood. You have internal knowledge of and a fair amount of control over assets, which are tangible and intangible things that have value. You also have some control over impact, which refers to loss of, or damage to, an asset. However, threats that represent adversaries and their methods of attack are external to your control. Likelihood is the wild card in the bunch. Likelihoods determine if and when a threat will materialize, succeed, and do damage. While never fully under your control, likelihoods can be shaped and influenced to manage the risk.\nMathematically, the forces can be represented in a formula such as: \n  \n    \n      \n        R\n        i\n        s\n        k\n\n== IT risk management ==\n\nIT risk management can be considered a component of a wider enterprise risk management system.The establishment, maintenance and continuous update of an information security management system (ISMS) provide a strong indication that a company is using a systematic approach for the identification, assessment and management of information security risks.Different methodologies have been proposed to manage IT risks, each of them divided into processes and steps.The Certified Information Systems Auditor Review Manual 2006 produced by ISACA, an international professional association focused on IT Governance, provides the following definition of risk management: \"Risk management is the process of identifying vulnerabilities and threats to the information resources used by an organization in achieving business objectives, and deciding what countermeasures, if any, to take in reducing risk to an acceptable level, based on the value of the information resource to the organization.\"The NIST Cybersecurity Framework encourages organizations to manage IT risk as part the Identify (ID) function:Risk Assessment (ID.RA): The organization understands the cybersecurity risk to organizational operations (including mission, functions, image, or reputation), organizational assets, and individuals.\n\nID.RA-1: Asset vulnerabilities are identified and documented\nID.RA-2: Cyber threat intelligence and vulnerability information is received from information sharing forums and source\nID.RA-3: Threats, both internal and external, are identified and documented\nID.RA-4: Potential business impacts and likelihoods are identified\nID.RA-5: Threats, vulnerabilities, likelihoods, and impacts are used to determine risk\nID.RA-6: Risk responses are identified and prioritizedRisk Management Strategy (ID.RM): The organization\u2019s priorities, constraints, risk tolerances, and assumptions are established and used to support operational risk decisions. \n\nID.RM-1: Risk management processes are established, managed, and agreed to by organizational stakeholders\nID.RM-2: Organizational risk tolerance is determined and clearly expressed\nID.RM-3: The organization\u2019s determination of risk tolerance is informed by its role in critical infrastructure and sector specific risk analysis\n\n== IT risk laws and regulations ==\nIn the following a brief description of applicable rules organized by source.\n\n\n*** OECD ***\nOECD issued the following:\n\nOrganisation for Economic Co-operation and Development (OECD) Recommendation of the Council concerning guidelines governing the protection of privacy and trans-border flows of personal data (23 September 1980)\nOECD Guidelines for the Security of Information Systems and Networks: Towards a Culture of Security (25 July 2002). Topic: General information security. Scope: Non binding guidelines to any OECD entities (governments, businesses, other organisations and individual users who develop, own, provide, manage, service, and use information systems and networks). The OECD Guidelines state the basic principles underpinning risk management and information security practices. While no part of the text is binding as such, non-compliance with any of the principles is indicative of a serious breach of RM/RA good practices that can potentially incur liability.\n\n\n*** European Union ***\nThe European Union issued the following, divided by topic:\n\nPrivacy\nRegulation (EC) No 45/2001 on the protection of individuals with regard to the processing of personal data by the Community institutions and bodies and on the free movement of such data provide an internal regulation, which is a practical application of the principles of the Privacy Directive described below. Furthermore, article 35 of the Regulation requires the Community institutions and bodies to take similar precautions with regard to their telecommunications infrastructure, and to properly inform the users of any specific risks of security breaches.\nDirective 95/46/EC on the protection of individuals with regard to the processing of personal data and on the free movement of such data require that any personal data processing activity undergoes a prior risk analysis in order to determine the privacy implications of the activity, and to determine the appropriate legal, technical and organisation measures to protect such activities;is effectively protected by such measures, which must be state of the art keeping into account the sensitivity and privacy implications of the activity (including when a third party is charged with the processing task) is notified to a national data protection authority, including the measures taken to ensure the security of the activity. Furthermore, article 25 and following of the Directive requires Member States to ban the transfer of personal data to non-Member States, unless such countries have provided adequate legal protection for such personal data, or barring certain other exceptions.\nCommission Decision 2001/497/EC of 15 June 2001 on standard contractual clauses for the transfer of personal data to third countries, under Directive 95/46/EC; and Commission Decision 2004/915/EC of 27 December 2004 amending Decision 2001/497/EC as regards the introduction of an alternative set of standard contractual clauses for the transfer of personal data to third countries. Topic: Export of personal data to third countries, specifically non-E.U. countries which have not been recognised as having a data protection level that is adequate (i.e. equivalent to that of the E.U.). Both Commission Decisions provide a set of voluntary model clauses which can be used to export personal data from a data controller (who is subject to E.U. data protection rules) to a data processor outside the E.U. who is not subject to these rules or to a similar set of adequate rules.\nInternational Safe Harbor Privacy Principles (see below USA and International Safe Harbor Privacy Principles )\nDirective 2002/58/EC of 12 July 2002 concerning the processing of personal data and the protection of privacy in the electronic communications sector\nNational Security\nDirective 2006/24/EC of 15 March 2006 on the retention of data generated or processed in connection with the provision of publicly available electronic communications services or of public communications networks and amending Directive 2002/58/EC (\u2018Data Retention Directive\u2019). Topic: Requirement for the providers of public electronic telecommunications service providers to retain certain information for the purposes of the investigation, detection and prosecution of serious crime\nCouncil Directive 2008/114/EC of 8 December 2008 on the identification and designation of European critical infrastructures and the assessment of the need to improve their protection. Topic: Identification and protection of European Critical Infrastructures. Scope: Applicable to Member States and to the operators of European Critical Infrastructure (defined by the draft directive as \u2018critical infrastructures the disruption or destruction of which would significantly affect two or more Member States, or a single Member State if the critical infrastructure is located in another Member State. This includes effects resulting from cross-sector dependencies on other types of infrastructure\u2019). Requires Member States to identify critical infrastructures on their territories, and to designate them as ECIs. Following this designation, the owners/operators of ECIs are required to create Operator Security Plans (OSPs), which should establish relevant security solutions for their protection\nCivil and Penal law\nCouncil Framework Decision 2005/222/JHA of 24 February 2005 on attacks against information systems. Topic: General decision aiming to harmonise national provisions in the field of cyber crime, encompassing material criminal law (i.e. definitions of specific crimes), procedural criminal law (including investigative measures and international cooperation) and liability issues. Scope: Requires Member States to implement the provisions of the Framework Decision in their national legal frameworks. Framework decision is relevant to RM/RA because it contains the conditions under which legal liability can be imposed on legal entities for conduct of certain natural persons of authority within the legal entity. Thus, the Framework decision requires that the conduct of such figures within an organisation is adequately monitored, also because the Decision states that a legal entity can be held liable for acts of omission in this regard.\n\n\n*** Council of Europe ***\nCouncil of Europe Convention on Cybercrime, Budapest, 23.XI.2001, European Treaty Series-No. 185. Topic: General treaty aiming to harmonise national provisions in the field of cyber crime, encompassing material criminal law (i.e. definitions of specific crimes), procedural criminal law (including investigative measures and international cooperation), liability issues and data retention. Apart from the definitions of a series of criminal offences in articles 2 to 10, the Convention is relevant to RM/RA because it states the conditions under which legal liability can be imposed on legal entities for conduct of certain natural persons of authority within the legal entity. Thus, the Convention requires that the conduct of such figures within an organisation is adequately monitored, also because the Convention states that a legal entity can be held liable for acts of omission in this regard.\n\n\n*** United States ***\nUnited States issued the following, divided by topic:\n\nCivil and Penal law\nAmendments to the Federal Rules of Civil Procedure with regard to electronic discovery. Topic: U.S. Federal rules with regard to the production of electronic documents in civil proceedings. The discovery rules allow a party in civil proceedings to demand that the opposing party produce all relevant documentation (to be defined by the requesting party) in its possession, so as to allow the parties and the court to correctly assess the matter. Through the e-discovery amendment, which entered into force on 1 December 2006, such information may now include electronic information. This implies that any party being brought before a U.S. court in civil proceedings can be asked to produce such documents, which includes finalised reports, working documents, internal memos and e-mails with regard to a specific subject, which may or may not be specifically delineated. Any party whose activities imply a risk of being involved in such proceedings must therefore take adequate precautions for the management of such information, including the secure storage. Specifically: The party must be capable of initiating a \u2018litigation hold\u2019, a technical/organisational measure which must ensure that no relevant information can be modified any longer in any way. Storage policies must be responsible: while deletion of specific information of course remains allowed when this is a part of general information management policies (\u2018routine, good-faith operation of the information system\u2019, Rule 37 (f)), the wilful destruction of potentially relevant information can be punished by extremely high fines (in one specific case of 1.6 billion US$). Thus, in practice, any businesses who risk civil litigation before U.S. courts must implement adequate information management policies, and must implement the necessary measures to initiate a litigation hold.\nPrivacy\nCalifornia Consumer Privacy Act (CCPA)\nCalifornia Privacy Rights Act (CPRA)\nGramm\u2013Leach\u2013Bliley Act (GLBA)\nUSA PATRIOT Act, Title III\nHealth Insurance Portability and Accountability Act (HIPAA) From an RM/RA perspective, the Act is particularly known for its provisions with regard to Administrative Simplification (Title II of HIPAA). This title required the U.S. Department of Health and Human Services (HHS) to draft specific rule sets, each of which would provide specific standards which would improve the efficiency of the health care system and prevent abuse. As a result, the HHS has adopted five principal rules: the Privacy Rule, the Transactions and Code Sets Rule, the Unique Identifiers Rule, the Enforcement Rule, and the Security Rule. The latter, published in the Federal Register on 20 February 2003 (see: http://www.cms.hhs.gov/SecurityStandard/Downloads/securityfinalrule.pdf), is specifically relevant, as it specifies a series of administrative, technical, and physical security procedures to assure the confidentiality of electronic protected health information. These aspects have been further outlined in a set of Security Standards on Administrative, Physical, Organisational and Technical Safeguards, all of which have been published, along with a guidance document on the basics of HIPAA risk management and risk assessment <http://www.cms.hhs.gov/EducationMaterials/04_SecurityMaterials.asp>. European or other countries health care service providers will generally not be affected by HIPAA obligations if they are not active on the U.S. market. However, since their data processing activities are subject to similar obligations under general European law (including the Privacy Directive), and since the underlying trends of modernisation and evolution towards electronic health files are the same, the HHS safeguards can be useful as an initial yardstick for measuring RM/RA strategies put in place by European health care service providers, specifically with regard to the processing of electronic health information. HIPAA security standards include the following:\nAdministrative safeguards:\nSecurity Management Process\nAssigned Security Responsibility\nWorkforce Security\nInformation Access Management\nSecurity Awareness and Training\nSecurity Incident Procedures\nContingency Plan\nEvaluation\nBusiness Associate Contracts and Other Arrangements\nPhysical safeguards\nFacility Access Controls\nWorkstation Use\nWorkstation Security\nDevice and Media Controls\nTechnical safeguards\nAccess Control\nAudit Controls\nIntegrity\nPerson or Entity Authentication\nTransmission Security\nOrganisational requirements\nBusiness Associate Contracts & Other Arrangements\nRequirements for Group Health Plans\nInternational Safe Harbor Privacy Principles issued by the US Department of Commerce on July 21, 2000 Export of personal data from a data controller who is subject to E.U. privacy regulations to a U.S. based destination; before personal data may be exported from an entity subject to E.U. privacy regulations to a destination subject to U.S. law, the European entity must ensure that the receiving entity provides adequate safeguards to protect such data against a number of mishaps. One way of complying with this obligation is to require the receiving entity to join the Safe Harbor, by requiring that the entity self-certifies its compliance with the so-called Safe Harbor Principles. If this road is chosen, the data controller exporting the data must verify that the U.S. destination is indeed on the Safe Harbor list (see safe harbor list)\nThe United States Department of Homeland Security also utilizes Privacy Impact Assessment (PIA) as a decision making tool to identify and mitigate risks of privacy violations.\nSarbanes\u2013Oxley Act\nFISMA\nAs legislation evolves, there has been increased focus to require 'reasonable security' for information management. CCPA states that \"manufacturers of connected devices to equip the device with reasonable security.\" New York's SHIELD Act requires that organizations that manage NY residents' information \u201cdevelop, implement and maintain reasonable safeguards to protect the security, confidentiality and integrity of the private information including, but not limited to, disposal of data.\u201d This concept will influence how businesses manage their risk management plan as compliance requirements develop.\n\n== Standards organizations and standards ==\nInternational standard bodies:\nInternational Organization for Standardization \u2013 ISO\nPayment Card Industry Security Standards Council\nInformation Security Forum\nThe Open Group\nUnited States standard bodies:\nNational Institute of Standards and Technology \u2013 NIST\nFederal Information Processing Standards \u2013 FIPS by NIST devoted to Federal Government and Agencies\nUK standard bodies\nBritish Standard Institute\n\n\n*** Short description of standards ***\nThe list is chiefly based on:\n\n\n**** ISO ****\nISO/IEC 13335-1:2004 \u2013 Information technology\u2014Security techniques\u2014Management of information and communications technology security\u2014Part 1: Concepts and models for information and communications technology security management http://www.iso.org/iso/en/CatalogueDetailPage.CatalogueDetail?CSNUMBER"
    }
  },
  {
    "instruction": "Context: Multi-party fair exchange protocol\n\n==Introduction==\nIn cryptography, a multi-party fair exchange protocol is protocol where parties accept to deliver an item if and only if they receive an item in return.\n\n== Definition ==\nMatthew K. Franklin and Gene Tsudik suggested in 1998 the following classification:\n\nAn \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  -party single-unit general exchange is a permutation \n  \n    \n      \n        \u03c3\n      \n    \n    {\\displaystyle \\sigma }\n   on \n  \n    \n      \n        {\n        1...\n        n\n        }\n      \n    \n    {\\displaystyle \\{1...n\\}}\n  , where each party \n  \n    \n      \n        \n          P\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle P_{i}}\n   offers a single unit of commodity \n  \n    \n      \n        \n          K\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle K_{i}}\n   to \n  \n    \n      \n        \n          P\n          \n            \u03c3\n            (\n            i\n            )\n          \n        \n      \n    \n    {\\displaystyle P_{\\sigma (i)}}\n  , and receives a single unit of commodity \n  \n    \n      \n        \n          K\n          \n            \n              \u03c3\n              \n                \u2212\n                1\n              \n            \n            (\n            i\n            )\n          \n        \n      \n    \n    {\\displaystyle K_{\\sigma ^{-1}(i)}}\n   from \n  \n    \n      \n        \n          P\n          \n            \n              \u03c3\n              \n                \u2212\n                1\n              \n            \n            (\n            i\n            )\n          \n        \n      \n    \n    {\\displaystyle P_{\\sigma ^{-1}(i)}}\n  .\nAn \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  -party multi-unit general exchange is a matrix of baskets, where the entry \n  \n    \n      \n        \n          B\n          \n            i\n            j\n          \n        \n      \n    \n    {\\displaystyle B_{ij}}\n   in row \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n   and column \n  \n    \n      \n        j\n      \n    \n    {\\displaystyle j}\n   is the basket of goods given by \n  \n    \n      \n        \n          P\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle P_{i}}\n   to \n  \n    \n      \n        \n          P\n          \n            j\n          \n        \n      \n    \n    {\\displaystyle P_{j}}\n  .\nQuestion: What is the significance of the matrix of baskets in an n-party multi-unit general exchange?\n\nAnswer:",
    "context": "",
    "output": "The matrix of baskets in an n-party multi-unit general exchange represents the exchange of commodities between the parties. Each entry in the matrix specifies the basket of commodities offered by one party to another, with the row and column indices indicating the parties involved in the exchange.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the significance of the matrix of baskets in an n-party multi-unit general exchange?",
      "answer": "The matrix of baskets in an n-party multi-unit general exchange represents the exchange of commodities between the parties. Each entry in the matrix specifies the basket of commodities offered by one party to another, with the row and column indices indicating the parties involved in the exchange.",
      "context": "Multi-party fair exchange protocol\n\n==Introduction==\nIn cryptography, a multi-party fair exchange protocol is protocol where parties accept to deliver an item if and only if they receive an item in return.\n\n== Definition ==\nMatthew K. Franklin and Gene Tsudik suggested in 1998 the following classification:\n\nAn \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  -party single-unit general exchange is a permutation \n  \n    \n      \n        \u03c3\n      \n    \n    {\\displaystyle \\sigma }\n   on \n  \n    \n      \n        {\n        1...\n        n\n        }\n      \n    \n    {\\displaystyle \\{1...n\\}}\n  , where each party \n  \n    \n      \n        \n          P\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle P_{i}}\n   offers a single unit of commodity \n  \n    \n      \n        \n          K\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle K_{i}}\n   to \n  \n    \n      \n        \n          P\n          \n            \u03c3\n            (\n            i\n            )\n          \n        \n      \n    \n    {\\displaystyle P_{\\sigma (i)}}\n  , and receives a single unit of commodity \n  \n    \n      \n        \n          K\n          \n            \n              \u03c3\n              \n                \u2212\n                1\n              \n            \n            (\n            i\n            )\n          \n        \n      \n    \n    {\\displaystyle K_{\\sigma ^{-1}(i)}}\n   from \n  \n    \n      \n        \n          P\n          \n            \n              \u03c3\n              \n                \u2212\n                1\n              \n            \n            (\n            i\n            )\n          \n        \n      \n    \n    {\\displaystyle P_{\\sigma ^{-1}(i)}}\n  .\nAn \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  -party multi-unit general exchange is a matrix of baskets, where the entry \n  \n    \n      \n        \n          B\n          \n            i\n            j\n          \n        \n      \n    \n    {\\displaystyle B_{ij}}\n   in row \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n   and column \n  \n    \n      \n        j\n      \n    \n    {\\displaystyle j}\n   is the basket of goods given by \n  \n    \n      \n        \n          P\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle P_{i}}\n   to \n  \n    \n      \n        \n          P\n          \n            j\n          \n        \n      \n    \n    {\\displaystyle P_{j}}\n  ."
    }
  },
  {
    "instruction": "Defense in depth (computing)\n\n==Introduction==\nDefense in depth is a concept used in information security in which multiple layers of security controls (defense) are placed throughout an information technology (IT) system. Its intent is to provide redundancy in the event a security control fails or a vulnerability is exploited that can cover aspects of personnel, procedural, technical and physical security for the duration of the system's life cycle.\n\n\n\n== Background ==\nThe idea behind the defense in depth approach is to defend a system against any particular attack using several independent methods. It is a layering tactic, conceived by the National Security Agency (NSA) as a comprehensive approach to information and electronic security. The term defense in depth in computing is inspired by a military strategy of the same name, but is quite different in concept. The military strategy revolves around having a weaker perimeter defense and intentionally yielding space to buy time, envelop, and ultimately counter-attack an opponent, whereas the information security strategy simply involves multiple layers of controls, but not intentionally ceding ground (cf. honeypot.)\n\n== Controls ==\nDefense in depth can be divided into three areas: Physical, Technical, and Administrative.\n\n\n*** Physical ***\nPhysical controls are anything that physically limits or prevents access to IT systems. Fences, guards, dogs, and CCTV systems and the like.\n\n\n*** Technical ***\nTechnical controls are hardware or software whose purpose is to protect systems and resources. Examples of technical controls would be disk encryption, File integrity software, and authentication. Hardware technical controls differ from physical controls in that they prevent access to the contents of a system, but not the physical systems themselves.\n\n\n*** Administrative ***\nAdministrative controls are organization's policies and procedures. Their purpose is to ensure that there is proper guidance available in regard to security and that regulations are met. They include things such as hiring practices, data handling procedures, and security requirements.\n\n== Methods ==\nUsing more than one of the following layers constitutes an example of defense in depth.\n\n\n*** System and application ***\nAntivirus software\nAuthentication and password security\nEncryption\nHashing passwords\nLogging and auditing\nMulti-factor authentication\nVulnerability scanners\nTimed access control\nInternet Security Awareness Training\nSandboxing\nIntrusion detection systems (IDS)\n\n\n*** Network ***\nFirewalls (hardware or software)\nDemilitarized zones (DMZ)\nVirtual private network (VPN)\n\n\n*** Physical ***\nBiometrics\nData-centric security\nPhysical security (e.g. deadbolt locks)\n\n\n*** Example ***\nIn the following scenario a web browser is developed using defense in depth -\n\nthe browser developers receive security training\nthe codebase is checked automatically using security analysis tools\nthe browser is regularly audited by an internal security team\n... is occasionally audited by an external security team\n... is executed inside a sandbox Answer this question using the following article:\n\nWhich layer of defense in depth includes antivirus software, authentication and password security, encryption, and logging and auditing?",
    "context": "",
    "output": "The system and application layer of defense in depth includes antivirus software, authentication and password security, encryption, hashing passwords, logging and auditing, multi-factor authentication, vulnerability scanners, timed access control, internet security awareness training, sandboxing, and intrusion detection systems (IDS).",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "Which layer of defense in depth includes antivirus software, authentication and password security, encryption, and logging and auditing?",
      "answer": "The system and application layer of defense in depth includes antivirus software, authentication and password security, encryption, hashing passwords, logging and auditing, multi-factor authentication, vulnerability scanners, timed access control, internet security awareness training, sandboxing, and intrusion detection systems (IDS).",
      "context": "Defense in depth (computing)\n\n==Introduction==\nDefense in depth is a concept used in information security in which multiple layers of security controls (defense) are placed throughout an information technology (IT) system. Its intent is to provide redundancy in the event a security control fails or a vulnerability is exploited that can cover aspects of personnel, procedural, technical and physical security for the duration of the system's life cycle.\n\n\n\n== Background ==\nThe idea behind the defense in depth approach is to defend a system against any particular attack using several independent methods. It is a layering tactic, conceived by the National Security Agency (NSA) as a comprehensive approach to information and electronic security. The term defense in depth in computing is inspired by a military strategy of the same name, but is quite different in concept. The military strategy revolves around having a weaker perimeter defense and intentionally yielding space to buy time, envelop, and ultimately counter-attack an opponent, whereas the information security strategy simply involves multiple layers of controls, but not intentionally ceding ground (cf. honeypot.)\n\n== Controls ==\nDefense in depth can be divided into three areas: Physical, Technical, and Administrative.\n\n\n*** Physical ***\nPhysical controls are anything that physically limits or prevents access to IT systems. Fences, guards, dogs, and CCTV systems and the like.\n\n\n*** Technical ***\nTechnical controls are hardware or software whose purpose is to protect systems and resources. Examples of technical controls would be disk encryption, File integrity software, and authentication. Hardware technical controls differ from physical controls in that they prevent access to the contents of a system, but not the physical systems themselves.\n\n\n*** Administrative ***\nAdministrative controls are organization's policies and procedures. Their purpose is to ensure that there is proper guidance available in regard to security and that regulations are met. They include things such as hiring practices, data handling procedures, and security requirements.\n\n== Methods ==\nUsing more than one of the following layers constitutes an example of defense in depth.\n\n\n*** System and application ***\nAntivirus software\nAuthentication and password security\nEncryption\nHashing passwords\nLogging and auditing\nMulti-factor authentication\nVulnerability scanners\nTimed access control\nInternet Security Awareness Training\nSandboxing\nIntrusion detection systems (IDS)\n\n\n*** Network ***\nFirewalls (hardware or software)\nDemilitarized zones (DMZ)\nVirtual private network (VPN)\n\n\n*** Physical ***\nBiometrics\nData-centric security\nPhysical security (e.g. deadbolt locks)\n\n\n*** Example ***\nIn the following scenario a web browser is developed using defense in depth -\n\nthe browser developers receive security training\nthe codebase is checked automatically using security analysis tools\nthe browser is regularly audited by an internal security team\n... is occasionally audited by an external security team\n... is executed inside a sandbox"
    }
  },
  {
    "instruction": "The two main components of the ABAC architecture are the Policy Enforcement Point (PEP) and the Policy Decision Point (PDP). The PEP is responsible for protecting the apps and data, inspecting the request and generating an authorization request. The PDP evaluates incoming requests against policies it has been configured with and returns a Permit/Deny decision.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What are the two main components of the ABAC architecture?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What are the two main components of the ABAC architecture?",
      "answer": "The two main components of the ABAC architecture are the Policy Enforcement Point (PEP) and the Policy Decision Point (PDP). The PEP is responsible for protecting the apps and data, inspecting the request and generating an authorization request. The PDP evaluates incoming requests against policies it has been configured with and returns a Permit/Deny decision."
    }
  },
  {
    "instruction": "The AKW2 algorithm is designed to be secure only under known-plaintext (or weaker) attacks and is intended for use in legacy systems and computationally limited devices where use of the other algorithms would be impractical.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the intended use of the AKW2 algorithm?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the intended use of the AKW2 algorithm?",
      "answer": "The AKW2 algorithm is designed to be secure only under known-plaintext (or weaker) attacks and is intended for use in legacy systems and computationally limited devices where use of the other algorithms would be impractical."
    }
  },
  {
    "instruction": "The HTTP CONNECT method is used by the client to request an HTTP proxy server to forward the TCP connection to the desired destination.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the purpose of the HTTP CONNECT method in tunneling?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the purpose of the HTTP CONNECT method in tunneling?",
      "answer": "The HTTP CONNECT method is used by the client to request an HTTP proxy server to forward the TCP connection to the desired destination."
    }
  },
  {
    "instruction": "Batch cryptography provides several improvements in cryptographic systems, such as increased efficiency, reduced computational overhead, and lower latency for processing multiple pieces of data simultaneously. Moreover, it enhances security by facilitating the use of advanced cryptographic techniques like threshold cryptography and secure multi-party computation, making it more challenging for attackers to compromise the system.\n\nWrite a question about the text above.",
    "context": "",
    "output": "In what ways does the application of batch cryptography lead to improvements in cryptographic systems?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "In what ways does the application of batch cryptography lead to improvements in cryptographic systems?",
      "answer": "Batch cryptography provides several improvements in cryptographic systems, such as increased efficiency, reduced computational overhead, and lower latency for processing multiple pieces of data simultaneously. Moreover, it enhances security by facilitating the use of advanced cryptographic techniques like threshold cryptography and secure multi-party computation, making it more challenging for attackers to compromise the system."
    }
  },
  {
    "instruction": "GlobalSign is a founding member of the CA/B Forum, actively participating in the organization's S/MIME and server certificate working groups. The company is also a member of MISA, Cloud Signature Consortium, CASC, and the Adobe Cloud Signature Partner Program, focusing on various aspects of security, identity, and certificate management.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What are some industry affiliations that GlobalSign is involved with, and what are their focuses?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What are some industry affiliations that GlobalSign is involved with, and what are their focuses?",
      "answer": "GlobalSign is a founding member of the CA/B Forum, actively participating in the organization's S/MIME and server certificate working groups. The company is also a member of MISA, Cloud Signature Consortium, CASC, and the Adobe Cloud Signature Partner Program, focusing on various aspects of security, identity, and certificate management."
    }
  },
  {
    "instruction": "Compression Algorithms for Real Programmers focuses on compression algorithms and is part of The For Real Programmers Series, implying that it targets experienced programmers who are already familiar with programming concepts.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What does Peter Wayner's Compression Algorithms for Real Programmers cover, and what is its intended audience?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What does Peter Wayner's Compression Algorithms for Real Programmers cover, and what is its intended audience?",
      "answer": "Compression Algorithms for Real Programmers focuses on compression algorithms and is part of The For Real Programmers Series, implying that it targets experienced programmers who are already familiar with programming concepts."
    }
  },
  {
    "instruction": "A strong key schedule helps to prevent related-key attacks by ensuring that the keys used in the encryption process are not simply related, making it difficult for attackers to perform related-key attacks. This is achieved by using a complex algorithm to generate keys based on a seed value, rather than using a simple mathematical relationship between keys.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does the key schedule help to prevent related-key attacks?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does the key schedule help to prevent related-key attacks?",
      "answer": "A strong key schedule helps to prevent related-key attacks by ensuring that the keys used in the encryption process are not simply related, making it difficult for attackers to perform related-key attacks. This is achieved by using a complex algorithm to generate keys based on a seed value, rather than using a simple mathematical relationship between keys."
    }
  },
  {
    "instruction": "End users can access the \"Trusted Vendors\" list maintained by the CCSS Forum by visiting the organization's website, [http://www.ccssforum.org](http://www.ccssforum.org). This list serves as a valuable resource for determining the trustworthiness of antivirus system providers.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How can end users access the \"Trusted Vendors\" list maintained by the CCSS Forum?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How can end users access the \"Trusted Vendors\" list maintained by the CCSS Forum?",
      "answer": "End users can access the \"Trusted Vendors\" list maintained by the CCSS Forum by visiting the organization's website, [http://www.ccssforum.org](http://www.ccssforum.org). This list serves as a valuable resource for determining the trustworthiness of antivirus system providers."
    }
  },
  {
    "instruction": "The software security assurance process begins with the categorization of the information that is to be contained in or used by the software. This categorization is based on the sensitivity of the information and helps determine the appropriate security requirements for the software.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How is the software security assurance process related to the categorization of information?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How is the software security assurance process related to the categorization of information?",
      "answer": "The software security assurance process begins with the categorization of the information that is to be contained in or used by the software. This categorization is based on the sensitivity of the information and helps determine the appropriate security requirements for the software."
    }
  },
  {
    "instruction": "The first public discussion of SQL injection in 1998, when Web applications integrated new technologies like JavaScript and Flash, led to the spread of SAST tools for security purposes. This discussion highlighted the need for securing applications and identifying vulnerabilities in the source code.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How did the first public discussion of SQL injection in 1998 contribute to the spread of SAST tools for security purposes?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How did the first public discussion of SQL injection in 1998 contribute to the spread of SAST tools for security purposes?",
      "answer": "The first public discussion of SQL injection in 1998, when Web applications integrated new technologies like JavaScript and Flash, led to the spread of SAST tools for security purposes. This discussion highlighted the need for securing applications and identifying vulnerabilities in the source code."
    }
  },
  {
    "instruction": "Access control\n\n==Introduction==\nIn physical security and information security, access control (AC) is the selective restriction of access to a place or other resource, while access management describes the process. The act of accessing may mean consuming, entering, or using. Permission to access a resource is called authorization.\nLocks and login credentials are two analogous mechanisms of access control.\n\n\n\n== Physical security ==\n\nGeographical access control may be enforced by personnel (e.g. border guard, bouncer, ticket checker), or with a device such as a turnstile. There may be fences to avoid circumventing this access control. An alternative of access control in the strict sense (physically controlling access itself) is a system of checking authorized presence, see e.g. Ticket controller (transportation). A variant is exit control, e.g. of a shop (checkout) or a country.The term access control refers to the practice of restricting entrance to a property, a building, or a room to authorized persons. Physical access control can be achieved by a human (a guard, bouncer, or receptionist), through mechanical means such as locks and keys, or through technological means such as access control systems like the mantrap. Within these environments, physical key management may also be employed as a means of further managing and monitoring access to mechanically keyed areas or access to certain small assets.Physical access control is a matter of who, where, and when. An access control system determines who is allowed to enter or exit, where they are allowed to exit or enter, and when they are allowed to enter or exit. Historically, this was partially accomplished through keys and locks. When a door is locked, only someone with a key can enter through the door, depending on how the lock is configured. Mechanical locks and keys do not allow restriction of the key holder to specific times or dates. Mechanical locks and keys do not provide records of the key used on any specific door, and the keys can be easily copied or transferred to an unauthorized person. When a mechanical key is lost or the key holder is no longer authorized to use the protected area, the locks must be re-keyed.\n\n\n*** Electronic access control ***\n\nElectronic access control (EAC) uses computers to solve the limitations of mechanical locks and keys. A wide range of credentials can be used to replace mechanical keys. The electronic access control system grants access based on the credential presented. When access is granted, the door is unlocked for a predetermined time and the transaction is recorded. When access is refused, the door remains locked and the attempted access is recorded. The system will also monitor the door and alarm if the door is forced open or held open too long after being unlocked.When a credential is presented to a reader, the reader sends the credential's information, usually a number, to a control panel, a highly reliable processor. The control panel compares the credential's number to an access control list, grants or denies the presented request, and sends a transaction log to a database. When access is denied based on the access control list, the door remains locked. If there is a match between the credential and the access control list, the control panel operates a relay that in turn unlocks the door. The control panel also ignores a door open signal to prevent an alarm. Often the reader provides feedback, such as a flashing red LED for an access denied and a flashing green LED for an access granted.The above description illustrates a single factor transaction. Credentials can be passed around, thus subverting the access control list. For example, Alice has access rights to the server room, but Bob does not. Alice either gives Bob her credential, or Bob takes it; he now has access to the server room. To prevent this, two-factor authentication can be used. In a two factor transaction, the presented credential and a second factor are needed for access to be granted; another factor can be a PIN, a second credential, operator intervention, or a biometric input.There are three types (factors) of authenticating information:\nsomething the user knows, e.g. a password, pass-phrase or PIN\nsomething the user has, such as smart card or a key fob\nsomething the user is, such as the users fingerprint, verified by biometric measurementPasswords are a common means of verifying a user's identity before access is given to information systems.  In addition, a fourth factor of authentication is now recognized: someone you know, whereby another person who knows you can provide a human element of authentication in situations where systems have been set up to allow for such scenarios.  For example, a user may have their password, but have forgotten their smart card.  In such a scenario, if the user is known to designated cohorts, the cohorts may provide their smart card and password, in combination with the extant factor of the user in question, and thus provide two factors for the user with the missing credential, giving three factors overall to allow access.\n\n\n*** Credential ***\nA credential is a physical/tangible object, a piece of knowledge, or a facet of a person's physical being that enables an individual access to a given physical facility or computer-based information system.  Typically, credentials can be something a person knows (such as a number or PIN), something they have (such as an access badge), something they are (such as a biometric feature), something they do (measurable behavioural patterns), or some combination of these items. This is known as multi-factor authentication. The typical credential is an access card or key-fob, and newer software can also turn users' smartphones into access devices.There are many card technologies including magnetic stripe, bar code, Wiegand, 125 kHz proximity, 26-bit card-swipe, contact smart cards, and contactless smart cards. Also available are key-fobs, which are more compact than ID cards, and attach to a key ring. Biometric technologies include fingerprint, facial recognition, iris recognition, retinal scan, voice, and hand geometry.  The built-in biometric technologies found on newer smartphones can also be used as credentials in conjunction with access software running on mobile devices. In addition to older more traditional card access technologies, newer technologies such as Near field communication (NFC), Bluetooth low energy or Ultra-wideband (UWB) can also communicate user credentials to readers for system or building access.\n\n\n*** Access control system components ***\n\nComponents of an access control system include:\n\nAn access control panel (also known as a controller)\nAn access-controlled entry, such as a door, turnstile, parking gate, elevator, or other physical barrier\nA reader installed near the entry. (In cases where the exit is also controlled, a second reader is used on the opposite side of the entry.)\nLocking hardware, such as electric door strikes and electromagnetic locks\nA magnetic door switch for monitoring door position\nRequest-to-exit (RTE) devices for allowing egress. When a RTE button is pushed, or the motion detector detects motion at the door, the door alarm is temporarily ignored while the door is opened. Exiting a door without having to electrically unlock the door is called mechanical free egress. This is an important safety feature. In cases where the lock must be electrically unlocked on exit, the request-to-exit device also unlocks the door.\n\n\n*** Access control topology ***\n\nAccess control decisions are made by comparing the credentials to an access control list. This look-up can be done by a host or server, by an access control panel, or by a reader. The development of access control systems has observed a steady push of the look-up out from a central host to the edge of the system, or the reader. The predominant topology circa 2009 is hub and spoke with a control panel as the hub, and the readers as the spokes. The look-up and control functions are by the control panel. The spokes communicate through a serial connection; usually RS-485. Some manufactures are pushing the decision making to the edge by placing a controller at the door. The controllers are IP enabled, and connect to a host and database using standard networks\n\n\n*** Types of readers ***\nAccess control readers may be classified by the functions they are able to perform:\nBasic (non-intelligent) readers: simply read card number or PIN, and forward it to a control panel. In case of biometric identification, such readers output the ID number of a user. Typically, Wiegand protocol is used for transmitting data to the control panel, but other options such as RS-232, RS-485 and Clock/Data are not uncommon. This is the most popular type of access control readers. Examples of such readers are RF Tiny by RFLOGICS, ProxPoint by HID, and P300 by Farpointe Data.\nSemi-intelligent readers: have all inputs and outputs necessary to control door hardware (lock, door contact, exit button), but do not make any access decisions. When a user presents a card or enters a PIN, the reader sends information to the main controller, and waits for its response. If the connection to the main controller is interrupted, such readers stop working, or function in a degraded mode. Usually semi-intelligent readers are connected to a control panel via an RS-485 bus. Examples of such readers are InfoProx Lite IPL200 by CEM Systems, and AP-510 by Apollo.\nIntelligent readers: have all inputs and outputs necessary to control door hardware; they also have memory and processing power necessary to make access decisions independently. Like semi-intelligent readers, they are connected to a control panel via an RS-485 bus. The control panel sends configuration updates, and retrieves events from the readers. Examples of such readers could be InfoProx IPO200 by CEM Systems, and AP-500 by Apollo. There is also a new generation of intelligent readers referred to as \"IP readers\". Systems with IP readers usually do not have traditional control panels, and readers communicate directly to a PC that acts as a host.Some readers may have additional features such as an LCD and function buttons for data collection purposes (i.e. clock-in/clock-out events for attendance reports), camera/speaker/microphone for intercom, and smart card read/write support.\n\n\n*** Access control system topologies ***\n\n1. Serial controllers. Controllers are connected to a host PC via a serial RS-485 communication line (or via 20mA current loop in some older systems). External RS-232/485 converters or internal RS-485 cards have to be installed, as standard PCs do not have RS-485 communication ports.Advantages:\nRS-485 standard allows long cable runs, up to 4000 feet (1200 m)\nRelatively short response time. The maximum number of devices on an RS-485 line is limited to 32, which means that the host can frequently request status updates from each device, and display events almost in real time.\nHigh reliability and security as the communication line is not shared with any other systems.Disadvantages:\nRS-485 does not allow Star-type wiring unless splitters are used\nRS-485 is not well suited for transferring large amounts of data (i.e. configuration and users). The highest possible throughput is 115.2 kbit/sec, but in most system it is downgraded to 56.2 kbit/sec, or less, to increase reliability.\nRS-485 does not allow the host PC to communicate with several controllers connected to the same port simultaneously. Therefore, in large systems, transfers of configuration, and users to controllers may take a very long time, interfering with normal operations.\nControllers cannot initiate communication in case of an alarm. The host PC acts as a master on the RS-485 communication line, and controllers have to wait until they are polled.\nSpecial serial switches are required, in order to build a redundant host PC setup.\nSeparate RS-485 lines have to be installed, instead of using an already existing network infrastructure.\nCable that meets RS-485 standards is significantly more expensive than regular Category 5 UTP network cable.\nOperation of the system is highly dependent on the host PC. In the case that the host PC fails, events from controllers are not retrieved, and functions that require interaction between controllers (i.e. anti-passback) stop working.\n2. Serial main and sub-controllers. All door hardware is connected to sub-controllers (a.k.a. door controllers or door interfaces). Sub-controllers usually do not make access decisions, and instead forward all requests to the main controllers. Main controllers usually support from 16 to 32 sub-controllers.\nAdvantages:\nWork load on the host PC is significantly reduced, because it only needs to communicate with a few main controllers.\nThe overall cost of the system is lower, as sub-controllers are usually simple and inexpensive devices.\nAll other advantages listed in the first paragraph apply.Disadvantages:\nOperation of the system is highly dependent on main controllers. In case one of the main controllers fails, events from its sub-controllers are not retrieved, and functions that require interaction between sub-controllers (i.e. anti-passback) stop working.\nSome models of sub-controllers (usually lower cost) do not have the memory or processing power to make access decisions independently. If the main controller fails, sub-controllers change to degraded mode in which doors are either completely locked or unlocked, and no events are recorded. Such sub-controllers should be avoided, or used only in areas that do not require high security.\nMain controllers tend to be expensive, therefore such a topology is not very well suited for systems with multiple remote locations that have only a few doors.\nAll other RS-485-related disadvantages listed in the first paragraph apply.\n3. Serial main controllers & intelligent readers. All door hardware is connected directly to intelligent or semi-intelligent readers. Readers usually do not make access decisions, and forward all requests to the main controller. Only if the connection to the main controller is unavailable, will the readers use their internal database to make access decisions and record events. Semi-intelligent reader that have no database and cannot function without the main controller should be used only in areas that do not require high security. Main controllers usually support from 16 to 64 readers. All advantages and disadvantages are the same as the ones listed in the second paragraph. \n\n4. Serial controllers with terminal servers. In spite of the rapid development and increasing use of computer networks, access control manufacturers remained conservative, and did not rush to introduce network-enabled products. When pressed for solutions with network connectivity, many chose the option requiring less efforts: addition of a terminal server, a device that converts serial data for transmission via LAN or WAN.\nAdvantages:\nAllows utilizing the existing network infrastructure for connecting separate segments of the system.\nProvides a convenient solution in cases when the installation of an RS-485 line would be difficult or impossible.Disadvantages:\nIncreases complexity of the system.\nCreates additional work for installers: usually terminal servers have to be configured independently, and not through the interface of the access control software.\nSerial communication link between the controller and the terminal server acts as a bottleneck: even though the data between the host PC and the terminal server travels at the 10/100/1000Mbit/sec network speed, it must slow down to the serial speed of 112.5 kbit/sec or less. There are also additional delays introduced in the process of conversion between serial and network data.All the RS-485-related advantages and disadvantages also apply.\n\n5. Network-enabled main controllers. The topology is nearly the same as described in the second and third paragraphs. The same advantages and disadvantages apply, but the on-board network interface offers a couple of valuable improvements. Transmission of configuration and user data to the main controllers is faster, and may be done in parallel. This makes the system more responsive, and does not interrupt normal operations. No special hardware is required in order to achieve redundant host PC setup: in the case that the primary host PC fails, the secondary host PC may start polling network controllers. The disadvantages introduced by terminal servers (listed in the fourth paragraph) are also eliminated. \n\n6. IP controllers. Controllers are connected to a host PC via Ethernet LAN or WAN.\nAdvantages:\nAn existing network infrastructure is fully utilized, and there is no need to install new communication lines.\nThere are no limitations regarding the number of controllers (as the 32 per line in cases of RS-485).\nSpecial RS-485 installation, termination, grounding and troubleshooting knowledge is not required.\nCommunication with the controllers may be done at the full network speed, which is important if transferring a lot of data (databases with thousands of users, possibly including biometric records).\nIn case of an alarm, controllers may initiate connection to the host PC. This ability is important in large systems, because it serves to reduce network traffic caused by unnecessary polling.\nSimplifies installation of systems consisting of multiple sites that are separated by large distances. A basic Internet link is sufficient to establish connections to the remote locations.\nWide selection of standard network equipment is available to provide connectivity in various situations (fiber, wireless, VPN, dual path, PoE)Disadvantages:\nThe system becomes susceptible to network related problems, such as delays in case of heavy traffic and network equipment failures.\nAccess controllers and workstations may become accessible to hackers if the network of the organization is not well protected. This threat may be eliminated by physically separating the access control network from the network of the organization. Most IP controllers utilize either Linux platform or proprietary operating systems, which makes them more difficult to hack. Industry standard data encryption is also used.\nMaximum distance from a hub or a switch to the controller (if using a copper cable) is 100 meters (330 ft).\nOperation of the system is dependent on the host PC. In case the host PC fails, events from controllers are not retrieved and functions that require interaction between controllers (i.e. anti-passback) stop working. Some controllers, however, have a peer-to-peer communication option in order to reduce dependency on the host PC.\n7. IP readers. Readers are connected to a host PC via Ethernet LAN or WAN.\nAdvantages:\nMost IP readers are PoE capable. This feature makes it very easy to provide battery backed power to the entire system, including the locks and various types of detectors (if used).\nIP readers eliminate the need for controller enclosures.\nThere is no wasted capacity when using IP readers (e.g. a 4-door controller would have 25% of unused capacity if it was controlling only 3 doors).\nIP reader systems scale easily: there is no need to install new main or sub-controllers.\nFailure of one IP reader does not affect any other readers in the system.Disadvantages:\nIn order to be used in high-security areas, IP readers require special input/output modules to eliminate the possibility of intrusion by accessing lock and/or exit button wiring. Not all IP reader manufacturers have such modules available.\nBeing more sophisticated than basic readers, IP readers are also more expensive and sensitive, therefore they should not be installed outdoors in areas with harsh weather conditions, or high probability of vandalism, unless specifically designed for exterior installation. A few manufacturers make such models.The advantages and disadvantages of IP controllers apply to the IP readers as well.\n\n\n*** Security risks ***\n\nThe most common security risk of intrusion through an access control system is by simply following a legitimate user through a door, and this is referred to as tailgating. Often the legitimate user will hold the door for the intruder. This risk can be minimized through security awareness training of the user population or more active means such as turnstiles. In very high-security applications this risk is minimized by using a sally port, sometimes called a security vestibule or mantrap, where operator intervention is required presumably to assure valid identification.The second most common risk is from levering a door open. This is relatively difficult on properly secured doors with strikes or high holding force magnetic locks. Fully implemented access control systems include forced door monitoring alarms. These vary in effectiveness, usually failing from high false positive alarms, poor database configuration, or lack of active intrusion monitoring. Most newer access control systems incorporate some type of door prop alarm to inform system administrators of a door left open longer than a specified length of time. The third most common security risk is natural disasters. In order to mitigate risk from natural disasters, the structure of the building, down to the quality of the network and computer equipment vital. From an organizational perspective, the leadership will need to adopt and implement an All Hazards Plan, or Incident Response Plan. The highlights of any incident plan determined by the National Incident Management System must include Pre-incident planning, during incident actions, disaster recovery, and after-action review.Similar to levering is crashing through cheap partition walls. In shared tenant spaces, the divisional wall is a vulnerability. A vulnerability along the same lines is the breaking of sidelights.Spoofing locking hardware is fairly simple and more elegant than levering. A strong magnet can operate the solenoid controlling bolts in electric locking hardware. Motor locks, more prevalent in Europe than in the US, are also susceptible to this attack using a doughnut-shaped magnet. It is also possible to manipulate the power to the lock either by removing or adding current, although most Access Control systems incorporate battery back-up systems and the locks are almost always located on the secure side of the door.Access cards themselves have proven vulnerable to sophisticated attacks. Enterprising hackers have built portable readers that capture the card number from a user's proximity card. The hacker simply walks by the user, reads the card, and then presents the number to a reader securing the door. This is possible because card numbers are sent in the clear, no encryption being used. To counter this, dual authentication methods, such as a card plus a PIN should always be used.\nMany access control credentials unique serial numbers are programmed in sequential order during manufacturing. Known as a sequential attack, if an intruder has a credential once used in the system they can simply increment or decrement the serial number until they find a credential that is currently authorized in the system. Ordering credentials with random unique serial numbers is recommended to counter this threat.Finally, most electric locking hardware still has mechanical keys as a fail-over. Mechanical key locks are vulnerable to bumping.\n\n\n**** The need-to-know principle ****\n\nThe need to know principle can be enforced with user access controls and authorization procedures and its objective is to ensure that only authorized individuals gain access to information or systems necessary to undertake their duties.\n\n== Computer security ==\n\nIn computer security, general access control includes authentication, authorization, and audit. A more narrow definition of access control would cover only access approval, whereby the system makes a decision to grant or reject an access request from an already authenticated subject, based on what the subject is authorized to access. Authentication and access control are often combined into a single operation, so that access is approved based on successful authentication, or based on an anonymous access token. Authentication methods and tokens include passwords, biometric analysis, physical keys, electronic keys and devices, hidden paths, social barriers, and monitoring by humans and automated systems.\nIn any access-control model, the entities that can perform actions on the system are called subjects, and the entities representing resources to which access may need to be controlled are called objects (see also Access Control Matrix). Subjects and objects should both be considered as software entities, rather than as human users: any human users can only have an effect on the system via the software entities that they control.Although some systems equate subjects with user IDs, so that all processes started by a user by default have the same authority, this level of control is not fine-grained enough to satisfy the principle of least privilege, and arguably is responsible for the prevalence of malware in such systems (see computer insecurity).In some models, for example the object-capability model, any software entity can potentially act as both subject and object.As of 2014, access-control models tend to fall into one of two classes: those based on capabilities and those based on access control lists (ACLs).\n\nIn a capability-based model, holding an unforgeable reference or capability to an object provides access to the object (roughly analogous to how possession of one's house key grants one access to one's house); access is conveyed to another party by transmitting such a capability over a secure channel\nIn an ACL-based model, a subject's access to an object depends on whether its identity appears on a list associated with the object (roughly analogous to how a bouncer at a private party would check an ID to see if a name appears on the guest list); access is conveyed by editing the list. (Different ACL systems have a variety of different conventions regarding who or what is responsible for editing the list and how it is edited.)Both capability-based and ACL-based models have mechanisms to allow access rights to be granted to all members of a group of subjects (often the group is itself modeled as a subject).Access control systems provide the essential services of authorization, identification and authentication (I&A),  access approval, and accountability where:\nauthorization specifies what a subject can do\nidentification and authentication ensure that only legitimate subjects can log on to a system\naccess approval grants access during operations, by association of users with the resources that they are allowed to access, based on the authorization policy\naccountability identifies what a subject (or all subjects associated with a user) did\n\n\n*** Access control models ***\nAccess to accounts can be enforced through many types of controls.\nAttribute-based Access Control (ABAC) An access control paradigm whereby access rights are granted to users through the use of policies which evaluate attributes (user attributes, resource attributes and environment conditions)\nDiscretionary Access Control (DAC)In DAC, the data owner determines who can access specific resources. For example, a system administrator may create a hierarchy of files to be accessed based on certain permissions.\nGraph-based Access Control (GBAC)Compared to other approaches like RBAC or ABAC, the main difference is that in GBAC access rights are defined using an organizational query language instead of total enumeration.\nHistory-Based Access Control (HBAC)Access is granted or declined based on the real-time evaluation of a history of activities of the inquiring party, e.g. behavior, time between requests, content of requests. For example, the access to a certain service or data source can be granted or declined on the personal behavior, e.g. the request interval exceeds one query per second.\nHistory-of-Presence Based Access Control (HPBAC)Access control to resources is defined in terms of presence policies that need to be satisfied by presence records stored by the requestor. Policies are usually written in terms of frequency, spread and regularity. An example policy would be \"The requestor has made k separate visitations, all within last week, and no two consecutive visitations are apart by more than T hours.\"\nIdentity-Based Access Control (IBAC)Using this network administrators can more effectively manage activity and access based on individual needs.\nLattice-Based Access Control (LBAC)A lattice is used to define the levels of security that an object may have and that a subject may have access to. The subject is only allowed to access an object if the security level of the subject is greater than or equal to that of the object.\nMandatory Access Control (MAC)In MAC, users do not have much freedom to determine who has access to their files. For example, security clearance of users and classification of data (as confidential, secret or top secret) are used as security labels to define the level of trust.\nOrganization-Based Access Control (OrBAC)  OrBAC model allows the policy designer to define a security policy independently of the implementation\nRole-Based Access Control (RBAC)RBAC allows access based on the job title. RBAC largely eliminates discretion when providing access to objects. For example, a human resources specialist should not have permissions to create network accounts; this should be a role reserved for network administrators.\nRule-Based Access Control (RAC)RAC method, also referred to as Rule-Based Role-Based Access Control (RB-RBAC), is largely context based. Example of this would be allowing students to use labs only during a certain time of day; it is the combination of students' RBAC-based information system access control with the time-based lab access rules.\nResponsibility Based Access Control  Information is accessed based on the responsibilities assigned to an actor or a business role\n\n== Telecommunication ==\nIn telecommunication, the term access control is defined in U.S. Federal Standard 1037C with the following meanings: \n\nA service feature or technique used to permit or deny use of the components of a communication system.\nA technique used to define or restrict the rights of individuals or application programs to obtain data from, or place data onto, a storage device.\nThe definition or restriction of the rights of individuals or application programs to obtain data from, or place data into, a storage device.\nThe process of limiting access to the resources of an AIS (Automated Information System) to authorized users, programs, processes, or other systems.\nThat function performed by the resource controller that allocates system resources to satisfy user requests.This definition depends on several other technical terms from Federal Standard 1037C.\n\n\n*** Attribute accessors ***\nSpecial public member methods \u2013 accessors (aka getters) and mutator methods (often called setters) are used to control changes to class variables in order to prevent unauthorized access and data corruption.\n\n== Public policy ==\nIn public policy, access control to restrict access to systems (\"authorization\") or to track or monitor behavior within systems (\"accountability\") is an implementation feature of using trusted systems for security or social control. Answer this question using the following article:\n\nWhat is Role-Based Access Control (RBAC) in computer security?",
    "context": "",
    "output": "Role-Based Access Control (RBAC) is an access control paradigm that allows access based on the job title.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is Role-Based Access Control (RBAC) in computer security?",
      "answer": "Role-Based Access Control (RBAC) is an access control paradigm that allows access based on the job title.",
      "context": "Access control\n\n==Introduction==\nIn physical security and information security, access control (AC) is the selective restriction of access to a place or other resource, while access management describes the process. The act of accessing may mean consuming, entering, or using. Permission to access a resource is called authorization.\nLocks and login credentials are two analogous mechanisms of access control.\n\n\n\n== Physical security ==\n\nGeographical access control may be enforced by personnel (e.g. border guard, bouncer, ticket checker), or with a device such as a turnstile. There may be fences to avoid circumventing this access control. An alternative of access control in the strict sense (physically controlling access itself) is a system of checking authorized presence, see e.g. Ticket controller (transportation). A variant is exit control, e.g. of a shop (checkout) or a country.The term access control refers to the practice of restricting entrance to a property, a building, or a room to authorized persons. Physical access control can be achieved by a human (a guard, bouncer, or receptionist), through mechanical means such as locks and keys, or through technological means such as access control systems like the mantrap. Within these environments, physical key management may also be employed as a means of further managing and monitoring access to mechanically keyed areas or access to certain small assets.Physical access control is a matter of who, where, and when. An access control system determines who is allowed to enter or exit, where they are allowed to exit or enter, and when they are allowed to enter or exit. Historically, this was partially accomplished through keys and locks. When a door is locked, only someone with a key can enter through the door, depending on how the lock is configured. Mechanical locks and keys do not allow restriction of the key holder to specific times or dates. Mechanical locks and keys do not provide records of the key used on any specific door, and the keys can be easily copied or transferred to an unauthorized person. When a mechanical key is lost or the key holder is no longer authorized to use the protected area, the locks must be re-keyed.\n\n\n*** Electronic access control ***\n\nElectronic access control (EAC) uses computers to solve the limitations of mechanical locks and keys. A wide range of credentials can be used to replace mechanical keys. The electronic access control system grants access based on the credential presented. When access is granted, the door is unlocked for a predetermined time and the transaction is recorded. When access is refused, the door remains locked and the attempted access is recorded. The system will also monitor the door and alarm if the door is forced open or held open too long after being unlocked.When a credential is presented to a reader, the reader sends the credential's information, usually a number, to a control panel, a highly reliable processor. The control panel compares the credential's number to an access control list, grants or denies the presented request, and sends a transaction log to a database. When access is denied based on the access control list, the door remains locked. If there is a match between the credential and the access control list, the control panel operates a relay that in turn unlocks the door. The control panel also ignores a door open signal to prevent an alarm. Often the reader provides feedback, such as a flashing red LED for an access denied and a flashing green LED for an access granted.The above description illustrates a single factor transaction. Credentials can be passed around, thus subverting the access control list. For example, Alice has access rights to the server room, but Bob does not. Alice either gives Bob her credential, or Bob takes it; he now has access to the server room. To prevent this, two-factor authentication can be used. In a two factor transaction, the presented credential and a second factor are needed for access to be granted; another factor can be a PIN, a second credential, operator intervention, or a biometric input.There are three types (factors) of authenticating information:\nsomething the user knows, e.g. a password, pass-phrase or PIN\nsomething the user has, such as smart card or a key fob\nsomething the user is, such as the users fingerprint, verified by biometric measurementPasswords are a common means of verifying a user's identity before access is given to information systems.  In addition, a fourth factor of authentication is now recognized: someone you know, whereby another person who knows you can provide a human element of authentication in situations where systems have been set up to allow for such scenarios.  For example, a user may have their password, but have forgotten their smart card.  In such a scenario, if the user is known to designated cohorts, the cohorts may provide their smart card and password, in combination with the extant factor of the user in question, and thus provide two factors for the user with the missing credential, giving three factors overall to allow access.\n\n\n*** Credential ***\nA credential is a physical/tangible object, a piece of knowledge, or a facet of a person's physical being that enables an individual access to a given physical facility or computer-based information system.  Typically, credentials can be something a person knows (such as a number or PIN), something they have (such as an access badge), something they are (such as a biometric feature), something they do (measurable behavioural patterns), or some combination of these items. This is known as multi-factor authentication. The typical credential is an access card or key-fob, and newer software can also turn users' smartphones into access devices.There are many card technologies including magnetic stripe, bar code, Wiegand, 125 kHz proximity, 26-bit card-swipe, contact smart cards, and contactless smart cards. Also available are key-fobs, which are more compact than ID cards, and attach to a key ring. Biometric technologies include fingerprint, facial recognition, iris recognition, retinal scan, voice, and hand geometry.  The built-in biometric technologies found on newer smartphones can also be used as credentials in conjunction with access software running on mobile devices. In addition to older more traditional card access technologies, newer technologies such as Near field communication (NFC), Bluetooth low energy or Ultra-wideband (UWB) can also communicate user credentials to readers for system or building access.\n\n\n*** Access control system components ***\n\nComponents of an access control system include:\n\nAn access control panel (also known as a controller)\nAn access-controlled entry, such as a door, turnstile, parking gate, elevator, or other physical barrier\nA reader installed near the entry. (In cases where the exit is also controlled, a second reader is used on the opposite side of the entry.)\nLocking hardware, such as electric door strikes and electromagnetic locks\nA magnetic door switch for monitoring door position\nRequest-to-exit (RTE) devices for allowing egress. When a RTE button is pushed, or the motion detector detects motion at the door, the door alarm is temporarily ignored while the door is opened. Exiting a door without having to electrically unlock the door is called mechanical free egress. This is an important safety feature. In cases where the lock must be electrically unlocked on exit, the request-to-exit device also unlocks the door.\n\n\n*** Access control topology ***\n\nAccess control decisions are made by comparing the credentials to an access control list. This look-up can be done by a host or server, by an access control panel, or by a reader. The development of access control systems has observed a steady push of the look-up out from a central host to the edge of the system, or the reader. The predominant topology circa 2009 is hub and spoke with a control panel as the hub, and the readers as the spokes. The look-up and control functions are by the control panel. The spokes communicate through a serial connection; usually RS-485. Some manufactures are pushing the decision making to the edge by placing a controller at the door. The controllers are IP enabled, and connect to a host and database using standard networks\n\n\n*** Types of readers ***\nAccess control readers may be classified by the functions they are able to perform:\nBasic (non-intelligent) readers: simply read card number or PIN, and forward it to a control panel. In case of biometric identification, such readers output the ID number of a user. Typically, Wiegand protocol is used for transmitting data to the control panel, but other options such as RS-232, RS-485 and Clock/Data are not uncommon. This is the most popular type of access control readers. Examples of such readers are RF Tiny by RFLOGICS, ProxPoint by HID, and P300 by Farpointe Data.\nSemi-intelligent readers: have all inputs and outputs necessary to control door hardware (lock, door contact, exit button), but do not make any access decisions. When a user presents a card or enters a PIN, the reader sends information to the main controller, and waits for its response. If the connection to the main controller is interrupted, such readers stop working, or function in a degraded mode. Usually semi-intelligent readers are connected to a control panel via an RS-485 bus. Examples of such readers are InfoProx Lite IPL200 by CEM Systems, and AP-510 by Apollo.\nIntelligent readers: have all inputs and outputs necessary to control door hardware; they also have memory and processing power necessary to make access decisions independently. Like semi-intelligent readers, they are connected to a control panel via an RS-485 bus. The control panel sends configuration updates, and retrieves events from the readers. Examples of such readers could be InfoProx IPO200 by CEM Systems, and AP-500 by Apollo. There is also a new generation of intelligent readers referred to as \"IP readers\". Systems with IP readers usually do not have traditional control panels, and readers communicate directly to a PC that acts as a host.Some readers may have additional features such as an LCD and function buttons for data collection purposes (i.e. clock-in/clock-out events for attendance reports), camera/speaker/microphone for intercom, and smart card read/write support.\n\n\n*** Access control system topologies ***\n\n1. Serial controllers. Controllers are connected to a host PC via a serial RS-485 communication line (or via 20mA current loop in some older systems). External RS-232/485 converters or internal RS-485 cards have to be installed, as standard PCs do not have RS-485 communication ports.Advantages:\nRS-485 standard allows long cable runs, up to 4000 feet (1200 m)\nRelatively short response time. The maximum number of devices on an RS-485 line is limited to 32, which means that the host can frequently request status updates from each device, and display events almost in real time.\nHigh reliability and security as the communication line is not shared with any other systems.Disadvantages:\nRS-485 does not allow Star-type wiring unless splitters are used\nRS-485 is not well suited for transferring large amounts of data (i.e. configuration and users). The highest possible throughput is 115.2 kbit/sec, but in most system it is downgraded to 56.2 kbit/sec, or less, to increase reliability.\nRS-485 does not allow the host PC to communicate with several controllers connected to the same port simultaneously. Therefore, in large systems, transfers of configuration, and users to controllers may take a very long time, interfering with normal operations.\nControllers cannot initiate communication in case of an alarm. The host PC acts as a master on the RS-485 communication line, and controllers have to wait until they are polled.\nSpecial serial switches are required, in order to build a redundant host PC setup.\nSeparate RS-485 lines have to be installed, instead of using an already existing network infrastructure.\nCable that meets RS-485 standards is significantly more expensive than regular Category 5 UTP network cable.\nOperation of the system is highly dependent on the host PC. In the case that the host PC fails, events from controllers are not retrieved, and functions that require interaction between controllers (i.e. anti-passback) stop working.\n2. Serial main and sub-controllers. All door hardware is connected to sub-controllers (a.k.a. door controllers or door interfaces). Sub-controllers usually do not make access decisions, and instead forward all requests to the main controllers. Main controllers usually support from 16 to 32 sub-controllers.\nAdvantages:\nWork load on the host PC is significantly reduced, because it only needs to communicate with a few main controllers.\nThe overall cost of the system is lower, as sub-controllers are usually simple and inexpensive devices.\nAll other advantages listed in the first paragraph apply.Disadvantages:\nOperation of the system is highly dependent on main controllers. In case one of the main controllers fails, events from its sub-controllers are not retrieved, and functions that require interaction between sub-controllers (i.e. anti-passback) stop working.\nSome models of sub-controllers (usually lower cost) do not have the memory or processing power to make access decisions independently. If the main controller fails, sub-controllers change to degraded mode in which doors are either completely locked or unlocked, and no events are recorded. Such sub-controllers should be avoided, or used only in areas that do not require high security.\nMain controllers tend to be expensive, therefore such a topology is not very well suited for systems with multiple remote locations that have only a few doors.\nAll other RS-485-related disadvantages listed in the first paragraph apply.\n3. Serial main controllers & intelligent readers. All door hardware is connected directly to intelligent or semi-intelligent readers. Readers usually do not make access decisions, and forward all requests to the main controller. Only if the connection to the main controller is unavailable, will the readers use their internal database to make access decisions and record events. Semi-intelligent reader that have no database and cannot function without the main controller should be used only in areas that do not require high security. Main controllers usually support from 16 to 64 readers. All advantages and disadvantages are the same as the ones listed in the second paragraph. \n\n4. Serial controllers with terminal servers. In spite of the rapid development and increasing use of computer networks, access control manufacturers remained conservative, and did not rush to introduce network-enabled products. When pressed for solutions with network connectivity, many chose the option requiring less efforts: addition of a terminal server, a device that converts serial data for transmission via LAN or WAN.\nAdvantages:\nAllows utilizing the existing network infrastructure for connecting separate segments of the system.\nProvides a convenient solution in cases when the installation of an RS-485 line would be difficult or impossible.Disadvantages:\nIncreases complexity of the system.\nCreates additional work for installers: usually terminal servers have to be configured independently, and not through the interface of the access control software.\nSerial communication link between the controller and the terminal server acts as a bottleneck: even though the data between the host PC and the terminal server travels at the 10/100/1000Mbit/sec network speed, it must slow down to the serial speed of 112.5 kbit/sec or less. There are also additional delays introduced in the process of conversion between serial and network data.All the RS-485-related advantages and disadvantages also apply.\n\n5. Network-enabled main controllers. The topology is nearly the same as described in the second and third paragraphs. The same advantages and disadvantages apply, but the on-board network interface offers a couple of valuable improvements. Transmission of configuration and user data to the main controllers is faster, and may be done in parallel. This makes the system more responsive, and does not interrupt normal operations. No special hardware is required in order to achieve redundant host PC setup: in the case that the primary host PC fails, the secondary host PC may start polling network controllers. The disadvantages introduced by terminal servers (listed in the fourth paragraph) are also eliminated. \n\n6. IP controllers. Controllers are connected to a host PC via Ethernet LAN or WAN.\nAdvantages:\nAn existing network infrastructure is fully utilized, and there is no need to install new communication lines.\nThere are no limitations regarding the number of controllers (as the 32 per line in cases of RS-485).\nSpecial RS-485 installation, termination, grounding and troubleshooting knowledge is not required.\nCommunication with the controllers may be done at the full network speed, which is important if transferring a lot of data (databases with thousands of users, possibly including biometric records).\nIn case of an alarm, controllers may initiate connection to the host PC. This ability is important in large systems, because it serves to reduce network traffic caused by unnecessary polling.\nSimplifies installation of systems consisting of multiple sites that are separated by large distances. A basic Internet link is sufficient to establish connections to the remote locations.\nWide selection of standard network equipment is available to provide connectivity in various situations (fiber, wireless, VPN, dual path, PoE)Disadvantages:\nThe system becomes susceptible to network related problems, such as delays in case of heavy traffic and network equipment failures.\nAccess controllers and workstations may become accessible to hackers if the network of the organization is not well protected. This threat may be eliminated by physically separating the access control network from the network of the organization. Most IP controllers utilize either Linux platform or proprietary operating systems, which makes them more difficult to hack. Industry standard data encryption is also used.\nMaximum distance from a hub or a switch to the controller (if using a copper cable) is 100 meters (330 ft).\nOperation of the system is dependent on the host PC. In case the host PC fails, events from controllers are not retrieved and functions that require interaction between controllers (i.e. anti-passback) stop working. Some controllers, however, have a peer-to-peer communication option in order to reduce dependency on the host PC.\n7. IP readers. Readers are connected to a host PC via Ethernet LAN or WAN.\nAdvantages:\nMost IP readers are PoE capable. This feature makes it very easy to provide battery backed power to the entire system, including the locks and various types of detectors (if used).\nIP readers eliminate the need for controller enclosures.\nThere is no wasted capacity when using IP readers (e.g. a 4-door controller would have 25% of unused capacity if it was controlling only 3 doors).\nIP reader systems scale easily: there is no need to install new main or sub-controllers.\nFailure of one IP reader does not affect any other readers in the system.Disadvantages:\nIn order to be used in high-security areas, IP readers require special input/output modules to eliminate the possibility of intrusion by accessing lock and/or exit button wiring. Not all IP reader manufacturers have such modules available.\nBeing more sophisticated than basic readers, IP readers are also more expensive and sensitive, therefore they should not be installed outdoors in areas with harsh weather conditions, or high probability of vandalism, unless specifically designed for exterior installation. A few manufacturers make such models.The advantages and disadvantages of IP controllers apply to the IP readers as well.\n\n\n*** Security risks ***\n\nThe most common security risk of intrusion through an access control system is by simply following a legitimate user through a door, and this is referred to as tailgating. Often the legitimate user will hold the door for the intruder. This risk can be minimized through security awareness training of the user population or more active means such as turnstiles. In very high-security applications this risk is minimized by using a sally port, sometimes called a security vestibule or mantrap, where operator intervention is required presumably to assure valid identification.The second most common risk is from levering a door open. This is relatively difficult on properly secured doors with strikes or high holding force magnetic locks. Fully implemented access control systems include forced door monitoring alarms. These vary in effectiveness, usually failing from high false positive alarms, poor database configuration, or lack of active intrusion monitoring. Most newer access control systems incorporate some type of door prop alarm to inform system administrators of a door left open longer than a specified length of time. The third most common security risk is natural disasters. In order to mitigate risk from natural disasters, the structure of the building, down to the quality of the network and computer equipment vital. From an organizational perspective, the leadership will need to adopt and implement an All Hazards Plan, or Incident Response Plan. The highlights of any incident plan determined by the National Incident Management System must include Pre-incident planning, during incident actions, disaster recovery, and after-action review.Similar to levering is crashing through cheap partition walls. In shared tenant spaces, the divisional wall is a vulnerability. A vulnerability along the same lines is the breaking of sidelights.Spoofing locking hardware is fairly simple and more elegant than levering. A strong magnet can operate the solenoid controlling bolts in electric locking hardware. Motor locks, more prevalent in Europe than in the US, are also susceptible to this attack using a doughnut-shaped magnet. It is also possible to manipulate the power to the lock either by removing or adding current, although most Access Control systems incorporate battery back-up systems and the locks are almost always located on the secure side of the door.Access cards themselves have proven vulnerable to sophisticated attacks. Enterprising hackers have built portable readers that capture the card number from a user's proximity card. The hacker simply walks by the user, reads the card, and then presents the number to a reader securing the door. This is possible because card numbers are sent in the clear, no encryption being used. To counter this, dual authentication methods, such as a card plus a PIN should always be used.\nMany access control credentials unique serial numbers are programmed in sequential order during manufacturing. Known as a sequential attack, if an intruder has a credential once used in the system they can simply increment or decrement the serial number until they find a credential that is currently authorized in the system. Ordering credentials with random unique serial numbers is recommended to counter this threat.Finally, most electric locking hardware still has mechanical keys as a fail-over. Mechanical key locks are vulnerable to bumping.\n\n\n**** The need-to-know principle ****\n\nThe need to know principle can be enforced with user access controls and authorization procedures and its objective is to ensure that only authorized individuals gain access to information or systems necessary to undertake their duties.\n\n== Computer security ==\n\nIn computer security, general access control includes authentication, authorization, and audit. A more narrow definition of access control would cover only access approval, whereby the system makes a decision to grant or reject an access request from an already authenticated subject, based on what the subject is authorized to access. Authentication and access control are often combined into a single operation, so that access is approved based on successful authentication, or based on an anonymous access token. Authentication methods and tokens include passwords, biometric analysis, physical keys, electronic keys and devices, hidden paths, social barriers, and monitoring by humans and automated systems.\nIn any access-control model, the entities that can perform actions on the system are called subjects, and the entities representing resources to which access may need to be controlled are called objects (see also Access Control Matrix). Subjects and objects should both be considered as software entities, rather than as human users: any human users can only have an effect on the system via the software entities that they control.Although some systems equate subjects with user IDs, so that all processes started by a user by default have the same authority, this level of control is not fine-grained enough to satisfy the principle of least privilege, and arguably is responsible for the prevalence of malware in such systems (see computer insecurity).In some models, for example the object-capability model, any software entity can potentially act as both subject and object.As of 2014, access-control models tend to fall into one of two classes: those based on capabilities and those based on access control lists (ACLs).\n\nIn a capability-based model, holding an unforgeable reference or capability to an object provides access to the object (roughly analogous to how possession of one's house key grants one access to one's house); access is conveyed to another party by transmitting such a capability over a secure channel\nIn an ACL-based model, a subject's access to an object depends on whether its identity appears on a list associated with the object (roughly analogous to how a bouncer at a private party would check an ID to see if a name appears on the guest list); access is conveyed by editing the list. (Different ACL systems have a variety of different conventions regarding who or what is responsible for editing the list and how it is edited.)Both capability-based and ACL-based models have mechanisms to allow access rights to be granted to all members of a group of subjects (often the group is itself modeled as a subject).Access control systems provide the essential services of authorization, identification and authentication (I&A),  access approval, and accountability where:\nauthorization specifies what a subject can do\nidentification and authentication ensure that only legitimate subjects can log on to a system\naccess approval grants access during operations, by association of users with the resources that they are allowed to access, based on the authorization policy\naccountability identifies what a subject (or all subjects associated with a user) did\n\n\n*** Access control models ***\nAccess to accounts can be enforced through many types of controls.\nAttribute-based Access Control (ABAC) An access control paradigm whereby access rights are granted to users through the use of policies which evaluate attributes (user attributes, resource attributes and environment conditions)\nDiscretionary Access Control (DAC)In DAC, the data owner determines who can access specific resources. For example, a system administrator may create a hierarchy of files to be accessed based on certain permissions.\nGraph-based Access Control (GBAC)Compared to other approaches like RBAC or ABAC, the main difference is that in GBAC access rights are defined using an organizational query language instead of total enumeration.\nHistory-Based Access Control (HBAC)Access is granted or declined based on the real-time evaluation of a history of activities of the inquiring party, e.g. behavior, time between requests, content of requests. For example, the access to a certain service or data source can be granted or declined on the personal behavior, e.g. the request interval exceeds one query per second.\nHistory-of-Presence Based Access Control (HPBAC)Access control to resources is defined in terms of presence policies that need to be satisfied by presence records stored by the requestor. Policies are usually written in terms of frequency, spread and regularity. An example policy would be \"The requestor has made k separate visitations, all within last week, and no two consecutive visitations are apart by more than T hours.\"\nIdentity-Based Access Control (IBAC)Using this network administrators can more effectively manage activity and access based on individual needs.\nLattice-Based Access Control (LBAC)A lattice is used to define the levels of security that an object may have and that a subject may have access to. The subject is only allowed to access an object if the security level of the subject is greater than or equal to that of the object.\nMandatory Access Control (MAC)In MAC, users do not have much freedom to determine who has access to their files. For example, security clearance of users and classification of data (as confidential, secret or top secret) are used as security labels to define the level of trust.\nOrganization-Based Access Control (OrBAC)  OrBAC model allows the policy designer to define a security policy independently of the implementation\nRole-Based Access Control (RBAC)RBAC allows access based on the job title. RBAC largely eliminates discretion when providing access to objects. For example, a human resources specialist should not have permissions to create network accounts; this should be a role reserved for network administrators.\nRule-Based Access Control (RAC)RAC method, also referred to as Rule-Based Role-Based Access Control (RB-RBAC), is largely context based. Example of this would be allowing students to use labs only during a certain time of day; it is the combination of students' RBAC-based information system access control with the time-based lab access rules.\nResponsibility Based Access Control  Information is accessed based on the responsibilities assigned to an actor or a business role\n\n== Telecommunication ==\nIn telecommunication, the term access control is defined in U.S. Federal Standard 1037C with the following meanings: \n\nA service feature or technique used to permit or deny use of the components of a communication system.\nA technique used to define or restrict the rights of individuals or application programs to obtain data from, or place data onto, a storage device.\nThe definition or restriction of the rights of individuals or application programs to obtain data from, or place data into, a storage device.\nThe process of limiting access to the resources of an AIS (Automated Information System) to authorized users, programs, processes, or other systems.\nThat function performed by the resource controller that allocates system resources to satisfy user requests.This definition depends on several other technical terms from Federal Standard 1037C.\n\n\n*** Attribute accessors ***\nSpecial public member methods \u2013 accessors (aka getters) and mutator methods (often called setters) are used to control changes to class variables in order to prevent unauthorized access and data corruption.\n\n== Public policy ==\nIn public policy, access control to restrict access to systems (\"authorization\") or to track or monitor behavior within systems (\"accountability\") is an implementation feature of using trusted systems for security or social control."
    }
  },
  {
    "instruction": "Not all email clients support indexing of encrypted messages' clear text, which can be a potential dilemma for users.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does S/MIME affect the indexing of encrypted messages' clear text?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does S/MIME affect the indexing of encrypted messages' clear text?",
      "answer": "Not all email clients support indexing of encrypted messages' clear text, which can be a potential dilemma for users."
    }
  },
  {
    "instruction": "Almost 40 tons of drugs were seized during the ANOM sting operation in Australia, including over eight tons of cocaine, 22 tons of cannabis and cannabis resin, six tons of synthetic drug precursors, and two tons of synthetic drugs.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How many tons of drugs were seized during the ANOM sting operation in Australia?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How many tons of drugs were seized during the ANOM sting operation in Australia?",
      "answer": "Almost 40 tons of drugs were seized during the ANOM sting operation in Australia, including over eight tons of cocaine, 22 tons of cannabis and cannabis resin, six tons of synthetic drug precursors, and two tons of synthetic drugs."
    }
  },
  {
    "instruction": "The location of the Chaos Communication Congress is not specified in the text.\n\nWrite a question about the text above.",
    "context": "",
    "output": "In what city does the Chaos Communication Congress take place?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "In what city does the Chaos Communication Congress take place?",
      "answer": "The location of the Chaos Communication Congress is not specified in the text."
    }
  },
  {
    "instruction": "WOT Services collected personal user details, such as websites visited, account names, email addresses, and potentially sensitive information like user illnesses, sexual preferences, and drug consumption. This information was sold or licensed to unidentified third-party businesses and entities for data monetization purposes.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What information did WOT Services collect and sell to third parties in violation of its privacy policies?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What information did WOT Services collect and sell to third parties in violation of its privacy policies?",
      "answer": "WOT Services collected personal user details, such as websites visited, account names, email addresses, and potentially sensitive information like user illnesses, sexual preferences, and drug consumption. This information was sold or licensed to unidentified third-party businesses and entities for data monetization purposes."
    }
  },
  {
    "instruction": "The computational security parameter is expressed in unary representation, as a string of \u03ba 1s. This allows for the time complexity of the cryptographic algorithm to be polynomial in the size of the input.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How is the computational security parameter related to the time complexity of a cryptographic algorithm?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How is the computational security parameter related to the time complexity of a cryptographic algorithm?",
      "answer": "The computational security parameter is expressed in unary representation, as a string of \u03ba 1s. This allows for the time complexity of the cryptographic algorithm to be polynomial in the size of the input."
    }
  },
  {
    "instruction": "OV-net relies on the hardness of the discrete logarithm problem. It utilizes a group G with a generator g of prime order q, where it is computationally difficult to determine the discrete logarithm.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What underlying mathematical problem is used in OV-net to guarantee the secrecy of input bits?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What underlying mathematical problem is used in OV-net to guarantee the secrecy of input bits?",
      "answer": "OV-net relies on the hardness of the discrete logarithm problem. It utilizes a group G with a generator g of prime order q, where it is computationally difficult to determine the discrete logarithm."
    }
  },
  {
    "instruction": "The condition that for any probabilistic polynomial algorithm A, the probability of finding a collision is small is important for ensuring the collision resistance of the hash function. If it were easy to find collisions, an attacker could potentially use this vulnerability to undermine the security of the hash function.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the significance of the condition that for any probabilistic polynomial algorithm A, the probability of finding a collision is small?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the significance of the condition that for any probabilistic polynomial algorithm A, the probability of finding a collision is small?",
      "answer": "The condition that for any probabilistic polynomial algorithm A, the probability of finding a collision is small is important for ensuring the collision resistance of the hash function. If it were easy to find collisions, an attacker could potentially use this vulnerability to undermine the security of the hash function."
    }
  },
  {
    "instruction": "Unlike a traditional computer virus, Bolgimo is a worm, which means it can self-replicate and spread without requiring user interaction or the opening of infected files.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does Bolgimo differ from a traditional computer virus?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does Bolgimo differ from a traditional computer virus?",
      "answer": "Unlike a traditional computer virus, Bolgimo is a worm, which means it can self-replicate and spread without requiring user interaction or the opening of infected files."
    }
  },
  {
    "instruction": "Security Device Event Exchange\n\n==Introduction==\nSecurity Device Event Exchange (SDEE) is a new standard proposed by the International Computer Security Association that specifies the format of messages and protocol used to communicate events generated by security devices.\nThis protocol is used in the Cisco Systems IPS Sensor 5.0 to replace Remote Data Exchange Protocol (RDEP), which is used by earlier versions of the Cisco IDS Sensor.\n\n\n\n Answer this question using the following article:\n\nHow does the Security Device Event Exchange (SDEE) protocol differ from the Remote Data Exchange Protocol (RDEP) in terms of the types of security devices they communicate with?",
    "context": "",
    "output": "SDEE is a newer standard than RDEP and is specifically designed for communication between security devices, whereas RDEP was used in earlier versions of the Cisco IDS Sensor. SDEE is proposed by the International Computer Security Association, which suggests that it has a broader scope and support than RDEP.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does the Security Device Event Exchange (SDEE) protocol differ from the Remote Data Exchange Protocol (RDEP) in terms of the types of security devices they communicate with?",
      "answer": "SDEE is a newer standard than RDEP and is specifically designed for communication between security devices, whereas RDEP was used in earlier versions of the Cisco IDS Sensor. SDEE is proposed by the International Computer Security Association, which suggests that it has a broader scope and support than RDEP.",
      "context": "Security Device Event Exchange\n\n==Introduction==\nSecurity Device Event Exchange (SDEE) is a new standard proposed by the International Computer Security Association that specifies the format of messages and protocol used to communicate events generated by security devices.\nThis protocol is used in the Cisco Systems IPS Sensor 5.0 to replace Remote Data Exchange Protocol (RDEP), which is used by earlier versions of the Cisco IDS Sensor.\n\n\n\n"
    }
  },
  {
    "instruction": "Context: Comparison of cryptography libraries\n\n==Introduction==\nThe tables below compare cryptography libraries that deal with cryptography algorithms and have API function calls to each of the supported features.\n\n== Cryptography libraries ==\n\n== FIPS 140 ==\nThis table denotes, if a cryptography library provides the technical requisites for FIPS 140, and the status of their FIPS 140 certification (according to NIST's CMVP search, modules in process list and implementation under test list).\n\n== Key operations ==\nKey operations include key generation algorithms, key exchange agreements and public key cryptography standards.\n\n\n*** Public key algorithms ***\n\n\n*** Elliptic-curve cryptography (ECC) support ***\n\n\n*** Public key cryptography standards ***\n\n== Hash functions ==\nComparison of supported cryptographic hash functions. Here hash functions are defined as taking an arbitrary length message and producing a fixed size output that is virtually impossible to use for recreating the original message.\n\n== MAC algorithms ==\nComparison of implementations of message authentication code (MAC) algorithms. A MAC is a short piece of information used to authenticate a message\u2014in other words, to confirm that the message came from the stated sender (its authenticity) and has not been changed in transit (its integrity).\n\n== Block ciphers ==\nTable compares implementations of block ciphers. Block ciphers are defined as being deterministic and operating on a set number of bits (termed a block) using a symmetric key. \nEach block cipher can be broken up into the possible key sizes and block cipher modes it can be run with.\n\n\n*** Block cipher algorithms ***\n\n\n*** Cipher modes ***\n\n== Stream ciphers ==\nThe table below shows the support of various stream ciphers. Stream ciphers are defined as using plain text digits that are combined with a pseudorandom cipher digit stream. Stream ciphers are typically faster than block ciphers and may have lower hardware complexity, but may be more susceptible to attacks.\n\n== Hardware-assisted support ==\nThese tables compare the ability to utilize hardware enhanced cryptography.  By using the assistance of specific hardware the library can achieve greater speeds and / or improved security than otherwise.\n\n\n*** Smart card, SIM and HSM protocol support ***\n\n\n*** General purpose CPU / platform acceleration support ***\n\n== Code size and code to comment ratio ==\n\n== Portability ==\nQuestion: What is the code size and code to comment ratio of these cryptography libraries, and what does it indicate about their complexity and efficiency?. Whats the answer?",
    "context": "",
    "output": "The Code size and code to comment ratio table in the given text compares the size of the code and the ratio of code to comments in different cryptography libraries. A lower ratio of code to comments indicates a more complex and less efficient codebase.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the code size and code to comment ratio of these cryptography libraries, and what does it indicate about their complexity and efficiency?",
      "answer": "The Code size and code to comment ratio table in the given text compares the size of the code and the ratio of code to comments in different cryptography libraries. A lower ratio of code to comments indicates a more complex and less efficient codebase.",
      "context": "Comparison of cryptography libraries\n\n==Introduction==\nThe tables below compare cryptography libraries that deal with cryptography algorithms and have API function calls to each of the supported features.\n\n== Cryptography libraries ==\n\n== FIPS 140 ==\nThis table denotes, if a cryptography library provides the technical requisites for FIPS 140, and the status of their FIPS 140 certification (according to NIST's CMVP search, modules in process list and implementation under test list).\n\n== Key operations ==\nKey operations include key generation algorithms, key exchange agreements and public key cryptography standards.\n\n\n*** Public key algorithms ***\n\n\n*** Elliptic-curve cryptography (ECC) support ***\n\n\n*** Public key cryptography standards ***\n\n== Hash functions ==\nComparison of supported cryptographic hash functions. Here hash functions are defined as taking an arbitrary length message and producing a fixed size output that is virtually impossible to use for recreating the original message.\n\n== MAC algorithms ==\nComparison of implementations of message authentication code (MAC) algorithms. A MAC is a short piece of information used to authenticate a message\u2014in other words, to confirm that the message came from the stated sender (its authenticity) and has not been changed in transit (its integrity).\n\n== Block ciphers ==\nTable compares implementations of block ciphers. Block ciphers are defined as being deterministic and operating on a set number of bits (termed a block) using a symmetric key. \nEach block cipher can be broken up into the possible key sizes and block cipher modes it can be run with.\n\n\n*** Block cipher algorithms ***\n\n\n*** Cipher modes ***\n\n== Stream ciphers ==\nThe table below shows the support of various stream ciphers. Stream ciphers are defined as using plain text digits that are combined with a pseudorandom cipher digit stream. Stream ciphers are typically faster than block ciphers and may have lower hardware complexity, but may be more susceptible to attacks.\n\n== Hardware-assisted support ==\nThese tables compare the ability to utilize hardware enhanced cryptography.  By using the assistance of specific hardware the library can achieve greater speeds and / or improved security than otherwise.\n\n\n*** Smart card, SIM and HSM protocol support ***\n\n\n*** General purpose CPU / platform acceleration support ***\n\n== Code size and code to comment ratio ==\n\n== Portability =="
    }
  },
  {
    "instruction": "NIST, in consultation with CISA and OMB, has delivered guidance for users of critical software (4i) and for minimum vendor testing of the security and integrity of the software supply chain (4r). Guidelines for enhancing supply chain software security (4c) and enhancing supply chain software (4e, 4s, 4t, 4u) will be delivered on days 180 and 270, respectively.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How can organizations ensure the security and integrity of their software supply chain?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How can organizations ensure the security and integrity of their software supply chain?",
      "answer": "NIST, in consultation with CISA and OMB, has delivered guidance for users of critical software (4i) and for minimum vendor testing of the security and integrity of the software supply chain (4r). Guidelines for enhancing supply chain software security (4c) and enhancing supply chain software (4e, 4s, 4t, 4u) will be delivered on days 180 and 270, respectively."
    }
  },
  {
    "instruction": "The pre-whitening process in MBAL uses two 64-bit extended keys to whiten the first 64 bits of the message, providing a randomized initial state for encryption.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does the pre-whitening process in MBAL enhance encryption?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does the pre-whitening process in MBAL enhance encryption?",
      "answer": "The pre-whitening process in MBAL uses two 64-bit extended keys to whiten the first 64 bits of the message, providing a randomized initial state for encryption."
    }
  },
  {
    "instruction": "The Information Commissioner's Office ruled that Phorm would only be legal under UK law if it were an opt-in service and stated it would closely monitor the testing and implementation of Phorm to ensure data protection laws were observed.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How did Phorm's Webwise service affect the Information Commissioner's Office?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How did Phorm's Webwise service affect the Information Commissioner's Office?",
      "answer": "The Information Commissioner's Office ruled that Phorm would only be legal under UK law if it were an opt-in service and stated it would closely monitor the testing and implementation of Phorm to ensure data protection laws were observed."
    }
  },
  {
    "instruction": "E-mails can be encrypted by using encryption algorithms and keys to secure the contents of the e-mails. This prevents unauthorized parties from reading the e-mails and accessing the personal information contained within them.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How can e-mails be encrypted to protect personal information?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How can e-mails be encrypted to protect personal information?",
      "answer": "E-mails can be encrypted by using encryption algorithms and keys to secure the contents of the e-mails. This prevents unauthorized parties from reading the e-mails and accessing the personal information contained within them."
    }
  },
  {
    "instruction": "Context: Setuid\n\n==Introduction==\nThe Linux and Unix access rights flags setuid and setgid (short for set user identity and set group identity) allow users to run an executable with the file system permissions of the executable's owner or group respectively and to change behaviour in directories. They are often used to allow users on a computer system to run programs with temporarily elevated privileges in order to perform a specific task.  While the assumed user id or group id privileges provided are not always elevated, at a minimum they are specific.\nThe flags setuid and setgid are needed for tasks that require different privileges than what the user is normally granted, such as the ability to alter system files or databases to change their login password. Some of the tasks that require additional privileges may not immediately be obvious, though, such as the ping command, which must send and listen for control packets on a network interface.\n\n\n\n== File modes ==\nThe setuid and setgid bits are normally represented as the values 4 for setuid and 2 for setgid in the high-order octal digit of the file mode. For example, 6711 has both the setuid and setgid bits (4 + 2\n\n== Effects ==\nThe setuid and setgid flags have different effects, depending on whether they are applied to a file, to a directory or binary executable or non binary executable file. The setuid and setgid flags have an effect only on binary executable files and not on scripts (e.g., Bash, Perl, Python).\n\n\n*** When set on an executable file ***\nWhen the setuid or setgid attributes are set on an executable file, then any users able to execute the file will automatically execute the file with the privileges of the file's owner (commonly root) and/or the file's group, depending upon the flags set. This allows the system designer to permit trusted programs to be run which a user would otherwise not be allowed to execute. These may not always be obvious. For example, the ping command may need access to networking privileges that a normal user cannot access; therefore it may be given the setuid flag to ensure that a user who needs to ping another system can do so, even if their own account does not have the required privilege for sending packets.\n\n\n**** Security impact ****\nFor security purposes, the invoking user is usually prohibited by the system from altering the new process in any way, such as by using ptrace, LD_LIBRARY_PATH or sending signals to it, to exploit the raised privilege, although signals from the terminal will still be accepted.\nWhile the setuid feature is very useful in many cases, its improper use can pose a security risk if the setuid attribute is assigned to executable programs that are not carefully designed. Due to potential security issues, many operating systems ignore the setuid attribute when applied to executable shell scripts.\nThe presence of setuid executables explains why the chroot system call is not available to non-root users on Unix. See limitations of chroot for more details.\n\n\n*** When set on a directory ***\nSetting the setgid permission on a directory causes files and subdirectories created within to inherit its group ownership, rather than the primary group of the file-creating process. Created subdirectories also inherit the setgid bit. The policy is only applied during creation and, thus, only prospectively. Directories and files existing when the setgid bit is applied are unaffected, as are directories and files moved into the directory on which the bit is set.\nThus is granted a capacity to work with files amongst a group of users without explicitly setting permissions, but limited by the security model expectation that existing files permissions do not implicitly change.\nThe setuid permission set on a directory is ignored on most UNIX and Linux systems. However FreeBSD can be configured to interpret setuid in a manner similar to setgid, in which case it forces all files and sub-directories created in a directory to be owned by that directory's owner - a simple form of inheritance. This is generally not needed on most systems derived from BSD, since by default directories are treated as if their setgid bit is always set, regardless of the actual value. As is stated in open(2), \"When a new file is created it is given the group of the directory which contains it.\"\n\n== Examples ==\n\n\n*** Checking permissions ***\nPermissions of a file can be checked in octal form and/or alphabetic form with the command line tool stat\n\n\n*** SUID ***\n4701 on an executable file owned by 'root' and the group 'root'\nA user named 'thompson' attempts to execute the file. The executable permission for all users is set (the '1') so 'thompson' can execute the file. The file owner is 'root' and the SUID permission is set (the '4') - so the file is executed as 'root'.\nThe reason an executable would be run as 'root' is so that it can modify specific files that the user would not normally be allowed to, without giving the user full root access.\n\nA default use of this can be seen with the /usr/bin/passwd binary file. /usr/bin/passwd needs to modify /etc/passwd and /etc/shadow which store account information and password hashes for all users, and these can only be modified by the user 'root'.\nThe owner of the process is not the user running the executable file but the owner of the executable file\n\n\n*** SGID ***\n2770 on a directory named 'music' owned by the user 'root' and the group 'engineers'\nA user named 'torvalds' who belongs primarily to the group 'torvalds' but secondarily to the group 'engineers' makes a directory named 'electronic' under the directory named 'music'. The group ownership of the new directory named 'electronic' inherits 'engineers.' This is the same when making a new file named 'imagine.txt'\nWithout SGID the group ownership of the new directory/file would have been 'torvalds' as that is the primary group of user 'torvalds'.\n\n\n*** Sticky bit ***\n\n1770 on a directory named 'videogames' owned by the user 'torvalds' and the group 'engineers'.\nA user named 'torvalds' creates a file named 'tekken' under the directory named 'videogames'. A user named 'wozniak', who is also part of the group 'engineers', attempts to delete the file named 'tekken' but he cannot, since he is not the owner.\nWithout sticky bit, 'wozniak' could have deleted the file, because the directory named 'videogames' allows read and write by 'engineers'. A default use of this can be seen at the /tmp folder.\n\n\n*** Sticky bit with SGID ***\n3171 on a directory named 'blog' owned by the group 'engineers' and the user 'root'\nA user named 'torvalds' who belongs primarily to the group 'torvalds' but secondarily to the group 'engineers' creates a file or directory named 'thoughts' inside the directory 'blog'. A user named 'wozniak' who also belongs to the group 'engineers' cannot delete, rename, or move the file or directory named 'thoughts', because he is not the owner and the sticky bit is set. However, if 'thoughts' is a file, then 'wozniak' can edit it.\n\nSticky bit has the final decision. If sticky bit and SGID had not been set, the user 'wozniak' could rename, move, or delete the file named 'thoughts' because the directory named 'blog' allows read and write by group, and wozniak belongs to the group, and the default 0002 umask allows new files to be edited by group. Sticky bit and SGID could be combined with something such as a read-only umask or an append only attribute.\n\n== Security ==\nDevelopers design and implement programs that use this bit on executables carefully in order to avoid security vulnerabilities including buffer overruns and path injection. Successful buffer-overrun attacks on vulnerable applications allow the attacker to execute arbitrary code under the rights of the process exploited. In the event that a vulnerable process uses the setuid bit to run as root, the code will execute with root privileges, in effect giving the attacker root access to the system on which the vulnerable process is running.\nOf particular importance in the case of a setuid process is the environment of the process. If the environment is not properly sanitized by a privileged process, its behavior can be changed by the unprivileged process that started it. For example, GNU libc was at one point vulnerable to an exploit using setuid and an environment variable that allowed executing code from untrusted shared libraries.\nQuestion: How can a user check the permissions of a file in octal form and/or alphabetic form in Linux and Unix systems?\n\nAnswer:",
    "context": "",
    "output": "The permissions of a file can be checked in octal form and/or alphabetic form with the command line tool stat.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How can a user check the permissions of a file in octal form and/or alphabetic form in Linux and Unix systems?",
      "answer": "The permissions of a file can be checked in octal form and/or alphabetic form with the command line tool stat.",
      "context": "Setuid\n\n==Introduction==\nThe Linux and Unix access rights flags setuid and setgid (short for set user identity and set group identity) allow users to run an executable with the file system permissions of the executable's owner or group respectively and to change behaviour in directories. They are often used to allow users on a computer system to run programs with temporarily elevated privileges in order to perform a specific task.  While the assumed user id or group id privileges provided are not always elevated, at a minimum they are specific.\nThe flags setuid and setgid are needed for tasks that require different privileges than what the user is normally granted, such as the ability to alter system files or databases to change their login password. Some of the tasks that require additional privileges may not immediately be obvious, though, such as the ping command, which must send and listen for control packets on a network interface.\n\n\n\n== File modes ==\nThe setuid and setgid bits are normally represented as the values 4 for setuid and 2 for setgid in the high-order octal digit of the file mode. For example, 6711 has both the setuid and setgid bits (4 + 2\n\n== Effects ==\nThe setuid and setgid flags have different effects, depending on whether they are applied to a file, to a directory or binary executable or non binary executable file. The setuid and setgid flags have an effect only on binary executable files and not on scripts (e.g., Bash, Perl, Python).\n\n\n*** When set on an executable file ***\nWhen the setuid or setgid attributes are set on an executable file, then any users able to execute the file will automatically execute the file with the privileges of the file's owner (commonly root) and/or the file's group, depending upon the flags set. This allows the system designer to permit trusted programs to be run which a user would otherwise not be allowed to execute. These may not always be obvious. For example, the ping command may need access to networking privileges that a normal user cannot access; therefore it may be given the setuid flag to ensure that a user who needs to ping another system can do so, even if their own account does not have the required privilege for sending packets.\n\n\n**** Security impact ****\nFor security purposes, the invoking user is usually prohibited by the system from altering the new process in any way, such as by using ptrace, LD_LIBRARY_PATH or sending signals to it, to exploit the raised privilege, although signals from the terminal will still be accepted.\nWhile the setuid feature is very useful in many cases, its improper use can pose a security risk if the setuid attribute is assigned to executable programs that are not carefully designed. Due to potential security issues, many operating systems ignore the setuid attribute when applied to executable shell scripts.\nThe presence of setuid executables explains why the chroot system call is not available to non-root users on Unix. See limitations of chroot for more details.\n\n\n*** When set on a directory ***\nSetting the setgid permission on a directory causes files and subdirectories created within to inherit its group ownership, rather than the primary group of the file-creating process. Created subdirectories also inherit the setgid bit. The policy is only applied during creation and, thus, only prospectively. Directories and files existing when the setgid bit is applied are unaffected, as are directories and files moved into the directory on which the bit is set.\nThus is granted a capacity to work with files amongst a group of users without explicitly setting permissions, but limited by the security model expectation that existing files permissions do not implicitly change.\nThe setuid permission set on a directory is ignored on most UNIX and Linux systems. However FreeBSD can be configured to interpret setuid in a manner similar to setgid, in which case it forces all files and sub-directories created in a directory to be owned by that directory's owner - a simple form of inheritance. This is generally not needed on most systems derived from BSD, since by default directories are treated as if their setgid bit is always set, regardless of the actual value. As is stated in open(2), \"When a new file is created it is given the group of the directory which contains it.\"\n\n== Examples ==\n\n\n*** Checking permissions ***\nPermissions of a file can be checked in octal form and/or alphabetic form with the command line tool stat\n\n\n*** SUID ***\n4701 on an executable file owned by 'root' and the group 'root'\nA user named 'thompson' attempts to execute the file. The executable permission for all users is set (the '1') so 'thompson' can execute the file. The file owner is 'root' and the SUID permission is set (the '4') - so the file is executed as 'root'.\nThe reason an executable would be run as 'root' is so that it can modify specific files that the user would not normally be allowed to, without giving the user full root access.\n\nA default use of this can be seen with the /usr/bin/passwd binary file. /usr/bin/passwd needs to modify /etc/passwd and /etc/shadow which store account information and password hashes for all users, and these can only be modified by the user 'root'.\nThe owner of the process is not the user running the executable file but the owner of the executable file\n\n\n*** SGID ***\n2770 on a directory named 'music' owned by the user 'root' and the group 'engineers'\nA user named 'torvalds' who belongs primarily to the group 'torvalds' but secondarily to the group 'engineers' makes a directory named 'electronic' under the directory named 'music'. The group ownership of the new directory named 'electronic' inherits 'engineers.' This is the same when making a new file named 'imagine.txt'\nWithout SGID the group ownership of the new directory/file would have been 'torvalds' as that is the primary group of user 'torvalds'.\n\n\n*** Sticky bit ***\n\n1770 on a directory named 'videogames' owned by the user 'torvalds' and the group 'engineers'.\nA user named 'torvalds' creates a file named 'tekken' under the directory named 'videogames'. A user named 'wozniak', who is also part of the group 'engineers', attempts to delete the file named 'tekken' but he cannot, since he is not the owner.\nWithout sticky bit, 'wozniak' could have deleted the file, because the directory named 'videogames' allows read and write by 'engineers'. A default use of this can be seen at the /tmp folder.\n\n\n*** Sticky bit with SGID ***\n3171 on a directory named 'blog' owned by the group 'engineers' and the user 'root'\nA user named 'torvalds' who belongs primarily to the group 'torvalds' but secondarily to the group 'engineers' creates a file or directory named 'thoughts' inside the directory 'blog'. A user named 'wozniak' who also belongs to the group 'engineers' cannot delete, rename, or move the file or directory named 'thoughts', because he is not the owner and the sticky bit is set. However, if 'thoughts' is a file, then 'wozniak' can edit it.\n\nSticky bit has the final decision. If sticky bit and SGID had not been set, the user 'wozniak' could rename, move, or delete the file named 'thoughts' because the directory named 'blog' allows read and write by group, and wozniak belongs to the group, and the default 0002 umask allows new files to be edited by group. Sticky bit and SGID could be combined with something such as a read-only umask or an append only attribute.\n\n== Security ==\nDevelopers design and implement programs that use this bit on executables carefully in order to avoid security vulnerabilities including buffer overruns and path injection. Successful buffer-overrun attacks on vulnerable applications allow the attacker to execute arbitrary code under the rights of the process exploited. In the event that a vulnerable process uses the setuid bit to run as root, the code will execute with root privileges, in effect giving the attacker root access to the system on which the vulnerable process is running.\nOf particular importance in the case of a setuid process is the environment of the process. If the environment is not properly sanitized by a privileged process, its behavior can be changed by the unprivileged process that started it. For example, GNU libc was at one point vulnerable to an exploit using setuid and an environment variable that allowed executing code from untrusted shared libraries."
    }
  },
  {
    "instruction": "X-KRSS can generate the key material, making key recovery easier and more straightforward than when keys are created manually, as it eliminates the need for manual backup and recovery procedures.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does X-KRSS make key recovery easier than when keys are created manually?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does X-KRSS make key recovery easier than when keys are created manually?",
      "answer": "X-KRSS can generate the key material, making key recovery easier and more straightforward than when keys are created manually, as it eliminates the need for manual backup and recovery procedures."
    }
  },
  {
    "instruction": "The main goal of Anonym.OS was to provide secure and anonymous web browsing access to everyday users.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What was the main goal of Anonym.OS?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What was the main goal of Anonym.OS?",
      "answer": "The main goal of Anonym.OS was to provide secure and anonymous web browsing access to everyday users."
    }
  },
  {
    "instruction": "A hash function is a one-way function that maps an input (or 'message') to a fixed-size string of bytes, while a message authentication code (MAC) is a symmetric-key function that generates a fixed-size string of bytes from an input and a secret key, which can be used to verify the integrity and authenticity of the input.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the difference between a hash function and a message authentication code (MAC) in TLS?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the difference between a hash function and a message authentication code (MAC) in TLS?",
      "answer": "A hash function is a one-way function that maps an input (or 'message') to a fixed-size string of bytes, while a message authentication code (MAC) is a symmetric-key function that generates a fixed-size string of bytes from an input and a secret key, which can be used to verify the integrity and authenticity of the input."
    }
  },
  {
    "instruction": "Cell phone microphones can be activated remotely, without any physical access, using a technique known as a \"roving bug.\" This feature has been used by law enforcement agencies and intelligence services to listen in on nearby conversations. A United States court ruled in 1988 that this technique is permissible with a court order.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How can cell phone microphones be activated remotely?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How can cell phone microphones be activated remotely?",
      "answer": "Cell phone microphones can be activated remotely, without any physical access, using a technique known as a \"roving bug.\" This feature has been used by law enforcement agencies and intelligence services to listen in on nearby conversations. A United States court ruled in 1988 that this technique is permissible with a court order."
    }
  },
  {
    "instruction": "Chips can be scanned in 3D and zoomed in on sections using Ptychographic X-ray laminography. This technique currently accommodates chips up to 12 millimeters by 12 millimeters, easily accommodating an Apple A12 chip but not yet able to scan a full Nvidia Volta GPU.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How can chips be scanned in 3D and zoomed in on sections?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How can chips be scanned in 3D and zoomed in on sections?",
      "answer": "Chips can be scanned in 3D and zoomed in on sections using Ptychographic X-ray laminography. This technique currently accommodates chips up to 12 millimeters by 12 millimeters, easily accommodating an Apple A12 chip but not yet able to scan a full Nvidia Volta GPU."
    }
  },
  {
    "instruction": "Google discontinued selling Bluetooth versions of the Titan Security Key in August 2021 due to concerns about their security and reliability.\n\nWrite a question about the text above.",
    "context": "",
    "output": "When did Google discontinue selling Bluetooth versions of the Titan Security Key, and why?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "When did Google discontinue selling Bluetooth versions of the Titan Security Key, and why?",
      "answer": "Google discontinued selling Bluetooth versions of the Titan Security Key in August 2021 due to concerns about their security and reliability."
    }
  },
  {
    "instruction": "Context: Content Security Policy\n\n==Introduction==\nContent Security Policy (CSP) is a computer security standard introduced to prevent cross-site scripting (XSS), clickjacking and other code injection  attacks resulting from execution of malicious content in the trusted web page context. It is a Candidate Recommendation of the W3C working group on Web Application Security, widely supported by modern web browsers. CSP provides a standard method for website owners to declare approved origins of content that browsers should be allowed to load on that website\u2014covered types are JavaScript, CSS, HTML frames, web workers, fonts, images, embeddable objects such as Java applets, ActiveX, audio and video files, and other HTML5 features.\n\n== Status ==\nThe standard, originally named Content Restrictions, was proposed by Robert Hansen in 2004, first implemented in Firefox 4 and quickly picked up by other browsers. Version 1 of the standard was published in 2012 as W3C candidate recommendation and quickly with further versions (Level 2) published in 2014. As of 2023, the draft of Level 3 is being developed with the new features being quickly adopted by the web browsers.The following header names are in use as part of experimental CSP implementations:\nContent-Security-Policy \u2013 standard header name proposed by the W3C document. Google Chrome supports this as of version 25. Firefox supports this as of version 23, released on 6 August 2013. WebKit supports this as of version 528 (nightly build). Chromium-based Microsoft Edge support is similar to Chrome's.\nX-WebKit-CSP \u2013 deprecated, experimental header introduced into Google Chrome, Safari and other WebKit-based web browsers in 2011.\nX-Content-Security-Policy \u2013 deprecated, experimental header introduced in Gecko 2 based browsers (Firefox 4 to Firefox 22,  Thunderbird 3.3,  SeaMonkey 2.1).A website can declare multiple CSP headers, also mixing enforcement and report-only ones. Each header will be processed separately by the browser.\nCSP can also be delivered within the HTML code using a HTML META tag, although in this case its effectiveness will be limited.Internet Explorer 10 and Internet Explorer 11 also support CSP, but only sandbox directive, using the experimental X-Content-Security-Policy header.A number of web application frameworks support CSP, for example AngularJS (natively) and Django (middleware). Instructions for Ruby on Rails have been posted by GitHub. Web framework support is however only required if the CSP contents somehow depend on the web application's state\u2014such as usage of the nonce origin. Otherwise, the CSP is rather static and can be delivered from web application tiers above the application, for example on load balancer or web server.\n\n\n*** Bypasses ***\nIn December 2015  and December 2016, a few methods of bypassing 'nonce' allowlisting origins were published. In January 2016, another method was published, which leverages server-wide CSP allowlisting to exploit old and vulnerable versions of JavaScript libraries hosted at the same server (frequent case with CDN servers). In May 2017 one more method was published to bypass CSP using web application frameworks code.\n\n== Mode of operation ==\n\nIf the Content-Security-Policy header is present in the server response, a compliant client enforces the declarative allowlist policy. One example goal of a policy is a stricter execution mode for JavaScript in order to prevent certain cross-site scripting attacks. In practice this means that a number of features are disabled by default:\n\nInline JavaScript code<script> blocks,\nDOM event handlers as HTML attributes (e.g. onclick)\nThe javascript: links\nInline CSS statements\n<style> block\nstyle attributed to HTML elements\nDynamic JavaScript code evaluationeval()\nstring arguments for setTimeout and setInterval functions\nnew Function() constructor\nDynamic CSS statements\nCSSStyleSheet.insertRule() methodWhile using CSP in a new application may be quite straightforward, especially with CSP-compatible JavaScript framework, existing applications may require some refactoring\u2014or relaxing the policy. Recommended coding practice for CSP-compatible web applications is to load code from external source files (<script src>), parse JSON instead of evaluating it and use EventTarget.addEventListener() to set event handlers.\n\n\n*** Notes ***\n\n== Reporting ==\nAny time a requested resource or script execution violates the policy, the browser will fire a POST request to the value specified in report-uri or  report-to containing details of the violation.\nCSP reports are standard JSON structures and can be captured either by application's own API or public CSP report receivers.In 2018 security researchers showed how to send false positive reports to the designated receiver specified in report-uri . This allows potential attackers to arbitrarily trigger those alarms and might render them less useful in case of a real attack. This behaviour is intended and cannot be fixed, as the browser (client) is sending the reports.\n\n== Browser add-ons and extensions exemption ==\nAccording to the original CSP (1.0) Processing Model (2012\u20132013), CSP should not interfere with the operation of browser add-ons or extensions installed by the user. This feature of CSP would have effectively allowed any add-on, extension, or Bookmarklet to inject script into web sites, regardless of the origin of that script, and thus be exempt from CSP policies.\n\nHowever, this policy has since been modified (as of CSP 1.1) with the following wording. Note the use of the word \"may\" instead of the prior absolute \"should (not)\" wording:Note: User agents may allow users to modify or bypass policy enforcement through user preferences, bookmarklets, third-party additions to the user agent, and other such mechanisms.The absolute \"should\" wording was being used by browser users to request/demand adherence to the policy and have changes installed in popular browsers (Firefox, Chrome, Safari) to support it. This was particularly contentious when sites like Twitter and GitHub started using strong CSP policies, which 'broke' the use of Bookmarklets.The W3C Web Application Security Working Group considers such script to be part of the Trusted Computing Base implemented by the browser; however, it has been argued to the working group by a representative of Cox Communications that this exemption is a potential security hole that could be exploited by malicious or compromised add-ons or extensions.\n\n== Complementary measures ==\nAs of 2015 a number of new browser security standards are being proposed by W3C, most of them complementary to CSP:\nSubresource Integrity (SRI), to ensure only known, trusted resource files (typically JavaScript, CSS) are loaded from third-party servers (typically CDNs)\nMixed Content, to clarify the intended browser's policy on pages loaded over HTTPS and linking content over plaintext HTTP\nUpgrade Insecure Requests, hinting browsers on how to handle legacy links on pages migrated to HTTPS\nCredential Management, a unified JavaScript API to access user's credentials to facilitate complex login schemes,\nReferrer Policy, CSP extension to hint the browser on generation of the Referer headers.\nQuestion: How can CSP reports be captured and what are the potential limitations of CSP report receivers?. Whats the answer?",
    "context": "",
    "output": "CSP reports can be captured by the application's own API or public CSP report receivers. However, there are potential limitations of CSP report receivers, such as the ability to send false positive reports, which may render them less useful in case of a real attack.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How can CSP reports be captured and what are the potential limitations of CSP report receivers?",
      "answer": "CSP reports can be captured by the application's own API or public CSP report receivers. However, there are potential limitations of CSP report receivers, such as the ability to send false positive reports, which may render them less useful in case of a real attack.",
      "context": "Content Security Policy\n\n==Introduction==\nContent Security Policy (CSP) is a computer security standard introduced to prevent cross-site scripting (XSS), clickjacking and other code injection  attacks resulting from execution of malicious content in the trusted web page context. It is a Candidate Recommendation of the W3C working group on Web Application Security, widely supported by modern web browsers. CSP provides a standard method for website owners to declare approved origins of content that browsers should be allowed to load on that website\u2014covered types are JavaScript, CSS, HTML frames, web workers, fonts, images, embeddable objects such as Java applets, ActiveX, audio and video files, and other HTML5 features.\n\n== Status ==\nThe standard, originally named Content Restrictions, was proposed by Robert Hansen in 2004, first implemented in Firefox 4 and quickly picked up by other browsers. Version 1 of the standard was published in 2012 as W3C candidate recommendation and quickly with further versions (Level 2) published in 2014. As of 2023, the draft of Level 3 is being developed with the new features being quickly adopted by the web browsers.The following header names are in use as part of experimental CSP implementations:\nContent-Security-Policy \u2013 standard header name proposed by the W3C document. Google Chrome supports this as of version 25. Firefox supports this as of version 23, released on 6 August 2013. WebKit supports this as of version 528 (nightly build). Chromium-based Microsoft Edge support is similar to Chrome's.\nX-WebKit-CSP \u2013 deprecated, experimental header introduced into Google Chrome, Safari and other WebKit-based web browsers in 2011.\nX-Content-Security-Policy \u2013 deprecated, experimental header introduced in Gecko 2 based browsers (Firefox 4 to Firefox 22,  Thunderbird 3.3,  SeaMonkey 2.1).A website can declare multiple CSP headers, also mixing enforcement and report-only ones. Each header will be processed separately by the browser.\nCSP can also be delivered within the HTML code using a HTML META tag, although in this case its effectiveness will be limited.Internet Explorer 10 and Internet Explorer 11 also support CSP, but only sandbox directive, using the experimental X-Content-Security-Policy header.A number of web application frameworks support CSP, for example AngularJS (natively) and Django (middleware). Instructions for Ruby on Rails have been posted by GitHub. Web framework support is however only required if the CSP contents somehow depend on the web application's state\u2014such as usage of the nonce origin. Otherwise, the CSP is rather static and can be delivered from web application tiers above the application, for example on load balancer or web server.\n\n\n*** Bypasses ***\nIn December 2015  and December 2016, a few methods of bypassing 'nonce' allowlisting origins were published. In January 2016, another method was published, which leverages server-wide CSP allowlisting to exploit old and vulnerable versions of JavaScript libraries hosted at the same server (frequent case with CDN servers). In May 2017 one more method was published to bypass CSP using web application frameworks code.\n\n== Mode of operation ==\n\nIf the Content-Security-Policy header is present in the server response, a compliant client enforces the declarative allowlist policy. One example goal of a policy is a stricter execution mode for JavaScript in order to prevent certain cross-site scripting attacks. In practice this means that a number of features are disabled by default:\n\nInline JavaScript code<script> blocks,\nDOM event handlers as HTML attributes (e.g. onclick)\nThe javascript: links\nInline CSS statements\n<style> block\nstyle attributed to HTML elements\nDynamic JavaScript code evaluationeval()\nstring arguments for setTimeout and setInterval functions\nnew Function() constructor\nDynamic CSS statements\nCSSStyleSheet.insertRule() methodWhile using CSP in a new application may be quite straightforward, especially with CSP-compatible JavaScript framework, existing applications may require some refactoring\u2014or relaxing the policy. Recommended coding practice for CSP-compatible web applications is to load code from external source files (<script src>), parse JSON instead of evaluating it and use EventTarget.addEventListener() to set event handlers.\n\n\n*** Notes ***\n\n== Reporting ==\nAny time a requested resource or script execution violates the policy, the browser will fire a POST request to the value specified in report-uri or  report-to containing details of the violation.\nCSP reports are standard JSON structures and can be captured either by application's own API or public CSP report receivers.In 2018 security researchers showed how to send false positive reports to the designated receiver specified in report-uri . This allows potential attackers to arbitrarily trigger those alarms and might render them less useful in case of a real attack. This behaviour is intended and cannot be fixed, as the browser (client) is sending the reports.\n\n== Browser add-ons and extensions exemption ==\nAccording to the original CSP (1.0) Processing Model (2012\u20132013), CSP should not interfere with the operation of browser add-ons or extensions installed by the user. This feature of CSP would have effectively allowed any add-on, extension, or Bookmarklet to inject script into web sites, regardless of the origin of that script, and thus be exempt from CSP policies.\n\nHowever, this policy has since been modified (as of CSP 1.1) with the following wording. Note the use of the word \"may\" instead of the prior absolute \"should (not)\" wording:Note: User agents may allow users to modify or bypass policy enforcement through user preferences, bookmarklets, third-party additions to the user agent, and other such mechanisms.The absolute \"should\" wording was being used by browser users to request/demand adherence to the policy and have changes installed in popular browsers (Firefox, Chrome, Safari) to support it. This was particularly contentious when sites like Twitter and GitHub started using strong CSP policies, which 'broke' the use of Bookmarklets.The W3C Web Application Security Working Group considers such script to be part of the Trusted Computing Base implemented by the browser; however, it has been argued to the working group by a representative of Cox Communications that this exemption is a potential security hole that could be exploited by malicious or compromised add-ons or extensions.\n\n== Complementary measures ==\nAs of 2015 a number of new browser security standards are being proposed by W3C, most of them complementary to CSP:\nSubresource Integrity (SRI), to ensure only known, trusted resource files (typically JavaScript, CSS) are loaded from third-party servers (typically CDNs)\nMixed Content, to clarify the intended browser's policy on pages loaded over HTTPS and linking content over plaintext HTTP\nUpgrade Insecure Requests, hinting browsers on how to handle legacy links on pages migrated to HTTPS\nCredential Management, a unified JavaScript API to access user's credentials to facilitate complex login schemes,\nReferrer Policy, CSP extension to hint the browser on generation of the Referer headers."
    }
  },
  {
    "instruction": "Context: Graph-based access control\n\n==Introduction==\nGraph-based access control (GBAC) is a declarative way to define access rights, task assignments, recipients and content in information systems. Access rights are granted to objects like files or documents, but also business objects such as an account. GBAC can also be used for the assignment of agents to tasks in workflow environments. Organizations are modeled as a specific kind of semantic graph comprising the organizational units, the roles and functions as well as the human and automatic agents (i.a. persons, machines). The main difference with other approaches such as role-based access control or attribute-based access control is that in GBAC access rights are defined using an organizational query language instead of total enumeration.\n\n\n\n== Definition ==\nGraph-based access control consists of two building blocks: \n\nA semantic graph modeling an organization\nA query language.\n\n\n*** Organizational graph ***\n\nThe organizational graph is divided into a type and an instance level. On the instance level there are node types for organizational units, functional units and agents. The basic structure of an organization is defined using so called \"structural relations\". They define the \"is part of\"- relations between functional units and organizational units as well as the mapping of agents to functional units. Additionally there are specific relationship types like \"deputyship\" or \"informed_by\". These types can be extended by the modeler. All relationships can be context sensitive through the usage of predicates.\nOn the type level organizational structures are described in a more general manner. It consists of organizational unit types, functional unit types and the same relationship types as on the instance level. Type definitions can be used to create new instances or reuse organizational knowledge in case of exceptions (for further reading see).\n\n\n*** Query language ***\nIn GBAC a query language is used to define agents having certain characteristics or abilities. The following table shows the usage of the query language in the context of an access control matrix.\nThe first query means that all managers working for the company for more than six months can read the financial report, as well as the managers who are classified by the flag \"ReadFinancialReport\".\nThe daily financial report can only be written by the manager of the controlling department or clerks of the department that are enabled to do that (WriteFinancialReport\n\n==TRUE).\n\n\n== Implementation\n\n==\n\nGBAC was first implemented in the CoCoS Environment within the organizational server CoCoSOrg. \nIn the C-Org-Project it was extended with more sophisticated features like separation of duty or access control in distributed environments. \nThere is also a cloud-based implementation on IBM's Bluemix platform.\nIn all implementations the server takes a query from a client system and resolves it to a set of agents. This set is sent back to the calling client as response. Clients can be file systems, database management systems, workflow management systems, physical security systems or even telephone servers.\n\n\n== See also\n\n==\n\n\n== References\nQuestion: What is the purpose of using predicates in GBAC?\n\nAnswer:",
    "context": "",
    "output": "Predicates are used in GBAC to make relationships context-sensitive.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the purpose of using predicates in GBAC?",
      "answer": "Predicates are used in GBAC to make relationships context-sensitive.",
      "context": "Graph-based access control\n\n==Introduction==\nGraph-based access control (GBAC) is a declarative way to define access rights, task assignments, recipients and content in information systems. Access rights are granted to objects like files or documents, but also business objects such as an account. GBAC can also be used for the assignment of agents to tasks in workflow environments. Organizations are modeled as a specific kind of semantic graph comprising the organizational units, the roles and functions as well as the human and automatic agents (i.a. persons, machines). The main difference with other approaches such as role-based access control or attribute-based access control is that in GBAC access rights are defined using an organizational query language instead of total enumeration.\n\n\n\n== Definition ==\nGraph-based access control consists of two building blocks: \n\nA semantic graph modeling an organization\nA query language.\n\n\n*** Organizational graph ***\n\nThe organizational graph is divided into a type and an instance level. On the instance level there are node types for organizational units, functional units and agents. The basic structure of an organization is defined using so called \"structural relations\". They define the \"is part of\"- relations between functional units and organizational units as well as the mapping of agents to functional units. Additionally there are specific relationship types like \"deputyship\" or \"informed_by\". These types can be extended by the modeler. All relationships can be context sensitive through the usage of predicates.\nOn the type level organizational structures are described in a more general manner. It consists of organizational unit types, functional unit types and the same relationship types as on the instance level. Type definitions can be used to create new instances or reuse organizational knowledge in case of exceptions (for further reading see).\n\n\n*** Query language ***\nIn GBAC a query language is used to define agents having certain characteristics or abilities. The following table shows the usage of the query language in the context of an access control matrix.\nThe first query means that all managers working for the company for more than six months can read the financial report, as well as the managers who are classified by the flag \"ReadFinancialReport\".\nThe daily financial report can only be written by the manager of the controlling department or clerks of the department that are enabled to do that (WriteFinancialReport\n\n==TRUE).\n\n\n== Implementation\n\n==\n\nGBAC was first implemented in the CoCoS Environment within the organizational server CoCoSOrg. \nIn the C-Org-Project it was extended with more sophisticated features like separation of duty or access control in distributed environments. \nThere is also a cloud-based implementation on IBM's Bluemix platform.\nIn all implementations the server takes a query from a client system and resolves it to a set of agents. This set is sent back to the calling client as response. Clients can be file systems, database management systems, workflow management systems, physical security systems or even telephone servers.\n\n\n== See also\n\n==\n\n\n== References"
    }
  },
  {
    "instruction": "TEMPEST is a technical surveillance counter-measures specification to protect against the interception of information through unintentional emissions, such as electromagnetic leakage. It is used in air-gapped networks to prevent data from being transmitted through these unintentional emissions.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the concept of TEMPEST in the context of air-gapped networks?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the concept of TEMPEST in the context of air-gapped networks?",
      "answer": "TEMPEST is a technical surveillance counter-measures specification to protect against the interception of information through unintentional emissions, such as electromagnetic leakage. It is used in air-gapped networks to prevent data from being transmitted through these unintentional emissions."
    }
  },
  {
    "instruction": "Cthulhu's arrest and conviction serve as a reminder of the importance of robust cybersecurity measures to protect against cybercrime. Law enforcement agencies worldwide continue to prioritize the investigation and prosecution of cybercriminals to maintain the integrity of the internet and protect users' safety and privacy.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does Cthulhu's arrest and conviction impact the broader issue of cybersecurity?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does Cthulhu's arrest and conviction impact the broader issue of cybersecurity?",
      "answer": "Cthulhu's arrest and conviction serve as a reminder of the importance of robust cybersecurity measures to protect against cybercrime. Law enforcement agencies worldwide continue to prioritize the investigation and prosecution of cybercriminals to maintain the integrity of the internet and protect users' safety and privacy."
    }
  },
  {
    "instruction": "A pre-computed dictionary attack or rainbow table attack is a technique that achieves a time-space tradeoff by pre-computing a list of hashes of dictionary words and storing these in a database using the hash as the key. This requires a considerable amount of preparation time, but allows the actual attack to be executed faster. Pre-computed dictionary attacks are particularly effective when a large number of passwords are to be cracked, and can be thwarted by the use of salt, a technique that forces the hash dictionary to be recomputed for each password sought, making precomputation infeasible.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is a pre-computed dictionary attack or a rainbow table attack?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is a pre-computed dictionary attack or a rainbow table attack?",
      "answer": "A pre-computed dictionary attack or rainbow table attack is a technique that achieves a time-space tradeoff by pre-computing a list of hashes of dictionary words and storing these in a database using the hash as the key. This requires a considerable amount of preparation time, but allows the actual attack to be executed faster. Pre-computed dictionary attacks are particularly effective when a large number of passwords are to be cracked, and can be thwarted by the use of salt, a technique that forces the hash dictionary to be recomputed for each password sought, making precomputation infeasible."
    }
  },
  {
    "instruction": "Intel has designed hardware fixes for future processors for Meltdown and Spectre-V2, and has developed Intel Microcode workarounds for processors dating back to 2013. However, it has backed off from its plan to develop workarounds for certain older processor families.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What are Intel's plans for hardware fixes and microcode workarounds for Meltdown and Spectre?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What are Intel's plans for hardware fixes and microcode workarounds for Meltdown and Spectre?",
      "answer": "Intel has designed hardware fixes for future processors for Meltdown and Spectre-V2, and has developed Intel Microcode workarounds for processors dating back to 2013. However, it has backed off from its plan to develop workarounds for certain older processor families."
    }
  },
  {
    "instruction": "The assumption made is that \u03f5 < 1, which ensures the Gaussian mechanism provides sufficient differential privacy guarantees.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the assumption made when discussing the equivalent Gaussian mechanism for high-dimensional functions?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the assumption made when discussing the equivalent Gaussian mechanism for high-dimensional functions?",
      "answer": "The assumption made is that \u03f5 < 1, which ensures the Gaussian mechanism provides sufficient differential privacy guarantees."
    }
  },
  {
    "instruction": "No, a party cannot offer and receive the same commodity in an n-party single-unit general exchange. Each party offers a commodity to another party, and receives a different commodity in return.\n\nWrite a question about the text above.",
    "context": "",
    "output": "Can a party offer and receive the same commodity in an n-party single-unit general exchange?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "Can a party offer and receive the same commodity in an n-party single-unit general exchange?",
      "answer": "No, a party cannot offer and receive the same commodity in an n-party single-unit general exchange. Each party offers a commodity to another party, and receives a different commodity in return."
    }
  },
  {
    "instruction": "The ChipTAN scheme protects against technical manipulation by generating TANs that are specific to the bank card and current transaction details. This ensures that modifying a transaction retroactively would cause the TAN to be invalid.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does the ChipTAN scheme protect against technical manipulation?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does the ChipTAN scheme protect against technical manipulation?",
      "answer": "The ChipTAN scheme protects against technical manipulation by generating TANs that are specific to the bank card and current transaction details. This ensures that modifying a transaction retroactively would cause the TAN to be invalid."
    }
  },
  {
    "instruction": "Yes, a multi-party fair exchange protocol can be used to exchange digital items, such as files or messages. This is because digital items can be easily duplicated and transferred over a network, making them well-suited for exchange in a multi-party fair exchange protocol.\n\nWrite a question about the text above.",
    "context": "",
    "output": "Can a multi-party fair exchange protocol be used to exchange digital items?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "Can a multi-party fair exchange protocol be used to exchange digital items?",
      "answer": "Yes, a multi-party fair exchange protocol can be used to exchange digital items, such as files or messages. This is because digital items can be easily duplicated and transferred over a network, making them well-suited for exchange in a multi-party fair exchange protocol."
    }
  },
  {
    "instruction": "The Permuted Choice 1 (PC-1) in the DES key schedule leads to round keys being either all zeros, all ones, or alternating zero-one patterns when weak keys are used.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the role of the Permuted Choice 1 (PC-1) in the DES key schedule in relation to weak keys?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the role of the Permuted Choice 1 (PC-1) in the DES key schedule in relation to weak keys?",
      "answer": "The Permuted Choice 1 (PC-1) in the DES key schedule leads to round keys being either all zeros, all ones, or alternating zero-one patterns when weak keys are used."
    }
  },
  {
    "instruction": "Deliberate information leakage, or subliminal channels, can be used to create an algorithmic converter that intentionally leaks small amounts of information. This allows the creator to intercept users' messages while maintaining the illusion of security for the user. This type of deliberate leakage is sometimes used by attackers to gain unauthorized access to a system or steal sensitive information.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What are some real-world examples of deliberate information leakage?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What are some real-world examples of deliberate information leakage?",
      "answer": "Deliberate information leakage, or subliminal channels, can be used to create an algorithmic converter that intentionally leaks small amounts of information. This allows the creator to intercept users' messages while maintaining the illusion of security for the user. This type of deliberate leakage is sometimes used by attackers to gain unauthorized access to a system or steal sensitive information."
    }
  },
  {
    "instruction": "Facebook malware\n\n==Introduction==\nThe social media platform and social networking service Facebook has been affected multiple times over its history by intentionally harmful software. Known as malware, these pose particular challenges both to users of the platform as well as to the personnel of the tech-company itself. Fighting the entities that create these is a topic of ongoing malware analysis.\n\n== Types of malware and notable incidents ==\nAttacks known as phishing, in which an attacker pretends to be some trustworthy entity in order to solicit private information, have increased exponentially in the 2010s and posed frustrating challenges. For Facebook in particular, tricks involving URLs are common; attackers will maliciously use a similar website such as http://faceb0ok.com/ instead of the correct http://facebook.com/, for example. The 11th International Conference on Detection of Intrusions and Malware, and Vulnerability Assessment (DIMVA), held in July 2014, issued a report condemning this as one of the \"common tricks\" that mobile computing users are especially vulnerable to.In terms of applications, Facebook has also been visually copied by phishing attackers, who aim to confuse individuals into thinking that something else is the legitimate Facebook log-in screen.In 2013, a variant of the \"Dorkbot\" malware caused alarm after spreading through Facebook's internal chat service. With suspected efforts by cybercriminals to harvest users' passwords affecting individuals from nations such as Germany, India, Portugal, and the United Kingdom. The antivirus organization Bitdefender discovered several thousand malicious links taking place in a twenty-four hour period, and contacted the Facebook administration about the problem. While the infection was contained, its unusual nature sparked interest given that the attackers exploited a flaw in the file-sharing site MediaFire to proliferate phony applications among victims' Facebook friends.The real computer worm \"Koobface\", which surfaced in 2008 via messages sent through both Facebook and MySpace, later became subject to inflated, grandiose claims about its effects and spread to the point of being an internet hoax. Later commentary claimed a link between the malware and messages about the Barack Obama administration that never actually existed. David Mikkelson of Snopes.com discussed the matter in a fact-checking article.On 26 July 2022, researchers at WithSecure discovered a cybercriminal operation that was targeting digital marketing and human resources professionals in an effort to hijack Facebook Business accounts using data-stealing malware.They dubbed the campaign as 'Ducktail' and found evidence to suggest that a Vietnamese threat actor has been developing and distributing the malware with motives appeared to be purely financially driven.\n\n== Responses ==\n\n\n*** Individual efforts ***\nIn the same vein as actions by Google and Microsoft, the company's administration has been willing to hire \"grey hat\" hackers, who have acted legally ambiguously in the past, to assist them in various functions. Programmer and social activist George Hotz (also known by the nickname \"GeoHot\") is an example.\n\n\n*** Bug Bounty Program ***\nOn July 29, 2011, Facebook announced an effort called the \"Bug Bounty Program\" in which certain security researchers will be paid a minimum of $500 for reporting security holes on Facebook's website itself. The company's official page for security researchers stated, \"If you give us a reasonable time to respond to your report before making any information public and make a good faith effort to avoid privacy violations, destruction of data, and interruption or degradation of our service during your research, we will not bring any lawsuit against you or ask law enforcement to investigate you.\" The effort attracted notice from publications such as PC Magazine, which noted that individuals must not just be the first to report the security glitch but must also find the problem native to Facebook (rather than an entity merely associated with it such as FarmVille).\n\n\n*** Targeting of specific users ***\nIn late 2017, Facebook systematically disabled accounts operated by North Koreans in response to that government's use of state-sponsored malware attacks. Microsoft did similar actions. The North Korean government had attracted widespread condemnation in the U.S. and elsewhere for its alleged proliferation of the \"WannaCry\" malware. Said computer worm affected over 230,000 computers in over 150 countries throughout 2017.\n\nAnswer this question \"What is the significance of the file-sharing site MediaFire in the spread of the \"Dorkbot\" malware in 2013?\" using the text above.",
    "context": "",
    "output": "The file-sharing site MediaFire was significant in the spread of the \"Dorkbot\" malware in 2013 because attackers exploited a flaw in the site to proliferate phony applications among victims' Facebook friends.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the significance of the file-sharing site MediaFire in the spread of the \"Dorkbot\" malware in 2013?",
      "answer": "The file-sharing site MediaFire was significant in the spread of the \"Dorkbot\" malware in 2013 because attackers exploited a flaw in the site to proliferate phony applications among victims' Facebook friends.",
      "context": "Facebook malware\n\n==Introduction==\nThe social media platform and social networking service Facebook has been affected multiple times over its history by intentionally harmful software. Known as malware, these pose particular challenges both to users of the platform as well as to the personnel of the tech-company itself. Fighting the entities that create these is a topic of ongoing malware analysis.\n\n== Types of malware and notable incidents ==\nAttacks known as phishing, in which an attacker pretends to be some trustworthy entity in order to solicit private information, have increased exponentially in the 2010s and posed frustrating challenges. For Facebook in particular, tricks involving URLs are common; attackers will maliciously use a similar website such as http://faceb0ok.com/ instead of the correct http://facebook.com/, for example. The 11th International Conference on Detection of Intrusions and Malware, and Vulnerability Assessment (DIMVA), held in July 2014, issued a report condemning this as one of the \"common tricks\" that mobile computing users are especially vulnerable to.In terms of applications, Facebook has also been visually copied by phishing attackers, who aim to confuse individuals into thinking that something else is the legitimate Facebook log-in screen.In 2013, a variant of the \"Dorkbot\" malware caused alarm after spreading through Facebook's internal chat service. With suspected efforts by cybercriminals to harvest users' passwords affecting individuals from nations such as Germany, India, Portugal, and the United Kingdom. The antivirus organization Bitdefender discovered several thousand malicious links taking place in a twenty-four hour period, and contacted the Facebook administration about the problem. While the infection was contained, its unusual nature sparked interest given that the attackers exploited a flaw in the file-sharing site MediaFire to proliferate phony applications among victims' Facebook friends.The real computer worm \"Koobface\", which surfaced in 2008 via messages sent through both Facebook and MySpace, later became subject to inflated, grandiose claims about its effects and spread to the point of being an internet hoax. Later commentary claimed a link between the malware and messages about the Barack Obama administration that never actually existed. David Mikkelson of Snopes.com discussed the matter in a fact-checking article.On 26 July 2022, researchers at WithSecure discovered a cybercriminal operation that was targeting digital marketing and human resources professionals in an effort to hijack Facebook Business accounts using data-stealing malware.They dubbed the campaign as 'Ducktail' and found evidence to suggest that a Vietnamese threat actor has been developing and distributing the malware with motives appeared to be purely financially driven.\n\n== Responses ==\n\n\n*** Individual efforts ***\nIn the same vein as actions by Google and Microsoft, the company's administration has been willing to hire \"grey hat\" hackers, who have acted legally ambiguously in the past, to assist them in various functions. Programmer and social activist George Hotz (also known by the nickname \"GeoHot\") is an example.\n\n\n*** Bug Bounty Program ***\nOn July 29, 2011, Facebook announced an effort called the \"Bug Bounty Program\" in which certain security researchers will be paid a minimum of $500 for reporting security holes on Facebook's website itself. The company's official page for security researchers stated, \"If you give us a reasonable time to respond to your report before making any information public and make a good faith effort to avoid privacy violations, destruction of data, and interruption or degradation of our service during your research, we will not bring any lawsuit against you or ask law enforcement to investigate you.\" The effort attracted notice from publications such as PC Magazine, which noted that individuals must not just be the first to report the security glitch but must also find the problem native to Facebook (rather than an entity merely associated with it such as FarmVille).\n\n\n*** Targeting of specific users ***\nIn late 2017, Facebook systematically disabled accounts operated by North Koreans in response to that government's use of state-sponsored malware attacks. Microsoft did similar actions. The North Korean government had attracted widespread condemnation in the U.S. and elsewhere for its alleged proliferation of the \"WannaCry\" malware. Said computer worm affected over 230,000 computers in over 150 countries throughout 2017."
    }
  },
  {
    "instruction": "The police reacted by searching through PhantomL0rd's house but only realized later that the call was fake.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How did the police react to the fake hostage situation report?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How did the police react to the fake hostage situation report?",
      "answer": "The police reacted by searching through PhantomL0rd's house but only realized later that the call was fake."
    }
  },
  {
    "instruction": "Context: L4 microkernel family\n\n==Introduction==\nL4 is a family of second-generation microkernels, used to implement a variety of types of operating systems (OS), though mostly for Unix-like, Portable Operating System Interface (POSIX) compliant types.\nL4, like its predecessor microkernel L3, was created by German computer scientist Jochen Liedtke as a response to the poor performance of earlier microkernel-based OSes. Liedtke felt that a system designed from the start for high performance, rather than other goals, could produce a microkernel of practical use. His original implementation in hand-coded Intel i386-specific assembly language code in 1993 sparked intense interest in the computer industry. Since its introduction, L4 has been developed to be cross-platform and to improve security, isolation, and robustness.\nThere have been various re-implementations of the original binary L4 kernel application binary interface (ABI) and its successors, including L4Ka::Pistachio (implemented by Liedtke and his students at Karlsruhe Institute of Technology), L4/MIPS (University of New South Wales (UNSW)), Fiasco (Dresden University of Technology (TU Dresden)). For this reason, the name L4 has been generalized and no longer refers to only Liedtke's original implementation. It now applies to the whole microkernel family including the L4 kernel interface and its different versions.\nL4 is widely deployed. One variant, OKL4 from Open Kernel Labs, shipped in billions of mobile devices.\n\n\n\n== Design paradigm ==\nSpecifying the general idea of a microkernel, Liedtke states:\n\nA concept is tolerated inside the microkernel only if moving it outside the kernel, i.e., permitting competing implementations, would prevent the implementation of the system's required functionality.\nIn this spirit, the L4 microkernel provides few basic mechanisms: address spaces (abstracting page tables and providing memory protection), threads and scheduling (abstracting execution and providing temporal protection), and inter-process communication (for controlled communication across isolation boundaries).\nAn operating system based on a microkernel like L4 provides services as servers in user space that monolithic kernels like Linux or older generation microkernels include internally. For example, to implement a secure Unix-like system, servers must provide the rights management that Mach included inside the kernel.\n\n== Cross-platform ==\n\n\n*** L4Ka::Pistachio ***\nUp until the release of L4Ka::Pistachio and newer versions of Fiasco, all L4 microkernels had been inherently tied close to the underlying CPU architecture. The next big shift in L4 development was the development of a cross-platform (platform-independent) application programming interface (API) that still retained the high performance characteristics despite its higher level of portability. Although the underlying concepts of the kernel were the same, the new API provided many significant changes relative to prior L4 versions, including better support for multi-processor systems, looser ties between threads and address spaces, and the introduction of user-level thread control blocks (UTCBs) and virtual registers. After releasing the new L4 API (version X.2 a.k.a. version 4) in early 2001, the System Architecture Group at the University of Karlsruhe implemented a new kernel, L4Ka::Pistachio, completely from scratch, now with focus on both high performance and portability. It was released under the two-clause BSD license.\n\n\n*** Newer Fiasco versions ***\nThe L4/Fiasco microkernel has also been extensively improved over the years. It now supports several hardware platforms ranging from x86 through AMD64 to several ARM platforms. Notably, a version of Fiasco (Fiasco-UX) can run as a user-level application on Linux.\nL4/Fiasco implements several extensions to the L4v2 API. Exception IPC enables the kernel to send CPU exceptions to user-level handler applications. With the help of alien threads, it is possible to perform fine-grained control over system calls. X.2-style UTCBs have been added. Also, Fiasco contains mechanisms for controlling communication rights and kernel-level resource use. On Fiasco, a collection of basic user level services are developed (named L4Env) that among others are used to para-virtualise the current Linux version (4.19 as of May 2019) (named L4Linux).\n\n\n*** University of New South Wales and NICTA ***\nDevelopment also occurred at the University of New South Wales (UNSW), where developers implemented L4 on several 64-bit platforms. Their work resulted in L4/MIPS and L4/Alpha, resulting in Liedtke's original version being retrospectively named L4/x86. Like Liedtke's original kernels, the UNSW kernels (written in a mix of assembly and C) were unportable and each implemented from scratch. With the release of the highly portable L4Ka::Pistachio, the UNSW group abandoned their own kernels in favor of producing highly tuned ports of L4Ka::Pistachio, including the fastest-ever reported implementation of message passing (36 cycles on the Itanium architecture). The group has also demonstrated that device drivers can perform equally well at user-level as in-kernel, and developed Wombat, a highly portable version of Linux on L4 that runs on x86, ARM, and MIPS processors. On XScale processors, Wombat context-switching costs are up to 50 times lower than in native Linux.Later the UNSW group, at their new home at NICTA (formerly National ICT Australia, Ltd.), forked L4Ka::Pistachio into a new L4 version named NICTA::L4-embedded. As the name implies, it was for use in commercial embedded systems, and consequently the implementation trade-offs favored small memory size and reduced complexity. The API was modified to keep almost all system calls short enough that they need no preemption points to ensure high real-time responsiveness.\n\n== Commercial deployment ==\nIn November 2005, NICTA announced that Qualcomm was deploying NICTA's L4 version on their Mobile Station Modem chipsets. This led to the use of L4 in mobile phone handsets on sale from late 2006. In August 2006, ERTOS leader and UNSW professor Gernot Heiser spun out a company named Open Kernel Labs (OK Labs) to support commercial L4 users and further develop L4 for commercial use under the brand name OKL4, in close collaboration with NICTA. OKL4 Version 2.1, released in April 2008, was the first generally available version of L4 which featured capability-based security. OKL4 3.0, released in October 2008, was the last open-source version of OKL4. More recent versions are closed source and based on a rewrite to support a native hypervisor variant named the OKL4 Microvisor. OK Labs also distributed a paravirtualized Linux named OK:Linux, a descendant of Wombat, and paravirtualized versions of SymbianOS and Android. OK Labs also acquired the rights to seL4 from NICTA.\nOKL4 shipments exceeded 1.5 billion in early 2012, mostly on Qualcomm wireless modem chips. Other deployments include automotive infotainment systems.Apple A series processors beginning with the A7 contain a Secure Enclave coprocessor running an L4 operating system\nbased on the L4-embedded kernel developed at NICTA in 2006.\nThis implies that L4 is now shipping on all iOS devices, the total shipment of which is estimated at 310 million for the year 2015.\n\n== High assurance: seL4 ==\nIn 2006, the NICTA group commenced a from-scratch design of a third-generation microkernel, named seL4, with the aim of providing a basis for highly secure and reliable systems, suitable for satisfying security requirements such as those of Common Criteria and beyond. From the beginning, development aimed for formal verification of the kernel. To ease meeting the sometimes conflicting requirements of performance and verification, the team used a middle-out software process starting from an executable specification written in the language Haskell.\nseL4 uses capability-based security access control to enable formal reasoning about object accessibility.\nA formal proof of functional correctness was completed in 2009.\nThe proof provides a guarantee that the kernel's implementation is correct against its specification, and implies that it is free of implementation bugs such as deadlocks, livelocks, buffer overflows, arithmetic exceptions or use of uninitialised variables. seL4 is claimed to be the first-ever general-purpose operating-system kernel that has been verified.seL4 takes a novel approach to kernel resource management, exporting the management of kernel resources to user level and subjects them to the same capability-based access control as user resources. This model, which was also adopted by Barrelfish, simplifies reasoning about isolation properties, and was an enabler for later proofs that seL4 enforces the core security properties of integrity and confidentiality. The NICTA team also proved correctness of the translation from the programming language C to executable machine code, taking the compiler out of the trusted computing base of seL4.\nThis implies that the high-level security proofs hold for the kernel executable. seL4 is also the first published protected-mode OS kernel with a complete and sound worst-case execution time (WCET) analysis, a prerequisite for its use in hard real-time computing.On 29 July 2014, NICTA and General Dynamics C4 Systems announced that seL4, with end to end proofs, was now released under open-source licenses.\nThe kernel source code and proofs are licensed under GNU General Public License version 2 (GPLv2), and most libraries and tools are under the BSD 2-clause. In April 2020, it was announced that the seL4 Foundation was created under the umbrella of the Linux Foundation to accelerate development and deployment of seL4.The researchers state that the cost of formal software verification is lower than the cost of engineering traditional \"high-assurance\" software despite providing much more reliable results. Specifically, the cost of one line of code during the development of seL4 was estimated at around US$400, compared to US$1,000 for traditional high-assurance systems.Under the Defense Advanced Research Projects Agency (DARPA) High-Assurance Cyber Military Systems (HACMS) program, NICTA together with project partners Rockwell Collins, Galois Inc, the University of Minnesota and Boeing developed a high-assurance drone using seL4, along with other assurance tools and software, with planned technology transfer onto the optionally piloted autonomous Boeing AH-6 Unmanned Little Bird helicopter being developed by Boeing. Final demonstration of the HACMS technology took place in Sterling, VA in April 2017. DARPA also funded several Small Business Innovative Research (SBIR) contracts related to seL4 under a program started by Dr. John Launchbury. Small businesses receiving an seL4-related SBIR included: DornerWorks, Techshot, Wearable Inc, Real Time Innovations, and Critical Technologies.\n\n== Other research and development ==\nOsker, an OS written in Haskell, targeted the L4 specification; although this project focused mainly on the use of a functional programming language for OS development, not on microkernel research.CodeZero is an L4 microkernel for embedded systems with a focus on virtualization and implementation of native OS services. There is a GPL-licensed version, and a version that was relicensed by B Labs Ltd., acquired by Nvidia, as closed source and forked in 2010.F9 microkernel, a BSD-licensed L4 implementation, is dedicated to ARM Cortex-M processors for deeply embedded devices with memory protection.\nThe NOVA OS Virtualization Architecture is a research project with focus on constructing a secure and efficient virtualization environment\nwith a small trusted computing base. NOVA consists of a microhypervisor, a user level hypervisor (virtual machine monitor), and an unprivileged componentised multi-server user environment running on it named NUL. NOVA runs on ARMv8-A and x86-based multi-core systems.\nWrmOS is a real-time operating system based on L4 microkernel. It has own implementations of kernel, standard libraries, and network stack, supporting ARM, SPARC, x86, and x86-64 architectures. There is the paravirtualized Linux kernel (w4linux) working on WrmOS.\nHelios is a microkernel inspired by seL4. It is part of the Ares operating system, supports x86-64 and aarch64 and is still under active development as of February 2023.\nQuestion: How has the seL4 Foundation contributed to the development and deployment of seL4 since its inception in 2020?\n\nAnswer:",
    "context": "",
    "output": "The seL4 Foundation, created in April 2020, aims to accelerate the development and deployment of seL4 by fostering collaboration among researchers, developers, and organizations. By providing a central hub for the seL4 community, the foundation encourages knowledge sharing, best practices, and standardization, ultimately driving the adoption of seL4 in various applications and industries.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How has the seL4 Foundation contributed to the development and deployment of seL4 since its inception in 2020?",
      "answer": "The seL4 Foundation, created in April 2020, aims to accelerate the development and deployment of seL4 by fostering collaboration among researchers, developers, and organizations. By providing a central hub for the seL4 community, the foundation encourages knowledge sharing, best practices, and standardization, ultimately driving the adoption of seL4 in various applications and industries.",
      "context": "L4 microkernel family\n\n==Introduction==\nL4 is a family of second-generation microkernels, used to implement a variety of types of operating systems (OS), though mostly for Unix-like, Portable Operating System Interface (POSIX) compliant types.\nL4, like its predecessor microkernel L3, was created by German computer scientist Jochen Liedtke as a response to the poor performance of earlier microkernel-based OSes. Liedtke felt that a system designed from the start for high performance, rather than other goals, could produce a microkernel of practical use. His original implementation in hand-coded Intel i386-specific assembly language code in 1993 sparked intense interest in the computer industry. Since its introduction, L4 has been developed to be cross-platform and to improve security, isolation, and robustness.\nThere have been various re-implementations of the original binary L4 kernel application binary interface (ABI) and its successors, including L4Ka::Pistachio (implemented by Liedtke and his students at Karlsruhe Institute of Technology), L4/MIPS (University of New South Wales (UNSW)), Fiasco (Dresden University of Technology (TU Dresden)). For this reason, the name L4 has been generalized and no longer refers to only Liedtke's original implementation. It now applies to the whole microkernel family including the L4 kernel interface and its different versions.\nL4 is widely deployed. One variant, OKL4 from Open Kernel Labs, shipped in billions of mobile devices.\n\n\n\n== Design paradigm ==\nSpecifying the general idea of a microkernel, Liedtke states:\n\nA concept is tolerated inside the microkernel only if moving it outside the kernel, i.e., permitting competing implementations, would prevent the implementation of the system's required functionality.\nIn this spirit, the L4 microkernel provides few basic mechanisms: address spaces (abstracting page tables and providing memory protection), threads and scheduling (abstracting execution and providing temporal protection), and inter-process communication (for controlled communication across isolation boundaries).\nAn operating system based on a microkernel like L4 provides services as servers in user space that monolithic kernels like Linux or older generation microkernels include internally. For example, to implement a secure Unix-like system, servers must provide the rights management that Mach included inside the kernel.\n\n== Cross-platform ==\n\n\n*** L4Ka::Pistachio ***\nUp until the release of L4Ka::Pistachio and newer versions of Fiasco, all L4 microkernels had been inherently tied close to the underlying CPU architecture. The next big shift in L4 development was the development of a cross-platform (platform-independent) application programming interface (API) that still retained the high performance characteristics despite its higher level of portability. Although the underlying concepts of the kernel were the same, the new API provided many significant changes relative to prior L4 versions, including better support for multi-processor systems, looser ties between threads and address spaces, and the introduction of user-level thread control blocks (UTCBs) and virtual registers. After releasing the new L4 API (version X.2 a.k.a. version 4) in early 2001, the System Architecture Group at the University of Karlsruhe implemented a new kernel, L4Ka::Pistachio, completely from scratch, now with focus on both high performance and portability. It was released under the two-clause BSD license.\n\n\n*** Newer Fiasco versions ***\nThe L4/Fiasco microkernel has also been extensively improved over the years. It now supports several hardware platforms ranging from x86 through AMD64 to several ARM platforms. Notably, a version of Fiasco (Fiasco-UX) can run as a user-level application on Linux.\nL4/Fiasco implements several extensions to the L4v2 API. Exception IPC enables the kernel to send CPU exceptions to user-level handler applications. With the help of alien threads, it is possible to perform fine-grained control over system calls. X.2-style UTCBs have been added. Also, Fiasco contains mechanisms for controlling communication rights and kernel-level resource use. On Fiasco, a collection of basic user level services are developed (named L4Env) that among others are used to para-virtualise the current Linux version (4.19 as of May 2019) (named L4Linux).\n\n\n*** University of New South Wales and NICTA ***\nDevelopment also occurred at the University of New South Wales (UNSW), where developers implemented L4 on several 64-bit platforms. Their work resulted in L4/MIPS and L4/Alpha, resulting in Liedtke's original version being retrospectively named L4/x86. Like Liedtke's original kernels, the UNSW kernels (written in a mix of assembly and C) were unportable and each implemented from scratch. With the release of the highly portable L4Ka::Pistachio, the UNSW group abandoned their own kernels in favor of producing highly tuned ports of L4Ka::Pistachio, including the fastest-ever reported implementation of message passing (36 cycles on the Itanium architecture). The group has also demonstrated that device drivers can perform equally well at user-level as in-kernel, and developed Wombat, a highly portable version of Linux on L4 that runs on x86, ARM, and MIPS processors. On XScale processors, Wombat context-switching costs are up to 50 times lower than in native Linux.Later the UNSW group, at their new home at NICTA (formerly National ICT Australia, Ltd.), forked L4Ka::Pistachio into a new L4 version named NICTA::L4-embedded. As the name implies, it was for use in commercial embedded systems, and consequently the implementation trade-offs favored small memory size and reduced complexity. The API was modified to keep almost all system calls short enough that they need no preemption points to ensure high real-time responsiveness.\n\n== Commercial deployment ==\nIn November 2005, NICTA announced that Qualcomm was deploying NICTA's L4 version on their Mobile Station Modem chipsets. This led to the use of L4 in mobile phone handsets on sale from late 2006. In August 2006, ERTOS leader and UNSW professor Gernot Heiser spun out a company named Open Kernel Labs (OK Labs) to support commercial L4 users and further develop L4 for commercial use under the brand name OKL4, in close collaboration with NICTA. OKL4 Version 2.1, released in April 2008, was the first generally available version of L4 which featured capability-based security. OKL4 3.0, released in October 2008, was the last open-source version of OKL4. More recent versions are closed source and based on a rewrite to support a native hypervisor variant named the OKL4 Microvisor. OK Labs also distributed a paravirtualized Linux named OK:Linux, a descendant of Wombat, and paravirtualized versions of SymbianOS and Android. OK Labs also acquired the rights to seL4 from NICTA.\nOKL4 shipments exceeded 1.5 billion in early 2012, mostly on Qualcomm wireless modem chips. Other deployments include automotive infotainment systems.Apple A series processors beginning with the A7 contain a Secure Enclave coprocessor running an L4 operating system\nbased on the L4-embedded kernel developed at NICTA in 2006.\nThis implies that L4 is now shipping on all iOS devices, the total shipment of which is estimated at 310 million for the year 2015.\n\n== High assurance: seL4 ==\nIn 2006, the NICTA group commenced a from-scratch design of a third-generation microkernel, named seL4, with the aim of providing a basis for highly secure and reliable systems, suitable for satisfying security requirements such as those of Common Criteria and beyond. From the beginning, development aimed for formal verification of the kernel. To ease meeting the sometimes conflicting requirements of performance and verification, the team used a middle-out software process starting from an executable specification written in the language Haskell.\nseL4 uses capability-based security access control to enable formal reasoning about object accessibility.\nA formal proof of functional correctness was completed in 2009.\nThe proof provides a guarantee that the kernel's implementation is correct against its specification, and implies that it is free of implementation bugs such as deadlocks, livelocks, buffer overflows, arithmetic exceptions or use of uninitialised variables. seL4 is claimed to be the first-ever general-purpose operating-system kernel that has been verified.seL4 takes a novel approach to kernel resource management, exporting the management of kernel resources to user level and subjects them to the same capability-based access control as user resources. This model, which was also adopted by Barrelfish, simplifies reasoning about isolation properties, and was an enabler for later proofs that seL4 enforces the core security properties of integrity and confidentiality. The NICTA team also proved correctness of the translation from the programming language C to executable machine code, taking the compiler out of the trusted computing base of seL4.\nThis implies that the high-level security proofs hold for the kernel executable. seL4 is also the first published protected-mode OS kernel with a complete and sound worst-case execution time (WCET) analysis, a prerequisite for its use in hard real-time computing.On 29 July 2014, NICTA and General Dynamics C4 Systems announced that seL4, with end to end proofs, was now released under open-source licenses.\nThe kernel source code and proofs are licensed under GNU General Public License version 2 (GPLv2), and most libraries and tools are under the BSD 2-clause. In April 2020, it was announced that the seL4 Foundation was created under the umbrella of the Linux Foundation to accelerate development and deployment of seL4.The researchers state that the cost of formal software verification is lower than the cost of engineering traditional \"high-assurance\" software despite providing much more reliable results. Specifically, the cost of one line of code during the development of seL4 was estimated at around US$400, compared to US$1,000 for traditional high-assurance systems.Under the Defense Advanced Research Projects Agency (DARPA) High-Assurance Cyber Military Systems (HACMS) program, NICTA together with project partners Rockwell Collins, Galois Inc, the University of Minnesota and Boeing developed a high-assurance drone using seL4, along with other assurance tools and software, with planned technology transfer onto the optionally piloted autonomous Boeing AH-6 Unmanned Little Bird helicopter being developed by Boeing. Final demonstration of the HACMS technology took place in Sterling, VA in April 2017. DARPA also funded several Small Business Innovative Research (SBIR) contracts related to seL4 under a program started by Dr. John Launchbury. Small businesses receiving an seL4-related SBIR included: DornerWorks, Techshot, Wearable Inc, Real Time Innovations, and Critical Technologies.\n\n== Other research and development ==\nOsker, an OS written in Haskell, targeted the L4 specification; although this project focused mainly on the use of a functional programming language for OS development, not on microkernel research.CodeZero is an L4 microkernel for embedded systems with a focus on virtualization and implementation of native OS services. There is a GPL-licensed version, and a version that was relicensed by B Labs Ltd., acquired by Nvidia, as closed source and forked in 2010.F9 microkernel, a BSD-licensed L4 implementation, is dedicated to ARM Cortex-M processors for deeply embedded devices with memory protection.\nThe NOVA OS Virtualization Architecture is a research project with focus on constructing a secure and efficient virtualization environment\nwith a small trusted computing base. NOVA consists of a microhypervisor, a user level hypervisor (virtual machine monitor), and an unprivileged componentised multi-server user environment running on it named NUL. NOVA runs on ARMv8-A and x86-based multi-core systems.\nWrmOS is a real-time operating system based on L4 microkernel. It has own implementations of kernel, standard libraries, and network stack, supporting ARM, SPARC, x86, and x86-64 architectures. There is the paravirtualized Linux kernel (w4linux) working on WrmOS.\nHelios is a microkernel inspired by seL4. It is part of the Ares operating system, supports x86-64 and aarch64 and is still under active development as of February 2023."
    }
  },
  {
    "instruction": "The purpose of forwarding messages in a relay attack is to allow the attacker to communicate with the legitimate user's device and impersonate the user in the communication system.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the purpose of forwarding messages in a relay attack?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the purpose of forwarding messages in a relay attack?",
      "answer": "The purpose of forwarding messages in a relay attack is to allow the attacker to communicate with the legitimate user's device and impersonate the user in the communication system."
    }
  },
  {
    "instruction": "Network forensics is the monitoring and analysis of computer network traffic for the purposes of information gathering, legal evidence, or intrusion detection. It deals with volatile and dynamic information and has two main uses: security, where it involves monitoring a network for anomalous traffic and identifying intrusions, and law enforcement, where analysis of captured network traffic can include tasks such as reassembling transferred files, searching for keywords, and parsing human communication such as emails or chat sessions.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is network forensics and what are its two main uses?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is network forensics and what are its two main uses?",
      "answer": "Network forensics is the monitoring and analysis of computer network traffic for the purposes of information gathering, legal evidence, or intrusion detection. It deals with volatile and dynamic information and has two main uses: security, where it involves monitoring a network for anomalous traffic and identifying intrusions, and law enforcement, where analysis of captured network traffic can include tasks such as reassembling transferred files, searching for keywords, and parsing human communication such as emails or chat sessions."
    }
  },
  {
    "instruction": "Speculative execution is a technique used in modern computers to improve performance by allowing the microprocessor to predict and execute instructions before the earlier operations have completed. When the earlier operation completes, the microprocessor determines whether the prediction was correct, and if it was incorrect, it rolls back the speculatively executed operations and repeats the original instruction with the real result. While this speculative execution may not be directly visible in the behavior of the computer, it can affect the state of certain components, like the cache. Attackers can exploit this by arranging for speculatively executed code to operate on secret data that they are unauthorized to access, and observing the effect of the speculative execution on the cache to infer the value of the secret data.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does speculative execution affect the behavior of a computer system, and how can it be exploited by attackers?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does speculative execution affect the behavior of a computer system, and how can it be exploited by attackers?",
      "answer": "Speculative execution is a technique used in modern computers to improve performance by allowing the microprocessor to predict and execute instructions before the earlier operations have completed. When the earlier operation completes, the microprocessor determines whether the prediction was correct, and if it was incorrect, it rolls back the speculatively executed operations and repeats the original instruction with the real result. While this speculative execution may not be directly visible in the behavior of the computer, it can affect the state of certain components, like the cache. Attackers can exploit this by arranging for speculatively executed code to operate on secret data that they are unauthorized to access, and observing the effect of the speculative execution on the cache to infer the value of the secret data."
    }
  },
  {
    "instruction": "The user accesses the hidden volume by providing the password/key of the hidden volume, which proves valid and mounts the hidden volume.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does the user access the hidden volume in disk encryption software?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does the user access the hidden volume in disk encryption software?",
      "answer": "The user accesses the hidden volume by providing the password/key of the hidden volume, which proves valid and mounts the hidden volume."
    }
  },
  {
    "instruction": "In the EU, personally identifiable information is protected by information privacy laws, which outline limits to the collection and use of personally identifiable information by public and private entities. The General Data Protection Regulation (GDPR) regulates the collection and use of personal data and electronic documents by public and private organizations, and provides for a harmonization of the data protection regulations throughout the EU. The GDPR also brings a new set of \"digital rights\" for EU citizens in an age when the economic value of personal data is increasing in the digital economy.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What are the legal protections for personal and private information in the EU?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What are the legal protections for personal and private information in the EU?",
      "answer": "In the EU, personally identifiable information is protected by information privacy laws, which outline limits to the collection and use of personally identifiable information by public and private entities. The General Data Protection Regulation (GDPR) regulates the collection and use of personal data and electronic documents by public and private organizations, and provides for a harmonization of the data protection regulations throughout the EU. The GDPR also brings a new set of \"digital rights\" for EU citizens in an age when the economic value of personal data is increasing in the digital economy."
    }
  },
  {
    "instruction": "Some methods used by organizations to detect internet shutdowns include expert analysis, remote sensing, and remote sensing with oversight. Expert analysis involves surveying multiple experts and aggregating their answers, while remote sensing techniques use software installed on computers of volunteers around the world to detect shutdowns. Remote sensing with automated oversight is a comparatively new method that uses technological methods to detect shutdowns, but then confirms those shutdowns using news reports, reports from local activists, official government statements, and statements from ISPs.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What are some methods used by organizations to detect internet shutdowns?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What are some methods used by organizations to detect internet shutdowns?",
      "answer": "Some methods used by organizations to detect internet shutdowns include expert analysis, remote sensing, and remote sensing with oversight. Expert analysis involves surveying multiple experts and aggregating their answers, while remote sensing techniques use software installed on computers of volunteers around the world to detect shutdowns. Remote sensing with automated oversight is a comparatively new method that uses technological methods to detect shutdowns, but then confirms those shutdowns using news reports, reports from local activists, official government statements, and statements from ISPs."
    }
  },
  {
    "instruction": "Libraries and toolkits are used by developers to integrate applications and services into SAML federations or to build their own SAML-actors like IdPs. They provide the necessary functionality to interact with SAML protocols and facilitate the development of SAML-enabled services.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What are libraries and toolkits used for in the context of SAML?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What are libraries and toolkits used for in the context of SAML?",
      "answer": "Libraries and toolkits are used by developers to integrate applications and services into SAML federations or to build their own SAML-actors like IdPs. They provide the necessary functionality to interact with SAML protocols and facilitate the development of SAML-enabled services."
    }
  },
  {
    "instruction": "The \"Internet Connection Firewall\" was disabled by default in Windows XP due to concerns with backward compatibility and the configuration screens being buried away in network configuration screens that many users never looked at.\n\nWrite a question about the text above.",
    "context": "",
    "output": "Why was the \"Internet Connection Firewall\" disabled by default in Windows XP?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "Why was the \"Internet Connection Firewall\" disabled by default in Windows XP?",
      "answer": "The \"Internet Connection Firewall\" was disabled by default in Windows XP due to concerns with backward compatibility and the configuration screens being buried away in network configuration screens that many users never looked at."
    }
  },
  {
    "instruction": "LibreSSL replaced custom memory calls with standard library functions such as strlcpy, calloc, asprintf, reallocarray, etc. This change helps in catching buffer overflow errors with advanced memory analysis tools or by observing program crashes through ASLR, use of the NX bit, stack canaries, etc. Additionally, fixes for potential double free scenarios and extra sanity checks related to length arguments, unsigned-to-signed variable assignments, pointer values, and method returns have been implemented.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How did LibreSSL address memory-related issues in their codebase?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How did LibreSSL address memory-related issues in their codebase?",
      "answer": "LibreSSL replaced custom memory calls with standard library functions such as strlcpy, calloc, asprintf, reallocarray, etc. This change helps in catching buffer overflow errors with advanced memory analysis tools or by observing program crashes through ASLR, use of the NX bit, stack canaries, etc. Additionally, fixes for potential double free scenarios and extra sanity checks related to length arguments, unsigned-to-signed variable assignments, pointer values, and method returns have been implemented."
    }
  },
  {
    "instruction": "Context: TUN/TAP\n\n==Introduction==\nIn computer networking, TUN and TAP are kernel virtual network devices. Being network devices supported entirely in software, they differ from ordinary network devices which are backed by physical network adapters.\nThe Universal TUN/TAP Driver originated in 2000 as a merger of the corresponding drivers in Solaris, Linux and BSD. The driver continues to be maintained as part of the Linux and FreeBSD kernels.\n\n\n\n== Design ==\n\nThough both are for tunneling purposes, TUN and TAP can't be used together because they transmit and receive packets at different layers of the network stack. TUN, namely network TUNnel, simulates a network layer device and operates in layer 3 carrying IP packets. TAP, namely network TAP, simulates a link layer device and operates in layer 2 carrying Ethernet frames. TUN is used with routing. TAP can be used to create a user space network bridge.Packets sent by an operating system via a TUN/TAP device are delivered to a user space program which attaches itself to the device. A user space program may also pass packets into a TUN/TAP device. In this case the TUN/TAP device delivers (or \"injects\") these packets to the operating-system network stack thus emulating their reception from an external source.\n\n== Applications ==\nVirtual private networks\nOpenVPN, Ethernet/IP over TCP/UDP; encrypted, compressed\nZeroTier, Ethernet/IP over TCP/UDP; encrypted, compressed, cryptographic addressing scheme\nFreeLAN, open-source, free, multi-platform IPv4, IPv6 and peer-to-peer VPN software over UDP/IP.\nn2n, an open source Layer 2 over Layer 3 VPN application which uses a peer-to-peer architecture for network membership and routing\nTinc, Ethernet/IPv4/IPv6 over TCP/UDP; encrypted, compressed\nVTun, Ethernet/IP/serial/Unix pipe over TCP; encrypted, compressed, traffic-shaping\nOpenSSH\ncoLinux, Ethernet/IP over TCP/UDP\nHamachi\nOpenConnect\nWireGuard\nTailscaleVirtual-machine networking\nBochs\ncoLinux\nHercules (S/390 emulator)\nOpen vSwitch\nQEMU/KVM\nUser-mode Linux\nVirtualBoxConnecting real machines with network simulation\nns-3\nGNU RadioNAT\nTAYGA, a stateless NAT64 implementation for Linux\n\n== Platforms ==\nPlatforms with TUN/TAP drivers include:\n\nFreeBSD\nLinux, starting around version 2.1.60 of the Linux kernel mainline\niOS (tun driver only)\nmacOS (native support only for TUN (utun))\nNetBSD\nOpenBSD\nAndroid\nSolaris\nWindows 2000/XP/Vista/7/8/8.1/10\nQNX\nQuestion: What platforms support TUN/TAP drivers?\n\nAnswer:",
    "context": "",
    "output": "Platforms that support TUN/TAP drivers include FreeBSD, Linux, iOS, macOS, NetBSD, OpenBSD, Android, Solaris, Windows 2000/XP/Vista/7/8/8.1/10, and QNX.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What platforms support TUN/TAP drivers?",
      "answer": "Platforms that support TUN/TAP drivers include FreeBSD, Linux, iOS, macOS, NetBSD, OpenBSD, Android, Solaris, Windows 2000/XP/Vista/7/8/8.1/10, and QNX.",
      "context": "TUN/TAP\n\n==Introduction==\nIn computer networking, TUN and TAP are kernel virtual network devices. Being network devices supported entirely in software, they differ from ordinary network devices which are backed by physical network adapters.\nThe Universal TUN/TAP Driver originated in 2000 as a merger of the corresponding drivers in Solaris, Linux and BSD. The driver continues to be maintained as part of the Linux and FreeBSD kernels.\n\n\n\n== Design ==\n\nThough both are for tunneling purposes, TUN and TAP can't be used together because they transmit and receive packets at different layers of the network stack. TUN, namely network TUNnel, simulates a network layer device and operates in layer 3 carrying IP packets. TAP, namely network TAP, simulates a link layer device and operates in layer 2 carrying Ethernet frames. TUN is used with routing. TAP can be used to create a user space network bridge.Packets sent by an operating system via a TUN/TAP device are delivered to a user space program which attaches itself to the device. A user space program may also pass packets into a TUN/TAP device. In this case the TUN/TAP device delivers (or \"injects\") these packets to the operating-system network stack thus emulating their reception from an external source.\n\n== Applications ==\nVirtual private networks\nOpenVPN, Ethernet/IP over TCP/UDP; encrypted, compressed\nZeroTier, Ethernet/IP over TCP/UDP; encrypted, compressed, cryptographic addressing scheme\nFreeLAN, open-source, free, multi-platform IPv4, IPv6 and peer-to-peer VPN software over UDP/IP.\nn2n, an open source Layer 2 over Layer 3 VPN application which uses a peer-to-peer architecture for network membership and routing\nTinc, Ethernet/IPv4/IPv6 over TCP/UDP; encrypted, compressed\nVTun, Ethernet/IP/serial/Unix pipe over TCP; encrypted, compressed, traffic-shaping\nOpenSSH\ncoLinux, Ethernet/IP over TCP/UDP\nHamachi\nOpenConnect\nWireGuard\nTailscaleVirtual-machine networking\nBochs\ncoLinux\nHercules (S/390 emulator)\nOpen vSwitch\nQEMU/KVM\nUser-mode Linux\nVirtualBoxConnecting real machines with network simulation\nns-3\nGNU RadioNAT\nTAYGA, a stateless NAT64 implementation for Linux\n\n== Platforms ==\nPlatforms with TUN/TAP drivers include:\n\nFreeBSD\nLinux, starting around version 2.1.60 of the Linux kernel mainline\niOS (tun driver only)\nmacOS (native support only for TUN (utun))\nNetBSD\nOpenBSD\nAndroid\nSolaris\nWindows 2000/XP/Vista/7/8/8.1/10\nQNX"
    }
  },
  {
    "instruction": "LogLogic's log management platform translates different log formats by using specialized software that can interpret and convert the various log formats into a standard format that can be searched and analyzed.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does LogLogic's log management platform translate different log formats?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does LogLogic's log management platform translate different log formats?",
      "answer": "LogLogic's log management platform translates different log formats by using specialized software that can interpret and convert the various log formats into a standard format that can be searched and analyzed."
    }
  },
  {
    "instruction": "The official Intel website can provide a detailed and updated listing of affected products.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the official Intel website where a detailed and updated listing of affected products can be found?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the official Intel website where a detailed and updated listing of affected products can be found?",
      "answer": "The official Intel website can provide a detailed and updated listing of affected products."
    }
  },
  {
    "instruction": "The Act prohibits the processing of special personal data, which includes information relating to the race, color, ethnic or tribal origin of the data subject, political opinions, religious beliefs, health, sexual life, and criminal behavior of an individual. However, special personal data may be processed where it is necessary or the data subject has given consent to the processing, where it is necessary for the protection of the vital interest of the data subject, or where it is required for legal proceedings.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the prohibition on processing special personal data, and what are the exceptions to this prohibition?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the prohibition on processing special personal data, and what are the exceptions to this prohibition?",
      "answer": "The Act prohibits the processing of special personal data, which includes information relating to the race, color, ethnic or tribal origin of the data subject, political opinions, religious beliefs, health, sexual life, and criminal behavior of an individual. However, special personal data may be processed where it is necessary or the data subject has given consent to the processing, where it is necessary for the protection of the vital interest of the data subject, or where it is required for legal proceedings."
    }
  },
  {
    "instruction": "The attackers were operating from servers in Russia, Albania, and China during Operation High Roller.\n\nWrite a question about the text above.",
    "context": "",
    "output": "From where were the attackers operating in Operation High Roller?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "From where were the attackers operating in Operation High Roller?",
      "answer": "The attackers were operating from servers in Russia, Albania, and China during Operation High Roller."
    }
  },
  {
    "instruction": "Encryption strength can weaken over time as computing speed becomes more efficient and more time is available to discover exploits in secure systems. This can make data more vulnerable to unauthorized access or decryption, particularly if the encryption method used is not regularly updated or strengthened.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How can encryption strength weaken over time and what are the potential impacts of this?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How can encryption strength weaken over time and what are the potential impacts of this?",
      "answer": "Encryption strength can weaken over time as computing speed becomes more efficient and more time is available to discover exploits in secure systems. This can make data more vulnerable to unauthorized access or decryption, particularly if the encryption method used is not regularly updated or strengthened."
    }
  },
  {
    "instruction": "Chen, Page, and Smart proposed a new elliptic curve cryptography scheme using Barreto\u2013Naehrig curves. This scheme is implemented by both EPID 2.0 and the TPM 2.0 standard and is recommended for TPMs in general.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the recommended elliptic curve cryptography scheme for TPMs in general?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the recommended elliptic curve cryptography scheme for TPMs in general?",
      "answer": "Chen, Page, and Smart proposed a new elliptic curve cryptography scheme using Barreto\u2013Naehrig curves. This scheme is implemented by both EPID 2.0 and the TPM 2.0 standard and is recommended for TPMs in general."
    }
  },
  {
    "instruction": "A successful key or plaintext recovery attack against a cipher could allow an attacker to gain unauthorized access to encrypted data, leading to potential data breaches or other security incidents. In addition, such an attack could undermine confidence in the affected cipher and lead to its replacement.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What are some potential consequences of a successful key or plaintext recovery attack against a cipher?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What are some potential consequences of a successful key or plaintext recovery attack against a cipher?",
      "answer": "A successful key or plaintext recovery attack against a cipher could allow an attacker to gain unauthorized access to encrypted data, leading to potential data breaches or other security incidents. In addition, such an attack could undermine confidence in the affected cipher and lead to its replacement."
    }
  },
  {
    "instruction": "Key management in hardware-based FDE solutions is handled independently from the computer's CPU, allowing for secure and transparent encryption of the complete data store. This removes computer memory as a potential attack vector. In the case of SEDs, key management takes place within the hard disk controller and encryption keys are 128 or 256 bit Advanced Encryption Standard (AES) keys.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How do hardware-based FDE solutions address the issue of key management?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How do hardware-based FDE solutions address the issue of key management?",
      "answer": "Key management in hardware-based FDE solutions is handled independently from the computer's CPU, allowing for secure and transparent encryption of the complete data store. This removes computer memory as a potential attack vector. In the case of SEDs, key management takes place within the hard disk controller and encryption keys are 128 or 256 bit Advanced Encryption Standard (AES) keys."
    }
  },
  {
    "instruction": "The Sri Lanka Computer Emergency Readiness Team and the Information Technology Society of Sri Lanka (ITSSL) are currently investigating the first cyberattack on the LK Domain Registry website.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What entities are currently investigating the first cyberattack on the LK Domain Registry website?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What entities are currently investigating the first cyberattack on the LK Domain Registry website?",
      "answer": "The Sri Lanka Computer Emergency Readiness Team and the Information Technology Society of Sri Lanka (ITSSL) are currently investigating the first cyberattack on the LK Domain Registry website."
    }
  },
  {
    "instruction": "The assignation of letters to numbers was frequently changed in the shackle code system, requiring the distribution of codes to each party in advance.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How frequently was the assignation of letters to numbers changed in the shackle code system?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How frequently was the assignation of letters to numbers changed in the shackle code system?",
      "answer": "The assignation of letters to numbers was frequently changed in the shackle code system, requiring the distribution of codes to each party in advance."
    }
  },
  {
    "instruction": "The Web Services Security Policy Language based on the WS-Policy framework uses an XML-based language that is published as version 1.3 in Feb. 2009.\n\nWrite a question about the text above.",
    "context": "",
    "output": "Which XML-based language is used for the Web Services Security Policy Language based on the WS-Policy framework?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "Which XML-based language is used for the Web Services Security Policy Language based on the WS-Policy framework?",
      "answer": "The Web Services Security Policy Language based on the WS-Policy framework uses an XML-based language that is published as version 1.3 in Feb. 2009."
    }
  },
  {
    "instruction": "Black hat (computer security)\n\n==Introduction==\nA black hat (black hat hacker or blackhat) is a computer hacker who usually violates laws or typical ethical standards. The term originates from 1950s westerns, when bad guys typically wore black hats and good guys white hats. Black hat hackers aim to hack into any system for their own profit or out of malice. A black hat is contrasted with a white hat. A third category is the gray hat, a person who hacks with good intentions but sometimes without permission.\n\n== Description ==\nCriminals who intentionally enter computer networks with malicious intent are known as \"black hat hackers\". They may distribute malware that steals data (particularly login credentials), financial information, or personal information (such as passwords or credit card numbers). This information is often then sold on the dark web. Malware can also be used to hold computers hostage or destroy files. Some hackers modify or destroy data in addition to stealing it. Even though hacking has become an important tool for governments to gather intelligence, black hats still tend to work alone or with organized crime groups to make easy money.Black hat hackers can be novices or experienced criminals. They are usually knowledgeable about infiltrating computer networks and getting around security protocols. They also create malware, a form of software that lets them access computer networks, monitor their victims' online activities, or lock their victims' devices. Black hat hackers can be involved in cyber espionage or protest, in addition to pursuing personal or financial gain. For some, cybercrime may be an addictive experience.\n\n== Strategies ==\n\n\n*** Concealing substance ***\nOne of the most famous black hat methods is to utilize nasty \"entryway pages,\" which are intended only for watchwords. Accordingly, the substance of these entryway pages is stowed away from both the clients and the web indexes. Entryway pages are designed to deceive search engines so that they cannot index or rank a website for synonymous keywords or phrases.\n\n\n*** Keyword stuffing ***\nAnother form of black hat search engine optimization (SEO) is known as keyword stuffing, which involves repeatedly using the same keywords to try to trick search engines. This tactic involves using irrelevant keywords on a webpage (such as on the homepage or in metadata tags) to make it appear more relevant for particular keywords, deceiving people who visit the site.\n\n\n*** Link farming ***\nLink farming occurs when multiple websites or pages link to your website. This is done in order to profit from the pay-per-click (PPC) advertisements on these websites or pages. The issue is that the links only point to your website because it promises something in return, when in fact they are only there to increase traffic to another page you own and its popularity. These websites are unethical and will damage the credibility of the other pages you worked so hard on, possibly reducing your income potential.\n\n\n*** Shrouding ***\nShrouding involves showing different content to clients and web search tools. A website may present search engines with information irrelevant to the website's real content. This is done to boost the website's visibility in search results.\n\n\n*** Spamdexing ***\nSpamdexing is a form of black hat SEO that involves using software to inject backlinks to a website into search engine results. This is done solely for the purpose of raising the website's ranking in search engines.\n\n\n*** Unethical redirects ***\nA redirect link is considered unethical if it takes the user to a webpage different from the one indicated in the link. For instance, it is unethical to have a link that should take the user to the website \"ABC\", but instead takes them to \"XYZ\". Users are tricked into following an unintended path, even though they might not be interested in the website they land on.\n\n== Examples of famous black hats ==\n\nKevin Mitnick is one of the most well-known black hat hackers. At one point, he was the most wanted cybercriminal in the world. He hacked into over forty major corporations, including Motorola and IBM, and even the US National Defense warning system. He was taken into custody and incarcerated in 1995. He became a cybersecurity consultant after his release in 2001, utilizing his hacking expertise for white hat hacking.\nVladimir Leonidovich Levin is a Russian hacker who, while working with a dial-up connection and a laptop from his Saint Petersburg apartment in 1994, accessed the accounts of several large corporate customers of Citibank, stealing USD$10.7 million. He ended up spending three years in jail. However, in 2005, an anonymous hacker group claimed responsibility for the theft, stating that they only sold Vladimir the data needed to steal the money.\n\n== Other hat types ==\n\n\n*** White hat ***\nAn ethical security hacker is referred to as a white hat or white-hat hacker. The term \"ethical hacking\" is meant to mean more than just penetration testing. White hat hackers aim to discover any flaws in the current system with the owner's permission. While a black hat will illegally exploit a vulnerability or instruct others on how to do so, a white hat hacker will only exploit it with permission and will not reveal its existence until it has been fixed. Teams known as \"sneakers and/or hacker clubs,\" \"red teams,\" or \"tiger teams\" are also common among white-hat hackers.\n\n\n*** Gray hat ***\nA grey hat is a hacker who typically does not have malicious intent but often violate laws or common ethical standards. A vulnerability will not be illegally exploited by a grey hat, nor will it instruct others on how to do so; however, the grey hat may trade this information for personal gain. A special group of gray hats are hacktivists, who hack to promote social change.The ideas of \"white hat\" and \"black hat\" hackers led to the use of the term \"gray hat\" at the end of the 1990s.\nAnother difference between these types of hackers is how they find vulnerabilities. The black hat will break into any system or network in order to uncover sensitive information for personal gain, whereas the white hat does so at the request of their employer or with explicit permission to determine how secure it is against hackers. The grey hat typically possesses the white hat's skills and intentions, and the black hat's disregard for permission or laws.\n\nAnswer this question \"How does link farming work and why is it considered unethical?\" using the text above.",
    "context": "",
    "output": "Link farming involves multiple websites or pages linking to a target website to profit from pay-per-click (PPC) advertisements or increase traffic. This tactic is unethical because the links are often not genuine and can damage the credibility of the target website, potentially reducing its income potential.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does link farming work and why is it considered unethical?",
      "answer": "Link farming involves multiple websites or pages linking to a target website to profit from pay-per-click (PPC) advertisements or increase traffic. This tactic is unethical because the links are often not genuine and can damage the credibility of the target website, potentially reducing its income potential.",
      "context": "Black hat (computer security)\n\n==Introduction==\nA black hat (black hat hacker or blackhat) is a computer hacker who usually violates laws or typical ethical standards. The term originates from 1950s westerns, when bad guys typically wore black hats and good guys white hats. Black hat hackers aim to hack into any system for their own profit or out of malice. A black hat is contrasted with a white hat. A third category is the gray hat, a person who hacks with good intentions but sometimes without permission.\n\n== Description ==\nCriminals who intentionally enter computer networks with malicious intent are known as \"black hat hackers\". They may distribute malware that steals data (particularly login credentials), financial information, or personal information (such as passwords or credit card numbers). This information is often then sold on the dark web. Malware can also be used to hold computers hostage or destroy files. Some hackers modify or destroy data in addition to stealing it. Even though hacking has become an important tool for governments to gather intelligence, black hats still tend to work alone or with organized crime groups to make easy money.Black hat hackers can be novices or experienced criminals. They are usually knowledgeable about infiltrating computer networks and getting around security protocols. They also create malware, a form of software that lets them access computer networks, monitor their victims' online activities, or lock their victims' devices. Black hat hackers can be involved in cyber espionage or protest, in addition to pursuing personal or financial gain. For some, cybercrime may be an addictive experience.\n\n== Strategies ==\n\n\n*** Concealing substance ***\nOne of the most famous black hat methods is to utilize nasty \"entryway pages,\" which are intended only for watchwords. Accordingly, the substance of these entryway pages is stowed away from both the clients and the web indexes. Entryway pages are designed to deceive search engines so that they cannot index or rank a website for synonymous keywords or phrases.\n\n\n*** Keyword stuffing ***\nAnother form of black hat search engine optimization (SEO) is known as keyword stuffing, which involves repeatedly using the same keywords to try to trick search engines. This tactic involves using irrelevant keywords on a webpage (such as on the homepage or in metadata tags) to make it appear more relevant for particular keywords, deceiving people who visit the site.\n\n\n*** Link farming ***\nLink farming occurs when multiple websites or pages link to your website. This is done in order to profit from the pay-per-click (PPC) advertisements on these websites or pages. The issue is that the links only point to your website because it promises something in return, when in fact they are only there to increase traffic to another page you own and its popularity. These websites are unethical and will damage the credibility of the other pages you worked so hard on, possibly reducing your income potential.\n\n\n*** Shrouding ***\nShrouding involves showing different content to clients and web search tools. A website may present search engines with information irrelevant to the website's real content. This is done to boost the website's visibility in search results.\n\n\n*** Spamdexing ***\nSpamdexing is a form of black hat SEO that involves using software to inject backlinks to a website into search engine results. This is done solely for the purpose of raising the website's ranking in search engines.\n\n\n*** Unethical redirects ***\nA redirect link is considered unethical if it takes the user to a webpage different from the one indicated in the link. For instance, it is unethical to have a link that should take the user to the website \"ABC\", but instead takes them to \"XYZ\". Users are tricked into following an unintended path, even though they might not be interested in the website they land on.\n\n== Examples of famous black hats ==\n\nKevin Mitnick is one of the most well-known black hat hackers. At one point, he was the most wanted cybercriminal in the world. He hacked into over forty major corporations, including Motorola and IBM, and even the US National Defense warning system. He was taken into custody and incarcerated in 1995. He became a cybersecurity consultant after his release in 2001, utilizing his hacking expertise for white hat hacking.\nVladimir Leonidovich Levin is a Russian hacker who, while working with a dial-up connection and a laptop from his Saint Petersburg apartment in 1994, accessed the accounts of several large corporate customers of Citibank, stealing USD$10.7 million. He ended up spending three years in jail. However, in 2005, an anonymous hacker group claimed responsibility for the theft, stating that they only sold Vladimir the data needed to steal the money.\n\n== Other hat types ==\n\n\n*** White hat ***\nAn ethical security hacker is referred to as a white hat or white-hat hacker. The term \"ethical hacking\" is meant to mean more than just penetration testing. White hat hackers aim to discover any flaws in the current system with the owner's permission. While a black hat will illegally exploit a vulnerability or instruct others on how to do so, a white hat hacker will only exploit it with permission and will not reveal its existence until it has been fixed. Teams known as \"sneakers and/or hacker clubs,\" \"red teams,\" or \"tiger teams\" are also common among white-hat hackers.\n\n\n*** Gray hat ***\nA grey hat is a hacker who typically does not have malicious intent but often violate laws or common ethical standards. A vulnerability will not be illegally exploited by a grey hat, nor will it instruct others on how to do so; however, the grey hat may trade this information for personal gain. A special group of gray hats are hacktivists, who hack to promote social change.The ideas of \"white hat\" and \"black hat\" hackers led to the use of the term \"gray hat\" at the end of the 1990s.\nAnother difference between these types of hackers is how they find vulnerabilities. The black hat will break into any system or network in order to uncover sensitive information for personal gain, whereas the white hat does so at the request of their employer or with explicit permission to determine how secure it is against hackers. The grey hat typically possesses the white hat's skills and intentions, and the black hat's disregard for permission or laws."
    }
  },
  {
    "instruction": "Network Admission Control can use network packet signatures or anomalies to control access to a network based on the applications and settings that a particular system is using.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does Network Admission Control use network packet signatures or anomalies?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does Network Admission Control use network packet signatures or anomalies?",
      "answer": "Network Admission Control can use network packet signatures or anomalies to control access to a network based on the applications and settings that a particular system is using."
    }
  },
  {
    "instruction": "The use of cloaked URLs in website spoofing can be detected through techniques such as checking for domain forwarding or control characters in the URL. These techniques can help users determine the true address of the website and avoid falling victim to phishing attacks.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How can the use of cloaked URLs in website spoofing be detected?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How can the use of cloaked URLs in website spoofing be detected?",
      "answer": "The use of cloaked URLs in website spoofing can be detected through techniques such as checking for domain forwarding or control characters in the URL. These techniques can help users determine the true address of the website and avoid falling victim to phishing attacks."
    }
  },
  {
    "instruction": "Cyberwarfare training programs such as those at the Korea Institute of Military Science and Technology's research center have used the principles and methodologies of the LARIAT platform in the development of simulated threat generators for cyberwarfare training.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How have the principles and methodologies of the LARIAT platform been applied in the field of cyberwarfare training?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How have the principles and methodologies of the LARIAT platform been applied in the field of cyberwarfare training?",
      "answer": "Cyberwarfare training programs such as those at the Korea Institute of Military Science and Technology's research center have used the principles and methodologies of the LARIAT platform in the development of simulated threat generators for cyberwarfare training."
    }
  },
  {
    "instruction": "The EternalBlue exploit was developed by the U.S. National Security Agency (NSA) but was leaked by the Shadow Brokers hacker group on April 14, 2017. It is not clear how the Shadow Brokers gained access to the exploit.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How did the EternalBlue exploit end up in the hands of the Shadow Brokers hacker group?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How did the EternalBlue exploit end up in the hands of the Shadow Brokers hacker group?",
      "answer": "The EternalBlue exploit was developed by the U.S. National Security Agency (NSA) but was leaked by the Shadow Brokers hacker group on April 14, 2017. It is not clear how the Shadow Brokers gained access to the exploit."
    }
  },
  {
    "instruction": "Apart from cars, wardriving can also be done using bicycles (warbiking), motorcycles (warbiking), on foot (warwalking or warjogging), and trains or trams (warrailing or Wartraining). A more recent variant is warflying, which utilizes aircraft to locate wireless networks.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What are the different modes of transportation used in wardriving apart from cars?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What are the different modes of transportation used in wardriving apart from cars?",
      "answer": "Apart from cars, wardriving can also be done using bicycles (warbiking), motorcycles (warbiking), on foot (warwalking or warjogging), and trains or trams (warrailing or Wartraining). A more recent variant is warflying, which utilizes aircraft to locate wireless networks."
    }
  },
  {
    "instruction": "Using SRAM as a PUF has several advantages, including the ability to be connected directly to standard digital circuitry embedded on the same chip, making them of particular interest for security solutions. SRAM-based PUF technology has been investigated extensively and has been commercialized by Intrinsic ID for cryptographic implementations.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What are the advantages of using SRAM as a PUF?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What are the advantages of using SRAM as a PUF?",
      "answer": "Using SRAM as a PUF has several advantages, including the ability to be connected directly to standard digital circuitry embedded on the same chip, making them of particular interest for security solutions. SRAM-based PUF technology has been investigated extensively and has been commercialized by Intrinsic ID for cryptographic implementations."
    }
  },
  {
    "instruction": "Routing in a social VPN is peer-to-peer. One approach is using a structured P2P system for sending IP packets encapsulated in overlay messages from a source to destination.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does routing work in a social VPN?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does routing work in a social VPN?",
      "answer": "Routing in a social VPN is peer-to-peer. One approach is using a structured P2P system for sending IP packets encapsulated in overlay messages from a source to destination."
    }
  },
  {
    "instruction": "The main challenges involve minimizing complexity overheads, efficiently handling active adversaries, and ensuring the privacy of inputs while computing the function.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What are the primary challenges in designing efficient secure two-party computation protocols secure against active adversaries?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What are the primary challenges in designing efficient secure two-party computation protocols secure against active adversaries?",
      "answer": "The main challenges involve minimizing complexity overheads, efficiently handling active adversaries, and ensuring the privacy of inputs while computing the function."
    }
  },
  {
    "instruction": "Organizations must obtain consent when collecting personal information, collect information by fair and lawful means, and have personal information policies that are clear, understandable, and readily available.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What are the requirements for organizations when collecting personal information under PIPEDA?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What are the requirements for organizations when collecting personal information under PIPEDA?",
      "answer": "Organizations must obtain consent when collecting personal information, collect information by fair and lawful means, and have personal information policies that are clear, understandable, and readily available."
    }
  },
  {
    "instruction": "The umask command allows the mask to be set as octal (e.g. 0754) if fewer than 4 digits are entered, leading zeros are assumed. An error will result if the argument is not a valid octal number or if it has more than 4 digits.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How can the mask be set in octal notation using the umask command?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How can the mask be set in octal notation using the umask command?",
      "answer": "The umask command allows the mask to be set as octal (e.g. 0754) if fewer than 4 digits are entered, leading zeros are assumed. An error will result if the argument is not a valid octal number or if it has more than 4 digits."
    }
  },
  {
    "instruction": "Spy Wiper\n\n==Introduction==\nSpy Wiper, also known as Mail Wiper and Spy Deleter, is a malware program that was fraudulently sold as an antispyware program.\nIn 2005, the Federal Trade Commission filed a civil suit against the companies Seismic Entertainment Productions, MailWiper Inc., and Spy Deleter Inc.  The suit alleged the three companies illegally sold the fraudulent malware program, receiving over $2 million in revenue.\n\n\n\n\n\nAnswer this question \"How did the companies behind Spy Wiper generate revenue, and what was the total amount they earned?\" using the text above.",
    "context": "",
    "output": "The companies behind Spy Wiper generated revenue by fraudulently selling the malware program as an antispyware solution. They earned a total of over $2 million from this unlawful activity.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How did the companies behind Spy Wiper generate revenue, and what was the total amount they earned?",
      "answer": "The companies behind Spy Wiper generated revenue by fraudulently selling the malware program as an antispyware solution. They earned a total of over $2 million from this unlawful activity.",
      "context": "Spy Wiper\n\n==Introduction==\nSpy Wiper, also known as Mail Wiper and Spy Deleter, is a malware program that was fraudulently sold as an antispyware program.\nIn 2005, the Federal Trade Commission filed a civil suit against the companies Seismic Entertainment Productions, MailWiper Inc., and Spy Deleter Inc.  The suit alleged the three companies illegally sold the fraudulent malware program, receiving over $2 million in revenue.\n\n\n\n"
    }
  },
  {
    "instruction": "Secure multi-party computation\n\n==Introduction==\nSecure multi-party computation (also known as secure computation, multi-party computation (MPC) or privacy-preserving computation) is a subfield of cryptography with the goal of creating methods for parties to jointly compute a function over their inputs while keeping those inputs private. Unlike traditional cryptographic tasks, where cryptography assures security and integrity of communication or storage and the adversary is outside the system of participants (an eavesdropper on the sender and receiver), the cryptography in this model protects participants' privacy from each other.\nThe foundation for secure multi-party computation started in the late 1970s with the work on mental poker, cryptographic work that simulates game playing/computational tasks over distances without requiring a trusted third party. Traditionally, cryptography was about concealing content, while this new type of computation and protocol is about concealing partial information about data while computing with the data from many sources, and correctly producing outputs. By the late 1980s, Michael Ben-Or, Shafi Goldwasser and Avi Wigderson, and independently David Chaum, Claude Cr\u00e9peau, and Ivan Damg\u00e5rd, had published papers showing \"how to securely compute any function in the secure channels setting\".\n\n\n\n== Definition and overview ==\nIn an MPC, a given number of participants,  p1, p2, ..., pN, each have private data, respectively d1, d2, ..., dN. Participants want to compute the value of a public function on that private data: F(d1, d2, ..., dN) while keeping their own inputs secret.\nFor example, suppose we have three parties Alice, Bob and Charlie, with respective inputs x, y and z denoting their salaries. They want to find out the highest of the three salaries, without revealing to each other how much each of them makes. Mathematically, this translates to them computing:\n\nF(x, y, z)\n\n== Security definitions ==\nA multi-party computation protocol must be secure to be effective. In modern cryptography, the security of a protocol is related to a security proof. The security proof is a mathematical proof where the security of a protocol is reduced to that of the security of its underlying primitives. Nevertheless, it is not always possible to formalize the cryptographic protocol security verification based on the party knowledge and the protocol correctness. For MPC protocols, the environment in which the protocol operates is associated with the Real World/Ideal World Paradigm. The parties can't be said to learn nothing, since they need to learn the output of the operation, and the output depends on the inputs. In addition, the output correctness is not guaranteed, since the correctness of the output depends on the parties\u2019 inputs, and the inputs have to be assumed to be correct.\nThe Real World/Ideal World Paradigm states two worlds: (i) In the ideal-world model, there exists an incorruptible trusted party to whom each protocol participant sends its input. This trusted party computes the function on its own and sends back the appropriate output to each party. (ii) In contrast, in the real-world model, there is no trusted party and all the parties can do is to exchange messages with each other. A protocol is said to be secure if one can learn no more about each party's private inputs in the real world than one could learn in the ideal world. In the ideal world, no messages are exchanged between parties, so real-world exchanged messages cannot reveal any secret information.\nThe Real World/Ideal World Paradigm provides a simple abstraction of the complexities of MPC to allow the construction of an application under the pretense that the MPC protocol at its core is actually an ideal execution. If the application is secure in the ideal case, then it is also secure when a real protocol is run instead.\nThe security requirements on an MPC protocol are stringent. Nonetheless, in 1987 it was demonstrated that any function can be securely computed, with security for malicious adversaries and the other initial works mentioned before.\nDespite these publications, MPC was not designed to be efficient enough to be used in practice at that time. Unconditionally or information-theoretically secure MPC is closely related and builds on to the problem of secret sharing, and more specifically verifiable secret sharing (VSS), which many secure MPC protocols use against active adversaries.\nUnlike traditional cryptographic applications, such as encryption or signature, one must assume that the adversary in an MPC protocol is one of the players engaged in the system (or controlling internal parties). That corrupted party or parties may collude in order to breach the security of the protocol. Let \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n   be the number of parties in the protocol and \n  \n    \n      \n        t\n      \n    \n    {\\displaystyle t}\n   the number of parties who can be adversarial. The protocols and solutions for the case of \n  \n    \n      \n        t\n        <\n        n\n        \n          /\n        \n        2\n      \n    \n    {\\displaystyle t<n/2}\n   (i.e., when an honest majority is assumed) are different from those where no such assumption is made. This latter case includes the important case of two-party computation where one of the participants may be corrupted, and the general case where an unlimited number of participants are corrupted and collude to attack the honest participants.\nAdversaries faced by the different protocols can be categorized according to how willing they are to deviate from the protocol. There are essentially two types of adversaries, each giving rise to different forms of security (and each fits into different real world scenario):\n\nSemi-Honest (Passive) Security: In this case, it is assumed that corrupted parties merely cooperate to gather information out of the protocol, but do not deviate from the protocol specification. This is a naive adversary model, yielding weak security in real situations. However, protocols achieving this level of security prevent inadvertent leakage of information between (otherwise collaborating) parties, and are thus useful if this is the only concern. In addition, protocols in the semi-honest model are quite efficient, and are often an important first step for achieving higher levels of security.\nMalicious (Active) Security: In this case, the adversary may arbitrarily deviate from the protocol execution in its attempt to cheat. Protocols that achieve security in this model provide a very high security guarantee. In the case of majority of misbehaving parties: The only thing that an adversary can do in the case of dishonest majority is to cause the honest parties to \"abort\" having detected cheating. If the honest parties do obtain output, then they are guaranteed that it is correct. Their privacy is always preserved.Security against active adversaries typically leads to a reduction in efficiency. Covert security is an alternative that aims to allow greater efficiency in exchange for weakening the security definition; it is applicable to situations where active adversaries are willing to cheat but only if they are not caught. For example, their reputation could be damaged, preventing future collaboration with other honest parties. Thus, protocols that are covertly secure provide mechanisms to ensure that, if some of the parties do not follow the instructions, then it will be noticed with high probability, say 75% or 90%. In a way, covert adversaries are active ones forced to act passively due to external non-cryptographic (e.g. business) concerns. This mechanism sets a bridge between both models in the hope of finding protocols which are efficient and secure enough in practice.\nLike many cryptographic protocols, the security of an MPC protocol can rely on different assumptions:\n\nIt can be computational (i.e. based on some mathematical problem, like factoring) or unconditional, namely relying on physical unavailability of messages on channels (usually with some probability of error which can be made arbitrarily small).\nThe model might assume that participants use a synchronized network, where a message sent at a \"tick\" always arrives at the next \"tick\", or that a secure and reliable broadcast channel exists, or that a secure communication channel exists between every pair of participants where an adversary cannot read, modify or generate messages in the channel, etc.The set of honest parties that can execute a computational task is related to the concept of access structure. Adversary structures can be static, where the adversary chooses its victims before the start of the multi-party computation, or dynamic, where it chooses its victims during the course of execution of the multi-party computation making the defense harder. An adversary structure can be defined as a threshold structure or as a more complex structure. In a threshold structure the adversary can corrupt or read the memory of a number of participants up to some threshold. Meanwhile, in a complex structure it can affect certain predefined subsets of participants, modeling different possible collusions.\n\n== Protocols ==\nThere are major differences between the protocols proposed for two party computation (2PC) and multi-party computation (MPC). Also, often for special purpose protocols of importance a specialized protocol that deviates from the generic ones has to be designed (voting, auctions, payments, etc.)\n\n\n*** Two-party computation ***\n\nThe two party setting is particularly interesting, not only from an applications perspective but also because special techniques can be applied in the two party setting which do not apply in the multi-party case. Indeed, secure multi-party computation (in fact the restricted case of secure function evaluation, where only a single function is evaluated) was first presented in the two-party setting. The original work is often cited as being from one of the two papers of Yao; although the papers do not actually contain what is now known as Yao's garbled circuit protocol.\nYao's basic protocol is secure against semi-honest adversaries and is extremely efficient in terms of number of rounds, which is constant, and independent of the target function being evaluated. The function is viewed as a Boolean circuit, with inputs in binary of fixed length. A Boolean circuit is a collection of gates connected with three different types of wires: circuit-input wires, circuit-output wires and intermediate wires. Each gate receives two input wires and it has a single output wire which might be fan-out (i.e. be passed to multiple gates at the next level). Plain evaluation of the circuit is done by evaluating each gate in turn; assuming the gates have been topologically ordered. The gate is represented as a truth table such that for each possible pair of bits (those coming from the input wires' gate) the table assigns a unique output bit; which is the value of the output wire of the gate. The results of the evaluation are the bits obtained in the circuit-output wires.\nYao explained how to garble a circuit (hide its structure) so that two parties, sender and receiver, can learn the output of the circuit and nothing else. At a high level, the sender prepares the garbled circuit and sends it to the receiver, who obliviously evaluates the circuit, learning the encodings corresponding to both his and the sender's output. He then just sends back the sender's encodings, allowing the sender to compute his part of the output. The sender sends the mapping from the receivers output encodings to bits to the receiver, allowing the receiver to obtain their output.\nIn more detail, the garbled circuit is computed as follows. The main ingredient is a double-keyed symmetric encryption scheme. Given a gate of the circuit, each possible value of its input wires (either 0 or 1) is encoded with a random number (label). The values resulting from the evaluation of the gate at each of the four possible pair of input bits are also replaced with random labels. The garbled truth table of the gate consists of encryptions of each output label using its inputs labels as keys. The position of these four encryptions in the truth table is randomized so no information on the gate is leaked.\nTo correctly evaluate each garbled gate the encryption scheme has the following two properties. Firstly, the ranges of the encryption function under any two distinct keys are disjoint (with overwhelming probability). The second property says that it can be checked efficiently whether a given ciphertext has been encrypted under a given key. With these two properties the receiver, after obtaining the labels for all circuit-input wires, can evaluate each gate by first finding out which of the four ciphertexts has been encrypted with his label keys, and then decrypting to obtain the label of the output wire. This is done obliviously as all the receiver learns during the evaluation are encodings of the bits.\nThe sender's (i.e. circuit creators) input bits can be just sent as encodings to the evaluator; whereas the receiver's (i.e. circuit evaluators) encodings corresponding to his input bits are obtained via a 1-out-of-2 Oblivious Transfer (OT) protocol. A 1-out-of-2 OT protocol, enables the sender, in possession of two values C1 and C2, to send the one requested by the receiver (b a value in {1,2}) in such a way that the sender does not know what value has been transferred, and the receiver only learns the queried value.\nIf one is considering malicious adversaries, further mechanisms to ensure correct behavior of both parties need to be provided. By construction it is easy to show security for the sender if the OT protocol is already secure against malicious adversary, as all the receiver can do is to evaluate a garbled circuit that would fail to reach the circuit-output wires if he deviated from the instructions. The situation is very different on the sender's side. For example, he may send an incorrect garbled circuit that computes a function revealing the receiver's input. This would mean that privacy no longer holds, but since the circuit is garbled the receiver would not be able to detect this. However, it is possible to efficiently apply Zero-Knowledge proofs to make this protocol secure against malicious adversaries with a small overhead comparing to the semi-honest protocol.\n\n\n*** Multi-party protocols ***\nMost MPC protocols, as opposed to 2PC protocols and especially under the unconditional setting of private channels, make use of secret sharing. In the secret sharing based methods, the parties do not play special roles (as in Yao, of creator and evaluator). Instead, the data associated with each wire is shared amongst the parties, and a protocol is then used to evaluate each gate. The function is now defined as a \"circuit\" over a finite field, as opposed to the binary circuits used for Yao. Such a circuit is called an arithmetic circuit in the literature, and it consists of addition and multiplication \"gates\" where the values operated on are defined over a finite field.\nSecret sharing allows one to distribute a secret among a number of parties by distributing shares to each party. Two types of secret sharing schemes are commonly used; Shamir secret sharing and additive secret sharing. In both cases the shares are random elements of a finite field that add up to the secret in the field; intuitively, security is achieved because any non-qualifying set of shares looks randomly distributed.\nSecret sharing schemes can tolerate an adversary controlling up to t parties out of n total parties, where t varies based on the scheme, the adversary can be passive or active, and different assumptions are made on the power of the adversary. The Shamir secret sharing scheme is secure against a passive adversary when \n  \n    \n      \n        t\n        <\n        \n          \n            n\n            2\n          \n        \n      \n    \n    {\\displaystyle t<{\\frac {n}{2}}}\n   and an active adversary when \n  \n    \n      \n        t\n        <\n        \n          \n            n\n            3\n          \n        \n      \n    \n    {\\displaystyle t<{\\frac {n}{3}}}\n   while achieving information-theoretic security, meaning that even if the adversary has unbounded computational power, they cannot learn any information about the secret underlying a share. The BGW protocol, which defines how to compute addition and multiplication on secret shares, is often used to compute functions with Shamir secret shares. Additive secret sharing schemes can tolerate the adversary controlling all but one party, that is \n  \n    \n      \n        t\n        <\n        n\n      \n    \n    {\\displaystyle t<n}\n  , while maintaining security against a passive and active adversary with unbounded computational power. Some protocols require a setup phase, which may only be secure against a computationally bounded adversary.\nA number of systems have implemented various forms of MPC with secret sharing schemes. The most popular is SPDZ, which implements MPC with additive secret shares and is secure against active adversaries.\n\n\n*** Other protocols ***\nIn 2014 a \"model of fairness in secure computation in which an adversarial party that aborts on receiving output is forced to pay a mutually predefined monetary penalty\" has been described for the Bitcoin network or for fair lottery.\n\n== Practical MPC systems ==\nMany advances have been made on 2PC and MPC systems in recent years.\n\n\n*** Yao-based protocols ***\nOne of the main issues when working with Yao-based protocols is that the function to be securely evaluated (which could be an arbitrary program) must be represented as a circuit, usually consisting of XOR and AND gates. Since most real-world programs contain loops and complex data structures, this is a highly non-trivial task. The Fairplay system was the first tool designed to tackle this problem. Fairplay comprises two main components. The first of these is a compiler enabling users to write programs in a simple high-level language, and output these programs in a Boolean circuit representation. The second component can then garble the circuit and execute a protocol to securely evaluate the garbled circuit. As well as two-party computation based on Yao's protocol, Fairplay can also carry out multi-party protocols. This is done using the BMR protocol, which extends Yao's passively secure protocol to the active case.\nIn the years following the introduction of Fairplay, many improvements to Yao's basic protocol have been created, in the form of both efficiency improvements and techniques for active security. These include techniques such as the free XOR method, which allows for much simpler evaluation of XOR gates, and garbled row reduction, reducing the size of garbled tables with two inputs by 25%.The approach that so far seems to be the most fruitful in obtaining active security comes from a combination of the garbling technique and the \"cut-and-choose\" paradigm. This combination seems to render more efficient constructions. To avoid the aforementioned problems with respect to dishonest behaviour, many garblings of the same circuit are sent from the constructor to the evaluator. Then around half of them (depending on the specific protocol) are opened to check consistency, and if so a vast majority of the unopened ones are correct with high probability. The output is the majority vote of all the evaluations. Here the majority output is needed. If there is disagreement on the outputs the receiver knows the sender is cheating, but he cannot complain as otherwise this would leak information on his input.\nThis approach for active security was initiated by Lindell and Pinkas. This technique was implemented by Pinkas et al. in 2009, This provided the first actively secure two-party evaluation of the Advanced Encryption Standard (AES) circuit, regarded as a highly complex (consisting of around 30,000 AND and XOR gates), non-trivial function (also with some potential applications), taking around 20 minutes to compute and requiring 160 circuits to obtain a \n  \n    \n      \n        \n          2\n          \n            \u2212\n            40\n          \n        \n      \n    \n    {\\displaystyle 2^{-40}}\n   cheating probability.\nAs many circuits are evaluated, the parties (including the receiver) need to commit to their inputs to ensure that in all the iterations the same values are used. The experiments of Pinkas et al. reported show that the bottleneck of the protocol lies in the consistency checks. They had to send over the net about 6,553,600 commitments to various values to evaluate the AES circuit. In recent results the efficiency of actively secure Yao-based implementations was improved even further, requiring only 40 circuits, and much less commitments, to obtain \n  \n    \n      \n        \n          2\n          \n            \u2212\n            40\n          \n        \n      \n    \n    {\\displaystyle 2^{-40}}\n   cheating probability. The improvements come from new methodologies for performing cut-and-choose on the transmitted circuits.\nMore recently, there has been a focus on highly parallel implementations based on garbled circuits, designed to be run on CPUs with many cores. Kreuter, et al. describe an implementation running on 512 cores of a powerful cluster computer. Using these resources they could evaluate the 4095-bit edit distance function, whose circuit comprises almost 6 billion gates. To accomplish this they developed a custom, better optimized circuit compiler than Fairplay and several new optimizations such as pipelining, whereby transmission of the garbled circuit across the network begins while the rest of the circuit is still being generated. The time to compute AES was reduced to 1.4 seconds per block in the active case, using a 512-node cluster machine, and 115 seconds using one node. Shelat and Shen improve this, using commodity hardware, to 0.52 seconds per block. The same paper reports on a throughput of 21 blocks per second, but with a latency of 48 seconds per block.\nMeanwhile, another group of researchers has investigated using consumer-grade GPUs to achieve similar levels of parallelism. They utilize OT extensions and some other novel techniques to design their GPU-specific protocol. This approach seems to achieve comparable efficiency to the cluster computing implementation, using a similar number of cores. However, the authors only report on an implementation of the AES circuit, which has around 50,000 gates. On the other hand, the hardware required here is far more accessible, as similar devices may already be found in many people's desktop computers or games consoles. The authors obtain a timing of 2.7 seconds per AES block on a standard desktop, with a standard GPU. If they allow security to decrease to something akin to covert security, they obtain a run time of 0.30 seconds per AES block. In the passive security case there are reports of processing of circuits with 250 million gates, and at a rate of 75 million gates per second.\n\n== Implementations of secure multi-party computation data analyses ==\nOne of the primary applications of secure multi-party computation is allowing analysis of data that is held by multiple parties, or blind analysis of data by third parties without allowing the data custodian to understand the kind of data analysis being performed.\n\n\n*** Demonstration and Production Systems ***\n\n\n*** Software Libraries ***\n\n\n*** Technology Providers ***\nSharemind\nGalois\nDuality Technologies\n\nAnswer this question \"What is the role of the Advanced Encryption Standard (AES) circuit in secure multi-party computation?\" using the text above.",
    "context": "",
    "output": "The AES circuit is a highly complex, non-trivial function consisting of around 30,000 AND and XOR gates, and it has potential applications in secure multi-party computation.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the role of the Advanced Encryption Standard (AES) circuit in secure multi-party computation?",
      "answer": "The AES circuit is a highly complex, non-trivial function consisting of around 30,000 AND and XOR gates, and it has potential applications in secure multi-party computation.",
      "context": "Secure multi-party computation\n\n==Introduction==\nSecure multi-party computation (also known as secure computation, multi-party computation (MPC) or privacy-preserving computation) is a subfield of cryptography with the goal of creating methods for parties to jointly compute a function over their inputs while keeping those inputs private. Unlike traditional cryptographic tasks, where cryptography assures security and integrity of communication or storage and the adversary is outside the system of participants (an eavesdropper on the sender and receiver), the cryptography in this model protects participants' privacy from each other.\nThe foundation for secure multi-party computation started in the late 1970s with the work on mental poker, cryptographic work that simulates game playing/computational tasks over distances without requiring a trusted third party. Traditionally, cryptography was about concealing content, while this new type of computation and protocol is about concealing partial information about data while computing with the data from many sources, and correctly producing outputs. By the late 1980s, Michael Ben-Or, Shafi Goldwasser and Avi Wigderson, and independently David Chaum, Claude Cr\u00e9peau, and Ivan Damg\u00e5rd, had published papers showing \"how to securely compute any function in the secure channels setting\".\n\n\n\n== Definition and overview ==\nIn an MPC, a given number of participants,  p1, p2, ..., pN, each have private data, respectively d1, d2, ..., dN. Participants want to compute the value of a public function on that private data: F(d1, d2, ..., dN) while keeping their own inputs secret.\nFor example, suppose we have three parties Alice, Bob and Charlie, with respective inputs x, y and z denoting their salaries. They want to find out the highest of the three salaries, without revealing to each other how much each of them makes. Mathematically, this translates to them computing:\n\nF(x, y, z)\n\n== Security definitions ==\nA multi-party computation protocol must be secure to be effective. In modern cryptography, the security of a protocol is related to a security proof. The security proof is a mathematical proof where the security of a protocol is reduced to that of the security of its underlying primitives. Nevertheless, it is not always possible to formalize the cryptographic protocol security verification based on the party knowledge and the protocol correctness. For MPC protocols, the environment in which the protocol operates is associated with the Real World/Ideal World Paradigm. The parties can't be said to learn nothing, since they need to learn the output of the operation, and the output depends on the inputs. In addition, the output correctness is not guaranteed, since the correctness of the output depends on the parties\u2019 inputs, and the inputs have to be assumed to be correct.\nThe Real World/Ideal World Paradigm states two worlds: (i) In the ideal-world model, there exists an incorruptible trusted party to whom each protocol participant sends its input. This trusted party computes the function on its own and sends back the appropriate output to each party. (ii) In contrast, in the real-world model, there is no trusted party and all the parties can do is to exchange messages with each other. A protocol is said to be secure if one can learn no more about each party's private inputs in the real world than one could learn in the ideal world. In the ideal world, no messages are exchanged between parties, so real-world exchanged messages cannot reveal any secret information.\nThe Real World/Ideal World Paradigm provides a simple abstraction of the complexities of MPC to allow the construction of an application under the pretense that the MPC protocol at its core is actually an ideal execution. If the application is secure in the ideal case, then it is also secure when a real protocol is run instead.\nThe security requirements on an MPC protocol are stringent. Nonetheless, in 1987 it was demonstrated that any function can be securely computed, with security for malicious adversaries and the other initial works mentioned before.\nDespite these publications, MPC was not designed to be efficient enough to be used in practice at that time. Unconditionally or information-theoretically secure MPC is closely related and builds on to the problem of secret sharing, and more specifically verifiable secret sharing (VSS), which many secure MPC protocols use against active adversaries.\nUnlike traditional cryptographic applications, such as encryption or signature, one must assume that the adversary in an MPC protocol is one of the players engaged in the system (or controlling internal parties). That corrupted party or parties may collude in order to breach the security of the protocol. Let \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n   be the number of parties in the protocol and \n  \n    \n      \n        t\n      \n    \n    {\\displaystyle t}\n   the number of parties who can be adversarial. The protocols and solutions for the case of \n  \n    \n      \n        t\n        <\n        n\n        \n          /\n        \n        2\n      \n    \n    {\\displaystyle t<n/2}\n   (i.e., when an honest majority is assumed) are different from those where no such assumption is made. This latter case includes the important case of two-party computation where one of the participants may be corrupted, and the general case where an unlimited number of participants are corrupted and collude to attack the honest participants.\nAdversaries faced by the different protocols can be categorized according to how willing they are to deviate from the protocol. There are essentially two types of adversaries, each giving rise to different forms of security (and each fits into different real world scenario):\n\nSemi-Honest (Passive) Security: In this case, it is assumed that corrupted parties merely cooperate to gather information out of the protocol, but do not deviate from the protocol specification. This is a naive adversary model, yielding weak security in real situations. However, protocols achieving this level of security prevent inadvertent leakage of information between (otherwise collaborating) parties, and are thus useful if this is the only concern. In addition, protocols in the semi-honest model are quite efficient, and are often an important first step for achieving higher levels of security.\nMalicious (Active) Security: In this case, the adversary may arbitrarily deviate from the protocol execution in its attempt to cheat. Protocols that achieve security in this model provide a very high security guarantee. In the case of majority of misbehaving parties: The only thing that an adversary can do in the case of dishonest majority is to cause the honest parties to \"abort\" having detected cheating. If the honest parties do obtain output, then they are guaranteed that it is correct. Their privacy is always preserved.Security against active adversaries typically leads to a reduction in efficiency. Covert security is an alternative that aims to allow greater efficiency in exchange for weakening the security definition; it is applicable to situations where active adversaries are willing to cheat but only if they are not caught. For example, their reputation could be damaged, preventing future collaboration with other honest parties. Thus, protocols that are covertly secure provide mechanisms to ensure that, if some of the parties do not follow the instructions, then it will be noticed with high probability, say 75% or 90%. In a way, covert adversaries are active ones forced to act passively due to external non-cryptographic (e.g. business) concerns. This mechanism sets a bridge between both models in the hope of finding protocols which are efficient and secure enough in practice.\nLike many cryptographic protocols, the security of an MPC protocol can rely on different assumptions:\n\nIt can be computational (i.e. based on some mathematical problem, like factoring) or unconditional, namely relying on physical unavailability of messages on channels (usually with some probability of error which can be made arbitrarily small).\nThe model might assume that participants use a synchronized network, where a message sent at a \"tick\" always arrives at the next \"tick\", or that a secure and reliable broadcast channel exists, or that a secure communication channel exists between every pair of participants where an adversary cannot read, modify or generate messages in the channel, etc.The set of honest parties that can execute a computational task is related to the concept of access structure. Adversary structures can be static, where the adversary chooses its victims before the start of the multi-party computation, or dynamic, where it chooses its victims during the course of execution of the multi-party computation making the defense harder. An adversary structure can be defined as a threshold structure or as a more complex structure. In a threshold structure the adversary can corrupt or read the memory of a number of participants up to some threshold. Meanwhile, in a complex structure it can affect certain predefined subsets of participants, modeling different possible collusions.\n\n== Protocols ==\nThere are major differences between the protocols proposed for two party computation (2PC) and multi-party computation (MPC). Also, often for special purpose protocols of importance a specialized protocol that deviates from the generic ones has to be designed (voting, auctions, payments, etc.)\n\n\n*** Two-party computation ***\n\nThe two party setting is particularly interesting, not only from an applications perspective but also because special techniques can be applied in the two party setting which do not apply in the multi-party case. Indeed, secure multi-party computation (in fact the restricted case of secure function evaluation, where only a single function is evaluated) was first presented in the two-party setting. The original work is often cited as being from one of the two papers of Yao; although the papers do not actually contain what is now known as Yao's garbled circuit protocol.\nYao's basic protocol is secure against semi-honest adversaries and is extremely efficient in terms of number of rounds, which is constant, and independent of the target function being evaluated. The function is viewed as a Boolean circuit, with inputs in binary of fixed length. A Boolean circuit is a collection of gates connected with three different types of wires: circuit-input wires, circuit-output wires and intermediate wires. Each gate receives two input wires and it has a single output wire which might be fan-out (i.e. be passed to multiple gates at the next level). Plain evaluation of the circuit is done by evaluating each gate in turn; assuming the gates have been topologically ordered. The gate is represented as a truth table such that for each possible pair of bits (those coming from the input wires' gate) the table assigns a unique output bit; which is the value of the output wire of the gate. The results of the evaluation are the bits obtained in the circuit-output wires.\nYao explained how to garble a circuit (hide its structure) so that two parties, sender and receiver, can learn the output of the circuit and nothing else. At a high level, the sender prepares the garbled circuit and sends it to the receiver, who obliviously evaluates the circuit, learning the encodings corresponding to both his and the sender's output. He then just sends back the sender's encodings, allowing the sender to compute his part of the output. The sender sends the mapping from the receivers output encodings to bits to the receiver, allowing the receiver to obtain their output.\nIn more detail, the garbled circuit is computed as follows. The main ingredient is a double-keyed symmetric encryption scheme. Given a gate of the circuit, each possible value of its input wires (either 0 or 1) is encoded with a random number (label). The values resulting from the evaluation of the gate at each of the four possible pair of input bits are also replaced with random labels. The garbled truth table of the gate consists of encryptions of each output label using its inputs labels as keys. The position of these four encryptions in the truth table is randomized so no information on the gate is leaked.\nTo correctly evaluate each garbled gate the encryption scheme has the following two properties. Firstly, the ranges of the encryption function under any two distinct keys are disjoint (with overwhelming probability). The second property says that it can be checked efficiently whether a given ciphertext has been encrypted under a given key. With these two properties the receiver, after obtaining the labels for all circuit-input wires, can evaluate each gate by first finding out which of the four ciphertexts has been encrypted with his label keys, and then decrypting to obtain the label of the output wire. This is done obliviously as all the receiver learns during the evaluation are encodings of the bits.\nThe sender's (i.e. circuit creators) input bits can be just sent as encodings to the evaluator; whereas the receiver's (i.e. circuit evaluators) encodings corresponding to his input bits are obtained via a 1-out-of-2 Oblivious Transfer (OT) protocol. A 1-out-of-2 OT protocol, enables the sender, in possession of two values C1 and C2, to send the one requested by the receiver (b a value in {1,2}) in such a way that the sender does not know what value has been transferred, and the receiver only learns the queried value.\nIf one is considering malicious adversaries, further mechanisms to ensure correct behavior of both parties need to be provided. By construction it is easy to show security for the sender if the OT protocol is already secure against malicious adversary, as all the receiver can do is to evaluate a garbled circuit that would fail to reach the circuit-output wires if he deviated from the instructions. The situation is very different on the sender's side. For example, he may send an incorrect garbled circuit that computes a function revealing the receiver's input. This would mean that privacy no longer holds, but since the circuit is garbled the receiver would not be able to detect this. However, it is possible to efficiently apply Zero-Knowledge proofs to make this protocol secure against malicious adversaries with a small overhead comparing to the semi-honest protocol.\n\n\n*** Multi-party protocols ***\nMost MPC protocols, as opposed to 2PC protocols and especially under the unconditional setting of private channels, make use of secret sharing. In the secret sharing based methods, the parties do not play special roles (as in Yao, of creator and evaluator). Instead, the data associated with each wire is shared amongst the parties, and a protocol is then used to evaluate each gate. The function is now defined as a \"circuit\" over a finite field, as opposed to the binary circuits used for Yao. Such a circuit is called an arithmetic circuit in the literature, and it consists of addition and multiplication \"gates\" where the values operated on are defined over a finite field.\nSecret sharing allows one to distribute a secret among a number of parties by distributing shares to each party. Two types of secret sharing schemes are commonly used; Shamir secret sharing and additive secret sharing. In both cases the shares are random elements of a finite field that add up to the secret in the field; intuitively, security is achieved because any non-qualifying set of shares looks randomly distributed.\nSecret sharing schemes can tolerate an adversary controlling up to t parties out of n total parties, where t varies based on the scheme, the adversary can be passive or active, and different assumptions are made on the power of the adversary. The Shamir secret sharing scheme is secure against a passive adversary when \n  \n    \n      \n        t\n        <\n        \n          \n            n\n            2\n          \n        \n      \n    \n    {\\displaystyle t<{\\frac {n}{2}}}\n   and an active adversary when \n  \n    \n      \n        t\n        <\n        \n          \n            n\n            3\n          \n        \n      \n    \n    {\\displaystyle t<{\\frac {n}{3}}}\n   while achieving information-theoretic security, meaning that even if the adversary has unbounded computational power, they cannot learn any information about the secret underlying a share. The BGW protocol, which defines how to compute addition and multiplication on secret shares, is often used to compute functions with Shamir secret shares. Additive secret sharing schemes can tolerate the adversary controlling all but one party, that is \n  \n    \n      \n        t\n        <\n        n\n      \n    \n    {\\displaystyle t<n}\n  , while maintaining security against a passive and active adversary with unbounded computational power. Some protocols require a setup phase, which may only be secure against a computationally bounded adversary.\nA number of systems have implemented various forms of MPC with secret sharing schemes. The most popular is SPDZ, which implements MPC with additive secret shares and is secure against active adversaries.\n\n\n*** Other protocols ***\nIn 2014 a \"model of fairness in secure computation in which an adversarial party that aborts on receiving output is forced to pay a mutually predefined monetary penalty\" has been described for the Bitcoin network or for fair lottery.\n\n== Practical MPC systems ==\nMany advances have been made on 2PC and MPC systems in recent years.\n\n\n*** Yao-based protocols ***\nOne of the main issues when working with Yao-based protocols is that the function to be securely evaluated (which could be an arbitrary program) must be represented as a circuit, usually consisting of XOR and AND gates. Since most real-world programs contain loops and complex data structures, this is a highly non-trivial task. The Fairplay system was the first tool designed to tackle this problem. Fairplay comprises two main components. The first of these is a compiler enabling users to write programs in a simple high-level language, and output these programs in a Boolean circuit representation. The second component can then garble the circuit and execute a protocol to securely evaluate the garbled circuit. As well as two-party computation based on Yao's protocol, Fairplay can also carry out multi-party protocols. This is done using the BMR protocol, which extends Yao's passively secure protocol to the active case.\nIn the years following the introduction of Fairplay, many improvements to Yao's basic protocol have been created, in the form of both efficiency improvements and techniques for active security. These include techniques such as the free XOR method, which allows for much simpler evaluation of XOR gates, and garbled row reduction, reducing the size of garbled tables with two inputs by 25%.The approach that so far seems to be the most fruitful in obtaining active security comes from a combination of the garbling technique and the \"cut-and-choose\" paradigm. This combination seems to render more efficient constructions. To avoid the aforementioned problems with respect to dishonest behaviour, many garblings of the same circuit are sent from the constructor to the evaluator. Then around half of them (depending on the specific protocol) are opened to check consistency, and if so a vast majority of the unopened ones are correct with high probability. The output is the majority vote of all the evaluations. Here the majority output is needed. If there is disagreement on the outputs the receiver knows the sender is cheating, but he cannot complain as otherwise this would leak information on his input.\nThis approach for active security was initiated by Lindell and Pinkas. This technique was implemented by Pinkas et al. in 2009, This provided the first actively secure two-party evaluation of the Advanced Encryption Standard (AES) circuit, regarded as a highly complex (consisting of around 30,000 AND and XOR gates), non-trivial function (also with some potential applications), taking around 20 minutes to compute and requiring 160 circuits to obtain a \n  \n    \n      \n        \n          2\n          \n            \u2212\n            40\n          \n        \n      \n    \n    {\\displaystyle 2^{-40}}\n   cheating probability.\nAs many circuits are evaluated, the parties (including the receiver) need to commit to their inputs to ensure that in all the iterations the same values are used. The experiments of Pinkas et al. reported show that the bottleneck of the protocol lies in the consistency checks. They had to send over the net about 6,553,600 commitments to various values to evaluate the AES circuit. In recent results the efficiency of actively secure Yao-based implementations was improved even further, requiring only 40 circuits, and much less commitments, to obtain \n  \n    \n      \n        \n          2\n          \n            \u2212\n            40\n          \n        \n      \n    \n    {\\displaystyle 2^{-40}}\n   cheating probability. The improvements come from new methodologies for performing cut-and-choose on the transmitted circuits.\nMore recently, there has been a focus on highly parallel implementations based on garbled circuits, designed to be run on CPUs with many cores. Kreuter, et al. describe an implementation running on 512 cores of a powerful cluster computer. Using these resources they could evaluate the 4095-bit edit distance function, whose circuit comprises almost 6 billion gates. To accomplish this they developed a custom, better optimized circuit compiler than Fairplay and several new optimizations such as pipelining, whereby transmission of the garbled circuit across the network begins while the rest of the circuit is still being generated. The time to compute AES was reduced to 1.4 seconds per block in the active case, using a 512-node cluster machine, and 115 seconds using one node. Shelat and Shen improve this, using commodity hardware, to 0.52 seconds per block. The same paper reports on a throughput of 21 blocks per second, but with a latency of 48 seconds per block.\nMeanwhile, another group of researchers has investigated using consumer-grade GPUs to achieve similar levels of parallelism. They utilize OT extensions and some other novel techniques to design their GPU-specific protocol. This approach seems to achieve comparable efficiency to the cluster computing implementation, using a similar number of cores. However, the authors only report on an implementation of the AES circuit, which has around 50,000 gates. On the other hand, the hardware required here is far more accessible, as similar devices may already be found in many people's desktop computers or games consoles. The authors obtain a timing of 2.7 seconds per AES block on a standard desktop, with a standard GPU. If they allow security to decrease to something akin to covert security, they obtain a run time of 0.30 seconds per AES block. In the passive security case there are reports of processing of circuits with 250 million gates, and at a rate of 75 million gates per second.\n\n== Implementations of secure multi-party computation data analyses ==\nOne of the primary applications of secure multi-party computation is allowing analysis of data that is held by multiple parties, or blind analysis of data by third parties without allowing the data custodian to understand the kind of data analysis being performed.\n\n\n*** Demonstration and Production Systems ***\n\n\n*** Software Libraries ***\n\n\n*** Technology Providers ***\nSharemind\nGalois\nDuality Technologies"
    }
  },
  {
    "instruction": "The purpose of reviewing records of past email communications in an automated whitelisting system is to identify trusted networks of friends and subnetworks generated by spams for inclusion in the whitelist.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the purpose of reviewing records of past email communications in an automated whitelisting system?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the purpose of reviewing records of past email communications in an automated whitelisting system?",
      "answer": "The purpose of reviewing records of past email communications in an automated whitelisting system is to identify trusted networks of friends and subnetworks generated by spams for inclusion in the whitelist."
    }
  },
  {
    "instruction": "The maximum firewall throughput on ZoneAlarm Z100G is 70 Mbit/s.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the maximum throughput of the firewall on ZoneAlarm Z100G?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the maximum throughput of the firewall on ZoneAlarm Z100G?",
      "answer": "The maximum firewall throughput on ZoneAlarm Z100G is 70 Mbit/s."
    }
  },
  {
    "instruction": "Hardware security bug\n\n==Introduction==\nIn digital computing, hardware security bugs are hardware bugs or flaws that create vulnerabilities affecting computer central processing units (CPUs), or other devices which incorporate programmable processors or logic and have direct memory access, which allow data to be read by a rogue process when such reading is not authorized.  Such vulnerabilities are considered \"catastrophic\" by security analysts.\n\n\n\n== Speculative execution vulnerabilities ==\nStarting in 2017, a series of security vulnerabilities were found in the implementations of speculative execution on common processor architectures which effectively enabled an elevation of privileges.\nThese include:\n\nForeshadow\nMeltdown\nMicroarchitectural Data Sampling\nSpectre\nSPOILER\nPacman\n\n== Intel VISA ==\nIn 2019 researchers discovered that a manufacturer debugging mode, known as VISA, had an undocumented feature on Intel Platform Controller Hubs, which are the chipsets included on most Intel-based motherboards and which have direct memory access, which made the mode accessible with a normal motherboard possibly leading to a security vulnerability. Answer this question using the following article:\n\nWhat is the role of direct memory access in hardware security bugs?",
    "context": "",
    "output": "Direct memory access is a feature of CPUs and other devices with programmable processors or logic that allows data to be read directly from memory, bypassing normal security measures. Hardware security bugs take advantage of this feature to allow unauthorized data to be read by a rogue process.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the role of direct memory access in hardware security bugs?",
      "answer": "Direct memory access is a feature of CPUs and other devices with programmable processors or logic that allows data to be read directly from memory, bypassing normal security measures. Hardware security bugs take advantage of this feature to allow unauthorized data to be read by a rogue process.",
      "context": "Hardware security bug\n\n==Introduction==\nIn digital computing, hardware security bugs are hardware bugs or flaws that create vulnerabilities affecting computer central processing units (CPUs), or other devices which incorporate programmable processors or logic and have direct memory access, which allow data to be read by a rogue process when such reading is not authorized.  Such vulnerabilities are considered \"catastrophic\" by security analysts.\n\n\n\n== Speculative execution vulnerabilities ==\nStarting in 2017, a series of security vulnerabilities were found in the implementations of speculative execution on common processor architectures which effectively enabled an elevation of privileges.\nThese include:\n\nForeshadow\nMeltdown\nMicroarchitectural Data Sampling\nSpectre\nSPOILER\nPacman\n\n== Intel VISA ==\nIn 2019 researchers discovered that a manufacturer debugging mode, known as VISA, had an undocumented feature on Intel Platform Controller Hubs, which are the chipsets included on most Intel-based motherboards and which have direct memory access, which made the mode accessible with a normal motherboard possibly leading to a security vulnerability."
    }
  },
  {
    "instruction": "The public version of Encryption Wizard uses the standard Java cryptographic library, while the unified version uses a FIP-140-2 certified crypto licensed by The Legion of the Bouncy Castle. The government-only version uses a FIPS-140-2 certified crypto stack licensed from RSA Security. The three versions interoperate.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the difference between the public, unified, and government-only versions of Encryption Wizard?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the difference between the public, unified, and government-only versions of Encryption Wizard?",
      "answer": "The public version of Encryption Wizard uses the standard Java cryptographic library, while the unified version uses a FIP-140-2 certified crypto licensed by The Legion of the Bouncy Castle. The government-only version uses a FIPS-140-2 certified crypto stack licensed from RSA Security. The three versions interoperate."
    }
  },
  {
    "instruction": "The NOIWON plays a critical role in ensuring a coordinated response to national security crises by providing a secure communication channel between various government agencies, including the National Military Command Center, National Military Joint Intelligence Center, State Department Operations Center, State Department Bureau of Intelligence and Research, CIA Operations Center, NSA Operations Center, The White House Situation Room, and U.S. Navy Multiple Threat Alert Center. By enabling real-time communication and collaboration between these agencies, the NOIWON helps to facilitate a coordinated response, ensuring that all relevant parties have access to the same information and can work together to address the crisis at hand.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the significance of the NOIWON's role in ensuring a coordinated response to national security crises between various government agencies?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the significance of the NOIWON's role in ensuring a coordinated response to national security crises between various government agencies?",
      "answer": "The NOIWON plays a critical role in ensuring a coordinated response to national security crises by providing a secure communication channel between various government agencies, including the National Military Command Center, National Military Joint Intelligence Center, State Department Operations Center, State Department Bureau of Intelligence and Research, CIA Operations Center, NSA Operations Center, The White House Situation Room, and U.S. Navy Multiple Threat Alert Center. By enabling real-time communication and collaboration between these agencies, the NOIWON helps to facilitate a coordinated response, ensuring that all relevant parties have access to the same information and can work together to address the crisis at hand."
    }
  },
  {
    "instruction": "Investigators identified the IP addresses associated with the DDoS attacks by monitoring the network traffic of Miami-Dade County Public Schools.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How did investigators identify the IP addresses associated with the DDoS attacks on Miami-Dade County Public Schools?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How did investigators identify the IP addresses associated with the DDoS attacks on Miami-Dade County Public Schools?",
      "answer": "Investigators identified the IP addresses associated with the DDoS attacks by monitoring the network traffic of Miami-Dade County Public Schools."
    }
  },
  {
    "instruction": "The KN-Cipher, a block cipher previously proved to be immune against standard differential cryptanalysis, was broken using higher-order differential cryptanalysis.\n\nWrite a question about the text above.",
    "context": "",
    "output": "Which block cipher was broken using higher-order differential cryptanalysis?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "Which block cipher was broken using higher-order differential cryptanalysis?",
      "answer": "The KN-Cipher, a block cipher previously proved to be immune against standard differential cryptanalysis, was broken using higher-order differential cryptanalysis."
    }
  },
  {
    "instruction": "One-way compression functions are often built from block ciphers in practice because it can save code space in tiny embedded systems and it can be easier to implement a single implementation of a block cipher for both a block cipher and a hash function.\n\nWrite a question about the text above.",
    "context": "",
    "output": "Why are one-way compression functions often built from block ciphers in practice?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "Why are one-way compression functions often built from block ciphers in practice?",
      "answer": "One-way compression functions are often built from block ciphers in practice because it can save code space in tiny embedded systems and it can be easier to implement a single implementation of a block cipher for both a block cipher and a hash function."
    }
  },
  {
    "instruction": "Trust boundaries define the limits of trust within a system. When using the STRIDE model, understanding trust boundaries is essential to understanding the flow of data and identifying potential threats.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the significance of trust boundaries when using the STRIDE model?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the significance of trust boundaries when using the STRIDE model?",
      "answer": "Trust boundaries define the limits of trust within a system. When using the STRIDE model, understanding trust boundaries is essential to understanding the flow of data and identifying potential threats."
    }
  },
  {
    "instruction": "DEA providers face challenges in presenting a total solution for users due to the uncertainty about the trustworthiness and reputation of site administrators, the availability of options to hide email addresses, the existence/enforcement of an acceptable privacy policy, and the chance that the site may one day be compromised or transferred to new owners. DEA users may also need to use a conventional-looking email address or create a separate mailbox in the worst-case scenario if required by a public/commercial entity.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What are the challenges faced by DEA providers in presenting a total solution for users?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What are the challenges faced by DEA providers in presenting a total solution for users?",
      "answer": "DEA providers face challenges in presenting a total solution for users due to the uncertainty about the trustworthiness and reputation of site administrators, the availability of options to hide email addresses, the existence/enforcement of an acceptable privacy policy, and the chance that the site may one day be compromised or transferred to new owners. DEA users may also need to use a conventional-looking email address or create a separate mailbox in the worst-case scenario if required by a public/commercial entity."
    }
  },
  {
    "instruction": "The Certificate Authority Security Council (CASC) is the industry advocacy organization that Comodo became a founding member of in February 2013 to address industry issues and educate the public on internet security.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What industry advocacy organization did Comodo become a founding member of in February 2013 to address industry issues and educate the public on internet security?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What industry advocacy organization did Comodo become a founding member of in February 2013 to address industry issues and educate the public on internet security?",
      "answer": "The Certificate Authority Security Council (CASC) is the industry advocacy organization that Comodo became a founding member of in February 2013 to address industry issues and educate the public on internet security."
    }
  },
  {
    "instruction": "Mixed reality technologies can pose legal challenges as laws governing the online world will also extend to the real world. Data tagging, virtual reality, and the amalgamation of mixed reality with daily tasks can implicate numerous legal issues ranging from copyright law to intellectual property law.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What are the implications of mixed reality technologies on the legal field?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What are the implications of mixed reality technologies on the legal field?",
      "answer": "Mixed reality technologies can pose legal challenges as laws governing the online world will also extend to the real world. Data tagging, virtual reality, and the amalgamation of mixed reality with daily tasks can implicate numerous legal issues ranging from copyright law to intellectual property law."
    }
  },
  {
    "instruction": "Operation Cyberstorm was a two-year undercover operation.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What was the time frame for Operation Cyberstorm?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What was the time frame for Operation Cyberstorm?",
      "answer": "Operation Cyberstorm was a two-year undercover operation."
    }
  },
  {
    "instruction": "Users can evaluate the performance of their WAF using WAFER in Cloudbric Labs, which tests the detection capabilities of widely-used WAFs and provides insights into their effectiveness in protecting websites.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How can users evaluate the performance of their WAF using Cloudbric Labs?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How can users evaluate the performance of their WAF using Cloudbric Labs?",
      "answer": "Users can evaluate the performance of their WAF using WAFER in Cloudbric Labs, which tests the detection capabilities of widely-used WAFs and provides insights into their effectiveness in protecting websites."
    }
  },
  {
    "instruction": "SWIPSY was significant in the development of MIDASS, an SNMP firewall system, as it was used to build this system. Additionally, SWIPSY technology was licensed by Clearswift for use in its Deep-Secure line of guard products. QinetiQ also used SWIPSY as the basis for a guard for the Citrix ICA protocol.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What was the significance of SWIPSY in the development of SNMP firewall system called MIDASS and Citrix ICA protocol guard?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What was the significance of SWIPSY in the development of SNMP firewall system called MIDASS and Citrix ICA protocol guard?",
      "answer": "SWIPSY was significant in the development of MIDASS, an SNMP firewall system, as it was used to build this system. Additionally, SWIPSY technology was licensed by Clearswift for use in its Deep-Secure line of guard products. QinetiQ also used SWIPSY as the basis for a guard for the Citrix ICA protocol."
    }
  },
  {
    "instruction": "The main objective of the IDESG was to administer the development and adoption of the NSTIC framework. The IDEF Registry, introduced in 2016, is a tool for self-assessment that helps organizations align with the IDEF and comply with NSTIC guidelines.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What was the main objective of the Identity Ecosystem Steering Group (IDESG) and what is the Identity Ecosystem Framework (IDEF) Registry?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What was the main objective of the Identity Ecosystem Steering Group (IDESG) and what is the Identity Ecosystem Framework (IDEF) Registry?",
      "answer": "The main objective of the IDESG was to administer the development and adoption of the NSTIC framework. The IDEF Registry, introduced in 2016, is a tool for self-assessment that helps organizations align with the IDEF and comply with NSTIC guidelines."
    }
  },
  {
    "instruction": "In 2001, the federal Competition Bureau of Canada issued a warning about documents that appeared to be invoices sent out by a business called the Internet Registry of Canada (a Brandon Gray reseller), which gave the impression that it was affiliated with the Government of Canada or that it was an officially sanctioned agency registering domain names in Canada. VeriSign was sued in 2002 for their actions in sending ambiguous emails informing people that their domain was about to expire and inviting them to click on a link to renew it. In March 2002, the FTC shut down TLD Network Ltd, Quantum Management (GB) Ltd., TBS Industries Ltd. of London, England, for selling bogus domain names \".USA\", \".BRIT\", which they deceptively marketed as usable suffixes.\n\nWrite a question about the text above.",
    "context": "",
    "output": "Can you give examples of past domain scams and the companies involved?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "Can you give examples of past domain scams and the companies involved?",
      "answer": "In 2001, the federal Competition Bureau of Canada issued a warning about documents that appeared to be invoices sent out by a business called the Internet Registry of Canada (a Brandon Gray reseller), which gave the impression that it was affiliated with the Government of Canada or that it was an officially sanctioned agency registering domain names in Canada. VeriSign was sued in 2002 for their actions in sending ambiguous emails informing people that their domain was about to expire and inviting them to click on a link to renew it. In March 2002, the FTC shut down TLD Network Ltd, Quantum Management (GB) Ltd., TBS Industries Ltd. of London, England, for selling bogus domain names \".USA\", \".BRIT\", which they deceptively marketed as usable suffixes."
    }
  },
  {
    "instruction": "Context: Certificate signing request\n\n==Introduction==\nIn public key infrastructure (PKI) systems, a certificate signing request (also CSR or certification request) is a message sent from an applicant to a certificate authority of the public key infrastructure in order to apply for a digital identity certificate. It usually contains the public key for which the certificate should be issued, identifying information (such as a domain name) and a proof of authenticity including integrity protection (e.g., a digital signature). The most common format for CSRs is the PKCS #10 specification; \nothers include the more capable  CRMF\nand the Signed Public Key and Challenge SPKAC format generated by some web browsers.\n\n\n\n== Procedure ==\nBefore creating a CSR for an X.509 certificate, the applicant first generates a key pair, keeping the private key secret. The CSR contains information identifying the applicant (such as a distinguished name), the public key chosen by the applicant, and possibly further information. When using the PKCS #10 format, the request must be self-signed using the applicant's private key, which provides proof-of-possession of the private key but limits the use of this format to keys that can be used for signing. The CSR should be accompanied by a proof of origin (i.e., proof of identity of the applicant) that is required by the certificate authority, and the certificate authority may contact the applicant for further information.\nTypical information required in a CSR (sample column from sample X.509 certificate). Note that there are often alternatives for the Distinguished Names (DN), the preferred value is listed.\n\nIf the request is successful, the certificate authority will send back an identity certificate that has been digitally signed using the private key of the certificate authority.\n\n== Structure of a PKCS #10 CSR ==\nA certification request in PKCS #10 format consists of three main parts: the certification request information, a signature algorithm identifier, and a digital signature on the certification request information.  The first part contains the significant information, including the public key.  The signature by the requester prevents an entity from requesting a bogus certificate of someone else's public key.  Thus the private key is needed to produce a PKCS #10 CSR, but it is not part of, the CSR.CSR for personal ID certificates and signing certificates must have the email address of the ID holder or name of organisation in case of business ID.\nThe first part, ASN.1 type CertificationRequestInfo, consists of a version number (which is 0 for all known versions, 1.0, 1.5, and 1.7 of the specifications), the subject name, the public key (algorithm identifier + bit string), and a collection of attributes providing additional information about the subject of the certificate.  The attributes can contain required certificate extensions, a challenge-password to restrict revocations, as well as any additional information about the subject of the certificate, possibly including local or future types.\n\n== Example of a PKCS #10 CSR ==\nThe PKCS#10 standard defines a binary format for encoding CSRs for use with X.509. It is expressed in ASN.1. Here is an example of how you can examine its ASN.1 structure using OpenSSL:\n\nopenssl asn1parse -i -in your_request\n\nA CSR may be represented as a Base64 encoded PKCS#10; an example of which is\ngiven below:\n\nThe above certificate signing request's ASN.1 structure (as parsed by openssl) appears as the following, where the first number is the byte offset, d\nQuestion: What is a certificate signing request (CSR) used for in public key infrastructure (PKI) systems?\n\nAnswer:",
    "context": "",
    "output": "A CSR is a message sent from an applicant to a certificate authority (CA) in a PKI system to apply for a digital identity certificate. It contains the public key for which the certificate should be issued, identifying information such as a domain name, and a proof of authenticity including integrity protection such as a digital signature.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is a certificate signing request (CSR) used for in public key infrastructure (PKI) systems?",
      "answer": "A CSR is a message sent from an applicant to a certificate authority (CA) in a PKI system to apply for a digital identity certificate. It contains the public key for which the certificate should be issued, identifying information such as a domain name, and a proof of authenticity including integrity protection such as a digital signature.",
      "context": "Certificate signing request\n\n==Introduction==\nIn public key infrastructure (PKI) systems, a certificate signing request (also CSR or certification request) is a message sent from an applicant to a certificate authority of the public key infrastructure in order to apply for a digital identity certificate. It usually contains the public key for which the certificate should be issued, identifying information (such as a domain name) and a proof of authenticity including integrity protection (e.g., a digital signature). The most common format for CSRs is the PKCS #10 specification; \nothers include the more capable  CRMF\nand the Signed Public Key and Challenge SPKAC format generated by some web browsers.\n\n\n\n== Procedure ==\nBefore creating a CSR for an X.509 certificate, the applicant first generates a key pair, keeping the private key secret. The CSR contains information identifying the applicant (such as a distinguished name), the public key chosen by the applicant, and possibly further information. When using the PKCS #10 format, the request must be self-signed using the applicant's private key, which provides proof-of-possession of the private key but limits the use of this format to keys that can be used for signing. The CSR should be accompanied by a proof of origin (i.e., proof of identity of the applicant) that is required by the certificate authority, and the certificate authority may contact the applicant for further information.\nTypical information required in a CSR (sample column from sample X.509 certificate). Note that there are often alternatives for the Distinguished Names (DN), the preferred value is listed.\n\nIf the request is successful, the certificate authority will send back an identity certificate that has been digitally signed using the private key of the certificate authority.\n\n== Structure of a PKCS #10 CSR ==\nA certification request in PKCS #10 format consists of three main parts: the certification request information, a signature algorithm identifier, and a digital signature on the certification request information.  The first part contains the significant information, including the public key.  The signature by the requester prevents an entity from requesting a bogus certificate of someone else's public key.  Thus the private key is needed to produce a PKCS #10 CSR, but it is not part of, the CSR.CSR for personal ID certificates and signing certificates must have the email address of the ID holder or name of organisation in case of business ID.\nThe first part, ASN.1 type CertificationRequestInfo, consists of a version number (which is 0 for all known versions, 1.0, 1.5, and 1.7 of the specifications), the subject name, the public key (algorithm identifier + bit string), and a collection of attributes providing additional information about the subject of the certificate.  The attributes can contain required certificate extensions, a challenge-password to restrict revocations, as well as any additional information about the subject of the certificate, possibly including local or future types.\n\n== Example of a PKCS #10 CSR ==\nThe PKCS#10 standard defines a binary format for encoding CSRs for use with X.509. It is expressed in ASN.1. Here is an example of how you can examine its ASN.1 structure using OpenSSL:\n\nopenssl asn1parse -i -in your_request\n\nA CSR may be represented as a Base64 encoded PKCS#10; an example of which is\ngiven below:\n\nThe above certificate signing request's ASN.1 structure (as parsed by openssl) appears as the following, where the first number is the byte offset, d"
    }
  },
  {
    "instruction": "ANSSI provides advice and support to government and operators of critical national infrastructure in the area of information systems security.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does ANSSI support government and operators of critical national infrastructure?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does ANSSI support government and operators of critical national infrastructure?",
      "answer": "ANSSI provides advice and support to government and operators of critical national infrastructure in the area of information systems security."
    }
  },
  {
    "instruction": "An Indicator of Compromise (IoC) in computer forensics is an artifact that is observed on a network or in an operating system, which, with high confidence, indicates a computer intrusion.\n\nWrite a question about the text above.",
    "context": "",
    "output": "Can you explain what an Indicator of Compromise (IoC) is in the context of computer forensics?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "Can you explain what an Indicator of Compromise (IoC) is in the context of computer forensics?",
      "answer": "An Indicator of Compromise (IoC) in computer forensics is an artifact that is observed on a network or in an operating system, which, with high confidence, indicates a computer intrusion."
    }
  },
  {
    "instruction": "The Computer Fraud and Abuse Act (CFAA) protects classified information contained in an intrastate local area network by including in the definition of \"protected computer\" any computer used in interstate or foreign commerce or communications. This specific inclusion ensures the protection of the integrity, confidentiality, and availability of classified information.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does the Computer Fraud and Abuse Act (CFAA) protect classified information contained in an intrastate local area network?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does the Computer Fraud and Abuse Act (CFAA) protect classified information contained in an intrastate local area network?",
      "answer": "The Computer Fraud and Abuse Act (CFAA) protects classified information contained in an intrastate local area network by including in the definition of \"protected computer\" any computer used in interstate or foreign commerce or communications. This specific inclusion ensures the protection of the integrity, confidentiality, and availability of classified information."
    }
  },
  {
    "instruction": "The Tapandegan's hack of the Tabriz International Airport is significant because it disrupted the arrival and departure monitors in the airport, and the message displayed expressed support for Iranian truckers who had been on strike across Iran for several weeks.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the significance of the Tapandegan's hack of the Tabriz International Airport, according to the given text?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the significance of the Tapandegan's hack of the Tabriz International Airport, according to the given text?",
      "answer": "The Tapandegan's hack of the Tabriz International Airport is significant because it disrupted the arrival and departure monitors in the airport, and the message displayed expressed support for Iranian truckers who had been on strike across Iran for several weeks."
    }
  },
  {
    "instruction": "The Safe Browsing Lookup API has a privacy drawback in that it does not hash the URLs to be looked up, allowing the server to know which URLs the API users have looked up. This can potentially compromise user privacy.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does the Safe Browsing Lookup API impact user privacy?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does the Safe Browsing Lookup API impact user privacy?",
      "answer": "The Safe Browsing Lookup API has a privacy drawback in that it does not hash the URLs to be looked up, allowing the server to know which URLs the API users have looked up. This can potentially compromise user privacy."
    }
  },
  {
    "instruction": "The article \"On Some Methods for Unconditionally Secure Key Distribution and Broadcast Encryption\" by Douglas Robert Stinson was published in issue 3 of Designs, Codes and Cryptography.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the issue number of the journal in which the article \"On Some Methods for Unconditionally Secure Key Distribution and Broadcast Encryption\" by Douglas Robert Stinson was published?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the issue number of the journal in which the article \"On Some Methods for Unconditionally Secure Key Distribution and Broadcast Encryption\" by Douglas Robert Stinson was published?",
      "answer": "The article \"On Some Methods for Unconditionally Secure Key Distribution and Broadcast Encryption\" by Douglas Robert Stinson was published in issue 3 of Designs, Codes and Cryptography."
    }
  },
  {
    "instruction": "Several users discovered a hidden backdoor crypto-mining tool in the Norton 360 security software suite.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What was the issue discovered with Norton 360 security software suite in January 2022?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What was the issue discovered with Norton 360 security software suite in January 2022?",
      "answer": "Several users discovered a hidden backdoor crypto-mining tool in the Norton 360 security software suite."
    }
  },
  {
    "instruction": "LCMS provides automation for the detailed accounting required for every COMSEC account, and electronic key generation and distribution capability in AKMS.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the role of LCMS in AKMS?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the role of LCMS in AKMS?",
      "answer": "LCMS provides automation for the detailed accounting required for every COMSEC account, and electronic key generation and distribution capability in AKMS."
    }
  },
  {
    "instruction": "Cohen's cryptosystem uses k public keys.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How many public keys are used in Cohen's cryptosystem?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How many public keys are used in Cohen's cryptosystem?",
      "answer": "Cohen's cryptosystem uses k public keys."
    }
  },
  {
    "instruction": "The GNIS Feature ID codes are more permanent and are maintained by the U.S. Board on Geographic Names, while the FIPS place codes were assigned alphabetically to places within each state and as a result changed frequently. The GNIS database is the official geographic names repository database for the United States, and is designated the only source of geographic names and locative attributes for use by the agencies of the Federal Government.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How do the GNIS Feature ID codes differ from the FIPS place codes?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How do the GNIS Feature ID codes differ from the FIPS place codes?",
      "answer": "The GNIS Feature ID codes are more permanent and are maintained by the U.S. Board on Geographic Names, while the FIPS place codes were assigned alphabetically to places within each state and as a result changed frequently. The GNIS database is the official geographic names repository database for the United States, and is designated the only source of geographic names and locative attributes for use by the agencies of the Federal Government."
    }
  },
  {
    "instruction": "Personal Information Protection and Electronic Documents Act\n\n==Introduction==\nThe Personal Information Protection and Electronic Documents Act (PIPEDA; French: Loi sur la protection des\nrenseignements personnels et\nles documents \u00e9lectroniques) is a Canadian law relating to data privacy. It governs how private sector organizations collect, use and disclose personal information in the course of commercial business. In addition, the Act contains various provisions to facilitate the use of electronic documents. PIPEDA became law on 13 April 2000 to promote consumer trust in electronic commerce. The act was also intended to reassure the European Union that the Canadian privacy law was adequate to protect the personal information of European citizens. In accordance with section 29 of PIPEDA, Part I of the Act (\"Protection of Personal Information in the Private Sector\") must be reviewed by Parliament every five years. The first Parliamentary review occurred in 2007.PIPEDA incorporates and makes mandatory provisions of the Canadian Standards Association's Model Code for the Protection of Personal Information, developed in 1995. However, there are a number of exceptions to the Code where information can be collected, used and disclosed without the consent of the individual. Examples include reasons of national security, international affairs, and emergencies. Under the Act, personal information can also be disclosed without knowledge or consent to investigations related to law enforcement, whether federal, provincial or foreign. There are also exceptions to the general rule that an individual shall be given access to his or her personal information. Exceptions may include information that would likely reveal personal information about a third party, information that cannot be disclosed for certain legal, security, or commercial proprietary reasons, and information that is subject to solicitor-client privilege.\n\n== Overview ==\n\"Personal Information\", as specified in PIPEDA, is as follows: information about an identifiable individual, but does not include the name, title or business address, or telephone number of an employee of an organization.\nThe Act gives individuals the right to\n\nknow why an organization collects, uses, or discloses their personal information;\nexpect an organization to collect, use or disclose their personal information reasonably and appropriately, and not use the information for any purpose other than that to which they have consented;\nknow who in the organization is responsible for protecting their personal information;\nexpect an organization to protect their personal information by taking appropriate security measures;\nexpect the personal information an organization holds about them to be accurate, complete, and up-to-date;\nobtain access to their personal information and ask for corrections if necessary; and\ncomplain about how an organization handles their personal information if they feel their privacy rights have not been respected.The Act requires organizations to\n\nobtain consent when they collect, use, or disclose their personal information;\nsupply an individual with a product or a service even if they refuse consent for the collection, use, or disclosure of your personal information unless that information is essential to the transaction;\ncollect information by fair and lawful means; and\nhave personal information policies that are clear, understandable, and readily available.\n\n== Implementation ==\nThe implementation of PIPEDA occurred in three stages. Starting in 2001, the law applied to federally regulated industries (such as airlines, banking and broadcasting).  In 2002, the law was expanded to include the health sector.  Finally in 2004, any organization that collects personal information in the course of commercial activity was covered by PIPEDA, except in provinces that have \"substantially similar\" privacy laws. As of October 2018, seven provinces have privacy laws that have been declared by the federal Governor in Council to be substantially similar to PIPEDA:\nAn Act Respecting the Protection of Personal Information in the Private Sector (Quebec)\nThe Personal Information Protection Act (British Columbia)\nThe Personal Information Protection Act (Alberta)\nThe Personal Health Information Protection Act (Ontario), \"with respect to health information custodians\"\nThe Personal Health Information Privacy and Access Act (New Brunswick), \"with respect to personal health information custodians\"\nThe Personal Health Information Act (Newfoundland and Labrador), \"with respect to health information custodians\"\nThe Personal Health Information Act (Nova Scotia), \"with respect to health information custodians\"\nMemorandum of Understanding\n\n\n*** Personal Information Protection Act (British Columbia) ***\nNotable provisions of PIPA:\nConsent must be garnered for the collection of personal information\nCollection of personal information limited to reasonable purposes\nLimits use and disclosure of personal information\nLimits access to personal information\nStored personal information must be accurate and complete\nDesignates the role of the Privacy Officer\nPolicies and procedures for breaches of privacy\nMeasures for resolution of complaints\nSpecial rules for employment relationships\n\n\n*** Personal Health Information Protection Act (Ontario) ***\n\nThe Personal Health Information Protection Act, known by its acronym PHIPA (typically pronounced 'pee-hip-ah'), established in 2004, outlines privacy regulations for health information custodians in Ontario, Canada. Breaches of PHIPA are directed to the Ontario Information and Privacy Commissioner.The Personal Health Information Protection Act serves three important functions:\n\nTo govern the collection, use, and disclosure of personal health information by health information custodians.\nTo provide patients with a right to request access to and correction of their records of personal health information held by health information custodians.\nTo impose administrative requirements (regulations) on custodians with respect to records of personal health information.\n\n== Amendment ==\nOn June 18, 2015, the Digital Privacy Act (Senate Bill S-4) became law, amending the PIPEDA to include a business transaction exemption, mandatory breach notification requirements, enhanced powers for the Privacy Commissioner, and various other updates.\nThe PIPEDA sets out ground rules for how private sector organizations may collect, use or disclose personal information in the course of commercial activities. PIPEDA also applies to federal works, undertaking,s and business in respect of employee personal information. The law gives individuals the right to access and request correction of the personal information these organizations may have collected about them.\nIn general, PIPEDA applies to organizations' commercial activities in all provinces, except organizations that collect, use or disclose personal information entirely within provinces that have their own privacy laws, which have been declared substantially similar to the federal law. In such cases, it is the substantially similar provincial law that will apply instead of PIPEDA, although PIPEDA continues to apply to federal works, undertakings or businesses and to interprovincial or international transfers of personal information.\n\n== Remedies ==\nThe Act does not create an automatic right to sue for violations of the law's obligations. Instead, PIPEDA follows an ombudsman model in which complaints are taken to the Office of the Privacy Commissioner of Canada. The Commissioner is required to investigate the complaint and to produce a report at its conclusion. The report is not binding on the parties but is more of a recommendation. The Commissioner does not have any powers to order compliance, award damages, or levy penalties. The organization complained about does not have to follow the recommendations. The complainant, with the report in hand, can then take the matter to the Federal Court of Canada. The responding organization cannot take the matter to the courts, because the report is not a decision and PIPEDA does not explicitly grant the responding organization the right to do so.PIPEDA provides, at section 14, the complainant the right to apply to the Federal Court of Canada for a hearing with respect to the subject matter of the complaint. The Court has the power to order the organization to correct its practices, to publicize the steps it will take to correct its practices, and to award damages.\n\n== Proposed Bill C-475 ==\nAs a result of long-enduring and central gap in Canada's privacy protections, Bill C-475 was proposed in February 2013 by Charmaine Borg, MP, proposing several amendments to the Act.  Bill C-475 was defeated in January 2014. Answer this question using the following article:\n\nWhat is the role of the Canadian Standards Association's Model Code for the Protection of Personal Information under PIPEDA?",
    "context": "",
    "output": "The Canadian Standards Association's Model Code for the Protection of Personal Information is incorporated and made mandatory under PIPEDA, setting the standards for personal information protection in the private sector.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the role of the Canadian Standards Association's Model Code for the Protection of Personal Information under PIPEDA?",
      "answer": "The Canadian Standards Association's Model Code for the Protection of Personal Information is incorporated and made mandatory under PIPEDA, setting the standards for personal information protection in the private sector.",
      "context": "Personal Information Protection and Electronic Documents Act\n\n==Introduction==\nThe Personal Information Protection and Electronic Documents Act (PIPEDA; French: Loi sur la protection des\nrenseignements personnels et\nles documents \u00e9lectroniques) is a Canadian law relating to data privacy. It governs how private sector organizations collect, use and disclose personal information in the course of commercial business. In addition, the Act contains various provisions to facilitate the use of electronic documents. PIPEDA became law on 13 April 2000 to promote consumer trust in electronic commerce. The act was also intended to reassure the European Union that the Canadian privacy law was adequate to protect the personal information of European citizens. In accordance with section 29 of PIPEDA, Part I of the Act (\"Protection of Personal Information in the Private Sector\") must be reviewed by Parliament every five years. The first Parliamentary review occurred in 2007.PIPEDA incorporates and makes mandatory provisions of the Canadian Standards Association's Model Code for the Protection of Personal Information, developed in 1995. However, there are a number of exceptions to the Code where information can be collected, used and disclosed without the consent of the individual. Examples include reasons of national security, international affairs, and emergencies. Under the Act, personal information can also be disclosed without knowledge or consent to investigations related to law enforcement, whether federal, provincial or foreign. There are also exceptions to the general rule that an individual shall be given access to his or her personal information. Exceptions may include information that would likely reveal personal information about a third party, information that cannot be disclosed for certain legal, security, or commercial proprietary reasons, and information that is subject to solicitor-client privilege.\n\n== Overview ==\n\"Personal Information\", as specified in PIPEDA, is as follows: information about an identifiable individual, but does not include the name, title or business address, or telephone number of an employee of an organization.\nThe Act gives individuals the right to\n\nknow why an organization collects, uses, or discloses their personal information;\nexpect an organization to collect, use or disclose their personal information reasonably and appropriately, and not use the information for any purpose other than that to which they have consented;\nknow who in the organization is responsible for protecting their personal information;\nexpect an organization to protect their personal information by taking appropriate security measures;\nexpect the personal information an organization holds about them to be accurate, complete, and up-to-date;\nobtain access to their personal information and ask for corrections if necessary; and\ncomplain about how an organization handles their personal information if they feel their privacy rights have not been respected.The Act requires organizations to\n\nobtain consent when they collect, use, or disclose their personal information;\nsupply an individual with a product or a service even if they refuse consent for the collection, use, or disclosure of your personal information unless that information is essential to the transaction;\ncollect information by fair and lawful means; and\nhave personal information policies that are clear, understandable, and readily available.\n\n== Implementation ==\nThe implementation of PIPEDA occurred in three stages. Starting in 2001, the law applied to federally regulated industries (such as airlines, banking and broadcasting).  In 2002, the law was expanded to include the health sector.  Finally in 2004, any organization that collects personal information in the course of commercial activity was covered by PIPEDA, except in provinces that have \"substantially similar\" privacy laws. As of October 2018, seven provinces have privacy laws that have been declared by the federal Governor in Council to be substantially similar to PIPEDA:\nAn Act Respecting the Protection of Personal Information in the Private Sector (Quebec)\nThe Personal Information Protection Act (British Columbia)\nThe Personal Information Protection Act (Alberta)\nThe Personal Health Information Protection Act (Ontario), \"with respect to health information custodians\"\nThe Personal Health Information Privacy and Access Act (New Brunswick), \"with respect to personal health information custodians\"\nThe Personal Health Information Act (Newfoundland and Labrador), \"with respect to health information custodians\"\nThe Personal Health Information Act (Nova Scotia), \"with respect to health information custodians\"\nMemorandum of Understanding\n\n\n*** Personal Information Protection Act (British Columbia) ***\nNotable provisions of PIPA:\nConsent must be garnered for the collection of personal information\nCollection of personal information limited to reasonable purposes\nLimits use and disclosure of personal information\nLimits access to personal information\nStored personal information must be accurate and complete\nDesignates the role of the Privacy Officer\nPolicies and procedures for breaches of privacy\nMeasures for resolution of complaints\nSpecial rules for employment relationships\n\n\n*** Personal Health Information Protection Act (Ontario) ***\n\nThe Personal Health Information Protection Act, known by its acronym PHIPA (typically pronounced 'pee-hip-ah'), established in 2004, outlines privacy regulations for health information custodians in Ontario, Canada. Breaches of PHIPA are directed to the Ontario Information and Privacy Commissioner.The Personal Health Information Protection Act serves three important functions:\n\nTo govern the collection, use, and disclosure of personal health information by health information custodians.\nTo provide patients with a right to request access to and correction of their records of personal health information held by health information custodians.\nTo impose administrative requirements (regulations) on custodians with respect to records of personal health information.\n\n== Amendment ==\nOn June 18, 2015, the Digital Privacy Act (Senate Bill S-4) became law, amending the PIPEDA to include a business transaction exemption, mandatory breach notification requirements, enhanced powers for the Privacy Commissioner, and various other updates.\nThe PIPEDA sets out ground rules for how private sector organizations may collect, use or disclose personal information in the course of commercial activities. PIPEDA also applies to federal works, undertaking,s and business in respect of employee personal information. The law gives individuals the right to access and request correction of the personal information these organizations may have collected about them.\nIn general, PIPEDA applies to organizations' commercial activities in all provinces, except organizations that collect, use or disclose personal information entirely within provinces that have their own privacy laws, which have been declared substantially similar to the federal law. In such cases, it is the substantially similar provincial law that will apply instead of PIPEDA, although PIPEDA continues to apply to federal works, undertakings or businesses and to interprovincial or international transfers of personal information.\n\n== Remedies ==\nThe Act does not create an automatic right to sue for violations of the law's obligations. Instead, PIPEDA follows an ombudsman model in which complaints are taken to the Office of the Privacy Commissioner of Canada. The Commissioner is required to investigate the complaint and to produce a report at its conclusion. The report is not binding on the parties but is more of a recommendation. The Commissioner does not have any powers to order compliance, award damages, or levy penalties. The organization complained about does not have to follow the recommendations. The complainant, with the report in hand, can then take the matter to the Federal Court of Canada. The responding organization cannot take the matter to the courts, because the report is not a decision and PIPEDA does not explicitly grant the responding organization the right to do so.PIPEDA provides, at section 14, the complainant the right to apply to the Federal Court of Canada for a hearing with respect to the subject matter of the complaint. The Court has the power to order the organization to correct its practices, to publicize the steps it will take to correct its practices, and to award damages.\n\n== Proposed Bill C-475 ==\nAs a result of long-enduring and central gap in Canada's privacy protections, Bill C-475 was proposed in February 2013 by Charmaine Borg, MP, proposing several amendments to the Act.  Bill C-475 was defeated in January 2014."
    }
  },
  {
    "instruction": "Context: VirusTotal\n\n==Introduction==\nVirusTotal is a website created by the Spanish security company Hispasec Sistemas.  Launched in June 2004, it was acquired by Google in September 2012. The company's ownership switched in January 2018 to Chronicle, a subsidiary of Google.\nVirusTotal aggregates many antivirus products and online scan engines called Contributors. In November, 2018, the Cyber National Mission Force, a unit subordinate to the U.S. Cyber Command became a Contributor. The aggregated data from these Contributors allows a user to check for viruses that the user's own antivirus software may have missed, or to verify against any false positives. Files up to 650 MB can be uploaded to the website, or sent via email (max. 32MB). Anti-virus software vendors can receive copies of files that were flagged by other scans but passed by their own engine, to help improve their software and, by extension, VirusTotal's own capability. Users can also scan suspect URLs and search through the VirusTotal dataset. VirusTotal uses the Cuckoo sandbox for dynamic analysis of malware.\nVirusTotal was selected by PC World as one of the best 100 products of 2007.\n\n== Products and services ==\n\n\n*** Windows Uploader ***\nVirusTotal's Windows Uploader was an application that integrates into the Explorer's (right-click) contextual menu, listed under Send To > Virus Total.  The application also launches manually for submitting a URL or a program that is currently running in the OS.\nVirusTotal stores the name and various hashes for each scanned file. Already scanned files can be identified by their known (e.g., VT default) SHA256 hash without uploading complete files. The SHA256 query URL has the form https://www.virustotal.com/latest-scan/SHA256. File uploads are normally limited to 128 MB. In 2017 VirusTotal discontinued support of the Windows Uploader.\n\n\n*** Uploader for Mac OS X and Linux ***\nSame as the Windows app you upload the file (via the app's UI or context menu) then you will be given back a result. The Mac OS X app can be downloaded from their website. However, you need to compile and build the app for Linux using the same core (provided in their repository) used in the Mac OS X application. Already scanned files can be identified by their known (e.g., VT default) SHA256 hash without uploading complete files.\n\n\n*** VirusTotal for Browsers ***\nThere are several browser extensions available, such as VT4Browsers for Mozilla Firefox, and Google Chrome and vtExplorer for Internet Explorer. They allow the user to download files directly with VirusTotal's web application prior to storing them in the computer, as well as scanning URLs.\n\n\n*** VirusTotal for Mobile ***\nThe service also offers an Android App that employs the public API to search any installed application for VirusTotal's previously scanned ones and show its status. Any application not previously scanned can be submitted, but an API key must be provided and other restrictions to public API usage may apply (see #Public API).\n\n\n*** Public API ***\nVirusTotal provides as a free service a public API that allows for automation of some of its online features such as \"upload and scan files, submit and scan URLs, access finished scan reports and make automatic comments on URLs and samples\". Some restrictions apply for requests made through the public API, such as requiring an individual API key freely obtained by online signing up, low priority scan queue, limited number of requests per time frame, etc.\n\n\n*** Antivirus products ***\nAntivirus engines used for detection for uploading files.\n\n\n*** Website/domain scanning engines and datasets ***\nAntivirus scanning engines used for URL scanning.\n\n\n*** File characterization tools & datasets ***\nUtilities used to provide additional info on uploaded files.\n\n== Privacy ==\nFiles uploaded to VirusTotal may be shared freely with anti-malware companies and will also be retained in a store. The VirusTotal About Page states under VirusTotal and confidentiality:\nFiles and URLs sent to VirusTotal will be shared with antivirus vendors and security companies so as to help them in improving their services and products. We do this because we believe it will eventually lead to a safer Internet and better end-user protection.\nBy default any file/URL submitted to VirusTotal which is detected by at least one scanner is freely sent to all those scanners that do not detect the resource. Additionally, all files and URLs enter a private store that may be accessed by premium (mainly security/antimalware companies/organizations) VirusTotal users so as to improve their security products and services.\nQuestion: Is it possible to use VirusTotal for free?\n\nAnswer:",
    "context": "",
    "output": "Yes, VirusTotal provides many of its features, such as uploading and scanning files, submitting and scanning URLs, accessing finished scan reports, and making automatic comments on URLs and samples, as a free service.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "Is it possible to use VirusTotal for free?",
      "answer": "Yes, VirusTotal provides many of its features, such as uploading and scanning files, submitting and scanning URLs, accessing finished scan reports, and making automatic comments on URLs and samples, as a free service.",
      "context": "VirusTotal\n\n==Introduction==\nVirusTotal is a website created by the Spanish security company Hispasec Sistemas.  Launched in June 2004, it was acquired by Google in September 2012. The company's ownership switched in January 2018 to Chronicle, a subsidiary of Google.\nVirusTotal aggregates many antivirus products and online scan engines called Contributors. In November, 2018, the Cyber National Mission Force, a unit subordinate to the U.S. Cyber Command became a Contributor. The aggregated data from these Contributors allows a user to check for viruses that the user's own antivirus software may have missed, or to verify against any false positives. Files up to 650 MB can be uploaded to the website, or sent via email (max. 32MB). Anti-virus software vendors can receive copies of files that were flagged by other scans but passed by their own engine, to help improve their software and, by extension, VirusTotal's own capability. Users can also scan suspect URLs and search through the VirusTotal dataset. VirusTotal uses the Cuckoo sandbox for dynamic analysis of malware.\nVirusTotal was selected by PC World as one of the best 100 products of 2007.\n\n== Products and services ==\n\n\n*** Windows Uploader ***\nVirusTotal's Windows Uploader was an application that integrates into the Explorer's (right-click) contextual menu, listed under Send To > Virus Total.  The application also launches manually for submitting a URL or a program that is currently running in the OS.\nVirusTotal stores the name and various hashes for each scanned file. Already scanned files can be identified by their known (e.g., VT default) SHA256 hash without uploading complete files. The SHA256 query URL has the form https://www.virustotal.com/latest-scan/SHA256. File uploads are normally limited to 128 MB. In 2017 VirusTotal discontinued support of the Windows Uploader.\n\n\n*** Uploader for Mac OS X and Linux ***\nSame as the Windows app you upload the file (via the app's UI or context menu) then you will be given back a result. The Mac OS X app can be downloaded from their website. However, you need to compile and build the app for Linux using the same core (provided in their repository) used in the Mac OS X application. Already scanned files can be identified by their known (e.g., VT default) SHA256 hash without uploading complete files.\n\n\n*** VirusTotal for Browsers ***\nThere are several browser extensions available, such as VT4Browsers for Mozilla Firefox, and Google Chrome and vtExplorer for Internet Explorer. They allow the user to download files directly with VirusTotal's web application prior to storing them in the computer, as well as scanning URLs.\n\n\n*** VirusTotal for Mobile ***\nThe service also offers an Android App that employs the public API to search any installed application for VirusTotal's previously scanned ones and show its status. Any application not previously scanned can be submitted, but an API key must be provided and other restrictions to public API usage may apply (see #Public API).\n\n\n*** Public API ***\nVirusTotal provides as a free service a public API that allows for automation of some of its online features such as \"upload and scan files, submit and scan URLs, access finished scan reports and make automatic comments on URLs and samples\". Some restrictions apply for requests made through the public API, such as requiring an individual API key freely obtained by online signing up, low priority scan queue, limited number of requests per time frame, etc.\n\n\n*** Antivirus products ***\nAntivirus engines used for detection for uploading files.\n\n\n*** Website/domain scanning engines and datasets ***\nAntivirus scanning engines used for URL scanning.\n\n\n*** File characterization tools & datasets ***\nUtilities used to provide additional info on uploaded files.\n\n== Privacy ==\nFiles uploaded to VirusTotal may be shared freely with anti-malware companies and will also be retained in a store. The VirusTotal About Page states under VirusTotal and confidentiality:\nFiles and URLs sent to VirusTotal will be shared with antivirus vendors and security companies so as to help them in improving their services and products. We do this because we believe it will eventually lead to a safer Internet and better end-user protection.\nBy default any file/URL submitted to VirusTotal which is detected by at least one scanner is freely sent to all those scanners that do not detect the resource. Additionally, all files and URLs enter a private store that may be accessed by premium (mainly security/antimalware companies/organizations) VirusTotal users so as to improve their security products and services."
    }
  },
  {
    "instruction": "Context: Parental controls\n\n==Introduction==\nParental controls are features which may be included in digital television services, computers and video games, mobile devices and software that allow parents to restrict the access of content to their children. These controls were created to assist parents in their ability to restrict certain content viewable by their children. This may be content they deem inappropriate for their age, maturity level or feel is aimed more at an adult audience. Parental controls fall into roughly four categories: content filters, which limit access to age inappropriate content; usage controls, which constrain the usage of these devices such as placing time-limits on usage or forbidding certain types of usage; computer usage management tools, which enforces the use of certain software; and monitoring, which can track location and activity when using the devices.Content filters were the first popular type of parental controls to limit access to Internet content. Television stations also began to introduce V-Chip technology to limit access to television content. Modern usage controls are able to restrict a range of explicit content such as explicit songs and movies. They are also able to turn devices off during specific times of the day, limiting the volume output of devices, and with GPS technology becoming affordable, it is now possible to easily locate devices such as mobile phones. UNICEF emphases the responsibility of parents and teachers in this role.The demand for parental control methods that restrict content has increased over the decades due to the rising availability of the Internet. A 2014 ICM survey showed that almost a quarter of people under the age of 12 had been exposed to online pornography. Restricting especially helps in cases when children are exposed to inappropriate content by accident. Monitoring may be effective for lessening acts of cyberbullying within the internet. It is unclear whether parental controls will affect online harassment in children, as little is known about the role the family plays in protecting children from undesirable experiences online. Psychologically, cyberbullying could be more harmful to the victim than traditional bullying. Studies done in the past have shown that about 75% of adolescents were subjected to cyberbullying. A lack of parental controls in the household could enable kids to be a part of cyberbullying or be the victim of cyberbullying.\n\n\n\n== Overview ==\nBehavioral control consists of controlling the amount of time a child spends online, or how much the child can view. Psychological control involves parents trying to influence children's behavior.Several techniques exist for creating parental controls for blocking websites. Add-on parental control software may monitor API in order to observe applications such as a web browser or Internet chat application and to intervene according to certain criteria, such as a match in a database of banned words. Virtually all parental control software includes a password or other form of authentication to prevent unauthorized users from disabling it.\nTechniques involving a proxy server are also used. A web browser is set to send requests for web content to the proxy server rather than directly to the web server intended. The proxy server then fetches the web page from the server on the browser's behalf and passes on the content to the browser. Proxy servers can inspect the data being sent and received and intervene depending on various criteria relating to content of the page or the URL being requested, for example, using a database of banned words or banned URLs. The proxy method's major disadvantage is that it requires that the client application to be configured to utilize the proxy, and if it is possible for the user to reconfigure applications to access the Internet directly rather than going through the proxy, then this control is easily bypassed. Proxy servers themselves may be used to circumvent parental controls. There are other techniques used to bypass parental controls.\nThe computer usage management method, unlike content filters, is focused on empowering the parents to balance the computing environment for children by regulating gaming. The main idea of these applications is to allow parents to introduce a learning component into the computing time of children, who must earn gaming time while working through educational contents.\nLately network-based parental control devices have emerged. These devices working as a firewall router use packet filtering, DNS Response Policy Zone (RPZ) and Deep packet inspection (DPI) methods to block inappropriate web content. These methods have been used in commercial and governmental communication networks. Another form of these devices made for home networks has been developed. These devices plug into the home router and create a new wireless network, which is specifically designed for kids to connect to.\n\n== Parental controls on mobile devices ==\nThe increased use of mobile devices that include full featured internet browsers and downloadable applications has created a demand for parental controls on these devices. Some examples of mobile devices that contain parental controls include cell phones, tablets, and e-readers. In November 2007, Verizon was the first carrier to offer age-appropriate content filters as well as the first to offer generic content filters, recognizing that mobile devices were used to access all manner of content from movies and music to short-code programs and websites. In June 2009, in iPhone OS 3.0, Apple was the first company to provide a built-in mechanism on mobile devices to create age brackets for users that would block unwanted applications from being downloaded to the device. In the following years, the developers of all major operating systems have presented in-built tools for parental control, including Linux, Android, Windows, and even the more business-oriented platform Blackberry. There are also applications that allow parents to monitor real-time conversations on their children's phone via access to text messages, browser history, and application history. An example of one of these is Trend Micro which not only offers protection from viruses, but also offers parental controls to phones and tablets of almost all brands. Most of these offer the ability to add extra features to parental controls. These apps have the features mobile devices already have, but have additional features such as, being able to monitor and filter texts/calls, protection while surfing the web, and denied access to specific websites. Applications of this sort have created a rising competition in their market.Mobile device software enables parents to restrict which applications their child can access while also allowing parents to monitor text messages, phone logs, MMS pictures, and other transactions occurring on their child's mobile device; to enable parents to set a time limit on the usage of mobile devices; and to track the exact location of their children as well as monitor calls and the content of texts. This software also allows parents to monitor social media accounts. Parents are able to view posts, pictures, and any interactions in real time. Another function of this software is to keep track of bullying.Most internet service providers offer no-cost filtering options to limit internet browsing options and block unsuitable content. Implementing parental controls and discussing internet safety are useful steps to protect children from inappropriate information.Although parental controls can protect children, they also come with some negative factors. Children's anxiety may increase due to parental controls. In extreme cases, a child may become so angry that they destroy their device, defeating the purpose of parental controls entirely. In that case, it might be a better idea to forgo installing parental controls.\n\n== Methods to bypass parental controls ==\nSeveral methods of bypassing parental controls can be used.\n\nIf the filtering software is located locally within the computer, all Internet software can be easily bypassed by booting up the computer in question from alternative media, with an alternative operating system or (on Windows) in Safe Mode. However, if the computer's BIOS is configured to disallow booting from removable media, and if changes to the BIOS are prohibited without proper authentication, then booting into an alternative operating system is not available without circumventing BIOS security by partially disassembling the computer and resetting BIOS configuration using a button or jumper, or removing and replacing the internal button cell battery.\nUsing external proxy servers or other servers. The user sends requests to the external server which retrieves content on the user's behalf. Filtering software may then never be able to know which URLs the user is accessing, as all communications are with the one external server and filtering software never sees any communications with the web servers from which content really originated. To counter this, filtering software may also block access to popular proxies. Additionally, filtering systems which only permit access to a set of allowed URLs (whitelisting) will not permit access anything outside this list, including proxy servers.\nResetting passwords using exploits\nModifying the software's files\nBrute-force attacks on software passwords'Incognito/InPrivate' modes with the 'image' tab: Users, parental control software, and parental control routers may use 'safe search' (SafeSearch) to enforce filtering at most major search engines. However, in most browsers a user may select 'Incognito' or 'InPrivate' browsing, enter search terms for content, and select the 'image' tab to effectively bypass 'safe search' and many parental control filters. See below for router based considerations and solutions.Filtering that occurs outside of the individuals computer (such as at the router) cannot be bypassed using the above methods (except for 'Incognito/InPrivate' modes). However,\n\nThe major search engines cache and serve content on their own servers. As a result, domain filters such as many third party DNS servers, also fail to filter the 'Incognito/InPrivate' with 'image' tab.\nMost commercially available routers with parental controls do not enforce safe search at the router, and therefore do not filter the 'Incognito/InPrivate' with 'image' tab.\n\n== Criticism ==\nWhile parental controls have been added to various electronic mediums and have increased in popularity, the question has been raised if they are enough to protect and deter children from exposure to inappropriate material. It has been speculated by researchers that the strict focus on control may hinder a child's ability to learn self-governing skills and restricting the growth of open communication between parent and child.\n\n== Video game systems that have used parental controls ==\nPlayStation 5\nPlayStation 4\nPlayStation 3\nPlayStation 2 (only for DVDs)\nPlayStation Vita\nPlayStation Portable\nXbox (console)\nXbox 360\nXbox One\nXbox Series X and Series S\nNintendo DSi\nNintendo 3DS\nNintendo Switch\nWii\nWii U\nGameStick\nNintendo DS\n\n== Operating systems with parental controls ==\nBelow is a list of popular operating systems which currently have built-in parental control features:\n\nAndroid operating system\niOS (12 or later)\nMac OS X (10.3 and later)\ndoudoulinux (built-in web filter)\nsabily (built-in web filter)\nUbuntu Christian edition (built-in web filter)\nWindows (Vista, 7, 10 and later)\nChromeOS (65 or later)\nQuestion: What are usage controls in parental controls and how do they work?. Whats the answer?",
    "context": "",
    "output": "Usage controls in parental controls are features that constrain the usage of digital devices such as placing time-limits on usage, forbidding certain types of usage, restricting volume output, or turning devices off during specific times of the day. They work by setting limits on the device's functionality or access to specific features based on predefined criteria.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What are usage controls in parental controls and how do they work?",
      "answer": "Usage controls in parental controls are features that constrain the usage of digital devices such as placing time-limits on usage, forbidding certain types of usage, restricting volume output, or turning devices off during specific times of the day. They work by setting limits on the device's functionality or access to specific features based on predefined criteria.",
      "context": "Parental controls\n\n==Introduction==\nParental controls are features which may be included in digital television services, computers and video games, mobile devices and software that allow parents to restrict the access of content to their children. These controls were created to assist parents in their ability to restrict certain content viewable by their children. This may be content they deem inappropriate for their age, maturity level or feel is aimed more at an adult audience. Parental controls fall into roughly four categories: content filters, which limit access to age inappropriate content; usage controls, which constrain the usage of these devices such as placing time-limits on usage or forbidding certain types of usage; computer usage management tools, which enforces the use of certain software; and monitoring, which can track location and activity when using the devices.Content filters were the first popular type of parental controls to limit access to Internet content. Television stations also began to introduce V-Chip technology to limit access to television content. Modern usage controls are able to restrict a range of explicit content such as explicit songs and movies. They are also able to turn devices off during specific times of the day, limiting the volume output of devices, and with GPS technology becoming affordable, it is now possible to easily locate devices such as mobile phones. UNICEF emphases the responsibility of parents and teachers in this role.The demand for parental control methods that restrict content has increased over the decades due to the rising availability of the Internet. A 2014 ICM survey showed that almost a quarter of people under the age of 12 had been exposed to online pornography. Restricting especially helps in cases when children are exposed to inappropriate content by accident. Monitoring may be effective for lessening acts of cyberbullying within the internet. It is unclear whether parental controls will affect online harassment in children, as little is known about the role the family plays in protecting children from undesirable experiences online. Psychologically, cyberbullying could be more harmful to the victim than traditional bullying. Studies done in the past have shown that about 75% of adolescents were subjected to cyberbullying. A lack of parental controls in the household could enable kids to be a part of cyberbullying or be the victim of cyberbullying.\n\n\n\n== Overview ==\nBehavioral control consists of controlling the amount of time a child spends online, or how much the child can view. Psychological control involves parents trying to influence children's behavior.Several techniques exist for creating parental controls for blocking websites. Add-on parental control software may monitor API in order to observe applications such as a web browser or Internet chat application and to intervene according to certain criteria, such as a match in a database of banned words. Virtually all parental control software includes a password or other form of authentication to prevent unauthorized users from disabling it.\nTechniques involving a proxy server are also used. A web browser is set to send requests for web content to the proxy server rather than directly to the web server intended. The proxy server then fetches the web page from the server on the browser's behalf and passes on the content to the browser. Proxy servers can inspect the data being sent and received and intervene depending on various criteria relating to content of the page or the URL being requested, for example, using a database of banned words or banned URLs. The proxy method's major disadvantage is that it requires that the client application to be configured to utilize the proxy, and if it is possible for the user to reconfigure applications to access the Internet directly rather than going through the proxy, then this control is easily bypassed. Proxy servers themselves may be used to circumvent parental controls. There are other techniques used to bypass parental controls.\nThe computer usage management method, unlike content filters, is focused on empowering the parents to balance the computing environment for children by regulating gaming. The main idea of these applications is to allow parents to introduce a learning component into the computing time of children, who must earn gaming time while working through educational contents.\nLately network-based parental control devices have emerged. These devices working as a firewall router use packet filtering, DNS Response Policy Zone (RPZ) and Deep packet inspection (DPI) methods to block inappropriate web content. These methods have been used in commercial and governmental communication networks. Another form of these devices made for home networks has been developed. These devices plug into the home router and create a new wireless network, which is specifically designed for kids to connect to.\n\n== Parental controls on mobile devices ==\nThe increased use of mobile devices that include full featured internet browsers and downloadable applications has created a demand for parental controls on these devices. Some examples of mobile devices that contain parental controls include cell phones, tablets, and e-readers. In November 2007, Verizon was the first carrier to offer age-appropriate content filters as well as the first to offer generic content filters, recognizing that mobile devices were used to access all manner of content from movies and music to short-code programs and websites. In June 2009, in iPhone OS 3.0, Apple was the first company to provide a built-in mechanism on mobile devices to create age brackets for users that would block unwanted applications from being downloaded to the device. In the following years, the developers of all major operating systems have presented in-built tools for parental control, including Linux, Android, Windows, and even the more business-oriented platform Blackberry. There are also applications that allow parents to monitor real-time conversations on their children's phone via access to text messages, browser history, and application history. An example of one of these is Trend Micro which not only offers protection from viruses, but also offers parental controls to phones and tablets of almost all brands. Most of these offer the ability to add extra features to parental controls. These apps have the features mobile devices already have, but have additional features such as, being able to monitor and filter texts/calls, protection while surfing the web, and denied access to specific websites. Applications of this sort have created a rising competition in their market.Mobile device software enables parents to restrict which applications their child can access while also allowing parents to monitor text messages, phone logs, MMS pictures, and other transactions occurring on their child's mobile device; to enable parents to set a time limit on the usage of mobile devices; and to track the exact location of their children as well as monitor calls and the content of texts. This software also allows parents to monitor social media accounts. Parents are able to view posts, pictures, and any interactions in real time. Another function of this software is to keep track of bullying.Most internet service providers offer no-cost filtering options to limit internet browsing options and block unsuitable content. Implementing parental controls and discussing internet safety are useful steps to protect children from inappropriate information.Although parental controls can protect children, they also come with some negative factors. Children's anxiety may increase due to parental controls. In extreme cases, a child may become so angry that they destroy their device, defeating the purpose of parental controls entirely. In that case, it might be a better idea to forgo installing parental controls.\n\n== Methods to bypass parental controls ==\nSeveral methods of bypassing parental controls can be used.\n\nIf the filtering software is located locally within the computer, all Internet software can be easily bypassed by booting up the computer in question from alternative media, with an alternative operating system or (on Windows) in Safe Mode. However, if the computer's BIOS is configured to disallow booting from removable media, and if changes to the BIOS are prohibited without proper authentication, then booting into an alternative operating system is not available without circumventing BIOS security by partially disassembling the computer and resetting BIOS configuration using a button or jumper, or removing and replacing the internal button cell battery.\nUsing external proxy servers or other servers. The user sends requests to the external server which retrieves content on the user's behalf. Filtering software may then never be able to know which URLs the user is accessing, as all communications are with the one external server and filtering software never sees any communications with the web servers from which content really originated. To counter this, filtering software may also block access to popular proxies. Additionally, filtering systems which only permit access to a set of allowed URLs (whitelisting) will not permit access anything outside this list, including proxy servers.\nResetting passwords using exploits\nModifying the software's files\nBrute-force attacks on software passwords'Incognito/InPrivate' modes with the 'image' tab: Users, parental control software, and parental control routers may use 'safe search' (SafeSearch) to enforce filtering at most major search engines. However, in most browsers a user may select 'Incognito' or 'InPrivate' browsing, enter search terms for content, and select the 'image' tab to effectively bypass 'safe search' and many parental control filters. See below for router based considerations and solutions.Filtering that occurs outside of the individuals computer (such as at the router) cannot be bypassed using the above methods (except for 'Incognito/InPrivate' modes). However,\n\nThe major search engines cache and serve content on their own servers. As a result, domain filters such as many third party DNS servers, also fail to filter the 'Incognito/InPrivate' with 'image' tab.\nMost commercially available routers with parental controls do not enforce safe search at the router, and therefore do not filter the 'Incognito/InPrivate' with 'image' tab.\n\n== Criticism ==\nWhile parental controls have been added to various electronic mediums and have increased in popularity, the question has been raised if they are enough to protect and deter children from exposure to inappropriate material. It has been speculated by researchers that the strict focus on control may hinder a child's ability to learn self-governing skills and restricting the growth of open communication between parent and child.\n\n== Video game systems that have used parental controls ==\nPlayStation 5\nPlayStation 4\nPlayStation 3\nPlayStation 2 (only for DVDs)\nPlayStation Vita\nPlayStation Portable\nXbox (console)\nXbox 360\nXbox One\nXbox Series X and Series S\nNintendo DSi\nNintendo 3DS\nNintendo Switch\nWii\nWii U\nGameStick\nNintendo DS\n\n== Operating systems with parental controls ==\nBelow is a list of popular operating systems which currently have built-in parental control features:\n\nAndroid operating system\niOS (12 or later)\nMac OS X (10.3 and later)\ndoudoulinux (built-in web filter)\nsabily (built-in web filter)\nUbuntu Christian edition (built-in web filter)\nWindows (Vista, 7, 10 and later)\nChromeOS (65 or later)"
    }
  },
  {
    "instruction": "The Global challenge is a procedure in CAVE-based authentication that requires any MS attempting to access the serving network to respond to a common challenge value being broadcast in the overhead message train. The MS must generate an authentication signature response (AUTHR) using CAVE with inputs of the global challenge value, ESN, either the last six dialed digits (for an origination attempt) or IMSI_S1 (for any other system access attempt), and SSD_A.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the Global challenge in CAVE-based authentication and how is it performed?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the Global challenge in CAVE-based authentication and how is it performed?",
      "answer": "The Global challenge is a procedure in CAVE-based authentication that requires any MS attempting to access the serving network to respond to a common challenge value being broadcast in the overhead message train. The MS must generate an authentication signature response (AUTHR) using CAVE with inputs of the global challenge value, ESN, either the last six dialed digits (for an origination attempt) or IMSI_S1 (for any other system access attempt), and SSD_A."
    }
  },
  {
    "instruction": "The U.S. government categorizes critical infrastructure into different sectors based on their organizational responsibilities and economic impact. These sectors include banking and finance, transportation, power, information and communications, federal and municipal services, emergency services, fire departments, law enforcement agencies, public works, agriculture and food, and national monuments and icons.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does the U.S. government categorize critical infrastructure into different sectors?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does the U.S. government categorize critical infrastructure into different sectors?",
      "answer": "The U.S. government categorizes critical infrastructure into different sectors based on their organizational responsibilities and economic impact. These sectors include banking and finance, transportation, power, information and communications, federal and municipal services, emergency services, fire departments, law enforcement agencies, public works, agriculture and food, and national monuments and icons."
    }
  },
  {
    "instruction": "The purpose of using COTS software packages for software security assurance activities is to support these activities and ensure the security of the software.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the purpose of using commercial off-the-shelf (COTS) software packages for software security assurance activities?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the purpose of using commercial off-the-shelf (COTS) software packages for software security assurance activities?",
      "answer": "The purpose of using COTS software packages for software security assurance activities is to support these activities and ensure the security of the software."
    }
  },
  {
    "instruction": "OutGuess supports image files in the common Netpbm and JPEG formats.\n\nWrite a question about the text above.",
    "context": "",
    "output": "Which image file formats does OutGuess support for hiding data?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "Which image file formats does OutGuess support for hiding data?",
      "answer": "OutGuess supports image files in the common Netpbm and JPEG formats."
    }
  },
  {
    "instruction": "Alice and Bob are fictional characters commonly used in discussions about cryptographic systems and protocols. They represent two parties involved in a cryptographic scenario, such as sending a private message. The use of these names helps to make the scenarios easier to understand and describe.\n\nWrite a question about the text above.",
    "context": "",
    "output": "Can you explain the role of Alice and Bob in the context of cryptographic systems and protocols?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "Can you explain the role of Alice and Bob in the context of cryptographic systems and protocols?",
      "answer": "Alice and Bob are fictional characters commonly used in discussions about cryptographic systems and protocols. They represent two parties involved in a cryptographic scenario, such as sending a private message. The use of these names helps to make the scenarios easier to understand and describe."
    }
  },
  {
    "instruction": "The Anti-Sec movement started Doxing police officers in April 2015 as part of their reappearance and in relation to an Anonymous operation, hacking into the Madison Police Department's database and releasing officers' personal data.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What prompted the Anti-Sec movement to start Doxing police officers in April 2015?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What prompted the Anti-Sec movement to start Doxing police officers in April 2015?",
      "answer": "The Anti-Sec movement started Doxing police officers in April 2015 as part of their reappearance and in relation to an Anonymous operation, hacking into the Madison Police Department's database and releasing officers' personal data."
    }
  },
  {
    "instruction": "DNS hijacking by ISPs can interfere with the operation of DNSBL anti-spam solutions, as these solutions rely on DNS.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does DNS hijacking by ISPs affect DNSBL anti-spam solutions?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does DNS hijacking by ISPs affect DNSBL anti-spam solutions?",
      "answer": "DNS hijacking by ISPs can interfere with the operation of DNSBL anti-spam solutions, as these solutions rely on DNS."
    }
  },
  {
    "instruction": "Threat (computer)\n\n==Introduction==\nIn computer security, a threat is a potential negative action or event facilitated by a vulnerability that results in an unwanted impact to a computer system or application.\nA threat can be either a negative \"intentional\" event (i.e. hacking: an individual cracker or a criminal organization) or an \"accidental\" negative event (e.g. the possibility of a computer malfunctioning, or the possibility of a natural disaster event such as an earthquake, a fire, or a tornado) or otherwise a circumstance, capability, action, or event.This is differentiated from a threat actor who is an individual or group that can perform the threat action, such as exploiting a vulnerability to actualise a negative impact.\nA more comprehensive definition, tied to an Information assurance point of view, can be found in \"Federal Information Processing Standards (FIPS) 200, Minimum Security Requirements for Federal Information and Information Systems\" by NIST of United States of America\nAny circumstance or event with the potential to adversely impact organizational operations (including mission, functions, image, or reputation), organizational assets, or individuals through an information system via unauthorized access, destruction, disclosure, modification of information, and/or denial of service. Also, the potential for a threat-source to successfully exploit a particular information system vulnerability.National Information Assurance Glossary defines threat as:\n\nAny circumstance or event with the potential to adversely impact an IS through unauthorized access, destruction, disclosure, modification of data, and/or denial of service.ENISA gives a similar definition:\nAny circumstance or event with the potential to adversely impact an asset [G.3] through unauthorized access, destruction, disclosure, modification of data, and/or denial of service.The Open Group defines threat as:\nAnything that is capable of acting in a manner resulting in harm to an asset and/or organization; for example, acts of God (weather, geological events,etc.); malicious actors; errors; failures.Factor analysis of information risk defines threat  as:\nthreats are anything (e.g., object, substance, human, etc.) that are capable of acting against an asset in a manner that can result in harm. A tornado is a threat, as is a flood, as is a hacker. The key consideration is that threats apply the force (water, wind, exploit code, etc.) against an asset that can cause a loss event to occur.National Information Assurance Training and Education Center gives a more articulated definition of threat:\nThe means through which the ability or intent of a threat agent to adversely affect an automated system, facility, or operation can be manifest. Categorize and classify threats as follows: Categories Classes Human Intentional Unintentional Environmental Natural Fabricated 2. Any circumstance or event with the potential to cause harm to a system in the form of destruction, disclosure, modification or data, and/or denial of service.  3. Any circumstance or event with the potential to cause harm to the ADP system or activity in the form of destruction, disclosure, and modification of data, or denial of service. A threat is a potential for harm. The presence of a threat does not mean that it will necessarily cause actual harm. Threats exist because of the very existence of the system or activity and not because of any specific weakness. For example, the threat of fire exists at all facilities regardless of the amount of fire protection available.  4. Types of computer systems related adverse events (i. e. , perils) that may result in losses. Examples are flooding, sabotage and fraud.  5. An assertion primarily concerning entities of the external environment (agents); we say that an agent (or class of agents) poses a threat to one or more assets; we write: T(e;i) where: e is an external entity; i is an internal entity or an empty set. 6. An undesirable occurrence that might be anticipated but is not the result of a conscious act or decision. In threat analysis, a threat is defined as an ordered pair, <peril; asset category>, suggesting the nature of these occurrences but not the details (details are specific to events).  7. The potential violation of security. 8. A set of properties of a specific external entity (which may be either an individual or class of entities) that, in union with a set of properties of a specific internal entity, implies a risk (according to a body of knowledge).g\n\n== Phenomenology ==\nThe term \"threat\" relates to some other basic security terms as shown in the following diagram:\n      + - - - - - - - - - - - - +  + - - - - +  + - - - - - - - - - - -+\n      | An Attack:              |  |Counter- |  | A System Resource:   |\n      | i.e., A Threat Action   |  | measure |  | Target of the Attack |\n      | +----------+            |  |         |  | +-----------------+  |\n      | | Attacker |<\n\n==================||<=========                 |  |\n      | |   i.e.,  |   Passive  |  |         |  | |  Vulnerability  |  |\n      | | A Threat |<\n\n=================>||<========>                 |  |\n      | |  Agent   |  or Active |  |         |  | +-------|||-------+  |\n      | +----------+   Attack   |  |         |  |         VVV          |\n      |                         |  |         |  | Threat Consequences  |\n      + - - - - - - - - - - - - +  + - - - - +  + - - - - - - - - - - -+\n\nA resource (both physical or logical) can have one or more vulnerabilities that can be exploited by a threat agent in a threat action. The result can potentially compromise the confidentiality, integrity or availability properties of resources (potentially different than the vulnerable one) of the organization and others involved parties (customers, suppliers).\nThe so-called CIA triad is the basis of information security.\nThe attack can be active when it attempts to alter system resources or affect their operation: so it compromises Integrity or Availability. A \"passive attack\" attempts to learn or make use of information from the system but does not affect system resources: so it compromises Confidentiality.\n\nOWASP (see figure) depicts the same phenomenon in slightly different terms: a threat agent through an attack vector exploits a weakness (vulnerability) of the system and the related security controls causing a technical impact on an IT resource (asset) connected to a business impact.\nA set of policies concerned with information security management, the Information security management systems (ISMS), has been developed to manage, according to risk management principles, the countermeasures in order to accomplish to a security strategy set up following rules and regulations applicable in a country. Countermeasures are also called security controls; when applied to the transmission of information are named security services.The overall picture represents the risk factors of the risk scenario.The widespread of computer dependencies and the consequent raising of the consequence of a successful attack, led to a new term cyberwarfare.\nNowadays the many real attacks exploit Psychology at least as much as technology. Phishing and Pretexting and other methods are called social engineering techniques. The Web 2.0 applications, specifically Social network services, can be a mean to get in touch with people in charge of system administration or even system security, inducing them to reveal sensitive information. One famous case is Robin Sage.The most widespread documentation on computer insecurity is about technical threats such as a computer virus, trojan and other malware, but a serious study to apply cost effective countermeasures can only be conducted following a rigorous IT risk analysis in the framework of an ISMS: a pure technical approach will let out the psychological attacks that are increasing threats.\n\n== Threats classification ==\nThreats can be classified according to their type and origin:\nTypes of threats:\nPhysical damage: fire, water, pollution\nNatural events: climatic, seismic, volcanic\nLoss of essential services: electrical power, air conditioning, telecommunication\nCompromise of information: eavesdropping, theft of media, retrieval of discarded materials\nTechnical failures: equipment, software, capacity saturation\nCompromise of functions: error in use, abuse of rights, denial of actionsNote that a threat type can have multiple origins.\n\nDeliberate: aiming at information asset\nspying\nillegal processing of data\nAccidental\nequipment failure\nsoftware failure\nEnvironmental\nnatural event\nloss of power supply\nNegligence: Known but neglected factors, compromising the network safety and sustainability\n\n== Threats Trends ==\nRecent trends in computer threats show an increase in ransomware attacks, supply chain attacks, and fileless malware. Ransomware attacks involve the encryption of a victim's files and a demand for payment to restore access. Supply chain attacks target the weakest links in a supply chain to gain access to high-value targets. Fileless malware attacks use techniques that allow malware to run in memory, making it difficult to detect.\n\n\n*** Common Threats ***\nBelow are the few common emerging threats:- \n\u25cf      Computer viruses\n\u25cf      Trojan horses\n\u25cf      Worms\n\u25cf      Rootkits\n\u25cf      Spyware\n\u25cf      Adware\n\u25cf      Ransomware\n\u25cf      Fileless malware\n\n== Threat classification ==\nMicrosoft published a mnemonic, STRIDE, from the initials of threat groups:\n\nSpoofing of user identity\nTampering\nRepudiation\nInformation disclosure (privacy breach or Data leak)\nDenial of Service (D.o.S.)\nElevation of privilegeMicrosoft previously rated the risk of security threats using five categories in a classification called DREAD: Risk assessment model. The model is considered obsolete by Microsoft.\nThe categories were:\n\nDamage \u2013 how bad would an attack be?\nReproducibility \u2013 how easy it is to reproduce the attack?\nExploitability \u2013 how much work is it to launch the attack?\nAffected users \u2013 how many people will be impacted?\nDiscoverability \u2013 how easy it is to discover the threat?The DREAD name comes from the initials of the five categories listed.\nThe spread over a network of threats can lead to dangerous situations. In military and civil fields, threat level has been defined: for example INFOCON is a threat level used by the US. Leading antivirus software vendors publish global threat level on their websites.\n\n== Associated terms ==\n\n\n*** Threat agents or actors ***\nThe term Threat Agent is used to indicate an individual or group that can manifest a threat. It is fundamental to identify who would want to exploit the assets of a company, and how they might use them against the company.\nIndividuals within a threat population; Practically anyone and anything can, under the right circumstances, be a threat agent \u2013 the well-intentioned, but inept, computer operator who trashes a daily batch job by typing the wrong command, the regulator performing an audit, or the squirrel that chews through a data cable.\nThreat agents can take one or more of the following actions against an asset:\nAccess \u2013 simple unauthorized access\nMisuse \u2013 unauthorized use of assets (e.g., identity theft, setting up a porn distribution service on a compromised server, etc.)\nDisclose \u2013 the threat agent illicitly discloses sensitive information\nModify \u2013 unauthorized changes to an asset\nDeny access \u2013 includes destruction, theft of a non-data asset, etc.It is important to recognize that each of these actions affects different assets differently, which drives the degree and nature of loss. For example, the potential for productivity loss resulting from a destroyed or stolen asset depends upon how critical that asset is to the organization's productivity. If a critical asset is simply illicitly accessed, there is no direct productivity loss. Similarly, the destruction of a highly sensitive asset that does not play a critical role in productivity would not directly result in a significant productivity loss. Yet that same asset, if disclosed, can result in significant loss of competitive advantage or reputation, and generate legal costs. The point is that it is the combination of the asset and type of action against the asset that determines the fundamental nature and degree of loss. Which action(s) a threat agent takes will be driven primarily by that agent's motive (e.g., financial gain, revenge, recreation, etc.) and the nature of the asset. For example, a threat agent bent on financial gain is less likely to destroy a critical server than they are to steal an easily pwned asset like a laptop.It is important to separate the concept of the event that a threat agent get in contact with the asset (even virtually, i.e. through the network) and the event that a threat agent act against the asset.OWASP collects a list of potential threat agents to prevent system designers, and programmers insert vulnerabilities in the software.Threat Agent\n\n== Threat management ==\nThreats should be managed by operating an ISMS, performing all the IT risk management activities foreseen by laws, standards and methodologies.\nVery large organizations tend to adopt business continuity management plans in order to protect, maintain and recover business-critical processes and systems. Some of these plans foreseen to set up computer security incident response team (CSIRT) or computer emergency response team (CERT)\nThere is some kind of verification of the threat management process:\n\nInformation security audit\nPenetration testMost organizations perform a subset of these steps, adopting countermeasures based on a non-systematic approach: computer insecurity studies the battlefield of computer security exploits and defences that results.\nInformation security awareness is a significant market (see category:Computer security companies). There has been a lot of software developed to deal with IT threats, including both open-source software (see category:free security software) and proprietary software (see category:computer security software companies for a partial list).\n\n\n*** Cyber threat management ***\nThreat management involves a wide variety of threats including physical threats like flood and fire. While ISMS risk assessment process does incorporate threat management for cyber threats such as remote buffer overflows the risk assessment process doesn't include processes such as threat intelligence management or response procedures.\nCyber threat management (CTM) is emerging as the best practice for managing cyber threats beyond the basic risk assessment found in ISMS. It enables early identification of threats, data-driven situational awareness, accurate decision-making, and timely threat mitigating actions.CTM includes:\n\nManual and automated intelligence gathering and threat analytics\nComprehensive methodology for real-time monitoring including advanced techniques such as behavioural modelling\nUse of advanced analytics to optimize intelligence, generate security intelligence, and provide Situational Awareness\nTechnology and skilled people leveraging situational awareness to enable rapid decisions and automated or manual actions\n\n== Threat hunting ==\nCyber threat hunting is \"the process of proactively and iteratively searching through networks to detect and isolate advanced threats that evade existing security solutions.\" This is in contrast to traditional threat management measures, such as firewalls intrusion detection systems, and SIEMs, which typically involve an investigation after there has been a warning of a potential threat, or an incident has occurred.\nThreat hunting can be a manual process, in which a security analyst sifts through various data information using their knowledge and familiarity with the network to create hypotheses about potential threats. To be even more effective and efficient, however, threat hunting can be partially automated, or machine-assisted, as well. In this case, the analyst utilizes software that harnesses machine learning and user and entity behaviour analytics (UEBA) to inform the analyst of potential risks. The analyst then investigates these potential risks, tracking suspicious behaviour in the network. Thus hunting is an iterative process, meaning that it must be continuously carried out in a loop, beginning with a hypothesis. There are three types of hypotheses: \n\nAnalytics-driven: \"Machine-learning and UEBA, used to develop aggregated risk scores that can also serve as hunting hypotheses\"\nSituational-awareness driven: \"Crown Jewel analysis, enterprise risk assessments, company- or employee-level trends\"\nIntelligence-driven: \"Threat intelligence reports, threat intelligence feeds, malware analysis, vulnerability scans\"The analyst researches their hypothesis by going through vast amounts of data about the network. The results are then stored so that they can be used to improve the automated portion of the detection system and to serve as a foundation for future hypotheses.\nThe SANS Institute has conducted research and surveys on the effectiveness of threat hunting to track and disrupt cyber adversaries as early in their process as possible. According to a survey performed in 2019, \"61% [of the respondents] report at least an 11% measurable improvement in their overall security posture\" and 23.6% of the respondents have experienced a 'significant improvement' in reducing the dwell time.\n\n== Threat Mitigation ==\nTo protect yourself from computer threats, it's essential to keep your software up-to-date, use strong and unique passwords, and be cautious when clicking on links or downloading attachments. Additionally, using antivirus software and regularly backing up your data can help mitigate the impact of a threat.\n\nAnswer this question \"How can threat classification help in managing threats?\" using the text above.",
    "context": "",
    "output": "Threat classification can help organizations prioritize and address threats based on their type and origin, and can also help in the development of appropriate countermeasures.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How can threat classification help in managing threats?",
      "answer": "Threat classification can help organizations prioritize and address threats based on their type and origin, and can also help in the development of appropriate countermeasures.",
      "context": "Threat (computer)\n\n==Introduction==\nIn computer security, a threat is a potential negative action or event facilitated by a vulnerability that results in an unwanted impact to a computer system or application.\nA threat can be either a negative \"intentional\" event (i.e. hacking: an individual cracker or a criminal organization) or an \"accidental\" negative event (e.g. the possibility of a computer malfunctioning, or the possibility of a natural disaster event such as an earthquake, a fire, or a tornado) or otherwise a circumstance, capability, action, or event.This is differentiated from a threat actor who is an individual or group that can perform the threat action, such as exploiting a vulnerability to actualise a negative impact.\nA more comprehensive definition, tied to an Information assurance point of view, can be found in \"Federal Information Processing Standards (FIPS) 200, Minimum Security Requirements for Federal Information and Information Systems\" by NIST of United States of America\nAny circumstance or event with the potential to adversely impact organizational operations (including mission, functions, image, or reputation), organizational assets, or individuals through an information system via unauthorized access, destruction, disclosure, modification of information, and/or denial of service. Also, the potential for a threat-source to successfully exploit a particular information system vulnerability.National Information Assurance Glossary defines threat as:\n\nAny circumstance or event with the potential to adversely impact an IS through unauthorized access, destruction, disclosure, modification of data, and/or denial of service.ENISA gives a similar definition:\nAny circumstance or event with the potential to adversely impact an asset [G.3] through unauthorized access, destruction, disclosure, modification of data, and/or denial of service.The Open Group defines threat as:\nAnything that is capable of acting in a manner resulting in harm to an asset and/or organization; for example, acts of God (weather, geological events,etc.); malicious actors; errors; failures.Factor analysis of information risk defines threat  as:\nthreats are anything (e.g., object, substance, human, etc.) that are capable of acting against an asset in a manner that can result in harm. A tornado is a threat, as is a flood, as is a hacker. The key consideration is that threats apply the force (water, wind, exploit code, etc.) against an asset that can cause a loss event to occur.National Information Assurance Training and Education Center gives a more articulated definition of threat:\nThe means through which the ability or intent of a threat agent to adversely affect an automated system, facility, or operation can be manifest. Categorize and classify threats as follows: Categories Classes Human Intentional Unintentional Environmental Natural Fabricated 2. Any circumstance or event with the potential to cause harm to a system in the form of destruction, disclosure, modification or data, and/or denial of service.  3. Any circumstance or event with the potential to cause harm to the ADP system or activity in the form of destruction, disclosure, and modification of data, or denial of service. A threat is a potential for harm. The presence of a threat does not mean that it will necessarily cause actual harm. Threats exist because of the very existence of the system or activity and not because of any specific weakness. For example, the threat of fire exists at all facilities regardless of the amount of fire protection available.  4. Types of computer systems related adverse events (i. e. , perils) that may result in losses. Examples are flooding, sabotage and fraud.  5. An assertion primarily concerning entities of the external environment (agents); we say that an agent (or class of agents) poses a threat to one or more assets; we write: T(e;i) where: e is an external entity; i is an internal entity or an empty set. 6. An undesirable occurrence that might be anticipated but is not the result of a conscious act or decision. In threat analysis, a threat is defined as an ordered pair, <peril; asset category>, suggesting the nature of these occurrences but not the details (details are specific to events).  7. The potential violation of security. 8. A set of properties of a specific external entity (which may be either an individual or class of entities) that, in union with a set of properties of a specific internal entity, implies a risk (according to a body of knowledge).g\n\n== Phenomenology ==\nThe term \"threat\" relates to some other basic security terms as shown in the following diagram:\n      + - - - - - - - - - - - - +  + - - - - +  + - - - - - - - - - - -+\n      | An Attack:              |  |Counter- |  | A System Resource:   |\n      | i.e., A Threat Action   |  | measure |  | Target of the Attack |\n      | +----------+            |  |         |  | +-----------------+  |\n      | | Attacker |<\n\n==================||<=========                 |  |\n      | |   i.e.,  |   Passive  |  |         |  | |  Vulnerability  |  |\n      | | A Threat |<\n\n=================>||<========>                 |  |\n      | |  Agent   |  or Active |  |         |  | +-------|||-------+  |\n      | +----------+   Attack   |  |         |  |         VVV          |\n      |                         |  |         |  | Threat Consequences  |\n      + - - - - - - - - - - - - +  + - - - - +  + - - - - - - - - - - -+\n\nA resource (both physical or logical) can have one or more vulnerabilities that can be exploited by a threat agent in a threat action. The result can potentially compromise the confidentiality, integrity or availability properties of resources (potentially different than the vulnerable one) of the organization and others involved parties (customers, suppliers).\nThe so-called CIA triad is the basis of information security.\nThe attack can be active when it attempts to alter system resources or affect their operation: so it compromises Integrity or Availability. A \"passive attack\" attempts to learn or make use of information from the system but does not affect system resources: so it compromises Confidentiality.\n\nOWASP (see figure) depicts the same phenomenon in slightly different terms: a threat agent through an attack vector exploits a weakness (vulnerability) of the system and the related security controls causing a technical impact on an IT resource (asset) connected to a business impact.\nA set of policies concerned with information security management, the Information security management systems (ISMS), has been developed to manage, according to risk management principles, the countermeasures in order to accomplish to a security strategy set up following rules and regulations applicable in a country. Countermeasures are also called security controls; when applied to the transmission of information are named security services.The overall picture represents the risk factors of the risk scenario.The widespread of computer dependencies and the consequent raising of the consequence of a successful attack, led to a new term cyberwarfare.\nNowadays the many real attacks exploit Psychology at least as much as technology. Phishing and Pretexting and other methods are called social engineering techniques. The Web 2.0 applications, specifically Social network services, can be a mean to get in touch with people in charge of system administration or even system security, inducing them to reveal sensitive information. One famous case is Robin Sage.The most widespread documentation on computer insecurity is about technical threats such as a computer virus, trojan and other malware, but a serious study to apply cost effective countermeasures can only be conducted following a rigorous IT risk analysis in the framework of an ISMS: a pure technical approach will let out the psychological attacks that are increasing threats.\n\n== Threats classification ==\nThreats can be classified according to their type and origin:\nTypes of threats:\nPhysical damage: fire, water, pollution\nNatural events: climatic, seismic, volcanic\nLoss of essential services: electrical power, air conditioning, telecommunication\nCompromise of information: eavesdropping, theft of media, retrieval of discarded materials\nTechnical failures: equipment, software, capacity saturation\nCompromise of functions: error in use, abuse of rights, denial of actionsNote that a threat type can have multiple origins.\n\nDeliberate: aiming at information asset\nspying\nillegal processing of data\nAccidental\nequipment failure\nsoftware failure\nEnvironmental\nnatural event\nloss of power supply\nNegligence: Known but neglected factors, compromising the network safety and sustainability\n\n== Threats Trends ==\nRecent trends in computer threats show an increase in ransomware attacks, supply chain attacks, and fileless malware. Ransomware attacks involve the encryption of a victim's files and a demand for payment to restore access. Supply chain attacks target the weakest links in a supply chain to gain access to high-value targets. Fileless malware attacks use techniques that allow malware to run in memory, making it difficult to detect.\n\n\n*** Common Threats ***\nBelow are the few common emerging threats:- \n\u25cf      Computer viruses\n\u25cf      Trojan horses\n\u25cf      Worms\n\u25cf      Rootkits\n\u25cf      Spyware\n\u25cf      Adware\n\u25cf      Ransomware\n\u25cf      Fileless malware\n\n== Threat classification ==\nMicrosoft published a mnemonic, STRIDE, from the initials of threat groups:\n\nSpoofing of user identity\nTampering\nRepudiation\nInformation disclosure (privacy breach or Data leak)\nDenial of Service (D.o.S.)\nElevation of privilegeMicrosoft previously rated the risk of security threats using five categories in a classification called DREAD: Risk assessment model. The model is considered obsolete by Microsoft.\nThe categories were:\n\nDamage \u2013 how bad would an attack be?\nReproducibility \u2013 how easy it is to reproduce the attack?\nExploitability \u2013 how much work is it to launch the attack?\nAffected users \u2013 how many people will be impacted?\nDiscoverability \u2013 how easy it is to discover the threat?The DREAD name comes from the initials of the five categories listed.\nThe spread over a network of threats can lead to dangerous situations. In military and civil fields, threat level has been defined: for example INFOCON is a threat level used by the US. Leading antivirus software vendors publish global threat level on their websites.\n\n== Associated terms ==\n\n\n*** Threat agents or actors ***\nThe term Threat Agent is used to indicate an individual or group that can manifest a threat. It is fundamental to identify who would want to exploit the assets of a company, and how they might use them against the company.\nIndividuals within a threat population; Practically anyone and anything can, under the right circumstances, be a threat agent \u2013 the well-intentioned, but inept, computer operator who trashes a daily batch job by typing the wrong command, the regulator performing an audit, or the squirrel that chews through a data cable.\nThreat agents can take one or more of the following actions against an asset:\nAccess \u2013 simple unauthorized access\nMisuse \u2013 unauthorized use of assets (e.g., identity theft, setting up a porn distribution service on a compromised server, etc.)\nDisclose \u2013 the threat agent illicitly discloses sensitive information\nModify \u2013 unauthorized changes to an asset\nDeny access \u2013 includes destruction, theft of a non-data asset, etc.It is important to recognize that each of these actions affects different assets differently, which drives the degree and nature of loss. For example, the potential for productivity loss resulting from a destroyed or stolen asset depends upon how critical that asset is to the organization's productivity. If a critical asset is simply illicitly accessed, there is no direct productivity loss. Similarly, the destruction of a highly sensitive asset that does not play a critical role in productivity would not directly result in a significant productivity loss. Yet that same asset, if disclosed, can result in significant loss of competitive advantage or reputation, and generate legal costs. The point is that it is the combination of the asset and type of action against the asset that determines the fundamental nature and degree of loss. Which action(s) a threat agent takes will be driven primarily by that agent's motive (e.g., financial gain, revenge, recreation, etc.) and the nature of the asset. For example, a threat agent bent on financial gain is less likely to destroy a critical server than they are to steal an easily pwned asset like a laptop.It is important to separate the concept of the event that a threat agent get in contact with the asset (even virtually, i.e. through the network) and the event that a threat agent act against the asset.OWASP collects a list of potential threat agents to prevent system designers, and programmers insert vulnerabilities in the software.Threat Agent\n\n== Threat management ==\nThreats should be managed by operating an ISMS, performing all the IT risk management activities foreseen by laws, standards and methodologies.\nVery large organizations tend to adopt business continuity management plans in order to protect, maintain and recover business-critical processes and systems. Some of these plans foreseen to set up computer security incident response team (CSIRT) or computer emergency response team (CERT)\nThere is some kind of verification of the threat management process:\n\nInformation security audit\nPenetration testMost organizations perform a subset of these steps, adopting countermeasures based on a non-systematic approach: computer insecurity studies the battlefield of computer security exploits and defences that results.\nInformation security awareness is a significant market (see category:Computer security companies). There has been a lot of software developed to deal with IT threats, including both open-source software (see category:free security software) and proprietary software (see category:computer security software companies for a partial list).\n\n\n*** Cyber threat management ***\nThreat management involves a wide variety of threats including physical threats like flood and fire. While ISMS risk assessment process does incorporate threat management for cyber threats such as remote buffer overflows the risk assessment process doesn't include processes such as threat intelligence management or response procedures.\nCyber threat management (CTM) is emerging as the best practice for managing cyber threats beyond the basic risk assessment found in ISMS. It enables early identification of threats, data-driven situational awareness, accurate decision-making, and timely threat mitigating actions.CTM includes:\n\nManual and automated intelligence gathering and threat analytics\nComprehensive methodology for real-time monitoring including advanced techniques such as behavioural modelling\nUse of advanced analytics to optimize intelligence, generate security intelligence, and provide Situational Awareness\nTechnology and skilled people leveraging situational awareness to enable rapid decisions and automated or manual actions\n\n== Threat hunting ==\nCyber threat hunting is \"the process of proactively and iteratively searching through networks to detect and isolate advanced threats that evade existing security solutions.\" This is in contrast to traditional threat management measures, such as firewalls intrusion detection systems, and SIEMs, which typically involve an investigation after there has been a warning of a potential threat, or an incident has occurred.\nThreat hunting can be a manual process, in which a security analyst sifts through various data information using their knowledge and familiarity with the network to create hypotheses about potential threats. To be even more effective and efficient, however, threat hunting can be partially automated, or machine-assisted, as well. In this case, the analyst utilizes software that harnesses machine learning and user and entity behaviour analytics (UEBA) to inform the analyst of potential risks. The analyst then investigates these potential risks, tracking suspicious behaviour in the network. Thus hunting is an iterative process, meaning that it must be continuously carried out in a loop, beginning with a hypothesis. There are three types of hypotheses: \n\nAnalytics-driven: \"Machine-learning and UEBA, used to develop aggregated risk scores that can also serve as hunting hypotheses\"\nSituational-awareness driven: \"Crown Jewel analysis, enterprise risk assessments, company- or employee-level trends\"\nIntelligence-driven: \"Threat intelligence reports, threat intelligence feeds, malware analysis, vulnerability scans\"The analyst researches their hypothesis by going through vast amounts of data about the network. The results are then stored so that they can be used to improve the automated portion of the detection system and to serve as a foundation for future hypotheses.\nThe SANS Institute has conducted research and surveys on the effectiveness of threat hunting to track and disrupt cyber adversaries as early in their process as possible. According to a survey performed in 2019, \"61% [of the respondents] report at least an 11% measurable improvement in their overall security posture\" and 23.6% of the respondents have experienced a 'significant improvement' in reducing the dwell time.\n\n== Threat Mitigation ==\nTo protect yourself from computer threats, it's essential to keep your software up-to-date, use strong and unique passwords, and be cautious when clicking on links or downloading attachments. Additionally, using antivirus software and regularly backing up your data can help mitigate the impact of a threat."
    }
  },
  {
    "instruction": "Norton Community Watch is a voluntary and anonymous service that allows a user's Norton product to forward information to Symantec servers, including the processes running and their SHA256 values. This data is used to create a whitelist of reappearing hash values and their corresponding files, which is then used to exclude matching processes from scanning.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the role of Norton Community Watch in Norton Insight?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the role of Norton Community Watch in Norton Insight?",
      "answer": "Norton Community Watch is a voluntary and anonymous service that allows a user's Norton product to forward information to Symantec servers, including the processes running and their SHA256 values. This data is used to create a whitelist of reappearing hash values and their corresponding files, which is then used to exclude matching processes from scanning."
    }
  },
  {
    "instruction": "The NSA's Condor project focuses on developing secure mobile phones with advanced security features. Unlike standard mobile phones, these devices prioritize secure communication through end-to-end encryption, protecting users' data and conversations from unauthorized access. The NSA's expertise in cybersecurity and surveillance makes the Condor project unique, as the agency can apply its knowledge to counter potential threats and vulnerabilities in mobile communications.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does the NSA ensure the security of mobile phones in the Condor project, and what makes it different from other secure communication methods?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does the NSA ensure the security of mobile phones in the Condor project, and what makes it different from other secure communication methods?",
      "answer": "The NSA's Condor project focuses on developing secure mobile phones with advanced security features. Unlike standard mobile phones, these devices prioritize secure communication through end-to-end encryption, protecting users' data and conversations from unauthorized access. The NSA's expertise in cybersecurity and surveillance makes the Condor project unique, as the agency can apply its knowledge to counter potential threats and vulnerabilities in mobile communications."
    }
  },
  {
    "instruction": "Context: Political repression of cyber-dissidents\n\n==Introduction==\nPolitical repression of cyber-dissidents is the oppression or persecution of people for expressing their political views on the Internet.\nAlong with development of the Internet, state authorities in many parts of the world carry out mass surveillance through electronic communications, establish Internet censorship to limit the flow of information, and persecute individuals and groups who express \"inconvenient\" political views in the Internet. Many cyber-dissidents have found themselves persecuted for attempts to bypass state controlled news media. Reporters Without Borders has released a Handbook For Bloggers and Cyber-Dissidents and maintains a roster of currently imprisoned cyber-dissidents.\n\n\n\n== Iran ==\nMohamad Reza Nasab Abdolahi was imprisoned for publishing an open letter to Ayatollah Ali Khamenei. His pregnant wife and other bloggers who commented on the arrest were also imprisoned.\n\n== Saudi Arabia ==\nRaif Badawi, Saudi Arabian writer and activist and the creator of the website Free Saudi Liberals, has been convicted of crimes including \"setting up a website that undermines general security\" and \"ridiculing Islamic religious figures.\" He was sentenced to seven years in prison and 600 lashes in 2013, then resentenced to 1000 lashes and ten years in prison plus a fine of 1 million riyal (equal to about $267,000). His wife, Ensaf Haidar, asserted that Raif will not be able to survive the flogging.\n\n== Egypt ==\nSeveral bloggers in Egypt have been arrested for allegedly defaming the president Hosni Mubarak or expressing critical views about Islam. Blogger Kareem Amer has been convicted to four years of prison.\n\n== China ==\n\nChinese Communist Party general secretary Hu Jintao ordered to \"maintain the initiative in opinion on the Internet and raise the level of guidance online,\" referring to censorship and ensuring online messages in China toe the party line. China is reported to have \"an internet police force \u2013 reportedly numbering 30,000 \u2013 trawl[ing] websites and chat rooms, erasing anti-Communist comments and posting pro-government messages.\" However, the number of Internet police personnel was challenged by Chinese authorities. Amnesty International blamed several companies, including Google, Microsoft and Yahoo!, of collusion with the Chinese authorities to restrict access to information over the Internet and identify cyber-dissidents by hiring \"big mamas\".It was reported that departments of provincial and municipal governments in mainland China began creating \"teams of internet commentators, whose job is to guide discussion on public bulletin boards away from politically sensitive topics by posting opinions anonymously or under false names\" in 2005. Applicants for the job were drawn mostly from the propaganda and police departments. Successful candidates have been offered classes in Marxism, propaganda techniques, and the Internet. \"They are actually hiring staff to curse online,\" said Liu Di, a Chinese student who was arrested for posting her comments in blogs.Foreign Ministry spokesperson Ma Zhaoxu objected to a question from foreign journalists regarding a cyber-dissident, stating that \"there are no dissidents in China\". Ai Weiwei believes that, by this statement, the government is effectively stating that: all dissidents are criminals, only criminals have dissenting views, anyone who believes China has dissidents is a criminal, and ultimately China does not have any dissidents because they are criminals.\n\n== Russia ==\n\nIn 2006 journalist Vladimir Rakhmankov published an article on the Internet where he named Vladimir Putin \"the nation's phallic symbol\". A regional court found Rakhmankov guilty of offending Vladimir Putin and fined him to a sum of 20,000 roubles (~US$680).In June 2013 a criminal case was opened on opposition blogger Stanislav Kalinichenko for retweeting a photograph of a leaflet reading \"Enough demonstrating\u2014it's time to act!\" signed by a group calling itself the First Resistance Detachment and calling for the destruction of corrupt officials' property. Kalinichenko was charged with Criminal Code 280 (\"calling publicly for extremist acts\"), carrying a 4 years prison sentence. The human rights organization Memorial has characterized the charges as politically motivated.In March 2014, on orders from the Attorney General, the government blocked the blog of opposition leader Alexey Navalny on the grounds that it disseminated extremism. In December 2015 Facebook complied with an order from the Attorney General to block Russian users' access to an event page by organizers of an unsanctioned rally in support of the Navalny brothers. All reposts of the event disappeared from users' walls. In addition, the supervisory body Roskomnadzor ordered a Ukrainian news website to delete a story about the protest.In March 2014 historian Konstantin Zharinov was charged with advocating extremism, after using the \"share with friends\" VKontakte feature on a public appeal by the Ukrainian militant group Right Sector. Zharinov was placed under surveillance, and his participation in anti-war demonstrations and pickets in support of Alexey Navalny featured prominently in the investigation.On 11 March 2022, Belarusian political police GUBOPiK arrested and detained editor of Russian Wikipedia from Minsk Mark Bernstein, who was editing the Wikipedia article about the Russian invasion of Ukraine, accusing him of the \"spread of anti-Russian materials\" and of violating Russian \"fake news\" law.\n\n== Tunisia ==\nLawyer and human rights defender Mohammed Abbou was imprisoned for criticizing torture on a web site.\n\n== Bangladesh ==\nAsif Mohiuddin, a winner of The Bobs-Best of Online Activism award, was imprisoned by the Bangladesh government for posting \"offensive comments about Islam and Mohammed\". Deutsche Welle state \"Asif's blog was one of the most read web pages in Bangladesh and is known for its strong criticism of religious fundamentalism and Bangladesh's 'anti-people politics'\"\nInternational organisations, including Human Rights Watch, Amnesty International, Reporters without Borders and the Committee to Protect Journalists have condemned the imprisonment of bloggers and the climate of fear for journalists.\nThe head of Reporters without Borders Asia-Pacific commented on the murder of writer Avijit Roy noting \"It is unacceptable for [police] to spend so much time searching news outlets, arresting journalists, censoring news and investigating bloggers, when the many attacks on bloggers are still unpunished.\"\n\n== Vietnam ==\nNguyen Vu Binh was imprisoned for writing about violations of human rights, and Truong Quoc Huy was arrested for discussing political reforms in an Internet chat room. Nguyen Vu Binh was released in June 2007.\n\n== Pakistan ==\nIn January 2017, four bloggers known for their anti-religious and pro-democracy activism went missing. Altogether, their disappearances alarmed secular liberals involved in social activism in Pakistan.\n\n== United States ==\nAustralian whistleblower, activist and founder of WikiLeaks Julian Assange became a dissident after publishing secret documents that proved American war crimes in Afghanistan and Iraq.\nQuestion: How have foreign companies been criticized for their role in restricting access to information over the Internet in China?. Whats the answer?",
    "context": "",
    "output": "Foreign companies, including Google, Microsoft, and Yahoo!, have been criticized for colluding with Chinese authorities to restrict access to information over the Internet and identify cyber-dissidents by hiring \"big mamas\". Amnesty International has accused these companies of taking part in these practices, leading to criticism from human rights organizations.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How have foreign companies been criticized for their role in restricting access to information over the Internet in China?",
      "answer": "Foreign companies, including Google, Microsoft, and Yahoo!, have been criticized for colluding with Chinese authorities to restrict access to information over the Internet and identify cyber-dissidents by hiring \"big mamas\". Amnesty International has accused these companies of taking part in these practices, leading to criticism from human rights organizations.",
      "context": "Political repression of cyber-dissidents\n\n==Introduction==\nPolitical repression of cyber-dissidents is the oppression or persecution of people for expressing their political views on the Internet.\nAlong with development of the Internet, state authorities in many parts of the world carry out mass surveillance through electronic communications, establish Internet censorship to limit the flow of information, and persecute individuals and groups who express \"inconvenient\" political views in the Internet. Many cyber-dissidents have found themselves persecuted for attempts to bypass state controlled news media. Reporters Without Borders has released a Handbook For Bloggers and Cyber-Dissidents and maintains a roster of currently imprisoned cyber-dissidents.\n\n\n\n== Iran ==\nMohamad Reza Nasab Abdolahi was imprisoned for publishing an open letter to Ayatollah Ali Khamenei. His pregnant wife and other bloggers who commented on the arrest were also imprisoned.\n\n== Saudi Arabia ==\nRaif Badawi, Saudi Arabian writer and activist and the creator of the website Free Saudi Liberals, has been convicted of crimes including \"setting up a website that undermines general security\" and \"ridiculing Islamic religious figures.\" He was sentenced to seven years in prison and 600 lashes in 2013, then resentenced to 1000 lashes and ten years in prison plus a fine of 1 million riyal (equal to about $267,000). His wife, Ensaf Haidar, asserted that Raif will not be able to survive the flogging.\n\n== Egypt ==\nSeveral bloggers in Egypt have been arrested for allegedly defaming the president Hosni Mubarak or expressing critical views about Islam. Blogger Kareem Amer has been convicted to four years of prison.\n\n== China ==\n\nChinese Communist Party general secretary Hu Jintao ordered to \"maintain the initiative in opinion on the Internet and raise the level of guidance online,\" referring to censorship and ensuring online messages in China toe the party line. China is reported to have \"an internet police force \u2013 reportedly numbering 30,000 \u2013 trawl[ing] websites and chat rooms, erasing anti-Communist comments and posting pro-government messages.\" However, the number of Internet police personnel was challenged by Chinese authorities. Amnesty International blamed several companies, including Google, Microsoft and Yahoo!, of collusion with the Chinese authorities to restrict access to information over the Internet and identify cyber-dissidents by hiring \"big mamas\".It was reported that departments of provincial and municipal governments in mainland China began creating \"teams of internet commentators, whose job is to guide discussion on public bulletin boards away from politically sensitive topics by posting opinions anonymously or under false names\" in 2005. Applicants for the job were drawn mostly from the propaganda and police departments. Successful candidates have been offered classes in Marxism, propaganda techniques, and the Internet. \"They are actually hiring staff to curse online,\" said Liu Di, a Chinese student who was arrested for posting her comments in blogs.Foreign Ministry spokesperson Ma Zhaoxu objected to a question from foreign journalists regarding a cyber-dissident, stating that \"there are no dissidents in China\". Ai Weiwei believes that, by this statement, the government is effectively stating that: all dissidents are criminals, only criminals have dissenting views, anyone who believes China has dissidents is a criminal, and ultimately China does not have any dissidents because they are criminals.\n\n== Russia ==\n\nIn 2006 journalist Vladimir Rakhmankov published an article on the Internet where he named Vladimir Putin \"the nation's phallic symbol\". A regional court found Rakhmankov guilty of offending Vladimir Putin and fined him to a sum of 20,000 roubles (~US$680).In June 2013 a criminal case was opened on opposition blogger Stanislav Kalinichenko for retweeting a photograph of a leaflet reading \"Enough demonstrating\u2014it's time to act!\" signed by a group calling itself the First Resistance Detachment and calling for the destruction of corrupt officials' property. Kalinichenko was charged with Criminal Code 280 (\"calling publicly for extremist acts\"), carrying a 4 years prison sentence. The human rights organization Memorial has characterized the charges as politically motivated.In March 2014, on orders from the Attorney General, the government blocked the blog of opposition leader Alexey Navalny on the grounds that it disseminated extremism. In December 2015 Facebook complied with an order from the Attorney General to block Russian users' access to an event page by organizers of an unsanctioned rally in support of the Navalny brothers. All reposts of the event disappeared from users' walls. In addition, the supervisory body Roskomnadzor ordered a Ukrainian news website to delete a story about the protest.In March 2014 historian Konstantin Zharinov was charged with advocating extremism, after using the \"share with friends\" VKontakte feature on a public appeal by the Ukrainian militant group Right Sector. Zharinov was placed under surveillance, and his participation in anti-war demonstrations and pickets in support of Alexey Navalny featured prominently in the investigation.On 11 March 2022, Belarusian political police GUBOPiK arrested and detained editor of Russian Wikipedia from Minsk Mark Bernstein, who was editing the Wikipedia article about the Russian invasion of Ukraine, accusing him of the \"spread of anti-Russian materials\" and of violating Russian \"fake news\" law.\n\n== Tunisia ==\nLawyer and human rights defender Mohammed Abbou was imprisoned for criticizing torture on a web site.\n\n== Bangladesh ==\nAsif Mohiuddin, a winner of The Bobs-Best of Online Activism award, was imprisoned by the Bangladesh government for posting \"offensive comments about Islam and Mohammed\". Deutsche Welle state \"Asif's blog was one of the most read web pages in Bangladesh and is known for its strong criticism of religious fundamentalism and Bangladesh's 'anti-people politics'\"\nInternational organisations, including Human Rights Watch, Amnesty International, Reporters without Borders and the Committee to Protect Journalists have condemned the imprisonment of bloggers and the climate of fear for journalists.\nThe head of Reporters without Borders Asia-Pacific commented on the murder of writer Avijit Roy noting \"It is unacceptable for [police] to spend so much time searching news outlets, arresting journalists, censoring news and investigating bloggers, when the many attacks on bloggers are still unpunished.\"\n\n== Vietnam ==\nNguyen Vu Binh was imprisoned for writing about violations of human rights, and Truong Quoc Huy was arrested for discussing political reforms in an Internet chat room. Nguyen Vu Binh was released in June 2007.\n\n== Pakistan ==\nIn January 2017, four bloggers known for their anti-religious and pro-democracy activism went missing. Altogether, their disappearances alarmed secular liberals involved in social activism in Pakistan.\n\n== United States ==\nAustralian whistleblower, activist and founder of WikiLeaks Julian Assange became a dissident after publishing secret documents that proved American war crimes in Afghanistan and Iraq."
    }
  },
  {
    "instruction": "Virtual data rooms provide controlled access, digital rights management, and secure log-ons to protect sensitive information and prevent unauthorized access, reducing the risk of data breaches.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How can virtual data rooms help prevent data breaches and protect sensitive information?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How can virtual data rooms help prevent data breaches and protect sensitive information?",
      "answer": "Virtual data rooms provide controlled access, digital rights management, and secure log-ons to protect sensitive information and prevent unauthorized access, reducing the risk of data breaches."
    }
  },
  {
    "instruction": "Fuchsia (operating system)\n\n==Introduction==\nFuchsia is an open-source capability-based operating system developed by Google. In contrast to Google's Linux-based operating systems such as ChromeOS and Android, Fuchsia is based on a custom kernel named Zircon. It publicly debuted as a self-hosted git repository in August 2016 without any official corporate announcement. After years of development, its official product launch was on the first-generation Google Nest Hub, replacing its original Linux-based Cast OS. \n\n\n\n== Etymology ==\nFuchsia is named for the color fuchsia, which is a combination of pink and purple.\n\n== Overview ==\nAs of 2022, most of Fuchsia's code is written in Rust.\n\n\n*** UI and Mobile Apps ***\nFuchsia's user interface and apps are written in Flutter, a software development kit allowing cross-platform development abilities for Fuchsia, Android and iOS. Flutter produces apps from Dart. Escher is the Vulkan-based graphics rendering engine, with specific support for \"volumetric soft shadows\", an element that Ars Technica wrote, \"seems custom-built to run Google's shadow-heavy 'Material Design' interface guidelines\". The Flutter cross-platform software development kit allows users to install parts of Fuchsia on Android devices.\nA special version of Android Runtime for Fuchsia is planned to run from a FAR file, the equivalent of the Android APK.\n\n\n*** Kernel ***\n\nFuchsia is based on a new object-capability kernel, named Zircon after the mineral zircon. Its codebase was derived from that of Little Kernel (LK) for embedded devices, aimed for low resource uses for a wide variety of devices. LK was developed by Travis Geiselbrecht, who had also co-authored the NewOS kernel used by Haiku, a free software reimplementation of BeOS. \nZircon is written mostly in C++, with some parts in C and assembly language. It is composed of a kernel with a small set of user services, drivers, and libraries which are all necessary for the system to boot, communicate with the hardware, and load the user processes. Its present features include handling threads, virtual memory, inter-process communication, and waiting for changes in the state of objects.It is heavily inspired by Unix kernels but differs greatly. For example, it does not support Unix-like signals but incorporates event-driven programming and the observer pattern. Most system calls do not block the main thread. Resources are represented as objects rather than files, unlike traditional Unix systems. Answer this question using the following article:\n\nWhat is the significance of the name Fuchsia?",
    "context": "",
    "output": "Fuchsia is named after the color fuchsia, which is a combination of pink and purple.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the significance of the name Fuchsia?",
      "answer": "Fuchsia is named after the color fuchsia, which is a combination of pink and purple.",
      "context": "Fuchsia (operating system)\n\n==Introduction==\nFuchsia is an open-source capability-based operating system developed by Google. In contrast to Google's Linux-based operating systems such as ChromeOS and Android, Fuchsia is based on a custom kernel named Zircon. It publicly debuted as a self-hosted git repository in August 2016 without any official corporate announcement. After years of development, its official product launch was on the first-generation Google Nest Hub, replacing its original Linux-based Cast OS. \n\n\n\n== Etymology ==\nFuchsia is named for the color fuchsia, which is a combination of pink and purple.\n\n== Overview ==\nAs of 2022, most of Fuchsia's code is written in Rust.\n\n\n*** UI and Mobile Apps ***\nFuchsia's user interface and apps are written in Flutter, a software development kit allowing cross-platform development abilities for Fuchsia, Android and iOS. Flutter produces apps from Dart. Escher is the Vulkan-based graphics rendering engine, with specific support for \"volumetric soft shadows\", an element that Ars Technica wrote, \"seems custom-built to run Google's shadow-heavy 'Material Design' interface guidelines\". The Flutter cross-platform software development kit allows users to install parts of Fuchsia on Android devices.\nA special version of Android Runtime for Fuchsia is planned to run from a FAR file, the equivalent of the Android APK.\n\n\n*** Kernel ***\n\nFuchsia is based on a new object-capability kernel, named Zircon after the mineral zircon. Its codebase was derived from that of Little Kernel (LK) for embedded devices, aimed for low resource uses for a wide variety of devices. LK was developed by Travis Geiselbrecht, who had also co-authored the NewOS kernel used by Haiku, a free software reimplementation of BeOS. \nZircon is written mostly in C++, with some parts in C and assembly language. It is composed of a kernel with a small set of user services, drivers, and libraries which are all necessary for the system to boot, communicate with the hardware, and load the user processes. Its present features include handling threads, virtual memory, inter-process communication, and waiting for changes in the state of objects.It is heavily inspired by Unix kernels but differs greatly. For example, it does not support Unix-like signals but incorporates event-driven programming and the observer pattern. Most system calls do not block the main thread. Resources are represented as objects rather than files, unlike traditional Unix systems."
    }
  },
  {
    "instruction": "Context: Cryptanalytic computer\n\n==Introduction==\nA cryptanalytic computer is a computer designed to be used for cryptanalysis, which nowadays involves massive statistical analysis and multiple trial decryptions that since before World War II  are possible only with automated equipment.  Polish cryptanalysts designed and built automated aids in their work on Enigma traffic. Arguably, the first modern computer (digital, electronic, and somewhat programmable) was built for cryptanalytic work at Bletchley Park (the Colossus) during the war. More modern computers were important after World War II, and some machines (like the Cray-1) are reported to have had machine instructions hardwired in at the request of NSA.\nComputers continue to be important in cryptanalysis well into the 21st century. NSA, in fact, is said to have the largest number of installed computers on the planet. Whether or not this is true in an age of Google computer farms and such is doubtful but remains publicly unknown.\n\n\nQuestion: How have cryptanalytic computers evolved in terms of their capabilities and uses since their inception during World War II?. Whats the answer?",
    "context": "",
    "output": "Cryptanalytic computers have evolved significantly in terms of their capabilities and uses since their inception during World War II. Initially, these computers were primarily used for decrypting enemy communications, such as the Enigma traffic. However, as technology advanced, so too did the capabilities of cryptanalytic computers. Today, these computers are used for a wide range of purposes, including the development of new encryption algorithms, the analysis of large datasets for security vulnerabilities, and the detection of cyber threats. Furthermore, modern cryptanalytic computers are much more powerful and sophisticated than their early predecessors, often featuring advanced hardware and software capabilities that enable them to process vast amounts of data at high speeds.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How have cryptanalytic computers evolved in terms of their capabilities and uses since their inception during World War II?",
      "answer": "Cryptanalytic computers have evolved significantly in terms of their capabilities and uses since their inception during World War II. Initially, these computers were primarily used for decrypting enemy communications, such as the Enigma traffic. However, as technology advanced, so too did the capabilities of cryptanalytic computers. Today, these computers are used for a wide range of purposes, including the development of new encryption algorithms, the analysis of large datasets for security vulnerabilities, and the detection of cyber threats. Furthermore, modern cryptanalytic computers are much more powerful and sophisticated than their early predecessors, often featuring advanced hardware and software capabilities that enable them to process vast amounts of data at high speeds.",
      "context": "Cryptanalytic computer\n\n==Introduction==\nA cryptanalytic computer is a computer designed to be used for cryptanalysis, which nowadays involves massive statistical analysis and multiple trial decryptions that since before World War II  are possible only with automated equipment.  Polish cryptanalysts designed and built automated aids in their work on Enigma traffic. Arguably, the first modern computer (digital, electronic, and somewhat programmable) was built for cryptanalytic work at Bletchley Park (the Colossus) during the war. More modern computers were important after World War II, and some machines (like the Cray-1) are reported to have had machine instructions hardwired in at the request of NSA.\nComputers continue to be important in cryptanalysis well into the 21st century. NSA, in fact, is said to have the largest number of installed computers on the planet. Whether or not this is true in an age of Google computer farms and such is doubtful but remains publicly unknown.\n\n"
    }
  },
  {
    "instruction": "2019 Baltimore ransomware attack\n\n==Introduction==\nDuring the Baltimore ransomware attack of May 2019, the American city of Baltimore, Maryland had its servers largely compromised by a variant of ransomware called RobbinHood. Baltimore became the second U.S. city to fall victim to this new variant of ransomware after Greenville, North Carolina and was the second major US city with a population of over 500,000 people to be hacked by ransomware in two years, after Atlanta was attacked the previous year.\n\n\n\n== Background ==\nBaltimore had been targeted by ransomware once prior to the May 2019 attack in 2018, though that attack was smaller in comparison and took down the city's emergency dispatch system for a short duration. On May 2, just days before the first infection, mayor Catherine Pugh resigned amidst a corruption scandal and was ultimately convicted and sentenced to 3 years in prison. She was replaced by Jack Young.\n\n== Attack ==\nOn May 7, 2019, most of Baltimore's government computer systems were infected with the aggressive ransomware variant RobbinHood. All servers, with the exception of essential services, were taken offline. In a ransom note, hackers demanded 13 bitcoin (roughly $76,280) in exchange for keys to restore access. The note stated that if the demands were not met within four days, the price would increase and within ten days the city would permanently lose all of the data. On May 25, security expert Nicole Perlroth speculated that the stolen NSA exploit EternalBlue was used to infiltrate the city's network vulnerabilities and initiate the attack, though in a memoir published in February 2021, Perlroth recanted her original statement after concluding that the exploit was not in fact responsible.Baltimore was susceptible to such an attack due to its IT practices, which included decentralized control of its technology budget and a failure to allocate money its information security manager wanted to fund cyberattack insurance. The attack has been compared to a ransomware attack on Atlanta the previous year, and was the second major use of the RobbinHood ransomware on an American city in 2019, as Greenville, North Carolina was also affected in April.\n\n== Aftermath ==\nThe attack had a negative impact on the real estate market as property transfers could not be completed digitally due to the system being down, as the city's card payment system and debt checking application were rendered inaccessible. In addition, city employees were unable to use their email system and resorted to creating Gmail accounts as workaround. Google automatically blocked their accounts at first due to the large number of accounts created in that timespan, though the company later restored the Gmail accounts.The recovery, initially estimated to take several more weeks on May 20, ultimately lasted until September. Frank Johnson, Baltimore's IT director, was put on unpaid leave following the ransomware attack. Since becoming the city's IT director during the Pugh administration, Johnson had been criticized for not having a written disaster recovery plan and for his handling of the 2019 attack, which was estimated to cost the city $18 million. He was replaced by deputy director Todd Carter, who later became the permanent IT director in February 2020 after Johnson left the role in October. Answer this question using the following article:\n\nWhat was the consequence of not meeting the hackers' demands within the stipulated time frame?",
    "context": "",
    "output": "If the demands were not met within four days, the price would increase and within ten days the city would permanently lose all of the data.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What was the consequence of not meeting the hackers' demands within the stipulated time frame?",
      "answer": "If the demands were not met within four days, the price would increase and within ten days the city would permanently lose all of the data.",
      "context": "2019 Baltimore ransomware attack\n\n==Introduction==\nDuring the Baltimore ransomware attack of May 2019, the American city of Baltimore, Maryland had its servers largely compromised by a variant of ransomware called RobbinHood. Baltimore became the second U.S. city to fall victim to this new variant of ransomware after Greenville, North Carolina and was the second major US city with a population of over 500,000 people to be hacked by ransomware in two years, after Atlanta was attacked the previous year.\n\n\n\n== Background ==\nBaltimore had been targeted by ransomware once prior to the May 2019 attack in 2018, though that attack was smaller in comparison and took down the city's emergency dispatch system for a short duration. On May 2, just days before the first infection, mayor Catherine Pugh resigned amidst a corruption scandal and was ultimately convicted and sentenced to 3 years in prison. She was replaced by Jack Young.\n\n== Attack ==\nOn May 7, 2019, most of Baltimore's government computer systems were infected with the aggressive ransomware variant RobbinHood. All servers, with the exception of essential services, were taken offline. In a ransom note, hackers demanded 13 bitcoin (roughly $76,280) in exchange for keys to restore access. The note stated that if the demands were not met within four days, the price would increase and within ten days the city would permanently lose all of the data. On May 25, security expert Nicole Perlroth speculated that the stolen NSA exploit EternalBlue was used to infiltrate the city's network vulnerabilities and initiate the attack, though in a memoir published in February 2021, Perlroth recanted her original statement after concluding that the exploit was not in fact responsible.Baltimore was susceptible to such an attack due to its IT practices, which included decentralized control of its technology budget and a failure to allocate money its information security manager wanted to fund cyberattack insurance. The attack has been compared to a ransomware attack on Atlanta the previous year, and was the second major use of the RobbinHood ransomware on an American city in 2019, as Greenville, North Carolina was also affected in April.\n\n== Aftermath ==\nThe attack had a negative impact on the real estate market as property transfers could not be completed digitally due to the system being down, as the city's card payment system and debt checking application were rendered inaccessible. In addition, city employees were unable to use their email system and resorted to creating Gmail accounts as workaround. Google automatically blocked their accounts at first due to the large number of accounts created in that timespan, though the company later restored the Gmail accounts.The recovery, initially estimated to take several more weeks on May 20, ultimately lasted until September. Frank Johnson, Baltimore's IT director, was put on unpaid leave following the ransomware attack. Since becoming the city's IT director during the Pugh administration, Johnson had been criticized for not having a written disaster recovery plan and for his handling of the 2019 attack, which was estimated to cost the city $18 million. He was replaced by deputy director Todd Carter, who later became the permanent IT director in February 2020 after Johnson left the role in October."
    }
  },
  {
    "instruction": "S/KEY passwords are mapped to six short words, of one to four characters each, from a publicly accessible 2048-word dictionary for improved human usability.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How are S/KEY passwords mapped for human usability?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How are S/KEY passwords mapped for human usability?",
      "answer": "S/KEY passwords are mapped to six short words, of one to four characters each, from a publicly accessible 2048-word dictionary for improved human usability."
    }
  },
  {
    "instruction": "The fact that many hash functions that were once thought to be collision resistant were later broken highlights the importance of ongoing research and development in the field of cryptography. As new attacks and techniques are discovered, it is important to continually evaluate and improve the security of existing cryptographic algorithms.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the significance of the fact that many hash functions that were once thought to be collision resistant were later broken?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the significance of the fact that many hash functions that were once thought to be collision resistant were later broken?",
      "answer": "The fact that many hash functions that were once thought to be collision resistant were later broken highlights the importance of ongoing research and development in the field of cryptography. As new attacks and techniques are discovered, it is important to continually evaluate and improve the security of existing cryptographic algorithms."
    }
  },
  {
    "instruction": "Australia has outlawed certain types of warrant canaries, making it illegal to disclose information about the existence or non-existence of warrants under mandatory data retention laws. This raises concerns about free speech and the potential for constitutionality challenges, as courts in the United States have ruled that compelling someone to speak against their wishes or to lie violates the Free Speech Clause and the First Amendment.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How has Australia's legal landscape affected the use of warrant canaries, and what are the implications for free speech and constitutionality challenges?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How has Australia's legal landscape affected the use of warrant canaries, and what are the implications for free speech and constitutionality challenges?",
      "answer": "Australia has outlawed certain types of warrant canaries, making it illegal to disclose information about the existence or non-existence of warrants under mandatory data retention laws. This raises concerns about free speech and the potential for constitutionality challenges, as courts in the United States have ruled that compelling someone to speak against their wishes or to lie violates the Free Speech Clause and the First Amendment."
    }
  },
  {
    "instruction": "The General Staff Department of the Korean People's Army is responsible for the defense of the country's military communication and information systems, as well as for conducting cyber intelligence and cyber warfare operations in support of national security. It also provides cyber security education and awareness programs to the military personnel and collaborates with other national and international organizations to enhance the cyber defense capabilities of North Korea.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the role of the North Korean General Staff Department of the Korean People's Army in the country's cyber defense?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the role of the North Korean General Staff Department of the Korean People's Army in the country's cyber defense?",
      "answer": "The General Staff Department of the Korean People's Army is responsible for the defense of the country's military communication and information systems, as well as for conducting cyber intelligence and cyber warfare operations in support of national security. It also provides cyber security education and awareness programs to the military personnel and collaborates with other national and international organizations to enhance the cyber defense capabilities of North Korea."
    }
  },
  {
    "instruction": "The letters \"~knzyvo}\" in the message displayed by the infected program are significant because they contain a hidden message when shifted 10 characters to the left in the ASCII table, revealing the word \"tadpoles\".\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the significance of the letters \"~knzyvo}\" in the message displayed by the infected program?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the significance of the letters \"~knzyvo}\" in the message displayed by the infected program?",
      "answer": "The letters \"~knzyvo}\" in the message displayed by the infected program are significant because they contain a hidden message when shifted 10 characters to the left in the ASCII table, revealing the word \"tadpoles\"."
    }
  },
  {
    "instruction": "Virtual machine software can inadvertently act as a rogue DHCP server on a network by handing out random IP addresses to clients when run on a client machine joined to the network. This can result in large portions of the network being cut off from the Internet and the rest of the domain without access.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How can virtual machine software inadvertently act as a rogue DHCP server on a network?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How can virtual machine software inadvertently act as a rogue DHCP server on a network?",
      "answer": "Virtual machine software can inadvertently act as a rogue DHCP server on a network by handing out random IP addresses to clients when run on a client machine joined to the network. This can result in large portions of the network being cut off from the Internet and the rest of the domain without access."
    }
  },
  {
    "instruction": "dm-crypt is a transparent block device encryption subsystem in Linux kernel versions 2.6 and later and in DragonFly BSD. It is part of the device mapper (dm) infrastructure, and uses cryptographic routines from the kernel's Crypto API.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is dm-crypt and which kernel versions does it support?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is dm-crypt and which kernel versions does it support?",
      "answer": "dm-crypt is a transparent block device encryption subsystem in Linux kernel versions 2.6 and later and in DragonFly BSD. It is part of the device mapper (dm) infrastructure, and uses cryptographic routines from the kernel's Crypto API."
    }
  },
  {
    "instruction": "AT&T Cybersecurity supports the development of the Open Source Security Information Management (OSSIM) project by providing computer security, intrusion detection, and response services. The company operates the project and makes its services available to the open-source community.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How did AT&T Cybersecurity support the development of the Open Source Security Information Management (OSSIM) project?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How did AT&T Cybersecurity support the development of the Open Source Security Information Management (OSSIM) project?",
      "answer": "AT&T Cybersecurity supports the development of the Open Source Security Information Management (OSSIM) project by providing computer security, intrusion detection, and response services. The company operates the project and makes its services available to the open-source community."
    }
  },
  {
    "instruction": "Relativistic quantum cryptography\n\n==Introduction==\nRelativistic quantum cryptography is a sub-field of quantum cryptography, in which in addition to exploiting the principles of quantum physics, the no-superluminal signalling principle of relativity theory stating that information cannot travel faster than light is exploited too. Technically speaking, relativistic quantum cryptography is a sub-field of relativistic cryptography, in which cryptographic protocols exploit the no-superluminal signalling principle, independently of whether quantum properties are used or not. However, in practice, the term relativistic quantum cryptography is used for relativistic cryptography too.\n\n== Basics ==\n\n\n*** No-signalling and no-superluminal signalling ***\nThe no-signalling principle of quantum theory states that information cannot be communicated between two distinct locations L0 and L1 without the transmission of any physical systems, despite any quantum entanglement shared between L0 and L1. This implies, in particular, that without the transmission of any physical systems between L0 and L1, quantum correlation between L0 and L1 cannot be used to transmit information between L0 and L1, even if they are non-locally causal and violate Bell inequalities. According to relativity theory, physical systems cannot travel faster than the speed of light. Thus, it follows from the no-signalling principle that information cannot travel faster than the speed of light. This is called the no-superluminal signalling principle.\nThe principle of no-superluminal signalling is the key physical principle exploited in relativistic cryptography. It guarantees that the outcome x of a random variable X obtained at some spacetime point P cannot influence the probability that a random variable Y takes some value y at a spacelike separated spacetime point Q. Thus, for example, if two parties Alice and Bob have each two agents, with the first agent of Bob sending a secret message x to a first agent of Alice at the spacetime point P, and with the second agent of Alice sending a secret message y to the second agent of Bob at the spacetime point Q, with P and Q spacelike separated, then Bob can be guaranteed that the message y received from Alice was chosen independently of the message x that he gave Alice, and vice versa. This is a useful mathematical property that is exploited to prove the security of cryptographic protocols in relativistic cryptography.\n\n\n*** The setting ***\nIt is a fundamental requirement in relativistic cryptography that the parties implementing the cryptographic task have a good description of spacetime, at least within the region of spacetime where the task is implemented. For example, in protocols implemented near the Earth surface, it can be assumed that spacetime is close to Minkowski. Importantly, this means that, near the Earth surface, physical systems and information cannot travel faster than the speed of light through vacuum, which is approximately 300,000 km/s. In principle, relativistic cryptography can be applied with more general spacetimes, as long as the parties can guarantee that there are no mechanisms allowing instant communication, like wormholes. Another requirement is that the parties have access to a common reference frame, so that they can guarantee that some communication events are spacelike separated.In relativistic cryptography, it is assumed that each party participating in the cryptographic task has various trusted agents that collaborate to implement the task. The agents implement the protocol by performing different actions at various points in spacetime. The agents of the same party may communicate via authenticated and secure channels, which can be implemented with previously shared secure keys, for example using one-time pads.Various tasks investigated by relativistic cryptography consist in tasks of mistrustful cryptography, in which two or more mistrustful parties must collaborate to implement a cryptographic task while at the same time being guaranteed that other parties do not cheat. Examples of tasks in mistrustful cryptography are bit commitment, coin tossing, oblivious transfer and secure computations. Key distribution does not belong to mistrustful cryptography, because in this case the parties distributing the key trust each other. In relativistic cryptography, each participating party has various trusted agents, who collaborate with each other by performing different actions at various spacetime points. For example, Alice and Bob can be two companies with offices and laboratories at various locations in the Earth. Alice's offices and laboratories work in collaboration and trust each other. Similarly, Bob's offices and laboratories work in collaboration and trust each other. But Alice and Bob do not trust each other.\n\n== Tasks investigated in relativistic cryptography ==\n\n\n*** Bit commitment ***\n\nBit commitment is an important cryptographic task that has been widely investigated in relativistic cryptography. In bit commitment, Alice commits to a bit b at some time t, and at some later time t\u2019 > t Alice unveils her committed bit b to Bob. A bit commitment is said to be \"hiding\" if Bob cannot know b before Alice unveils. It is said to be \"binding\" if after the commitment time t, Alice cannot choose the value of b and successfully unveil b to Bob. A bit commitment protocol is \"secure\" if it is hiding and binding. The Mayers-Lo-Chau no go theorem states that unconditionally secure bit commitment is impossible based only on the laws of quantum physics. It was shown by Kent that the Mayers-Lo-Chau theorem is not general enough because it excludes protocols that exploit the principle of no-superluminal signalling. Kent provided the first unconditionally secure bit commitment protocol in the setting of relativistic cryptography. Various protocols for bit commitment have been devised by Kent and others. Experimental demonstrations of relativistic bit commitment have been implemented.\n\n\n*** Coin tossing ***\nIn strong coin tossing, Alice and Bob are at different locations and they wish to toss a coin in such a way that Alice is guaranteed that Bob cannot bias the outcome, and Bob is guaranteed that Alice cannot bias the outcome either. It was shown by Lo and Chau that ideal strong coin tossing is impossible to achieve with unconditional security based only on the laws of quantum physics. However, Kent overcame this no-go theorem by providing a relativistic protocol for strong coin tossing that is unconditionally secure. This protocol is conceptually very simple and is illustrated here as an example of a protocol in relativistic cryptography.\nIn Kent's coin tossing protocol, Alice has two agents A0 and A1, and Bob has two agents B0 and B1. Ai and Bi are at location Li, for \n  \n    \n      \n        i\n        \u2208\n        {\n        0\n        ,\n        1\n        }\n      \n    \n    {\\displaystyle i\\in \\{0,1\\}}\n  . Let L0 and L1 have a distant separation D. Let us assume that spacetime is Minkowski. Thus, the minimum time that light takes to travel between L0 and L1 is t\n\nAnswer this question \"What is the difference between the no-signalling principle and the no-superluminal signalling principle?\" using the text above.",
    "context": "",
    "output": "The no-signalling principle is a concept in quantum theory that states information cannot be communicated between two distinct locations without the transmission of any physical systems, despite any quantum entanglement shared between them. On the other hand, the no-superluminal signalling principle, which is a consequence of the no-signalling principle and relativity theory, states that information cannot travel faster than the speed of light.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the difference between the no-signalling principle and the no-superluminal signalling principle?",
      "answer": "The no-signalling principle is a concept in quantum theory that states information cannot be communicated between two distinct locations without the transmission of any physical systems, despite any quantum entanglement shared between them. On the other hand, the no-superluminal signalling principle, which is a consequence of the no-signalling principle and relativity theory, states that information cannot travel faster than the speed of light.",
      "context": "Relativistic quantum cryptography\n\n==Introduction==\nRelativistic quantum cryptography is a sub-field of quantum cryptography, in which in addition to exploiting the principles of quantum physics, the no-superluminal signalling principle of relativity theory stating that information cannot travel faster than light is exploited too. Technically speaking, relativistic quantum cryptography is a sub-field of relativistic cryptography, in which cryptographic protocols exploit the no-superluminal signalling principle, independently of whether quantum properties are used or not. However, in practice, the term relativistic quantum cryptography is used for relativistic cryptography too.\n\n== Basics ==\n\n\n*** No-signalling and no-superluminal signalling ***\nThe no-signalling principle of quantum theory states that information cannot be communicated between two distinct locations L0 and L1 without the transmission of any physical systems, despite any quantum entanglement shared between L0 and L1. This implies, in particular, that without the transmission of any physical systems between L0 and L1, quantum correlation between L0 and L1 cannot be used to transmit information between L0 and L1, even if they are non-locally causal and violate Bell inequalities. According to relativity theory, physical systems cannot travel faster than the speed of light. Thus, it follows from the no-signalling principle that information cannot travel faster than the speed of light. This is called the no-superluminal signalling principle.\nThe principle of no-superluminal signalling is the key physical principle exploited in relativistic cryptography. It guarantees that the outcome x of a random variable X obtained at some spacetime point P cannot influence the probability that a random variable Y takes some value y at a spacelike separated spacetime point Q. Thus, for example, if two parties Alice and Bob have each two agents, with the first agent of Bob sending a secret message x to a first agent of Alice at the spacetime point P, and with the second agent of Alice sending a secret message y to the second agent of Bob at the spacetime point Q, with P and Q spacelike separated, then Bob can be guaranteed that the message y received from Alice was chosen independently of the message x that he gave Alice, and vice versa. This is a useful mathematical property that is exploited to prove the security of cryptographic protocols in relativistic cryptography.\n\n\n*** The setting ***\nIt is a fundamental requirement in relativistic cryptography that the parties implementing the cryptographic task have a good description of spacetime, at least within the region of spacetime where the task is implemented. For example, in protocols implemented near the Earth surface, it can be assumed that spacetime is close to Minkowski. Importantly, this means that, near the Earth surface, physical systems and information cannot travel faster than the speed of light through vacuum, which is approximately 300,000 km/s. In principle, relativistic cryptography can be applied with more general spacetimes, as long as the parties can guarantee that there are no mechanisms allowing instant communication, like wormholes. Another requirement is that the parties have access to a common reference frame, so that they can guarantee that some communication events are spacelike separated.In relativistic cryptography, it is assumed that each party participating in the cryptographic task has various trusted agents that collaborate to implement the task. The agents implement the protocol by performing different actions at various points in spacetime. The agents of the same party may communicate via authenticated and secure channels, which can be implemented with previously shared secure keys, for example using one-time pads.Various tasks investigated by relativistic cryptography consist in tasks of mistrustful cryptography, in which two or more mistrustful parties must collaborate to implement a cryptographic task while at the same time being guaranteed that other parties do not cheat. Examples of tasks in mistrustful cryptography are bit commitment, coin tossing, oblivious transfer and secure computations. Key distribution does not belong to mistrustful cryptography, because in this case the parties distributing the key trust each other. In relativistic cryptography, each participating party has various trusted agents, who collaborate with each other by performing different actions at various spacetime points. For example, Alice and Bob can be two companies with offices and laboratories at various locations in the Earth. Alice's offices and laboratories work in collaboration and trust each other. Similarly, Bob's offices and laboratories work in collaboration and trust each other. But Alice and Bob do not trust each other.\n\n== Tasks investigated in relativistic cryptography ==\n\n\n*** Bit commitment ***\n\nBit commitment is an important cryptographic task that has been widely investigated in relativistic cryptography. In bit commitment, Alice commits to a bit b at some time t, and at some later time t\u2019 > t Alice unveils her committed bit b to Bob. A bit commitment is said to be \"hiding\" if Bob cannot know b before Alice unveils. It is said to be \"binding\" if after the commitment time t, Alice cannot choose the value of b and successfully unveil b to Bob. A bit commitment protocol is \"secure\" if it is hiding and binding. The Mayers-Lo-Chau no go theorem states that unconditionally secure bit commitment is impossible based only on the laws of quantum physics. It was shown by Kent that the Mayers-Lo-Chau theorem is not general enough because it excludes protocols that exploit the principle of no-superluminal signalling. Kent provided the first unconditionally secure bit commitment protocol in the setting of relativistic cryptography. Various protocols for bit commitment have been devised by Kent and others. Experimental demonstrations of relativistic bit commitment have been implemented.\n\n\n*** Coin tossing ***\nIn strong coin tossing, Alice and Bob are at different locations and they wish to toss a coin in such a way that Alice is guaranteed that Bob cannot bias the outcome, and Bob is guaranteed that Alice cannot bias the outcome either. It was shown by Lo and Chau that ideal strong coin tossing is impossible to achieve with unconditional security based only on the laws of quantum physics. However, Kent overcame this no-go theorem by providing a relativistic protocol for strong coin tossing that is unconditionally secure. This protocol is conceptually very simple and is illustrated here as an example of a protocol in relativistic cryptography.\nIn Kent's coin tossing protocol, Alice has two agents A0 and A1, and Bob has two agents B0 and B1. Ai and Bi are at location Li, for \n  \n    \n      \n        i\n        \u2208\n        {\n        0\n        ,\n        1\n        }\n      \n    \n    {\\displaystyle i\\in \\{0,1\\}}\n  . Let L0 and L1 have a distant separation D. Let us assume that spacetime is Minkowski. Thus, the minimum time that light takes to travel between L0 and L1 is t"
    }
  },
  {
    "instruction": "Social engineering is the use of psychological manipulation to trick people into divulging sensitive information or performing actions that can be used to carry out a cyberattack. It can be used in a variety of ways, such as phishing emails, phone calls, or in-person interactions.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is social engineering and how is it used in cyberattacks?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is social engineering and how is it used in cyberattacks?",
      "answer": "Social engineering is the use of psychological manipulation to trick people into divulging sensitive information or performing actions that can be used to carry out a cyberattack. It can be used in a variety of ways, such as phishing emails, phone calls, or in-person interactions."
    }
  },
  {
    "instruction": "Data leakage can occur due to a variety of circumstances, including misconfigured systems, human error, or malfunctioning hardware.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How can data leakage occur?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How can data leakage occur?",
      "answer": "Data leakage can occur due to a variety of circumstances, including misconfigured systems, human error, or malfunctioning hardware."
    }
  },
  {
    "instruction": "A hash filter detects spam emails by creating a hash sum from the email's content and comparing it with other known spam hash sums. Spammers attempt to evade this by adding random strings to the text content and random pixel changes to image content, also known as \"confetti\" technique, to alter the email's hash sum and avoid matching with known spam hash sums.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does a hash filter detect spam emails and what techniques do spammers use to evade such filters?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does a hash filter detect spam emails and what techniques do spammers use to evade such filters?",
      "answer": "A hash filter detects spam emails by creating a hash sum from the email's content and comparing it with other known spam hash sums. Spammers attempt to evade this by adding random strings to the text content and random pixel changes to image content, also known as \"confetti\" technique, to alter the email's hash sum and avoid matching with known spam hash sums."
    }
  },
  {
    "instruction": "An example of SGX used in security is a demo application from wolfSSL that uses it for cryptography algorithms.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is an example of SGX used in security, and what type of algorithms does it use?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is an example of SGX used in security, and what type of algorithms does it use?",
      "answer": "An example of SGX used in security is a demo application from wolfSSL that uses it for cryptography algorithms."
    }
  },
  {
    "instruction": "Organizations can reduce security risks by training employees in security protocols, establishing frameworks of trust, scrutinizing sensitive information exposure, establishing security protocols, and performing unannounced, periodic tests of the security framework. Regularly reviewing these steps is also essential.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How can organizations reduce their security risks associated with social engineering?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How can organizations reduce their security risks associated with social engineering?",
      "answer": "Organizations can reduce security risks by training employees in security protocols, establishing frameworks of trust, scrutinizing sensitive information exposure, establishing security protocols, and performing unannounced, periodic tests of the security framework. Regularly reviewing these steps is also essential."
    }
  },
  {
    "instruction": "XSS attacks can be carried out using double URI-encoding by incorporating a payload into the HTTP GET parameter name and then double URI-encoding the payload. This can allow the payload to bypass security filters and be accepted by the system, potentially allowing an attacker to inject malicious scripts into the application.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How can XSS attacks be carried out using double URI-encoding?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How can XSS attacks be carried out using double URI-encoding?",
      "answer": "XSS attacks can be carried out using double URI-encoding by incorporating a payload into the HTTP GET parameter name and then double URI-encoding the payload. This can allow the payload to bypass security filters and be accepted by the system, potentially allowing an attacker to inject malicious scripts into the application."
    }
  },
  {
    "instruction": "Context: 2021 FBI email hack\n\n==Introduction==\nOn November 13, 2021, a hacker compromised the FBI's external email system, sending thousands of messages warning of a cyberattack by cybersecurity CEO Vinny Troia who was falsely suggested to have been identified as part of The Dark Overlord hacking group by the United States Department of Homeland Security.The emails were sent to addresses taken from the American Registry for Internet Numbers database and it was reported that the hacker used the FBI's public-facing email system which made the emails appear legitimate. The campaign was likely done in an attempt to defame Troia. The hacker \"Pompompurin\" (revealed in 2023 to be an individual named Conor Brian Fitzpatrick) later claimed responsibility for the hack.\n\n\n\n== Responses ==\n\n\n*** FBI ***\nThe FBI stated that they remediated the software vulnerablilty that caused the attack. They told people to ignore the email and \"confirmed the integrity\" of the FBI's computer systems following the attack.\n\n\n*** Pompompurin ***\nThe hacker Pompompurin claimed responsibility for attack claiming in an interview with Krebs on Security. In a later interview with ProPublica Pompompurin later claimed the hack was done for \"fun.\"Vinny Troia blogged about his belief it was the work of Canadian hacker Chris Meunier. In an interview with ProPublica, Pompompurin denied being Meunier.\n\n== Aftermath ==\nIn March 2023 Pompompurin was arrested on unrelated computer crime charges in Peekskill, New York and was identified as a 20 to 21 year old man named Conor Brian Fitzpatrick. Fitzpatrick was said to have told the arresting officer that he was the creator of BreachForums, which had been created to \"fill the void\" caused by the seizure of RaidForums a few weeks earlier. He was identified as connected to the 2021 Robinhood Markets data breach and a data breach of Twitter in 2022.\nQuestion: Who did the hacker \"Pompompurin\" claim to be in an interview with Krebs on Security?. Whats the answer?",
    "context": "",
    "output": "The hacker \"Pompompurin\" claimed responsibility for the 2021 FBI email hack in an interview with Krebs on Security.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "Who did the hacker \"Pompompurin\" claim to be in an interview with Krebs on Security?",
      "answer": "The hacker \"Pompompurin\" claimed responsibility for the 2021 FBI email hack in an interview with Krebs on Security.",
      "context": "2021 FBI email hack\n\n==Introduction==\nOn November 13, 2021, a hacker compromised the FBI's external email system, sending thousands of messages warning of a cyberattack by cybersecurity CEO Vinny Troia who was falsely suggested to have been identified as part of The Dark Overlord hacking group by the United States Department of Homeland Security.The emails were sent to addresses taken from the American Registry for Internet Numbers database and it was reported that the hacker used the FBI's public-facing email system which made the emails appear legitimate. The campaign was likely done in an attempt to defame Troia. The hacker \"Pompompurin\" (revealed in 2023 to be an individual named Conor Brian Fitzpatrick) later claimed responsibility for the hack.\n\n\n\n== Responses ==\n\n\n*** FBI ***\nThe FBI stated that they remediated the software vulnerablilty that caused the attack. They told people to ignore the email and \"confirmed the integrity\" of the FBI's computer systems following the attack.\n\n\n*** Pompompurin ***\nThe hacker Pompompurin claimed responsibility for attack claiming in an interview with Krebs on Security. In a later interview with ProPublica Pompompurin later claimed the hack was done for \"fun.\"Vinny Troia blogged about his belief it was the work of Canadian hacker Chris Meunier. In an interview with ProPublica, Pompompurin denied being Meunier.\n\n== Aftermath ==\nIn March 2023 Pompompurin was arrested on unrelated computer crime charges in Peekskill, New York and was identified as a 20 to 21 year old man named Conor Brian Fitzpatrick. Fitzpatrick was said to have told the arresting officer that he was the creator of BreachForums, which had been created to \"fill the void\" caused by the seizure of RaidForums a few weeks earlier. He was identified as connected to the 2021 Robinhood Markets data breach and a data breach of Twitter in 2022."
    }
  },
  {
    "instruction": "The piling-up lemma states that if the input variables are independent, then the bias of a linear Boolean function is related to the product of the input biases. If the input variables are not independent, then the lemma does not apply.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does the piling-up lemma handle the case where the input variables are not independent?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does the piling-up lemma handle the case where the input variables are not independent?",
      "answer": "The piling-up lemma states that if the input variables are independent, then the bias of a linear Boolean function is related to the product of the input biases. If the input variables are not independent, then the lemma does not apply."
    }
  },
  {
    "instruction": "AV-Comparatives\n\n==Introduction==\nAV-Comparatives is an Austrian independent organization that tests and assesses antivirus software, regularly releasing charts and reports that are freely available to the public and the media. Antivirus vendors have to meet various requirements regarding trustworthiness and reliability in order to take part in the tests.AV-Comparatives issues relevant awards, based on antivirus software's comprehensive performance according to multiple testing criteria. It is also supported by the University of Innsbruck and other academic bodies from around the world, as well as by the Austrian Federal Government and the regional government of Tirol.\n\n\n\n== Real World Protection Test ==\nThe AV-Comparatives \"Real World Protection Test\" is a test environment that closely approximates how well an antivirus product will protect real-world users. Test results are released monthly (from March to June and August to November). Two detailed overall result reports are released in June and December. The Real World Protection Test framework was recognized by the \"Standortagentur Tirol\" with the 2012 Cluster Award for innovation in computer science.\n\n== Latest Test Series ==\nIn 2018 AV-Comparatives started with a large scale Enterprise Security Software Test Series, consisting of a Real-World Test, a False Alarm Test, a Malware Protection Test and a Performance Test as well as a review.\n\n== Listing of tests and reviews by AV-Comparatives ==\nReal-World Protection Tests\nFile Detection Tests\nMalware Protection Test\nHeuristic / Behaviour Test\nFalse Alarm Test\nPerformanceTest\nMalware Removal Test\nAnti-Phishing Test\nParental Control Test\nMac Security Reviews / Tests\nMobile Security Review\nCorporate / Enterprise Security Reviews\nPowerShell-based File-less Attacks and File-based Exploits Test\n\n== Operating systems used for antivirus tests ==\nMicrosoft Windows\nmacOS\niOS\nAndroid\nLinux\n\n== AVC UnDroid Analyzer ==\nAV-Comparatives has provided \"UnDroid APK Analyzer\" as a free service for its website's users since May 2013. Designed for Android smartphone users, it provides a static analysis of Android apps. Users can upload an Android application package (APK) and receive a quick online analysis containing the file hashes, graphical danger level and additional information.\n\n== Awards and certifications given to AV-Comparatives ==\n2016: EN ISO 9001:2015 for the Scope \"Independent Tests of Anti-Virus Software\"\n2015: EICAR trusted IT-security testing lab\n2013: Constantinus Award in Computer Science, the highest award/certification given by Austrian Government (Chamber of Commerce) for projects in computer science.\n2012: Austrian eAward\n2012: Cluster Award 2012\n\n== References list == Answer this question using the following article:\n\nWhat is the significance of AV-Comparatives being an Austrian independent organization, and how does it impact its testing and assessment of antivirus software?",
    "context": "",
    "output": "Being an Austrian independent organization, AV-Comparatives is not influenced or biased by any commercial interests or vendor affiliations. This allows it to provide objective and unbiased tests and assessments of antivirus software, ensuring the highest level of accuracy and reliability.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the significance of AV-Comparatives being an Austrian independent organization, and how does it impact its testing and assessment of antivirus software?",
      "answer": "Being an Austrian independent organization, AV-Comparatives is not influenced or biased by any commercial interests or vendor affiliations. This allows it to provide objective and unbiased tests and assessments of antivirus software, ensuring the highest level of accuracy and reliability.",
      "context": "AV-Comparatives\n\n==Introduction==\nAV-Comparatives is an Austrian independent organization that tests and assesses antivirus software, regularly releasing charts and reports that are freely available to the public and the media. Antivirus vendors have to meet various requirements regarding trustworthiness and reliability in order to take part in the tests.AV-Comparatives issues relevant awards, based on antivirus software's comprehensive performance according to multiple testing criteria. It is also supported by the University of Innsbruck and other academic bodies from around the world, as well as by the Austrian Federal Government and the regional government of Tirol.\n\n\n\n== Real World Protection Test ==\nThe AV-Comparatives \"Real World Protection Test\" is a test environment that closely approximates how well an antivirus product will protect real-world users. Test results are released monthly (from March to June and August to November). Two detailed overall result reports are released in June and December. The Real World Protection Test framework was recognized by the \"Standortagentur Tirol\" with the 2012 Cluster Award for innovation in computer science.\n\n== Latest Test Series ==\nIn 2018 AV-Comparatives started with a large scale Enterprise Security Software Test Series, consisting of a Real-World Test, a False Alarm Test, a Malware Protection Test and a Performance Test as well as a review.\n\n== Listing of tests and reviews by AV-Comparatives ==\nReal-World Protection Tests\nFile Detection Tests\nMalware Protection Test\nHeuristic / Behaviour Test\nFalse Alarm Test\nPerformanceTest\nMalware Removal Test\nAnti-Phishing Test\nParental Control Test\nMac Security Reviews / Tests\nMobile Security Review\nCorporate / Enterprise Security Reviews\nPowerShell-based File-less Attacks and File-based Exploits Test\n\n== Operating systems used for antivirus tests ==\nMicrosoft Windows\nmacOS\niOS\nAndroid\nLinux\n\n== AVC UnDroid Analyzer ==\nAV-Comparatives has provided \"UnDroid APK Analyzer\" as a free service for its website's users since May 2013. Designed for Android smartphone users, it provides a static analysis of Android apps. Users can upload an Android application package (APK) and receive a quick online analysis containing the file hashes, graphical danger level and additional information.\n\n== Awards and certifications given to AV-Comparatives ==\n2016: EN ISO 9001:2015 for the Scope \"Independent Tests of Anti-Virus Software\"\n2015: EICAR trusted IT-security testing lab\n2013: Constantinus Award in Computer Science, the highest award/certification given by Austrian Government (Chamber of Commerce) for projects in computer science.\n2012: Austrian eAward\n2012: Cluster Award 2012\n\n== References list =="
    }
  },
  {
    "instruction": "The NCCU was formed by merging the Serious Organised Crime Agency's cyber division with the Police Central E-Crime Unit (PCeU) of the Metropolitan Police Service. This merger indicates that cyber crime has become a more significant threat, requiring a combined effort from multiple law enforcement agencies to effectively identify and combat it.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does the formation of the NCCU reflect the evolving nature of cyber crime?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does the formation of the NCCU reflect the evolving nature of cyber crime?",
      "answer": "The NCCU was formed by merging the Serious Organised Crime Agency's cyber division with the Police Central E-Crime Unit (PCeU) of the Metropolitan Police Service. This merger indicates that cyber crime has become a more significant threat, requiring a combined effort from multiple law enforcement agencies to effectively identify and combat it."
    }
  },
  {
    "instruction": "The NSA advised partners and vendors that have not yet made the transition to Suite B algorithms not to make a significant expenditure to do so and instead to prepare for the upcoming quantum resistant algorithm transition.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What advice did the NSA give to partners and vendors regarding the transition to Suite B algorithms?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What advice did the NSA give to partners and vendors regarding the transition to Suite B algorithms?",
      "answer": "The NSA advised partners and vendors that have not yet made the transition to Suite B algorithms not to make a significant expenditure to do so and instead to prepare for the upcoming quantum resistant algorithm transition."
    }
  },
  {
    "instruction": "The bugs discovered in WPA3's Dragonfly handshake allow an adversary to impersonate any user and access the Wi-Fi network without knowing the user's password, which could have serious implications for the security of the Wi-Fi network in enterprise mode.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How do the bugs discovered in WPA3's Dragonfly handshake affect the security of the Wi-Fi network in enterprise mode?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How do the bugs discovered in WPA3's Dragonfly handshake affect the security of the Wi-Fi network in enterprise mode?",
      "answer": "The bugs discovered in WPA3's Dragonfly handshake allow an adversary to impersonate any user and access the Wi-Fi network without knowing the user's password, which could have serious implications for the security of the Wi-Fi network in enterprise mode."
    }
  },
  {
    "instruction": "Procedures specified in a certificate policy ensure that all actors within the PKI follow the same guidelines for certificate application, issuance, acceptance, renewal, re-key, modification, and revocation. This helps maintain a consistent level of assurance within the PKI.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the purpose of specifying procedures in a certificate policy, and which procedures are typically addressed?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the purpose of specifying procedures in a certificate policy, and which procedures are typically addressed?",
      "answer": "Procedures specified in a certificate policy ensure that all actors within the PKI follow the same guidelines for certificate application, issuance, acceptance, renewal, re-key, modification, and revocation. This helps maintain a consistent level of assurance within the PKI."
    }
  },
  {
    "instruction": "Tavis Ormandy has criticized Comodo for using access control lists (ACLs) throughout its product.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the opinion of Tavis Ormandy regarding Comodo's use of ACLs?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the opinion of Tavis Ormandy regarding Comodo's use of ACLs?",
      "answer": "Tavis Ormandy has criticized Comodo for using access control lists (ACLs) throughout its product."
    }
  },
  {
    "instruction": "Since 2009, the Philippines has criminalized copying, reproducing, sharing or exhibiting sexually explicit images or videos over the Internet without written consent of the individual depicted, with a penalty of up to three years' imprisonment or a fine of up to 5 million South Korean won. The use of hidden cameras for illicitly filming people, known as \"molka\", is widespread in the country, and in 2018 more than 6,000 incidents of spy-cam porn were being reported to the police annually, with only 2% of reported cases leading to a prison sentence.\n\nWrite a question about the text above.",
    "context": "",
    "output": "In what ways has the Philippines criminalized revenge porn?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "In what ways has the Philippines criminalized revenge porn?",
      "answer": "Since 2009, the Philippines has criminalized copying, reproducing, sharing or exhibiting sexually explicit images or videos over the Internet without written consent of the individual depicted, with a penalty of up to three years' imprisonment or a fine of up to 5 million South Korean won. The use of hidden cameras for illicitly filming people, known as \"molka\", is widespread in the country, and in 2018 more than 6,000 incidents of spy-cam porn were being reported to the police annually, with only 2% of reported cases leading to a prison sentence."
    }
  },
  {
    "instruction": "Groups contribute to the security of cryptographic protocols by providing mathematical structure and complexity. They allow for the creation of complex mathematical problems that are difficult to solve, which makes it difficult for attackers to break the encryption used in the protocol. This helps to ensure the confidentiality and integrity of the data being transmitted.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How do groups contribute to the security of cryptographic protocols?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How do groups contribute to the security of cryptographic protocols?",
      "answer": "Groups contribute to the security of cryptographic protocols by providing mathematical structure and complexity. They allow for the creation of complex mathematical problems that are difficult to solve, which makes it difficult for attackers to break the encryption used in the protocol. This helps to ensure the confidentiality and integrity of the data being transmitted."
    }
  },
  {
    "instruction": "Some methods of bypassing parental controls use external proxy servers or other servers by sending requests to the external server which retrieves content on the user's behalf. This allows the user to bypass filtering software that may be monitoring URLs or web servers, as all communications are with the one external server.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How do some methods of bypassing parental controls use external proxy servers or other servers?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How do some methods of bypassing parental controls use external proxy servers or other servers?",
      "answer": "Some methods of bypassing parental controls use external proxy servers or other servers by sending requests to the external server which retrieves content on the user's behalf. This allows the user to bypass filtering software that may be monitoring URLs or web servers, as all communications are with the one external server."
    }
  },
  {
    "instruction": "The students in the University of Mississippi's Center for Intelligence and Security Studies (CISS) represent a diverse range of languages, including Arabic, Chinese, English, French, German, Japanese, Latin, Portuguese, Russian, and Spanish.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What languages are represented by the students in the University of Mississippi's Center for Intelligence and Security Studies (CISS)?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What languages are represented by the students in the University of Mississippi's Center for Intelligence and Security Studies (CISS)?",
      "answer": "The students in the University of Mississippi's Center for Intelligence and Security Studies (CISS) represent a diverse range of languages, including Arabic, Chinese, English, French, German, Japanese, Latin, Portuguese, Russian, and Spanish."
    }
  },
  {
    "instruction": "The EUTXO model allows UTXOs to be linked to arbitrary pieces of data and logic in the form of smart contracts, and each UTXO is associated with a data value that can change as the UTXO is consumed, allowing contracts to maintain state across transactions.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does the Extended UTXO (EUTXO) model differ from the traditional UTXO model in terms of smart contracts and state maintenance?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does the Extended UTXO (EUTXO) model differ from the traditional UTXO model in terms of smart contracts and state maintenance?",
      "answer": "The EUTXO model allows UTXOs to be linked to arbitrary pieces of data and logic in the form of smart contracts, and each UTXO is associated with a data value that can change as the UTXO is consumed, allowing contracts to maintain state across transactions."
    }
  },
  {
    "instruction": "The World Intellectual Property Organization (WIPO) offers a Uniform Domain-Name Dispute-Resolution Policy (UDRP) that allows trademark holders to file a case against Typosquatters. To win a case, the complainant must prove that the registered domain name is identical or confusingly similar to their trademark, that the registrant has no legitimate interest in the domain name, and that the domain name is being used in bad faith.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the WIPO resolution procedure and how does it address Typosquatting?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the WIPO resolution procedure and how does it address Typosquatting?",
      "answer": "The World Intellectual Property Organization (WIPO) offers a Uniform Domain-Name Dispute-Resolution Policy (UDRP) that allows trademark holders to file a case against Typosquatters. To win a case, the complainant must prove that the registered domain name is identical or confusingly similar to their trademark, that the registrant has no legitimate interest in the domain name, and that the domain name is being used in bad faith."
    }
  },
  {
    "instruction": "Deterministic encryption schemes cannot achieve semantic security because the same plaintext will always generate the same ciphertext, making it possible for an attacker to learn information about the plaintext by observing the ciphertext.\n\nWrite a question about the text above.",
    "context": "",
    "output": "Why can deterministic encryption schemes never achieve semantic security?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "Why can deterministic encryption schemes never achieve semantic security?",
      "answer": "Deterministic encryption schemes cannot achieve semantic security because the same plaintext will always generate the same ciphertext, making it possible for an attacker to learn information about the plaintext by observing the ciphertext."
    }
  },
  {
    "instruction": "During the initial infection, the KAK worm adds a registry key and edits AUTOEXEC.BAT to make itself persistent on the infected system, ensuring that it runs every time the system starts up. During subsequent infections, the worm sets the user's email signature to contain the code to infect other systems, making the infection persistent by spreading to other systems through email.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does the KAK worm's behavior differ between the initial infection and subsequent infections in terms of persistence?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does the KAK worm's behavior differ between the initial infection and subsequent infections in terms of persistence?",
      "answer": "During the initial infection, the KAK worm adds a registry key and edits AUTOEXEC.BAT to make itself persistent on the infected system, ensuring that it runs every time the system starts up. During subsequent infections, the worm sets the user's email signature to contain the code to infect other systems, making the infection persistent by spreading to other systems through email."
    }
  },
  {
    "instruction": "Former NSA analyst Perry Fellwock, under the pseudonym Winslow Peck, first disclosed the existence of ECHELON to Ramparts in 1972.\n\nWrite a question about the text above.",
    "context": "",
    "output": "Who was the first to publicly disclose the existence of ECHELON, and when did this occur?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "Who was the first to publicly disclose the existence of ECHELON, and when did this occur?",
      "answer": "Former NSA analyst Perry Fellwock, under the pseudonym Winslow Peck, first disclosed the existence of ECHELON to Ramparts in 1972."
    }
  },
  {
    "instruction": "PGP and S/MIME, competing e-mail encryption standards, eventually replaced the privacy-enhanced mail series of RFCs.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What replaced the privacy-enhanced mail series of RFCs?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What replaced the privacy-enhanced mail series of RFCs?",
      "answer": "PGP and S/MIME, competing e-mail encryption standards, eventually replaced the privacy-enhanced mail series of RFCs."
    }
  },
  {
    "instruction": "Context: Privacy platform\n\n==Introduction==\nA privacy platform is a piece of software or a system that is designed to retain the privacy of its users and operators.\n\n\n\n== Examples ==\nPrivate.Me\nGeens.com\nQuestion: What are some potential consequences of a privacy platform failing to protect user data?. Whats the answer?",
    "context": "",
    "output": "If a privacy platform fails to protect user data, there could be several potential consequences. These might include legal penalties, damage to the reputation of the platform or its operators, and financial losses. In addition, users whose data has been compromised may suffer harm, such as identity theft or financial fraud.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What are some potential consequences of a privacy platform failing to protect user data?",
      "answer": "If a privacy platform fails to protect user data, there could be several potential consequences. These might include legal penalties, damage to the reputation of the platform or its operators, and financial losses. In addition, users whose data has been compromised may suffer harm, such as identity theft or financial fraud.",
      "context": "Privacy platform\n\n==Introduction==\nA privacy platform is a piece of software or a system that is designed to retain the privacy of its users and operators.\n\n\n\n== Examples ==\nPrivate.Me\nGeens.com"
    }
  },
  {
    "instruction": "Drive-by download\n\n==Introduction==\nDrive-by download is of two types, each concerning the unintended download of computer software from the Internet:\nAuthorized drive-by downloads are downloads which a person has authorized but without understanding the consequences (e.g. downloads which install an unknown or counterfeit executable program, ActiveX component, or Java applet).\nUnauthorized drive-by downloads are downloads which happen without a person's knowledge, often a computer virus, spyware, malware, or crimeware.Drive-by downloads may happen when visiting a website, opening an e-mail attachment or clicking a link, or clicking on a deceptive pop-up window: by clicking on the window in the mistaken belief that, for example, an error report from the computer's operating system itself is being acknowledged or a seemingly innocuous advertisement pop-up is being dismissed. In such cases, the \"supplier\" may claim that the user \"consented\" to the download, although the user was in fact unaware of having started an unwanted or malicious software download. Similarly if a person is visiting a site with malicious content, the person may become victim to a drive-by download attack. That is, the malicious content may be able to exploit vulnerabilities in the browser or plugins to run malicious code without the user's knowledge.A drive-by install (or installation) is a similar event. It refers to installation rather than download (though sometimes the two terms are used interchangeably).\n\n== Process ==\nWhen creating a drive-by download, an attacker must first create their malicious content to perform the attack. With the rise in exploit packs that contain the vulnerabilities needed to carry out unauthorized drive-by download attacks, the skill level needed to perform this attack has been reduced.The next step is to host the malicious content that the attacker wishes to distribute. One option is for the attacker to host the malicious content on their own server. However, because of the difficulty in directing users to a new page, it may also be hosted on a compromised legitimate website, or a legitimate website unknowingly distributing the attackers content through a third party service (e.g. an advertisement).  When the content is loaded by the client, the attacker will analyze the fingerprint of the client in order to tailor the code to exploit vulnerabilities specific to that client.Finally, the attacker exploits the necessary vulnerabilities to launch the drive-by download attack. Drive-by downloads usually use one of two strategies. The first strategy is exploiting API calls for various plugins. For example, the DownloadAndInstall API of the Sina ActiveX component did not properly check its parameters and allowed the downloading and execution of arbitrary files from the internet. The second strategy involves writing shellcode to memory, and then exploiting vulnerabilities in the web browser or plugin to divert the control flow of the program to the shell code. After the shellcode has been executed, the attacker can perform further malicious activities. This often involves downloading and installing malware, but can be anything, including stealing information to send back to the attacker.The attacker may also take measures to prevent detection throughout the attack. One method is to rely on the obfuscation of the malicious code. This can be done through the use of iframes. Another method is to encrypt the malicious code to prevent detection. Generally the attacker encrypts the malicious code into a ciphertext, then includes the decryption method after the ciphertext.\n\n== Detection and prevention ==\nDetection of drive-by download attacks is an active area of research. Some methods of detection involve anomaly detection, which tracks for state changes on a user's computer system while the user visits a webpage. This involves monitoring the user's computer system for anomalous changes when a web page is rendered. Other methods of detection include detecting when malicious code (shellcode) is written to memory by an attacker's exploit. Another detection method is to make run-time environments that allow JavaScript code to run and track its behavior while it runs. Other detection methods include examining contents of HTML pages to identify features that can be used to identify malicious web pages, and using characteristics of web servers to determine if a page is malicious. Some antivirus tools use static signatures to match patterns of malicious scripts, although these are not very effective because of obfuscation techniques. Detection is also possible by using low-interaction or high-interaction honeyclients.Drive-by downloads can also be prevented from occurring by using script-blockers such as NoScript, which can easily be added into browsers such as Firefox.  Using such a script-blocker, the user can disable all the scripts on a given webpage, and then selectively re-enable individual scripts on a one-by-one basis in order to determine which ones are truly necessary for webpage functionality.  However, some script-blocking tools can have unintended consequences, such as breaking parts of other websites, which can be a bit of a balancing act. Answer this question using the following article:\n\nWhat strategies do attackers use to launch drive-by download attacks?",
    "context": "",
    "output": "Attackers use two main strategies to launch drive-by download attacks: exploiting API calls for various plugins, and writing shellcode to memory and exploiting vulnerabilities in web browsers or plugins to divert the control flow of the program to the shell code.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What strategies do attackers use to launch drive-by download attacks?",
      "answer": "Attackers use two main strategies to launch drive-by download attacks: exploiting API calls for various plugins, and writing shellcode to memory and exploiting vulnerabilities in web browsers or plugins to divert the control flow of the program to the shell code.",
      "context": "Drive-by download\n\n==Introduction==\nDrive-by download is of two types, each concerning the unintended download of computer software from the Internet:\nAuthorized drive-by downloads are downloads which a person has authorized but without understanding the consequences (e.g. downloads which install an unknown or counterfeit executable program, ActiveX component, or Java applet).\nUnauthorized drive-by downloads are downloads which happen without a person's knowledge, often a computer virus, spyware, malware, or crimeware.Drive-by downloads may happen when visiting a website, opening an e-mail attachment or clicking a link, or clicking on a deceptive pop-up window: by clicking on the window in the mistaken belief that, for example, an error report from the computer's operating system itself is being acknowledged or a seemingly innocuous advertisement pop-up is being dismissed. In such cases, the \"supplier\" may claim that the user \"consented\" to the download, although the user was in fact unaware of having started an unwanted or malicious software download. Similarly if a person is visiting a site with malicious content, the person may become victim to a drive-by download attack. That is, the malicious content may be able to exploit vulnerabilities in the browser or plugins to run malicious code without the user's knowledge.A drive-by install (or installation) is a similar event. It refers to installation rather than download (though sometimes the two terms are used interchangeably).\n\n== Process ==\nWhen creating a drive-by download, an attacker must first create their malicious content to perform the attack. With the rise in exploit packs that contain the vulnerabilities needed to carry out unauthorized drive-by download attacks, the skill level needed to perform this attack has been reduced.The next step is to host the malicious content that the attacker wishes to distribute. One option is for the attacker to host the malicious content on their own server. However, because of the difficulty in directing users to a new page, it may also be hosted on a compromised legitimate website, or a legitimate website unknowingly distributing the attackers content through a third party service (e.g. an advertisement).  When the content is loaded by the client, the attacker will analyze the fingerprint of the client in order to tailor the code to exploit vulnerabilities specific to that client.Finally, the attacker exploits the necessary vulnerabilities to launch the drive-by download attack. Drive-by downloads usually use one of two strategies. The first strategy is exploiting API calls for various plugins. For example, the DownloadAndInstall API of the Sina ActiveX component did not properly check its parameters and allowed the downloading and execution of arbitrary files from the internet. The second strategy involves writing shellcode to memory, and then exploiting vulnerabilities in the web browser or plugin to divert the control flow of the program to the shell code. After the shellcode has been executed, the attacker can perform further malicious activities. This often involves downloading and installing malware, but can be anything, including stealing information to send back to the attacker.The attacker may also take measures to prevent detection throughout the attack. One method is to rely on the obfuscation of the malicious code. This can be done through the use of iframes. Another method is to encrypt the malicious code to prevent detection. Generally the attacker encrypts the malicious code into a ciphertext, then includes the decryption method after the ciphertext.\n\n== Detection and prevention ==\nDetection of drive-by download attacks is an active area of research. Some methods of detection involve anomaly detection, which tracks for state changes on a user's computer system while the user visits a webpage. This involves monitoring the user's computer system for anomalous changes when a web page is rendered. Other methods of detection include detecting when malicious code (shellcode) is written to memory by an attacker's exploit. Another detection method is to make run-time environments that allow JavaScript code to run and track its behavior while it runs. Other detection methods include examining contents of HTML pages to identify features that can be used to identify malicious web pages, and using characteristics of web servers to determine if a page is malicious. Some antivirus tools use static signatures to match patterns of malicious scripts, although these are not very effective because of obfuscation techniques. Detection is also possible by using low-interaction or high-interaction honeyclients.Drive-by downloads can also be prevented from occurring by using script-blockers such as NoScript, which can easily be added into browsers such as Firefox.  Using such a script-blocker, the user can disable all the scripts on a given webpage, and then selectively re-enable individual scripts on a one-by-one basis in order to determine which ones are truly necessary for webpage functionality.  However, some script-blocking tools can have unintended consequences, such as breaking parts of other websites, which can be a bit of a balancing act."
    }
  },
  {
    "instruction": "Several weaknesses have been found in the ME, including a Remote Elevation of Privilege bug (SA-00075), major security flaws affecting a large number of computers incorporating ME, Trusted Execution Engine (TXE), and Server Platform Services (SPS) firmware, and a ring -3 rootkit that can be installed regardless of whether the AMT is present or enabled on the system.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What are some of the security vulnerabilities found in the Intel ME?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What are some of the security vulnerabilities found in the Intel ME?",
      "answer": "Several weaknesses have been found in the ME, including a Remote Elevation of Privilege bug (SA-00075), major security flaws affecting a large number of computers incorporating ME, Trusted Execution Engine (TXE), and Server Platform Services (SPS) firmware, and a ring -3 rootkit that can be installed regardless of whether the AMT is present or enabled on the system."
    }
  },
  {
    "instruction": "The Nitrokey supports AES keys of up to 256 bits, which is a highly secure and widely used symmetric encryption algorithm. This makes the Nitrokey suitable for use in a variety of secure applications, such as disk encryption and secure file transfer.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What AES key sizes are supported by the Nitrokey?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What AES key sizes are supported by the Nitrokey?",
      "answer": "The Nitrokey supports AES keys of up to 256 bits, which is a highly secure and widely used symmetric encryption algorithm. This makes the Nitrokey suitable for use in a variety of secure applications, such as disk encryption and secure file transfer."
    }
  },
  {
    "instruction": "Location data, which is a class of personal data that is specifically hard to keep anonymous, can be re-identified or correlated with a person's private life contexts by mapping coordinates onto addresses. Streams of location information play an important role in the reconstruction of personal identifiers from smartphone data accessed by apps.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How can location data be re-identified or correlated with a person's private life contexts?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How can location data be re-identified or correlated with a person's private life contexts?",
      "answer": "Location data, which is a class of personal data that is specifically hard to keep anonymous, can be re-identified or correlated with a person's private life contexts by mapping coordinates onto addresses. Streams of location information play an important role in the reconstruction of personal identifiers from smartphone data accessed by apps."
    }
  },
  {
    "instruction": "Context: Authorization\n\n==Introduction==\nAuthorization or authorisation (see spelling differences) is the function of specifying access rights/privileges to resources, which is related to general information security and computer security, and to access control in particular. More formally, \"to authorize\" is to define an access policy. For example, human resources staff are normally authorized to access employee records and this policy is often formalized as access control rules in a computer system. During operation, the system uses the access control rules to decide whether access requests from (authenticated) consumers shall be approved (granted) or disapproved (rejected). Resources include individual files or an item's data, computer programs, computer devices and functionality provided by computer applications. Examples of consumers are computer users, computer software and other hardware on the computer.\n\n== Overview ==\nAccess control in computer systems and networks rely on access policies. The access control process can be divided into the following phases: policy definition phase where access is authorized, and policy enforcement phase where access requests are approved or disapproved. Authorization is the function of the policy definition phase which precedes the policy enforcement phase where access requests are approved or disapproved based on the previously defined authorizations.\nMost modern, multi-user operating systems include role-based access control (RBAC) and thereby rely on authorization. Access control also uses authentication to verify the identity of consumers. When a consumer tries to access a resource, the access control process checks that the consumer has been authorized to use that resource. Authorization is the responsibility of an authority, such as a department manager, within the application domain, but is often delegated to a custodian such as a system administrator. Authorizations are expressed as access policies in some types of \"policy definition application\", e.g. in the form of an access control list or a capability, or a policy administration point e.g. XACML. On the basis of the \"principle of least privilege\": consumers should only be authorized to access whatever they need to do their jobs. Older and single user operating systems often had weak or non-existent authentication and access control systems.\n\"Anonymous consumers\" or \"guests\", are consumers that have not been required to authenticate. They often have limited authorization. On a distributed system, it is often desirable to grant access without requiring a unique identity. Familiar examples of access tokens include keys, certificates and tickets: they grant access without proving identity.\nTrusted consumers are often authorized for unrestricted access to resources on a system, but must be verified so that the access control system can make the access approval decision. \"Partially trusted\" and guests will often have restricted authorization in order to protect resources against improper access and usage. The access policy in some operating systems, by default, grant all consumers full access to all resources. Others do the opposite, insisting that the administrator explicitly authorizes a consumer to use each resource.\nEven when access is controlled through a combination of authentication and access control lists, the problems of maintaining the authorization data is not trivial, and often represents as much administrative burden as managing authentication credentials. It is often necessary to change or remove a user's authorization: this is done by changing or deleting the corresponding access rules on the system. Using atomic authorization is an alternative to per-system authorization management, where a trusted third party securely distributes authorization information.\n\n== Related interpretations ==\n\n\n*** Public policy ***\nIn public policy, authorization is a feature of trusted systems used for security or social control.\n\n\n*** Banking ***\nIn banking, an authorization is a hold placed on a customer's account when a purchase is made using a debit card or credit card.\n\n\n*** Publishing ***\n\nIn publishing, sometimes public lectures and other freely available texts are published without the approval of the author. These are called unauthorized texts. An example is the 2002  'The Theory of Everything: The Origin and Fate of the Universe' , which was collected from Stephen Hawking's lectures and published without his permission as per copyright law.\nQuestion: What are access tokens and how are they used in access control?. Whats the answer?",
    "context": "",
    "output": "Access tokens, such as keys, certificates, and tickets, grant access to resources without proving identity. They are often used in distributed systems to grant access without requiring a unique identity.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What are access tokens and how are they used in access control?",
      "answer": "Access tokens, such as keys, certificates, and tickets, grant access to resources without proving identity. They are often used in distributed systems to grant access without requiring a unique identity.",
      "context": "Authorization\n\n==Introduction==\nAuthorization or authorisation (see spelling differences) is the function of specifying access rights/privileges to resources, which is related to general information security and computer security, and to access control in particular. More formally, \"to authorize\" is to define an access policy. For example, human resources staff are normally authorized to access employee records and this policy is often formalized as access control rules in a computer system. During operation, the system uses the access control rules to decide whether access requests from (authenticated) consumers shall be approved (granted) or disapproved (rejected). Resources include individual files or an item's data, computer programs, computer devices and functionality provided by computer applications. Examples of consumers are computer users, computer software and other hardware on the computer.\n\n== Overview ==\nAccess control in computer systems and networks rely on access policies. The access control process can be divided into the following phases: policy definition phase where access is authorized, and policy enforcement phase where access requests are approved or disapproved. Authorization is the function of the policy definition phase which precedes the policy enforcement phase where access requests are approved or disapproved based on the previously defined authorizations.\nMost modern, multi-user operating systems include role-based access control (RBAC) and thereby rely on authorization. Access control also uses authentication to verify the identity of consumers. When a consumer tries to access a resource, the access control process checks that the consumer has been authorized to use that resource. Authorization is the responsibility of an authority, such as a department manager, within the application domain, but is often delegated to a custodian such as a system administrator. Authorizations are expressed as access policies in some types of \"policy definition application\", e.g. in the form of an access control list or a capability, or a policy administration point e.g. XACML. On the basis of the \"principle of least privilege\": consumers should only be authorized to access whatever they need to do their jobs. Older and single user operating systems often had weak or non-existent authentication and access control systems.\n\"Anonymous consumers\" or \"guests\", are consumers that have not been required to authenticate. They often have limited authorization. On a distributed system, it is often desirable to grant access without requiring a unique identity. Familiar examples of access tokens include keys, certificates and tickets: they grant access without proving identity.\nTrusted consumers are often authorized for unrestricted access to resources on a system, but must be verified so that the access control system can make the access approval decision. \"Partially trusted\" and guests will often have restricted authorization in order to protect resources against improper access and usage. The access policy in some operating systems, by default, grant all consumers full access to all resources. Others do the opposite, insisting that the administrator explicitly authorizes a consumer to use each resource.\nEven when access is controlled through a combination of authentication and access control lists, the problems of maintaining the authorization data is not trivial, and often represents as much administrative burden as managing authentication credentials. It is often necessary to change or remove a user's authorization: this is done by changing or deleting the corresponding access rules on the system. Using atomic authorization is an alternative to per-system authorization management, where a trusted third party securely distributes authorization information.\n\n== Related interpretations ==\n\n\n*** Public policy ***\nIn public policy, authorization is a feature of trusted systems used for security or social control.\n\n\n*** Banking ***\nIn banking, an authorization is a hold placed on a customer's account when a purchase is made using a debit card or credit card.\n\n\n*** Publishing ***\n\nIn publishing, sometimes public lectures and other freely available texts are published without the approval of the author. These are called unauthorized texts. An example is the 2002  'The Theory of Everything: The Origin and Fate of the Universe' , which was collected from Stephen Hawking's lectures and published without his permission as per copyright law."
    }
  },
  {
    "instruction": "S/MIME (Secure/Multipurpose Internet Mail Extensions) is the standard for public-key encryption and signing of MIME data.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the standard for public-key encryption and signing of MIME data?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the standard for public-key encryption and signing of MIME data?",
      "answer": "S/MIME (Secure/Multipurpose Internet Mail Extensions) is the standard for public-key encryption and signing of MIME data."
    }
  },
  {
    "instruction": "Traceroute can be used to help identify incorrect routing table definitions or firewalls that may be blocking ICMP traffic or high port UDP in Unix ping. However, a correct traceroute response does not guarantee connectivity for applications as a firewall may permit ICMP packets but not permit packets of other protocols.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How can traceroute be used to identify issues with routing table definitions or firewalls?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How can traceroute be used to identify issues with routing table definitions or firewalls?",
      "answer": "Traceroute can be used to help identify incorrect routing table definitions or firewalls that may be blocking ICMP traffic or high port UDP in Unix ping. However, a correct traceroute response does not guarantee connectivity for applications as a firewall may permit ICMP packets but not permit packets of other protocols."
    }
  },
  {
    "instruction": "In a TE.TE attack, both the front-end and back-end servers process the request using the Transfer-Encoding header, but the header can be obfuscated in a way that makes one of the servers ignore it. If one of the servers still processes these obfuscated HTTP requests, the rest of the attack will be similar to how CL.TE or TE.CL attacks work.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does a TE.TE attack work when both the front-end and back-end servers process the request using the Transfer-Encoding header?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does a TE.TE attack work when both the front-end and back-end servers process the request using the Transfer-Encoding header?",
      "answer": "In a TE.TE attack, both the front-end and back-end servers process the request using the Transfer-Encoding header, but the header can be obfuscated in a way that makes one of the servers ignore it. If one of the servers still processes these obfuscated HTTP requests, the rest of the attack will be similar to how CL.TE or TE.CL attacks work."
    }
  },
  {
    "instruction": "Quantum simulation may be an important application of quantum computing in chemistry and nanotechnology, enabling the simulation of quantum systems that are impossible to simulate efficiently classically.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the potential impact of quantum computing on chemistry and nanotechnology?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the potential impact of quantum computing on chemistry and nanotechnology?",
      "answer": "Quantum simulation may be an important application of quantum computing in chemistry and nanotechnology, enabling the simulation of quantum systems that are impossible to simulate efficiently classically."
    }
  },
  {
    "instruction": "Peter Wayner proposed replacing large subway trains with competing fleets of smaller, thinner, and more nimble autonomous cars, scooters, hoverboards, and pods in an attempt to modernize and improve the efficiency of the city's public transportation.\n\nWrite a question about the text above.",
    "context": "",
    "output": "In what way did Peter Wayner suggest improving the New York City transit system?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "In what way did Peter Wayner suggest improving the New York City transit system?",
      "answer": "Peter Wayner proposed replacing large subway trains with competing fleets of smaller, thinner, and more nimble autonomous cars, scooters, hoverboards, and pods in an attempt to modernize and improve the efficiency of the city's public transportation."
    }
  },
  {
    "instruction": "Trickbot provides access-as-a-service to other malware by allowing it to access infected systems, potentially spreading further and causing more damage.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does Trickbot provide access-as-a-service to other malware?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does Trickbot provide access-as-a-service to other malware?",
      "answer": "Trickbot provides access-as-a-service to other malware by allowing it to access infected systems, potentially spreading further and causing more damage."
    }
  },
  {
    "instruction": "The Fun.Exe virus adds itself to auto-run information so that it executes multiple copies on startup.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does the Fun.Exe virus affect the system's startup process?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does the Fun.Exe virus affect the system's startup process?",
      "answer": "The Fun.Exe virus adds itself to auto-run information so that it executes multiple copies on startup."
    }
  },
  {
    "instruction": "An APIDS focuses its monitoring and analysis on a specific application protocol or protocols used by the computing system. It examines the dynamic behavior and state of the protocol to ensure the correct use of the protocol, and can even learn or be taught to recognize the subset of the application protocol used by the monitored application.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does an Application Protocol-based Intrusion Detection System (APIDS) focus its monitoring and analysis?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does an Application Protocol-based Intrusion Detection System (APIDS) focus its monitoring and analysis?",
      "answer": "An APIDS focuses its monitoring and analysis on a specific application protocol or protocols used by the computing system. It examines the dynamic behavior and state of the protocol to ensure the correct use of the protocol, and can even learn or be taught to recognize the subset of the application protocol used by the monitored application."
    }
  },
  {
    "instruction": "Crypto-anarchism, also known as cyberanarchism, is a political ideology that emphasizes the protection of privacy, political freedom, and economic freedom. Adherents of this ideology use cryptographic software to ensure confidentiality and security when sending and receiving information over computer networks, enabling total anonymity, freedom of speech, and trade.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is crypto-anarchism and how does it relate to political and economic freedom?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is crypto-anarchism and how does it relate to political and economic freedom?",
      "answer": "Crypto-anarchism, also known as cyberanarchism, is a political ideology that emphasizes the protection of privacy, political freedom, and economic freedom. Adherents of this ideology use cryptographic software to ensure confidentiality and security when sending and receiving information over computer networks, enabling total anonymity, freedom of speech, and trade."
    }
  },
  {
    "instruction": "CyberBerkut uses various methods, including distributed denial-of-service (DDoS) attacks, hacking, and publishing sensitive information to further their goals.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does CyberBerkut carry out their attacks?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does CyberBerkut carry out their attacks?",
      "answer": "CyberBerkut uses various methods, including distributed denial-of-service (DDoS) attacks, hacking, and publishing sensitive information to further their goals."
    }
  },
  {
    "instruction": "Chinese authorities have attempted to maintain control over the dissemination of political information on the Internet by establishing Internet censorship and by creating teams of internet commentators whose job is to guide discussion on public bulletin boards away from politically sensitive topics. They have also hired \"big mamas\" to help them identify and punish cyber-dissidents who express dissenting opinions.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How have Chinese authorities attempted to maintain control over the dissemination of political information on the Internet?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How have Chinese authorities attempted to maintain control over the dissemination of political information on the Internet?",
      "answer": "Chinese authorities have attempted to maintain control over the dissemination of political information on the Internet by establishing Internet censorship and by creating teams of internet commentators whose job is to guide discussion on public bulletin boards away from politically sensitive topics. They have also hired \"big mamas\" to help them identify and punish cyber-dissidents who express dissenting opinions."
    }
  },
  {
    "instruction": "IBM Cloud Hyper Protect Services is one of the public cloud services offered by IBM that utilizes the IBM Secure Service Container (SSC) technology.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How is the IBM Secure Service Container (SSC) related to IBM Cloud Hyper Protect Services?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How is the IBM Secure Service Container (SSC) related to IBM Cloud Hyper Protect Services?",
      "answer": "IBM Cloud Hyper Protect Services is one of the public cloud services offered by IBM that utilizes the IBM Secure Service Container (SSC) technology."
    }
  },
  {
    "instruction": "HAIPE is being inserted into client devices that provide both wired and wireless capabilities, such as L3Harris Technologies' KOV-26 Talon and KOV-26B Talon2, and Harris Corporation's KIV-54 and PRC-117G radio.\n\nWrite a question about the text above.",
    "context": "",
    "output": "Into what types of devices is HAIPE being inserted?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "Into what types of devices is HAIPE being inserted?",
      "answer": "HAIPE is being inserted into client devices that provide both wired and wireless capabilities, such as L3Harris Technologies' KOV-26 Talon and KOV-26B Talon2, and Harris Corporation's KIV-54 and PRC-117G radio."
    }
  },
  {
    "instruction": "Microsoft was responsible for taking down the Waledac botnet.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What company was responsible for taking down the Waledac botnet?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What company was responsible for taking down the Waledac botnet?",
      "answer": "Microsoft was responsible for taking down the Waledac botnet."
    }
  },
  {
    "instruction": "The PSA Joint Stakeholders Agreement outlines how members can create a worldwide standard for IoT security, enabling the electronic industry to have an easy-to-understand security scheme.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the PSA Joint Stakeholders Agreement and how does it contribute to the IoT industry?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the PSA Joint Stakeholders Agreement and how does it contribute to the IoT industry?",
      "answer": "The PSA Joint Stakeholders Agreement outlines how members can create a worldwide standard for IoT security, enabling the electronic industry to have an easy-to-understand security scheme."
    }
  },
  {
    "instruction": "Guards were initially designed to control the release of information from classified systems, protecting the confidentiality of the sensitive information handled by the protected system.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What was the initial purpose of guards in information security?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What was the initial purpose of guards in information security?",
      "answer": "Guards were initially designed to control the release of information from classified systems, protecting the confidentiality of the sensitive information handled by the protected system."
    }
  },
  {
    "instruction": "OpenBSD's development process is open and tiered, with anyone with appropriate skills able to contribute. The project releases two official versions per year, with maintenance patches and upgrades available for supported releases. The generic OpenBSD kernel is recommended for end users, and packages outside the base system are maintained by individual maintainers known as porters.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does OpenBSD's development process differ from other operating systems?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does OpenBSD's development process differ from other operating systems?",
      "answer": "OpenBSD's development process is open and tiered, with anyone with appropriate skills able to contribute. The project releases two official versions per year, with maintenance patches and upgrades available for supported releases. The generic OpenBSD kernel is recommended for end users, and packages outside the base system are maintained by individual maintainers known as porters."
    }
  },
  {
    "instruction": "The TDF Specification is freely available and can be used by anyone.\n\nWrite a question about the text above.",
    "context": "",
    "output": "Who can use the TDF Specification?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "Who can use the TDF Specification?",
      "answer": "The TDF Specification is freely available and can be used by anyone."
    }
  },
  {
    "instruction": "Silent Circle and Geeksphone created a joint venture called SGP Technologies, which built the Blackphone - a smartphone designed for privacy.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What was the joint venture between Silent Circle and Geeksphone, and what product did they create?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What was the joint venture between Silent Circle and Geeksphone, and what product did they create?",
      "answer": "Silent Circle and Geeksphone created a joint venture called SGP Technologies, which built the Blackphone - a smartphone designed for privacy."
    }
  },
  {
    "instruction": "The IRS Phone Scam was a voice phishing scam ring that posed as Internal Revenue Service and immigration employees to more than 50,000 individuals, stealing hundreds of millions of dollars as well as victims\u2019 personal information. Alleged co-conspirators from the United States and India threatened vulnerable respondents with \u201carrest, imprisonment, fines, or deportation.\u201d\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the IRS Phone Scam, and how did it defraud victims between 2012 and 2016?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the IRS Phone Scam, and how did it defraud victims between 2012 and 2016?",
      "answer": "The IRS Phone Scam was a voice phishing scam ring that posed as Internal Revenue Service and immigration employees to more than 50,000 individuals, stealing hundreds of millions of dollars as well as victims\u2019 personal information. Alleged co-conspirators from the United States and India threatened vulnerable respondents with \u201carrest, imprisonment, fines, or deportation.\u201d"
    }
  },
  {
    "instruction": "Context: Non-interference (security)\n\n==Introduction==\nNoninterference is a strict multilevel security policy model, first described by Goguen and Meseguer in 1982, and amplified further in 1984.\n\n== Introduction ==\nIn simple terms, a computer is modeled as a machine with inputs and outputs. Inputs and outputs are classified as either low (low sensitivity, not highly classified) or high (sensitive, not to be viewed by uncleared individuals). A computer has the noninterference property if and only if any sequence of low inputs will produce the same low outputs, regardless of what the high level inputs are. \nThat is, if a low (uncleared) user is working on the machine, it will respond in exactly the same manner (on the low outputs) whether or not a high (cleared) user is working with sensitive data. The low user will not be able to acquire any information about the activities (if any) of the high user.\n\n== Formal expression ==\nLet \n  \n    \n      \n        M\n      \n    \n    {\\displaystyle M}\n   be a memory configuration, and let \n  \n    \n      \n        \n          M\n          \n            L\n          \n        \n      \n    \n    {\\displaystyle M_{\\text{L}}}\n   and \n  \n    \n      \n        \n          M\n          \n            H\n          \n        \n      \n    \n    {\\displaystyle M_{H}}\n   be the projection of the memory \n  \n    \n      \n        M\n      \n    \n    {\\displaystyle M}\n   to the low and high parts, respectively. Let\n\n== Limitations ==\n\n\n*** Strictness ***\nThis is a very strict policy, in that a computer system with covert channels may comply with, say, the Bell\u2013LaPadula model, but will not comply with noninterference.  The reverse could be true (under reasonable conditions, being that the system should have labelled files, etc.) except for the \"No classified information at startup\" exceptions noted below.  However, noninterference has been shown to be stronger than nondeducibility.\nThis strictness comes with a price. It is very difficult to make a computer system with this property. There may be only one or two commercially available products that have been verified to comply with this policy, and these would essentially be as simple as switches and one-way information filters (although these could be arranged to provide useful behaviour).\n\n\n*** No classified information at startup ***\nIf the computer has (at time\n\n== Generalizations ==\nThe noninterference property requires that the system should not reveal any information about the high inputs from the observable output for various low inputs. However, one can argue that achieving noninterference is oftentimes not possible for a large class of practical systems, and moreover, it may not be desirable: programs need to reveal information that depends on the secret inputs, e.g. the output must be different when a user enters a correct credential vs. when she enters incorrect credentials. Shannon entropy, guessing entropy, and min-entropy are prevalent notions of quantitative information leakage that generalize noninterference.\nQuestion: How do notions of quantitative information leakage generalize the noninterference property?. Whats the answer?",
    "context": "",
    "output": "Notions of quantitative information leakage, such as Shannon entropy, guessing entropy, and min-entropy, generalize the noninterference property by allowing for some information leakage while still providing a measure of confidentiality in a computer system. This is useful because achieving noninterference is not always possible or desirable in practical systems.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How do notions of quantitative information leakage generalize the noninterference property?",
      "answer": "Notions of quantitative information leakage, such as Shannon entropy, guessing entropy, and min-entropy, generalize the noninterference property by allowing for some information leakage while still providing a measure of confidentiality in a computer system. This is useful because achieving noninterference is not always possible or desirable in practical systems.",
      "context": "Non-interference (security)\n\n==Introduction==\nNoninterference is a strict multilevel security policy model, first described by Goguen and Meseguer in 1982, and amplified further in 1984.\n\n== Introduction ==\nIn simple terms, a computer is modeled as a machine with inputs and outputs. Inputs and outputs are classified as either low (low sensitivity, not highly classified) or high (sensitive, not to be viewed by uncleared individuals). A computer has the noninterference property if and only if any sequence of low inputs will produce the same low outputs, regardless of what the high level inputs are. \nThat is, if a low (uncleared) user is working on the machine, it will respond in exactly the same manner (on the low outputs) whether or not a high (cleared) user is working with sensitive data. The low user will not be able to acquire any information about the activities (if any) of the high user.\n\n== Formal expression ==\nLet \n  \n    \n      \n        M\n      \n    \n    {\\displaystyle M}\n   be a memory configuration, and let \n  \n    \n      \n        \n          M\n          \n            L\n          \n        \n      \n    \n    {\\displaystyle M_{\\text{L}}}\n   and \n  \n    \n      \n        \n          M\n          \n            H\n          \n        \n      \n    \n    {\\displaystyle M_{H}}\n   be the projection of the memory \n  \n    \n      \n        M\n      \n    \n    {\\displaystyle M}\n   to the low and high parts, respectively. Let\n\n== Limitations ==\n\n\n*** Strictness ***\nThis is a very strict policy, in that a computer system with covert channels may comply with, say, the Bell\u2013LaPadula model, but will not comply with noninterference.  The reverse could be true (under reasonable conditions, being that the system should have labelled files, etc.) except for the \"No classified information at startup\" exceptions noted below.  However, noninterference has been shown to be stronger than nondeducibility.\nThis strictness comes with a price. It is very difficult to make a computer system with this property. There may be only one or two commercially available products that have been verified to comply with this policy, and these would essentially be as simple as switches and one-way information filters (although these could be arranged to provide useful behaviour).\n\n\n*** No classified information at startup ***\nIf the computer has (at time\n\n== Generalizations ==\nThe noninterference property requires that the system should not reveal any information about the high inputs from the observable output for various low inputs. However, one can argue that achieving noninterference is oftentimes not possible for a large class of practical systems, and moreover, it may not be desirable: programs need to reveal information that depends on the secret inputs, e.g. the output must be different when a user enters a correct credential vs. when she enters incorrect credentials. Shannon entropy, guessing entropy, and min-entropy are prevalent notions of quantitative information leakage that generalize noninterference."
    }
  },
  {
    "instruction": "Organizations that fail to comply with regulations and laws that mandate SAT for organizations in specific industries may face penalties, fines, or legal action.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What are the consequences of non-compliance with regulations and laws that mandate SAT for organizations in specific industries?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What are the consequences of non-compliance with regulations and laws that mandate SAT for organizations in specific industries?",
      "answer": "Organizations that fail to comply with regulations and laws that mandate SAT for organizations in specific industries may face penalties, fines, or legal action."
    }
  },
  {
    "instruction": "Ping of death\n\n==Introduction==\nA ping of death is a type of attack on a computer system that involves sending a malformed or otherwise malicious ping to a computer.A correctly formed ping packet is typically 56 bytes in size, or 64 bytes when the Internet Control Message Protocol (ICMP) header is considered, and 84 bytes including Internet Protocol (IP) version 4 header. However, any IPv4 packet (including pings) may be as large as 65,535 bytes. Some computer systems were never designed to properly handle a ping packet larger than the maximum packet size because it violates the Internet Protocol. Like other large but well-formed packets, a ping of death is fragmented into groups of 8 octets before transmission. However, when the target computer reassembles the malformed packet, a buffer overflow can occur, causing a system crash and potentially allowing the injection of malicious code.\nIn early implementations of TCP/IP, this bug is easy to exploit and can affect a wide variety of systems including Unix, Linux, Mac, Windows, and peripheral devices. As systems began filtering out pings of death through firewalls and other detection methods, a different kind of ping attack known as ping flooding later appeared, which floods the victim with so many ping requests that normal traffic fails to reach the system (a basic denial-of-service attack).\n\n== Detailed information ==\nThe maximum packet length of an IPv4 packet including the IP header is 65,535 (216 \u2212 1) bytes, a limitation presented by the use of a 16-bit wide IP header field that describes the total packet length.\nThe underlying data link layer almost always poses limits to the maximum frame size (See MTU). In Ethernet, this is typically 1500 bytes. In such a case, a large IP packet is split across multiple IP packets (also known as IP fragments), so that each IP fragment will match the imposed limit. The receiver of the IP fragments will reassemble them into the complete IP packet and continue processing it as usual.\nWhen fragmentation is performed, each IP fragment needs to carry information about which part of the original IP packet it contains. This information is kept in the Fragment Offset field, in the IP header. The field is 13 bits long, and contains the offset of the data in the current IP fragment, in the original IP packet. The offset is given in units of 8 bytes. This allows a maximum offset of 65,528 ((213-1)*8). Then when adding 20 bytes of IP header, the maximum will be 65,548 bytes, which exceeds the maximum frame size. This means that an IP fragment with the maximum offset should have data no larger than 7 bytes, or else it would exceed the limit of the maximum packet length. A malicious user can send an IP fragment with the maximum offset and with much more data than 8 bytes (as large as the physical layer allows it to be).\nWhen the receiver assembles all IP fragments, it will end up with an IP packet which is larger than 65,535 bytes. This may possibly overflow memory buffers which the receiver allocated for the packet, and can cause various problems.\nAs is evident from the description above, the problem has nothing to do with ICMP, which is used only as payload, big enough to exploit the problem. It is a problem in the reassembly process of IP fragments, which may contain any type of protocol (TCP, UDP, IGMP, etc.).\nThe correction of the problem is to add checks in the reassembly process. The check for each incoming IP fragment makes sure that the sum of \"Fragment Offset\" and \"Total length\" fields in the IP header of each IP fragment is smaller or equal to 65,535. If the sum is greater, then the packet is invalid, and the IP fragment is ignored.\nThis check is performed by some firewalls, to protect hosts that do not have the bug fixed.\nAnother fix for the problem is using a memory buffer larger than 65,535 bytes for the re-assembly of the packet. (This is essentially a breaking of the specification, since it adds support for packets larger than those allowed.)\n\n\n*** Ping of death in IPv6 ***\nIn 2013, an IPv6 version of the ping of death vulnerability was discovered in Microsoft Windows. Windows TCP/IP stack did not handle memory allocation correctly when processing incoming malformed ICMPv6 packets, which could cause remote denial of service. This vulnerability was fixed in MS13-065 in August 2013. The CVE-ID for this vulnerability is CVE-2013-3183. In 2020, another bug (CVE-2020-16898) in ICMPv6 was found around Router Advertisement, which could even lead to remote code execution. Answer this question using the following article:\n\nWhat is the purpose of the check performed in the reassembly process of IP fragments?",
    "context": "",
    "output": "The purpose of the check performed in the reassembly process of IP fragments is to ensure that the sum of the \"Fragment Offset\" and \"Total length\" fields in the IP header of each IP fragment is smaller or equal to 65,535. If the sum is greater, the packet is invalid and the IP fragment is ignored. This check is performed by some firewalls to protect hosts that do not have the bug fixed.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the purpose of the check performed in the reassembly process of IP fragments?",
      "answer": "The purpose of the check performed in the reassembly process of IP fragments is to ensure that the sum of the \"Fragment Offset\" and \"Total length\" fields in the IP header of each IP fragment is smaller or equal to 65,535. If the sum is greater, the packet is invalid and the IP fragment is ignored. This check is performed by some firewalls to protect hosts that do not have the bug fixed.",
      "context": "Ping of death\n\n==Introduction==\nA ping of death is a type of attack on a computer system that involves sending a malformed or otherwise malicious ping to a computer.A correctly formed ping packet is typically 56 bytes in size, or 64 bytes when the Internet Control Message Protocol (ICMP) header is considered, and 84 bytes including Internet Protocol (IP) version 4 header. However, any IPv4 packet (including pings) may be as large as 65,535 bytes. Some computer systems were never designed to properly handle a ping packet larger than the maximum packet size because it violates the Internet Protocol. Like other large but well-formed packets, a ping of death is fragmented into groups of 8 octets before transmission. However, when the target computer reassembles the malformed packet, a buffer overflow can occur, causing a system crash and potentially allowing the injection of malicious code.\nIn early implementations of TCP/IP, this bug is easy to exploit and can affect a wide variety of systems including Unix, Linux, Mac, Windows, and peripheral devices. As systems began filtering out pings of death through firewalls and other detection methods, a different kind of ping attack known as ping flooding later appeared, which floods the victim with so many ping requests that normal traffic fails to reach the system (a basic denial-of-service attack).\n\n== Detailed information ==\nThe maximum packet length of an IPv4 packet including the IP header is 65,535 (216 \u2212 1) bytes, a limitation presented by the use of a 16-bit wide IP header field that describes the total packet length.\nThe underlying data link layer almost always poses limits to the maximum frame size (See MTU). In Ethernet, this is typically 1500 bytes. In such a case, a large IP packet is split across multiple IP packets (also known as IP fragments), so that each IP fragment will match the imposed limit. The receiver of the IP fragments will reassemble them into the complete IP packet and continue processing it as usual.\nWhen fragmentation is performed, each IP fragment needs to carry information about which part of the original IP packet it contains. This information is kept in the Fragment Offset field, in the IP header. The field is 13 bits long, and contains the offset of the data in the current IP fragment, in the original IP packet. The offset is given in units of 8 bytes. This allows a maximum offset of 65,528 ((213-1)*8). Then when adding 20 bytes of IP header, the maximum will be 65,548 bytes, which exceeds the maximum frame size. This means that an IP fragment with the maximum offset should have data no larger than 7 bytes, or else it would exceed the limit of the maximum packet length. A malicious user can send an IP fragment with the maximum offset and with much more data than 8 bytes (as large as the physical layer allows it to be).\nWhen the receiver assembles all IP fragments, it will end up with an IP packet which is larger than 65,535 bytes. This may possibly overflow memory buffers which the receiver allocated for the packet, and can cause various problems.\nAs is evident from the description above, the problem has nothing to do with ICMP, which is used only as payload, big enough to exploit the problem. It is a problem in the reassembly process of IP fragments, which may contain any type of protocol (TCP, UDP, IGMP, etc.).\nThe correction of the problem is to add checks in the reassembly process. The check for each incoming IP fragment makes sure that the sum of \"Fragment Offset\" and \"Total length\" fields in the IP header of each IP fragment is smaller or equal to 65,535. If the sum is greater, then the packet is invalid, and the IP fragment is ignored.\nThis check is performed by some firewalls, to protect hosts that do not have the bug fixed.\nAnother fix for the problem is using a memory buffer larger than 65,535 bytes for the re-assembly of the packet. (This is essentially a breaking of the specification, since it adds support for packets larger than those allowed.)\n\n\n*** Ping of death in IPv6 ***\nIn 2013, an IPv6 version of the ping of death vulnerability was discovered in Microsoft Windows. Windows TCP/IP stack did not handle memory allocation correctly when processing incoming malformed ICMPv6 packets, which could cause remote denial of service. This vulnerability was fixed in MS13-065 in August 2013. The CVE-ID for this vulnerability is CVE-2013-3183. In 2020, another bug (CVE-2020-16898) in ICMPv6 was found around Router Advertisement, which could even lead to remote code execution."
    }
  },
  {
    "instruction": "WTLS uses compressed data structures, such as bit-fields, to reduce packet sizes and optimize for low bandwidth mobile devices.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does WTLS differ from TLS in terms of data structures?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does WTLS differ from TLS in terms of data structures?",
      "answer": "WTLS uses compressed data structures, such as bit-fields, to reduce packet sizes and optimize for low bandwidth mobile devices."
    }
  },
  {
    "instruction": "The best current practices for network ingress filtering are documented by the Internet Engineering Task Force in BCP 38 and 84, which are defined by RFC 2827 and RFC 3704, respectively.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What are the best current practices for network ingress filtering?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What are the best current practices for network ingress filtering?",
      "answer": "The best current practices for network ingress filtering are documented by the Internet Engineering Task Force in BCP 38 and 84, which are defined by RFC 2827 and RFC 3704, respectively."
    }
  },
  {
    "instruction": "Memory forensics is most commonly used in investigations of advanced computer attacks that are stealthy enough to avoid leaving data on the computer's hard drive. These attacks can be difficult to detect using traditional hard drive forensics, making memory forensics a critical tool for uncovering evidence of these attacks. By analyzing the memory dump, investigators can gain insights into the attacker's behavior, the tools and techniques used in the attack, and the extent of the damage caused. This information can be critical in identifying and mitigating the effects of the attack, as well as in bringing the attackers to justice.\n\nWrite a question about the text above.",
    "context": "",
    "output": "In what types of investigations is memory forensics most commonly used?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "In what types of investigations is memory forensics most commonly used?",
      "answer": "Memory forensics is most commonly used in investigations of advanced computer attacks that are stealthy enough to avoid leaving data on the computer's hard drive. These attacks can be difficult to detect using traditional hard drive forensics, making memory forensics a critical tool for uncovering evidence of these attacks. By analyzing the memory dump, investigators can gain insights into the attacker's behavior, the tools and techniques used in the attack, and the extent of the damage caused. This information can be critical in identifying and mitigating the effects of the attack, as well as in bringing the attackers to justice."
    }
  },
  {
    "instruction": "firewalld v0.9.0 added native support for forward and output forwarding via policy objects. This allows filtering traffic flowing between zones. Policies support most firewalld primitives available to zones: services, ports, forward-ports, masquerade, rich rules, etc.\n\nWrite a question about the text above.",
    "context": "",
    "output": "How does firewalld allow filtering traffic flowing between zones?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "How does firewalld allow filtering traffic flowing between zones?",
      "answer": "firewalld v0.9.0 added native support for forward and output forwarding via policy objects. This allows filtering traffic flowing between zones. Policies support most firewalld primitives available to zones: services, ports, forward-ports, masquerade, rich rules, etc."
    }
  },
  {
    "instruction": "The Blue Hat Microsoft Hacker Conference is an invitation-only conference created by Window Snyder that is intended to open communication between Microsoft engineers and hackers.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What is the Blue Hat Microsoft Hacker Conference?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What is the Blue Hat Microsoft Hacker Conference?",
      "answer": "The Blue Hat Microsoft Hacker Conference is an invitation-only conference created by Window Snyder that is intended to open communication between Microsoft engineers and hackers."
    }
  },
  {
    "instruction": "SMBRelay and SMBRelay2 exploit a security vulnerability in the SMB protocol that allows for man-in-the-middle attacks. This vulnerability existed since the protocol's inception, and it is a fundamental design flaw rather than a bug.\n\nWrite a question about the text above.",
    "context": "",
    "output": "What security vulnerability do SMBRelay and SMBRelay2 exploit?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "What security vulnerability do SMBRelay and SMBRelay2 exploit?",
      "answer": "SMBRelay and SMBRelay2 exploit a security vulnerability in the SMB protocol that allows for man-in-the-middle attacks. This vulnerability existed since the protocol's inception, and it is a fundamental design flaw rather than a bug."
    }
  },
  {
    "instruction": "The hacker \"Pompompurin\" denied being Canadian hacker Chris Meunier in an interview with ProPublica.\n\nWrite a question about the text above.",
    "context": "",
    "output": "Who did the hacker \"Pompompurin\" deny being in an interview with ProPublica?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval2",
    "parsed_raw_data": {
      "question": "Who did the hacker \"Pompompurin\" deny being in an interview with ProPublica?",
      "answer": "The hacker \"Pompompurin\" denied being Canadian hacker Chris Meunier in an interview with ProPublica."
    }
  }
]